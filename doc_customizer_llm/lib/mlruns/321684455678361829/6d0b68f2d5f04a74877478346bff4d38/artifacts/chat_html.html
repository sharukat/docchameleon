    <p style="color:black;">Human: <br>Use the following pieces of context to answer the question at the end.  If you do not know the answer, please think rationally and answer from your own knowledge base.<br><br>Title: how to load and use a saved model on tensorflow?<br><br>Body: <p>I have found 2 ways to save a model in Tensorflow: <code>tf.train.Saver()</code> and <code>SavedModelBuilder</code>. However, <strong>I can't find documentation on using the model</strong> after it being loaded  the second way.</p><br>Title: How to restore dangling tf.py_func within the tf.data.Dataset() with tf.saved_model API?<br><br>Body: <p>After doing a research for restoring the <code>tf.py_func()</code> when using saved_model API in vain, I couldn't find other information than documented in <a href="https://www.tensorflow.org/api_docs/python/tf/py_func" rel="nofollow noreferrer">tensorflow</a>:</p><br>Title: KeyError: u'NearestNeighbors' on loading saved model from tf.contrib.factorization.KMeansClustering<br><br>Body: <p>I am trying to do the following:</p><br><br><ul><br><li>Run kmeans clustering using tensorflow (1.8.0)</li><br><li>Save the model using <code>kmeans.export_savedmodel</code></li><br><li>Use the model using <code>tf.saved_model.loader.load</code></li><br></ul><br><br>Inadequate Examples definition:<br>Issues that mention the documentation has insufficient examples.<br><br><br>Below is a Stack Overflow question posted by a user related to documentation replication on other examples.<br><br>Question Title: How to retrain a model that was saved using the tf.saved_model.save() function in Tensorflow<br>Question Body: <p>I am building a Neural Machine Translator for English to Konkani (a local language) language using the Transformer architecture proposed by (Vaswani et, al. 2017). I am following the tutorial code from <a href="https://www.tensorflow.org/text/tutorials/transformer" rel="nofollow noreferrer">https://www.tensorflow.org/text/tutorials/transformer</a>. I have trained the model and used the <code>tf.saved_model.save()</code> method to save the model files locally.</p><br><p>I now want to retrain that saved model on a new dataset that I have gathered recently, but I've realised that after loading the model using the <code>tf.saved_model.load()</code> method, I am not able to train it again as the loaded model now lacks the necessary method <code>model.fit()</code> .</p><br><p>Here is a part of the model training code:</p><br><pre class="lang-py prettyprint-override"><code>class Transformer(tf.keras.Model):<br>  def __init__(self, *, num_layers, d_model, num_heads, dff,<br>               input_vocab_size, target_vocab_size, dropout_rate=0.1):<br>    super().__init__()<br>    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,<br>                           num_heads=num_heads, dff=dff,<br>                           vocab_size=input_vocab_size,<br>                           dropout_rate=dropout_rate)<br><br>    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,<br>                           num_heads=num_heads, dff=dff,<br>                           vocab_size=target_vocab_size,<br>                           dropout_rate=dropout_rate)<br><br>    self.final_layer = tf.keras.layers.Dense(target_vocab_size)<br><br>  def call(self, inputs):<br>    # To use a Keras model with `.fit` you must pass all your inputs in the<br>    # first argument.<br>    context, x  = inputs<br><br>    context = self.encoder(context)  # (batch_size, context_len, d_model)<br><br>    x = self.decoder(x, context)  # (batch_size, target_len, d_model)<br><br>    # Final linear layer output.<br>    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)<br><br>    try:<br>      # Drop the keras mask, so it doesn't scale the losses/metrics.<br>      # b/250038731<br>      del logits._keras_mask<br>    except AttributeError:<br>      pass<br><br>    # Return the final output and the attention weights.<br>    return logits<br>#-----------------------------------------------------------------------<br><br>#...&lt;code to define optimizers and loss functions&gt;...<br><br># This Class acts as an interface for the Transformer<br>class Translator(tf.Module):<br>  def __init__(self, context_tokenizers, target_tokenizers, transformer):<br>    self.context_tokenizers = context_tokenizers<br>    self.target_tokenizers = target_tokenizers<br>    self.transformer = transformer<br><br>  def __call__(self, sentence, max_length=MAX_TOKENS): #max_length=MAX_TOKENS<br>    assert isinstance(sentence, tf.Tensor)<br>    if len(sentence.shape) == 0:<br>      sentence = sentence[tf.newaxis]<br><br>    sentence = tokenize(sentence,self.context_tokenizers).to_tensor()<br><br>    encoder_input = sentence<br><br>    # As the output language is English, initialize the output with the<br>    # English `[START]` token.<br><br>    start_end = tokenize('',self.target_tokenizers)[0]<br>    start = start_end[0][tf.newaxis]<br>    end = start_end[-1][tf.newaxis]<br><br>    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)<br>    output_array = output_array.write(0, start)<br><br>    for i in tf.range(max_length):<br>      output = tf.transpose(output_array.stack())<br>      predictions = self.transformer([encoder_input, output], training=False)<br><br>      # Select the last token from the `seq_len` dimension.<br>      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.<br><br>      predicted_id = tf.argmax(predictions, axis=-1)<br><br>      # Concatenate the `predicted_id` to the output which is given to the<br>      # decoder as its input.<br>      output_array = output_array.write(i+1, predicted_id[0])<br><br>      if predicted_id == end:<br>        break<br><br>    output = tf.transpose(output_array.stack())<br>    # The output shape is `(1, tokens)`.<br><br>    text = self.target_tokenizers.detokenize(output)<br><br>    tokens = tf.gather(target_vocab, output)<br><br>    # `tf.function` prevents us from using the attention_weights that were<br>    # calculated on the last iteration of the loop.<br>    # So, recalculate them outside the loop.<br>    self.transformer([encoder_input, output[:,:-1]], training=False)<br>    attention_weights = self.transformer.decoder.last_attn_scores<br><br>    joined_text = tf.strings.reduce_join(text[0][1:-1], separator=' ', axis=-1)<br>    return joined_text, tokens, attention_weights<br>#-----------------------------------------------------------------------<br><br>class ExportTranslator(tf.Module):<br>  def __init__(self, translator):<br>    self.translator = translator<br><br>  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])<br>  def __call__(self, sentence):<br>    (result,<br>     tokens,<br>     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)<br><br>    return result<br>#-----------------------------------------------------------------------<br><br>transformer = Transformer(<br>    num_layers=num_layers,<br>    d_model=d_model,<br>    num_heads=num_heads,<br>    dff=dff,<br>    input_vocab_size=context_vocab_size,<br>    target_vocab_size=target_vocab_size,<br>    dropout_rate=dropout_rate)<br><br>transformer.compile(<br>    loss=masked_loss,<br>    optimizer=optimizer,<br>    metrics=[masked_accuracy])<br><br># training the model on the training data for some epochs<br>transformer.fit(train_batches,<br>                epochs=20,<br>                validation_data=val_batches,<br>                callbacks=[<br>                  tf.keras.callbacks.EarlyStopping(patience=3)],<br>                )<br><br>translator = Translator(context_tokenizer, target_tokenizer, transformer)<br><br>exp_translator = ExportTranslator(translator)<br><br>#saving the model<br>tf.saved_model.save(exp_translator, export_dir=MODEL_SAVED_FILES)<br><br>#-----------------------------------------------------------------------<br><br>#loading a saved model<br>reloaded = tf.saved_model.load(MODEL_SAVED_FILES)<br></code></pre><br><p>Here's the error I get when I try to retrain the model using the following code:</p><br><pre class="lang-py prettyprint-override"><code>reloaded = tf.saved_model.load(MODEL_SAVED_FILES)<br><br>#retraing the model on new dataset<br>reloaded.translator.transformer.fit(train_batches,<br>                epochs=20,<br>                validation_data=val_batches,<br>                callbacks=[<br>                  tf.keras.callbacks.EarlyStopping(patience=3)],<br>                )<br></code></pre><br><p>The error:</p><br><pre class="lang-py prettyprint-override"><code><br>---------------------------------------------------------------------------<br><br>AttributeError                            Traceback (most recent call last)<br><br>&lt;ipython-input-41-ad1b625ff6c0&gt; in &lt;cell line: 2&gt;()<br>      1 #retraing the model on new dataset<br>----&gt; 2 reloaded.translator.transformer.fit(train_batches,<br>      3                 epochs=20,<br>      4                 validation_data=val_batches,<br>      5                 callbacks=[<br><br>AttributeError: '_UserObject' object has no attribute 'fit'<br></code></pre><br><p>After reading the documentation I've realised that when saving the model in the above method, the <code>model.fit()</code> and other methods are not saved hence they are not callable.</p><br><p>I need help in finding a way to retrain my saved model, It is not feasible for me to train a new model on a combined dataset as It will take up lot of time and I have very limited resources. I have been looking up on the web for days but couldn't find a solution. Any help in this regards will be appreciated!</p><br><br><br>Provide multiple complete examples to showcase its usability with respect to the question asked by the user.. And this customization will enhance the understandability of the documentation while avoiding any questions like this in future.<br>:</p>    <blockquote>      <p style="color:green;">        The user is asking for examples on how to retrain a model that was saved using the `tf.saved_model.save()` function in TensorFlow. They have tried loading the saved model using `tf.saved_model.load()` but are unable to train it again as the loaded model lacks the necessary method `model.fit()`.<br><br>To address this issue, the documentation can provide multiple complete examples that showcase the usability of the `tf.saved_model.save()` function and how to retrain the saved model. These examples should include the necessary steps to load the saved model and perform training on new datasets.<br><br>Example 1: Retraining a saved model using `tf.saved_model.save()` and `tf.saved_model.load()`<br><br>```python<br># Training and saving the model<br>model = tf.keras.Sequential([...])  # Define your model architecture<br>model.compile([...])  # Compile the model with loss and optimizer<br>model.fit(train_data, epochs=10)  # Train the model<br>tf.saved_model.save(model, 'saved_model')  # Save the model<br><br># Loading the saved model and retraining<br>loaded_model = tf.saved_model.load('saved_model')  # Load the saved model<br>loaded_model.compile([...])  # Compile the loaded model with loss and optimizer<br>loaded_model.fit(new_train_data, epochs=5)  # Retrain the model on new dataset<br>```<br><br>Example 2: Retraining a saved model using `tf.saved_model.save()` and custom training loop<br><br>```python<br># Training and saving the model<br>model = tf.keras.Sequential([...])  # Define your model architecture<br>optimizer = tf.keras.optimizers.Adam()<br>loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()<br>for epoch in range(10):<br>    for batch in train_data:<br>        with tf.GradientTape() as tape:<br>            logits = model(batch['input'])<br>            loss_value = loss_fn(batch['target'], logits)<br>        grads = tape.gradient(loss_value, model.trainable_variables)<br>        optimizer.apply_gradients(zip(grads, model.trainable_variables))<br>tf.saved_model.save(model, 'saved_model')  # Save the model<br><br># Loading the saved model and retraining<br>loaded_model = tf.saved_model.load('saved_model')  # Load the saved model<br>optimizer = tf.keras.optimizers.Adam()<br>loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()<br>for epoch in range(5):<br>    for batch in new_train_data:<br>        with tf.GradientTape() as tape:<br>            logits = loaded_model(batch['input'])<br>            loss_value = loss_fn(batch['target'], logits)<br>        grads = tape.gradient(loss_value, loaded_model.trainable_variables)<br>        optimizer.apply_gradients(zip(grads, loaded_model.trainable_variables))<br>```<br><br>These examples demonstrate how to save a model using `tf.saved_model.save()` and then load and retrain the saved model using `tf.saved_model.load()`. The examples include both the usage of `model.fit()` and a custom training loop to showcase different approaches to retraining the model.      </p>    </blockquote>    