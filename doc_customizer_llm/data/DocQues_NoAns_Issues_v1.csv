QuestionId,Title,Body,CreationDate,UserId,UserReputation,QuestionURL,IssueType
36295624,Tensorflow loss not decreasing and acuraccy stuck at 0.00%?,"<h1>Code</h1>

<p>I""m trying to train CNN with UCF101 single frame data.
As far as I understand the problem is either with the weight Initialization or 
the loss with either the <code>tf.nn.softmax and tf.nn.softmax_cross_entropy_with_logits</code>or the cost and optimizer function.</p>

<p>Also is there any way to use xavier initialization ??</p>

<pre><code>import tensorflow as tf
import numpy as np
import scipy as sci
import cv2
import input_data_conv
import skimage.transform
from skimage import color


# Parameters
learning_rate = 0.001
training_iters = 200000
batch_size = 64
display_step = 20
n_classes=101 # number of classes

#Input data and classes
global train_data,train_class,test_data,test_classs,train_i,test_i
test_i, train_i = 0,0
train_data=input_data_conv.train_single_frames
train_class=input_data_conv.train_single_classes
test_data=input_data_conv.test_single_frames
test_classs=input_data_conv.test_single_classes


# Network Parameters
n_input = [227, 227, 3 ]# MNIST data input (img shape: 227*227*3)
dropout = 0.5 # Dropout, probability to keep units

# tf Graph input
x = tf.placeholder(tf.float32, [None, 227,227,3])
y = tf.placeholder(tf.float32, [None, n_classes])
keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)

def resize_im(im, nh, nw):
    im=np.copy(im)
    h, w, _ = im.shape
    im = skimage.transform.resize(im, (nh, nw), preserve_range=True)
    return im
def create_class_vec(val,nuoclasses):
    x=np.zeros(nuoclasses)
    x[val]=1
    return x

def init_weights(shape):
    return tf.Variable(tf.random_normal(shape, stddev=0.01))

def conv2d(name, l_input, w, b,s):
    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(l_input, w, strides=[1, s, s, 1], padding='SAME'),b), name=name)
def conv2dpad(name, l_input, w, b,s):
    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(l_input, w, strides=[1, s, s, 1], padding='VALID'),b), name=name)

def max_pool(name, l_input, k,s):
    return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding='SAME', name=name)

def norm(name, l_input, lsize):
    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.0001 / 9.0, beta=0.75, name=name)

def vgg_single_frame(_X, _weights, _biases, _dropout):
    # Reshape input picture
    _X = tf.reshape(_X, shape=[-1, 227, 227, 3])

    conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'],s=2)
    pool1 = max_pool('pool1', conv1, k=3,s=2)
    norm1 = norm('norm1', pool1, lsize=5)

    conv2 = conv2d('conv2', norm1, _weights['wc2'], _biases['bc2'],s=2)
    pool2 = max_pool('pool2', conv2, k=3,s=2)
    norm2 = norm('norm2', pool2, lsize=5)


    conv3 = conv2d('conv3', norm2, _weights['wc3'], _biases['bc3'],s=1)
    conv4 = conv2d('conv4', conv3, _weights['wc4'], _biases['bc4'],s=1)
    conv5 = conv2d('conv4', conv4, _weights['wc5'], _biases['bc5'],s=1)
    pool5 = max_pool('pool5', conv5, k=3,s=2)

    # Fully connected layer
    dense1 = tf.reshape(pool5, [-1, _weights['wd1'].get_shape().as_list()[0]]) # Reshape conv3 output to fit dense layer input
    dense1 = tf.nn.relu(tf.matmul(dense1, _weights['wd1']) + _biases['bd1'], name='fc6') # Relu activation
    dense1 = tf.nn.dropout(dense1, _dropout)
    dense2 = tf.nn.relu(tf.matmul(dense1, _weights['wd2']) + _biases['bd2'], name='fc7') # Relu activation
    dense2 = tf.nn.dropout(dense2, _dropout)

    # Output, class prediction
    out = tf.nn.softmax(tf.matmul(dense2, _weights['out']) + _biases['out'])
    return out

weights = {
    'wc1': tf.Variable(tf.random_normal([7, 7, 3, 96])), # 7x7 conv, 1 input, 96 outputs ,stride 2
    'wc2': tf.Variable(tf.random_normal([5, 5, 96, 384])), # 5x5 conv, 32 inputs, 64 outputs
    'wc3': tf.Variable(tf.random_normal([3, 3, 384, 512])),#s 2 ,p a
    'wc4': tf.Variable(tf.random_normal([3, 3, 512, 512])),#s 2, p 1
    'wc5': tf.Variable(tf.random_normal([3, 3, 512, 384])),#s 2, p 1
    'wd1': tf.Variable(tf.random_normal([8*8*384, 4096])), # fully connected, 7*7*64 inputs, 1024 outputs
    'wd2': tf.Variable(tf.random_normal([4096, 4096])), # fully connected, 7*7*64 inputs, 1024 outputs
    'out': tf.Variable(tf.random_normal([4096, n_classes])) # 1024 inputs, 10 outputs (class prediction)
}

biases = {
    'bc1': tf.Variable(tf.random_normal([96])),
    'bc2': tf.Variable(tf.random_normal([384])),
    'bc3': tf.Variable(tf.random_normal([512])),
    'bc4': tf.Variable(tf.random_normal([512])),
    'bc5': tf.Variable(tf.random_normal([384])),
    'bd1': tf.Variable(tf.random_normal([4096])),
    'bd2': tf.Variable(tf.random_normal([4096])),
    'out': tf.Variable(tf.random_normal([n_classes]))
}

def train_next_batch(batch_size):
    temp_data=np.ndarray(shape=(batch_size,227,227,3),dtype=float)
    temp_class=np.ndarray(shape=(batch_size,n_classes),dtype=float)
    for idx,x in enumerate(train_data[train_i:train_i+batch_size]):
        temp_data[idx,:,:,:]=resize_im(cv2.imread(x,1),227,227)
        temp_class[idx,:]=create_class_vec(train_class[train_i+idx],101)
    return temp_data,temp_class


pred = vgg_single_frame(x, weights, biases, keep_prob)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
# Evaluate model
correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
#
# cost = -tf.reduce_sum(y*tf.log(pred))
# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
# correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))
# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# Initializing the variables
init = tf.initialize_all_variables()

with tf.Session() as sess:
    sess.run(init)
    step = 1
    # Keep training until reach max iterations
    while step * batch_size &lt; training_iters:
        batch_xs, batch_ys = train_next_batch(batch_size)
        # Fit training using batch data
        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})
        if step % display_step == 0:
            # Calculate batch accuracy
            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})
            # Calculate batch loss
            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})
            print ""Iter "" + str(step*batch_size) + "", Minibatch Loss= "" + ""{:.6f}"".format(loss) + "", Training Accuracy= "" + ""{:.5f}"".format(acc)
        step += 1
    print ""Optimization Finished!""
    # Calculate accuracy for 256 mnist test images
    print ""Testing Accuracy:"", sess.run(accuracy, feed_dict={x: mnist.test.images[:256], y: mnist.test.labels[:256], keep_prob: 1.})
</code></pre>

<h1>Output</h1>

<pre><code>Total memory: 12.00GiB
Free memory: 10.77GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.23GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb06c80000 extends to 0xd9579bb34
Iter 1280, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 2560, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 3840, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 5120, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 6400, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 7680, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 8960, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 10240, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 11520, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 12800, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 14080, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 15360, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 16640, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 17920, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 19200, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 20480, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 21760, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 23040, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 24320, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 25600, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 26880, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 28160, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 29440, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 30720, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 32000, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 33280, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 34560, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 35840, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 37120, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 38400, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 39680, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 40960, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 42240, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 43520, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 44800, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 46080, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 47360, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 48640, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 49920, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 51200, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 52480, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 53760, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 55040, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 56320, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 57600, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 58880, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 60160, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 61440, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 62720, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 64000, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 65280, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 66560, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 67840, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 69120, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 70400, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 71680, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 72960, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 74240, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 75520, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 76800, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 78080, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 79360, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 80640, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 81920, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 83200, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 84480, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 85760, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 87040, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 88320, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 89600, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 90880, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 92160, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 93440, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 94720, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 96000, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 97280, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 98560, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 99840, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 101120, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 102400, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 103680, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 104960, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 106240, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 107520, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 108800, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 110080, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 111360, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 112640, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 113920, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 115200, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 116480, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 117760, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 119040, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 120320, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 121600, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 122880, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 124160, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 125440, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 126720, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 128000, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 129280, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 130560, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 131840, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 133120, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 134400, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 135680, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 136960, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 138240, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 139520, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 140800, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 142080, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 143360, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 144640, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 145920, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 147200, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 148480, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 149760, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 151040, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 152320, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 153600, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 154880, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 156160, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 157440, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 158720, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 160000, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 161280, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 162560, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 163840, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 165120, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 166400, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 167680, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 168960, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 170240, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 171520, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 172800, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 174080, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 175360, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 176640, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 177920, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 179200, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 180480, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 181760, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 183040, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 184320, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 185600, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 186880, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 188160, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 189440, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 190720, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 192000, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 193280, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 194560, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 195840, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 197120, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 198400, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Iter 199680, Minibatch Loss= 4.631989, Training Accuracy= 0.00000
Optimization Finished!
</code></pre>
",2016-03-29 21:41:40,2527680,3683,https://stackoverflow.com/questions/36295624,Documentation Replicability
36508860,How do I actually execute a saved TensorFlow model?,"<p>Tensorflow newbie here. I'm trying to build an RNN. My input data is a set of vector instances of size <code>instance_size</code> representing the (x,y) positions of a set of particles at each time step. (Since the instances already have semantic content, they do not require an embedding.) The goal is to learn to predict the positions of the particles at the next step. </p>

<p>Following the <a href=""https://www.tensorflow.org/versions/r0.7/tutorials/recurrent/index.html"" rel=""nofollow"">RNN tutorial</a> and slightly adapting the included RNN code, I create a model more or less like this (omitting some details):</p>

<pre><code>inputs, self._input_data = tf.placeholder(tf.float32, [batch_size, num_steps, instance_size])
self._targets = tf.placeholder(tf.float32, [batch_size, num_steps, instance_size])

with tf.variable_scope(""lstm_cell"", reuse=True):
  lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=0.0)
  if is_training and config.keep_prob &lt; 1:
    lstm_cell = tf.nn.rnn_cell.DropoutWrapper(
        lstm_cell, output_keep_prob=config.keep_prob)
  cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers)

self._initial_state = cell.zero_state(batch_size, tf.float32)

from tensorflow.models.rnn import rnn
inputs = [tf.squeeze(input_, [1])
          for input_ in tf.split(1, num_steps, inputs)]
outputs, state = rnn.rnn(cell, inputs, initial_state=self._initial_state)

output = tf.reshape(tf.concat(1, outputs), [-1, hidden_size])
softmax_w = tf.get_variable(""softmax_w"", [hidden_size, instance_size])
softmax_b = tf.get_variable(""softmax_b"", [instance_size])
logits = tf.matmul(output, softmax_w) + softmax_b
loss = position_squared_error_loss(
    tf.reshape(logits, [-1]),
    tf.reshape(self._targets, [-1]),
)
self._cost = cost = tf.reduce_sum(loss) / batch_size
self._final_state = state
</code></pre>

<p>Then I create a <code>saver = tf.train.Saver()</code>, iterate over the data to train it using the given <code>run_epoch()</code> method, and write out the parameters with <code>saver.save()</code>. So far, so good.</p>

<p>But how do I actually <em>use</em> the trained model? The tutorial stops at this point. From <a href=""https://www.tensorflow.org/versions/r0.7/how_tos/variables/index.html#restoring-variables"" rel=""nofollow"">the docs on <code>tf.train.Saver.restore()</code></a>, in order to read back in the variables, I need to either set up exactly the same graph I was running when I saved the variables out, or selectively restore particular variables. Either way, that means my new model will require inputs of size <code>batch_size x num_steps x instance_size</code>. However, all I want now is to do a single forward pass through the model on an input of size <code>num_steps x instance_size</code> and read out a single <code>instance_size</code>-sized result (the prediction for the next time step); in other words, I want to create a model that accepts a different-size tensor than the one I trained on. I can kludge it by passing the existing model my intended data <code>batch_size</code> times, but that doesn't seem like a best practice. What's the best way to do this? </p>
",2016-04-08 20:34:39,4185992,2644,https://stackoverflow.com/questions/36508860,Documentation Replication on Other Examples
36570729,tf.IndexedSlicesValue when returned from tf.gradients(),"<p>I'm having the following problem, I have four embedding matrices and want to get the gradients of my loss function with respect to those matrices.</p>

<p>When I run the session to return the values for the gradients, two of those returned objects are of type tensorflow.python.framework.ops.IndexedSlicesValue, the other two are numpy arrays. Now for the numpy arrays, their shape corresponds to the shape of their corresponding embedding matrix, but I'm having problems with the IndexedSlicesValue objects. </p>

<p>If I call .values on one of those objects, I get an array whose shape does not match that of the gradient, the shape of the embedding matrix is [22,30], but calling .values on the IndexedSlicesValue object I get an array with shape [4200,30] ( The shape of my input tensor had dimensions of [30,20,7], the product of those dimensions equals 4200, not sure if this is relevant).
The IndexedSlicesValue object has an attribute called dense_shape, which is an array that holds the dimensions the gradient should have, i.e. array([22,30]) is value returned by .dense_shape.</p>

<p>I don't really understand the docs here: <a href=""https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#IndexedSlices"" rel=""noreferrer"">https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#IndexedSlices</a></p>

<p>It says:</p>

<blockquote>
  <p>An IndexedSlices is typically used to represent a subset of a
  larger tensor dense of shape [LARGE0, D1, .. , DN] where LARGE0 >> D0.
  The values in indices are the indices in the first dimension of the
  slices that have been extracted from the larger tensor.</p>
</blockquote>

<p>So this array of shape (4200,30) is extracted from an array corresponding to an even larger, dense tensor?</p>

<p>What exactly is the gradient in this IndexedSlicesValue object and why does tensorflow automatically use this type for some gradients returned by tf.gradients()?</p>

<p>Here is my code:</p>

<pre><code>input_tensor = tf.placeholder(tf.int32, shape = [None, memory_size, max_sent_length], name = 'Input')
q_tensor = tf.placeholder(tf.int32, shape = [None,max_sent_length], name = 'Question')
a_tensor = tf.placeholder(tf.float32, shape = [None,V+1], name = 'Answer')
# Embedding matrices
A_prior = tf.get_variable(name = 'A', shape = [V+1,d], initializer = tf.random_normal_initializer(stddev = 0.1))
A = tf.concat(0,[tf.zeros(shape = tf.pack([1,tf.shape(A_prior)[1]])),tf.slice(A_prior,[1,0],[-1,-1])])
B = tf.get_variable(name = 'B', shape = [V+1,d], initializer = tf.random_normal_initializer(stddev = 0.1))
C = tf.get_variable(name = 'C', shape = [V+1,d], initializer = tf.random_normal_initializer(stddev = 0.1))
W = tf.get_variable(name = 'W', shape = [V+1,d], initializer= tf.random_normal_initializer(stddev = 0.1))
embeddings = tf.reduce_sum(tf.nn.embedding_lookup(A,input_tensor),2)
u = tf.reshape(tf.reduce_sum(tf.nn.embedding_lookup(B,q_tensor),1),[-1,1,d])
test = tf.transpose(embeddings, perm = [0,2,1])
test_batch_mul = tf.squeeze(tf.batch_matmul(u,test))
cond = tf.not_equal(test_batch_mul,0.0)
tt = tf.fill(tf.shape(test_batch_mul),-1000.0)
softmax_in = tf.select(cond, test_batch_mul, tt)
p_values = tf.nn.softmax(softmax_in)
c_values = tf.reduce_sum(tf.nn.embedding_lookup(C,input_tensor),2)
o = tf.squeeze(tf.batch_matmul(tf.expand_dims(p_values,1),c_values))
a_pred = tf.nn.softmax(tf.matmul(tf.squeeze(u)+o,tf.transpose(W)))
loss = tf.nn.softmax_cross_entropy_with_logits(a_pred, a_tensor, name = 'loss')
cost = tf.reduce_mean(loss)
global_step = tf.Variable(0,name = 'global_step', trainable= False)
#optimizer = tf.train.MomentumOptimizer(0.01,0.9)
vars_list = tf.trainable_variables()
grads = tf.gradients(cost, vars_list)
#train_op = optimizer.minimize( cost, global_step, vars_list, name = 'train_op')

sess = tf.Session()
init = tf.initialize_all_variables()
sess.run(init)
input_feed = {input_tensor : phrases, q_tensor : questions, a_tensor : answers}
grad_results = sess.run(grads, feed_dict = input_feed)
</code></pre>
",2016-04-12 10:35:30,3042790,1464,https://stackoverflow.com/questions/36570729,Documentation Replication on Other Examples
36631868,Tensorflow: Noise contrastive estimation language model,"<p>I want to change the loss function in the <a href=""https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/rnn/ptb/ptb_word_lm.py"" rel=""nofollow"">ptb_word_lm.py</a> example to <code>tf.nn.nce_loss</code>. Looking at the <code>tf.nn.nce_loss</code> implementation:</p>

<pre><code>def nce_loss(weights, biases, inputs, labels, num_sampled, num_classes,
         num_true=1,
         sampled_values=None,
         remove_accidental_hits=False,
         partition_strategy=""mod"",
         name=""nce_loss""):
</code></pre>

<p>I think </p>

<ul>
<li>the 3rd parameter (inputs) is the logits of language model,  </li>
<li>4th parameter (labels) is the next word (self._targets) of language
model, </li>
<li>num_classes is the vocab_size</li>
</ul>

<p>But I do not know what are the first two parameters, weights and biases. How could I adapt <code>tf.nn.nce_loss</code> to language model? Thanks.</p>

########UPDATES

<p>@Aaron:</p>

<p>Thanks, I have tried the following:</p>

<pre><code>loss = tf.reduce_mean(
        tf.nn.nce_loss(softmax_w, softmax_b, logits, tf.reshape(self._targets, [-1,1]),
                                     64, vocab_size))
</code></pre>

<p>According to the document at <a href=""https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#nce_loss"" rel=""nofollow"">here</a>:</p>

<ul>
<li><p>weights: A Tensor of shape [num_classes, dim], or a list of Tensor
objects 
           whose concatenation along dimension 0 has shape [num_classes, dim]. The (possibly-partitioned) class embeddings.</p></li>
<li><p>biases: A Tensor of shape [num_classes]. The class biases.</p></li>
<li><p>inputs: A Tensor of shape [batch_size, dim]. The forward activations
of the input network.</p></li>
<li><p>labels: A Tensor of type int64 and shape [batch_size, num_true]. The
target classes.</p></li>
<li><p>num_sampled: An int. The number of classes to randomly sample per
batch.</p></li>
<li><p>num_classes: An int. The number of possible classes.</p></li>
</ul>

<p>So, </p>

<ul>
<li>weights is the softmax_w tensor, which has shape (hidden_size,
vocab_size)</li>
<li>biases is softmax_b, which has shape (vocab_size)</li>
<li>inputs is logits, which has shape (batch_size*num_steps, vocab_size)</li>
<li>labels is self._targets, which has shape (batch_size, num_steps),
thus, we need to reshape it, tf.reshape(self._targets, [-1,1])</li>
</ul>

<p>My PTBModel model looks like</p>

<pre><code>class PTBModel(object):
    def __init__(self, is_training, config):
        self.batch_size = batch_size = config.batch_size
        self.num_steps = num_steps = config.num_steps
        size = config.hidden_size
        vocab_size = config.vocab_size
        self._input_data = tf.placeholder(tf.int32, [batch_size, num_steps])
        self._targets = tf.placeholder(tf.int32, [batch_size, num_steps])

        lstm_cell = rnn_cell.BasicLSTMCell(size, forget_bias=0.0)
        if is_training and config.keep_prob &lt; 1:
            lstm_cell = rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=config.keep_prob)
        cell = rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers)
        self._initial_state = cell.zero_state(batch_size, tf.float32)
        with tf.device(""/cpu:0""):
            embedding = tf.get_variable(""embedding"", [vocab_size, size])
            inputs = tf.nn.embedding_lookup(embedding, self._input_data)
        if is_training and config.keep_prob &lt; 1:
            inputs = tf.nn.dropout(inputs, config.keep_prob)

        outputs = []
        states = []
        state = self._initial_state
        with tf.variable_scope(""RNN""):
            for time_step in range(num_steps):
                if time_step &gt; 0: tf.get_variable_scope().reuse_variables()
                (cell_output, state) = cell(inputs[:, time_step, :], state)
                outputs.append(cell_output)
                states.append(state)
        output = tf.reshape(tf.concat(1, outputs), [-1, size])
        softmax_w = tf.get_variable(""softmax_w"", [size, vocab_size])
        softmax_b = tf.get_variable(""softmax_b"", [vocab_size])
        logits = tf.matmul(output, softmax_w) + softmax_b

        '''
        #minimize the average negative log probability using sequence_loss_by_example
        loss = seq2seq.sequence_loss_by_example([logits],
                                                [tf.reshape(self._targets, [-1])],
                                                [tf.ones([batch_size * num_steps])],
                                                vocab_size)

        loss = tf.reduce_mean(
            tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,
                                         num_sampled, vocabulary_size))
        weights: A Tensor of shape [num_classes, dim], or a list of Tensor objects 
            whose concatenation along dimension 0 has shape [num_classes, dim]. The (possibly-partitioned) class embeddings.
        biases: A Tensor of shape [num_classes]. The class biases.
        inputs: A Tensor of shape [batch_size, dim]. The forward activations of the input network.
        labels: A Tensor of type int64 and shape [batch_size, num_true]. The target classes.
        num_sampled: An int. The number of classes to randomly sample per batch.
        num_classes: An int. The number of possible classes.

        '''
        loss = tf.reduce_mean(
            tf.nn.nce_loss(softmax_w, softmax_b, logits, tf.reshape(self._targets, [-1,1]),
                                         64, vocab_size))


        self._cost = cost = tf.reduce_sum(loss) / batch_size
        self._final_state = states[-1]
        if not is_training:
            return
        self._lr = tf.Variable(0.0, trainable=False)
        tvars = tf.trainable_variables()
        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),
                                          config.max_grad_norm)
        optimizer = tf.train.GradientDescentOptimizer(self.lr)
        self._train_op = optimizer.apply_gradients(zip(grads, tvars))
</code></pre>

<p>However, I got an error</p>

<pre><code>Epoch: 1 Learning rate: 1.000
W tensorflow/core/common_runtime/executor.cc:1102] 0x528c980 Compute status: Invalid argument: Index 9971 at offset 0 in Tindices is out of range
     [[Node: model/nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](model/softmax_w/read, model/nce_loss/concat)]]
W tensorflow/core/common_runtime/executor.cc:1102] 0x528c980 Compute status: Invalid argument: Index 9971 at offset 0 in Tindices is out of range
     [[Node: model/nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](model/softmax_w/read, model/nce_loss/concat)]]
     [[Node: _send_model/RNN/concat_19_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1438650956868917036, tensor_name=""model/RNN/concat_19:0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](model/RNN/concat_19)]]
Traceback (most recent call last):
  File ""/home/user/works/workspace/python/ptb_word_lm/ptb_word_lm.py"", line 235, in &lt;module&gt;
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/user/works/workspace/python/ptb_word_lm/ptb_word_lm.py"", line 225, in main
    verbose=True)
  File ""/home/user/works/workspace/python/ptb_word_lm/ptb_word_lm.py"", line 189, in run_epoch
    m.initial_state: state})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 315, in run
    return self._run(None, fetches, feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 511, in _run
    feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _do_run
    target_list)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 586, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: Index 9971 at offset 0 in Tindices is out of range
     [[Node: model/nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](model/softmax_w/read, model/nce_loss/concat)]]
Caused by op u'model/nce_loss/embedding_lookup', defined at:
  File ""/home/user/works/workspace/python/ptb_word_lm/ptb_word_lm.py"", line 235, in &lt;module&gt;
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/user/works/workspace/python/ptb_word_lm/ptb_word_lm.py"", line 214, in main
    m = PTBModel(is_training=True, config=config)
  File ""/home/user/works/workspace/python/ptb_word_lm/ptb_word_lm.py"", line 122, in __init__
    64, vocab_size))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn.py"", line 798, in nce_loss
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn.py"", line 660, in _compute_sampled_logits
    weights, all_ids, partition_strategy=partition_strategy)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/embedding_ops.py"", line 86, in embedding_lookup
    validate_indices=validate_indices)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 447, in gather
    validate_indices=validate_indices, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2040, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1087, in __init__
    self._traceback = _extract_stack()
</code></pre>

<p>Did I miss anything here? Thanks again.</p>
",2016-04-14 19:07:07,200340,3321,https://stackoverflow.com/questions/36631868,Documentation Replication on Other Examples
36693740,What's the difference between tf.placeholder and tf.Variable?,"<p>I'm a newbie to TensorFlow. I'm confused about the difference between <code>tf.placeholder</code> and <code>tf.Variable</code>. In my view, <code>tf.placeholder</code> is used for input data, and <code>tf.Variable</code> is used to store the state of data. This is all what I know. </p>

<p>Could someone explain to me more in detail about their differences? In particular, when to use <code>tf.Variable</code> and when to use <code>tf.placeholder</code>? </p>
",2016-04-18 12:16:23,6176753,3649,https://stackoverflow.com/questions/36693740,Lack of Alternative Solutions/Documentation
37086098,Does tensorflow map_fn support taking more than one tensor?,"<p>Does tf.map_fn support taking more than one tensors as is supported by python's native map function (example provided below)?</p>

<pre><code>a = [1,2,3,4]
b = [17,12,11,10]
print(map(lambda x,y:x+y, a,b)) # ==&gt; [18, 14, 14, 14]
</code></pre>
",2016-05-07 08:06:35,6227444,817,https://stackoverflow.com/questions/37086098,Documentation Replicability
37159372,API Reference for RNN and Seq2Seq models in tensorflow,"<p>Where can I find the API references that specifies the available functions in the RNN and Seq2Seq models.</p>

<p>In the github page it was mentioned that rnn and seq2seq were moved to tf.nn</p>
",2016-05-11 10:07:15,1363836,416,https://stackoverflow.com/questions/37159372,Documentation Replicability
38136081,Setting num_epochs on tf.train.string_input_producer produces an error,"<p>Setting num_epochs on tf.train.string_input_producerto anything other than None produces the error</p>

<pre><code>Attempting to use uninitialized value input_producer/limit_epochs/epoch
</code></pre>

<p>What causes this and how can it be fixed?</p>
",2016-07-01 02:25:12,4392784,6596,https://stackoverflow.com/questions/38136081,Documentation Replicability
38356622,Distributing graphs across several machines in Distributed Tensorflow,"<p>I am currently working on a project using Distributed Tensorflow. My goal is to run several independent graphs across several different machines.</p>

<p>As an example, I want to do something like this (assume that the server is open on each machine)</p>

<pre><code>import tensorflow as tf
a = tf.constant(3)
b = tf.constant(2)
x = tf.mul(a,b)             # To be run on ""grpc://www.example0.com:2222""
y = tf.mul(a,b)             # To be run on ""grpc://www.example1.com:2222""
z = tf.mul(a,b)             # To be run on ""grpc://www.example2.com:2222""

with tf.Session() as sess:
    sess.run([x,y,z])       # Ops x,y,z are run on different machines in parallel
</code></pre>

<p>My current attempt at this is shown in the following code. However, this code runs the sessions in serial, but I want them to be executed in a parallel distributed manner.</p>

<pre><code>import tensorflow as tf
a = tf.constant(3)
b = tf.constant(2)
x = tf.mul(a,b)             # To be run on ""grpc://www.example0.com:2222""
y = tf.mul(a,b)             # To be run on ""grpc://www.example1.com:2222""
z = tf.mul(a,b)             # To be run on ""grpc://www.example2.com:2222""

with tf.Session(""grpc://www.example0.com:2222"") as sess:
    sess.run(x)
with tf.Session(""grpc://www.example1.com:2222"") as sess:
    sess.run(y)
with tf.Session(""grpc://www.example2.com:2222"") as sess:
    sess.run(z)
</code></pre>

<p>While reading the documentation about Distributed Tensorflow, I found that <code>tf.device</code> allows me to set which CPU or GPU to run Tensorflow Ops on. Is there something similar that allows me to set the <code>session target</code> to specify which machine will run which op? Or is there another way of distributing Tensorflow Ops?</p>
",2016-07-13 16:02:56,6585219,1,https://stackoverflow.com/questions/38356622,Documentation Replication on Other Examples
38641887,How to save a trained tensorflow model for later use for application?,"<p>I am a bit of a beginner with tensorflow so please excuse if this is a stupid question and the answer is obvious. </p>

<p>I have created a Tensorflow graph where starting with placeholders for X and y I have optimized some tensors which represent my model. Part of the graph is something where a vector of predictions can be calculated, e.g. for linear regression something like </p>

<pre class=""lang-py prettyprint-override""><code>y_model = tf.add(tf.mul(X,w),d)
y_vals = sess.run(y_model,feed_dict={....})
</code></pre>

<p>After training has been completed I have acceptable values for w and d and now I want to save my model for later. Then, in a different python session I want to restore the model so that I can again run</p>

<pre class=""lang-py prettyprint-override""><code>## Starting brand new python session
import tensorflow as tf
## somehow restor the graph and the values here: how????
## so that I can run this:
y_vals = sess.run(y_model,feed_dict={....})
</code></pre>

<p>for some different data and get back the y-values. </p>

<p>I want this to work in a way where the graph for calculating the y-values from the placeholders is also stored and restored - as long as the placeholders get fed the correct data, this should work transparently without the user (the one who applies the model) needing to know what the graph looks like). </p>

<p>As far as I understand tf.train.Saver().save(..) only saves the variables but I also want to save the graph. I think that tf.train.export_meta_graph could be relevant here but I do not understand how to use it correctly, the documentation is a bit cryptic to me and the examples do not even use export_meta_graph anywhere. </p>
",2016-07-28 16:23:56,1382437,2019,https://stackoverflow.com/questions/38641887,Inadequate Examples
38893526,What's the meaning of tf.nn.embedding_lookup_sparse in TensorFlow?,"<p>We spend a lot of time in reading the API document of <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#embedding_lookup_sparse"" rel=""nofollow"">tf.nn.embedding_lookup_sparse</a>. The meaning of <code>embedding_lookup_sparse</code> is confusing and it seems quite different from <code>embedding_lookup</code>.</p>

<p>Here's what I think and please correct me if I'm wrong. The example of wide and deep model uses <code>contrib.layers</code> APIs and call <code>embedding_lookup_sparse</code> for sparse feature colume. If it gets the SparseTensor(for example, country, which is sparse), it creates the embedding which is actually for one-host encoding. Then call <code>to_weights_sum</code> to return the result of <code>embedding_lookup_sparse</code> as <code>prediction</code> and the embedding as <code>variable</code>.</p>

<p>The the result of <code>embedding_lookup_sparse</code> add <code>bias</code> and become the <code>logits</code> for loss function and training operation. That means the <code>embedding_lookup_sparse</code> do something like <code>w * x</code>(part of <code>y = w * x + b</code>) for dense tensor.</p>

<p>Maybe for one-hot encoding or SparseTensor, the <code>weight</code> from <code>embedding_lookup_sparse</code> is actually the value of <code>w * x</code> because the look-up data is always <code>1</code> and no need to add other <code>0</code>s.</p>

<p>What I said is also confusing. Can anyone help to explain this in detail?</p>
",2016-08-11 10:16:30,2502090,1701,https://stackoverflow.com/questions/38893526,Documentation Replication on Other Examples
38962308,Unclear behavior for sampler in Tensorflow,"<p>For the samplers implemented in tensorflow, e.g. tf.nn.fixed_unigram_candidate_sampler. The behavior is not well-defined in the document. For instance, I would expect the labels specified in true_classes will be excluded from the sampling pool, and the sampling will be conducted for each batch. But according to my experiments, neither of above is true.</p>

<p>Consider the following code:</p>

<pre><code>import tensorflow as tf

labels_matrix = tf.reshape(tf.constant([1, 2, 3, 4], dtype=tf.int64), [-1, 1])

sampled_ids, _, _ = tf.nn.fixed_unigram_candidate_sampler(
true_classes = labels_matrix,
num_true = 1,
num_sampled = 1,
unique = True,
range_max = 5,
distortion = 0.0,
unigrams = range(5)
)

init = tf.initialize_all_variables()
with tf.Session() as sess:
sess.run(init)
print sess.run([sampled_ids])
</code></pre>

<p>The output can be 3, which actually belongs to the set of true classes. - Also, the output has the dimension [1], which basically means that the sampling is only conducted once, not for each batch.</p>

<p>Can someone help to clarify this?</p>
",2016-08-15 20:09:40,4097290,5,https://stackoverflow.com/questions/38962308,Documentation Ambiguity
39211332,Custom initializer for get_variable,"<p>How can one specify a custom initializer as the third argument for <code>tf.get_variable()</code>? Specifically, I have a variable <code>y</code> which I want to initialize using another (already initialized) variable <code>x</code>. </p>

<p>This is easy to do using <code>tf.Variable()</code>, just say, <code>y = tf.Variable(x.initialized_value())</code>. But I couldn't find an analog in the documentation for <code>tf.get_variable()</code>.</p>
",2016-08-29 16:54:32,1994648,65,https://stackoverflow.com/questions/39211332,Lack of Alternative Solutions/Documentation
39282060,Nonlinear regression on tensorflow,"<p>What activation and cost functions on <code>tensorflow</code> could be suitable below for <strong>tf.nn</strong> to <strong>learn</strong> a simple single variate nonlinear relationship <code>f(x) = x * x</code> that is a priori unknown? </p>

<p>Certainly, this impractical model is used for the sole purpose of understanding <code>tf.nn mechanics 101</code>.</p>



<pre><code>import numpy as np
import tensorflow as tf

x = tf.placeholder(tf.float32, [None, 1]) 
W = tf.Variable(tf.zeros([1,1]))
b = tf.Variable(tf.zeros([1]))
y = some_nonlinear_activation_function_HERE(tf.matmul(x,W) + b) 
y_ = tf.placeholder(tf.float32, [None, 1]) 
cost = tf.reduce_mean(some_related_cost_function_HERE(y, y_)) 
learning_rate = 0.001
optimize = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

sess = tf.Session()
sess.run(tf.initialize_all_variables())
steps = 1000
for i in range(steps):
  sess.run(optimize, 
    feed_dict={x: np.array([[i]])), y_: np.array([[i*i]])})   
print(""prediction: %f"" % sess.run(y, 
  feed_dict={x: np.array([[1100]])})) 
# expected output near 1210000
</code></pre>
",2016-09-01 23:00:02,363663,9331,https://stackoverflow.com/questions/39282060,Documentation Replication on Other Examples
39450992,Tensorflow slim how to specify batch size during training,"<p>I'm trying to use slim interface to create and train a convolutional neural network, but I couldn't figure out how to specify the batch size for training.
During the training my net crashes because of ""Out of Memory"" on my graphic card.
So I think that should be a way to handle this condition...
Do I have to split the data and the labels in batches and then explicitly loop or the slim.learning.train is taking care of it?
In the code I paste train_data are all the data in my training set (numpy array)..and the model definition is not included here
I had a quick loop to the sources but no luck so far...</p>

<pre><code>g = tf.Graph()
    with g.as_default():
        # Set up the data loading:
        images = train_data
        labels = tf.contrib.layers.one_hot_encoding(labels=train_labels, num_classes=num_classes)
        # Define the model:
        predictions = model7_2(images, num_classes, is_training=True)

        # Specify the loss function:
        slim.losses.softmax_cross_entropy(predictions, labels)

        total_loss = slim.losses.get_total_loss()
        tf.scalar_summary('losses/total loss', total_loss)

        # Specify the optimization scheme:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=.001)
        train_tensor = slim.learning.create_train_op(total_loss, optimizer)

        slim.learning.train(train_tensor,
            train_log_dir,
            number_of_steps=1000,
            save_summaries_secs=300,
            save_interval_secs=600)
</code></pre>

<p>Any hints suggestions?</p>

<p>Edit:
I re-read the documentation...and I found this example</p>

<pre><code>image, label = MyPascalVocDataLoader(...)
images, labels = tf.train.batch([image, label], batch_size=32)
</code></pre>

<p>But It's not clear at all how to feed image and label to be passed to tf.train.batch... as MyPascalVocDataLoader function is not specified...
In my case my data set are loaded from a sqlite database and I have training data and labels as numpy array....still confused.
Of course I tried to pass my numpy arrays (converted to constant tensor) to the tf.train.batch like this</p>

<pre><code>    image = tf.constant(train_data)
    label = tf.contrib.layers.one_hot_encoding(labels=train_labels, num_classes=num_classes)
    images, labels = tf.train.batch([image, label], batch_size=32)
</code></pre>

<p>But seems not the right path to follow... it seems that the train.batch wants only one element from my data set...(how to pass this? it does not make sense to me to pass only train_data[0] and train_labels[0])</p>
",2016-09-12 13:04:11,6695432,91,https://stackoverflow.com/questions/39450992,Documentation Ambiguity
39627140,Why would the naive definition of moving average cause unnecessary locking in TensorFlow?,"<p>The TensorFlow <a href=""https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#moving-averages"" rel=""nofollow"">docs for tf.train.ExponentialMovingAverage</a> say,</p>

<blockquote>
  <p>When you run the ops to maintain the moving averages, each shadow
  variable is updated with the formula:</p>
  
  <p>shadow_variable -= (1 - decay) * (shadow_variable - variable)</p>
  
  <p>This is mathematically equivalent to the classic formula below, but
  the use of an assign_sub op (the ""-="" in the formula) allows
  concurrent lockless updates to the variables:</p>
  
  <p>shadow_variable = decay * shadow_variable + (1 - decay) * variable</p>
</blockquote>

<p>Why does the first formula permit more concurrency than the second formula?  How can I know if my own code is incurring unnecessary locking because of some subtle locking issue?</p>
",2016-09-21 21:51:52,4943253,712,https://stackoverflow.com/questions/39627140,Documentation Replicability
39681026,Tensorflow: How to pass output from previous time-step as input to next timestep,"<p>It is a duplicate of this question <a href=""https://stackoverflow.com/questions/35145645/how-can-i-feed-last-output-yt-1-as-input-for-generating-yt-in-tensorflow-rnn#"">How can I feed last output y(t-1) as input for generating y(t) in tensorflow RNN?</a></p>

<p>I want to pass the output of RNN at time-step T as the input at time-step T+1. <code>input_RNN(T+1) = output_RNN(T)</code>
As per the documentation, the  tf.nn.rnn as well as tf.nn.dynamic_rnn functions explicitly take the complete input to all time-steps. </p>

<p>I checked the seq2seq example at <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py</a>
It uses a loop and calls the cell(input,state) function. The cell can be lstm or gru or any other rnn cell. I checked the documentation to find the data type and shape of the arguments to cell(), but I found only the contructor of the form cell(num_neurons). 
I would like to know the correct way of passing output to input. I don't want to use other libraries/wrappers like keras built over tensorflow. Any suggestions?</p>
",2016-09-24 21:14:24,2531306,1427,https://stackoverflow.com/questions/39681026,Documentation Completeness
39971297,Tensorflow: python tf.gradients equivalent in C++,"<p>What is the equivalent of Python function <code>tf.gradients(loss, [var])</code> in C++? Thanks!</p>
",2016-10-11 06:07:00,6166308,91,https://stackoverflow.com/questions/39971297,Documentation Replication on Other Examples
40394910,What do classes tf.train.Coordinator and class tf.train.QueueRunner do in tensorflow?,"<p>I understand that both classes deal with threads. According to the documentation, tf.train.Coordinator coordinates the termination of a set of threads and tf.train.QueueRunner holds a list of enqueue operations for a queue, each to be run in a thread. </p>

<p>However, what is their role in simple words? When are they necessary during the training?</p>
",2016-11-03 06:10:31,1279459,5458,https://stackoverflow.com/questions/40394910,Documentation Replicability
40409793,Tensorflow: Elementwise-inversion of multiple matrices of different shape,"<p>I have a set of differently-shaped matrices <code>M = (M_1, M_2, ... M_K)</code>. For efficiency purposes, I can store all of <code>M</code> into a single tensor of size <code>K x max(M_k.shape[0]) x max(M_k.shape[1])</code>. This works fine for doing things like batch matrix multiplication and elementwise additions. But what if I want to do elementwise divisions where the zero elements are ignored?</p>

<p>The best version of this I've come up with is:</p>

<pre><code>import numpy as np
import tensorflow as tf
M = tf.constant(np.array([[1.,2.,0],[3.,4.,5.],[6.,0,0]]), tf.float32)
Minv = tf.select(tf.equal(M, 0), tf.zeros_like(M), tf.inv(M))
</code></pre>

<p>Is this the fastest way? Does <code>tf.select</code> still get accelerated well via a GPU?</p>
",2016-11-03 19:31:38,330561,4555,https://stackoverflow.com/questions/40409793,Documentation Ambiguity
40451974,"Tensorflow, restore variables in a specific device","<p>Maybe my question is a bit naive, but I really didn't find anything in the tensorflow documentation.</p>

<p>I have a trained tensorflow model where the variables of it was placed in the GPU. Now I would like to restore this model and test it using the CPU.</p>

<p>If I do this via 'tf.train.Saver.restore` as in the example:
<code>
 saver = tf.train.import_meta_graph(""/tmp/graph.meta"")
 saver.restore(session, ""/tmp/model.ckp"")
</code></p>

<p>I have the following excpetion:</p>

<p><code>
InvalidArgumentError: Cannot assign a device to node 'b_fc8/b_fc8/Adam_1': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0
</code></p>

<p>How can I make restore these variables in the <code>CPU</code>?</p>

<p>Thanks</p>
",2016-11-06 16:58:18,5913101,690,https://stackoverflow.com/questions/40451974,Documentation Replication on Other Examples
40534098,Can I apply calculated gradient in tensorflow?,"<p>What I want to do is to simulate the back-propagation process on different machines, from one machine, I get the gradient from layer3 <code>d(layer3_output)/d(layer2_output)</code> as a numpy array, how am I able to get <code>d(layer3_output)/d(layer1_output)</code> efficiently given the gradient I received and passed to the previous layer?</p>
",2016-11-10 17:54:37,5257450,3094,https://stackoverflow.com/questions/40534098,Documentation Replication on Other Examples
40569670,Inserting data into regression network in keras,"<p>I am currently struggling to understand how i should train my regression network using keras.  I am not sure how I should pass my input data to the network. </p>

<p>Both the input data and the output data is stored as a list of numpy arrays. </p>

<p>Each input numpy array is a matrix which has (400 rows, x columns)
Each output numpy array is a matrix which has (x number of rows, 13 columns)</p>

<p>So input dimension is 400 and output is 13. 
But how do I pass each of these sets within the list to the training?</p>

<pre><code># Multilayer Perceptron
model = Sequential()    # Feedforward
model.add(Dense(3, input_dim=400))
model.add(Activation('tanh'))
model.add(Dense(1))
model.compile('sgd', 'mse')
</code></pre>

<p>Just by parsing data into gives me this error message :</p>

<pre><code>Traceback (most recent call last):
  File ""tensorflow_datapreprocess_mfcc_extraction_rnn.py"", line 167, in &lt;module&gt;
    model.fit(train_set_data,train_set_output,verbose=1)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 620, in fit
    sample_weight=sample_weight)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1034, in fit
    batch_size=batch_size)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 961, in _standardize_user_data
    exception_prefix='model input')
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 51, in standardize_input_data
    '...')
Exception: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 arrays but instead got the following list of 270 arrays: [array([[ -1.52587891e-04,   3.05175781e-05,  -1.52587891e-04,
         -5.18798828e-04,   3.05175781e-05,  -3.96728516e-04,
          1.52587891e-04,   3.35693359e-04,  -9.15527344e-05,
          3.3...
</code></pre>
",2016-11-13 01:42:09,6317366,355,https://stackoverflow.com/questions/40569670,Documentation Replicability
40819430,"Input pipeline based on tfrecord, the queue are always empty","<p>I have a problem with tensorflow and a tfrecord based input pipeline. </p>

<p>Each of my records contains:</p>

<ul>
<li>'image' a 3 dimensional array of dimension [480,585,5] with datatype uint8 </li>
<li>'target' a 4 dimensional array of dimension [7,7,1,6] with datatype float32</li>
</ul>

<p>This is the code sample that I use to read the data from the tfrecord and create a minibatch:</p>

<pre><code>def getBatch(filenames,num_examples):

    filename_queue = tf.train.string_input_producer(filenames,num_epochs=None)

    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)

    batch_of_example = tf.train.batch([serialized_example],num_examples, capacity=2500, num_threads=16)
    features = tf.parse_example(
        batch_of_example,
        features={
            'label': tf.FixedLenFeature([7,7,1,6], tf.float32),
            'image': tf.FixedLenFeature([], tf.string)
        }
    )

    image_raw = tf.reshape(tf.decode_raw(features['image'],tf.uint8),[num_examples,480,585,5])
    #rescale images for neural network
    images =tf.image.resize_images(image_raw,[224,224])

    return images,feature['label']
</code></pre>

<p>However when I try to use it in a training routine the performance are really bad (6/7 example for second with a relatively small net on a Titan X) and neither the cpu nor the gpu seems to be under high work load. </p>

<p>I am using as training set 26 tfrecord file with 2500 example each (~3.5GB each) and a batch size of 32.</p>

<p>I think that the slow performance are caused by the input queue always empty as can be seen from 
<a href=""https://i.stack.imgur.com/afWAB.png"" rel=""nofollow noreferrer"">this graph:</a></p>

<p>Can anybody spot where the problem in my input pipeline is? Or can anybody give me some guidance on why I have such bad performance?</p>
",2016-11-26 14:35:40,5650844,113,https://stackoverflow.com/questions/40819430,Documentation Replication on Other Examples
40891533,"ValueError: Variable weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?","<p>I can run my tensorflow code using tf.Variable but tf.get_variable is much more efficient. The above error is produced by this code:</p>

<pre><code>    w = tf.get_variable(name='weights',
                shape=filter_shape,
                initializer=tf.random_normal_initializer(0., 0.01))
    b = tf.get_variable(name='biases',
                        shape=filter_shape[-1],
                        initializer=tf.constant_initializer(0.))
</code></pre>

<p>and I can't understand the reason. Any ideas?</p>
",2016-11-30 14:59:35,6631259,163,https://stackoverflow.com/questions/40891533,Documentation Replicability
40977431,TensorFlow Dynamic RNN - How to take mean over all LSTM states ignoring zero vectors?,"<p>I understand that <code>tf.nn.dynamic_rnn</code> handles variable lengths by copying the last valid state to the end of the output vector and pads the LSTM output with zero vectors. </p>

<p>In this case, i would like to do a mean over all LSTM states with ignoring the zero vectors. How can I do this in TensorFlow?</p>

<p>Alternatively, how do you take a mean over a list of vectors while masking the zeros?</p>

<p>Thanks! </p>
",2016-12-05 15:14:55,5718092,163,https://stackoverflow.com/questions/40977431,Documentation Replicability
41125183,Tensorflow: split_v with variable num_splits,"<p>I am wondering if the same holds for <code>tf.split_v()</code> as <code>tf.split()</code>.</p>

<p>According to the documentation <code>split_v</code> also accepts a Tensor as second argument.</p>

<p>However, when I try this code</p>

<pre><code>batch_size_ph = tf.placeholder(dtype = tf.int32, name='BatchSize')
seq_length_ph = tf.placeholder(dtype = tf.int32, name='SeqLength')
input_data = tf.placeholder(dtype=tf.float32, shape=[50, 25, 10])


inputs = tf.split_v(input_data,seq_length_ph, 1) #tf.ones(seq_length_ph, tf.int32)
#inputs = [tf.squeeze(input_, [1]) for input_ in inputs]

with tf.Session() as sess:
    [out] = sess.run([inputs],feed_dict = {batch_size_ph: 50,
                                           seq_length_ph: 25,
                                           input_data: np.random.rand(50,25,10)})

print out
print len(out)
print out[0].shape
</code></pre>

<p>The error is</p>

<blockquote>
  <p>NameError: global name 'value_shape' is not defined</p>
</blockquote>

<p>Is this possible or not?</p>
",2016-12-13 15:50:04,987397,1395,https://stackoverflow.com/questions/41125183,Documentation Replicability
41176347,"python , Passing array as parameter","<p>I want to run another python file in a python file , passing array as parameter, not a string as parameter.</p>

<p>I could pass a string like this:</p>

<pre><code>os.system(""python another_file.py 123"")
</code></pre>

<p>By the way , the reason why I could not <code>import</code> is that the <code>Variable</code> of tensorflow may conflict.</p>
",2016-12-16 02:22:13,2455061,1722,https://stackoverflow.com/questions/41176347,Documentation Ambiguity
41273756,TensorFlow while_loop parallelization TensorArray,"<p>I don't exactly understand how the while_loop parallelization works. Suppose I have a TensorArray having 10 Tensors all of same shape. Now suppose the computations in the loop body for the first 5 Tensors are independent of the computations in the remaining 5 Tensors. Would TensorFlow run these two in parallel? Also if I use a Tensor instead of a TensorArray and made the updates to it using scatter_update, would it pass the gradients properly during backprop?</p>
",2016-12-21 23:47:09,3150181,834,https://stackoverflow.com/questions/41273756,Documentation Ambiguity
41353079,Tensorflow image.central_crop (mis)behavior,"<p>In the Tensorflow documentation for <a href=""https://www.tensorflow.org/api_docs/python/image/cropping#central_crop"" rel=""nofollow noreferrer"">tf.image.central_crop</a> function:</p>

<pre><code>Remove the outer parts of an image but retain the central region of
the image along each dimension. If we specify central_fraction = 0.5,
this function returns the region marked with ""X"" in the below diagram.

 --------
|        |
|  XXXX  |
|  XXXX  |
|        |   where ""X"" is the central 50% of the image.
 --------
</code></pre>

<p>Consider the following code:</p>

<pre><code>In [2]: import tensorflow as tf
In [3]: image_raw = tf.placeholder(tf.string)
In [4]: image = tf.image.decode_jpeg(image_raw, channels=3)
In [5]: crop = tf.image.central_crop(image, central_fraction=0.5)
In [6]: init_op = tf.global_variables_initializer()
In [7]: sess = tf.Session()
In [8]: sess.run(init_op)
In [9]: image_np, crop_np = sess.run([image, crop],
   ...:     feed_dict={image_raw: open(""/tmp/test.jpg"", 'rb').read()})
In [10]: image_np.shape
Out[10]: (456, 450, 3)
</code></pre>

<p>Original image size is 456x450</p>

<pre><code>In [11]: crop_np.shape
Out[11]: (228, 226, 3)
</code></pre>

<p>Crop size is 228x226</p>

<p>Which gives area ratio of:</p>

<pre><code>In [12]: 228*226 / (456*450.)
Out[12]: 0.2511111111111111
</code></pre>

<p>Not 0.5 as I expected. Can someone help to clarify this?</p>
",2016-12-27 22:39:59,6996238,1,https://stackoverflow.com/questions/41353079,Documentation Ambiguity
41437483,How does tf.nn.conv2d calculate its values?,"<p>I've looked at the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn/convolution"" rel=""nofollow noreferrer"">documentation</a> for <code>tf.nn.conv2d</code> but it didn't really help much. So I tried to multiply the first 4 values of my input array that form a square <code>(0, 1, 2, 2.5)</code> with the first column of the <code>filter_weights</code> array <code>(0.19041163, -0.36705261, 0.69018674, 1.7655524)</code>. But regardless of how I multiply these values I'm not getting <code>1.13938534</code>, I don't know what I'm doing wrong. </p>

<p>Below I have the code that I used.</p>

<p>Given an array:</p>

<pre><code>x = np.array([
[0, 1, 0.5, 10],
[2, 2.5, 1, -8],
[4, 0, 5, 6],
[15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))

X = tf.constant(x)
</code></pre>

<p>And weights:</p>

<pre><code>filter_weights = tf.truncated_normal([2,2,1,3])
</code></pre>

<p>Which prints:</p>

<pre><code>[[[[ 0.19041163  0.59322315  0.27544078]]

  [[-0.36705261 -1.18738699  1.45393717]]]


 [[[ 0.69018674  1.08702338 -1.15911126]]

  [[ 1.76255524 -1.42660797 -0.18624328]]]]
</code></pre>

<p>How does:</p>

<pre><code>strides = [1, 2, 2, 1]
padding = ""SAME""
tf.nn.conv2d(input, F_W, strides, padding)
</code></pre>

<p>Give:</p>

<pre><code> [[[[  1.13938534  -5.06340981  -4.23629761]
   [-18.01530266  -4.67841816  16.20156288]]

  [[ -9.49576092  -4.87288237   6.77371216]
   [ -0.57718992 -12.70932484   0.89242649]]]]
</code></pre>
",2017-01-03 06:14:27,3529361,4140,https://stackoverflow.com/questions/41437483,Lack of Alternative Solutions/Documentation
41449338,TensorFlow for MultiGPU,"<p>If someone can help me understand the situation it would be great. Thanks in advance.
My setup:
OS: Ubuntu 16.04, 2 Titan X GPUs. TensorFlow (version 0.12.1) installed in a conda environment using pip as on TF docs. Python 3.5.</p>

<p>Code:
I ran the following code to test my 2 GPU setup. Once each with <code>random_matrix = tf.zeros(...)</code> and <code>random_matrix = tf.random_uniform(...)</code>. The outputs are shown below. </p>

<p>Questions:
1) When I run with <code>tf.zeros</code>. The timings on CPU and GPU are identical. But with <code>tf.random_uniform</code> I see that the GPU is faster (as I had expected). Why is <code>tf.zeros</code> slower on GPU? What am I missing?
2) I have fixed the global seed and the local seed. Why are the outputs within the GPUs different for the <code>tf.random_uniform</code> case?</p>

<p>Thanks a lot for any insights in advance.</p>

<pre><code>import sys
import numpy as np
import tensorflow as tf
from datetime import datetime

device_names = [""/cpu:0"", ""/gpu:0"", ""/gpu:1""]
shapes = [(3000, 3000), (6000, 6000), (9000, 9000), (12000, 12000)]

all_timings = []
tf.set_random_seed(1234)
for device_name in device_names:
    device_timings = []
    for shape in shapes:
        print(""device_name:::::::::{}"".format(device_name))
        with tf.device(device_name):
            # random_matrix = tf.zeros(shape)
            random_matrix = tf.random_uniform(shape=shape, 
                                              minval=0, 
                                              maxval=1, 
                                              seed=1234)
            result_op = tf.reduce_sum(tf.matmul(random_matrix,tf.transpose(random_matrix)))

        start_time = datetime.now()
        result = -1.0
        with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as session:
            result = session.run(result_op)
            time_diff = datetime.now() - start_time
            device_timings.append((device_name,
                                   shape,
                                   ""time_taken (secs): {}"".format(time_diff.total_seconds()),
                                   ""result: {}"".format(result)))
            print(""++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n"")
all_timings.append(device_timings)

print(""\n\n"")
for device_timings in all_timings:
    for t in device_timings:
    print(t)
    print(""---------------------------------------------------------\n\n"")
</code></pre>

<p>Timings with tf.random_uniform():</p>

<pre><code>('/cpu:0', (3000, 3000), 'time_taken (secs): 1.146831', 'result:     6754431488.0')
('/cpu:0', (6000, 6000), 'time_taken (secs): 2.816985', 'result: 54023852032.0')
('/cpu:0', (9000, 9000), 'time_taken (secs): 9.372665', 'result: 184425938944.0')
('/cpu:0', (12000, 12000), 'time_taken (secs): 21.718614', 'result: 439655661568.0')
--------------------------------------------------------


('/gpu:0', (3000, 3000), 'time_taken (secs): 0.39667', 'result: 6754406912.0')
('/gpu:0', (6000, 6000), 'time_taken (secs): 0.085984', 'result: 54006796288.0')
('/gpu:0', (9000, 9000), 'time_taken (secs): 0.221407', 'result: 182251880448.0')
('/gpu:0', (12000, 12000), 'time_taken (secs): 0.444187', 'result: 431996174336.0')
---------------------------------------------------------


('/gpu:1', (3000, 3000), 'time_taken (secs): 0.399159', 'result: 6754401792.0')
('/gpu:1', (6000, 6000), 'time_taken (secs): 0.102889', 'result: 54006857728.0')
('/gpu:1', (9000, 9000), 'time_taken (secs): 0.262842', 'result: 182251585536.0')
('/gpu:1', (12000, 12000), 'time_taken (secs): 0.469139', 'result: 431996141568.0')
---------------------------------------------------------
</code></pre>

<p>Timings with tf.zeros():</p>

<pre><code>('/cpu:0', (3000, 3000), 'time_taken (secs): 1.040602', 'result: 0.0')
('/cpu:0', (6000, 6000), 'time_taken (secs): 2.760587', 'result: 0.0')
('/cpu:0', (9000, 9000), 'time_taken (secs): 9.134257', 'result: 0.0')
('/cpu:0', (12000, 12000), 'time_taken (secs): 21.410583', 'result: 0.0')
---------------------------------------------------------


('/gpu:0', (3000, 3000), 'time_taken (secs): 0.394707', 'result: 0.0')
(/gpu:0', (6000, 6000), 'time_taken (secs): 2.750311', 'result: 0.0')
('/gpu:0', (9000, 9000), 'time_taken (secs): 9.141721', 'result: 0.0')
('/gpu:0', (12000, 12000), 'time_taken (secs): 21.441183', 'result: 0.0')
 --------------------------------------------------------


('/gpu:1', (3000, 3000), 'time_taken (secs): 0.390197', 'result: 0.0')
('/gpu:1', (6000, 6000), 'time_taken (secs): 2.788815', 'result: 0.0')
('/gpu:1', (9000, 9000), 'time_taken (secs): 9.335516', 'result: 0.0')
('/gpu:1', (12000, 12000), 'time_taken (secs): 21.654866', 'result: 0.0')
</code></pre>
",2017-01-03 17:44:27,1882931,11,https://stackoverflow.com/questions/41449338,Documentation Replicability
41467115,"Using word2vec pretrained vectors, how to generate ids of a sentence as input to tf.nn.embedding_lookup function in tensorflow?","<p>To extract the embedding representations of input data, the tensorflow documentation says we can use the following:</p>

<pre><code>embed = tf.nn.embedding_lookup(embeddings, input_data)
</code></pre>

<p>Accdg to the <a href=""https://www.tensorflow.org/api_docs/python/nn/embeddings#embedding_lookup"" rel=""nofollow noreferrer"">TF documentation</a>, the 2nd parameter of the function tf.nn.embedding_lookup is a tensor of ids:</p>

<blockquote>
  <p>ids: A Tensor with type int32 or int64 containing the ids to be looked up in params.</p>
</blockquote>

<p>My question is: Given a sentence, say, </p>

<blockquote>
  <p>""Welcome to the world""</p>
</blockquote>

<p>how can I represent and transform it into <code>ids</code>? In the code below, how can I transform my sentence into <code>input_data</code>. </p>

<pre><code>from gensim import models
embedding_path = ""../embeddings/GoogleNews-vectors-negative300.bin""
w = models.Word2Vec.load_word2vec_format(embedding_path, binary=True)
X = w.syn0
W = tf.Variable(tf.constant(0.0, shape=X.shape),trainable=False, name=""W"")
embedding_placeholder = tf.placeholder(tf.float32, X.shape)
embedding_init = W.assign(embedding_placeholder)
embed = tf.nn.embedding_lookup(embedding_init, input_data)
sess = tf.Session()
sess.run(embed, feed_dict={embedding_placeholder: X})
</code></pre>
",2017-01-04 15:13:46,3009947,63,https://stackoverflow.com/questions/41467115,Documentation Replication on Other Examples
41559723,Does the tf.nn.conv2d_transpose transpose the filter?,"<p>I have a trained feedforward CNN. The shape of filter is [height, width, in_channels, out_channels]. And i want to use those filter to do deconv, we know that the deconv process needs the transpose of the filter.Do i need to transpose the filter mannuly, or the <code>TF</code> will do it inside the <code>tf.nn.conv2d_transpose</code>and all we need to do is pass the trained filter to <code>tf.nn.conv2d_transpose</code>?</p>
",2017-01-10 01:21:07,7345996,829,https://stackoverflow.com/questions/41559723,Documentation Replication on Other Examples
41953678,Documentation for Inference from saved model in Tensorflow,"<p>As explained at <a href=""https://www.tensorflow.org/tutorials/mnist/pros/#build_a_multilayer_convolutional_network"" rel=""nofollow noreferrer"">Multilayer CNN for MNIST Digit Recognition</a> I created a CNN for MNIST image recognition dataset. I don't want to test it in the same script so I trained the model, saved the checkpoint files and graph structure and then using <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py"" rel=""nofollow noreferrer"">freeze_graph.py</a> script. I froze it into one single .pb file. Now using this .pb file I want to infer for MNIST test dataset and check the accuracy of the model but there is no clear documentation as to how to do it. There is one example written in examples/label_images directory but that too is in C++ and for inception network. I have already parsed the .pb file and made a tf.Graph object. And also why can't a single inference script be provided since whole graph structure can be read from graph saved in the .pb file.</p>
",2017-01-31 09:18:30,5182224,175,https://stackoverflow.com/questions/41953678,Documentation Replication on Other Examples
42133661,Tensorflow - LSTM state reuse within batch,"<p>I am working on a Tensorflow NN which uses an LSTM to track a parameter (time series data regression problem). A batch of training data contains a batch_size of <em>consecutive</em> observations. I would like to use the LSTM state as input to the next sample. So, if I have a batch of data observations, I would like to feed the state of the first observation as input to the second observation and so on. Below I define the lstm state as a tensor of size = batch_size. I would like to reuse the state <em>within</em> a batch:</p>

<pre><code>state = tf.Variable(cell.zero_states(batch_size, tf.float32), trainable=False)
cell = tf.nn.rnn_cell.BasicLSTMCell(100)
output, curr_state = tf.nn.rnn(cell, data, initial_state=state) 
</code></pre>

<p>In the API there is a tf.nn.state_saving_rnn but the documentation is kinda vague. <strong>My question</strong>: How to reuse curr_state <em>within</em> a training batch.</p>
",2017-02-09 10:06:30,2061800,637,https://stackoverflow.com/questions/42133661,Documentation Ambiguity
42159830,How to use tf.compute_gradient_error,"<p>I want to use <code>tf.test.compute_gradient_error</code> to check if all gradients are reasonable (almost equal zero).   </p>

<p>I did a small test, It seems this function accept placeholder.<br>
Compute gradient error without feed placeholder data is ok</p>

<pre><code>x = tf.Variable([2], dtype=tf.float32)
xp = tf.placeholder(dtype=tf.float32, shape=[None, 5])
y = xp * 2
y2 = y * x
y3 = y2 * 3
y4 = tf.reduce_mean(y3)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    # err = 9.84e-5
    err = tf.test.compute_gradient_error(y2, (2, 5), y3, (2, 5))
    # err1 = 6.94e-5
    err1 = tf.test.compute_gradient_error(y2, (2, 5), y4, ())
</code></pre>

<p>But when I start check, It shows error message </p>

<pre><code>loss_sumup = func(sumup) # e.g. concat and reduce_mean....
loss = loss_sumup + lossL2
# err = 4.67e-5
err = tf.test.compute_gradient_error(loss_sumup, [], loss, [])

# err1: You must feed a value for placeholder tensor 'Placeholder'
err1 = tf.test.compute_gradient_error(lossL2, [], loss, [])

# err2: You must feed a value for placeholder tensor 'Placeholder'
err2 = tf.test.compute_gradient_error(sumup, [100, 10], loss, [])
</code></pre>

<p>lossL2 is weight l2 loss</p>

<pre><code>tf_vars = tf.trainable_variables()
lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in tf_vars
                   if 'bias' not in v.name]) * 0.001
</code></pre>

<p>If I use parameter <code>extra_feed_dict</code> to feed placeholder data, the pycharm debuger show <code>Timeout waiting for response on 113</code><br>
I think timeout is a acceptable result, because my model use almost 2 mins for each iteraction, I need to find some way to speed up    </p>

<p><strong>Edit 02/11</strong>    </p>

<pre><code>A = 200
B = 1
# f = np.random.rand(A, B)
# vif = tf.placeholder(tf.float32, shape=[A, B])
f = np.ones((A, B), dtype=np.float32)
vif = tf.constant(f, dtype=tf.float32)

out1 = vif + tf.floor(vif)
out2 = tf.sub(vif, tf.floor(vif))
out3 = tf.subtract(vif, tf.floor(vif))
out4 = vif - tf.floor(vif)

with tf.Session() as sess:
    # sometimes value close 500, sometimes close 1E-5
    err1 = tf.test.compute_gradient_error(vif, [A, B], out1, [A, B])
    err2 = tf.test.compute_gradient_error(vif, [A, B], out2, [A, B])
    err3 = tf.test.compute_gradient_error(vif, [A, B], out3, [A, B])
    err4 = tf.test.compute_gradient_error(vif, [A, B], out4, [A, B])
</code></pre>
",2017-02-10 12:50:04,6306884,1430,https://stackoverflow.com/questions/42159830,Documentation Ambiguity
42169830,How to save two different checkpoints during training in Tensorflow,"<p>Assume we have test/val/train splits. During training, we want to save some model checkpoints [save_1] that can be used to restart the training later.</p>

<p>In addition, we want to save another model during training that shows the best performance on the validation sets [save_2]. After done with training, we use save_2 to report the performance on the test data. </p>

<p>My question is that how we can have two different tf.savers during training in TensorFlow? whatever examples that I have seen, only save [save_1].
Pointer to any codes would be appreciated.</p>

<p>Thanks.</p>
",2017-02-10 22:43:16,1214630,833,https://stackoverflow.com/questions/42169830,Documentation Replication on Other Examples
42211485,How to collect performance metrics from running google cloud ml training instances?,"<p>I'm running a model on google cloud ml training, and it's taking about 10 hours with some naive guesses at the shapes of the machine. I'd like to optimize it a bit to cut down on running time and overall cost.</p>

<p>What's the best way to determine if I'm using the resources effectively? I'd like cpu measurements, memory pressure, and GPU usage (whenever they are available). I suspect I'd need to either 1) log these or 2) install a monitoring agent like stack driver, and assume things like nvidia-smi are locatable, but I'm curious if any one has tried.</p>
",2017-02-13 18:57:39,54858,13393,https://stackoverflow.com/questions/42211485,Documentation Replication on Other Examples
42287954,tf.argmax() vs tf.arg_max() in TensorFlow,"<p>It seems <code>tf.argmax()</code> and <code>tf.arg_max()</code> are doing the same thing for outputting the indies of the biggest element in matrix.</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/argmax"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/argmax</a>
<a href=""https://www.tensorflow.org/api_docs/python/tf/arg_max"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/arg_max</a></p>

<p>Why does TensorFlow have two APIs for this?</p>
",2017-02-17 01:46:00,5538737,243,https://stackoverflow.com/questions/42287954,Documentation Ambiguity
42333101,Predicting Next Word of LSTM Model from Tensorflow Example,"<p>My buddy and I are trying to utilize the trained model from the LSTM tensorflow example <a href=""https://www.tensorflow.org/tutorials/recurrent"" rel=""nofollow noreferrer"">here</a>. We've been able to train our model, save the model, and then import the model. We've just used tensorflow's Supervisor. It was in the tutorial, but you can read more about it <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard6/tf.train.Supervisor.md"" rel=""nofollow noreferrer"">here</a>. </p>

<p>It's weird because there's not a whole lot of clear documentation for this. I understand that tensorflow is an API that's going through a lot of changes and adaptations right now, but it's hard to find clear answers. For example, we want to use <code>tf.train.Saver()</code>, but we aren't sure if there is anything comparable to <code>tf.train.Supervisor()</code>'s <code>managed_session</code>. </p>

<p>More to the point, however, we <em>just want to use our model</em>. We want to be able to map a string using <code>tensorflow.models.rnn.ptb.reader</code>. We're not sure how to do this. We pass in a string, and we want to do a simple prediction in terms of like predicting the next word in a string. So, something similar to this:</p>

<pre><code>import tensorflow as tf
sess = tf.Session()
new_saver = tf.train.import_meta_graph('ptbmodel.meta')
new_saver.restore(sess, tf.train.latest_checkpoint('./')) # latest checkpoint
all_vars = tf.global_variables()
# just want to make sure all our variables are there!
for v in all_vars:
    v_ = sess.run(v)
    print(""This is {} with value: {}"".format(v.name, v_))


sent = raw_input(""Enter a string where you want to predict the next word: "")
split_sent = sent.split()
# THEN map these words into our LSTM model and pull off the most likely word that 
# is coming next
</code></pre>

<p>But again, my buddy and I are pretty new to this, so we're not sure about where to go. I know this is probably too broad of a question for stack, but we've been pouring over the documentation and haven't been able to make much progress. <strong>ANY</strong> help would be appreciated so much! </p>

<p>We've already found these other Stack links. Check them out <a href=""https://stackoverflow.com/questions/36286594/predicting-the-next-word-using-the-lstm-ptb-model-tensorflow-example"">here</a> and <a href=""https://stackoverflow.com/questions/33773661/predicting-next-word-using-the-language-model-tensorflow-example"">here</a>.</p>

<p>We are not sure how to associate the <code>logits</code> probability list with any meaningful words.</p>
",2017-02-19 21:29:21,6347839,951,https://stackoverflow.com/questions/42333101,Documentation Replication on Other Examples
42334855,state output from tf.nn.dynamic_rnn operation,"<p>For this code snippet:</p>

<pre><code>rnn_cell = tf.contrib.rnn.BasicRNNCell(config.hidden_size, activation=tf.tanh)
initial_state = rnn_cell.zero_state(config.batch_size, tf.float32)
rnn_out, state = tf.nn.dynamic_rnn(rnn_cell, embed_out, initial_state=initial_state)
</code></pre>

<p>I was expected the last time index from rnn_out to be equal to state. Or, perhaps the tanh of the state. But this isn't what I am seeing - they don't match. In the context of this RNN recurrence relation, what value does state contain?</p>

<p>h(t) = tanh[b + W<em>h(t-1) + U</em>x(t)]</p>

<p>The answer here, implies the last time index of rnn_out and state should be equal (but they are not):</p>

<p><a href=""https://stackoverflow.com/questions/40384791/for-the-tf-nn-rnn-cell-basicrnn-whats-the-difference-between-the-state-and-outp"">for the tf.nn.rnn_cell.BasicRNN,what&#39;s the difference between the state and output</a></p>

<p>The TF documentation isn't clear to me on this point.</p>
",2017-02-20 00:54:46,7590388,216,https://stackoverflow.com/questions/42334855,Documentation Ambiguity
42381548,Tensor Flow: Simple Network Surgery (dropping first layers),"<p>Assume you have a trained network that is comprised by five layers represented as <strong>L1->L2->L3->L4->L5</strong>. 
Here, L1, is the <em>input</em> layer, comprised by a tf.placeholder. </p>

<p>How can you <em>fix</em> the output of a middle layer, like L3, to a value specified by the user and run a forward pass to see the output values of L5? In other words in this scenario we would like to treat L3 as the starting input layer and ignore L1 and L2 altogether.</p>

<p>Finally, assume that there is <strong>no</strong> need for a backward pass: i.e., we only want to evaluate and not train further the model.</p>

<p>Thanks!</p>
",2017-02-22 02:21:48,986040,1541,https://stackoverflow.com/questions/42381548,Documentation Replication on Other Examples
42399401,Use of grads_ys parameter in tf.gradients - TensorFlow,"<p>I want to understand the <code>grad_ys</code> paramter in <code>tf.gradients</code>. I've seen it used like a multiplyer of the true gradient but its not crear in the definition. Mathematically how would the whole expression look like?</p>
",2017-02-22 18:24:04,2118130,9696,https://stackoverflow.com/questions/42399401,Lack of Alternative Solutions/Documentation
42437115,"Tensorflow: Replacement for tf.nn.rnn_cell._linear(input, size, 0, scope)","<p>I am trying to get the SequenceGAN (<a href=""https://github.com/LantaoYu/SeqGAN"" rel=""noreferrer"">https://github.com/LantaoYu/SeqGAN</a>) from <a href=""https://arxiv.org/pdf/1609.05473.pdf"" rel=""noreferrer"">https://arxiv.org/pdf/1609.05473.pdf</a> to run.<br>
After fixing the obvious errors, like replacing <code>pack</code> with <code>stack</code>, it still doesn't run, since the highway-network part requires the <code>tf.nn.rnn_cell._linear</code> function:</p>

<pre><code># highway layer that borrowed from https://github.com/carpedm20/lstm-char-cnn-tensorflow
def highway(input_, size, layer_size=1, bias=-2, f=tf.nn.relu):
    """"""Highway Network (cf. http://arxiv.org/abs/1505.00387).

    t = sigmoid(Wy + b)
    z = t * g(Wy + b) + (1 - t) * y
    where g is nonlinearity, t is transform gate, and (1 - t) is carry gate.
    """"""
    output = input_
    for idx in range(layer_size):
        output = f(tf.nn.rnn_cell._linear(output, size, 0, scope='output_lin_%d' % idx)) #tf.contrib.layers.linear instad doesn't work either.
        transform_gate = tf.sigmoid(tf.nn.rnn_cell._linear(input_, size, 0, scope='transform_lin_%d' % idx) + bias)
        carry_gate = 1. - transform_gate

        output = transform_gate * output + carry_gate * input_

    return output
</code></pre>

<p>the <code>tf.nn.rnn_cell._linear</code> function doesn't appear to be there anymore in Tensorflow 1.0 or 0.12, and I have no clue what to replace it with. I can't find any new implementations of this, or any information on tensorflow's github or (unfortunately very sparse) documentation.</p>

<p>Does anybody know the new pendant of the function?
Thanks a lot in advance!</p>
",2017-02-24 11:08:11,5122790,337,https://stackoverflow.com/questions/42437115,Requesting (Additional) Documentation/Examples
42462895,How can I use tf.Session.run() on Android?,"<p>I want to make Tensorflow predictions on the Android. I found example Tensorflow Demo app for Android. But how can I use tf.Session.run,  tf.nn.softmax and other functions?</p>
",2017-02-25 23:30:59,5244666,563,https://stackoverflow.com/questions/42462895,Documentation Replicability
42618350,Tensorflow consecutive slice_input_producer,"<p>I am confused with how does <code>tf.train.slice_input_producer</code> works, I know it returns a dequeue op, but if I apply another <code>slice_input_producer</code> on the previous dequeued tensor, it seems the second <code>slice_input_producer</code> triggered the first ones dequeue op without finishing slicing. </p>

<p>Here is an example code:</p>

<pre><code>x = np.arange(6).reshape([2, 3])
input_x = tf.constant(x, dtype=tf.int32)

[row] = tf.train.slice_input_producer([input_x], num_epochs=1, shuffle=False)
[cloumn] = tf.train.slice_input_producer([row], num_epochs=1, shuffle=False)

init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())

sess = tf.Session()
sess.run(init_op)

coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)

print(x)
col = sess.run(cloumn)
print(col)
col = sess.run(cloumn)
print(col)
</code></pre>

<p>I am expecting 0,1,2,3,4,5 each time I eval <code>column</code>. But it gives 0 and 4, the second <code>slice_input_producer</code> didn't finishing slicing the first row.</p>

<p>How can I fix this? Many thanks in advance. </p>
",2017-03-06 05:43:46,4405877,493,https://stackoverflow.com/questions/42618350,Documentation Ambiguity
42695305,Accessing row in a 2-D tensor,"<p>I have the following code of an incredibly simple neural network (this code is actually an adaptation for an easy question):</p>

<pre><code>import numpy as np
import tensorflow as tf

with tf.device(""cpu:0""):
    sess = tf.InteractiveSession()
    nNodes = 3
    inputDim = 1

    rowIdxs = np.zeros([nNodes, nNodes])
    colIdxs = np.zeros([nNodes, nNodes])
    for rowIdx in range(nNodes):
        for colIdx in range(nNodes):
            rowIdxs[rowIdx, colIdx] = rowIdx
            colIdxs[rowIdx, colIdx] = colIdx

    rowIdxs = np.reshape(rowIdxs, [-1])
    colIdxs = np.reshape(colIdxs, [-1])

    # build a matrix with nNodes x nNodes elements
    # with each row i containing the distance from node i to all the other nodes
    distances = np.zeros([nNodes, nNodes])
    for i in range(nNodes):
        for j in range(nNodes):
            distances[i, j] = ((rowIdxs[i] - rowIdxs[j]) ** 2 + (colIdxs[i] - colIdxs[j]) ** 2)
    print('distances=', distances)

    # tensorflow constant from distances matrix
    distances_ = tf.constant(distances, dtype=tf.float32)

    # w corresponds to a weight matrix in a neural network
    w = tf.random_uniform((nNodes, inputDim), 0.0, 1.0)

    # x corresponds to the input to the network
    x = tf.random_uniform((1, inputDim), 0.0, 1.0)

    xx = tf.tile(x, [nNodes,1])
    print('w', w.shape)
    print('x', x.shape)
    print('xx', xx.shape)

    # differences between weights and input vector
    diff = tf.reduce_sum(tf.abs(tf.subtract(xx, w)), 1)
    print('diff.shape', diff.shape)


    # index of the best matching unit
    bmu = tf.arg_min(diff, 0)       

    # Now I need to access the distances from BMU to the other nodes
    slice = tf.slice(distances_, [bmu, 0], [bmu, -1])

    sess.run(tf.global_variables_initializer())
    sess.run(slice)
    print('slice=', slice.eval())
    print('diff', diff.eval())
    print('bmu=', bmu.eval())
</code></pre>

<p>Basically, given an input <code>x</code>, compare it to the weights <code>w</code> and choose the node <code>BMU</code> with the minimum differences.</p>

<p>I have several problems with that code:</p>

<p><strong>1. sometimes it works without errors sometimes it raises an exception.</strong> </p>

<p><strong>When it DOES NOT work</strong>, the output is this:</p>

<pre><code>distances= 
 [[ 0.  1.  4.]
 [ 1.  0.  1.]
 [ 4.  1.  0.]]

w (3, 1)
x (1, 1)
xx (3, 1)
diff.shape (3,)

InvalidArgumentError (see above for traceback): Expected size[0] in [0, 1], but got 2
 [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]
</code></pre>

<p>The full stack follows:</p>

<pre><code>Traceback (most recent call last):
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1022, in _do_call
    return fn(*args)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""D:\python\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected size[0] in [0, 1], but got 2
     [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 44, in &lt;module&gt;
    sess.run(slice)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 767, in run
    run_metadata_ptr)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected size[0] in [0, 1], but got 2
     [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]

Caused by op 'Slice', defined at:
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 39, in &lt;module&gt;
    slice = tf.slice(distances_, [bmu, 0], [bmu, -1])
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 561, in slice
    return gen_array_ops._slice(input_, begin, size, name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 3053, in _slice
    name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Expected size[0] in [0, 1], but got 2
     [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]
</code></pre>

<p><strong>When it works</strong></p>

<pre><code>w (3, 1)
x (1, 1)
xx (3, 1)
diff.shape (3,)
slice= [[ 1.  0.  1.]]
diff [ 0.29777944  0.08669317  0.09722018]
bmu= 0
</code></pre>

<p><code>bmu</code> is wrong, it should be <code>1</code>, but the slice is correct.</p>

<p>Sometimes I get this:</p>

<pre><code>w (3, 1)
x (1, 1)
xx (3, 1)
diff.shape (3,)
slice= []
diff [ 0.33319855  0.12426794  0.49753141]
bmu= 1
</code></pre>

<p><code>bmu</code> is 1, but slice is empty.</p>

<p><strong>2. When I switch to the GPU, I have an exception telling me I cannot use <code>bmu</code> for indexing.</strong>
Starting with <code>with tf.device(""gpu:0""):</code>, I get this:</p>

<pre><code>InvalidArgumentError (see above for traceback): Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]
</code></pre>

<p>The full stack trace follows:</p>

<pre><code>Traceback (most recent call last):
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1022, in _do_call
    return fn(*args)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""D:\python\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 45, in &lt;module&gt;
    sess.run(slice)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 767, in run
    run_metadata_ptr)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]

Caused by op 'Slice/size', defined at:
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 40, in &lt;module&gt;
    slice = tf.slice(distances_, [bmu, 0], [bmu, -1])
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 561, in slice
    return gen_array_ops._slice(input_, begin, size, name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 3053, in _slice
    name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 491, in apply_op
    preferred_dtype=default_dtype)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 923, in _autopacking_conversion_function
    return _autopacking_helper(v, inferred_dtype, name or ""packed"")
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 886, in _autopacking_helper
    return gen_array_ops._pack(elems_as_tensors, name=scope)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 2041, in _pack
    result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]
</code></pre>

<p>I cannot understand what's happening: I have an idea, but cannot find any reference in the documentation or anywhere else. May be I use the wrong keywords.</p>

<p>Is there anyone who can help me?</p>
",2017-03-09 12:22:48,774133,2966,https://stackoverflow.com/questions/42695305,Lack of Alternative Solutions/Documentation
42708109,I get a CUDA_ERROR_OUT_OF_MEMORY when using images with Estimator API r1.0,"<p>I am trying to use the Estimator API from <code>tf.contrib.learn.estimator</code> to build, fit, and evaluate CNN image classifiers. My code below is based on abalone.py from the tutorial on <a href=""https://www.tensorflow.org/extend/estimators"" rel=""nofollow noreferrer"">Creating Estimators</a>. In addition, I am importing the code from the <a href=""https://www.tensorflow.org/tutorials/deep_cnn"" rel=""nofollow noreferrer"">cifar10 tutorial</a> to provide both the model and the input feeds.  The code is as follows:</p>

<pre><code>import tensorflow as tf
import cifar10

def model_fn(features, targets, mode, params):
# Generate predictions from cifar10 network
logits = cifar10.inference(features)
prediction_dict = {""classes"" : logits}

# Loss operation
loss = tf.losses.softmax_cross_entropy(targets, logits, scope='loss')

# Metrics for evaluation
eval_metric_ops = {
    ""accuracy""  :   tf.metrics.accuracy(targets, logits, name='accuracy'),
    ""precision"" :   tf.metrics.precision(targets, logits, name='precision')
}

# Training operation
train_op = tf.contrib.layers.optimize_loss(
    loss=loss,
    global_step=tf.contrib.framework.get_global_step(),
    learning_rate=params[""learning_rate""],
    optimizer=""SGD"")

return tf.contrib.learn.ModelFnOps(
    mode=mode,
    predictions=prediction_dict,
    loss=loss,
    train_op=train_op,
    eval_metric_ops=eval_metric_ops
)
def input_fn():
    features, labels = cifar10.distorted_inputs()
    return features, tf.one_hot(labels, 10)

def eval_input_fn():
    return cifar10.inputs(eval_data=True)

def main(args=None):
    # Set model params
    model_params = {""learning_rate"": 0.1}
#Create and fit estimator
nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)
nn.fit(input_fn=input_fn, steps=5000)

ev = nn.evaluate(input_fn=eval_input_fn(), steps=1)
print(""Loss: %s"" % ev[""loss""])
print(""Accuracy: %s"" % ev[""accuracy""])
print(""Precision: %s"" % ev[""precision""])

if __name__ == '__main__':
  tf.app.run()
</code></pre>

<p>The error messages I get are as follows:</p>

<pre><code>E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 7.92G (8507555840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 7.13G (7656800256 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 6.42G (6891120128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 5.78G (6202008064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 5.20G (5581807104 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
</code></pre>

<p>The error messages continue to count down memory size and end with the following three lines:</p>

<pre><code>E tensorflow/stream_executor/cuda/cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
E tensorflow/stream_executor/cuda/cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
F tensorflow/core/kernels/conv_ops.cc:605] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms(&amp;algorithms) 
</code></pre>
",2017-03-10 00:37:15,7674512,113,https://stackoverflow.com/questions/42708109,Documentation Ambiguity
42734106,How to restore variable object,"<p>I want to restore a variable object. That is, I want to have an object of type <code>tensorflow.Variables</code> after deserialization.</p>

<p>I try to use <a href=""https://www.tensorflow.org/versions/r0.12/how_tos/meta_graph/"" rel=""nofollow noreferrer"">MetaGraph</a>. Here is a minimal example. Serialization:</p>

<pre><code>import tensorflow as tf

var = tf.Variable(101)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    saver = tf.train.Saver()
    tf.add_to_collection('var', var)
    saver.save(sess, 'data/sess')
</code></pre>

<p>Deserialization</p>

<pre><code>import tensorflow as tf

with tf.Session() as sess:
    saver = tf.train.import_meta_graph('data/sess.meta')
    saver.restore(sess, 'data/sess')

    var = tf.get_collection('var')[0]
    print(var)
    print(type(var))
    # Output:
    # Tensor(""Variable:0"", shape=(), dtype=int32_ref)
    # &lt;class 'tensorflow.python.framework.ops.Tensor'&gt;

    print(tf.get_collection('variables'))
    # [&lt;tensorflow.python.ops.variables.Variable object at 0x10edd1d30&gt;]

    test_var = tf.get_collection('variables')[0]
    print(test_var.name)
    # Variable:0
</code></pre>

<p>The issue is that <code>tf.get_collection</code> return <code>tf.Tensor</code> object, not
<code>tf.Variable</code>. But I can see <code>tf.Variable</code> objects in <code>variables</code> collection.</p>

<p>What is the correct way of restoring <code>Variable</code> object?</p>
",2017-03-11 10:33:44,1292688,386,https://stackoverflow.com/questions/42734106,Documentation Replication on Other Examples
42754259,Sampled softmax loss over variable sequence batches?,"<p><strong>Background info</strong>: I'm working on sequence-to-sequence models, and right now my model accepts variable-length input tensors (not lists) with input shapes corresponding to [batch size, sequence length]. However, in my implementation, sequence length is <em>unspecified</em> (set to None) to allow for variable length inputs. Specifically, input sequence batches are padded only to the length of the longest sequence in that batch. This has sped up my training time considerably, so I'd prefer to keep it this way, as opposed to going back to bucketed models and/or padded all sequences in the training data to the same length. I'm using TensorFlow 1.0.0.</p>

<p><strong>Problem</strong>: I'm currently using the following to compute the loss (which runs just fine).</p>

<pre><code>loss = tf.losses.sparse_softmax_cross_entropy(
    weights=target_labels,  # shape: [batch size, None]
    logits=outputs[:, :-1, :], # shape: [batch size, None, vocab size]
    weights=target_weights[:, :-1]) # shape: [batch size, None]
</code></pre>

<p>where vocab size is typically about 40,000. I'd like to use a sampled softmax, but I've ran into an issue that's due to the unspecified nature of the input shape. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""nofollow noreferrer"">documentation for tf.nn.sampled_softmax_loss</a>, <strong>it requires the inputs to be fed separately for each timestep</strong>. However, I can't call, for example,  </p>

<pre><code>tf.unstack(target_labels, axis=1)
</code></pre>

<p>since the axis is unknown beforehand.Does anyone know how I might go about implementing this? One would assume that since both dynamic_rnn and <a href=""https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy"" rel=""nofollow noreferrer"">tf.losses.sparse_softmax_cross_entropy</a> seem to have no issue doing this, that a workaround could be implemented with the sampled softmax loss somehow. After digging around in the source code and even models repository, I've come up empty handed. Any help/suggestions would be greatly appreciated.</p>
",2017-03-12 23:03:38,6706630,46,https://stackoverflow.com/questions/42754259,Documentation Replicability
43057816,Tensorflow - Am I restoring the model correctly?,"<p>I have the following code which is working (no errors). My question is just am I <strong>restoring</strong> the model correctly? Especially that I cannot see any output for the statement <code>print(v_)</code>.</p>

<p>So, I'm trying to know if I'm doing the following correct:</p>

<ol>
<li>Restoring the model</li>
<li><p>Using that restored model</p>

<p>import tensorflow as tf</p>

<pre><code>data, labels = cifar_tools.read_data('C:\\Users\\abc\\Desktop\\Testing')

x = tf.placeholder(tf.float32, [None, 150 * 150])
y = tf.placeholder(tf.float32, [None, 2])

w1 = tf.Variable(tf.random_normal([5, 5, 1, 64]))
b1 = tf.Variable(tf.random_normal([64]))

w2 = tf.Variable(tf.random_normal([5, 5, 64, 64]))
b2 = tf.Variable(tf.random_normal([64]))

w3 = tf.Variable(tf.random_normal([38*38*64, 1024]))
b3 = tf.Variable(tf.random_normal([1024]))

w_out = tf.Variable(tf.random_normal([1024, 2]))
b_out = tf.Variable(tf.random_normal([2]))

def conv_layer(x,w,b):
    conv = tf.nn.conv2d(x,w,strides=[1,1,1,1], padding = 'SAME')
    conv_with_b = tf.nn.bias_add(conv,b)
    conv_out = tf.nn.relu(conv_with_b)
    return conv_out

def maxpool_layer(conv,k=2):
    return tf.nn.max_pool(conv, ksize=[1,k,k,1], strides=[1,k,k,1], padding='SAME')

def model():
    x_reshaped = tf.reshape(x, shape=[-1, 150, 150, 1])

    conv_out1 = conv_layer(x_reshaped, w1, b1)
    maxpool_out1 = maxpool_layer(conv_out1)
    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)
    conv_out2 = conv_layer(norm1, w2, b2)
    norm2 = tf.nn.lrn(conv_out2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)
    maxpool_out2 = maxpool_layer(norm2)

    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, w3.get_shape().as_list()[0]])
    local = tf.add(tf.matmul(maxpool_reshaped, w3), b3)
    local_out = tf.nn.relu(local)

    out = tf.add(tf.matmul(local_out, w_out), b_out)
    return out

model_op = model()

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model_op, y))
train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)

correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    onehot_labels = tf.one_hot(labels, 2, on_value=1.,off_value=0.,axis=-1)
    onehot_vals = sess.run(onehot_labels)
    batch_size = len(data)
    # Restore model
    saver = tf.train.import_meta_graph('C:\\Users\\abc\\Desktop\\\Testing\\mymodel.meta')
    saver.restore(sess, tf.train.latest_checkpoint('./'))
    all_vars = tf.get_collection('vars')
    for v in all_vars:
        v_ = sess.run(v)
        print(v_)

for j in range(0, 5):
    print('EPOCH', j)
    for i in range(0, len(data), batch_size):
        batch_data = data[i:i+batch_size, :]
        batch_onehot_vals = onehot_vals[i:i+batch_size, :]
        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})
        print(i, accuracy_val)

    print('DONE WITH EPOCH')
</code></pre></li>
</ol>

<p><strong>EDIT 1</strong></p>

<p>Would restoring this way work?</p>

<pre><code>saver = tf.train.Saver()
saver = tf.train.import_meta_graph('C:\\Users\\Abder-Rahman\\Desktop\\\Testing\\mymodel.meta')
saver.restore(sess, tf.train.latest_checkpoint('./'))
print('model restored'
</code></pre>

<p><strong>EDIT 2</strong></p>

<p>This is how I <strong>save</strong> my model:</p>

<pre><code>#Save model
saver = tf.train.Saver()
saved_path = saver.save(sess, 'C:\\Users\\abc\\Desktop\\\Testing\\mymodel')
print(""The model is in this file: "", saved_path)
</code></pre>

<p>Thanks.</p>
",2017-03-27 22:58:29,588855,48042,https://stackoverflow.com/questions/43057816,Documentation Replication on Other Examples
43108211,How to add new op in distributed Tensorflow?,"<p>I'm trying to add a new op in distributed tensorflow. Following code is how I create a new operator which can add two array (following this tutorial: <a href=""https://www.tensorflow.org/api_docs/python/tf/py_func"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/py_func</a>).</p>

<pre><code>import tensorflow as tf
import numpy as np

array1 = np.array([[1, 2], [3, 4]], dtype=np.float32)
array2 = np.array([[5, 6], [7, 8]], dtype=np.float32)

def add(array1, array2):
    return array1 + array2

add_op = tf.py_func(add, [array1, array2], [tf.float32])


sess = tf.Session()
print sess.run(add_op)
</code></pre>

<p>Then I follow this tutorial(<a href=""https://www.tensorflow.org/deploy/distributed"" rel=""nofollow noreferrer"">https://www.tensorflow.org/deploy/distributed</a>) to create a cluster of TensorFlow servers and try put an operator in it. I start the nodes, use the following code and command line.  </p>

<pre><code>#worker.py
import tensorflow as tf

# Configuration of cluster 
ps_hosts = [ ""127.0.0.1:8887"" ]
worker_hosts = [ ""127.0.0.1:8888"", ""127.0.0.1:8889"" ]
cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})      

tf.app.flags.DEFINE_string(""job_name"", ""worker"", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

FLAGS = tf.app.flags.FLAGS

def main(_):
    server = tf.train.Server(cluster,
                             job_name=FLAGS.job_name,
                             task_index=FLAGS.task_index)
    server.join()

if __name__ == ""__main__"":
    tf.app.run()
</code></pre>

<p>Command line:</p>

<pre><code># On worker0
python worker.py --job_name=worker --task_index=0

# On ps0
python worker.py --job_name=ps --task_index=0
</code></pre>

<p>Then execute this file to specify whether ops run.</p>

<pre><code>#master.py

import tensorflow as tf
import numpy as np

def add(array1, array2):
    return array1 + array2    

with tf.device(""/job:ps/task:0""):
    array1 = np.array([[1, 2], [3, 4]], dtype=np.float32)
    array2 = np.array([[5, 6], [7, 8]], dtype=np.float32)

with tf.device(""/job:worker/task:0""):
    add_op = tf.py_func(add, [array1, array2], [tf.float32])


with tf.Session(""grpc://127.0.0.1:8887"") as sess:
    print sess.run(add_op)
</code></pre>

<p>But this code is not working, following is the error </p>

<pre><code>Traceback (most recent call last):
  File ""master.py"", line 19, in &lt;module&gt;
    print sess.run(add_op)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Failed to run py callback pyfunc_0: see error log.
     [[Node: PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_FLOAT], token=""pyfunc_0"", _device=""/job:worker/replica:0/task:0/cpu:0""](PyFunc/input_0, PyFunc/input_1)]]
     [[Node: PyFunc_S1 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:0/cpu:0"", send_device_incarnation=-6409934414370243221, tensor_name=""edge_8_PyFunc"", tensor_type=DT_FLOAT, _device=""/job:ps/replica:0/task:0/cpu:0""]()]]

Caused by op u'PyFunc', defined at:
  File ""master.py"", line 15, in &lt;module&gt;
    add_op = tf.py_func(add, [array1, array2], [tf.float32])
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/script_ops.py"", line 189, in py_func
    input=inp, token=token, Tout=Tout, name=name)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_script_ops.py"", line 40, in _py_func
    name=name)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/WakeUp/Repository/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Failed to run py callback pyfunc_0: see error log.
     [[Node: PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_FLOAT], token=""pyfunc_0"", _device=""/job:worker/replica:0/task:0/cpu:0""](PyFunc/input_0, PyFunc/input_1)]]
     [[Node: PyFunc_S1 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:0/cpu:0"", send_device_incarnation=-6409934414370243221, tensor_name=""edge_8_PyFunc"", tensor_type=DT_FLOAT, _device=""/job:ps/replica:0/task:0/cpu:0""]()]]
</code></pre>

<p>According to the N.B. in this page (<a href=""https://www.tensorflow.org/api_docs/python/tf/py_func"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/py_func</a>), I think I didn't violate any rule of py_func function. Such as serializing the model or forgetting run <code>tf.train.Server</code> and <code>tf.device()</code>. Is there still something I didn't notice?</p>
",2017-03-30 03:49:25,6478313,23,https://stackoverflow.com/questions/43108211,Documentation Replicability
43114238,Tensorflow: how do I extract/export variable values at every iteration of training?,"<p>I have been playing around with some neural networks on Tensorflow and I wanted to make a visualization of the neural network's learning process. 
To do so, I intend to extract the following variables into text/JSON/csv: pre-activation result before 1st layer, activation, bias and weight values for testing and training, each layer and for all time steps. I am looking for a generalizable solution so that I don't have to modify my source code (or at least not more than one or two lines) when applying visualization to future networks. Ideally I could run some function from another python program to read any python/TF code and extract the variables described above. So far I have considered the following solutions:
1) use tf.summary and the filewriter to save as a serialized protocol buffer, then find a way to go from protocol buffer --> JSON format. This unfortunately would not fit the bill as it requires me to modify too much inner code. 
2) Perhaps using <a href=""https://www.tensorflow.org/api_docs/python/tf/train/export_meta_graph"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/export_meta_graph</a>
Although I am not sure how to implement given my TF foundations are not quite there yet
3) I have also found this solution:</p>

<pre><code>W_val, b_val= sess.run([W, b])
np.savetxt(""W1.csv"", W_val, delimiter="","")
np.savetxt(""b1.csv"", b_val, delimiter="","")
</code></pre>

<p>But the problem is that it only saves the final values of the weights and biases, whereas I am looking to save their values at all timesteps of training. </p>

<p>If anyone has any suggestions on how to tackle this problem or any guidance I would appreciate it. </p>

<p>Many thanks</p>
",2017-03-30 09:49:15,3299870,1,https://stackoverflow.com/questions/43114238,Documentation Replication on Other Examples
43131606,What's the difference of add methods in TensorFlow?,"<p>Three add methods:
<code>+</code>, <code>tf.add</code>, <code>tf.nn.bias_add</code>.
I made test in ipython, here is the test data.</p>

<pre><code>a = tf.Variable([[1,2],[3,4]])
b = tf.Variable([10,20])
</code></pre>

<p>All three methods returned <code>array([[11, 22],[13, 24]], dtype=int32)</code>.
So what's the difference between them?</p>

<p>Thanks!</p>
",2017-03-31 02:54:52,7677894,875,https://stackoverflow.com/questions/43131606,Documentation Replicability
43261919,How to know if I should wrap operations in name_scope or variable_scope for Tensorboard with example,"<p>When grouping together operations for visualisations there is a large difference between the outputs generated between the two programs below.
The <code>tf.name_scope</code> gives double rnn outputs, one inside the <code>name_scope</code> and one outside while <code>tf.variable_scope</code> gives the clearer representation. How do I know if I must wrap something in variable vs name scopes (besides the obvious case with <code>get_variable</code>)?</p>

<pre><code>import tensorflow as tf

with tf.name_scope(""bongo""):
    x = tf.placeholder(tf.float32,[1,None, 50], name='myxxxx')
    lstm = tf.contrib.rnn.BasicLSTMCell(77)
    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=0.5)
    cell = tf.contrib.rnn.MultiRNNCell([drop] * 3)

    initial_state = cell.zero_state(33, tf.float32)

with tf.name_scope(""alias""):
    outputs, final_state = tf.nn.dynamic_rnn(
        cell,
        x, dtype=tf.float32)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    fw = tf.summary.FileWriter('/tmp/testmodel/1', sess.graph)
</code></pre>

<p>And</p>

<pre><code>import tensorflow as tf

with tf.name_scope(""bongo""):
    x = tf.placeholder(tf.float32,[1,None, 50], name='myxxxx')
    lstm = tf.contrib.rnn.BasicLSTMCell(77)
    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=0.5)
    cell = tf.contrib.rnn.MultiRNNCell([drop] * 3)

    initial_state = cell.zero_state(33, tf.float32)

with tf.variable_scope(""alias""):
    outputs, final_state = tf.nn.dynamic_rnn(
        cell,
        x, dtype=tf.float32)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    fw = tf.summary.FileWriter('/tmp/testmodel/1', sess.graph)
</code></pre>
",2017-04-06 17:22:50,3139545,7052,https://stackoverflow.com/questions/43261919,Documentation Replicability
43367697,Batching and shuffling padded tf.train.SequenceExample,"<p>I have some training example of a sequence-to-sequence scenario which are stored as <code>tf.train.SequenceExample</code> in one (or more) file(s) written <code>TFRecordWriter</code>. I would like to read, decode them and feed shuffled batches of them into my network. I have been struggling with the documentation and some tutorials found here and there but I could not make anything out of such stuff. I am working on a self-contained example, here below. </p>

<pre><code>import random

import tensorflow as tf

from six.moves import xrange


MIN_LEN = 6
MAX_LEN = 12
NUM_EXAMPLES = 20
BATCH_SIZE = 3
PATH = 'ciaone.tfrecords'
MIN_AFTER_DEQUEUE = 10
NUM_THREADS = 2
SAFETY_MARGIN = 1
CAPACITY = MIN_AFTER_DEQUEUE + (NUM_THREADS + SAFETY_MARGIN) * BATCH_SIZE


def generate_example():
    # fake examples which are just useful to have a quick visualization.
    # The input is a sequence of random numbers.
    # The output is a sequence made of those numbers from the
    # input sequence which are greater or equal then the average.
    length = random.randint(MIN_LEN, MAX_LEN)
    input_ = [random.randint(0, 10) for _ in xrange(length)]
    avg = sum([1.0 * item for item in input_]) / len(input_)
    output = [item for item in input_ if item &gt;= avg]
    return input_, output


def encode(input_, output):
    length = len(input_)
    example = tf.train.SequenceExample(
        context=tf.train.Features(
            feature={
                'length': tf.train.Feature(
                    int64_list=tf.train.Int64List(value=[length]))
            }),
        feature_lists=tf.train.FeatureLists(
            feature_list={
                'input': tf.train.FeatureList(
                    feature=[
                        tf.train.Feature(
                            int64_list=tf.train.Int64List(value=[item]))
                        for item in input_]),
                'output': tf.train.FeatureList(
                    feature=[
                        tf.train.Feature(
                            int64_list=tf.train.Int64List(value=[item]))
                        for item in output])
            }
        )
    )
    return example


def decode(example):
    context_features = {
        'length': tf.FixedLenFeature([], tf.int64)
    }
    sequence_features = {
        'input': tf.FixedLenSequenceFeature([], tf.int64),
        'output': tf.FixedLenSequenceFeature([], tf.int64)
    }
    ctx, seq = tf.parse_single_sequence_example(
        example, context_features, sequence_features)
    input_ = seq['input']
    output = seq['output']
    return input_, output

if __name__ == '__main__':
    # STEP 1. -- generate a dataset.
    with tf.python_io.TFRecordWriter(PATH) as writer:
        for _ in xrange(NUM_EXAMPLES):
           record = encode(*generate_example())
           writer.write(record.SerializeToString())

    with tf.Session() as sess:
        queue = tf.train.string_input_producer([PATH])
        reader = tf.TFRecordReader()
        _, value = reader.read(queue)
        input_, output = decode(value)

        # HERE I AM STUCK!

        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        sess.run(tf.local_variables_initializer())
        sess.run(tf.global_variables_initializer())
        try:
            while True:
                # do something...
        except tf.errors.OutOfRangeError, e:
            coord.request_stop(e)
        finally:
            coord.request_stop()
            coord.join(threads)
        coord.request_stop()
        coord.join(threads)
</code></pre>

<p>Can anyone suggest me how to proceed?
Thanks in advance!</p>

<p>P.S. as a side request: any pointer about resources to better understand the input pipeline APIs of TensorFlow is appreciated.</p>
",2017-04-12 10:59:51,1861627,1753,https://stackoverflow.com/questions/43367697,Requesting (Additional) Documentation/Examples
43443205,Tensorflow tf.nn.conv2d clarification,"<p>In reading through the Tensorflow tutorial and API documentation, I do not understand how they defined the shape of the convolution input and filter arguments. The method is: <code>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)</code>, where the input is shape: <code>[batch, in_height, in_width, in_channels]</code> and the filter is shape: <code>[filter_height, filter_width, in_channels, out_channels]</code>. If anyone could shed light on how to properly define the ""in_channel"" and ""out_channel"" sizes, that would be very helpful. </p>
",2017-04-16 23:22:18,6749990,25,https://stackoverflow.com/questions/43443205,Documentation Ambiguity
43460838,tensorflow tfrecord storage for large datasets,"<p>I'm trying to understand the ""proper"" method of storage for large datasets for tensorflow ingestion. The documentation seems relatively clear that no matter what, tfrecord files are preferred. Large is a subjective measure, but the examples below are randomly generated regression datasets from sklearn.datasets.make_regression() of 10,000 rows and between 1 and 5,000 features, all float64.</p>

<p>I've experimented with two different methods of writing tfrecord files with dramatically different performance.</p>

<p>For numpy arrays, <code>X</code>, <code>y</code> (X.shape=(10000, n_features), y.shape=(10000,)</p>

<h2><code>tf.train.Example</code> with per-feature <code>tf.train.Features</code></h2>

<p>I construct a tf.train.Example in the way that tensorflow developers seem to prefer, at least judging by tensorflow example code at <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py</a>. </p>

<p>For each observation or row in <code>X</code>, I create a dictionary keyed with feature names (f_0, f_1, ...) whose values are <code>tf.train.Feature</code> objects with the feature's observation data as a single element of its float_list.</p>

<pre><code>def _feature_dict_from_row(row):
    """"""
    Take row of length n+1 from 2-D ndarray and convert it to a dictionary of
    float features:

      {
        'f_0': row[0],
        'f_1': row[1],
        ...
        'f_n': row[n]
      }
    """"""
    def _float64_feature(feature):
        return tf.train.Feature(float_list=tf.train.FloatList(value=[feature]))

    features = { ""f_{:d}"".format(i): _float64_feature(value) for i, value in enumerate(row) }
    return features

def write_regression_data_to_tfrecord(X, y, filename):
    with tf.python_io.TFRecordWriter('{:s}'.format(filename)) as tfwriter:
        for row_index in range(X.shape[0]):
            features = _feature_dict_from_row(X[row_index])
            features['label'] = y[row_index]

            example = tf.train.Example(features=tf.train.Features(feature=features))
            tfwriter.write(example.SerializeToString())
</code></pre>

<h2><code>tf.train.Example</code> with one large <code>tf.train.Feature</code> containing all features</h2>

<p>I construct a dictionary with one feature (really two counting the label) whose value is a <code>tf.train.Feature</code> with the entire feature row in as its float_list</p>

<pre><code>def write_regression_data_to_tfrecord(X, y, filename, store_by_rows=True):
    with tf.python_io.TFRecordWriter('{:s}'.format(filename)) as tfwriter:
        for row_index in range(X.shape[0]):
            features = { 'f_0': tf.train.Feature(float_list=tf.train.FloatList(value=X[row_index])) }
            features['label'] = y[row_index]

            example = tf.train.Example(features=tf.train.Features(feature=features))
            tfwriter.write(example.SerializeToString())
</code></pre>

<p>As the number of features in the dataset grows, the second option gets considerably faster than the first, as shown in the following graph. <em>Note the log scale</em></p>

<p><strong>10,000 rows:</strong></p>

<p><img src=""https://i.stack.imgur.com/p4w9M.png"" alt=""graph""></p>

<p>It makes intuitive sense to me that creating 5,000 <code>tf.train.Feature</code> objects is significantly slower than creating one object with a float_list of 5,000 elements, but it's not clear that this is the ""intended"" method for feeding large numbers of features into a tensorflow model.</p>

<p>Is there something inherently wrong with doing this the faster way?</p>
",2017-04-17 22:47:02,306537,35,https://stackoverflow.com/questions/43460838,Documentation Replication on Other Examples
43567551,Tensorflow seed not working with LSTM model,"<p><strong>tf.set_random_seed() is not working and opt seed not found.</strong> <br>
For many parameters in the LSTM, it seems no opt seed found in the tf.nn.rnn_cell.BasicLSTMCell. Thus, for every time it produces different results. How to set the seed to produce the same results for running several times?</p>

<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.python.ops import rnn, rnn_cell 

if __name__ == '__main__':

np.random.seed(1234)


X = np.array(np.array(range(1,121)).reshape(4, 6, 5), dtype = float)

x0 = tf.placeholder(tf.float32, [4, 6, 5])
x = tf.reshape(x0, [-1, 5])
x = tf.split(0, 4, x)


with tf.variable_scope('lstm') as scope:

    lstm = tf.nn.rnn_cell.BasicLSTMCell(5, state_is_tuple = True)   

    outputs, states = tf.nn.rnn(lstm, x, dtype = tf.float32)

    scope.reuse_variables()

    outputs2, states2 = tf.nn.dynamic_rnn(lstm, x0, dtype=tf.float32,time_major = True)

    outputs3, states3 = tf.nn.rnn(lstm, x, dtype=tf.float32)

print(outputs3)   

with tf.Session() as sess:              

    tf.set_random_seed(1)

    init = tf.initialize_all_variables()
    sess.run(init)

    for var in tf.trainable_variables():
        print var.name 

    for i in range(3):
        result1, result2, result3 = sess.run([outputs, outputs2, outputs3], feed_dict = {x0: X})

        print result1
        print '---------------------------------------'

        print result2
        print '---------------------------------------'

        print result3
        print '---------------------------------------'
</code></pre>
",2017-04-23 04:59:22,7907993,11,https://stackoverflow.com/questions/43567551,Documentation Replication on Other Examples
43916019,Control dependencies and order of evaluation,"<p>Please consider the following code: </p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

with tf.device(""gpu:0""):
    sess = tf.InteractiveSession()
    idx = tf.constant(0)
    # 10 iterations
    while_condition = lambda i: tf.less(i, tf.constant(10))        
    acc = tf.Variable(0, dtype=tf.float64)
    # the body of the while adds 1 to acc in each iteration
    def body_accumulator(i):
        mainOp = tf.assign_add(acc, 1.0)
        return tf.tuple([tf.add(i, 1)], control_inputs=[mainOp])
    whileOp = tf.while_loop(while_condition, body_accumulator, [idx])

    # My idea: return acc after evaluating whileOp, whose code modifies acc
    def f(dummy):
        with tf.control_dependencies([whileOp]):
            # with return tf.identity(acc) it works
            return acc
    def g():
        return acc

    sess.run(tf.global_variables_initializer())
    print('""g: return acc .eval()"" - this is the only time where I would expect 0')
    print(g().eval())
    print('f(dummy)')
    print(f(1).eval())
    print('whileOp.eval()')
    print(whileOp.eval())
    print('acc value:')
    print(acc.eval())
    print('""g: return acc .eval()""')
    print(g().eval())
</code></pre>

<p>The output is:</p>

<pre><code>""g: return acc .eval()"" - this is the only time where I would expect 0
0.0
f(dummy)
0.0
whileOp.eval()
10
acc value:
10.0
""g: return acc .eval()""
10.0
</code></pre>

<p>My question is:</p>

<p>why does <code>f(1).eval()</code> return 0 even if there is a control dependency on the <code>whileOp</code> that modifies the returned variable <code>acc</code>?</p>

<p>After reading the documentation, I was expecting <code>whileOp</code> to be evaluated before returning acc. How should I write the function <code>f(.)</code> in order to force the evaluation of <code>whileOp</code>?</p>

<p>In <code>f(.)</code>, if I return <code>tf.identity(acc)</code> instead of <code>acc</code>, it works as I expect.</p>
",2017-05-11 12:52:40,774133,2966,https://stackoverflow.com/questions/43916019,Inadequate Examples
44093698,How does Tensorflow Batch Normalization work?,"<p>I'm using tensorflow batch normalization in my deep neural network successfully. I'm doing it the following way:</p>

<pre class=""lang-py prettyprint-override""><code>if apply_bn:
    with tf.variable_scope('bn'):
        beta = tf.Variable(tf.constant(0.0, shape=[out_size]), name='beta', trainable=True)
        gamma = tf.Variable(tf.constant(1.0, shape=[out_size]), name='gamma', trainable=True)
        batch_mean, batch_var = tf.nn.moments(z, [0], name='moments')
        ema = tf.train.ExponentialMovingAverage(decay=0.5)

        def mean_var_with_update():
            ema_apply_op = ema.apply([batch_mean, batch_var])
            with tf.control_dependencies([ema_apply_op]):
                return tf.identity(batch_mean), tf.identity(batch_var)

        mean, var = tf.cond(self.phase_train,
                            mean_var_with_update,
                            lambda: (ema.average(batch_mean), ema.average(batch_var)))

        self.z_prebn.append(z)
        z = tf.nn.batch_normalization(z, mean, var, beta, gamma, 1e-3)
        self.z.append(z)

        self.bn.append((mean, var, beta, gamma))
</code></pre>

<p>And it works fine both for training and testing phases.
However I encounter problems when I try to use the computed neural network parameters in my another project, where I need to compute all the matrix multiplications and stuff by myself. The problem is that I can't reproduce the behavior of the <code>tf.nn.batch_normalization</code> function:</p>

<pre class=""lang-py prettyprint-override""><code>feed_dict = {
    self.tf_x: np.array([range(self.x_cnt)]) / 100, 
    self.keep_prob: 1,
    self.phase_train: False
}

for i in range(len(self.z)):
    # print 0 layer's 1 value of arrays
    print(self.sess.run([
        self.z_prebn[i][0][1], # before bn
        self.bn[i][0][1],      # mean
        self.bn[i][1][1],      # var
        self.bn[i][2][1],      # offset
        self.bn[i][3][1],      # scale
        self.z[i][0][1],       # after bn
    ], feed_dict=feed_dict))
    # prints
    # [-0.077417567, -0.089603029, 0.000436493, -0.016652612, 1.0055743, 0.30664611]
</code></pre>

<p>According to the formula on the page <a href=""https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/nn/batch_normalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/nn/batch_normalization</a>:</p>

<pre><code>bn = scale * (x - mean) / (sqrt(var) + 1e-3) + offset
</code></pre>

<p>But as we can see, </p>

<pre><code>1.0055743 * (-0.077417567 - -0.089603029)/(0.000436493^0.5 + 1e-3) + -0.016652612
= 0.543057
</code></pre>

<p>Which differs from the value <code>0.30664611</code>, computed by Tensorflow itself. 
So what am I doing wrong here and why I can't just calculate batch normalized value myself? </p>

<p>Thanks in advance!</p>
",2017-05-21 06:05:56,2078632,21,https://stackoverflow.com/questions/44093698,Documentation Replication on Other Examples
44097181,Why MonitoredTrainingSession can not receive graph as an argument?,"<p>Why <code>tf.train.MonitoredTrainingSession</code> does not receive graph as an argument?</p>

<p><code>tf.Session</code> (and <code>tf.train.Supervisor</code>) can do that as below:</p>

<pre class=""lang-py prettyprint-override""><code>with tf.Graph().as_default() as g:
    # Build computation graph...

with tf.Session(graph=g) as sess:
    # Run operations...
</code></pre>

<p>Only the way of writing as below is recommended?</p>

<pre class=""lang-py prettyprint-override""><code>with tf.Graph().as_default() as g:
    # Build computation graph...

    with tf.train.MonitoredTrainingSession(...) as mon_sess:
        # Run operations...
</code></pre>
",2017-05-21 13:01:22,6472530,193,https://stackoverflow.com/questions/44097181,Documentation Replicability
44103457,Why tf. Variable's value does not change upon different calls in the same programe?,"<p>In the following code Why tf.Variable valur remains same when I print it twice. Since tf.truncate_normal produces random values so I expect that it should be different upon different calls?  </p>

<pre><code>`initial = tf.truncated_normal([2,3], mean=100.0, stddev = 10.0)
 output = tf.Variable(initial)
 sess = tf.InteractiveSession()
 sess.run(tf.initialize_all_variables())
 print output.eval()
 print output.eval()`
</code></pre>
",2017-05-22 01:36:52,7997184,67,https://stackoverflow.com/questions/44103457,Documentation Replicability
44123088,How tf.nn.softmax_cross_entropy_with_logits can compute softmax cross entropy in tensorflow?,"<p>tf.nn.softmax_cross_entropy_with_logits, Documentation says that it computes softmax cross entropy between logits and labels what does it mean? Is it not applying cross entropy loss function formula on it? Why documentation says that it computes sofmax cross entropy?</p>
",2017-05-22 22:32:25,7997184,67,https://stackoverflow.com/questions/44123088,Documentation Ambiguity
44339463,confusing situations when `tf.constant` not displayed in `tensorboard`?,"<p>Below is the working code where some <code>tf.constant</code> get displayed in <code>tensorboard</code>, some don't. </p>

<p>However, I have no idea why those don't get displayed. </p>

<p>Could anyone help me out here? Thanks</p>

<pre><code>import tensorflow as tf
import numpy as np
# tf.constant(value, dtype=None, shape=None,
# name='Const', verify_shape=False)


a = tf.constant([2, 2], name=""a"")
b = tf.constant([[0, 1], [2, 3]], name=""b"")
x = tf.add(a, b, name=""add"")
y = tf.multiply(a, b, name=""mul"")

# verify_shape=True, error if shape not match
# edge1 = tf.constant(2, dtype=None, shape=[2,2], name=""wrong_shape"", verify_shape=True)


# verify_shape=False, if shape not match, will add to match
edge2 = tf.constant(2, dtype=None, shape=[2,2], name=""edge2"", verify_shape=False)
# increase row by row, from left to right
edge3 = tf.constant([1,2,3,4], dtype=None, shape=[4,3], name=""edge3"", verify_shape=False)

# reassign works
edge2c = edge2
edge3c = edge3

edge4 = tf.constant(np.ones((2,2)), dtype=None, shape=None, name=""shape22"", verify_shape=False)
# increase row by row, from left to right
edge5 = tf.constant(np.ones((4,3)), dtype=None, shape=[4,3], name=""shape43"", verify_shape=False)


with tf.Session() as sess:
    writer = tf.summary.FileWriter('./log/01_tf', sess.graph)
    x, y = sess.run([x, y])
    sess.run(edge4)
    sess.run(edge5)
    sess.run(edge2c)
    sess.run(edge3c)

writer.close()
</code></pre>
",2017-06-03 01:43:50,4333609,1448,https://stackoverflow.com/questions/44339463,Documentation Replicability
44357675,Documentation on how to use tf.estimator in TensorFlow,"<p>I understand that we can write custom models and encapsulate it using tf.estimator. But I just can't seem to find any documentation with an example.</p>

<p>I know that you have to define your model inside a 'model_fn' but what exactly should I return from this function. Also am I supposed to put the the loss and the training step within the 'model_fn' or just the network.  How should I modify the code give below to make it work with tf.estimator. Would really appreciate some help.</p>

<pre><code>def test_model(features,labels):
    X = tf.placeholder(tf.float32,shape=(None,1),name=""Data_Input"")
    #Output
    Y = tf.placeholder(tf.float32,shape=(None,1),name=""Target_Labels"")
    W =  tf.Variable(tf.random_normal([0],stddev=stddev0)) 
    b = tf.Variable(tf.random_normal([0],stddev=stddev0))

    Ypredict = W*X + b
    return Ypredict

 estimator = tf.estimator.Estimator(model_fn = test_model)
</code></pre>
",2017-06-04 18:51:09,7656080,757,https://stackoverflow.com/questions/44357675,Documentation Replicability
44415901,tensorflow using tf.train.string_input_producer,"<p>I'm using tf.train.string_input_producer to read data from tfRecord file. I suppose it create a queue and pipeline and the data will automatically loaded and feed into my model. However, it stuck at the first batch, and show this exception:</p>

<blockquote>
  <p>FailedPreconditionError (see above for traceback): Attempting to use uninitialized value input_producer/limit_epochs/epochs</p>
</blockquote>

<p>my tfrecord was made by tf.train.SequenceExample, instead of tf.train.Example, which don't have clear documentation in the official guide.</p>

<p>here is code snapshot to reproduce my problem. (I believe my problem come from the queue initializing or sth. because it seems that the whole pipeline is hang up)</p>

<pre><code>from config.config import get_config

init = tf.global_variables_initializer()
config = get_config()

filename_queue = tf.train.string_input_producer(['data0.tfrecord,data1.tfrecord'], 5, capacity=16384)
reader = tf.TFRecordReader()

(keys, values) = reader.read_up_to(filename_queue, config.batch_size)

context_features = {
    ""seq_len"": tf.FixedLenFeature([1], dtype=tf.int64),
}
audio_features = {
    ""audio"": tf.FixedLenSequenceFeature([config.num_features], dtype=tf.float32),
    ""label"": tf.FixedLenSequenceFeature([config.num_classes], dtype=tf.float32)
}
audio_list = []
label_list = []
len_list = []

for i in range(config.batch_size):
    print(i)
    context, sequence = tf.parse_single_sequence_example(
        serialized=values[i],
        context_features=context_features,
        sequence_features=audio_features
    )
    audio = sequence['audio']
    label = sequence['label']
    # seq_len = context['seq_len'][0]
    seq_len = tf.shape(audio)[0]
    audio_list.append(audio)
    label_list.append(label)
    len_list.append(seq_len)

audio_tensor = tf.stack(audio_list)
label_tenor = tf.stack(label_list)
len_tensor = tf.stack(len_list)

with tf.Session() as sess:
    sess.run(init)

    threads = tf.train.start_queue_runners(sess=sess)
    for i in range(3):
        x, y, z = sess.run([audio_tensor, label_tenor, len_tensor])
        print(z)
</code></pre>
",2017-06-07 14:45:09,6861219,3011,https://stackoverflow.com/questions/44415901,Lack of Alternative Solutions/Documentation
44415901,tensorflow using tf.train.string_input_producer,"<p>I'm using tf.train.string_input_producer to read data from tfRecord file. I suppose it create a queue and pipeline and the data will automatically loaded and feed into my model. However, it stuck at the first batch, and show this exception:</p>

<blockquote>
  <p>FailedPreconditionError (see above for traceback): Attempting to use uninitialized value input_producer/limit_epochs/epochs</p>
</blockquote>

<p>my tfrecord was made by tf.train.SequenceExample, instead of tf.train.Example, which don't have clear documentation in the official guide.</p>

<p>here is code snapshot to reproduce my problem. (I believe my problem come from the queue initializing or sth. because it seems that the whole pipeline is hang up)</p>

<pre><code>from config.config import get_config

init = tf.global_variables_initializer()
config = get_config()

filename_queue = tf.train.string_input_producer(['data0.tfrecord,data1.tfrecord'], 5, capacity=16384)
reader = tf.TFRecordReader()

(keys, values) = reader.read_up_to(filename_queue, config.batch_size)

context_features = {
    ""seq_len"": tf.FixedLenFeature([1], dtype=tf.int64),
}
audio_features = {
    ""audio"": tf.FixedLenSequenceFeature([config.num_features], dtype=tf.float32),
    ""label"": tf.FixedLenSequenceFeature([config.num_classes], dtype=tf.float32)
}
audio_list = []
label_list = []
len_list = []

for i in range(config.batch_size):
    print(i)
    context, sequence = tf.parse_single_sequence_example(
        serialized=values[i],
        context_features=context_features,
        sequence_features=audio_features
    )
    audio = sequence['audio']
    label = sequence['label']
    # seq_len = context['seq_len'][0]
    seq_len = tf.shape(audio)[0]
    audio_list.append(audio)
    label_list.append(label)
    len_list.append(seq_len)

audio_tensor = tf.stack(audio_list)
label_tenor = tf.stack(label_list)
len_tensor = tf.stack(len_list)

with tf.Session() as sess:
    sess.run(init)

    threads = tf.train.start_queue_runners(sess=sess)
    for i in range(3):
        x, y, z = sess.run([audio_tensor, label_tenor, len_tensor])
        print(z)
</code></pre>
",2017-06-07 14:45:09,6861219,3011,https://stackoverflow.com/questions/44415901,Documentation Replicability
44690363,How to use tf.train.ExponentialMovingAverage in Android/IOS,"<p>I use <code>freeze_graph</code> to export my model to a file named <code>""frozen.pb""</code>. But Found that the accuracy of predictions on <code>frozen.pb</code> is very bad.</p>

<p>I know the problem maybe <code>MovingAverage</code> not included in <code>frozen.pb</code>.</p>

<p>When I use <code>model.ckpt</code> files to restore model for evaluating, if I call <code>tf.train.ExponentialMovingAverage(0.999)</code> , then the accuracy is good as expected, else the accuracy is bad.</p>

<p><strong>So How To export a binary model which performance is the same as the one restored from checkpoint files?</strong>  I want to use <code>"".pb""</code> files in Android Devices.</p>

<p><a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/train/moving_averages"" rel=""nofollow noreferrer"">The official document</a> doesn't mention this.</p>

<p>Thanks!!</p>

<p>Freeze Command:</p>

<pre><code>~/bazel-bin/tensorflow/python/tools/freeze_graph \
  --input_graph=./graph.pbtxt \
  --input_checkpoint=./model.ckpt-100000 \
  --output_graph=frozen.pb \
  --output_node_names=output  \
  --restore_op_name=save/restore_all \
  --clear_devices
</code></pre>

<p>Evaluate Code:</p>

<pre><code>... ...
logits = carc19.inference(images)
top_k = tf.nn.top_k(logits, k=10)

# Precision: 97%
# Restore the moving average version of the learned variables for eval.
variable_averages = tf.train.ExponentialMovingAverage(carc19.MOVING_AVERAGE_DECAY)
variables_to_restore = variable_averages.variables_to_restore()
for k in variables_to_restore.keys():
  print (k,variables_to_restore[k])
saver = tf.train.Saver(variables_to_restore)

# Precision: 84%
#saver = tf.train.Saver()

#model_path = '/tmp/carc19_train/model.ckpt-9801'
with tf.Session() as sess:
  saver.restore(sess, model_path)
... ...
</code></pre>
",2017-06-22 04:48:01,8058425,101,https://stackoverflow.com/questions/44690363,Lack of Alternative Solutions/Documentation
44707368,Batch variable length sequences in tensorflow,"<p>I am reading variable length input sequences from files as numpy arrays, each of size <code>[timesteps_i, feature_size]</code>, and store them in a Python list.</p>

<p>Passing this list as argument to <code>tf.train.batch</code> results in a list of the same length, containing Tensors of size <code>[batch_size, timesteps_i, feature_size]</code>. </p>

<pre><code>inputs_batch_padded = tf.train.batch(
                tensors=inputs_chunk,
                batch_size=batch_size,
                capacity=128,
                enqueue_many=False,
                dynamic_pad=True)
</code></pre>

<ol>
<li><p>How can I obtain an output list that is <code>batch_size</code> times shorter than the original list?</p></li>
<li><p>How can it be inferred the original length of the sequences for each batch that is being passed to a <code>feed_dict</code>? I am checking out the seq to seq library, and it requires a list of lengths for each batch.</p></li>
<li><p>Am I supposed to pass numpy arrays for <code>tensors</code>? The <code>dynamic_pad</code> argument allows a <code>None</code> for the variable length dimension, but this will be known in advance in my case.</p></li>
<li><p>How should I interpret the following line from the API doc:
""An input tensor with shape [x, y, z] will be output as a tensor with shape [batch_size, x, y, z]"" ?
Is the same input tensor being replicated <code>batch_size</code> times ?</p></li>
</ol>
",2017-06-22 18:57:39,3115923,934,https://stackoverflow.com/questions/44707368,Documentation Replicability
44753916,How to slice a part of tensor?,"<p>I want to slice [3.0 ,33.0].I have tried to access this slice by following code. I'm not so clear about tf.slice command. I'm not so clear about begin and size mentioned in documentaion about this command. Can someone please make it easy to understand.  </p>

<pre><code>batch = tf.constant([
  [#First image
    [[0.0,10.0],[1.0,11.0]],
    [[3.0,33.0],[4.0,44.0]]
  ],
  [#Second image
    [[5.0,55.0],[6.0,66.0]],
    [[7.0,77.0],[8.0,88.0]]
  ]
])
slice1 = tf.slice(batch,[0,0,0,0], [0,0,1,0]) 
sess = tf.InteractiveSEssion()
sess.run(tf.initialize_all_variables())
print slice1.eval()
</code></pre>
",2017-06-26 06:10:01,8214056,41,https://stackoverflow.com/questions/44753916,Documentation Ambiguity
44905344,tensorflow.ones_like on a SparseTensor,"<p>In tensorflow, I want to do tf.ones_like on a SparseTensor; however, it seems it only works for normal (dense) tensors. Do you know any function or workaround?</p>

<p>As an example, I want to go from [['aa','ab','ac'],['ba','bb', UND],['ca',UND,UND] to [[1,1,1],[1,1,UND],[1,UND,UND]], where UND = undefined.</p>

<p>Thanks!</p>
",2017-07-04 11:54:53,4189580,13484,https://stackoverflow.com/questions/44905344,Documentation Replicability
44936825,use variational_recurrent in tf.contrib.rnn.DropoutWrapper,"<p>In the api of <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"" rel=""nofollow noreferrer"">tf.contrib.rnn.DropoutWrapper</a>, I am trying to set <code>variational_recurrent=True</code>, in which case, input_size is mandatory. As explained, <code>input_size</code> is <code>TensorShape</code> objects containing the <strong>depth(s)</strong> of the input tensors. </p>

<p><strong>depth(s)</strong> is confusing, what is it please? Is it just the shape of the tensor as we can get by <code>tf.shape()</code>? Or the number of channels for the special case of images? But my input tensor is not an image.</p>

<p>And I don't understand why <code>dtype</code> is demanded when <code>variational_recurrent=True</code>.</p>

<p>Thanks!</p>
",2017-07-05 22:13:13,6005072,57,https://stackoverflow.com/questions/44936825,Documentation Ambiguity
45090843,Does sequence_length help performance of dynamic_rnn?,"<p>In <a href=""https://github.com/tensorflow/nmt"" rel=""nofollow noreferrer"">Google's recent nmt tutorial</a>, they say this: </p>

<blockquote>
  <p>Note that sentences have different lengths to avoid wasting computation, we tell dynamic_rnn the exact source sentence lengths through source_seqence_length</p>
</blockquote>

<p>with this code: 
<code>encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_emb_inp,
    sequence_length=source_seqence_length, time_major=True)
</code></p>

<p>However, I was reading <a href=""https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn.py"" rel=""nofollow noreferrer"">dynamic_rnn's documentation</a> and it says: </p>

<blockquote>
  <p>The parameter <code>sequence_length</code> is optional and is used to copy-through state
    and zero-out outputs when past a batch element's sequence length. So it's more
    for correctness than performance.</p>
</blockquote>

<p>I'm just wondering if sequence_length really helps performance of dynamic_rnn, e.g. they do some kind of dynamic bucketing? If they do, is there any place where I can read more about it? Thanks a lot.</p>
",2017-07-13 21:03:11,5029595,926,https://stackoverflow.com/questions/45090843,Requesting (Additional) Documentation/Examples
45115650,"How to find Tensorflow max value index, but the value is repeat","<p>A tensor array is:
array = [1, 1, 0, 1, 1, 0]</p>

<p>If I use tf.argmax(), its can find only the first index.
output => ""0""</p>

<p>But I want find the max value at last index.
output would be ""4""</p>
",2017-07-15 07:25:29,7625321,31,https://stackoverflow.com/questions/45115650,Documentation Replicability
45202404,TensorFlow Slim Pre-trained models Negative Dimensions,"<p>I've been trying to design a wrapper to use the pre-made tensorflow slim models for a custom dataset. the dataset is 1000 images of squares and triangles, 32x32 grayscale. They are organized as dataset/shapes/triangles/ and dataset/shapes/squares/. </p>

<p>Using the following code, I am able to train the inception_v2 model without errors. The tf.reshape will be replaced with the correct variable parameters later. The .tfrecords files are created using <a href=""https://github.com/tensorflow/models/blob/master/inception/inception/data/build_image_data.py"" rel=""nofollow noreferrer"">this</a> script from google that creates the records from the above mentioned dataset structure. </p>

<pre><code>graph = tf.Graph()
sess = tf.InteractiveSession(graph=graph)

with graph.as_default():
    name_dict, nClass = gen_dict(data_directory, path_to_labels_file)

    # associate the ""label"" and ""image"" objects with the corresponding features read from
    # a single example in the training data file
    label, image = getImage(""datasets/shapes/train-00000-of-00001"", height, width, nClass)

    # associate the ""label_batch"" and ""image_batch"" objects with a randomly selected batch---
    # of labels and images respectively
    imageBatch, labelBatch = tf.train.shuffle_batch(
        [image, label], batch_size=bsize,
        capacity=2000,
        min_after_dequeue=1000)

    with sess.as_default():
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)

        sess.run(tf.global_variables_initializer())

        batch_xs, batch_ys = sess.run([imageBatch, labelBatch])

        print('ran shuffle batch')
        print(tf.shape(batch_xs))
        print(tf.shape(batch_ys))
        # batch_xs = tf.expand_dims(batch_xs, 2)
        batch_xs = tf.reshape(batch_xs, [100, 32, 32, 1])
        print(tf.shape(batch_xs))
        logits, end_points = inception.inception_v2(batch_xs,
                                                    num_classes=2,
                                                    is_training=True)

        predictions = end_points['Predictions']
        logits = end_points['Logits']

        tf.losses.softmax_cross_entropy(batch_ys, logits)

        total_loss = slim.losses.get_total_loss()

        optimizer = tf.train.GradientDescentOptimizer(learning_rate=.001)

        train_tensor = slim.learning.create_train_op(total_loss, optimizer)

        slim.learning.train(train_tensor,
                            train_log_dir,
                            number_of_steps=1000)
</code></pre>

<p>The issue I'm having is with other models. Using inception_v1, with the same arguments, I get the following error:</p>

<pre><code>File ""model_test.py"", line 62, in &lt;module&gt;
    is_training=True)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/nets/inception_v1.py"", line 349, in inception_v1
    net, [7, 7], stride=1, scope='MaxPool_0a_7x7')
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args
    return func(*args, **current_args)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 131, in avg_pool2d
    outputs = layer.apply(inputs)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 492, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 441, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/layers/pooling.py"", line 276, in call
    data_format=utils.convert_data_format(self.data_format, 4))
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1741, in avg_pool
    name=name)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 48, in _avg_pool
    data_format=data_format, name=name)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2508, in create_op
    set_shapes_for_outputs(ret)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1873, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1823, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/home/chakicherla3/tf_slim_image_classification/models/slim/python/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Negative dimension size caused by subtracting 7 from 1 for 'InceptionV1/Logits/MaxPool_0a_7x7/AvgPool' (op: 'AvgPool') with input shapes: [100,1,1,1024].
</code></pre>

<p>I get a similar error using inception_v3. With vgg_16 and vgg_19, I get:</p>

<pre><code>ValueError: Negative dimension size caused by subtracting 7 from 1 for 'vgg_16/fc6/convolution' (op: 'Conv2D') with input shapes: [100,1,1,512], [7,7,512,4096].
</code></pre>

<p>Can anyone give insight into these errors? What could be the difference between inception_v1 and inception_v2 that would cause it to crash, and how are the inception models this different? I haven't tried this dataset with ResNet yet, but I suspect a similar error will happen with that as well.</p>

<p>For reference, this example code is based on the 'working example' provided with the tf slim documentation, located <a href=""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim#working-example-training-the-vgg16-model"" rel=""nofollow noreferrer"">here</a></p>

<p>The system it is running on is using Python 2.7.10 with Tensorflow-GPU 1.2.0. It's a Xeon system with 4 Nvidia Titan X GPUs, on Ubuntu 14.10.</p>

<p>Thanks! If you need any additional system configurations or the getImage function I can provide those as well!</p>
",2017-07-19 22:59:11,8309477,11,https://stackoverflow.com/questions/45202404,Documentation Replication on Other Examples
45217998,Tensorflow: Weighted sparse softmax with cross entropy loss,"<p>I am doing image segmentation using fully convolutional neural networks (link to the paper): <a href=""https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf"" rel=""nofollow noreferrer"">https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf</a></p>

<p>This can be considered as pixel classification (in the end each pixel is getting a label)</p>

<p>I am using the tf.nn.sparse_softmax_cross_entropy_with_logits loss function.</p>

<pre><code>loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,
                                                                      labels=tf.squeeze(annotation, squeeze_dims=[3]),
                                                                      name=""entropy""))) 
</code></pre>

<p>Everything is going well. However, I saw that one class occurs in the vast majority of pixels (95%+), call this class 0. Lets say that we have another three classes, 1, 2 and 3.</p>

<p>What would be the easiest way to put weights to the classes? Essentially, I would like to have very low weight for class 0 (like 0.1) compared to the other three classes who should have normal weight 1.</p>

<p>I know that this function exists: <a href=""https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy</a></p>

<p>It just looks to me that it does something totally different and I do not understand how the weights should have the same rank as labels. I mean, in my case, weights should be something like Tensor([0.1, 1, 1, 1]) so shape (4,) and rank 1, while labels have shape (batch_size, width, height) and so rank 3. Am I missing something?</p>

<p>The equivalent on PyTorch would be </p>

<pre><code>torch.nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100)
</code></pre>

<p>where weight is a torch tensor [0.1, 1, 1, 1]</p>

<p>Thanks!</p>
",2017-07-20 14:44:16,1549979,331,https://stackoverflow.com/questions/45217998,Documentation Ambiguity
45237900,Dynamic RNN padding and indexing to match ground truth,"<p>I am running an RNN (many-to-many). I have a different time dimension for each user. E.g. user 1 has 5-time stamps and user 2 has 8-time stamps, etc. I think the RNN accepts only tensors with constant dimensions, so I currently pad (not using tensorflow) the time dimension with zeros till it reaches the maximum time stamps (max_user_time) among all users in the batch. For example, if user #1 has 2 time stamps and 3 features I get a tensor with dimensions [1,2,3]:</p>

<pre><code>|1 2|
|2 5|
|6 3|
</code></pre>

<p>If user 3 in the batch has 3 time stamps, then we need to add paading such that user 1 has a tensor with dimensions [1,3,3]:</p>

<pre><code>|1 2 0|
|2 5 0|
|6 3 0|
</code></pre>

<p>The padding for each user will be of different length. </p>

<p>Is there a way to get this using tf.pad or something similar for all users at once? </p>

<p>After padding, I pass these tensors as input to the RNN and reshape the output:</p>

<pre><code>outputs,states=tf.nn.dynamic_rnn(lstm_cell,inputs=input
                                     ,dtype=tf.float32,sequence_length=max_batch)

reshape_out=tf.reshape(outputs,[-1,n_hidden])
</code></pre>

<p>For the sequence length parameter, I pass a vector with the timestamps for each user, so expecting a zero output if a user has passed its max time - according to <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">tf.dynamic_rnn</a> documentation. </p>

<p>So, I get from reshaping a tensor sized [batch_sizeXmax_user_time,n_hidden].</p>

<p>This is a bigger tensor than the ground truth tesnor, which is smaller and has rows for each user according to its timestamps. </p>

<p>Is there an easy way to use tensorflow to pick only the rows that are observed in order to calculate the loss? </p>
",2017-07-21 12:36:49,7764047,81,https://stackoverflow.com/questions/45237900,Documentation Replication on Other Examples
45290607,Tensorflow tf_strided_slice elaboration,"<p>I'm trying to understand how tf.strided_slice works. In order to do this, I've written the following code:</p>

<pre><code>import numpy as np
import tensorflow as tf

# parameters
record_size = 841

# create a random vector of 1682 integers in range [0.255]
content = np.random.randint(255,size=[1682])

depth_major = tf.reshape(
  tf.strided_slice(content, [0],
                   [record_size]),
                   [1, 29, 29])

depth_major1 = tf.reshape(
  tf.strided_slice(content, [record_size+1],
                   [2*record_size]),
                   [1, 29, 29])

# Initializing the variables
init = tf.global_variables_initializer()

with tf.Session as sess:
  sess.run(depth_major)
  print(""depth_major"", depth_major.shape)
</code></pre>

<p>When I execute the above example, I get the following error:</p>

<pre><code>ValueError: Cannot reshape a tensor with 840 elements to shape [1,29,29] (841 elements) for 'Reshape_1' (op: 'Reshape') with input shapes: [840], [3] and with input tensors computed as partial shapes: input[1] = [1,29,29].
</code></pre>

<p>I simply cannot understand why the number of elements is 840 since I start at [0] and end at [record_size]? </p>
",2017-07-24 21:46:34,8312790,33,https://stackoverflow.com/questions/45290607,Documentation Replicability
45313351,Tensorflow Depthwise Convolution Understanding,"<p>I'm currently trying to understand how Tensorflow's <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d"" rel=""nofollow noreferrer"">Depthwise Convolution</a> works. As far as I've understood, each channel in the input image is convolved with it's own set of filters, and then the results are concatenated. I'm going to stick with the parameter <code>depth_multiplier=1</code> for the sake of simplicity in the remainder, so <code>n_inputchannels == n_outputchannels</code>. </p>

<p>So in theory, I could split up the depthwise convolution into <code>N</code> individual, regular <code>Conv2Ds</code>, correct? Why does the following code produce different results then I am wondering - is this a precision issue? I'm following the documentation for the ordering <code>[filter_height, filter_width, in_channels, 1]</code> for the depthwise convolution filters, and <code>[filter_height, filter_width, in_channels, out_channels]</code> for the regular convolutions, and <code>NHWC</code> data format.</p>

<pre><code>import tensorflow as tf
import numpy as np
import random

width = 128
height = 128
channels = 32
kernel_width = 3
kernel_height = 3

with tf.Session() as sess:

    _input = np.float32(np.random.rand(1, height, width, channels))
    _weights =  np.float32(np.random.rand(kernel_height, kernel_width, channels, 1))

    _input_ph = tf.placeholder(tf.float32, shape=(1, height, width, channels))
    _weights_pc = tf.placeholder(tf.float32, shape=(kernel_height, kernel_width, channels, 1))

    feed = { _input_ph: _input, _weights_pc : _weights }

    result = tf.nn.depthwise_conv2d(_input_ph, _weights_pc, [1,1,1,1], 'SAME')

    individual_results = []
    for i in range(channels):
        individual_results.append(tf.nn.conv2d(tf.expand_dims(_input_ph[:,:,:,i],axis=3), tf.expand_dims(_weights_pc[:,:,i,:],axis=3), [1,1,1,1], 'SAME'))

    depth_result = sess.run(result, feed_dict=feed)
    concat_result = sess.run(tf.concat(individual_results, axis=3), feed_dict=feed)

    channel_diff = 0.0
    for i in range(channels):
        channel_diff += np.sum(depth_result[:,:,:,i]-concat_result[:,:,:,i])

    print(channel_diff)
</code></pre>

<p>Here I'm computing first the normal <code>tf.nn.depthwise_conv2d</code> and then slice the input and weights accordingly and do <code>tf.nn.conv2d</code>s individually. For these parameters I get about <code>1e-5</code> difference, but that tends to get higher when I increase the number of channels.</p>

<p>I would be really glad if someone could explain to me what's going on :) 
Thanks!</p>
",2017-07-25 20:57:23,3362759,945,https://stackoverflow.com/questions/45313351,Documentation Replication on Other Examples
45553038,How to compile custom ops in tensorflow without having to dynamically import them in python?,"<p>I checked through tensorflow documentation and they seem to only give information about compiling a custom op through a bazel rule:</p>

<pre><code>load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")

tf_custom_op_library(
    name = ""zero_out.so"",
    srcs = [""zero_out.cc""],
)
</code></pre>

<p>Once bazel builds it, you get a zero_out.so file which you can import into python like below:</p>

<pre><code>import tensorflow as tf
zero_out_module = tf.load_op_library('./zero_out.so')
</code></pre>

<p>Is there anyway you can link custom_ops during the bazel build of tensorflow so that you don't need to manually import custom ops through tf.load_op_library?</p>
",2017-08-07 18:01:17,7922336,223,https://stackoverflow.com/questions/45553038,Documentation Completeness
45553280,TensorArray Initialization from another tensor,"<p>What is the right way to initialize a tensorarray from another tensor in tensorflow. </p>

<p>Suppose I have a tensor</p>

<pre><code>T1 

TensorArr = tf.TensorArray(tf.int32, 1, dynamic_size=True)
</code></pre>

<p>What is way to say that this tensorarray depends on T1?  Looking at the <a href=""https://www.tensorflow.org/api_docs/python/tf/TensorArray"" rel=""nofollow noreferrer"">documentation</a> I cant figure out how to initialize this. </p>

<p>Correct me if my understanding is wrong, T1 is a nested tensor and I want to loop over a dimension using tf.while_loop and hence I want to initialize the TensorArray with it. </p>
",2017-08-07 18:15:21,4040998,3340,https://stackoverflow.com/questions/45553280,Documentation Replication on Other Examples
45634450,What are the advantages of using tf.train.SequenceExample over tf.train.Example for variable length features?,"<p>Recently I read <a href=""http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features"" rel=""noreferrer"">this</a> guide on undocumented featuers in TensorFlow, as I needed to pass variable length sequences as input. However, I found the protocol for <code>tf.train.SequenceExample</code> relatively confusing (especially due to lack of documentation), and managed to build an input pipe using <code>tf.train.Example</code> just fine instead.</p>

<p>Are there any advantages to using <code>tf.train.SequenceExample</code>? Using the standard example protocol when there is a dedicated one for variable length sequences seems like a cheat, but does it bear any consequence?</p>
",2017-08-11 11:46:08,7000919,768,https://stackoverflow.com/questions/45634450,Documentation Replicability
45678931,tensorflow input pipeline returns multiple values,"<p>I'm trying to make an input pipeline in tensorflow for image classification, therefore I want to make batches of images and corresponding labels. The Tensorflow document suggests that we can use tf.train.batch to make batches of inputs:</p>

<pre><code>train_batch, train_label_batch = tf.train.batch(
[train_image, train_image_label],
batch_size=batch_size,
num_threads=1,
capacity=10*batch_size,
enqueue_many=False,
shapes=[[224,224,3], [len(labels),]],
allow_smaller_final_batch=True
)
</code></pre>

<p>However, I'm thinking would it be a problem if I feed in the graph like this:</p>

<pre><code>cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_label_batch, logits=Model(train_batch)))
</code></pre>

<p>The question is does the operation in the cost function dequeues images and their corresponding labels, or it returns them separately? Therefore causing the training with wrong images and labels.</p>
",2017-08-14 16:26:51,8075619,187,https://stackoverflow.com/questions/45678931,Documentation Replicability
45698621,TensorFlow embedding_rnn_decoder 'Tensor' object is not iterable,"<p>I am trying to construct a custom estimator for my ML Engine package and I seem to be having trouble properly constructing my decoder input sequence in the correct format.  Consider the following where label1, label2 is supposed to be a sequence of labels.</p>

<pre><code>label1, label2 = tf.decode_csv(rows, record_defaults=[[""""], [""""]])
labels = tf.stack([label1, label2], axis=1)
label_index = tf.contrib.lookup.index_table_from_file(
    vocabulary_file = label_file)
label_idx = label_index.lookup(labels)
features = dict(zip(['decoder_input'], [label_idx]))
</code></pre>

<p>these ""features"" are then passed as the decoder input as below.  When I go to use the decoder_input as input into my custom estimator, I run into the an error 'TypeError: 'Tensor' object is not iterable.' here:</p>

<pre><code>outputs, state = tf.contrib.legacy_seq2seq.embedding_rnn_decoder(
    decoder_inputs = features['decoder_input'],
    initial_state = curr_layer,
    cell = tf.contrib.rnn.GRUCell(hidden_units),
    num_symbols = n_labels,
    embedding_size = embedding_dims, # should not be hard-coded
    feed_previous = False)
</code></pre>

<p>The full stack trace (below) suggests that the portion of code causing the issue is for <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py#L296"" rel=""nofollow noreferrer"">'for i in decoder_inputs' from line 296</a> so it seems pretty clear to me that the issue is in how I construct my decoder_input in the input_fn(). However, I can't seem to figure out how to make the Tensor object an iterable list of sequences.</p>

<p>Stacktrace:</p>

<pre><code>File ""/Users/user/anaconda/envs/tensorflow-

  cloud/lib/python2.7/sitepackages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py"", line 296, in embedding_rnn_decoder
    for i in decoder_inputs)
  File ""/Users/user/anaconda/envs/tensorflow-cloud/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 541, in __iter__
    raise TypeError(""'Tensor' object is not iterable."")
TypeError: 'Tensor' object is not iterable.
</code></pre>

<p>Can anybody help spot how I should correctly format my labels so that they are iterable? The documentation says that decoder_inputs should be ""A list of 1D batch-sized int32 Tensors (decoder inputs)."" so I thought that by staIs there a more appropriate way to generate the sequence of labels than tf.stack()?</p>
",2017-08-15 17:53:34,4086968,2031,https://stackoverflow.com/questions/45698621,Documentation Replication on Other Examples
45761087,Tensorflow 1.3.0 NameError: name 'LinearRegressor' is not defined,"<p>I am following the ""get started"" instruction on the official Website.
<a href=""https://www.tensorflow.org/get_started/"" rel=""nofollow noreferrer"">https://www.tensorflow.org/get_started/</a></p>

<p>I have tried both virtualenv and pip native installment method. And tensorflow can be imported at this time.</p>

<p>But when the tf.estimator.LinearRegressor can not be used. Do I need to link some kind of path to make the APIs started to work?</p>

<p>The error is:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/binwang/Documents/Learning_Tensorflow/3_Getting_Started_With_Tensorflow.py"", line 13, in &lt;module&gt;
    estimator = LinearRegressor(feature_columns=feature_columns)
NameError: name 'LinearRegressor' is not defined
</code></pre>

<p>The code is:</p>

<pre><code>import tensorflow as tf
# NumPy is often used to load, manipulate and preprocess data.
import numpy as np

# Declare list of features. We only have one numeric feature. There are many
# other types of columns that are more complicated and useful.
feature_columns = [tf.feature_column.numeric_column(""x"", shape=[1])]

# An estimator is the front end to invoke training (fitting) and evaluation
# (inference). There are many predefined types like linear regression,
# linear classification, and many neural network classifiers and regressors.
# The following code provides an estimator that does linear regression.
estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)

# TensorFlow provides many helper methods to read and set up data sets.
# Here we use two data sets: one for training and one for evaluation
# We have to tell the function how many batches
# of data (num_epochs) we want and how big each batch should be.
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.estimator.inputs.numpy_input_fn(
    {""x"": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    {""x"": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    {""x"": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)

# We can invoke 1000 training steps by invoking the  method and passing the
# training data set.
estimator.train(input_fn=input_fn, steps=1000)

# Here we evaluate how well our model did.
train_metrics = estimator.evaluate(input_fn=train_input_fn)
eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
print(""train metrics: %r""% train_metrics)
print(""eval metrics: %r""% eval_metrics)
</code></pre>

<p>Thanks!</p>
",2017-08-18 16:23:16,8484738,19,https://stackoverflow.com/questions/45761087,Documentation Replication on Other Examples
45784815,How best to implement a matrix mask operation in tensorflow?,"<p>I had a case where I needed to fill some holes (missing data) in an image processing application in tensorflow. The 'holes' are easy to locate as they are zeros and the good data is not zeros. I wanted to fill the holes with random data. This is quite easy to do using python numpy but doing it in tensorflow requires some work. I came up with a solution and wanted to see if there is a better or more efficient way to do the same thing. I understand that tensorflow does not yet support the more advanced numpy type indexing yet but there is a function tf.gather_nd() that seems promising for this. However, I could not tell from the documentation how to us it for what I wanted to do. I would appreciate answers that improve on what I did or especially if someone can show me how to do it using tf.gather_nd(). Also, tf.boolean_mask() does not work for what I am  trying to do because it does not allow you to use the output as an index.  In python what I am trying to do:</p>

<pre><code>a = np.ones((2,2))
a[0,0]=a[0,1] = 0
mask = a == 0
a[mask] = np.random.random_sample(a.shape)[mask]
print('new a = ', a)
</code></pre>

<p>What I ended up doing in Tensorflow to achieve same thing (skipping filling the array steps)</p>

<pre><code>zeros = tf.zeros(tf.shape(a))  
mask = tf.greater(a,zeros)
mask_n = tf.equal(a,zeros)
mask = tf.cast(mask,tf.float32)
mask_n = tf.cast(mask_n,tf.float32
r = tf.random_uniform(tf.shape(a),minval = 0.0,maxval=1.0,dtype=tf.float32)
r_add = tf.multiply(mask_n,r)
targets = tf.add(tf.multiply(mask,a),r_add)
</code></pre>
",2017-08-20 17:14:28,7447161,867,https://stackoverflow.com/questions/45784815,Inadequate Examples
45869131,All Tensorflow outputs are nan,"<pre><code>import tensorflow as tf

# Model parameters
A = tf.Variable([.3], dtype=tf.float32)
W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
q_model = A * (x**2) + W * x + b
y = tf.placeholder(tf.float32)

# loss
loss = tf.reduce_sum(tf.square(q_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)

# training data
x_train = [0, 1, 2, 3, 4]
y_train = [0, 1, 4, 9, 16]
# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
  sess.run(train, {x: x_train, y: y_train})

# evaluate training accuracy
curr_A, curr_W, curr_b, curr_loss = sess.run([A, W, b, loss], {x: x_train, y: y_train})
print(""A: %s W: %s b: %s loss: %s""%(curr_A, curr_W, curr_b, curr_loss))
</code></pre>

<p>On their website, tf gives model code to perform linear regression. However, I wanted to play around to see if I could also get it to do quadratic regression. To do so, I added a tf.Variable A, put it into the model and then modified the output to tell me what it got as the value.</p>

<p>Here are the results:</p>

<pre><code>A: [ nan] W: [ nan] b: [ nan] loss: nan
</code></pre>

<p>What do y'all think is the issue here? Is it between the chair and the keyboard?</p>
",2017-08-24 19:00:24,5183434,694,https://stackoverflow.com/questions/45869131,Documentation Replication on Other Examples
45900233,tf.slice and tf.strided_slice,"<p>trying to comprehend tensorflow strided_slice and slice</p>

<pre><code>x = tf.constant(np.array(   [[[111, 112, 113], [121, 122, 123]],
                            [[211, 212, 213], [221, 222, 223]],
                            [[311, 312, 313], [321, 322, 323]]]))
with tf.Session() as sess:
    print(""tf.shape ------------------"")
    print(sess.run(tf.shape(x)))
    print(""tf.slice ------------------------"")
    print(sess.run((tf.slice(x, [1, 0, 0], [2, 1, 3]) )))
    print(""tf.strided_slice ------------------------"")
    print(sess.run(tf.strided_slice(x, [1, 0, 0], [2, 1, 3], [1, 1, 1])))
    print(sess.run(tf.strided_slice(x, [1, -1, 0], [2, -3, 3], [1, -1, 1])))
    print(sess.run(x[1,-1,0]))
    print(sess.run(x[2,-3,3]))
</code></pre>

<p>output</p>

<pre><code>tf.shape ------------------
[3 2 3]
tf.slice ------------------------
[[[211 212 213]]

 [[311 312 313]]]
tf.strided_slice ------------------------
[[[211 212 213]]]
[[[221 222 223]
  [211 212 213]]]
221
ValueError: slice index -1 of dimension 1 out of bounds. for 'strided_slice_8' (op: 'StridedSlice') with input shapes: [3,2,3], [3], [3], [3] and with computed input tensors: input[1] = &lt;2 -3 3&gt;, input[2] = &lt;3 -2 4&gt;, input[3] = &lt;1 1 1&gt;.
</code></pre>

<p>for tf.slice i understand we have to mentions slice sizes in each dimension and hence out of range values makes sense. but in strided slice the end is a tensor index in the tensor itself, how come  out of size value is valid. </p>

<p>Example is taken from
<a href=""https://www.tensorflow.org/api_docs/python/tf/strided_slice"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/strided_slice</a></p>

<p>Trying to implement folding layer part from paper <a href=""https://arxiv.org/abs/1404.2188"" rel=""nofollow noreferrer"">A Convolutional Neural Network for Modelling Sentences</a></p>

<blockquote>
  <p>In the formulation of the network so far, feature detectors applied to
  an individual row of the sentence matrix s can have many orders and
  create complex dependencies across the same rows in multiple feature
  maps. Feature detectors in different rows, however, are independent of
  each other until the top fully connected layer. Full dependence
  between different rows could be achieved by making M in Eq. 5 a full
  matrix instead of a sparse matrix of diagonals. Here we explore a
  simpler method called folding that does not introduce any additional
  parameters. After a convolutional layer and before (dynamic) k-max
  pooling, <strong>one just sums every two rows in a feature map component-wise</strong>.
  For a map of d rows, folding returns a map of d/2 rows, thus halving
  the size of the representation. With a folding layer, a feature
  detector of the i-th order depends now on two rows of feature values
  in the lower maps of order i − 1. This ends the description of the
  DCNN.</p>
</blockquote>
",2017-08-26 22:39:57,471384,1635,https://stackoverflow.com/questions/45900233,Documentation Replicability
46298583,Tensorflow embeddings,"<p>I know what embeddings are and how they are trained. Precisely, while referring to the tensorflow's documentation, I came across two different articles. I wish to know what exactly is the difference between them.</p>

<p>link 1: <a href=""https://www.tensorflow.org/tutorials/word2vec#building_the_graph"" rel=""nofollow noreferrer"">Tensorflow | Vector Representations of words</a></p>

<p>In the first tutorial, they have explicitly trained embeddings on a specific dataset. There is a distinct session run to train those embeddings. I can then later on save the learnt embeddings as a numpy object and use the </p>

<p><code>tf.nn.embedding_lookup()</code> function while training an LSTM network.</p>

<p>link 2: <a href=""https://www.tensorflow.org/programmers_guide/embedding"" rel=""nofollow noreferrer"">Tensorflow | Embeddings</a></p>

<p>In this second article however, I couldn't understand what is happening. </p>

<pre><code>word_embeddings = tf.get_variable(“word_embeddings”,
[vocabulary_size, embedding_size])
embedded_word_ids = tf.gather(word_embeddings, word_ids)
</code></pre>

<p>This is given under the training embeddings sections. My doubt is: does the gather function train the embeddings automatically? I am not sure since this op ran very fast on my pc.</p>

<p>Generally: What is the right way to convert words into vectors (link1 or link2) in tensorflow for training a seq2seq model? Also, how to train the embeddings for a seq2seq dataset, since the data is in the form of separate sequences for my task unlike (a continuous sequence of words refer: link 1 dataset) </p>
",2017-09-19 10:53:19,4341842,426,https://stackoverflow.com/questions/46298583,Documentation Replication on Other Examples
46372554,When feeding a dictionary to a tensorflow function I get Why do I get TypeError: unhashable type: 'numpy.ndarray',"<p>I am working on a Tensor Flow Coursera Course and I dont understand why I am getting a type mismatch. </p>

<p>This is the function I am defining:</p>

<pre><code>def one_hot_matrix(labels, C):
    """"""
    Creates a matrix where the i-th row corresponds to the ith class number and the jth column
                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) 
                     will be 1. 

Arguments:
labels -- vector containing the labels 
C -- number of classes, the depth of the one hot dimension

Returns: 
one_hot -- one hot matrix
""""""

### START CODE HERE ###

# Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)
C = tf.constant(C, name=""C"")
#labels =tf.placeholder(labels, name=""labels"")

# Use tf.one_hot, be careful with the axis (approx. 1 line)
one_hot_matrix = tf.one_hot(indices=labels, depth=C, axis=0)

# Create the session (approx. 1 line)
sess = tf.Session()

# Run the session (approx. 1 line)
one_hot = sess.run(one_hot_matrix, feed_dict={labels:labels, C:C})

# Close the session (approx. 1 line). See method 1 above.
sess.close()

### END CODE HERE ###

return one_hot
</code></pre>

<p>And when running this: </p>

<pre><code>labels = np.array([1,2,3,0,2,1])
one_hot = one_hot_matrix(labels, C = 4)
print (""one_hot = "" + str(one_hot))
</code></pre>

<p>I get this type error:</p>

<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-113-2b9d0290645f&gt; in &lt;module&gt;()
      1 labels = np.array([1,2,3,0,2,1])
----&gt; 2 one_hot = one_hot_matrix(labels, C = 4)
      3 print (""one_hot = "" + str(one_hot))

&lt;ipython-input-112-f9f17c86d0ba&gt; in one_hot_matrix(labels, C)
     28 
     29     # Run the session (approx. 1 line)
---&gt; 30     one_hot = sess.run(one_hot_matrix, feed_dict={labels:labels, C:C})
     31 
     32     # Close the session (approx. 1 line). See method 1 above.

TypeError: unhashable type: 'numpy.ndarray'ter code here
</code></pre>

<p>I checked the Tensorflow documentation for tf.one_hot and there shouldn't be a problem with np.arrays.</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/one_hot"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/one_hot</a></p>
",2017-09-22 20:12:39,5462568,323,https://stackoverflow.com/questions/46372554,Documentation Ambiguity
46381790,How does TensorFlow handle none shape?,"<p>I'm trying to implement a simple computational graph framework and test it with simple neural network, mainly by learning from TensorFlow. Now I would want to be clear how does TensorFlow handle none shape tensors.</p>

<p>In <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/multilayer_perceptron.py"" rel=""nofollow noreferrer"">this example</a>, <code>X</code> has shape <code>[None, n_input]</code>, <code>weights['h1']</code> has shape <code>[n_input, n_hidden_1]</code>, and <code>biases['b1']</code> has shape <code>[n_hidden_1]</code>. When it tries to do this: <code>layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])</code>, <code>tf.matmul(x, weights['h1'])</code> should have shape <code>[None, n_hidden_1]</code>, and how exactly does TensorFlow add it with <code>biases['b1']</code>? Based on the <a href=""https://www.tensorflow.org/api_docs/python/tf/add"" rel=""nofollow noreferrer"">documentation</a>, <code>tf.add</code> only works when the 2 operands have the same shape. If we run with a batch of size 10, <code>tf.matmul(x, weights['h1'])</code> will have shape <code>[10, n_hidden_1]</code>, and it shouldn't be able to be added with <code>biases['b1']</code>.</p>
",2017-09-23 16:25:16,7420679,41,https://stackoverflow.com/questions/46381790,Documentation Replication on Other Examples
46386211,When would I want to set a stride in the batch or channel dimension for TensorFlow convolution?,"<p>Tensor flow implements a basic convolution operation with <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""nofollow noreferrer"" title=""tf.nn.conv2d"">tf.nn.conv2d</a>.</p>
<p>I am specifically interested in the &quot;strides&quot; parameter, which lets you set the stride of the convolution filter -- how far across the image you shift the filter each time.</p>
<p>The example given in <a href=""https://www.tensorflow.org/get_started/mnist/pros"" rel=""nofollow noreferrer"">one of the early tutorials</a>, with an image stride of 1 in each direction, is</p>
<pre><code>def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
</code></pre>
<p>The strides array is explained more in the linked docs:</p>
<blockquote>
<p>In detail, with the default NHWC format...</p>
<p>Must have strides[0] = strides[3] = 1. For the most common case of the same horizontal and vertices strides, strides = [1, stride, stride, 1].</p>
</blockquote>
<p>Note the order of &quot;strides&quot; matches the order of inputs: <code>[batch, height, width, channels]</code> in the NHWC format.</p>
<p>Obviously having a stride of not 1 for <code>batch</code> and <code>channels</code> wouldn't make sense, right? (your filter should always go across every batch and every channel)</p>
<p>But why is it even an option to put something other than 1 in <code>strides[0]</code> and <code>strides[3]</code>, then? (where it being an &quot;option&quot; is in regards to the fact that you could put something other than 1 in the python array you pass in, disregarding the documentation quote above)</p>
<p>Is there a situation where I would have a non-one stride for the <code>batch</code> or <code>channels</code> dimension, e.g.</p>
<pre><code>tf.nn.conv2d(x, W, strides=[2, 1, 1, 2], padding='SAME')
</code></pre>
<p>If so, what would that example even mean in terms of the convolution operation?</p>
",2017-09-24 03:10:38,2343795,1729,https://stackoverflow.com/questions/46386211,Requesting (Additional) Documentation/Examples
46394659,Does tf.histogram_fixed_width() support back propagation?,"<p>I want to use the histogram of the output from a CNN to compute the loss. I am wondering whether <code>tf.histogram_fixed_width()</code> supports the gradient to flow back to its former layer. Only it works, I can add a loss layer after calculating the histogram.</p>
",2017-09-24 20:42:08,8666472,31,https://stackoverflow.com/questions/46394659,Documentation Replicability
46484373,Return a tf.Variable from an Estimator,"<p>I have an Tensorflow Estimator defined by a model function in the usual way. 
I want to determine which of my (zscore normalised) inputs are significant to the result, and which can be eliminated.   I have altered the model to introduce two changes: </p>

<p>(1) A new layer <code>weight_layer</code> which is randomly intialized and elementwise multiplied with <code>input_layer</code>. </p>

<pre><code>weight_layer   =  tf.Variable(tf.random_normal([1, inputs_n], 0.5, 1))
weighted_input = tf.multiply(weight_layer, input_layer)
first_hidden_layer =  tf.layers.dense(weighted_input,  
                                      int(inputs_n), 
                                      activation=tf.nn.relu, 
                                      name='dense1') 
</code></pre>

<p>(2) A penalty <code>sparsity</code> which is added to the loss function to penalize the loss by the sum of the weights in <code>weight_layer</code></p>

<pre><code> sparsity = tf.reduce_sum(weight_layer)    
 loss = tf.losses.mean_squared_error(labels, predictions) + (1000*sparsity)
</code></pre>

<p>The trouble comes at prediction time, when I try to return the values of <code>weight_layer</code>, as follows: </p>

<pre><code>if mode == tf.estimator.ModeKeys.PREDICT:
   return tf.estimator.EstimatorSpec( mode=mode, 
                                      predictions={
                                       ""predictions"": predictions, 
                                       ""sparsity"" : weight_layer})
</code></pre>

<p>I get the following error: </p>

<pre><code> TypeError: predictions[sparsity] must be Tensor, 
 given: &lt;tf.Variable 'Model/Variable:0' shape=(1, 275) dtype=float32_ref&gt;  
</code></pre>

<p>This seems odd, since although predictions[sparsity] is not a Tensor, it is a tf.Variable, and the tf.Variable documentation suggests I can treat a tf.Variable 'like a normal tf.Tensor'.  </p>

<p>How can I fix the above to return the weight_layer, or if I there is a more fundamental mistake, please recommend a way for me to determine which of my input variables are significant. </p>
",2017-09-29 08:02:48,1536634,36,https://stackoverflow.com/questions/46484373,Documentation Replication on Other Examples
46650905,Got stuck when using hdfs for logdirs of MonitoredTrainingSession of distributed tensorflow,"<p>I am using between-graph replica with hdfs, but my program got stuck when the parameter of MonitoredTrainingSession-logdirs is set to hdfs://default/mypath4train_logs. The code is like:</p>

<pre><code>with tf.train.MonitoredTrainingSession(master=server.target,
                                           is_chief=(worker_index==0),
                                           checkpoint_dir=""hdfs://default/mypath4train_logs/train_logs"",
                                           config=sess_config) as sess:
</code></pre>

<p>I have read the documentation on tensorflow guide <a href=""https://www.tensorflow.org/deploy/hadoop"" rel=""nofollow noreferrer"">how to run TensorFlow on hadoop</a>, and done whatever it says, in which, most importantly, the paths to libjvm.so and libhdfs.so have been appended to LD_LIBRARY_PATH.</p>

<p>However, the chief worker's log stopped at:</p>

<pre><code>INFO:tensorflow:Create CheckpointSaverHook.
2017-10-09 23:34:55,575 Create CheckpointSaverHook.
</code></pre>

<p>I debugged it, it seems that the program got stuck on tensorflow::FileSystem::RecursivelyCreateDir, yet without any error. Here's exactly how I debugged it:</p>

<pre><code>(gdb) next
Single stepping until exit from function _ZNSsC1ERKSs@plt,
which has no line number information.
0x00007fc181431260 in std::basic_string&lt;char, std::char_traits&lt;char&gt;, 
std::allocator&lt;char&gt; &gt;::basic_string(std::basic_string&lt;char, 
std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) ()
from /usr/lib64/libstdc++.so.6
(gdb) next
Single stepping until exit from function _ZNSsC2ERKSs,
which has no line number information.
0x00007fc1a1aeddcd in 
tensorflow::HadoopFileSystem::Connect(tensorflow::StringPiece, hdfs_internal**) ()
from /search/odin/tensorflow/py34tf1.3env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
(gdb) next
Single stepping until exit from function _ZN10tensorflow16HadoopFileSystem7ConnectENS_11StringPieceEPP13hdfs_internal,
which has no line number information.
0x00007fc1a1aef752 in tensorflow::HadoopFileSystem::FileExists(std::basic_string&lt;char, 
std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) ()
from /search/odin/tensorflow/py34tf1.3env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
(gdb) next
Single stepping until exit from function _ZN10tensorflow16HadoopFileSystem10FileExistsERKSs,
which has no line number information.
0x00007fc1a1d31ffa in 
tensorflow::FileSystem::RecursivelyCreateDir(std::basic_string&lt;char, 
std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) ()
from /search/odin/tensorflow/py34tf1.3env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
(gdb) s
Single stepping until exit from function _ZN10tensorflow10FileSystem20RecursivelyCreateDirERKSs,
which has no line number information.
</code></pre>

<p>Notice that the last command of gdb has never returned.</p>

<p>I have also found these tow similar questions yet are either unsolved or unhelpful for my problem:</p>

<p><a href=""https://stackoverflow.com/questions/43354494/distributed-tensorflow-1-0-supervisor-stuck-if-logdir-is-in-hdfs?answertab=votes#tab-top"">Distributed Tensorflow 1.0 Supervisor stuck if logdir is in HDFS</a></p>

<p><a href=""https://stackoverflow.com/questions/45843494/how-to-use-hdfs-directory-path-in-tf-train-monitoredtrainingsession-api-for-writ#"">How to use hdfs directory path in tf.train.MonitoredTrainingSession API for writing logs and checkpoints</a></p>
",2017-10-09 16:21:09,8746240,41,https://stackoverflow.com/questions/46650905,Documentation Replicability
46659101,Using `softmax_cross_entropy_with_logits()` with `seq2seq.sequence_loss()`,"<p>I have a working RNN using the default softmax loss function for <code>tf.contrib.seq2seq.sequence_loss()</code> (which I'm assuming is <code>tf.nn.softmax()</code>) but would instead like to use <code>tf.nn.softmax_cross_entropy_with_logits()</code>. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss"" rel=""nofollow noreferrer"">seq2seq.sequence_loss</a> documentation, one may use <code>softmax_loss_function=</code> to override the default loss function:</p>

<blockquote>
  <p><strong>softmax_loss_function</strong>: Function (labels, logits) -> loss-batch to be
  used instead of the standard softmax (the default if this is None).
  Note that to avoid confusion, it is required for the function to
  accept named arguments.</p>
</blockquote>

<p>Here is my code that works:</p>

<pre><code>from tensorflow.python.layers.core import Dense

# Build the graph
train_graph = tf.Graph()
# Set the graph to default to ensure that it is ready for training
with train_graph.as_default():

    # Load the model inputs    
    input_data, targets, keep_prob, lr, target_sequence_length, max_target_sequence_length, source_sequence_length \
    = get_model_inputs()

    # Create the training and inference logits
    training_decoder_output, inference_decoder_output = seq2seq_model(input_data, 
                                                                      targets, 
                                                                      lr, 
                                                                      target_sequence_length, 
                                                                      max_target_sequence_length, 
                                                                      source_sequence_length,
                                                                      len(source_letter_to_int),
                                                                      len(target_letter_to_int),
                                                                      encoding_embedding_size, 
                                                                      decoding_embedding_size, 
                                                                      rnn_size, 
                                                                      num_layers,
                                                                      keep_prob)    

    # Create tensors for the training logits and inference logits
    training_logits = tf.identity(training_decoder_output.rnn_output, 'logits')
    inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')

    # Create the weights for sequence_loss
    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')

    with tf.name_scope(""optimization""):

        # Loss function
        cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks)

        # Optimizer
        optimizer = tf.train.AdamOptimizer(lr)

        # Gradient Clipping
        gradients = optimizer.compute_gradients(cost)
        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]
        train_op = optimizer.apply_gradients(capped_gradients)

        # Add variables to collection in order to load them up when retraining a saved graph
        tf.add_to_collection(""cost"", cost)
        tf.add_to_collection(""train_op"", train_op)
</code></pre>

<p>My attempt to change the loss function is as follows (I've only indicated the code that is different):</p>

<pre><code>with tf.name_scope(""optimization""):

    # One-hot encode targets and reshape to match logits, one row per batch_size per step
    y_one_hot = tf.one_hot(targets, len(target_letter_to_int))
    y_reshaped = tf.reshape(y_one_hot, [batch_size, len(target_letter_to_int), 30])

    # Loss function
    loss = tf.nn.softmax_cross_entropy_with_logits(logits=training_logits, labels=y_reshaped)
    loss = tf.reduce_mean(loss)
    cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks, softmax_loss_function=loss)
</code></pre>

<p>The line <code>cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks, softmax_loss_function=loss)</code> is now giving me ""<strong>TypeError</strong>: 'Tensor' object is not callable."" This is one of the most opaque errors I've seen Tensorflow produce and I haven't found much of anything in the way of explanation on the internet. Any help would be appreciated.</p>
",2017-10-10 05:20:50,852795,2664,https://stackoverflow.com/questions/46659101,Documentation Replication on Other Examples
46752071,Feed a Tensor of SparseTensors to estimators,"<p>To get started with TF, I wanted to learn a predictor of match outcomes for a game. There are three features: the 5 heros on team 0, the 5 heroes on team 1, and the map. The winner is the label, 0 or 1.  I want to represent the teams and the maps as SparseTensors. Out of a possible 71 heroes, five will be selected. Likewise for maps, out of a possible 13, one will be selected.</p>

<pre><code>import tensorflow as tf
import packunpack as source
import tempfile
from collections import namedtuple

GameRecord = namedtuple('GameRecord', 'team_0 team_1 game_map winner')
def parse(line):
    parts = line.rstrip().split(""\t"")
    return GameRecord(
        game_map = parts[1], 
        team_0 = parts[2].split("",""), 
        team_1 = parts[3].split("",""), 
        winner = int(parts[4]))

def conjugate(record):
    return GameRecord(
        team_0 = record.team_1, 
        team_1 = record.team_0, 
        game_map = record.game_map, 
        winner = 0 if record.winner == 1 else 1)

def sparse_team(team):
    indices = list(map(lambda x: [x], map(source.encode_hero, team)))
    return tf.SparseTensor(indices=indices, values = [1] * len(indices), dense_shape=[len(source.heroes_array)])

def sparse_map(map_name):
    return tf.SparseTensor(indices=[[source.encode_hero(map_name)]], values = [1], dense_shape=[len(source.maps_array)])

def make_input_fn(filename, shuffle = True, add_conjugate_games = True):
    def _fn():
        records = []
        with open(filename, ""r"") as raw:
            i = 0
            for line in raw:
                record = parse(line)
                records.append(record)
                if add_conjugate_games:
                # since 0 and 1 are arbitrary team labels, learn and test the conjugate game whenever
                # learning the original inference
                    records.append(conjugate(record))

        print(""Making team 0"")
        team_0s = tf.constant(list(map(lambda r: sparse_team(r.team_0), records)))
        print(""Making team 1"")
        team_1s = tf.constant(list(map(lambda r: sparse_team(r.team_1), records)))
        print(""making maps"")
        maps = tf.constant(list(map(lambda r: sparse_map(r.game_map), records)))
        print(""Making winners"")
        winners = tf.constant(list(map(lambda r: tf.constant([r.winner]), records)))

        return {
                    ""team_0"": team_0s,
                    ""team_1"": team_1s,
                    ""game_map"": maps,
                }, winners
        #Please help me finish this function?

    return _fn

team_0 = tf.feature_column.embedding_column(
    tf.feature_column.categorical_column_with_vocabulary_list(""team_0"", source.heroes_array), len(source.heroes_array))
team_1 = tf.feature_column.embedding_column(
    tf.feature_column.categorical_column_with_vocabulary_list(""team_1"", source.heroes_array), len(source.heroes_array))
game_map = tf.feature_column.embedding_column(
    tf.feature_column.categorical_column_with_vocabulary_list(""game_map"", source.maps_array), len(source.maps_array))

model_dir = tempfile.mkdtemp()
m = tf.estimator.DNNClassifier(
    model_dir=model_dir,
    hidden_units = [1024, 512, 256], 
    feature_columns=[team_0, team_1, game_map])

def main():
    m.train(input_fn=make_input_fn(""tiny.txt""), steps = 100)

if __name__ == ""__main__"":
    main()
</code></pre>

<p>This fails on <code>team_0s = tf.constant(list(map(lambda r: sparse_team(r.team_0), records)))</code></p>

<p>It's very difficult to understand what tf wants me to return in my input_fn, because all of the examples I can find in the docs ultimately call out to a pandas or numpy helper function, and I'm not familiar with those frameworks. I thought that each dictionary value should be a Tensor containing all examples of a single feature. Each of my examples is a SparseTensor, and I want to simply embed them as their dense versions for the sake of the DNNClassifier.</p>

<p>I'm sure my mental model is horribly broken right now, and I appreciate any help setting it straight.</p>

<p>Error output:</p>

<pre><code>python3 estimator.py
Making team 0
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 468, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 468, in &lt;listcomp&gt;
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe8
b4d7aef0&gt;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""estimator.py"", line 79, in &lt;module&gt;
    main()
  File ""estimator.py"", line 76, in main
    m.train(input_fn=make_input_fn(""tiny.txt""), steps = 100)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 709, in _train_model
    input_fn, model_fn_lib.ModeKeys.TRAIN)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 577, in _get_features_and_l
abels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 663, in _call_input_fn
    return input_fn(**kwargs)
  File ""estimator.py"", line 44, in _fn
    team_0s = tf.constant(list(map(lambda r: sparse_team(r.team_0), records)))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 472, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type &lt;class 'list'&gt; to Tensor. Contents: [&lt;tensorflow.python.framework.sparse_tenso
r.SparseTensor object at 0x7fe8b4d7aef0&gt;, &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe8b4d7af28
&gt;, &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe8b4d7af60&gt;, &lt;tensorflow.python.framework.sparse_
tensor.SparseTensor object at 0x7fe8b4d7aeb8&gt; ... ]
</code></pre>
",2017-10-15 05:39:55,86432,9350,https://stackoverflow.com/questions/46752071,Inadequate Examples
46885191,tf.nn.conv2d_transpose output_shape dynamic batch_size,"<p>The documentation of tf.nn.conv2d_transpose says:</p>

<pre><code>tf.nn.conv2d_transpose(
    value,
    filter,
    output_shape,
    strides,
    padding='SAME',
    data_format='NHWC',
    name=None
)
</code></pre>

<p>The output_shape argument requires a 1D tensor specifying the shape of the tensor output by this op. Here, since my conv-net part has been built entirely on dynamic batch_length placeholders, I can't seem to device a workaround to the static <code>batch_size</code> requirement of the output_shape for this op. </p>

<p>There are many discussions around the web for this, however, I couldn't find any solid solution to this issue. Most of them are hacky ones with a <code>global_batch_size</code> variable defined. I wish to know the best possible solution to this problem. This trained model is going be shipped as a deployed service.</p>
",2017-10-23 08:45:42,4341842,426,https://stackoverflow.com/questions/46885191,Inadequate Examples
46900332,How to create custom metrics for use in Tensorflow's Estimator class?,"<p>In Tensorflow's <a href=""https://www.tensorflow.org/versions/master/extend/estimators"" rel=""noreferrer"">Creating Estimators in tf.estimator</a> guide, the example used a metric that is already predefined in the <code>tf.metrics</code> module.</p>

<p>Are there any resources that describe how to define a custom metric that can be used to evaluate an Estimator? I'd like to implement the F1 metric.</p>
",2017-10-24 00:18:05,3775778,1108,https://stackoverflow.com/questions/46900332,Documentation Replication on Other Examples
46976226,`tf.estimator.RunConfig` vs `tf.contrib.learn.RunConfig`,"<p>I am confused regarding whether I should be using <code>tf.estimator.RunConfig</code> or <code>tf.contrib.learn.RunConfig</code> to pass a <code>RunConfig</code> to an estimator. </p>

<p>using <code>tf.contrib.learn.RunConfig</code> is straightforward:</p>

<pre><code>rc = tf.contrib.learn.RunConfig(save_checkpoints_secs=1,
                                model_dir=model_dir)
</code></pre>

<p>But <code>tf.estimator.RunConfig</code> has some odd syntax:</p>

<pre><code>rc = tf.estimator.RunConfig()
rc = rc.replace(save_checkpoints_secs=1,
                model_dir=model_dir)
</code></pre>

<p>Is there any reason to prefer one <code>RunConfig</code> over the other? The documentation is not clear on this.</p>
",2017-10-27 13:29:17,592235,10387,https://stackoverflow.com/questions/46976226,Lack of Alternative Solutions/Documentation
47119604,"In tensorflow, does tf.summary record average values over multiple steps?","<p>By default, <code>RunConfig.save_summary_steps</code> is 100 in <code>tf.estimator.Estimator</code>, so it saves summaries every 100 steps. At each time it saves a summary, does it just save the current summary value computed from the current <code>step/minibatch</code>? Or it saves the average summary values computed from the recent 100 <code>steps/minibatches</code>? I cannot find a clear description for this in the official documentation.</p>
",2017-11-05 08:27:00,3295829,33,https://stackoverflow.com/questions/47119604,Lack of Alternative Solutions/Documentation
47254265,dynamic batch size with tf.data or tf.contrib.datta,"<p>I can use a placeholder as the batch_size with tf.train.batch_join() (Which is queue based,) so I can dynamically change the batch size in the training loop. </p>

<p>But when I use placeholder (or a nontrainable variable) as the batch_size for tf.data.Dataset.batch(), I got this error,</p>

<pre><code>ValueError: Cannot capture a placeholder (name:Placeholder, type:Placeholder) by value.
</code></pre>

<p>The whole error stack trace is very long. I traced the error to v1.4 tensorflow/python/data/ops/dataset_ops.py:108 in make_one_shot_iterator()</p>

<pre><code>@function.Defun(capture_by_value=True)
</code></pre>

<p>Full stack trace attached. I was trying the official tf resnet model.</p>

<p>Thanks!!</p>

<pre><code>Traceback (most recent call last):
  File ""imagenet_main.py"", line 281, in &lt;module&gt;
    tf.app.run(argv=[sys.argv[0]] + unparsed)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""imagenet_main.py"", line 270, in main
    hooks=[logging_hook])
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 708, in _train_model
    input_fn, model_fn_lib.ModeKeys.TRAIN)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 577, in _get_features_and_labels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 663, in _call_input_fn
    return input_fn(**kwargs)
  File ""imagenet_main.py"", line 269, in &lt;lambda&gt;
    True, FLAGS.data_dir, worker_batch_size, FLAGS.epochs_per_eval),
  File ""imagenet_main.py"", line 157, in input_fn
    iterator = dataset.make_one_shot_iterator()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 113, in make_one_shot_iterator
    _make_dataset.add_to_graph(ops.get_default_graph())
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 486, in add_to_graph
    self._create_definition_if_needed()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 321, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 338, in _create_definition_if_needed_impl
    outputs = self._func(*inputs)

  File ""/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 111, in _make_dataset
    return self._as_variant_tensor()  # pylint: disable=protected-access
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1225, in _as_variant_tensor
    self._input_dataset._as_variant_tensor(),  # pylint: disable=protected-access
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1036, in _as_variant_tensor
    self._input_dataset._as_variant_tensor(),  # pylint: disable=protected-access
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1147, in _as_variant_tensor
    self._input_dataset._as_variant_tensor(),  # pylint: disable=protected-access
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1598, in _as_variant_tensor
    output_types=nest.flatten(self.output_types))
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 1062, in prefetch_dataset
    output_shapes=output_shapes, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 691, in create_op
    inputs[i] = self._add_tensor_and_parents(x)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 706, in _add_tensor_and_parents
    op = self._add_op_and_parents(tensor.op)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/function.py"", line 718, in _add_op_and_parents
    ""by value."" % (op.name, op.type))
ValueError: Cannot capture a placeholder (name:Placeholder, type:Placeholder) by value.
</code></pre>
",2017-11-12 21:35:52,1702121,79,https://stackoverflow.com/questions/47254265,Documentation Replicability
47380573,How to properly update variables in a while loop in TensorFlow?,"<p>Can someone please explain (or point me to the relevant place in the documentation that I've missed) how to properly update a <code>tf.Variable()</code> in a <code>tf.while_loop</code>? I am trying to update variables in the loop that will store some information until the next iteration of the loop using the <code>assign()</code> method. However, this isn't doing anything.</p>

<p>As the values of <code>mu_tf</code> and <code>sigma_tf</code> are being updated by the minimizer, while <code>step_mu</code> isn't, I am obviously doing something wrong, but I don't understand what it is. Specifically, I guess I should say that I know <a href=""https://stackoverflow.com/a/34220750/8931942""><code>assign()</code> does not do anything until it is executed when the graph is run</a>, so I know that I can do</p>

<p><code>sess.run(step_mu.assign(mu_tf))</code></p>

<p>and that will update <code>step_mu</code>, but I want to do this in the loop correctly. I don't understand how to add an <code>assign</code> operation to the body of the loop.</p>

<p>A simplified working example of what I'm doing follows here:</p>

<pre><code>import numpy as np
import tensorflow as tf

mu_true = 0.5
sigma_true = 1.5

n_events = 100000

# Placeholders
X = tf.placeholder(dtype=tf.float32)

# Variables
mu_tf = tf.Variable(initial_value=tf.random_normal(shape=[], mean=0., stddev=0.1,
                                                dtype=tf.float32),
                    dtype=tf.float32)
sigma_tf = tf.Variable(initial_value=tf.abs(tf.random_normal(shape=[], mean=1., stddev=0.1,
                                                dtype=tf.float32)),
                       dtype=tf.float32,
                       constraint=lambda x: tf.abs(x))

step_mu = tf.Variable(initial_value=-99999., dtype=tf.float32)   
step_loss = tf.Variable(initial_value=-99999., dtype=tf.float32)

# loss function
gaussian_dist = tf.distributions.Normal(loc=mu_tf, scale=sigma_tf)
log_prob = gaussian_dist.log_prob(value=X)
negative_log_likelihood = -1.0 * tf.reduce_sum(log_prob)

# optimizer
optimizer = tf.train.AdamOptimizer(learning_rate=0.1)

# sample data
x_sample = np.random.normal(loc=mu_true, scale=sigma_true, size=n_events)

# Construct the while loop.
def cond(step):
    return tf.less(step, 10)

def body(step):
    # gradient step
    train_op = optimizer.minimize(loss=negative_log_likelihood)

    # update step parameters
    with tf.control_dependencies([train_op]):
        step_mu.assign(mu_tf)

        return tf.add(step,1)

loop = tf.while_loop(cond, body, [tf.constant(0)])

# Execute the graph
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    step_loss = sess.run(fetches=negative_log_likelihood, feed_dict={X: x_sample})

    print('Before loop:\n')
    print('mu_tf: {}'.format(sess.run(mu_tf)))
    print('sigma_tf: {}'.format(sess.run(sigma_tf)))
    print('step_mu: {}'.format(sess.run(step_mu)))
    print('step_loss: {}\n'.format(step_loss))

    sess.run(fetches=loop, feed_dict={X: x_sample})

    print('After loop:\n')
    print('mu_tf: {}'.format(sess.run(mu_tf)))
    print('sigma_tf: {}'.format(sess.run(sigma_tf)))
    print('step_mu: {}'.format(sess.run(step_mu)))
    print('step_loss: {}'.format(step_loss))
</code></pre>
",2017-11-19 18:39:39,8931942,806,https://stackoverflow.com/questions/47380573,Documentation Replicability
47485498,Tensorflow tf.nn.embedding_lookup,"<p>is there a small neural network in tf.nn.embedding_lookup??
When I train some data, a value of the same index is changing.
So is it trained also? while I'm training my model</p>

<p>I checked the official embedding_lookup code but I can not see any tf.Variables for train embedding parameter.
But when I print all tf.Variables then I can found a Variable which is within embedding scope</p>

<p>Thank you.</p>
",2017-11-25 11:33:32,8956473,21,https://stackoverflow.com/questions/47485498,Documentation Replicability
47558813,How does tensorflow tf.contrib.image.rotate works?,"<p>I'm new in using tensorflow and also python and play little bit with it and can't figure out how <code>tf.contrib.image.rotate</code> works that i can use it as <code>tensor</code> for example in <code>tf.cast</code> operation.</p>

<p>Maybe someone can help me out to figure out how it can be used? </p>

<p>Greetz</p>
",2017-11-29 17:50:57,9027227,31,https://stackoverflow.com/questions/47558813,Documentation Replication on Other Examples
47644412,TensorFlow Dataset API Parsing Error,"<p>I'm using the TensorFlow Dataset API to parse a CSV file and run a logistic regression. I'm following the example from the TF documentation <a href=""https://github.com/tensorflow/models/blob/master/official/wide_deep/wide_deep.py"" rel=""nofollow noreferrer"">here</a>.</p>

<p>The following code snippet shows how I am setting up the model:</p>

<pre><code>def input_fn(path, num_epochs, batch_size):
    dataset = tf.data.TextLineDataset(path)
    dataset = dataset.map(parse_table, num_parallel_calls=12)
    dataset = dataset.repeat(num_epochs)
    dataset.batch(batch_size)

    iterator = dataset.make_one_shot_iterator()
    features, labels = iterator.get_next()
    return features, labels

def parse_table(value):
    cols = tf.decode_csv(value, record_defaults=TAB_COLUMN_DEFAULTS)
    indep_vars = dict(zip(CSV_COLS, cols))
    y = indep_vars.pop('y')
    return indep_vars, y

def build_indep_vars():
    continuous_vars = [
        tf.feature_column.numeric_column(x, shape=1) for x in CONT_COLS]
    categorical_vars = [
        tf.feature_column.categorical_column_with_hash_bucket(
            x, hash_bucket_size=100) for x in CAT_COLS]
    return categorical_vars + continuous_vars
</code></pre>

<p>When calling <code>lr.train(input_fn = lambda: input_fn(data_path, 1, 100))</code> (note: batch size is 100) I'm getting the error </p>

<pre><code>ValueError: Feature (key: V1) cannot have rank 0. Give: Tensor(""IteratorGetNext:0"", shape=(), dtype=float32, device=/device:CPU:0)
</code></pre>

<p>So I'm assuming this means one of the <code>tf.feature_column.numeric_column</code> calls is getting a scalar value which it doesn't like. However, I cannot figure out why this is the case. I've set <code>batch_size</code> to a positive integer and according to the documentation the shape of the NDarray resulting from <code>tf.feature_column.numeric_column</code> should be <code>1Xbatch_size</code> by default. Can anyone explain why TensorFlow is returning this error?</p>

<p>I'm sure this question has a simple answer that will make me feel stupid for not figuring it out, but after spending some time on this I'm still stumped.</p>
",2017-12-05 00:53:29,8152457,117,https://stackoverflow.com/questions/47644412,Documentation Ambiguity
47748803,.h file not found when build tensorflow android demo with bazel,"<p>error occurred(.h file not found,and different .h file every time I build) when I build tf android demo with bazel.I've tried some ways proposed in this website,but not solved my problem.please help me,very thanks!</p>

<p><img src=""https://i.stack.imgur.com/RDuM0.png"" alt=""enter image description here"">
And sometimes another .h file not found
<a href=""https://i.stack.imgur.com/qOq7F.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
",2017-12-11 08:18:14,7288357,11,https://stackoverflow.com/questions/47748803,Documentation Replicability
47775244,Difference between tf.nn.convolution and tf.nn.conv2d,"<p>Could someone explain me the difference between <code>tf.nn.convolution</code> and <code>tf.nn.conv2d</code> ?</p>
",2017-12-12 14:39:57,6627095,101,https://stackoverflow.com/questions/47775244,Documentation Replication on Other Examples
47814401,How does tf.layers.batch_normalization calculate mean and variance during test time? (test data has machine-generated samples),"<p>I am trying to implement batch-normalization on my CNN that currently applies dropout. One problem is that I do not know how the mean and variance are calculated during test time.</p>

<p>On the documentation it says that if training=False is set then the normalization is done with moving statistics. What does this mean?</p>

<p>In addition, since my test data has lots of machine-generated samples I cannot use population mean and variance and just apply tf.nn.batch_normalization(). These samples are used to prevent hand labeling and are excluded when scoring my model</p>
",2017-12-14 13:20:57,8805495,1,https://stackoverflow.com/questions/47814401,Documentation Completeness
47822996,How does tensorflow import work?,"<p>When I do <code>import tensorflow as tf</code>, I can access different packages inside <code>tf</code>: <code>tf.nn</code>, <code>tf.train</code>, etc</p>

<p>BUT accessing <code>tensorflow.examples</code> fails:</p>

<pre><code>Traceback (most recent call last):
  File ""interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""&lt;ipython-input-4-c704d4902e0c&gt;"", line 1, in &lt;module&gt;
    tf.examples
AttributeError: 'module' object has no attribute 'examples'
</code></pre>

<p>I have to import it differently, like <code>from tensorflow.examples.tutorials.mnist import input_data</code>, and only after that <code>tf.examples</code> does resolve. Why?</p>
",2017-12-14 22:21:28,9101095,17,https://stackoverflow.com/questions/47822996,Documentation Replicability
47935393,Tensorflow stft does not use gpu,"<p>I have a very simple tensorflow program that computes the spectrogram of a wav file:</p>

<pre><code># load a wav file into audio_data

audio_data = tf.convert_to_tensor(audio_data, dtype=tf.float32)

stft = tf.contrib.signal.stft(audio_data, frame_length=255, frame_step=1)
mag = tf.abs(stft)

init = tf.global_variables_initializer()

with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:
    sess.run(init)
    mag = sess.run(mag)
</code></pre>

<p>The docs for <code>tf.contrib.signal.stft</code> say its implemented with GPU-compatible ops, and I see the device placement logs say every op in the program is being placed on my gpu. However, when I run this, my <strong>cpu</strong> is maxed out at 100%, and my <strong>gpu</strong> is completely idle. I've also tried adding an explicit <code>with tf.device('/gpu:0'):</code> above the stft line, but to no avail. What do I need to do to get this running on my gpu? Could it be a bug with the op? Other gpu ops, such as the convolution ops, seem to work great with my gpu and I can get full 100% usage from it when I use those.</p>

<p>I am on Linux Ubuntu, Tensorflow 1.4.1 (compiled from source), and I am using CUDA 9.0 and cuDNN 7.0.</p>
",2017-12-22 03:12:11,2382483,3389,https://stackoverflow.com/questions/47935393,Documentation Replication on Other Examples
47981089,How to get TensorFlow source for canned models (Estimators),"<p>We are using the canned dnn (tf.estimator.DNNClassifier and 
 tf.estimator.DNNLinearCombinedClassifier)(and others) estimators in TensorFlow 1.4 but are interested in inspecting and perhaps reimplementing the models with variations in native TensorFlow, as well as for learning purposes. Is there any way to do this or is it available in the docs? Or is there a way to see it in the source?</p>
",2017-12-26 16:16:36,137783,10562,https://stackoverflow.com/questions/47981089,Documentation Replicability
47984876,Tensorflow tf.map_fn parameters,"<p>I'm attempting to structure my parameters so that they will work properly with tf.map_fn() but most of the example documentation only discusses arrays or tensors of the same shape as function arguments.</p>

<p>Links include:</p>

<p><a href=""https://stackoverflow.com/questions/37086098/does-tensorflow-map-fn-support-taking-more-than-one-tensor"">Does tensorflow map_fn support taking more than one tensor?</a></p>

<p>My specific example is this:
I have some tensorflow function that expects [None, 2] and [x,y] as parameter tensor shapes.</p>

<p>Tensor A is of shape [batch_size, x*y, 2]</p>

<p>Tensor B is of shape [batch_size, x, y]</p>

<pre><code>lambdaData = (tensorA, tensorB)
lambdaFunc = lambda x: tensorflowFunc(x[0], x[1])
returnValues = tf.map_fn(lambdaFunc, lambdaData)
</code></pre>

<p>From the tensorflow documentation:</p>

<pre><code>If elems is a (possibly nested) list or tuple of tensors, then each of these 
tensors must have a matching first (unpack) dimension
</code></pre>

<p>Since tensorsA and B only match in dimension 0, I cannot stack or concatenate them; I have also tried creating lambdaData as:</p>

<ol>
<li>A list of two tensors</li>
<li>A tuple of two tensors</li>
<li>A list of tensor pairs</li>
</ol>

<p>All of the above result in varying dimension mismatch errors.  I would follow the recommended use as per documentation of placing all of the data into a single tensor, but because of dimension mismatching between tensorA and tensorB I am unable to.  Has anybody had any luck with tuples or lists of arguments for elems?</p>
",2017-12-26 23:54:18,1519665,511,https://stackoverflow.com/questions/47984876,Lack of Alternative Solutions/Documentation
48021777,Tensorflow tf.concat,"<p>Sorry for asking a totally elementary question, but I'm trying to use the <code>tf.concat()</code> function. Just to get going, I try to run the example code on their site: <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/array_ops/slicing_and_joining"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r0.12/api_docs/python/array_ops/slicing_and_joining</a></p>

<pre><code>t1 = [[1, 2, 3], [4, 5, 6]]
t2 = [[7, 8, 9], [10, 11, 12]]
tf.concat(0, [t1, t2]) 
</code></pre>

<p>This should generate the output: <code>[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]</code>.</p>

<p>However, I get the error message, saying that </p>

<blockquote>
  <p>""Shapes (2, 2, 3) and () are incompatible"".</p>
</blockquote>
",2017-12-29 11:18:01,8918908,793,https://stackoverflow.com/questions/48021777,Documentation Replication on Other Examples
48033687,How to use tf.train.shuffle_batch to train NN?,"<p>I've trained my neural built with tensorflow network and got some overfit I'd like to reduce. I hoped learning the model on batches could help ad I tried to test this idea. I found tf.train.shuffle_batch() and fought this may do the thing. So I tried and it didn't work. Tensorflow's documentation doesn't help. I've found <a href=""https://stackoverflow.com/questions/45203872/how-tf-train-shuffle-batch-works"">one topic, but the example there</a> only prints arrays out. It was promising to use it to learn NN but in my case istead of getting data divided to n-element batches I got them multiplied n-times in additional dimension. </p>

<p>Here is the code sample:</p>

<pre><code>nnInput = tf.placeholder(tf.float32, [None, input_width], ""network_input"")
nnOutput = tf.placeholder(tf.float32, [None, output_width], ""expected_labels"")

batch_readings, batch_labels = tf.train.shuffle_batch(
    [
        tf.constant(train_readings), 
        tf.constant(train_labels)
    ],
    batch_size = 15,
    num_threads = 4,
    capacity = 500,
    min_after_dequeue = 250,
    allow_smaller_final_batch = True
)

sess.run(tf.global_variables_initializer())

for epoch in range(learning_steps):
    print(""epoch:"", epoch)
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    print(""Input data shapes:"", train_readings.shape, train_labels.shape)
    for batch in range(10):
        x, y = sess.run([batch_readings, batch_labels])
        print(""Batch shapes:"", x.shape, y.shape)
        sess.run(train, feed_dict = {nnInput : x, nnOutput : y})
    coord.request_stop()
    coord.join(threads)
</code></pre>

<p>and here is the output:</p>

<pre><code>epoch: 0 
Input data shapes: (165, 60) (165, 1) 
Batch shapes: (15, 165, 60) (15, 165, 1)
</code></pre>

<p>And the error list concludes with:</p>

<pre><code>ValueError: Cannot feed value of shape (15, 165, 60) for Tensor 'network_input_1:0', which has shape '(?, 60)'
</code></pre>

<p>The conlusion is not surprising when I fed the NN with 3D array but why do I get such a batch when I expect x:(15, 60) and y:(15, 1)? Why do I get x:(15, 165, 60) y:(15, 165, 1) and how to get useful batches?</p>

<p>I'm using tensorflow-gpu but hope this should work as well, right?</p>
",2017-12-30 11:53:02,8214796,81,https://stackoverflow.com/questions/48033687,Documentation Replication on Other Examples
48051722,"The difference between tf.layers, tf.contrib, and tf.nn in Tensorflow","<p>The variants of functions that perform the same functionalities in tensorflow is a very confusing (at least for me). I want to use the official tensorflow API (already gave up on the mess of the high-level API's). However, I trying to understand the difference between tf.layers, tf.contrib, and tf.nn
For example, I am trying to use batch normalization in tensorflow. I google it and the first three links:</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization"" rel=""nofollow noreferrer"">tf.nn.batch_normalization</a></p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">tf.layers.batch_normalization</a></p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm"" rel=""nofollow noreferrer"">tf.contrib.layers.batch_norm</a></p>

<p>I understand they both have different parameters and eventually serve the same purpose. But the question is why do we have these three different classes? Is there a valid reason? </p>

<p>I searched the source code and realized that tf.layers is a wrapper for tf.nn</p>

<p>Update: This question is already answered <a href=""https://stackoverflow.com/questions/48001759/what-is-right-batch-normalization-function-in-tensorflow"">here</a>.</p>
",2018-01-01 17:24:00,7361690,199,https://stackoverflow.com/questions/48051722,Documentation Ambiguity
48065164,TensorFlow weighted_cross_entropy_with_logits produces wrong result,"<p>I am trying to use tf.nn.weighted_cross_entropy_with_logits API, but I found I just can not get the right result when the weight is not 1.0 (1.0 means no weight).</p>

<pre><code>import tensorflow as tf
import numpy as np

def my_binary_crossentropy_np(labels, output, weight=10.0):
  """"""
  Weighted binary crossentropy between an output tensor 
  and a target tensor.
  """"""
  # transform back to logits
  epsilon = 1e-08
  np.clip(output, epsilon, 1.0 - epsilon, out=output)
  output = np.log(output / (1.0 - output))

  # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits 
  # l = 1 + (q - 1) * z
  # (1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0))
  l = 1.0 + (weight - 1.0) * labels
  loss1 = np.multiply(1.0 - labels, output)
  loss2 = np.multiply(l, np.log(1.0 + np.exp(-abs(output))))
  loss3 = np.maximum(-output, 0)
  loss = loss1 + loss2 + loss3

  return np.mean(loss)


def my_binary_crossentropy_tf(labels, output, weight=1.0):
  """"""
  Weighted binary crossentropy between an output tensor 
  and a target tensor.
  """"""
  epsilon = 1e-08
  output = tf.clip_by_value(output, epsilon, 1.0 - epsilon)
  output = tf.log(output / (1.0 - output))

  # compute weighted loss
  #loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=output)
  loss = tf.nn.weighted_cross_entropy_with_logits(targets=labels, logits=output, pos_weight=weight)
  return tf.reduce_mean(loss)


# generate random test data and random label
predict = np.random.rand(10, 8)

label = np.random.rand(10, 8)
label[label &gt;= 0.5] = 1
label[label &lt; 0.5] = 0


loss1 = my_binary_crossentropy_np(label, predict, 1.0)
print('loss1 = ', loss1)

loss1 = my_binary_crossentropy_np(label, predict, 10.0)
print('loss1 = ', loss1)


predict_tf = tf.convert_to_tensor(predict)
loss2 = my_binary_crossentropy_tf(label, predict_tf, 1.0)
loss2 = tf.Session().run(loss2)
print('loss2 = ', loss2)

loss2 = my_binary_crossentropy_tf(label, predict_tf, 10.0)
loss2 = tf.Session().run(loss2)
print('loss2 = ', loss2)
</code></pre>

<p>running result:</p>

<pre><code>loss1 = 1.02193164517
loss1 = 1.96332399324

loss2 = 1.02193164517
loss2 = 4.80529539791
</code></pre>
",2018-01-02 17:17:41,5532550,63,https://stackoverflow.com/questions/48065164,Documentation Replicability
48072635,Why and when does the tensor's shape information unspecific?,"<p>I found piece of code like this:</p>

<pre><code>y = tf.strided_slice(data, [0, i * num_steps + 1],
                     [batch_size, (i + 1) * num_steps + 1])
y.set_shape([batch_size, num_steps])
</code></pre>

<p>as <a href=""https://stackoverflow.com/questions/35451948/clarification-on-tf-tensor-set-shape"">Clarification on tf.Tensor.set_shape()</a> said, set_shape can make the shape information more specific. But why data's shape information here is not specific? When does the tensor's information unspecific?</p>
",2018-01-03 06:58:32,3134227,63,https://stackoverflow.com/questions/48072635,Documentation Replicability
48222274,tensorflow ctc_loss how to understand labels param,"<p>tensorflow document:
labels.values[i] must take on values in [0, num_labels], allow values[i] have zero value,  </p>

<p>labels is SparseTensor,<br>
indices: specifies the indices of the elements in the sparse tensor that contain nonzero values, values:which supplies the values for each element in indices</p>

<p>according to sparsetensor define, labels.values[i] is nonzero value, but tf.nn.ctc_loss labels.values allow labels.values[i] have zero value,</p>

<p>how to understand labels.values[i] allow have zero value</p>
",2018-01-12 08:30:01,9207839,1,https://stackoverflow.com/questions/48222274,Documentation Replicability
48224021,Create tf.estimator.Estimator from tf.saved_model.SavedModel,"<p>I have a TensorFlow model on disk saved using tf.saved_model.builder.SavedModelBuilder. How to create a TF Estimator from it?</p>
",2018-01-12 10:15:21,1370397,2322,https://stackoverflow.com/questions/48224021,Documentation Replication on Other Examples
48235239,The fit function from tf.contrib.learn.LinearRegressor asks to switch to tf.train.get_global_step,"<p>I am trying to get a <code>LinearRegressor</code> to work and I get an error for which there doesn't seem to be much documentation about.</p>

<p>When I do:</p>

<pre><code>regressor = tf.contrib.learn.LinearRegressor(feature_columns=linear_features)

regressor.fit(input_fn=training_input_fn, steps=10000)

regressor.evaluate(input_fn=eval_input_fn)
</code></pre>

<p>I get the error:</p>

<blockquote>
  <p>Instructions for updating: Please switch to tf.train.get_global_step</p>
</blockquote>

<p>I am not sure how to proceed.</p>

<p>I read from the docs:</p>

<blockquote>
  <p>SOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-12-01.
  Instructions for updating: Estimator is decoupled from Scikit Learn
  interface by moving into separate class SKCompat. Arguments x, y and
  batch_size are only available in the SKCompat class, Estimator will
  only accept input_fn. Example conversion: est = Estimator(...) -> est
  = SKCompat(Estimator(...))</p>
</blockquote>

<p>But I'm not sure to what I should change to, or how to switch to the global step.</p>

<p>I tried using <code>tf.estimator.LinearRegressor</code> mainly because I'm out of ideas, and did something like this:</p>

<pre><code>estimator = tf.estimator.LinearRegressor(feature_columns=linear_features)

estimator.train(input_fn=training_input_fn)
estimator.evaluate(input_fn=eval_input_fn)
estimator.predict(input_fn=eval_input_fn)
</code></pre>

<p>But got no output at all.</p>
",2018-01-12 23:06:34,463065,40323,https://stackoverflow.com/questions/48235239,Lack of Alternative Solutions/Documentation
48281583,Tensorflow manual evaluation with tf.estimators,"<p>I'm using Tensorflow api <code>tf.estimator</code> to train and evaluate models, building a custom estimator as explained <a href=""https://developers.googleblog.com/2017/12/creating-custom-estimators-in-tensorflow.html"" rel=""nofollow noreferrer"">in this blog</a>, and running the process with this convenient way:</p>
<pre><code>run_config = tf.estimator.RunConfig(save_checkpoints_secs=save_interval_secs,
                                    keep_checkpoint_max=keep_checkpoint_max,
                                    save_summary_steps=save_summary_steps,
                                    model_dir=logdir)
estimator = tf.estimator.Estimator(model_fn=model_fn,
                                   config=run_config)
train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=train_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps=eval_steps, throttle_secs=eval_interval_secs)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</code></pre>
<p>This process is very efficient to train and monitor <code>tf.metrics</code> metrics into Tensorboard (e.g. with <code>tf.metrics.accuracy</code>).</p>
<p>For one of my projects, I would like to add some more (complicated) metrics coming from a standalone python function, and visualize them in the Tensorboard. This function would take as an argument the training logdir (to load the model and run it on data) and would return some scalar (or tensor) to be monitored into the Tensorboard.</p>
<p>Last but not least, the function will need the GPU resources, so I expect this function to be called after evaluation:</p>
<pre><code>Train xx steps =&gt; Evaluation xx steps =&gt; Custom metrics =&gt; Train xx steps =&gt; ...
</code></pre>
<p>I was thinking about using <code>tf.summary.FileWriter</code> and/or Training Hooks (see <a href=""https://web.archive.org/web/20180925064834/https://www.tensorflow.org/api_guides/python/train#Training_Hooks"" rel=""nofollow noreferrer"">Tensorflow documentation</a>) but I don't know how to use them in a straightforward way with <code>tf.estimator</code> api.</p>
<p>Thank you very much for your help!</p>
<p>M.</p>
",2018-01-16 12:43:04,9224055,71,https://stackoverflow.com/questions/48281583,Documentation Replication on Other Examples
48299597,How to efficiently shuffle a large tf.data.Dataset when using tf.estimator.train_and_evaluate?,"<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer""><code>tf.estimator.train_and_evaluate</code></a> documentation makes it clear that the input dataset must be properly shuffled for the training to see all examples:</p>

<blockquote>
  <p>Overfitting: In order to avoid overfitting, it is recommended to set up the training input_fn to shuffle the training data properly. It is also recommended to train the model a little longer, say multiple epochs, before performing evaluation, as the input pipeline starts from scratch for each training. It is particularly important for local training and evaluation.</p>
</blockquote>

<p>In my application, I would like to uniformly sample examples from the full <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code></a> with arbitrary evaluation frequency and <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"" rel=""nofollow noreferrer""><code>shuffle()</code></a>'s buffer size. Otherwise, the training can at most see the first:</p>

<pre><code>(steps_per_second * eval_delay * batch_size) + buffer_size
</code></pre>

<p>elements, effectively discarding the rest. Is there an efficient way to work around that without loading the complete dataset in the system memory?</p>

<p>I considered <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shard"" rel=""nofollow noreferrer"">sharding</a> the dataset based on the buffer size, but if the evaluation does not occur frequently, it will iterate on the same shard multiple times (a <code>repeat()</code> closes the pipeline). Ideally, I would like to move to another shard after a complete iteration over the dataset, is that possible?</p>

<p>Thanks for any pointers!</p>
",2018-01-17 11:06:08,2529808,504,https://stackoverflow.com/questions/48299597,Documentation Replicability
48348775,How do I profile a tf.data.Dataset?,"<p>I'm trying to understand what bottlenecks I have in my <code>input_fn</code> with <code>tf.data.Dataset</code> so I figured I'd use <code>tf.profiler</code> but it only shows the iterator op. How can I get the profiler to output the relevant ops in my Dataset pipeline instead?</p>

<h1>Example</h1>

<pre><code>dataset = input_fn()
iterator = dataset.make_one_shot_iterator()
minibatch = iterator.get_next()
run_metadata = tf.RunMetadata()
with tf.Session() as session:
    features, labels = session.run(minibatch, 
                                   options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
                                   run_metadata=run_metadata)

tf.profiler.advise(tf.get_default_graph(), run_metadata)
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>checkers {
  key: ""AcceleratorUtilizationChecker""
  value {
  }
}
checkers {
  key: ""ExpensiveOperationChecker""
  value {
    reports: ""top 1 operation type: IteratorGetNext, cpu: 79.89sec, accelerator: 0us, total: 79.89sec (99.96%)\ntop 2 operation type: OneShotIterator, cpu: 27.92ms, accelerator: 0us, total: 27.92ms (0.03%)\ntop 3 operation type: _retval_IteratorGetNext_3_3, cpu: 57us, accelerator: 0us, total: 57us (0.00%)""
    reports: ""top 1 graph node: IteratorGetNext, cpu: 79.89sec, accelerator: 0us, total: 79.89sec\ntop 2 graph node: OneShotIterator, cpu: 27.92ms, accelerator: 0us, total: 27.92ms""
    reports: ""&lt;ipython-input-2-c5f67ba0356f&gt;:49:&lt;module&gt;, cpu: 79.89sec, accelerator: 0us, total: 79.89sec\n&lt;ipython-input-2-c5f67ba0356f&gt;:48:&lt;module&gt;, cpu: 27.92ms, accelerator: 0us, total: 27.92ms""
  }
}
checkers {
  key: ""OperationChecker""
  value {
  }
}
</code></pre>
",2018-01-19 20:09:58,7287271,2712,https://stackoverflow.com/questions/48348775,Documentation Replicability
48369961,Tensorflow Estimator API with large number of features,"<p>I am using Tensorflow Estimator API to train some models, but what found that I have to use <code>tf.feature_column</code> for every feature </p>

<p>I have dataset consists of this columns :</p>

<blockquote>
  <p>['age', 'workclass', 'education', 'education_num', 'marital_status',
         'occupation', 'relationship', 'race', 'gender', 'capital_gain',
         'capital_loss', 'hours_per_week', 'native_country', 'income_bracket']</p>
</blockquote>

<p>why do I have to make them like this</p>

<pre><code>gender = tf.feature_column.categorical_column_with_hash_bucket(""gender"", hash_bucket_size=10)
occupation = tf.feature_column.categorical_column_with_hash_bucket(""occupation"", hash_bucket_size=1000)
marital_status = tf.feature_column.categorical_column_with_hash_bucket(""marital_status"", hash_bucket_size=1000)
relationship = tf.feature_column.categorical_column_with_hash_bucket(""relationship"", hash_bucket_size=1000)
education = tf.feature_column.categorical_column_with_hash_bucket(""education"", hash_bucket_size=1000)
workclass = tf.feature_column.categorical_column_with_hash_bucket(""workclass"", hash_bucket_size=1000)
native_country = tf.feature_column.categorical_column_with_hash_bucket(""native_country"", hash_bucket_size=1000)
</code></pre>

<p>.. etc, seems not the best way to handle the preprocessing for the features. is there a better way or we will be in this pain if we ever go to <code>tf.estimator</code></p>
",2018-01-21 17:58:58,9195600,633,https://stackoverflow.com/questions/48369961,Documentation Replication on Other Examples
48396599,"Canonical Tensorflow ""for loop""","<p>What is the canonical way of running a Tensorflow ""for loop""? </p>

<p>Specifically, suppose we have some <code>body</code> function which does NOT depend on the loop iteration, but must be run <code>n</code> times. </p>

<p>One might think that a good method might be to run this inside of a <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/control_flow_operations#while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop</code></a> like this:</p>

<pre><code>def body(x):
    return ...

def while_body(i,x):
    return i+1, body(x) 

i, x = tf.while_loop(lambda i: tf.less(i, n), while_body, [tf.constant(0),x])
</code></pre>

<p>In fact, that is precisely what the highest rated answer in this question suggests:</p>

<p><a href=""https://stackoverflow.com/questions/35330117/how-can-i-run-a-loop-with-a-tensor-as-its-range-in-tensorflow"">How can I run a loop with a tensor as its range? (in tensorflow)</a></p>

<p>However, the <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/control_flow_operations#while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop</code> docs</a> specifically say </p>

<blockquote>
  <p>For correct programs, while_loop should return the same result for any parallel_iterations > 0.</p>
</blockquote>

<p>If you put a counter in the body, then it seems that that condition is violated. So it seems that there must be a different way of setting up a ""for loop"". </p>

<p>Furthermore, even if there is no explicit error, doing so seems like it will create a dependency between iterations meaning that I do not think they will run in parallel. </p>
",2018-01-23 07:48:05,3309610,7062,https://stackoverflow.com/questions/48396599,Lack of Alternative Solutions/Documentation
48427269,What's the efficient way to feed elements from Iterator (from tf.data.Dataset) into TensorFlow model?,"<p>I'm using TensrFlow's new API for importing data via <code>tf.data.Dataset</code> and iterators. It is working fine, but I'm not sure if what I do is efficient. </p>

<p>What I'm doing at the moment is evaluating an iterator's <code>get_next()</code> method, which gives me a bunch of elements like the actual image, its label, filename, etc. I then feed the image into my model using the <code>feed_dict</code>. </p>

<p>I know that <code>feed_dict</code> is very slow, so am I losing benefits of <code>Dataset</code> and Iterators and having serialised dataset in <code>TFRecord</code>s by evaluating the entries and feeding them into the graph via <code>feed_dict</code>? I haven't found any examples in TF's documentation which shows how one's expected to use Iterator's <code>get_next()</code> to feed elements into the model. Is it better to unpack <code>get_next()</code> and use the result directly in my graph? </p>
",2018-01-24 16:28:41,298209,5130,https://stackoverflow.com/questions/48427269,Inadequate Examples
48445751,Keras: Constrained dictionary search with CTC decode,"<p>I'm trying to constrain the CTC decoding to a specific (external) dictionary in Keras with a the tensorflow backend. In the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_decode"" rel=""nofollow noreferrer"">tensorflow documentation for Keras' ctc_decode</a>, it is written that when <code>greedy=False</code> a dictionary will be used. Here is the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder"" rel=""nofollow noreferrer"">documentation for  tf.nn.ctc_beam_search_decoder</a>, which will be called by this option as far as I understand.</p>

<p>Since there is no way to pass an external dictionary or language model (to constrain the search), I assume that with <code>greedy=False</code> it creates its own dictionary from the training data. Is this correct? Is there a way to constrain the search to a specific (external) dictionary?</p>
",2018-01-25 14:53:14,1578793,81,https://stackoverflow.com/questions/48445751,Documentation Replication on Other Examples
48732627,How to do data argumentation with tensorflow dataset api?,"<p>I want to use the <code>tf.data.dataset</code>  to do image argumentation while training. The code is similar to official <a href=""https://www.tensorflow.org/programmers_guide/datasets"" rel=""nofollow noreferrer"">guideline</a> as follow:</p>

<pre class=""lang-py prettyprint-override""><code>train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))
train_dataset = train_dataset.map(
    lambda file, label: tuple(tf.py_func(
        _parse_train_image, [file, label],
        [tf.float32, tf.int32]
    ))
).batch(batch_size).repeat(epoch)

def _parse_train_image(file, label):
    image = cv2.imread(file.decode(), cv2.IMREAD_COLOR)
    image = process_image(image)
    return image, label
</code></pre>

<p>The <code>train_data</code> and <code>train_label</code> here refer to two lists which contains image file paths and labels seperately. However, this transformation can only return the original image, I also need to argument the images(like flip and rotate). 
How can I continue to argument the images and return these images?</p>
",2018-02-11 14:38:15,5321613,113,https://stackoverflow.com/questions/48732627,Documentation Replication on Other Examples
48736753,"How do you load ""any"" model from disk into a TensorFlow Estimator without having the model_fn source code?","<p>In Keras you can load a model that you had previously trained by using:</p>

<p>trained_keras_model = tf.keras.models.load_model(model_name)</p>

<p>Is there any equivalent method for doing this using TensorFlow estimator API? According to the documentation, I have to use: </p>

<p>trained_estimator = tf.estimator.Estimator (model_fn,model_dir)
I want to get the trained estimator using just the files in the model directory. To be more clear my idea was to load ""any"" model from disk without having the model_fn source code. Is it possible to do it this way? </p>

<p>This feature is implemented in Keras so I am at a loss to understand why Estimator API cannot do this. </p>
",2018-02-11 21:40:09,7656080,757,https://stackoverflow.com/questions/48736753,Documentation Replicability
48815906,Implement early stopping in tf.estimator.DNNRegressor using the available training hooks,"<p>I am new to tensorflow and want to implement early stopping in <code>tf.estimator.DNNRegressor</code> with  available training hooks<a href=""https://www.tensorflow.org/api_guides/python/train#Training_Hooks"" rel=""noreferrer"">Training Hooks</a> for the MNIST dataset. The early stopping hook will stop training if the loss does not improve for some specified number of steps. Tensorflow documentaton only provides example for <a href=""https://www.tensorflow.org/tutorials/layers#set_up_a_logging_hook"" rel=""noreferrer"">Logging hooks</a>. Can someone write a code snippet for implementing it?</p>
",2018-02-15 20:41:36,6533039,1065,https://stackoverflow.com/questions/48815906,Requesting (Additional) Documentation/Examples
49066695,How to use tf.nn.raw_rnn function in Tensorflow?,"<p>I am trying to implement LSTM based network where after hidden state computation we also apply linear + sigmoid transformation at each time step. I have found the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn"" rel=""nofollow noreferrer"">official documentation</a> and <a href=""https://hanxiao.github.io/2017/08/16/Why-I-use-raw-rnn-Instead-of-dynamic-rnn-in-Tensorflow-So-Should-You-0/"" rel=""nofollow noreferrer"">a nice article</a> that describe <code>tf.nn.raw_rnn</code> function suitable for this task however I struggle to understand why it does not work in my particular case.</p>

<h3>Input description</h3>

<p>So, let our input to LSTM be a minibatch of size <code>[num_steps x batch_size x size]</code>, concretely <code>[5, 32, 100]</code>. Let LSTM have 200 hidden units. Then the output of the LSTM is <code>[5, 32, 200]</code> tensor which we can later use for loss computation. I assume the input <code>[5, 32, 100]</code> tensor is first unstacked into an array of <code>[32, 100]</code> tensors and then stacked back if we use <code>tf.nn.dynamic_rnn</code> with <code>time_major=True</code> in Tensorflow:</p>

<pre><code>                                      tf.nn.dynamic_rnn(LSTM)
                   LSTM t=0    LSTM t=1   LSTM t=2   LSTM t=3   LSTM t=4  
[5, 32, 100] --&gt;   [[32, 100], [32, 100], [32, 100], [32, 100], [32, 100]] --&gt; [5, 32, 200]
</code></pre>

<h3>Hidden state model</h3>

<p>In addition after each LSTM cell I need to perform linear + sigmoid transformation to squash each <code>[32, 200]</code> tensor into <code>[32, 1]</code> for example. Our <code>tf.nn.dynamic_rnn</code> won't work for that since it only accepts cells. We need to use <code>tf.nn.raw_rnn</code> API. So, here is my try:</p>

<pre><code>def _get_raw_rnn_graph(self, inputs):
    time = tf.constant(0, dtype=tf.int32)
    _inputs_ta = tf.TensorArray(dtype=tf.float32, size=5)
    # our [5, 32, 100] tensor becomes [[32, 100], [32, 100], ...]
    _inputs_ta = _inputs_ta.unstack(inputs)  

    # create simple LSTM cell
    cell = tf.contrib.rnn.LSTMCell(config.hidden_size)

    # create loop_fn for raw_rnn
    def loop_fn(time, cell_output, cell_state, loop_state):
        emit_output = cell_output  # == None if time = 0

        if cell_output is None:  # time = 0
            next_cell_state = cell.zero_state(32, tf.float32)
            self._initial_state = next_cell_state
        else:
            next_cell_state = cell_state

        elements_finished = (time &gt;= 32)
        finished = tf.reduce_all(elements_finished)
        next_input = tf.cond(finished,
                             lambda: tf.zeros([32, config.input_size], dtype=tf.float32),                                                   
                             lambda: _inputs_ta.read(time))

        # apply linear + sig transform here
        next_input = self._linear_transform(next_input, activation=tf.sigmoid)

        next_loop_state = None
        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)

    outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)
    outputs = outputs_ta.stack()
    return outputs, final_state
</code></pre>

<p>This unfortunately does not work. The <code>loop_fn</code> iterates only two times instead of <code>num_steps</code> times as I expected and its output is <code>Tensor(""Train/Model/TensorArrayStack/TensorArrayGatherV3:0"", shape=(?, 32, 200), dtype=float32)</code> not <code>[5, 32, 1]</code> as we intended. What am I missing here?</p>
",2018-03-02 09:54:30,1984680,6278,https://stackoverflow.com/questions/49066695,Documentation Replication on Other Examples
49155119,Using TensorFlow ``grad_loss / grad_ys`` parameter to add gradients,"<p>I'm trying to use the <code>grad_loss</code> parameter in <code>optimizer.minimize(loss, grad_loss=)</code> to modify the network gradients with existing gradients.
I followed the comments here:
<a href=""https://stackoverflow.com/questions/42399401/use-of-grads-ys-parameter-in-tf-gradients-tensorflow"">Use of grads_ys parameter in tf.gradients - TensorFlow</a></p>

<p>and I would like to run a toy example, in which I recreate the default <code>1</code> values for <code>grad_ys</code>, as specified in the documentation.</p>

<p>Here's the relevant code segment:</p>

<pre><code>grads_and_vars = optimizer.compute_gradients(loss_op) 
vars_with_grad = [v for g, v in grads_and_vars if g is not None] 
grad_loss = [] 
for grad,var in grads_and_vars:
    grad_loss.append(tf.ones_like(grad))
train_op = optimizer.minimize(loss_op, grad_loss=grad_loss)
</code></pre>

<p>The first part extracts gradients using <code>compute_gradients</code>. The last line computes gradients of the loss function <code>loss_op</code> but attempts to use <code>1</code>-filled vectors for the grads. As far as I understand, this should behave similarly to funning <code>minimize</code> without the <code>grad_loss</code> parameter. </p>

<p>Unfortunately, this fails since it expects <code>grad_loss</code> to be a Tensor (and have a dtype) and not a list. Looking into <code>gradients_impl.py</code> I see that the function expected <code>grad_loss</code> to be of the same dimension as <code>loss</code> (which in this case is a scalar). </p>

<p>I would appreciate any assistance in this simple example - how do I add elements to the gradients this way? </p>

<p>EDIT: I guess the question boils down to the definition of <code>grad_loss</code>: ""A <code>Tensor</code> holding the gradient computed for <code>loss</code>."" How do I generate such a tensor from a set of gradients obtained by <code>compute_gradients</code>?</p>

<p>Thanks.</p>
",2018-03-07 15:07:04,635622,1806,https://stackoverflow.com/questions/49155119,Documentation Replication on Other Examples
49201832,How to use TensorBoard and summary operations with the tf.layers module,"<p>I have followed the <a href=""https://www.tensorflow.org/tutorials/layers"" rel=""nofollow noreferrer"">TensorFlow Layers tutorial</a> to create a CNN for MNIST digit classification using TensorFlow's tf.layers module. Now I'm trying to learn how to use TensorBoard from <a href=""https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"" rel=""nofollow noreferrer"">TensorBoard: Visualizing Learning</a>. Perhaps this tutorial hasn't been updated recently, because it says its example code is a modification of that tutorial's and links to it, but the code is completely different: it manually defines a single-hidden-layer fully-connected network.</p>

<p>The TensorBoard tutorial shows how to use tf.summary to attach summaries to a layer by creating operations on the layer's weights tensor, which is directly accessible because we manually defined the layer, and attaching tf.summary objects to those operations. To do this if I'm using tf.layers and its tutorial code, I believe I'd have to:</p>

<ol>
<li>Modify the Layers tutorial's example code to use the non-functional interface (Conv2D instead of conv2d and Dense instead of dense) to create the layers</li>
<li>Use the layer objects' trainable_weights() functions to get the weight tensors and attach tf.summary objects to those</li>
</ol>

<p>Is that the best way to use TensorBoard with tf.layers, or is there a way that's more directly compatible with tf.layers and the functional interface? If so, is there an updated official TensorBoard tutorial? It would be nice if the documentation and tutorials were more unified. </p>
",2018-03-09 20:42:03,2328207,644,https://stackoverflow.com/questions/49201832,Requesting (Additional) Documentation/Examples
49335184,Reuse variables and model encapsulated in class,"<p>I want to train a model in tensorflow and only define the graph and variables once. So I encapsulated that in a class as follows in this functionally non-sense minimum example:</p>

<pre><code>import tensorflow as tf
import numpy as np


class Model:
    weights = tf.get_variable(""weights"", (10, 1))
    bias = tf.get_variable(""bias"", 1)

    x = tf.placeholder(tf.float32, (100, 10), ""x"")
    y = tf.placeholder(tf.float32, 100, ""y"")

    output = tf.matmul(x, weights) + bias
    cost = tf.reduce_sum(tf.abs(output - y))
    optimizer = tf.train.MomentumOptimizer(0.5, 0.9).minimize(cost)

    def train(self, data, lbls):
        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            for i in range(10):
                _ = sess.run(self.optimizer, {self.x: data, self.y: lbls})

    def predict(self, data):
        with tf.Session() as sess:
            return sess.run(self.output, {self.x: data})


data = np.random.randint(0, 100, (100, 10))
lbls = np.random.randint(0, 1, (100, ))
mdl = Model()
mdl.train(data, lbls)
mdl.predict(data)
</code></pre>

<p>I expect the predict function to reuse the trained variables <code>self.weights</code> and <code>self.bias</code> but all I get is <code>FailedPreconditionError (see above for traceback): Attempting to use uninitialized value bias</code> in the return line of the <code>Model.predict()</code> function.</p>

<p>This sounds simple to me, but somewhere I must have a wrong assumption. The <a href=""https://www.tensorflow.org/programmers_guide/variables#sharing_variables"" rel=""nofollow noreferrer"">official Tensorflow tutorial</a> just states ""Explicitly passing tf.Variable objects around"" as one way of sharing variables. Defining variables as class variables should do that in my understanding. I have googled extensively but cannot find a simple example of tensorflow with classes like this. 
In my actual project I fiddled around with variable scope (<code>tf.variable_scope(.., reuse=True)</code>) which still raises me an uninitialized variables warning, which I can only fix by initializing but then the trained variables are reset, of course.</p>

<p>Is the whole class approach like this wrong? How can I simply reuse my variables without a saver or other more complicated structure? And: Where is my understanding of tensorflow variables, graphs and so on, wrong?</p>
",2018-03-17 10:58:03,5240546,400,https://stackoverflow.com/questions/49335184,Inadequate Examples
49346599,tf.feature_column.input_layer returning wrong shape of tensor,"<p>When I use <code>tf.feature_column.input_layer</code>, it seems to be returning a tensor with shape <code>[number of features, batch size]</code> when it should be returning the opposite - <code>[batch size, number of features]</code>. The code is:</p>

<pre><code>## Generate the input functions
def create_train_input_fn(x_train, y_train): 
    return tf.estimator.inputs.pandas_input_fn(
        x=x_train,
        y=y_train, 
        batch_size=32,
        num_epochs=500,
        shuffle=True)
p = create_train_input_fn(df, df.reward_next)

## Create the custom estimator
deep_q = tf.estimator.Estimator(
    model_fn=deep_q_model_test,
    params={
        'feature_columns_current_state': feature_columns_results['current'],
        'feature_columns_next_state': feature_columns_results['next'],
        'gamma': GAMMA,
        'n_classes':ACTION_DIM,
        'hidden_units':[256, 256],
        'batch_size':32
    })

# Train the Model.
deep_q.train(p)
</code></pre>

<p>The documentation clearly states </p>

<blockquote>
  <p>Its shape is (batch_size, first_layer_dimension) </p>
</blockquote>

<p>I am using my own custom estimator function (<code>deep_q_model_test</code> in the code above), and within that I have the first line as:</p>

<pre><code>net = tf.feature_column.input_layer(features, feature_columns)
print('shape of input to forward pass: ' + str(net.get_shape()))
</code></pre>

<p>And the shape shown in my print (and also after inspecting the tensor board) is:</p>

<pre><code>shape of input to forward pass: (?, 32)
shape of hidden layer: (?, 256)
shape of hidden layer: (?, 256)
</code></pre>

<p>I am using the prebuilt pandas input function as well to be fed into it: tf.estimator.inputs.pandas_input_fn. The feature columns were built with it being:</p>

<pre><code>[_NumericColumn(key='cpc', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _NumericColumn(key='comp_win', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _NumericColumn(key='impressions', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _NumericColumn(key='clicks', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _NumericColumn(key='cost', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _NumericColumn(key='transactions', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _NumericColumn(key='cpo', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _NumericColumn(key='reward', shape=(1,), default_value=None, 
dtype=tf.float32, normalizer_fn=None),
 _IndicatorColumn(categorical_column=_IdentityCategoricalColumn(key='hrs', 
num_buckets=24, default_value=None))]
</code></pre>

<p>Also the neural net is actually trains and inspecting the tensorboard it does show the shape is flipped. The problem with this is when I run a batch size which is different, lets say for prediction where i want to only predict 1 observation, it wont work.</p>

<p><strong>EDITED</strong>
Adding in the actual code for the model</p>

<pre><code>def deep_q_model(features, labels, mode, params):
""""""deep q learning model""""""

## Create the models/
def nn1_forward(features, feature_columns, hidden_units, n_classes):
    net = tf.feature_column.input_layer(features, feature_columns)
    print('shape of input to forward pass: ' + str(net.get_shape()))

    # Hidden layers (batch size, hidden_nodes_dim)
    layer_number = 0
    for units in hidden_units:
        net = tf.layers.dense(net, units=units,
                              activation=tf.nn.relu,
                             name='layer' + str(layer_number),
                             reuse=tf.AUTO_REUSE)
        print('shape of hidden layer: ' + str(net.get_shape()))
        layer_number += 1

    # Logits layer with no activation (batch size, output dims)
    logits = tf.layers.dense(net, n_classes,
                             activation=None,
                            name='layerOutput',
                            reuse=tf.AUTO_REUSE)
    print('shape of output layer: ' + str(logits.get_shape()))

    return logits

## Current state forward pass
logits_current = nn1_forward(features,
                            params['feature_columns_current_state'],
                            params['hidden_units'],
                            params['n_classes'])
tf.summary.histogram('logits_current', logits_current)

# Reshape the action tensor
action_num = tf.reshape(tf.cast(features['action_num'], tf.int32), [params['batch_size'], 1])
# Generate a counter
counter = tf.reshape(tf.range(params['batch_size']), [params['batch_size'], 1])
actions = tf.concat([counter,
                     action_num], axis=1)
print('shape of actions ' + str(actions.get_shape()))

# Get the Q values based on the actual action taken for each observation - flatten to (batch size, 1)
predicted_q_values = tf.transpose(tf.gather_nd(logits_current, [actions]))
print('shape of predicted q values: ' + str(predicted_q_values.get_shape()))


## next state forward pass
logits_next = nn1_forward(features,
                          params['feature_columns_next_state'],
                        params['hidden_units'],
                        params['n_classes'])
tf.summary.histogram('logits_next', logits_next)

# Get the maximum Q value possible for each observation - flatten to (batch size, 1)
max_next_q_values = tf.reshape(tf.reduce_max(logits_next, axis=1), [params['batch_size'], 1])
print('shape of max q values: ' + str(max_next_q_values.get_shape()))


### Bellman equation
# Rewards is what was fed in as ""labels""
rewards = tf.cast(tf.reshape(labels,  [params['batch_size'], 1]), tf.float64)
expected_q_values = tf.add(rewards,tf.multiply(tf.cast(params['gamma'], tf.float64),
                                               tf.cast(max_next_q_values, tf.float64)))
tf.summary.histogram('expected_q_values', expected_q_values)
print('shape of expected q value: '+ str(expected_q_values.get_shape()))

## Compute predictions - predictions will calculate the Q values without activation
predicted_classes = tf.argmax(logits_current, 1)
if mode == tf.estimator.ModeKeys.PREDICT:
    predictions = {
        'class_ids': predicted_classes[:, tf.newaxis],
        'probabilities': tf.nn.softmax(logits_current),
        'logits': logits_current,
    }
    return tf.estimator.EstimatorSpec(mode, predictions=predictions)


# Compute loss
loss = tf.losses.mean_squared_error(labels=tf.cast(expected_q_values, tf.float32),
                                    predictions=tf.cast(predicted_q_values, tf.float32))


# Compute evaluation metrics.
if mode == tf.estimator.ModeKeys.EVAL:
    return tf.estimator.EstimatorSpec(
        mode, loss=loss, eval_metric_ops=loss)

# Create training op.
assert mode == tf.estimator.ModeKeys.TRAIN

optimizer = tf.train.AdamOptimizer(learning_rate=0.01)
train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)
</code></pre>
",2018-03-18 09:59:30,4148062,11,https://stackoverflow.com/questions/49346599,Documentation Replication on Other Examples
49405794,Why tensor_summary doesn't work?,"<p>I use <code>tf.summary.tensor_summary</code> in my code, following this: <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/tensor_summary"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/summary/tensor_summary</a></p>

<p>But I didn't see anything new in tensorboard, and tensorboard also printed some warnings:</p>

<pre><code>W0321 12:50:47.244003 Reloader tf_logging.py:121] This summary with tag 'component_3_finalize/wealth_tensor' is oddly not associated with a plugin.
</code></pre>

<p>How to make this work? Do I need install some plugin? I didn't find any docs on this.</p>

<p>UPDATE:</p>

<p>So I here is how I create my summary:</p>

<pre><code>def finalize_graph(self, graph_building_context):
    tf.summary.scalar('loss', loss)

    # the wealth tensor is of shape [B], where B is the batch size at runtime
    tf.summary.scalar('wealth', tf.reduce_mean(wealth))
    # uhmm, this tensor_summary doesn't work yet
    tf.summary.tensor_summary('wealth_tensor', wealth)
</code></pre>

<p>Then I use a <code>MonitoredTrainingSession</code>, by default it will save the summary, and I can see my <code>loss</code> and <code>wealth</code> scalar summry, but not this <code>wealth_tensor</code> summary.</p>
",2018-03-21 11:59:05,2218586,2841,https://stackoverflow.com/questions/49405794,Lack of Alternative Solutions/Documentation
49435335,Verify that keras GaussianNoise is enabled at train time when using inference with edward,"<p>I would like to check if noise is truly added and used during training of my neural network. I therefore build my NN with keras like this:</p>

<pre><code>from keras.layers import Input
from keras.layers.noise import GaussianNoise
inp = Input(tensor=self.X_ph)
noised_x = GaussianNoise(stddev=self.x_noise_std)(inp)
x = Dense(15, activation='elu')(noised_x)
x = Dense(15, activation='elu')(x)
self.estimator = x
...
# kernel weights, as output by the neural network
self.logits = logits = Dense(n_locs * self.n_scales, activation='softplus')(self.estimator)
self.weights = tf.nn.softmax(logits)

# mixture distributions
self.cat = cat = Categorical(logits=logits)
self.components = components = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc in locs_array for scale in scales_array]
self.mixtures = mixtures = Mixture(cat=cat, components=components, value=tf.zeros_like(self.y_ph))
</code></pre>

<p>Then I use edward to execute inference:</p>

<pre><code>self.inference = ed.MAP(data={self.mixtures: self.y_ph})
self.inference.initialize(var_list=tf.trainable_variables(), n_iter=self.n_training_epochs)
tf.global_variables_initializer().run()
</code></pre>

<p>According to the documentation, the closest I get to this is through ed.MAP's <code>run()</code> and <code>update()</code> functions. </p>

<p>Preferably, I would do something like this:</p>

<pre><code>noised_x = self.sess.run(self.X_ph, feed_dict={self.X_ph: X, self.y_ph: Y}) 
np.allclose(noised_x, X) --&gt; False
</code></pre>

<h2>How can I properly verify that noise is being used at train time and disabled at test time within ed.MAP?</h2>

<h3>Update 1</h3>

<p>Apparently the way I use GaussianNoise doesn't seem to add noise to my input since the following unittest fails:</p>

<pre><code>X, Y = self.get_samples(std=1.0)

model_no_noise = KernelMixtureNetwork(n_centers=5, x_noise_std=None, y_noise_std=None)
model_no_noise.fit(X,Y)
var_no_noise = model_no_noise.covariance(x_cond=np.array([[2]]))[0][0][0]

model_noise = KernelMixtureNetwork(n_centers=5, x_noise_std=20.0, y_noise_std=20.0)
model_noise.fit(X, Y)
var_noise = model_noise.covariance(x_cond=np.array([[2]]))[0][0][0]
self.assertGreaterEqual(var_noise - var_no_noise, 0.1)
</code></pre>

<p>I also made sure that during the <code>inference.update(...)</code> the assertion
<code>assert tf.keras.backend.learning_phase() == 1</code>
passes.</p>

<p>Where could have something gone wrong here?</p>
",2018-03-22 17:50:05,7353970,10660,https://stackoverflow.com/questions/49435335,Documentation Replication on Other Examples
49472402,Tensorflow tf.nn.softmax() function performs much better than hand-written softmax,"<p>I'm writing a simple logistic regression with tensorflow. I found out that when using tf.nn.softmax, the algorithm converges much quicker, and in the end the accuracy is higher.
If switched to my own implementation of softmax, the network converges slower, and the end accuracy is not as good.</p>
<p>Here's the code:</p>
<pre><code>SEED = 1025
W = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels], seed=SEED))
b = tf.Variable(tf.zeros([num_labels]))
logits = tf.matmul(train_dataset, W) + b

# My softmax:
y_ = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis=0)
# Tensorflow softmax: 
y_ = tf.nn.softmax(logits)

y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)
loss = -tf.reduce_mean(tf.reduce_sum(train_labels * tf.log(y_clipped), axis=1))
</code></pre>
<p>Using my softmax:</p>
<pre><code>Loss at step 0: 22.213934
Training accuracy: 12.7%
Validation accuracy: 13.2%
Loss at step 100: 12.777291
Training accuracy: 45.3%
Validation accuracy: 45.5%
Loss at step 200: 11.361242
Training accuracy: 48.2%
Validation accuracy: 47.4%
Loss at step 300: 10.658278
Training accuracy: 51.4%
Validation accuracy: 49.7%
Loss at step 400: 9.297832
Training accuracy: 59.2%
Validation accuracy: 56.8%
Loss at step 500: 8.902699
Training accuracy: 62.0%
Validation accuracy: 59.2%
Loss at step 600: 8.681184
Training accuracy: 64.2%
Validation accuracy: 61.0%
Loss at step 700: 8.529438
Training accuracy: 65.8%
Validation accuracy: 62.3%
Loss at step 800: 8.416442
Training accuracy: 66.8%
Validation accuracy: 63.3%
Test accuracy: 70.4%
</code></pre>
<p>Using tensorflow's softmax:</p>
<pre><code>Loss at step 0: 13.555875
Training accuracy: 12.7%
Validation accuracy: 14.5%
Loss at step 100: 2.194562
Training accuracy: 72.5%
Validation accuracy: 72.0%
Loss at step 200: 1.808641
Training accuracy: 75.5%
Validation accuracy: 74.5%
Loss at step 300: 1.593390
Training accuracy: 76.8%
Validation accuracy: 75.0%
Loss at step 400: 1.442661
Training accuracy: 77.7%
Validation accuracy: 75.2%
Loss at step 500: 1.327751
Training accuracy: 78.2%
Validation accuracy: 75.4%
Loss at step 600: 1.236314
Training accuracy: 78.5%
Validation accuracy: 75.6%
Loss at step 700: 1.161479
Training accuracy: 78.9%
Validation accuracy: 75.6%
Loss at step 800: 1.098717
Training accuracy: 79.4%
Validation accuracy: 75.8%
Test accuracy: 83.3%
</code></pre>
<p>From the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/softmax"" rel=""nofollow noreferrer"">documentation</a>, in theory tensorflow's softmax should be exact the same as I implemented, no?</p>
<blockquote>
<p>This function performs the equivalent of</p>
<p>softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)</p>
</blockquote>
<p><strong>EDIT:</strong> I added a seed when initializing from normal distribution, now I can reproduce the accuracy results.
When setting axis value in &quot;My softmax&quot; line, only axis=0 doesn't result in error. Setting axis=1 or axis=-1 both results in this error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 10 and 10000 for 'truediv' (op: 'RealDiv') with input shapes: [10000,10], [10000].
</code></pre>
",2018-03-25 03:57:14,778800,307,https://stackoverflow.com/questions/49472402,Documentation Replicability
49494632,How can we do tf.tile with extra dimensions in the output?,"<p>Suppose I have a <code>tensor = tf.constant([1, 2])</code>, what's the best way of creating a tensor of <code>[[tensor, tensor], [tensor, tensor]]</code>, which is <code>[[[1, 2], [1, 2]], [[1, 2], [1, 2]]]</code>?</p>

<p>The use case looks similar to <code>tf.tile</code>. However, <code>tf.tile</code> does not create the extra dimensions.</p>
",2018-03-26 15:02:15,2100910,327,https://stackoverflow.com/questions/49494632,Documentation Replicability
49497353,Use tf.image.random_flip_left_right method to batch of images,"<p>Does any way to use <strong>tf.image.random_flip_left_right</strong> method for batch of images?</p>

<p>Thanks.</p>
",2018-03-26 17:35:08,3153317,13,https://stackoverflow.com/questions/49497353,Documentation Replicability
49500873,Using tf.boolean_mask with greater_equal to slicing a tensor,"<p>I am trying to use tf.boolean_mask to select certain values from a tensor.</p>

<pre><code>myArray = tf.random_normal([6], mean=1, stddev=4, seed = 1)
with tf.Session() as test_a:
    myMask =  tf.greater_equal(myArray, 0.5)
    myScores = tf.boolean_mask( myArray, myMask )
    print(""myArray = "", myArray.eval())
    print(""myMask = "", myMask.eval())
    print(""myScores = "", myScores.eval())
</code></pre>

<p>To which I get the following.</p>

<pre><code>myArray =  [-2.24527287  6.93839502  1.26131749 -8.77081585  1.39699364  3.36489725]
myMask =  [False  True  True  True False False]
myScores =  [ 2.71667314  1.12839425  1.47780943  1.50100374]
</code></pre>

<p>I had expected to get</p>

<pre><code>myArray =  [-2.24527287  6.93839502  1.26131749 -8.77081585  1.39699364  3.36489725]
myMask =  [False  True  True  False True True]
myScores =  [ 6.93839502  1.26131749  1.39699364  3.36489725]
</code></pre>

<p>How can I do this?</p>
",2018-03-26 21:24:52,868166,11,https://stackoverflow.com/questions/49500873,Documentation Replicability
49542954,What are tf.TensorArray objects?,"<p>I am not able to get an understanding of <a href=""https://www.tensorflow.org/api_docs/python/tf/TensorArray"" rel=""nofollow noreferrer"">tf.TensorArray</a> objects. What are they and where are they needed? I have some (highly likely faulty) understanding -
 they are used in while_loops especially to write the information to the loop_state. If somehow we end up increasing the number of tensors or their dimensions across iterations it throws back an error. hence normal way to pass the loop_state across iterations collecting information from each iteration, which would be passing a list, would throw back an error. So we create tf.TensorArray objects and write the information to them at each iteration and pass these tf.TensorArray objects across loops and for some reason that way it is able to pass through</p>

<p>I couldnt find any blog or documentation explaining the working of a tf.TensorArray objects and documentation doesn't help much either</p>

<p>So, if this is not the best place to be asking this question, kindly direct me to nearest help.</p>
",2018-03-28 19:47:09,6546694,5020,https://stackoverflow.com/questions/49542954,Lack of Alternative Solutions/Documentation
49605330,Example of tf.feature_column.indicator_column,"<p>I’m reading tensorflow’s document about <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column"" rel=""nofollow noreferrer"">tf.feature_column.indicator_column</a>.</p>

<p>In this document, there is an example.</p>

<pre><code>name = indicator_column(categorical_column_with_vocabulary_list(
       'name', ['bob', 'george', 'wanda'])
columns = [name, ...]
features = tf.parse_example(..., features=make_parse_example_spec(columns))
dense_tensor = input_layer(features, columns)

dense_tensor == [[1, 0, 0]]  # If ""name"" bytes_list is [""bob""]
dense_tensor == [[1, 0, 1]]  # If ""name"" bytes_list is [""bob"", ""wanda""]
dense_tensor == [[2, 0, 0]]  # If ""name"" bytes_list is [""bob"", ""bob”]
</code></pre>

<p>My problem is the omitted(<code>...</code>) part of this code. I just want a complete, running, simple example. And I can’t find a kind example including tf.Example and so on.</p>

<p>Can anyone make this complete?</p>

<p>Thank you for advance.</p>
",2018-04-02 04:32:04,766330,5147,https://stackoverflow.com/questions/49605330,Documentation Completeness
49605958,what's the purpose of tf.nn.dropout?,"<p>I notice there are two APIs in TensorFlow concerning with dropout, one is tf.nn.dropout, the other is tf.layers.dropout. I just wonder what's the purpose of tf.nn.dropout?
According to <a href=""https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf"" rel=""nofollow noreferrer"">https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</a>, there should be a parameter to distinguish between training and testing stage. I see tf.layers.dropout provides the proper behavior, so why another function tf.nn.dropout? Anyone has any idea? Thanks.</p>
",2018-04-02 05:49:18,6902674,21,https://stackoverflow.com/questions/49605958,Documentation Ambiguity
49619995,How to control when to compute evaluation vs training using the Estimator API of tensorflow?,"<p>As stated in <a href=""https://stackoverflow.com/questions/45952149/tensorflow-estimator-periodic-evaluation-on-eval-dataset"">this question</a>:</p>

<blockquote>
  <p>The tensorflow documentation does not provide any example of how to perform a periodic evaluation of the model on an evaluation set</p>
</blockquote>

<p>The accepted answer suggested the use of Experiment (which is deprecated according to <a href=""https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/contrib/learn/README.md"" rel=""noreferrer"">this README</a>).</p>

<p>All I found on online points towards using the <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate"" rel=""noreferrer"">train_and_evaluate</a> method. However, I still do not see how to switch between the two processes (train and evaluate). I have tried the following:</p>

<pre><code>estimator = tf.estimator.Estimator(
    model_fn=model_fn,
    params=hparams,
    model_dir=model_dir,
    config = tf.estimator.RunConfig(
        save_checkpoints_steps = 2000,
        save_summary_steps = 100,
        keep_checkpoint_max=5
    )
)

train_input_fn = lambda: input_fn(
    train_file, #a .tfrecords file
    train=True,
    batch_size=70,
    num_epochs=100
)

eval_input_fn = lambda: input_fn(
    val_file, # another .tfrecords file
    train=False,
    batch_size=70,
    num_epochs=1
)
train_spec = tf.estimator.TrainSpec(
    train_input_fn,
    max_steps=125
)    

eval_spec = tf.estimator.EvalSpec(
    eval_input_fn,
    steps=30,
    name='validation',
    start_delay_secs=150,
    throttle_secs=200
)

tf.logging.info(""start experiment..."")
tf.estimator.train_and_evaluate(
    estimator,
    train_spec,
    eval_spec
)
</code></pre>

<p>Here is what I think my code should be doing:</p>

<blockquote>
  <p>Train the model for 100 epochs using a batch size of 70; save checkpoints every 2000 batches; save summaries every 100 batches; keep at most 5 checkpoints; after 150 batches on the training set, compute the validation error using 30 batches of validation data</p>
</blockquote>

<p>However, I get the following logs:</p>

<pre><code>INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1 into /output/model.ckpt.
INFO:tensorflow:loss = 39.55082, step = 1
INFO:tensorflow:global_step/sec: 178.622
INFO:tensorflow:loss = 1.0455043, step = 101 (0.560 sec)
INFO:tensorflow:Saving checkpoints for 150 into /output/model.ckpt.
INFO:tensorflow:Loss for final step: 0.8327793.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2018-04-02-22:49:15
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /projects/MNIST-GCP/output/model.ckpt-150
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Evaluation [3/30]
INFO:tensorflow:Evaluation [6/30]
INFO:tensorflow:Evaluation [9/30]
INFO:tensorflow:Evaluation [12/30]
INFO:tensorflow:Evaluation [15/30]
INFO:tensorflow:Evaluation [18/30]
INFO:tensorflow:Evaluation [21/30]
INFO:tensorflow:Evaluation [24/30]
INFO:tensorflow:Evaluation [27/30]
INFO:tensorflow:Evaluation [30/30]
INFO:tensorflow:Finished evaluation at 2018-04-02-22:49:15
INFO:tensorflow:Saving dict for global step 150: accuracy = 0.8552381, global_step =150, loss = 0.95031387
</code></pre>

<p>From the logs, it seems that the training stops after the first evaluation step. What am I missing from the documentation? Could you explain me how I should have implemented what I think my code is doing? </p>

<p>Additional info I am running everything using the MNIST dataset, which has 50,000 images in the training set, so (I think) the model should run for *num_epochs*50,000/batch_size ≃ 7,000 steps* </p>

<p>I sincerely appreciate your help!</p>

<p>EDIT: after running experiments I realize that max_steps controls the number of steps of the whole training procedure, not just the amount of steps before computing the metrics on the test set. Reading tf.estimator.Estimator.train, I see it has a steps argument, which works incrementally and is bounded by max_steps; however, tf.estimator.TrainSpec does not have the steps argument, which means I cannot control the number of steps to take before computing metrics on the validation set.</p>
",2018-04-02 23:08:36,4833773,507,https://stackoverflow.com/questions/49619995,Lack of Alternative Solutions/Documentation
49633383,tensorflow tf.nn.rnn_cell.BasicLSTMCell,"<p>I'm trying to play with ""tf.nn.rnn_cell.BasicLSTMCell"" with TF on python.</p>

<p>Reading here ""<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell</a>"", in the ""<strong>init</strong>"" method, I see the param ""num_units""
with description ""int, The number of units in the LSTM cell.""</p>

<p>But ... wait a moment ""number of UNITS""? Which type of units? The class is called ""...LSTMCell"" but from ""num_units"" it seem that we are speaking about a layer, not a single neuron.</p>

<p>I'm confused. Any help is appreciated.
TIA</p>
",2018-04-03 15:06:40,7835905,11,https://stackoverflow.com/questions/49633383,Documentation Replicability
49662470,Tensorflow global_step TypeError,"<p>I'm adding Tensorboard to an existing small Tensorflow project that I know works to practice working with Tensorboard but I get a type error that global_step must be a string or tensor, however I have assigned global_step to a <code>tf.Variable(0, name='global_step', trainable=False)</code> just like the documentation and every example I see online. Any idea of what I'm missing would be super appreciated. </p>



<p>---> 70             [summary_merge, tf.train.global_step(sess, global_step_tensor) ,update_model, weights], feed_dict)</p>

<p>TypeError: Fetch argument 0 has invalid type , must be a string or Tensor. (Can not convert a int into a Tensor or Operation.)</p>

<pre class=""lang-python prettyprint-override""><code>import gym
import numpy as np
import random
import ipdb
import matplotlib.pyplot as plt
import tensorflow as tf
%matplotlib inline

tf.reset_default_graph()
env = gym.make('FrozenLake-v0')

global_step_tensor = tf.Variable(0, name='global_step', trainable=False)
saver = tf.train.Saver()

with tf.name_scope('policy-network'):
    observations = tf.placeholder(shape=[1, env.observation_space.n], dtype=tf.float32, name='input')
    weights = tf.Variable(tf.random_uniform([16,4], 0, 0.01))
    Qout = tf.matmul(observations, weights)
    predict = tf.argmax(Qout, 1)

    nextQ = tf.placeholder(shape=[1, 4], dtype=tf.float32)
    loss = tf.reduce_sum(tf.square(nextQ - Qout))
    trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)
    update_model = trainer.minimize(loss, global_step= global_step_tensor)

with tf.name_scope('summaries'):
    summary_merge = tf.summary.merge([
        tf.summary.histogram('loss', loss),
        tf.summary.histogram('weights', weights)
    ])


init = tf.global_variables_initializer()

gamma = .99
epsilon = 0.1
num_episodes = 2000

j_list = []
r_list = []

with tf.Session() as sess:
    # Create a writer for summary data
    writer = tf.summary.FileWriter('/tmp/display', sess.graph)
    sess.run(init)
    for i in range(num_episodes):
        s = env.reset()
        reward_all = 0
        done = False
        j = 0

        while j &lt; 99:
            j+= 1

            a, allQ = sess.run([predict, Qout], feed_dict={observations:np.identity(16)[s:s+1]})
            if np.random.rand(1) &lt; epsilon:
                a[0] = env.action_space.sample()

            s1, reward, done, _ = env.step(a[0])
            Q1 = sess.run(Qout, feed_dict={observations: np.identity(16)[s1:s1+1]}) 

            maxQ1 = np.max(Q1)
            targetQ = allQ

            targetQ[0, a[0]] = reward + gamma*maxQ1
            feed_dict = {observations: np.identity(16)[s:s+1], nextQ:targetQ}

            # Run prediction operation, evaluate summary_merge and assign to summaries
            summaries, global_step_tensor, _, W1 = sess.run(
            [summary_merge, tf.train.global_step(sess, global_step_tensor) ,update_model, weights], feed_dict)

            # Write summaries to writer
            writer.add_summary(summaries, global_step)

            reward_all += reward
            s = s1

            if done == True:
                epsilon = 1./((i/50) + 10)
                break

        if (i+1) % 1000 == 0:
            # Save the graph every 1000 episodes
            saver.save(sess, '/tmp/checkpoint', global_step=global_step)

        j_list.append(j)
        r_list.append(reward_all)

print(""Percent of succesful episodes: {} %"".format((sum(r_list)/num_episodes)))
</code></pre>
",2018-04-05 00:40:23,5780994,65,https://stackoverflow.com/questions/49662470,Lack of Alternative Solutions/Documentation
49745029,How to use Distributed Tensorflow on remote machines?,"<p>I am trying to run a distributed Tensorflow script across three machines: my local machine running the parameter server and two remote machines I have access to running worker jobs. I am following <a href=""https://www.tensorflow.org/deploy/distributed#putting_it_all_together_example_trainer_program"" rel=""nofollow noreferrer"">this example</a> from the Tensorflow documentation, passing the IP addresses and unique port numbers to each worker job, and setting the <code>protocol</code> option in <code>tf.train.Server</code> to <code>'grpc'</code>. However, when I run the script, all three processes are started on my localhost, and none of the jobs are on the remote machines. Is there a step I am missing? </p>

<p>My (abridged) code:</p>

<pre><code># Define flags
tf.app.flags.DEFINE_string(""ps_hosts"", ""localhost:2223"", 
                        ""comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", 
""server1.com:2224,server2.com:2225"",
                        ""comma-separated list of hostname:port pairs"")

tf.app.flags.DEFINE_string(""job_name"", ""worker"", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

ps_hosts = FLAGS.ps_hosts.split("","")
worker_hosts = FLAGS.worker_hosts.split("","")

cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})
server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index, protocol='grpc')

if FLAGS.job_name == ""ps"":
    server.join()
elif FLAGS.job_name == ""worker"":
    # Between-graph replication
    with tf.device(tf.train.replica_device_setter(cluster=cluster, worker_device=""/job:worker/task:{}"".format(FLAGS.task_index))):
        # Create model...
        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                                 logdir=""./checkpoint"",
                                 init_op=init_op,
                                 summary_op=summary,
                                 saver=saver,
                                 global_step=global_step,
                                 save_model_secs=600)

        with sv.managed_session(server.target, 
                                 config=config_proto) as sess:
            # Train model...
</code></pre>

<p>This code causes two problems:</p>

<ol>
<li>Both of the worker jobs give errors about not getting a response from the other:</li>
</ol>

<p>From worker0:</p>

<pre><code>2018-04-09 23:48:39.749679: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
</code></pre>

<p>From worker1:</p>

<pre><code>2018-04-09 23:49:30.439166: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
</code></pre>

<ol start=""2"">
<li>I can get rid of the earlier problem by using a <code>device_filter</code>, but all jobs are started on my local machine, and not on the remote servers. </li>
</ol>

<p>How do I get the two worker jobs to run on the remote servers?</p>
",2018-04-10 03:52:45,9621612,21,https://stackoverflow.com/questions/49745029,Documentation Replication on Other Examples
49746064,What is the difference between tf.nn.ctc_beam_search_decoder and tf.contrib.seq2seq.BeamSearchDecoder mechanism?,"<p>I am building a seq2seq model with tensorflow.
Can you explain the details of the two beam search functions?
Thank you.</p>

<p>tf.nn.ctc.beam_search_decoder
<a href=""https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder</a></p>

<p>tf.contrib.seq2seq.BeamSearchDecoder
<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BeamSearchDecoder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BeamSearchDecoder</a></p>
",2018-04-10 05:38:10,9622974,19,https://stackoverflow.com/questions/49746064,Documentation Replicability
49765437,Tensorflow Type Error,"<p>Getting strange type error with TensorFlow code:</p>

<pre><code>curMaxAbs = tf.Variable(-1.0, tf.float32)
maxi = tf.Variable(-1, tf.int32)
for i, g in enumerate(grads):
    maxG = tf.reduce_max(tf.abs(g))            
    oCurMaxAbs = curMaxAbs            
    curMaxAbs = tf.cond(tf.greater(maxG,oCurMaxAbs),
                        lambda: maxG,
                        lambda: oCurMaxAbs)
    maxi = tf.cond(tf.greater(maxG,oCurMaxAbs),
                   lambda: maxi,
                   lambda: i)
</code></pre>

<p>Getting the error for line <code>if not tf.equal(curMaxAbs,tf.maximum(curMaxAbs, maxG))</code></p>

<blockquote>
  <p>TypeError: Input 'y' of 'Maximum' Op has type float32 that does not
  match type int32 of argument 'x'</p>
</blockquote>

<p>How in the world could <code>curMaxAbs</code> have type <code>int32</code>, when it is only reassigned with the <code>curMaxAbs = tf.maximum(curMaxAbs, maxG)</code> statement, and the <code>tf.maximum</code> function returns the same type as the first argument? (per <a href=""https://www.tensorflow.org/api_docs/python/tf/maximum"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/maximum</a>).</p>
",2018-04-11 02:14:58,3661120,2040,https://stackoverflow.com/questions/49765437,Documentation Replication on Other Examples
49768997,Writing TFRecords in batches,"<p>All documentations I found regarding TFRecords are generating <code>tf.train.Example()</code>s one by one, and writing them using</p>

<pre><code>writer = tf.python_io.TFRecordWrite(path)
ex = generate_example(features)  # Returns tf.train.Example() instance
writer.write(ex.SerializeToString())
</code></pre>

<p>Since I'm dealing with very big data, I know that I'll pay a high overhead price for writing examples separately</p>

<p>Is there any way to write multiple <code>tf.train.Example()</code> to a TFRecord at once?</p>
",2018-04-11 07:28:26,5368083,12085,https://stackoverflow.com/questions/49768997,Documentation Replication on Other Examples
49785239,TensorFlow.constant() throws TypeError with placeholder parameter (TF v1.4),"<p>Python host language. TF v1.4.</p>

<p><a href=""https://www.tensorflow.org/versions/r1.4/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.4/api_docs/python/tf/constant</a></p>

<p>Nearly just like docs example (above), I need to make a constant 2-D tensor populated with scalar value, in my case some mean value, which is mean of r, but r is a placeholder, not a variable, NOT a numpy array. As such, feed_dict needs to be used to fill-in placeholder r in my application.  Now a python ndarray or some python list was used in the docs example, which won't work in my application, so that's the difference.</p>

<p>In my application, global_bias (below) needs to be a tf.constant not a tf.variable -- because what I'm saying is, the optimizer needs to not learn it. Just leave it be, please.</p>

<p>Note: In my application, r is a placeholder not a variable.</p>

<pre><code>#global_bias_value = tf.reduce_mean(r)    # tf.constant() FAILS (below)
global_bias_value = 87. # tf.constant() runs OK (below)
global_bias = tf.constant(global_bias_value, shape=(I,J)) #TypeError: List of Tensors when single Tensor expected
rhat = global_bias + fm
</code></pre>

<p>So, as I said, what TF code would be used to make a constant 2-D tensor populated with scalar value, in my case some mean value, which is mean of r, but r is a placeholder, not a variable, NOT a numpy array?</p>

<p>Hey I tried .eval() but TF said you need a session to do that. So are you TF folks saying I need 2 sessions, run sequentially, just to do this little thing?  Or else are you saying I should bypass feed_dict to feed in my r placeholder actual data via numpy arrays in through the side door (in app memory as a python list or ndarray) plus the front door (feed_dict), which would be janky?  </p>

<p>Thanks for clues!   I need to get one.</p>
",2018-04-11 22:22:54,39123,1544,https://stackoverflow.com/questions/49785239,Documentation Replicability
49830843,What's the alternative for TensorFlow VocabularyProcessor?,"<p>It says that it is deprecated and will be removed in the future. Another line says ""Please use tensorflow/transform or tf.data."". I searched the internet but I couldn't find the answer. Here is the line that gives me the warning:</p>

<pre><code># Change texts into numeric vectors
vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(max_sequence_length,min_frequency=min_word_frequency)
</code></pre>
",2018-04-14 11:17:23,8433372,429,https://stackoverflow.com/questions/49830843,Documentation Ambiguity
49862069,Is there a way to dispose tensors in tf.Model object?,"<p>I'm building an interactive app in which users can play around with the parameters of a model. After new parameters are specified, I no longer need the old tf.Model object and the associated tensors. Is there an equivalent of tf.Tensor.dispose() for tf.Model? </p>

<p>Thanks!</p>
",2018-04-16 16:27:22,9647899,26,https://stackoverflow.com/questions/49862069,Documentation Replicability
49959130,how to insert two or more label lists in the tf.estimator.inputs.numpy_input_fn?,"<p>I am using the <code>tf.estimator.inputs.numpy_input_fn</code> to feed data in my model and train it in a similar way with the <a href=""https://www.tensorflow.org/tutorials/layers"" rel=""nofollow noreferrer"">MNIST example</a>. The only difference is that I need to insert two numpy lists of labels instead of one. I tried passing them in a dictionary like this:</p>

<pre><code>train_input_fn = tf.estimator.inputs.numpy_input_fn(
            x={""x"": training_images},
            y={""labels1"": training_labels1, ""labels2"": training_labels2},
            batch_size=BATCH_SIZE,
            num_epochs=None,
            shuffle=True)

my_cnn_model.train(input_fn=train_input_fn,steps=NUM_TRAINING_STEPS)
</code></pre>

<p>Then when I try to retrieve them in the model like so:</p>

<pre><code>def build_cnn_model(features, labels, mode):
</code></pre>

<p>I get the following error:</p>

<blockquote>
  <p>AttributeError: 'dict' object has no attribute 'shape'</p>
</blockquote>

<p>I also tried to change the name of the variable ""labels"" to be ""targets"" according to <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn"" rel=""nofollow noreferrer"">tensorflow inputs.numpy_input_fn documentation</a>:</p>

<pre><code>def build_cnn_model(features, targets, mode):
</code></pre>

<p>and I get this error:</p>

<blockquote>
  <p><code>ValueError: model_fn (&lt;function build_cnn_model at 0x7f88df9c9d08&gt;)
  has following not expected args: ['targets']</code></p>
</blockquote>

<p>If you have any solution or suggestion to my problem, please let me know.</p>

<p>Thanks a lot in advance.</p>

<p>Antonios</p>
",2018-04-21 18:47:06,7184238,1,https://stackoverflow.com/questions/49959130,Documentation Ambiguity
50029121,How to use tf.layers classes instead of functions,"<p>It seems that tf.Layer modules come in two flavours: functions and classes. I normally use the functions directly (e.g, tf.layers.dense) but I'd like to know how to use classes directly (tf.layers.<strong>D</strong>ense). I've started experimenting with the new eager execution mode in tensorflow and I think using classes are going to be useful there as well but I haven't seen good examples in the documentation. Is there any part of TF documentation that shows how these are used? </p>

<p>I guess it would make sense to use them in a class where these layers are instantiated in the <code>__init__</code> and then they're linked in the <code>__call__</code> method when the inputs and dimensions are known?</p>

<p>Are these tf.layer classes related to <code>tf.keras.Model</code>? Is there an equivalent wrapper class for using <code>tf.layers</code>?</p>

<p><strong>Update:</strong> for eager execution there's <code>tfe.Network</code> that must be inherited. There's an example <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network_eager_api.py"" rel=""noreferrer"">here</a></p>
",2018-04-25 18:31:48,298209,5130,https://stackoverflow.com/questions/50029121,Lack of Alternative Solutions/Documentation
50047909,Benefit of applying tf.image.per_image_standardization() over batch_norm layer in Tensorflow?,"<p>What is the benefit in applying <code>tf.image.per_image_standardization()</code> before the first layer of the deep neural network <strong>over</strong> adding the <code>Batch_Norm layer</code> as the first layer? </p>

<p>In order to normalize the [0.0, 255.0] float value image pixels before feeding into the network, which method would be suitable?</p>

<ol>
<li><p>tf.image.per_image_standardization()</p></li>
<li><p>Batch_Norm - layer</p></li>
</ol>
",2018-04-26 16:27:40,8865844,143,https://stackoverflow.com/questions/50047909,Documentation Replication on Other Examples
50054453,Tensorflow shape inference static RNN compiler error,"<p>I am working on OCR software optimized for phone camera images. </p>

<p>Currently, each 300 x 1000 x 3 (RGB) image is reformatted as a 900 x 1000 numpy array. I have plans for a more complex model architecture, but for now I just want to get a baseline working. I want to get started by training a static RNN on the data that I've generated.</p>

<p>Formally, I am feeding in n_t at each timestep t for T timesteps, where n_t is a 900-vector and T = 1000 (similar to reading the whole image left to right). Here is the Tensorflow code in which I create batches for training:</p>

<pre><code>sequence_dataset = tf.data.Dataset.from_generator(example_generator, (tf.int32, 
tf.int32))
sequence_dataset = sequence_dataset.batch(experiment_params['batch_size'])
iterator = sequence_dataset.make_initializable_iterator() 
x_batch, y_batch = iterator.get_next()
</code></pre>

<p>The tf.nn.static_bidirectional_rnn documentation claims that the input must be a ""length T list of inputs, each a tensor of shape [batch_size, input_size], or a nested tuple of such elements."" So, I go through the following steps in order to get the data into the correct format.</p>

<pre><code># Dimensions go from [batch, n , t] -&gt; [t, batch, n]
x_batch = tf.transpose(x_batch, [2, 0, 1])

# Unpack such that x_batch is a length T list with element dims [batch_size, n]
x_batch = tf.unstack(x_batch, experiment_params['example_t'], 0)
</code></pre>

<p>Without altering the batch any further, I make the following call:</p>

<pre><code>output, _, _ = tf.nn.static_rnn(lstm_fw_cell, x_batch, dtype=tf.int32)
</code></pre>

<p>Note that I do not explicitly tell Tensorflow the dimensions of the matrices (this could be the problem). They all have the same dimensionality, yet I am getting the following bug:</p>

<pre><code>ValueError: Input size (dimension 0 of inputs) must be accessible via shape 
inference, but saw value None.
</code></pre>

<p>At which point in my stack should I be declaring the dimensions of my input? Because I am using a Dataset and hoping to get its batches directly to the RNN, I am not sure that the ""placeholder -> feed_dict"" route makes sense. If that in fact is the method that makes the most sense, let me know what that looks like (I definitely do not know). Otherwise, let me know if you have any other insights to the problem. Thanks!</p>
",2018-04-27 02:42:45,9707928,1,https://stackoverflow.com/questions/50054453,Documentation Replication on Other Examples
50078749,Tensorflow-hub Text-Module Preprocessing,"<p>I'm playing around with the new Modules which are available on the tensorflow-hub (which I really like - thanks for that).</p>

<p>Whats unclear to me, is the preprocessing which should take place when feeding a sentence. The module <a href=""https://www.tensorflow.org/hub/modules/google/nnlm-en-dim128/1"" rel=""nofollow noreferrer"">documentation</a> says, that in the preprocessing step the inputj sentences gets splitted at the spaces.</p>

<p>However, when I run the following program, I only get a single vector:</p>

<pre><code>with tf.device(""/cpu:0""):
  embed = hub.Module(""https://tfhub.dev/google/nnlm-en-dim128/1"")

global_step1 = tf.train.get_or_create_global_step()
with tf.device(""/cpu:0""):
  embeddings = embed({""default"": [""Cat sat on mat""]})

with tf.train.MonitoredTrainingSession(is_chief=True) as sess:
  message_embeddings_cat = sess.run(embeddings)
  print(message_embeddings_cat.shape) # (result: (1, 128))
</code></pre>

<p>How do I get the embeddings for each word, and what does the single vector represents? A <em>fixed-dimensional representation</em> of the sentence, the <em>Unknown-Word</em> embedding or something else?</p>

<p>Thanks in advance!</p>

<p>Edit: It seems the result is a combined embedding created with <a href=""https://github.com/tensorflow/hub/blob/master/examples/text_embeddings/export.py#L130"" rel=""nofollow noreferrer""><code>tf.nn.embedding_lookup_sparse</code></a>. (Thanks for the confirmation @svsgoogle)</p>
",2018-04-28 16:34:50,863543,2147,https://stackoverflow.com/questions/50078749,Documentation Replication on Other Examples
50149953,Using tf.keras within Tensorflow,"<p>What is the correct way of using the <code>tf.keras</code> API. Can <code>tf.layers.*</code> be directly replaced with <code>tf.keras.layers</code>(Similarly activations or loss functions)? Is it necessary to import <code>tf.keras.backend</code> and do <code>set_learning_phase</code>? This doesnt seem to be explained on the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras"" rel=""nofollow noreferrer"">official TF docs</a> but is mentioned in this <a href=""https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"" rel=""nofollow noreferrer"">relatively old blog post</a>. </p>
",2018-05-03 08:06:20,3656081,3126,https://stackoverflow.com/questions/50149953,Lack of Alternative Solutions/Documentation
50210594,the function of 'bounding_boxes' and 'min_object_covered' in tf.image.sample_distorted_bounding_box?,"<p>How parameters 'bounding_boxes' and 'min_object_covered' control the generation of a single randomly distorted bounding box for an image in tf.image.sample_distorted_bounding_box? </p>

<p>I have read the <a href=""https://www.tensorflow.org/api_docs/python/tf/image/sample_distorted_bounding_box"" rel=""nofollow noreferrer"">function</a> in tensorflow api, but I still can not understand the proplem. Maybe I need a intuitive example.</p>
",2018-05-07 09:07:07,8307005,469,https://stackoverflow.com/questions/50210594,Requesting (Additional) Documentation/Examples
50222149,How to scan through tensor not at dimension 0?,"<p>The tensorflow document states that tf.scan scans on the list of tensors unpacked from elems on dimension 0.
The simplest version of scan repeatedly applies the callable fn to a sequence of elements from first to last. The elements are made of the tensors unpacked from elems on dimension 0.</p>

<p>My question is:
How to scan on the list of tensors on other dimension instead of dimension 0?
For example, 
I have a tensor, ref, defined as below.</p>

<pre><code>&gt;&gt;&gt; ref = tf.Variable(tf.ones([2,3,3],tf.int32))
....
&gt;&gt;&gt; print(ref.eval())
[[[1 1 1]
  [1 1 1]
  [1 1 1]]

 [[1 1 1]
  [1 1 1]
  [1 1 1]]]
</code></pre>

<p>I want to scan through the ref[1,0], ref[1,1], ref[1,2] and apply a function to each of the, ,say add 1.
That is to say, I want ref be after the operation</p>

<pre><code>&gt;&gt;&gt; print(ref.eval())
[[[1 1 1]
  [1 1 1]
  [1 1 1]]

 [[2 2 2]
  [2 2 2]
  [2 2 2]]]
</code></pre>

<p>Can I use tf.scan to do that? If yes, how?
If not, any how to do in other way?</p>

<p>Thanks.</p>
",2018-05-07 20:43:39,4987560,601,https://stackoverflow.com/questions/50222149,Documentation Replication on Other Examples
49003393,Tensorflow seq2seq Sequence loss function : trying to get per-iteration cross-entropy loss (to avoid OOM),"<p>I am trying to add a mechanism so that the cross entropy loss calculated in seq2seq.sequence_loss (<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss</a>) is done so not in a batch but per iteration</p>

<p>I tried to use tf.while_loop and tf.scan , but have been facing issues for 2 days. My (vain)attempt with tf.scan is below.</p>

<p>This function is supposed to replace and emulate the result of this one : <a href=""https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/contrib/seq2seq/python/ops/loss.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/contrib/seq2seq/python/ops/loss.py</a></p>

<p>Firstly , can it even be done? 
If yes , where am I messing up ?
Any help would be appreciated :D</p>

<pre><code>from __future__ import absolute_import
    from __future__ import division
    from __future__ import print_function
    import tensorflow as tf
    from tensorflow.python.framework import ops
    from tensorflow.python.ops import array_ops
    from tensorflow.python.ops import math_ops
    from tensorflow.python.ops import nn_ops



def sequence_loss(logits, targets, weights, average_across_timesteps=True, average_across_batch=True,
                  softmax_loss_function=None, name=None):
    timestep_del = array_ops.shape(logits)[1]
    num_classes = array_ops.shape(logits)[2]
    logi = array_ops.shape(logits)[0]

    timesteps = array_ops.reshape(logits, [-1, logi])
    logits_flat = array_ops.reshape(logits, [-1, num_classes])

    timestep_holder = tf.placeholder(tf.float32, shape=None, name='timestep_holder')
    stacked_tensors = tf.stack(values=[logits_flat, tf.to_float(targets)], axis=0)

    timesteps = math_ops.reduce_sum(weights, axis=[1], name='timestep_from_weight')

    with ops.name_scope(name, ""sequence_loss"", [logits, targets, weights]):

        def scan_func(nothing, stacked_tensors):

            logits_flat, targets = tf.unstack(value=stacked_tensors, axis=0)

            # reshaping logits to put in the softmax:
            logits_flatr = array_ops.reshape(logits_flat, [-1, timestep_del])

            scan_timestep = array_ops.reshape(logits_flat, [-1, logi])


            # reshaping target
            reshaped_target = array_ops.reshape(targets, [-1])

            # matmul to get logits for softmax per timestep

            logit_scan = tf.concat(values=[tf.to_float(logits_flatr), tf.to_float(scan_timestep)], name='logit_scan',
                                   axis=0)

            if softmax_loss_function is None:
                crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(labels=reshaped_target,
                                                                           logits=tf.to_float(logit_scan))
                crossent *= array_ops.reshape(weights, [-1])

            else:
                crossent = softmax_loss_function(labels=reshaped_target, logits=tf.to_float(logit_scan))
                crossent *= array_ops.reshape(weights, [-1])

            print(""\n the loss is :"", crossent)
            return crossent

        # elems : tuple of logits and label per TS
        init = tf.zeros_like(timesteps)

        print(""\n\n\n TIMESTEPS: \n\n:"", timesteps, ""\n\n\n Shape"", tf.shape(timesteps), ""\n\n"")

        scan_crossent = tf.scan(fn=scan_func, elems=timesteps, infer_shape=False, initializer=init)
        print(""\n\n\n tf.scan output : \n\n:"", scan_crossent, ""\n\n\n Shape"", tf.shape(scan_crossent), ""\n\n"")



    return scan_crossent

""""""GOOGLE DOCUMENTAION:Weighted cross-entropy loss for a sequence of logits.
      Depending on the values of `average_across_timesteps` and
      `average_across_batch`, the return Tensor will have rank 0, 1, or 2 as these
      arguments reduce the cross-entropy at each target, which has shape
      `[batch_size, sequence_length]`, over their respective dimensions. For
      example, if `average_across_timesteps` is `True` and `average_across_batch`
      is `False`, then the return Tensor will have shape `[batch_size]`.
      Args:
        logits: A Tensor of shape
          `[batch_size, sequence_length, num_decoder_symbols]` and dtype float.
          The logits correspond to the prediction across all classes at each
          timestep.

        targets: A Tensor of shape `[batch_size, sequence_length]` and dtype
          int. The target represents the true class at each timestep.

        weights: A Tensor of shape `[batch_size, sequence_length]` and dtype
          float. `weights` constitutes the weighting of each prediction in the
          sequence. When using `weights` as masking, set all valid timesteps to 1
          and all padded timesteps to 0, e.g. a mask returned by `tf.sequence_mask`.

        average_across_timesteps: If set, sum the cost across the sequence
          dimension and divide the cost by the total label weight across timesteps.

        average_across_batch: If set, sum the cost across the batch dimension and
          divide the returned cost by the batch size.
        softmax_loss_function: Function (labels, logits) -&gt; loss-batch
          to be used instead of the standard softmax (the default if this is None).
          **Note that to avoid confusion, it is required for the function to accept
          named arguments.**
        name: Optional name for this operation, defaults to ""sequence_loss"".
      Returns:
        A float Tensor of rank 0, 1, or 2 depending on the
        `average_across_timesteps` and `average_across_batch` arguments. By default,
        it has rank 0 (scalar) and is the weighted average cross-entropy
        (log-perplexity) per symbol.
      Raises:
        ValueError: logits does not have 3 dimensions or targets does not have 2
                    dimensions or weights does not have 2 dimensions.
      """"""
</code></pre>
",2018-02-27 07:33:18,9250129,21,https://stackoverflow.com/questions/49003393,Documentation Ambiguity
48981022,what is the difference between tf.nn.convolution and tf.nn.conv2d?,"<p>I want to make dilated convolution on a feature. In tensorflow I found <code>tf.nn.convolution</code> and <code>tf.nn.conv2d</code>. But <code>tf.nn.conv2d</code> doesn't seem to support dilated convolution. </p>

<p>So I tried using <code>tf.nn.convolution</code>. </p>

<p>Do the 2 formulations below give the same result?</p>

<p><code>
tf.nn.conv2d(x, w, strides=[1, 1, 2, 2], padding='SAME',data_format='NCHW')
</code></p>

<p><code>
tf.nn.convolution(x, w, strides=[1, 1, 2, 2], padding='SAME',data_format='NCHW')
</code></p>
",2018-02-26 03:28:05,9411147,31,https://stackoverflow.com/questions/48981022,Documentation Replication on Other Examples
48311823,regarding tf.nn.conv1d and its corresponding transpose operation,"<p>In the latest tensorflow version, there is <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose"" rel=""nofollow noreferrer"">tf.nn.conv2d_transpose</a> for the 2D deconvolution operation. However, there is no corresponding 1D deconvolution operation for <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv1d"" rel=""nofollow noreferrer"">tf.nn.conv1d</a>. How to perform the deconvolution for 1D data?</p>
",2018-01-17 23:47:44,288609,12685,https://stackoverflow.com/questions/48311823,Inadequate Examples
50226274,how to explain the output of tf.rank in tensorflow,"<p>I am new in tensorflow and have a question about tf.rank method.</p>

<p>In the doc <a href=""https://www.tensorflow.org/api_docs/python/tf/rank"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/rank</a> there is a simple example about the tf.rank:</p>

<pre><code># shape of tensor 't' is [2, 2, 3]
t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])
tf.rank(t)  # 3
</code></pre>

<p>But when I run the code below:</p>

<pre><code>t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])
print(tf.rank(t))  # 3
</code></pre>

<p>I get output like:</p>

<pre><code>Tensor(""Rank:0"", shape=(), dtype=int32)
</code></pre>

<p>Why can I get the output of ""3""?</p>
",2018-05-08 05:15:55,4710918,327,https://stackoverflow.com/questions/50226274,Documentation Replication on Other Examples
50252720,How to combine prefetch_to_device with make_initializer,"<p><a href=""https://github.com/tensorflow/tensorflow/releases/tag/v1.8.0"" rel=""nofollow noreferrer"">Tensorflow 1.8</a> has introduced <code>tf.contrib.data.prefetch_to_device</code>,
which can be used with <code>tf.data.Dataset.apply</code>, according to <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/data/prefetch_to_device"" rel=""nofollow noreferrer"">the official documentation</a>.</p>

<p>I have written some custom data loading, for which I would like to utilize this to prefetch to GPU. The problem is that this operation needs to be the last one in all transformations of the dataset.
I am using <code>tf.data.Iterator.make_initializer</code> and <code>tf.data.Iterator.from_structure</code> as follows.
This is a minimal example that raises the error.</p>

<pre><code>import tensorflow as tf

class MyData(object):
    def __call__(self):
         return range(100)

expected_shapes = []
expected_types = tf.int32
iterator = tf.data.Iterator.from_structure(output_types=expected_types, output_shapes=expected_shapes)
dataset = tf.data.Dataset.from_generator(MyData(), output_types=expected_types, output_shapes=expected_shapes)

prefetch_op = tf.contrib.data.prefetch_to_device(device=""/gpu:0"")
dataset = dataset.apply(prefetch_op)

# This raises NotImplementedError: `prefetch_to_device()` must be the last transformation in a dataset pipeline.
initializer = iterator.make_initializer(dataset)
</code></pre>

<p>Of course, this does not happen when I turn the order around, but then the prefetching transformation is not taken into account for the initializer.</p>

<pre><code>initializer = iterator.make_initializer(dataset)
dataset = dataset.apply(prefetch_op)
</code></pre>

<p>How can I get this to work to create the initializer after telling it to prefetch? Or is that simply not possible (currently)?
I would like to avoid having to create a new <code>Iterator</code>, unlike <a href=""https://github.com/tensorflow/tensorflow/commit/4681562607bf4001ecd61492f1e7567be9212c6f"" rel=""nofollow noreferrer"">this test case from tensorflow</a>.</p>
",2018-05-09 11:53:28,3344139,4597,https://stackoverflow.com/questions/50252720,Documentation Replication on Other Examples
50259009,How to modify the return tensor from tf.nn.embedding_lookup()?,"<p>I want to use <code>scatter_nd_update</code> to change the content of the tensor returned from <code>tf.nn.embedding_lookup()</code>. However, the returned tensor is not mutable, and the <code>scatter_nd_update()</code> require an mutable tensor as input.
I spent a lot of time trying to find a solution, including using <code>gen_state_ops._temporary_variable</code> and using <code>tf.sparse_to_dense</code>, unfortunately all failed.</p>

<p>I wonder is there a beautiful solution toward it?</p>

<pre><code>with tf.device('/cpu:0'), tf.name_scope(""embedding""):
            self.W = tf.Variable(
                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),
                name=""W"")
            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)
            updates = tf.constant(0,shape=[embedding_size])
            for i in range(1,sequence_length - 2):
                indices = [None,i]
                tf.scatter_nd_update(self.embedded_chars,indices,updates)
            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)
</code></pre>
",2018-05-09 17:30:39,4987560,601,https://stackoverflow.com/questions/50259009,Documentation Replicability
50442156,Loading a model from tensorflow SavedModel onto mutliple GPUs,"<p>Let's say someone hands me a TF SavedModel and I would like to replicate this model on the 4 GPUs I have on my machine so I can run inference in parallel on batches of data. Are there any good examples of how to do this? </p>

<p>I can load a saved model in this way:</p>

<pre><code>def load_model(self, saved_model_dirpath):
    '''Loads a model from a saved model directory - this should 
       contain a .pb file and a variables directory'''

    signature_key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY
    input_key = 'input'
    output_key = 'output'

    meta_graph_def = tf.saved_model.loader.load(self.sess, [tf.saved_model.tag_constants.SERVING],
                                                saved_model_dirpath)
    signature = meta_graph_def.signature_def

    input_tensor_name = signature[signature_key].inputs[input_key].name
    output_tensor_name = signature[signature_key].outputs[output_key].name

    self.input_tensor = self.sess.graph.get_tensor_by_name(input_tensor_name)
    self.output_tensor = self.sess.graph.get_tensor_by_name(output_tensor_name)
</code></pre>

<p>..but this would require that I have a handle to the session. For models that I have written myself, I would have access to the inference function and I could just call it and wrap it using <code>with tf.device()</code>, but in this case, I'm not sure how to extract the inference function out of a Saved Model. Should I load 4 separate sessions or is there a better way? Couldn't find much documentation on this, but apologies in advance if I missed something. Thanks!</p>
",2018-05-21 04:50:14,3953896,63,https://stackoverflow.com/questions/50442156,Inadequate Examples
50454095,tf.gradients - dimensions of output,"<p>Here is my code: </p>

<pre><code>import tensorflow as tf
tf.reset_default_graph()
x = tf.placeholder(tf.float32, [None, 3],name='x')
W_1 = tf.get_variable('W_1', [3,3], dtype = tf.float32, initializer=tf.constant_initializer(1.0))
layer_out = tf.matmul(x, W_1, name = 'layer_out')
sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run([tf.gradients(layer_out, [x])], feed_dict = {x: np.array([[1,7,5]])} )
</code></pre>

<p>it returns:</p>

<pre><code>[[array([[3., 3., 3.]], dtype=float32)]]
</code></pre>

<p>I am expecting to get 3 by 3 matrix or as per <code>tf.gradients</code> docs list of dim 3 with 3 elements for each list entry.</p>

<p>What I am missing?</p>

<p><strong>UPDATE:</strong></p>

<p>I see in docs <a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">tf.gradients</a></p>

<pre><code>A list of sum(dy/dx) for each x in xs
</code></pre>

<p>but why sum and how do I get all entries of Jacobian?</p>
",2018-05-21 17:45:27,1700890,7336,https://stackoverflow.com/questions/50454095,Lack of Alternative Solutions/Documentation
50486241,Tensorflow: tf.while_loop() with vector condition,"<p>The function tf.while_loop() (<a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/while_loop</a>) repeats the body ""b"" while the condition ""c"" is true. For example:</p>

<pre><code>import tensorflow as tf    
i = tf.constant(0)
c = lambda i: tf.greater(10,i)
b = lambda i: tf.add(i, 1)
r = tf.while_loop(c, b, [i])
</code></pre>

<p>How can I adjust this, when the condition is a vector, e.g.</p>

<pre><code>c = lambda i: tf.greater([10,10],[i,i])
</code></pre>

<p>?</p>

<p>The problem is that the above returns a vector (instead of True or False), same as e.g.</p>

<pre><code>tf.greater([2,2],[1,1])
</code></pre>

<p>I need something that returns true when all the vector elements are true, and false otherwise. I would suggest</p>

<pre><code>i = tf.constant(0)
c = lambda i: True if all(item == True for item in tf.greater([10,10],[i,i]))==True else False
b = lambda i: tf.add(i, 1)
r = tf.while_loop(c, b, [i])
</code></pre>

<p>But this does not work, with the following error:</p>

<pre><code>TypeError: `Tensor` objects are not iterable when eager execution is not enabled. To iterate over this tensor use `tf.map_fn`.
</code></pre>

<p>Any ideas?</p>
",2018-05-23 10:38:47,2594778,858,https://stackoverflow.com/questions/50486241,Documentation Replication on Other Examples
50500579,what is the difference between tf.nn.max_pool() and tf.layers.max_pooling2d(),"<p>I am a beginner of tensorflow,i have met two methods about create max_pool layer these days. one is ""tf.nn.max_pool()"" and the other is ""tf.layers.max_pooling2d()"".i want to learn about its difference,and when to use them suitably.based on this ,i have read its official document and searched in google,it is not any help at all.i have searched it in stackoverflow , there is a similar answer(<a href=""https://stackoverflow.com/questions/42785026/tf-nn-conv2d-vs-tf-layers-conv2d"">tf.nn.conv2d vs tf.layers.conv2d</a>）but it didn't solve my problem.does any one can help me? thanks in advance.</p>
",2018-05-24 03:43:03,7955072,731,https://stackoverflow.com/questions/50500579,Inadequate Examples
50560013,"Tensorflow, multi-label confusion matrix","<p>I am trying to figure out how to the generate a confusion matrix for a multi-label classification task using neural networks. I previously managed to calculate the accuracy using the function &quot;intersection&quot;, since for that I did not care about any ordering.</p>
<pre><code>intersection = tf.sets.set_intersection(predictions, labels)
</code></pre>
<p>However, in order to calculate the confusion matrix, I do care about the indexing order of the predictions/labels. And since the labels have always the same value (<code>1,1</code> or <code>0.5,0.5</code>) there is no possible sorting according to higher/lower value.</p>
<p>I wonder:</p>
<p><strong>1) Is it possible to calculate a confusion matrix for the multi-label classification task?</strong></p>
<p><strong>2) How would that be implemented ?</strong></p>
<p><strong>3) How can you handle the case of failure in predicting both labels? Since it is not possible to know which confusion belongs to which prediction.</strong></p>
<p><strong>4) What is the logic behind the sorting of the function tf.nn.top_k()</strong></p>
<p>Below I show an example of the code that I was trying to use.</p>
<pre><code>import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

Z = np.array([[7.0, 3.0, 5.0, 1.0, 0.0, 6.0],[2.0, 3.0, 4.0, 1.0, 3.25, 2.2], [2.0 , 5.0, 1.0, 7.0, 0.0, 8.0]])
Y = np.array([[0.5, 0, 0, 0.0, 0, 0.5],[0, 0.0, 0.5, 0, 0.5, 0], [0,0,0,0.5,0,0.5]])

_, predicted_softmax = tf.nn.top_k(tf.nn.softmax(Z), k = 2, sorted = False)
_ , labels = tf.nn.top_k(Y, k = 2, sorted = False)

with tf.Session() as sess:
    # reshape to (6,1) because there is 2 correct values per sample(2*3)
    print(predicted_softmax.eval().reshape(6,1))
    print(labels.eval().reshape(6,1))
    predicted = predicted_softmax.eval().reshape(6,1)
    labels_idx = labels.eval().reshape(6,1)

class_labels = np.arange(6)
cnf_matrix_train = confusion_matrix(labels_idx, predicted, labels = class_labels)

print(cnf_matrix_train)
</code></pre>
<p>I don't really get why the output of predicted_softmax is:</p>
<pre><code>[[5] [0] [4] [2] [3] [5]] , 
</code></pre>
<p>I was expecting [5] [3] for the last two terms. There is no any logic to this output. In the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/top_k"" rel=""nofollow noreferrer"">documentation</a> they don't specify anything about the ordering in the case that <code>sorted = False</code> thought, but I was expecting some consistent behavior.</p>
<p>Thanks for any help!</p>
",2018-05-28 06:02:06,9527947,487,https://stackoverflow.com/questions/50560013,Documentation Completeness
50635729,ValueError: Cannot use 'Enter' as input to 'Merge' because 'Enter' is in a while loop,"<p>Problem occured when I use tf.nn.dynamic_rnn,I don't quite understand what does this 'Enter' and 'Merge' mean in this context. Hope you can help me, thanks!</p>

<pre><code># here is python code
value, _ = tf.nn.dynamic_rnn(lstmCell, wordvec_tensor, dtype=tf.float32)
</code></pre>

<p>Here is the <a href=""https://i.stack.imgur.com/aHnyh.png"" rel=""nofollow noreferrer"">error log picture</a></p>
",2018-06-01 03:32:42,4265099,356,https://stackoverflow.com/questions/50635729,Documentation Replication on Other Examples
50724495,Train and validate using tensorflow estimator,"<p>I have created a shallow NN using tf.estimator API. I would like to something similar to the hyperparameter search explained in here <a href=""https://www.youtube.com/watch?time_continue=948&amp;v=eBbEDRsCmv4"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?time_continue=948&amp;v=eBbEDRsCmv4</a> at TensorFlow Dev Summit.</p>

<p>I could not find any updated documentation about how can you do this. I have the following code (I will try to simplify as much as possible):</p>

<pre><code># Define nn architecture
def neural_net(features):
    input_layer = tf.cast(features['x'], tf.float32)
    hidden_layer = nn_layer(input_layer, 10, 'hidden_layer', act=tf.nn.relu)
    out_layer = nn_layer(hidden_layer, 2, 'out_layer', act=tf.nn.relu)
    return out_layer

# Define model function
def model_fn(features, labels, mode):
    # Build the neural network
    logits = neural_net(features&lt;9


    with tf.name_scope('loss'):
    # Define loss and optimizer
        loss = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)

    # Configure the Training
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(
        loss=loss,
        global_step=tf.train.get_global_step())

        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)


nn_classifier = tf.estimator.Estimator(model_fn=model_fn)


train_input_fn = tf.estimator.inputs.numpy_input_fn(
            x={""x"": train_data},
            y=train_labels,
            batch_size=100,
            num_epochs=None,
            shuffle=True)

nn_classifier.train(
        input_fn=train_input_fn,
        steps=20000
        )
</code></pre>

<p>Executing this code I can obtain the summary for the loss and observe it in Tensorboard. But imagine I want to obtain different curves. Let's say that I want to see how the loss evolves with the number of samples, so I would train two models with different sample size. Or two models with a different architecture... whatever.</p>

<p>How can I get these two curves in Tensorboard?</p>
",2018-06-06 15:45:22,8380638,1662,https://stackoverflow.com/questions/50724495,Documentation Replication on Other Examples
50763281,Does tensorflow only optimize/update tf.get_variable and tf.Variable?,"<p>Does TensorFlow only optimize <code>tf.Variable</code> and <code>tf.get_variable</code> tensors in the computational graph?</p>
",2018-06-08 14:51:43,7887773,77,https://stackoverflow.com/questions/50763281,Documentation Replicability
50825446,Restoring a trained generator network in DCGAN,"<p>I have a question regarding the saving and storing models in tensorflow. I know how to save a model with tf.train.Saver() and load it later through meta file. My problem is this:</p>

<p>I have trained a variant of DCGAN (Deep Convolution GAN), now I want to use only generator network for other tasks. Unfortunately, I do not know how to get entire generator network such that if I feed it with a new vector z, it generates an output based on the trained parameters. All the example I found in the stackoverflow, or tensorflow documentation, just mention very simple operations with two numbers. This is not I want. I want to understand if you have trained a giant network, say with 50 layers, how to load it and feed it with new input and get the output without going into the different parameters and layers in the trained network. I want to load it as a blackbox.</p>
",2018-06-12 20:34:38,9932068,7,https://stackoverflow.com/questions/50825446,Documentation Replication on Other Examples
50828432,tensorflow: how to make distributed training with tf.estimator.train_and_evaluate,"<p>refer to  tf.estimator.train_and_evaluate example on <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate</a>
I want to make the example to run distributed, but it seems doesn't work that the training process did not start in distributed mode.</p>

<p><strong>my question is : 
what can I do For Making the source code run distributed?</strong> </p>

<p>platform: system: Ubuntu 18
          tensorflow: v1.8</p>

<p>the following log is my source code and operate step:</p>

<p><strong>1 source code:</strong></p>

<pre><code>import tensorflow as tf
import os
import sys
import json
import logging
import numpy as np
x = np.random.rand(1000)
y = np.random.choice([0,1],1000)
def data_input():
    ret={}
    ret['x'] = x   
    y_batch = y 
    print ""data""
    return ret,y_batch  
tf.logging.set_verbosity(tf.logging.DEBUG)
my_feature_columns=[]
v_feature_column = tf.feature_column.numeric_column(key=""x"",shape=[])
my_feature_columns.append(v_feature_column)

estimator = tf.estimator.DNNClassifier(
    feature_columns=my_feature_columns,
    hidden_units=[1024, 512, 256],
    model_dir='/home/clxman/tf/')


train_spec = tf.estimator.TrainSpec(input_fn=lambda:data_input(), max_steps=1000)
eval_spec = tf.estimator.EvalSpec(input_fn=lambda:data_input())

tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</code></pre>

<p><strong>2 run it on single mode in which the train run well. looking the following log</strong> </p>

<p>clxman@clxman-VirtualBox:~/test$ python test_c.py</p>

<pre><code>/home/clxman/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters

INFO:tensorflow:Using default config.

INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4e37077890&gt;, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/home/clxman/tf/', '_global_id_in_cluster': 0, '_save_summary_steps': 100}

INFO:tensorflow:Running training and evaluation locally (non-distributed).

INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.
data
INFO:tensorflow:Calling model_fn.

DEBUG:tensorflow:Transforming feature_column _NumericColumn(key='x', shape=(), default_value=None, dtype=tf.float32, normalizer_fn=None).

INFO:tensorflow:Done calling model_fn.

INFO:tensorflow:Create CheckpointSaverHook.

INFO:tensorflow:Graph was finalized.

2018-06-12 23:50:25.702344: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2


INFO:tensorflow:Running local_init_op.

INFO:tensorflow:Done running local_init_op.

**INFO:tensorflow:Saving checkpoints for 1 into /home/clxman/tf/model.ckpt**.

**INFO:tensorflow:loss = 693.219, step = 1**


INFO:tensorflow:global_step/sec: 8.12489


**INFO:tensorflow:loss = 691.08575, step = 101 (12.309 sec)**

INFO:tensorflow:global_step/sec: 8.11321

INFO:tensorflow:loss = 690.9834, step = 201 (12.325 sec)
</code></pre>

<p><strong>3  config TF_CONFIG and start script  by command line Respectively</strong></p>

<pre><code>**chief session command line：**

clxman@clxman-VirtualBox:~/test$ TF_CONFIG='{
    ""cluster"": {
        ""chief"": [""192.168.6.99.123:2222""],
        ""worker"": [""192.168.6.99.123:2300""],
        ""ps"": [""192.168.6.99.123:2400""]
    },
    ""task"": {""type"": ""chief"", ""index"": 0}
}'  python test_c.py

**ps session comand line:**

clxman@clxman-VirtualBox:~/test$ TF_CONFIG='{
    ""cluster"": {
        ""chief"": [""192.168.6.99.123:2222""],
        ""worker"": [""192.168.6.99.123:2300""],
        ""ps"": [""192.168.6.99.123:2400""]
    },
    ""task"": {""type"": ""ps"", ""index"": 0}
}'  python test_c.py

**worker session comand line:**

clxman@clxman-VirtualBox:~/test$ TF_CONFIG='{
    ""cluster"": {
        ""chief"": [""192.168.6.99.123:2222""],
        ""worker"": [""192.168.6.99.123:2300""],
        ""ps"": [""192.168.6.99.123:2400""]
    },
    ""task"": {""type"": ""worker"", ""index"": 0}
}'  python test_c.py

**evaluator session command line:**

clxman@clxman-VirtualBox:~/test$ TF_CONFIG='{
    ""cluster"": {
        ""chief"": [""192.168.6.99.123:2222""],
        ""worker"": [""192.168.6.99.123:2300""],
        ""ps"": [""192.168.6.99.123:2400""]
    },
    ""task"": {""type"": ""evaluator"", ""index"": 0}
}'  python test_c.py
</code></pre>

<p><strong>4  the following log is from the chief session,  we can see the training process did not start. 
   the string ""data"" means that the training process has called the data_input function which feeds train data</strong> </p>

<pre><code>INFO:tensorflow:Using default config.

INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_train_distribute': None, '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0024f18d0&gt;, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://192.168.6.99.123:2222', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/home/clxman/tf/', '_global_id_in_cluster': 0, '_save_summary_steps': 100}

INFO:tensorflow:Start Tensorflow server.

2018-06-12 23:23:25.694865: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2

2018-06-12 23:23:25.697065: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -&gt; {0 -&gt; localhost:2222}

2018-06-12 23:23:25.697159: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; 192.168.6.99.123:2400}

2018-06-12 23:23:25.697180: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; 192.168.6.99.123:2300}

2018-06-12 23:23:25.698882: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:332] Started server with target: grpc://localhost:2222

**data**

INFO:tensorflow:Calling model_fn.

DEBUG:tensorflow:Transforming feature_column _NumericColumn(key='x', shape=(), default_value=None, dtype=tf.float32, normalizer_fn=None).

INFO:tensorflow:Done calling model_fn.

INFO:tensorflow:Create CheckpointSaverHook.

INFO:tensorflow:Graph was finalized.
</code></pre>
",2018-06-13 02:52:01,9933306,1,https://stackoverflow.com/questions/50828432,Documentation Replication on Other Examples
50840759,"Incorrect name returned in Tensorflow causes ""Tensor which does not exist"" error while invoking get_tensor_by_name","<p>As per the <a href=""https://www.tensorflow.org/programmers_guide/graphs#naming_operations"" rel=""nofollow noreferrer"" title=""description"">documentation</a> TensorFlow would append ""_1"", ""_2"", and so on to the name in tf.Graph namespace, in order to make it unique.  Here I define two convolutional operations.  It is expected that the first one will be named as ""conv2d"" and second one ""conv2d_1"".  But when I try to obtain the name of the second convolution it returns ""conv2d_2"".  I causes error when I try to invoke get_tensor_by_name. Here is the code:</p>

<pre><code>import numpy as np
import tensorflow as tf
import os

x = tf.constant(np.random.randn(1,2,2,1), dtype=tf.float32)
kernel_size = (1,1)
no_of_out = 20
strides = (1,1)
conv_out1 = tf.layers.conv2d(x, 10, (1,1), (1,1))
conv_out2 = tf.layers.conv2d(x, 10, (1,1), (1,1))

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print conv_out1.name # conv2d/BiasAdd:0 .  This value is correct
    print conv_out2.name # conv2d_2/BiasAdd:0 .  This value is incorrect.  It should be conv2d_1/BiasAdd:0
    conv_weights1 = tf.get_default_graph().get_tensor_by_name(os.path.split(conv_out1.name)[0] + '/kernel:0')
    conv_weights2 = tf.get_default_graph().get_tensor_by_name('conv2d_1/kernel:0')  
    conv_weights2 = tf.get_default_graph().get_tensor_by_name(os.path.split(conv_out2.name)[0] + '/kernel:0')
</code></pre>

<p>I could not understand why conv_out2.name returns ""conv2d_2"" instead of ""conv2d_1""</p>
",2018-06-13 15:16:01,8284911,45,https://stackoverflow.com/questions/50840759,Documentation Ambiguity
50945733,why this Tensorflow code raises tf.errors.OutOfRangeError?,"<p>This Tensorflow code below raises a <code>tf.errors.OutofRangeError</code>:</p>



<pre><code>try:
     while not coord.should_stop():        
          vector1,vector2,vector3,vector4,vector5,labels = sess.run([train_vector1,train_vector2,train_vector3,train_vector4,train_vector5,train_labels])
          shape1 = tf.shape(vector1)
          print (sess.run(shape1))
except tf.errors.OutOfRangeError:
   print ('tf.errors.OutOfRangeError')

finally:
    coord.request_stop()
</code></pre>

<p>Why is <code>tf.errors.OutofRangeError</code> printed when all the samples are read?
It seems unreasonable.</p>
",2018-06-20 10:13:58,5030342,183,https://stackoverflow.com/questions/50945733,Documentation Replicability
50988466,Using L-BFGS optimizer with Tensorflow estimator API,"<p>I am using Tensorflow Estimator API but haven't figured out how to use the L-BFGS optimizer available at <code>tf.contrib.opt.ScipyOptimizerInterface</code>.</p>

<p>It seems the estimator API expects some optimizer from the <code>tf.train</code> module but no BFGS implementation is available there. The only one defined in <code>contrib</code> does not follow the same interface.</p>

<p>To be more specific, in the <a href=""https://www.tensorflow.org/get_started/custom_estimators#train"" rel=""nofollow noreferrer"">official tutorial</a> to define custom estimators, it's shown how to use the <code>AdagradOptimizer</code>:</p>

<pre><code>optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)
train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
</code></pre>

<p>However, the API of the <code>ScipyOptimizerInterface</code> is as follows:</p>

<pre><code>optimizer = ScipyOptimizerInterface(loss, options={'maxiter': 100})

with tf.Session() as session:
    optimizer.minimize(session)
</code></pre>

<p>Taking a full example:</p>

<pre><code>from sklearn import datasets
import numpy as np


def _custom_model_fn(features, labels, mode, feature_columns):

    predictions = tf.feature_column.linear_model(features, feature_columns)
    predictions = tf.reshape(predictions, [-1])

    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {'predictions': predictions}
        return tf.estimator.EstimatorSpec(mode, predictions=predictions)

    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions,
                                        reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)

    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)

    # Create training op.
    assert mode == tf.estimator.ModeKeys.TRAIN

    # train_op = tf.contrib.opt.ScipyOptimizerInterface(loss, options={'maxiter': 10})

    optimizer = tf.train.FtrlOptimizer(learning_rate=1.)
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode,
                                      predictions=predictions,
                                      loss=loss,
                                      train_op=train_op)

class MyRegressor(tf.estimator.Estimator):
    def __init__(self, feature_columns, model_dir=None, config=None):

        def _model_fn(features, labels, mode, config):
            return _custom_model_fn(features, labels, mode, feature_columns)

        super(MyRegressor, self).__init__(model_fn=_model_fn)

# Load the diabetes dataset
diabetes = datasets.load_diabetes()
diabetes_X = diabetes.data[:, np.newaxis, 2]
diabetes_y = diabetes.target

# Create the custom estimator and train it
feature_columns = [tf.feature_column.numeric_column('x')]
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'x': np.array(diabetes.data[:, 2])},
    y=np.array(diabetes.target),
    num_epochs=None,
    shuffle=True)
myregressor = MyRegressor(feature_columns)
myregressor.train(train_input_fn, steps=10000)
</code></pre>

<p>If I un-comment the line to use the <code>ScipyOptimizer</code> instead, I obviously get an error as follows</p>

<pre><code>TypeError: train_op must be Operation or Tensor, given: &lt;tensorflow.contrib.opt.python.training.external_optimizer.ScipyOptimizerInterface object
</code></pre>

<p>Is there an easy way to use the Scipy optimizer?</p>

<p>Thanks in advance.</p>
",2018-06-22 12:57:37,2689882,133,https://stackoverflow.com/questions/50988466,Documentation Replication on Other Examples
50998956,How to use tf.nn.avg_pool to get same results as by tf.reduce_mean,"<p>In the following code, I want to use <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool"" rel=""nofollow noreferrer"">tf.nn.avg_pool</a> to get the same results as when I use <a href=""https://www.tensorflow.org/api_docs/python/tf/reduce_mean"" rel=""nofollow noreferrer"">tf.reduce_mean</a>. But how to fix the parameters of tf.nn.avg_pool to get similar results?</p>

<pre><code>input = tf.Variable(tf.random_normal([2,16,16,200]))
filter= tf.Variable(tf.random_normal([16,16,200,1]))
def depth_conv2d(input):
    return tf.nn.depthwise_conv2d(input,filter, strides=[1,4,4,1],padding= 'VALID')

depth_conv_out = depth_conv2d(input)

Relu = tf.nn.relu(depth_conv_out)
avg_pooling = tf.reduce_mean(Relu, reduction_indices=[3], keep_dims=True) 
sess = tf. InteractiveSession()
sess.run(tf.initialize_all_variables())

print(""convolution result"")
print (depth_conv_out.get_shape())
print (""Relu result"")
print (Relu.eval())
print(Relu.get_shape())
print (""Average pooling"")
print (avg_pooling.get_shape())
</code></pre>
",2018-06-23 07:25:25,9854153,55,https://stackoverflow.com/questions/50998956,Documentation Replication on Other Examples
51077930,tf.image.resize_bilinear()-when align_corners=False,"<p>I am using Tensorflow 1.4.0</p>

<p>The Tensorflow tf.image.resize_bilinear() has an argument called 'align_corners' and I am confused with the behavior when we set it to be False. In the <a href=""https://www.tensorflow.org/api_docs/python/tf/image/resize_bilinear"" rel=""noreferrer"">official document</a>, it says:</p>

<blockquote>
  <p>align_corners: An optional bool. Defaults to False. If true, the centers of the 4 corner pixels of the input and output tensors are aligned, preserving the values at the corner pixels. Defaults to false.</p>
</blockquote>

<p>When I use tf.image.resize_bilinear() with align_corners=True in the following program:</p>

<pre><code>import tensorflow as tf
sess = tf.Session()
x = tf.Variable(tf.Variable([[[[1],[2]],[[3],[4]]]]))
pooling_output_size = [4, 4]
pool_output = tf.image.resize_bilinear(x, pooling_output_size,align_corners=True)
sess.run(tf.global_variables_initializer())
print pool_output.eval(session=sess)
</code></pre>

<p>it outputs</p>

<pre><code>[[[[1.       ]
   [1.3333334]
   [1.6666667]
   [2.       ]]

  [[1.6666667]
   [2.       ]
   [2.3333335]
   [2.6666667]]

  [[2.3333335]
   [2.6666665]
   [3.       ]
   [3.3333335]]

  [[3.       ]
   [3.3333333]
   [3.6666667]
   [4.       ]]]]
</code></pre>

<p>which corners are correctly aligned.</p>

<p>However when I set the align_corners=False, I got the following weird outputs</p>

<pre><code>[[[[1. ]
   [1.5]
   [2. ]
   [2. ]]

  [[2. ]
   [2.5]
   [3. ]
   [3. ]]

  [[3. ]
   [3.5]
   [4. ]
   [4. ]]

  [[3. ]
   [3.5]
   [4. ]
   [4. ]]]]
</code></pre>

<p>Is there anyone who understand why Tensorflow will use this weird implementation? I didn't find any explanation anywhere.</p>

<p>Actually PyTorch's bilinear upsampling has the align_corner argument too, when you set it to True, it works well. But if you set it to False, it performs a differnet behaviour to Tensorflow's. I am totally confused with their implementations now (maybe just use align_corners=True will be fine).</p>
",2018-06-28 08:15:39,9809485,51,https://stackoverflow.com/questions/51077930,Documentation Ambiguity
51247229,"Cannot use custom dataset in official resnet model, raised tensorflow.python.framework.errors_impl.CancelledError","<p>These days I modified the official <code>cifar10_main.py</code> , in order to train the kaggle dogs_cats_redux dataset.</p>

<p>First, I created the tfrecord files, following the standard pipeline, you guys can download the tfrecord files <a href=""https://drive.google.com/open?id=1P7zGwxIY0ynFAN5PrmK71IMu51m4U2Rt"" rel=""nofollow noreferrer"">here.</a></p>

<p>And then, I wrote some tfrecord parsing functions and dogs_cats_model class, and the rest of the code remain the same as the original resnet repo, you guys can check my <code>main.py</code> <a href=""https://gist.github.com/JustinhoCHN/d6d4534d322595dc562ff0d0d59b8a59"" rel=""nofollow noreferrer"">here</a>.</p>

<p>But when I run the <code>main.py</code>, it raised the CancelledError:</p>

<pre><code>Traceback (most recent call last):
  File ""main.py"", line 326, in &lt;module&gt;
    main(argv=sys.argv)
  File ""main.py"", line 321, in main
    shape=[_HEIGHT, _WIDTH, _NUM_CHANNELS])
  File ""/home/jto/projects/dogs_cats_tf/official/resnet/resnet_run_loop.py"", line 396, in resnet_main
    max_steps=flags.max_train_steps)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 843, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 859, in _train_model_default
    saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 1059, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 567, in run
    run_metadata=run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1043, in run
    run_metadata=run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1134, in run
    raise six.reraise(*original_exc_info)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/six.py"", line 686, in reraise
    raise value
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1119, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1191, in run
    run_metadata=run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 971, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.CancelledError: Queue '_2_input_producer' is already closed.
         [[Node: input_producer/input_producer_Close = QueueCloseV2[cancel_pending_enqueues=false](input_producer)]]
         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,3], [?,2]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
         [[Node: IteratorGetNext/_2401 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_534_IteratorGetNext"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
</code></pre>

<p>I've googled so many solutions, most of them say that's because somehow the data queue is stopped, or we didn't start the queue correctly, solutions like:</p>

<pre><code># Start the data queue
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess, coord)
</code></pre>

<p>But the official resnet_run_loop.resnet_main() using tf.estimator.Estimator to train the model, the source code doesn't need to start the queue like that, so how can we solve this problem? Any ideas would be appreciate.</p>

<p>system info:
ubuntu 16.04 LTS
tensorflow-gpu v1.8.0
cuda 9.0
cudnn 7.1</p>

<p>The github issue is <a href=""https://github.com/tensorflow/models/issues/4724"" rel=""nofollow noreferrer"">here.</a></p>
",2018-07-09 13:51:26,8859796,11,https://stackoverflow.com/questions/51247229,Documentation Replication on Other Examples
51248442,Behavior of the parameter 'throttle_secs' in tf.estimator.EvalSpec for use in tf.estimator.train_and_evaluate,"<p>I am using tensorflow's train_and_eval function as in the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">example</a>. Therefore i create an instance of tf.estimator.EvalSpec, according to </p>

<pre><code>eval_spec = tf.estimator.EvalSpec(input_fn=...,throttle_secs=60).
</code></pre>

<p>According to its <a href=""http://eval_spec%20=%20tf.estimator.EvalSpec(input_fn=lambda:%20tf_data_utils.monuseg_input_func(mdl_info,train=False,normalize=True),throttle_secs=60*5)"" rel=""nofollow noreferrer"">documentation</a> the explanation of the parameter throttle_secs states that </p>

<p>""Of course, evaluation does not occur if no new checkpoints are available, hence, this is the minimum.""</p>

<p>However, i observe a different behavior. If there is no new checkpoint and evaluation should be triggered according to the passed parameter a new checkpoint is created and evaluation is performed. </p>

<p>Is this a bug or am i missing something here?</p>
",2018-07-09 14:54:11,6456025,33,https://stackoverflow.com/questions/51248442,Documentation Replicability
51265030,Can tf.saved_model.simple_save be used to create a SavedModel for C++?,"<p>I want to save a model for inference from C++ and I am looking into <code>SavedModel</code>s as <a href=""https://www.tensorflow.org/programmers_guide/saved_model#save_and_restore_models"" rel=""nofollow noreferrer"">suggested by the documentation</a>.</p>

<p>Now <a href=""https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save"" rel=""nofollow noreferrer""><code>tf.saved_model.simple_save</code></a> seems to be a convenience function to easily create a <code>SavedModel</code>: from within a <code>Session</code>, provide the inputs, outputs and an export dir: </p>

<pre><code>simple_save(session,
            export_dir,
            inputs={""x"": x, ""y"": y},
            outputs={""z"": z})
</code></pre>

<p>When looking at this API, the function looks rather broad in application; however the documentation warns us that </p>

<blockquote>
  <p>The <code>SavedModel</code> will load in TensorFlow Serving and supports the Predict API. To use the Classify, Regress, or MultiInference APIs, please use either <code>tf.Estimator</code> or the lower level <code>SavedModel</code> APIs.</p>
</blockquote>

<p>I am not familiar with Tensorflow serving, but it seems that these distinctions between Predict, Classify aso. relates to Tensorflow serving.</p>

<p>Actually the documentaiton on <code>tf.saved_model.simple_save</code> says that it is a</p>

<blockquote>
  <p>Convenience function to build a SavedModel <strong>suitable for serving</strong>.</p>
</blockquote>

<p>(emphasis mine).</p>

<p>So <code>tf.saved_model.simple_save</code> can create <code>SavedModel</code>s for serving, but my question is,</p>

<ul>
<li>can <code>tf.saved_model.simple_save</code> also be used to create a <code>SavedModel</code> for inference in C++,</li>
<li>if so, what are the limitation in terms of models that can be created by this function? (Given the fact that for serving, it apparently does have some restrictions.)</li>
</ul>
",2018-07-10 12:19:14,9973879,1817,https://stackoverflow.com/questions/51265030,Documentation Replicability
51392594,"`ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'sparse_softmax_cross_entropy_loss' [Tensorflow]","<p>I am rather new to Tensorflow, and has been trying to pick up the basics by reading through the guides and documentation on tensorflow.org</p>

<p>I have learnt the basics of how to use the tf.data and tf.estimator APIs and is trying to get them to work together on a basic image model for MNIST.</p>

<p>I am currently following these guides: 
<a href=""https://www.tensorflow.org/tutorials/estimators/cnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/estimators/cnn</a> 
<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py</a></p>

<p>I've changed the original python script to be using <code>Dataset.from_tensor_slices</code> rather than <code>numpy_input_fn</code> but I am facing the error at the evaluation step. (though not at the training step)</p>

<p><code>ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [1,10].</code></p>

<p>My code can be found in a python notebook here (only changed the input_fn): <a href=""https://github.com/quanta0801/tf_scripts/blob/master/mnist/mnist_estimator_baseline.ipynb"" rel=""nofollow noreferrer"">https://github.com/quanta0801/tf_scripts/blob/master/mnist/mnist_estimator_baseline.ipynb</a></p>

<p>Thanks!</p>

<p>PS: any additional links to excellent guides to using tf.data &amp; tf.estimators will be great too! Official documentation cycles between these, keras and the low level APIs which is not conducive.</p>
",2018-07-18 02:12:35,10088125,31,https://stackoverflow.com/questions/51392594,Documentation Replication on Other Examples
51396366,TensorFlow with keras: Where is the ReLU layer in tf version 1.8?,"<p>Update: Found it: The class is <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation#__init__"" rel=""nofollow noreferrer"">tf.keras.layers.Activation</a>; needs to be called with argument activation='relu'....</p>

<hr>

<p>Trying to access tf.keras.layers.ReLU gives the error:</p>

<blockquote>
  <p>AttributeError: module
  'tensorflow.tools.api.generator.api.keras.layers' has no attribute
  'ReLU'.</p>
</blockquote>

<p>In the docs, version <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/keras/layers/ReLU"" rel=""nofollow noreferrer"">master</a> has such a layer. Version 1.8 (and 1.9) only seems to have leaky relu, PReLU, and other derivatives. </p>

<p>Right now I'm using <a href=""https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/keras/layers/ThresholdedReLU"" rel=""nofollow noreferrer"">ThresholdedReLU</a> with theta of 0.0, I hope this results in a standard ReLU. But there must be a simple 'ReLU' layer as well?</p>

<p>Where can I find keras' ReLU layer in tensorflow 1.8?
I want a keras layer class, i.e., not <a href=""https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/keras/backend/relu"" rel=""nofollow noreferrer"">tf.keras.backend.relu</a>.</p>

<p>It feels as if I'm overlooking something completely obvious. I haven't used keras before, so, sorry if this is a super stupid question.</p>
",2018-07-18 07:46:12,4726173,597,https://stackoverflow.com/questions/51396366,Documentation Replication on Other Examples
51397198,Tensoflow Estimator: how to use tf.graph_util.convert_variables_to_constants,"<p>I would like to know if it is possible to use the function <em><a href=""https://www.tensorflow.org/api_docs/python/tf/graph_util/convert_variables_to_constants"" rel=""nofollow noreferrer"">tf.graph_util.convert_variables_to_constants</a></em> (in order to store the frozen version of the graph) in a train/evaluation loop, while I'm using a custom estimators. For example:</p>

<pre class=""lang-py prettyprint-override""><code>best_validation_accuracy = -1
for _ in range(steps // how_often_validation):

    # Train the model
    estimator.train(input_fn=train_input_fn, steps=how_often_validation)

    # Evaluate the model
    validation_accuracy = estimator.evaluate(input_fn=eval_input_fn)

    # Save best model
    if validation_accuracy[""accuracy""] &gt; best_validation_accuracy:
        best_validation_accuracy = validation_accuracy[""accuracy""]
        # Save best model perfomances
        # I WANT TO USE  tf.graph_util.convert_variables_to_constants HERE
</code></pre>
",2018-07-18 08:32:09,6142101,163,https://stackoverflow.com/questions/51397198,Documentation Ambiguity
51407186,Invalid Syntax Error when creating estimator in Tensorflow,"<p>I am attempting to use Tensorflow in a Colab Notebook to train identically structured neural networks with varying sizes of randomly chosen training examples from the MNIST data set. I have previously been successful in training neural networks in a similar fashion several times, but this time I am receiving an Invalid Syntax error that I have not been able to correct. The error appears for the following line of code:</p>

<p><code>mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)</code></p>

<p>I have used this same line of code successfully in a different notebook, and I have not been able to recognize any problems with the syntax (it's from the Tensorflow documentation found here: <a href=""https://www.tensorflow.org/tutorials/layers"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/layers</a>) </p>

<p>The code I am trying to execute can be found below (but I have omitted the definition of cnn_model_fn for the sake of brevity).</p>

<pre><code>#Initialize list to hold all of the accuracy data
all_accuracies = []

#For each training set group
for group_number in range(len(train_set_sizes)):

  #For each ANN in training set group
  for i in range(num_ANNs):

    #Initialize group_accuracies list
    group_accuracies = []

    #--------------Generate a training set--------------------------------

    #Initialize train_set lists
    train_set_examples = []
    train_set_labels = []

    #randomly select indices to pull train set examples
    example_select_indices = np.random.randint(0,55000,size=train_set_sizes[group_number])

    #For number of images in the appropriate training set group
    for j in range(train_set_sizes[group_number]):

      random_index = example_select_indices[j]
      train_set_examples = np.asarray(train_set_examples.append(train_images[random_index]))
      train_set_labels = np.asarray(train_set_labels.append(train_labels[random_index])

    # Create the MNIST Estimator
    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)

    # Train the CNN model
    mnist_classifier.train(input_fn=train_input_fn,steps=train_steps)

    # Evaluate the models and print results
    eval_result = mnist_classifier.evaluate(input_fn=eval_input_fn)
    print(""Group Number "",group_number+1,"", ANN #"",i+1,"" Accuracy: "",eval_result,"" %"")

    #Record ANN accuracy
    group_accuracies.append(eval_result)

#record group accuracies in all_accuracies
all_accuracies.append(group_accuracies)
</code></pre>

<p>Does anybody have any suggestions for why this error might be occurring?</p>

<p>Thank you!</p>
",2018-07-18 16:46:49,5910469,79,https://stackoverflow.com/questions/51407186,Documentation Replication on Other Examples
51499154,"Mnist with Tensorflow Premade Estimator, input dimension mismatch on evaluate","<p>I am rather new to Tensorflow, and has been trying to pick up the basics by reading through the guides and documentation on tensorflow.org</p>

<p>I have learnt the basics of how to use the <code>tf.data</code> and <code>tf.estimator</code> APIs and is trying to get them to work together on a basic classification model for MNIST.</p>

<p>I am using this script to load MNIST: <a href=""https://github.com/tensorflow/models/blob/master/official/mnist/dataset.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/models/blob/master/official/mnist/dataset.py</a></p>

<p>I made modifications to the dataset function to return a feature dictionary rather than vector:</p>

<pre><code>def dataset(directory, images_file, labels_file):
  """"""Download and parse MNIST dataset.""""""

  images_file = download(directory, images_file)
  labels_file = download(directory, labels_file)

  check_image_file_header(images_file)
  check_labels_file_header(labels_file)

  def decode_image(image):
    # Normalize from [0, 255] to [0.0, 1.0]
    image = tf.decode_raw(image, tf.uint8)
    image = tf.cast(image, tf.float32)
    image = tf.reshape(image, [784])
    return image / 255.0

  def decode_label(label):
    label = tf.decode_raw(label, tf.uint8)  # tf.string -&gt; [tf.uint8]
    label = tf.reshape(label, [])  # label is a scalar
    return tf.to_int32(label)

  images = tf.data.FixedLengthRecordDataset(
      images_file, 28 * 28, header_bytes=16).map(decode_image)
  labels = tf.data.FixedLengthRecordDataset(
      labels_file, 1, header_bytes=8).map(decode_label)
  return tf.data.Dataset.zip(({""image"":images}, labels))
</code></pre>

<p>My MNIST classifier script using the premade estimator in tf is as follows:</p>

<pre><code>import tensorflow as tf
import dataset

fc = [tf.feature_column.numeric_column(""image"", shape=784)]

mnist_classifier = tf.estimator.DNNClassifier(
    hidden_units=[512,512],
    feature_columns=fc,
    model_dir=""models/mnist/dnn"",
    n_classes=10)

def input_fn(train=False, batch_size=None):
    if train:
        ds = mnist.train(""MNIST-data"")
        ds = ds.shuffle(1000).repeat().batch(batch_size)
    else:
        ds = mnist.test(""MNIST-data"")
    return ds

mnist_classifier.train(
  input_fn=lambda:input_fn(True, 32),
  steps=10000)

eval_results = mnist_classifier.evaluate(input_fn=lambda:input_fn())
</code></pre>

<p>The classifier doesn't crash on training, but on evaluate, I faced the following traceback:</p>

<blockquote>
  <p>ValueError: Cannot reshape a tensor with 784 elements to shape
  [784,784] (614656 elements) for
  'dnn/input_from_feature_columns/input_layer/image/Reshape' (op:
  'Reshape') with input shapes: [784,1], [2] and with input tensors
  computed as partial shapes: input[1] = [784,784].</p>
</blockquote>

<p>What could be causing the issue here?</p>

<p>I have tried printing the output shapes and types of both train and test datasets, and they are exactly the same.</p>

<p>I have also tried viewing the model on tensorboard, and only the projector tab is available, no scalars or graphs tab.</p>

<p>Thanks!</p>

<p>PS: Any links to TF tutorials using the Datasets and Estimators APIs will be great too.</p>
",2018-07-24 12:53:31,10088125,31,https://stackoverflow.com/questions/51499154,Documentation Replication on Other Examples
51507788,What are inputs and outputs in tf.saved_model.simple_save?,"<p>In tf.saved_model.simple_save, there are 4 params:</p>

<ul>
<li>session, the session</li>
<li>export_dir, the dir where the model will be saved</li>
<li>inputs, <strong>what it this?</strong></li>
<li>outputs, <strong>what is this?</strong></li>
</ul>

<p>I've been reading how to <a href=""https://www.tensorflow.org/guide/saved_model#simple_save"" rel=""noreferrer"">simple_save</a> but I haven't been able to figure out what to put in these two parameters (inputs and outputs). I know the model must have input values so that it can be either trained or predict. So I don't know what these two parameters should contain and wether they should map variables inside the model or what...</p>

<p>The docs aren't that great so any explaining would be much appreciated.</p>
",2018-07-24 21:28:21,1071459,1521,https://stackoverflow.com/questions/51507788,Requesting (Additional) Documentation/Examples
51509549,Feature importance from tf.estimator.BoostedTreeRegression,"<p>I am trying to extracted feature importance from a model built in python using <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/BoostedTreesRegressor"" rel=""nofollow noreferrer"">tf.estimator.BoostedTreeRegressor</a>.</p>

<p>It looks like a standard way to achieve it is by iterating over all trees in the forest and from the importance of each tree's coefficients to calculate some statistics.</p>

<p>Example in <a href=""http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html"" rel=""nofollow noreferrer"">sklearn</a>, <a href=""https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/"" rel=""nofollow noreferrer"">xgboost</a>. I have not found how to address this issue in tensorflow.</p>
",2018-07-25 01:13:20,1090562,217413,https://stackoverflow.com/questions/51509549,Documentation Replication on Other Examples
51586459,Why the false_fn in tf.cond never called?,"<p>It's so wired to use <code>tf.while_loop</code> with <code>tf.cond</code> together. why the false condition never met? </p>

<pre><code>i0 = tf.constant(1)
m0 = tf.zeros([1, 2], dtype=tf.int32)
first_set = tf.Variable(True, dtype=tf.bool)

def cond_true_fn(i, m):
    global first_set
    first_set = tf.assign(first_set, False)
    return [i + 1, tf.concat([m, [[6, 6]]], axis=0)]


def cond_false_fn(i, m):
    return [i + 1, tf.concat([m, [[3, 3]]], axis=0)]


def body(i, m):
    return tf.cond(first_set, lambda:cond_true_fn(i,m), lambda:cond_false_fn(i,m))

def condi(i, m):
    return tf.less_equal(i, 3)

_, r = tf.while_loop(condi, body, loop_vars=[i0, m0], shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])], back_prop=False)

with tf.Session() as sess:
    tf.global_variables_initializer().run()
    _r = sess.run([r])
    print(_r)
</code></pre>

<p>it always fall in true condition. give me the result unexpected as below:
<code>[[0, 0], [6, 6], [6, 6], [6, 6]]</code> </p>
",2018-07-30 02:59:43,3331276,145,https://stackoverflow.com/questions/51586459,Documentation Replication on Other Examples
51625529,How to use tf.data's initializable iterator and reinitializable interator and feed data to estimator api?,"<p>All the official google tutorials use the one shot iterator for all the estimator api implementation, i couldnt find any documentation on how to use tf.data's initializable iterator and reinitializable interator instead of one shot iterator.</p>

<p>Can someone kindly show me how to switch between train_data and test_data using tf.data's initializable iterator and reinitializable interator. We need to run a session to use feed dict and switch the dataset in the initializable iterator, its a low level api and its confusing how to use it part of estimator api architecture</p>

<p>PS : I did find that google mentions 
""Note: Currently, one-shot iterators are the only type that is easily usable with an Estimator.""</p>

<p>But is there any work around within the community? or should we just stick with one shot iterator for some good reason</p>
",2018-08-01 04:50:04,10163720,93,https://stackoverflow.com/questions/51625529,Lack of Alternative Solutions/Documentation
51687832,Probability Distribution for tf.nn.softmax_cross_entropy_with_logits_v2,"<p>I am trying to understand the Tensorflow documentation better for tf.nn.softmax_cross_entropy_with_logits_v2().</p>

<p>In the documentation, it states:
While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution. If they are not, the computation of the gradient will be incorrect.</p>

<p>Does this mean that, for my labels, I shouldn't be simply using one-hot encoding, but should also account for the number of instances of each label? For example, if I have 2 classes, and there are 90 examples for class ""A"" and only 10 examples for class ""B"", should my label for a class A be [0.9, 0.1], instead of just [1, 0]?</p>

<p>I hope this makes sense. Thanks!</p>
",2018-08-04 17:05:55,10012553,219,https://stackoverflow.com/questions/51687832,Documentation Replication on Other Examples
51776390,how to use tensorboard debugger with datalab which uses tf.estimator on google cloud platform,"<p>When I start tensorboard via datalab it uses the google syntax which is described <a href=""https://googledatalab.github.io/pydatalab/google.datalab.ml.html"" rel=""nofollow noreferrer"">here</a>.  This document only mentions start, stop and list.  However, there is a debugger pane which I can not use.</p>

<p><a href=""https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/debugger"" rel=""nofollow noreferrer"">This</a> document describes how to use tensorboard debugger with a tf.estimator but it uses a different syntax.</p>

<p>Is there someway to blend the two so the debugger is usable with datalab?</p>
",2018-08-09 22:06:48,1008596,4239,https://stackoverflow.com/questions/51776390,Documentation Replication on Other Examples
51856041,Input dimension for tf.nn.in_top_k,"<p>I am following the TF documentation with respect to in_top_k: <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k</a> where it states that <code>targets</code> should be a vector of <code>batch size</code></p>

<p>Nevertheless, I'm continuously prompted with the following error:</p>

<blockquote>
  <p>InvalidArgumentError (see above for traceback): targets must be
  1-dimensional
           [[Node: in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Cas t_2/_4305, sub/_4307, in_top_k/InTopKV2/k)]]</p>
</blockquote>

<p>In my case, my <code>predictions</code> and <code>targets</code> inputs have the following shapes:</p>

<ul>
<li>predictions: <code>Tensor(""Cast_2:0"", shape=(128, 1000), dtype=float32, device=/device:GPU:0)</code></li>
<li>targets: <code>Tensor(""sub:0"", shape=(128,), dtype=int32, device=/device:GPU:0)</code></li>
</ul>

<p>From my understanding, there is still something not ok with my <code>targets</code> label, and despite using different combinations of tf.reshape or tf.squeeze I cannot seem to find where is the error. Is there any way to work around this issue?</p>
",2018-08-15 09:19:01,10228489,1,https://stackoverflow.com/questions/51856041,Documentation Ambiguity
51858891,Loading a NumPy array into a Tensor,"<p>According to the TensorFlow webpage at (<a href=""https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets</a>), the <code>tf.read_file</code> can be used to load an image file from a given filename, and convert it to a Tensor:</p>

<pre><code>image_string = tf.read_file(filename)
image_decoded = tf.image.decode_image(image_string)
</code></pre>

<p>In my case however, I want to load a NumPy array rather than an image. So the <code>filename</code> above points to a NumPy array on my machine.</p>

<p>If I were to use <code>tf.read_file(filename)</code> on this filename, then according to the documentation, this function returns a string Tensor (a byte array). How can I convert this into a Tensor representing the data in the NumPy array? Is there an equivalent function to <code>tf.image.decode_image()</code> for decoding a NumPy array?</p>
",2018-08-15 12:40:10,3320135,23213,https://stackoverflow.com/questions/51858891,Documentation Replication on Other Examples
51883196,Tensorflow: tf.reverse_sequence - seq_dim and batch_dim,"<p>I am trying to learn Tensorflow and was looking at <code>tf.reverse_sequence</code>. It has two parameters <code>seq_dim</code> and <code>batch_dim</code>. From the documentation given <a href=""https://www.tensorflow.org/api_docs/python/tf/reverse_sequence"" rel=""nofollow noreferrer"">here</a> I understand that setting <code>batch_dim = 0</code> means we go through the the rows from top and setting <code>seq_dim = 1</code> means we go through columns from left to right but what do these numbers mean? I can't understand from the documentation when I should set <code>batch_dim = 1</code> or <code>2</code>. I tried <code>reverse_sequence</code> on <code>x = [[1,2,3], [4,5,6], [7,8,9]]</code> and got <code>[[3,2,1], [6,5,4], [9,8,7]]</code> with <code>batch_dim = 0</code> and <code>seq_dim = 1</code>. But I always get errors when I change <code>seq_dim</code> and <code>batch_dim</code> values from <code>1</code> and <code>0</code> respectively. Could someone explain the meaning of these values?</p>
",2018-08-16 18:21:39,7460955,893,https://stackoverflow.com/questions/51883196,Lack of Alternative Solutions/Documentation
51923689,tf strided_slice equivalent in numpy?,"<p>I'm trying to ""backport"", in a sense, the tensorflow strided slice operation tf.strided_slice (<a href=""https://www.tensorflow.org/api_docs/python/tf/strided_slice"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/strided_slice</a>) into numpy, but I can't figure out how to do it. More specifically, given the arguments for a call to strided slice, how would I manipulate these into array indices to produce the same result that a call to tf.strided_slice would produce? </p>

<p>(I know that tf.strided_slice is for use on tensors and numpy slice indexing is for use on numpy arrays)</p>
",2018-08-20 03:05:59,5294613,33,https://stackoverflow.com/questions/51923689,Documentation Replication on Other Examples
51965094,What's the difference between tf.feature_column.input_layer and tf.layers.Input,"<p>I currently get stuck at distinguishing between <code>tf.feature_column.input_layer</code> and <code>tf.layers.Input</code>. Are the two exchangable in the actual constructed model? What is the use case of each of the two?</p>
",2018-08-22 10:44:29,5729303,1117,https://stackoverflow.com/questions/51965094,Documentation Replicability
51971050,Graph optimizations on a tensorflow serveable created using tf.Estimator,"<p><strong>Context</strong>:</p>

<p>I have a simple classifier based on <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier"" rel=""noreferrer"">tf.estimator.DNNClassifier</a> that takes text and output probabilities over an intent tags.  I am able to train an export the model to a serveable as well as serve the serveable using <a href=""https://www.tensorflow.org/serving/setup"" rel=""noreferrer"">tensorflow serving</a>.  The problem is this servable is too big (around 1GB) and so I wanted to try some <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size"" rel=""noreferrer"">tensorflow graph transforms</a> to try to reduce the size of the files being served.  </p>

<p><strong>Problem</strong>:</p>

<p>I understand how to take the <code>saved_model.pb</code> and use <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py"" rel=""noreferrer"">freeze_model.py</a> to create a new <code>.pb</code> file that can be used to call transforms on. The result of these transforms (a <code>.pb</code> file as well) is not a servable and cannot be used with tensorflow serving.</p>

<p>How can a developer go from:</p>

<pre><code>saved model -&gt; graph transforms -&gt; back to a servable
</code></pre>

<p>There's <a href=""https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models"" rel=""noreferrer"">documentation</a> that suggests that this is certainly possible, but its not at all intuitive from the docs as to how to do this.</p>

<p><strong>What I've Tried</strong>:</p>

<pre><code>import tensorflow as tf

from tensorflow.saved_model import simple_save
from tensorflow.saved_model import signature_constants
from tensorflow.saved_model import tag_constants
from tensorflow.tools.graph_transforms import TransformGraph


with tf.Session(graph=tf.Graph()) as sess_meta:
    meta_graph_def = tf.saved_model.loader.load(
        sess_meta,
        [tag_constants.SERVING],
        ""/model/path"")

    graph_def = meta_graph_def.graph_def

    other_graph_def = TransformGraph(
        graph_def,
        [""Placeholder""],
        [""dnn/head/predictions/probabilities""],
        [""quantize_weights""])


    with tf.Graph().as_default():
        graph = tf.get_default_graph()
        tf.import_graph_def(other_graph_def)
        in_tensor = graph.get_tensor_by_name(
            ""import/Placeholder:0"")
        out_tensor = graph.get_tensor_by_name(
            ""import/dnn/head/predictions/probabilities:0"")

        inputs = {""inputs"": in_tensor}
        outputs = {""outputs"": out_tensor}

        simple_save(sess_meta, ""./new"", inputs, outputs)
</code></pre>

<p>My idea was to load the servable, extract the graph_def from the meta_graph_def, transform the graph_def and then try to recreate the servable.  This seems to be the incorrect approach.</p>

<p>Is there a way to successfully perform transforms (to reduce file size at inference) on a graph from an exported servable, and then recreate a servable with the transformed graph?</p>

<p>Thanks.</p>

<p><strong>Update (2018-08-28)</strong>:</p>

<p>Found <a href=""https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/meta_graph_transform/meta_graph_transform.py"" rel=""noreferrer"">contrib.meta_graph_transform()</a> which looks promising.</p>

<p><strong>Update (2018-12-03)</strong>:</p>

<p>A related <a href=""https://github.com/tensorflow/serving/issues/1078#issuecomment-443906077"" rel=""noreferrer"">github issue</a> I opened that seems to be resolved in a detailed blog post which is listed at the end of the ticket.</p>
",2018-08-22 16:13:01,3222797,17215,https://stackoverflow.com/questions/51971050,Lack of Alternative Solutions/Documentation
51997426,TensorFlow: alternate between datasets of different output shapes,"<p>I'm trying to use <code>tf.Dataset</code> for a 3D image CNN where the shape of the 3D image fed into it from the training set and the validation set are different (training: (64, 64, 64), validation: (176, 176, 160)). I didn't even know this was possible, but I'm recreating this network based on a paper, and using the classic <code>feed_dict</code> method the network indeed works. For performance reasons (and just to learn) I'm trying to switch the network to use <code>tf.Dataset</code> instead.</p>

<p>I have two datasets and iterators built like the following:</p>

<pre class=""lang-py prettyprint-override""><code>def _data_parser(dataset, shape):
        features = {""input"": tf.FixedLenFeature((), tf.string),
                    ""label"": tf.FixedLenFeature((), tf.string)}
        parsed_features = tf.parse_single_example(dataset, features)

        image = tf.decode_raw(parsed_features[""input""], tf.float32)
        image = tf.reshape(image, shape + (1,))

        label = tf.decode_raw(parsed_features[""label""], tf.float32)
        label = tf.reshape(label, shape + (1,))
        return image, label

train_datasets = [""train.tfrecord""]
train_dataset = tf.data.TFRecordDataset(train_datasets)
train_dataset = train_dataset.map(lambda x: _data_parser(x, (64, 64, 64)))
train_dataset = train_dataset.batch(batch_size) # batch_size = 16
train_iterator = train_dataset.make_initializable_iterator()

val_datasets = [""validation.tfrecord""]
val_dataset = tf.data.TFRecordDataset(val_datasets)
val_dataset = val_dataset.map(lambda x: _data_parser(x, (176, 176, 160)))
val_dataset = val_dataset.batch(1)
val_iterator = val_dataset.make_initializable_iterator()
</code></pre>

<p><a href=""https://www.tensorflow.org/guide/datasets#creating_an_iterator"" rel=""nofollow noreferrer"">TensorFlow documentation</a> has examples regarding switching between datasets using <code>reinitializable_iterator</code> or <code>feedable_iterator</code>, but they all switch between iterators of <strong>same</strong> output shape, which is not the case here.</p>

<p>How should I switch between training set and validation set using <code>tf.Dataset</code> and <code>tf.data.Iterator</code> in my case then?</p>
",2018-08-24 04:18:52,10190297,836,https://stackoverflow.com/questions/51997426,Lack of Alternative Solutions/Documentation
51999636,Keras model failed to learn anything after changing to use tf.data api,"<p>I was trying to convert a simple Keras model to use tf.data api for data loading, but somehow the accuracy remains about 10% during the whole 10 epochs.</p>

<p>In comparison, the original code without using tf.data api can easily achieve about 98% accuracy. Did I do anything wrong?</p>

<p>The version using tf.data api</p>

<pre><code>import math
import tensorflow as tf
import numpy as np

batch_size = 32


def load_data():
    mnist = tf.keras.datasets.mnist
    (train_data, train_label), (validation_data, validation_label) = mnist.load_data()
    train_data, validation_data = train_data / 255.0, validation_data / 255.0
    train_label = train_label.astype(np.float32)
    return train_data, train_label


def build_model():
    class MyModel(tf.keras.Model):

        def __init__(self):
            super(MyModel, self).__init__(name='my_model')
            self.flatten = tf.keras.layers.Flatten()
            self.dense_1 = tf.keras.layers.Dense(512, activation=tf.nn.relu)
            self.dropout = tf.keras.layers.Dropout(0.2)
            self.dense_2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)

        def call(self, inputs):
            x = self.flatten(inputs)
            x = self.dense_1(x)
            x = self.dropout(x)
            y = self.dense_2(x)
            return y

    model = MyModel()

    model.compile(optimizer=tf.train.AdamOptimizer(),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    return model


train_data, train_label = load_data()
train_sample_count = len(train_data)

train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))

train_dataset = train_dataset.batch(batch_size)
train_dataset = train_dataset.repeat()

model = build_model()
model.fit(
    train_dataset,
    epochs=10,
  steps_per_epoch=math.ceil(train_sample_count/batch_size)
)
</code></pre>

<p>The version without using tf.data api</p>

<pre><code># load_data and build_model are exactly same as those in the tf.data api version

train_data, train_label = load_data()
model = build_model()
model.fit(
    train_data,
    train_label,
    epochs=10
)
</code></pre>
",2018-08-24 07:37:52,10263076,43,https://stackoverflow.com/questions/51999636,Documentation Replication on Other Examples
52035692,Tensorflow v1.10: store images as byte strings or per channel?,"<h2>Context</h2>
<p>It is known that, at the moment, TF's Record documentation leaves something to be desired.</p>
<p>My question is in regards to what is optimal for storing:</p>
<ul>
<li>a sequence,</li>
<li>its per-element class probabilities, and</li>
<li>some (context?) information (e.g. name of the sequence)</li>
</ul>
<p>as a TF Record.</p>
<p>Namely, this questions considers storing the sequence and class probabilities as channels vs as a byte string and whether or not the meta information should go in as features of a <code>tf.train.Example</code> or as the context of a <code>tf.train.SequenceExample</code>. (see questions at the bottom).</p>
<h2>M.W.E.</h2>
<p>For example, lets assume my looks sequence like this</p>
<pre><code>seq = [ 
        # el1, el2 
        [ 0,   1   ], # channel 1
        [ 0,   1   ]  # channel 2
      ]
</code></pre>
<p>i.e. it is a 2 channel sequence of <em>fixed</em> length (in this example, 2) where the values can only be integer value.</p>
<p>and that we have three classes for which we are trying to segment the sequence into</p>
<pre><code>cls_probs = [ 
        #cls1, cls2, cls3
        [0   , 0.9 , 0.1 ], # class probabilities element 1
        [0   , 0.1 , 0.9 ]  # class probabilities element 2
      ]
</code></pre>
<p>where in effect both <code>seq</code> and <code>cls_probs</code> are <code>numpy.array</code>s.</p>
<p>The network only <em>requires</em> this information. However, I also have some meta data which I would like to keep with the sequence.</p>
<p>e.g.</p>
<pre><code>meta = {
           'name': 'my_seq',  # safer to keep this with the data rather than as file name
           'meta_val_1': 100, # not used by network, but may be useful when evaluating network's predictions for this particular sequence
           'meta_val_2': 10
       }
</code></pre>
<h1>Making TF Record</h1>
<h2>tf.train.Example</h2>
<p>Then I have several ways I could construct my <code>tf.train.Example</code>:</p>
<h3>as channels</h3>
<pre><code>example = tf.train.Example(
    features = tf.train.Features(
        feature = {
            'channel_1': tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,0])),
            'channel_2': tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,1])),
            'class_1'  : tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,0])),
            'class_2'  : tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,1])),
            'class_3'  : tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,2])),
            'name'     : tf.train.Feature(bytes_list=tf.train.BytesList(value=[f'{meta[&quot;name&quot;]}'.encode('utf-8')])), 
            # should these be FloatList even though it is just a single value?
            # should these be included here if they are not used by the network?
            'val_1'    : tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_1&quot;]}'])),
            'val_2'    : tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_2&quot;]}'])),
    })
)
</code></pre>
<p>where <code>f'{variable}'.encode('utf-8')</code> is the currently not suggested <a href=""https://www.python.org/dev/peps/pep-0498/"" rel=""nofollow noreferrer""><code>fb'&lt;string&gt;'</code></a> (note: <code>f-strings</code> only work with python3.6+).</p>
<p>This format is somewhat nice as each sequence channel is explicit. However it is also verbose and requires preprocessing when loaded to be feed into the network.</p>
<h3>as string</h3>
<p>or, I could dump my array to an string</p>
<pre><code>example = tf.train.Example(
    features = tf.train.Features(
        feature = {
            'sequence' : tf.train.Feature(bytes_list=tf.train.BytesList(value=seq.tostring())),
            'cls_probs': tf.train.Feature(bytes_list=tf.train.BytesList(value=cls_probs.tostring())),
            # ... see encoding of meta values from above
    })
)
</code></pre>
<h2>tf.train.SequenceExample</h2>
<p>TF Records also accept another form: <code>tf.train.SequenceExample</code>. <code>SequenceExample</code> expects context features and an ordered list of unnamed features.</p>
<h3>as channels</h3>
<p>So restructuring above's as <em>channels</em> example:</p>
<pre><code>example = tf.train.SequenceExample(
    context = tf.train.Features(
        feature = {
            'Name' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[f'{meta[&quot;name&quot;]}'.encode('utf-8')])), 
            'Val_1': tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_1&quot;]}'])),
            'Val_2': tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_2&quot;]}'])),
        }
    ),
    feature_lists = tf.train.FeatureLists(
        feature_list = {
            'sequence': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,0])),
                    tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,1])),
                ]
            ),
            'class_probabilities': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,0])),
                    tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,1])),
                    tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,2]))
                ]
            )
        }
    )
)
</code></pre>
<h3>as string</h3>
<p>likewise we can create the as <em>string</em> example:</p>
<pre><code>example = tf.train.SequenceExample(
    context = tf.train.Features(
        # see above
    ),
    feature_lists = tf.train.FeatureLists(
        feature_list = {
            'sequence': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(bytes_list=tf.train.BytesList(value=seq.tostring()))
                ]
            ),
            'class_probabilities': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(bytes_list=tf.train.BytesList(value=cls_probs.tostring()))
                ]
            )
        }
    )
)
</code></pre>
<h1>Questions</h1>
<p>Here I gave a M.W.E. for how one could construct an example (ready to be exported to a TF Record) as both <code>tf.train.Example</code> and <code>tf.train.SequenceExample</code>. Further, I demonstrated both how to do this per channel or by dumping as a byte string. Both of these methods (as channels / as strings) include the meta information within the example.</p>
<p>Thus my questions are:</p>
<ol>
<li><p>which way (as channels / as string) of storage is more optimal (for read, write, re-use, etc) ?</p>
</li>
<li><p>given the meta information which should be kept with the example, is better to use <code>tf.train.Example</code> and store the meta information as features there? or use <code>tf.train.SequenceExample</code> and store the meta information in the context argument?</p>
</li>
</ol>
<p>Does anyone know if there are any notable advantages / disadvantages for any of four these strategies?</p>
<p>For those who would like to test this on larger less dummy like data, some functions for producing this code can be found <a href=""https://stackoverflow.com/a/52041027/5623899""><strong>below</strong></a></p>
<p>Lastly, I would like to point out this <a href=""https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564"" rel=""nofollow noreferrer"">medium post</a> which greatly elaborates on TF's docs.</p>
",2018-08-27 08:51:37,5623899,4978,https://stackoverflow.com/questions/52035692,Documentation Replication on Other Examples
52046902,cudnnLSTM won't restore into a cudnnCompatibleLSTM,"<p>I'm trying to train an elementary network on a GPU machine (AWS p3x2, Volta) with TF 1.9 / 1.10. Not Keras -- TF only.</p>

<p>Based on the [rather limited] documentation my aim is to train with cudnnLSTM cell, save a checkpoint, and then restore for inference on a CPU. Per that aim, I thought that cudnnCompatibleLSTM is the way to go as it is supposed to suck in the weights from the GPU-specific LSTM implementation.</p>

<p>I get the following error, no matter what I try:</p>

<pre><code>NotFoundError (see above for traceback): Key caseTesting/testbed/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias not found in checkpoint   [[Node: caseTesting/testbed/save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT],
_device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_ caseTesting/testbed/save/Const_0_0, caseTesting/testbed/save/RestoreV2/tensor_names, caseTesting/testbed/save/RestoreV2/shape_and_slices)]]
</code></pre>

<p>Another related issue is that cudnnCompatibleLSTM and cudnnLSTM are not the same mathematically. I get different results for initialized cells. [initialized by some tf.constant() as initializer, no save/restore]. Seems that cudnnLSTM does depend on the random seed [dropout is zero], which means that there are some unique tensor/tensor initialization going on, separating it from cudnnCompatibleLSTM.</p>

<p>Does anybody have a clue?</p>
",2018-08-27 21:00:47,6281444,59,https://stackoverflow.com/questions/52046902,Documentation Replicability
52073782,Computations (such as tf.greater and tf.cond) on random value tensors not working as expected,"<p>I am a tensorflow beginner. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/greater"" rel=""nofollow noreferrer"">documentation</a>, <strong>tf.greater returns the truth value of (x>y) element-wise</strong></p>

<p>My code is as below:</p>

<pre><code>x = tf.random_uniform([])  # Empty array as shape creates a scalar.
y = tf.random_uniform([])
print('x: '+str(x.eval()))
print('y: ' +str(y.eval()))
out = tf.cond(tf.greater(x, y), lambda: x + y, lambda: x - y)
print(sess.run(tf.greater(x, y)))
print(sess.run(out))
</code></pre>

<p>The output I got is:</p>

<pre><code>x: 0.79379404
y: 0.30891895
False
0.3438499
</code></pre>

<p>x is bigger than y so it should return True and x+y should be 1.10271299
why is my expected output different than the actual output?</p>
",2018-08-29 09:16:02,8496110,562,https://stackoverflow.com/questions/52073782,Documentation Replication on Other Examples
52090848,how to make embedding column through features directly?,"<p>I'm learning wide&amp;deep model for ctr. My data has a feature user_id which has more than 2**26 values. How I can get embedding column through this feature? I used 
<code>user_id = tf.feature_column.categorical_column_with_hash_bucket('user_id', hash_bucket_size=2**26)</code>, 
<code>user_id_emb = tf.feature_column.embedding_column(user_id, dimension=95)</code>,
 but it shows out of memeory.</p>
",2018-08-30 06:52:51,8686837,11,https://stackoverflow.com/questions/52090848,Documentation Replication on Other Examples
52134130,How to restrict the absolut value of each dimention of a sparse gradient from being too large?,"<p>Consider the code below:</p>

<pre><code>import tensorflow as tf

inputs=tf.placeholder(tf.int32, [None])
labels=tf.placeholder(tf.int32, [None])

with tf.variable_scope('embedding'):
    embedding=tf.get_variable('embedding', shape=[2000000, 300], dtype=tf.float32)

layer1=tf.nn.embedding_lookup(embedding, inputs)
logits=tf.layers.dense(layer1, 2000000)

loss=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)
cost=tf.reduce_sum(loss)

optimizer=tf.train.GradientDescentOptimizer(0.01)
grads, vars=zip(*optimizer.compute_gradients(cost))
for g in grads:
    print(0, g)

grads1=[tf.clip_by_value(g, -100, 100) for g in grads]
for g in grads1:
    print(1, g)

grads2, _=tf.clip_by_global_norm(grads, 10)
for g in grads2:
    print(2, g)
</code></pre>

<p>The output is:</p>

<pre><code>0 IndexedSlices(indices=Tensor(""gradients/embedding_lookup_grad/Reshape_1:0"", shape=(?,), dtype=int32), values=Tensor(""gradients/embedding_lookup_grad/Reshape:0"", shape=(?, 300), dtype=float32), dense_shape=Tensor(""gradients/embedding_lookup_grad/ToInt32:0"", shape=(2,), dtype=int32))
0 Tensor(""gradients/dense/MatMul_grad/tuple/control_dependency_1:0"", shape=(300, 2000000), dtype=float32)
0 Tensor(""gradients/dense/BiasAdd_grad/tuple/control_dependency_1:0"", shape=(2000000,), dtype=float32)
C:\Python\Python36\lib\site-packages\tensorflow\python\ops\gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 600000000 elements. This may consume a large amount of memory.
  num_elements)
1 Tensor(""clip_by_value:0"", shape=(?, 300), dtype=float32)
1 Tensor(""clip_by_value_1:0"", shape=(300, 2000000), dtype=float32)
1 Tensor(""clip_by_value_2:0"", shape=(2000000,), dtype=float32)
2 IndexedSlices(indices=Tensor(""gradients/embedding_lookup_grad/Reshape_1:0"", shape=(?,), dtype=int32), values=Tensor(""clip_by_global_norm/clip_by_global_norm/_0:0"", shape=(?, 300), dtype=float32), dense_shape=Tensor(""gradients/embedding_lookup_grad/ToInt32:0"", shape=(2,), dtype=int32))
2 Tensor(""clip_by_global_norm/clip_by_global_norm/_1:0"", shape=(300, 2000000), dtype=float32)
2 Tensor(""clip_by_global_norm/clip_by_global_norm/_2:0"", shape=(2000000,), dtype=float32)
</code></pre>

<p>I know there are two ways to restrict gradients from being too large. <code>tf.clip_by_value</code> to restrict each dimentions, and <code>tf.clip_by_global_norm</code> to restrict according global gradients norms.</p>

<p>However, <code>tf.clip_by_value</code> will cast a sparse gradient into a dense one, which significantly increase the memory usage and decreases the calculation efficiency, just as the warning indicates, while <code>tf.clip_by_global_norm</code> will not. Although I can understand why this is designed, how can I restrict the absolut value of each dimention of a sparse gradient from being too large without efficiency decrease?</p>

<p>Please don't tell me just use <code>tf.clip_by_global_norm</code>, I know this is ok for most cases, but is not what I want.</p>
",2018-09-02 05:04:23,1337994,31,https://stackoverflow.com/questions/52134130,Lack of Alternative Solutions/Documentation
52190877,Tensorflow: tf.case giving errors,"<p>When I print output of <code>tf.case</code>, it gives <code>ValueError: Operation 'case_11/cond/Merge' has been marked as not fetchable.</code></p>

<p>The code is following :</p>

<pre><code>a = tf.random_uniform([],minval = -1,maxval = 1)
b = tf.random_uniform([],minval = -1,maxval = 1)
def f1(): return a + b
def f2(): return a - b
def f3(): return tf.constant(0.0)
out2 = tf.case({tf.less(a,b):f1,tf.greater(a,b):f2},default = f3,exclusive = True)
print(sess.run(out2))
</code></pre>

<p>PS: But this is not the issue with <code>tf.cond()</code>.</p>

<p>Please help me here . 
Thanks!</p>
",2018-09-05 17:50:00,8548844,1,https://stackoverflow.com/questions/52190877,Documentation Replicability
52234780,Reading from .tfrecord files using tf.data.Dataset,"<p>I want to read the dataset generated by <a href=""https://github.com/tensorflow/models/blob/master/research/slim/datasets/download_and_convert_cifar10.py"" rel=""nofollow noreferrer"">this code</a> with the <code>tf.data.Dataset</code> api. The repo shows it was written like this:</p>

<pre><code>def image_to_tfexample(image_data, image_format, height, width, class_id):
  return tf.train.Example(features=tf.train.Features(feature={
      'image/encoded': bytes_feature(image_data),
      'image/format': bytes_feature(image_format),
      'image/class/label': int64_feature(class_id),
      'image/height': int64_feature(height),
      'image/width': int64_feature(width),
  }))
</code></pre>

<p>with <code>(encoded byte-string, b'png', 32, 32, label)</code> as parameters.</p>

<p>So, to read the .tfrecord file, the data format would have to be:</p>

<pre><code>example_fmt = {
    'image/encoded': tf.FixedLenFeature((), tf.string, """"),
    'image/format': tf.FixedLenFeature((), tf.string, """"),
    'image/class/label': tf.FixedLenFeature((), tf.int64, -1),
    'image/height': tf.FixedLenFeature((), tf.int64, -1),
    'image/width': tf.FixedLenFeature((), tf.int64, -1)
}
parsed = tf.parse_single_example(example, example_fmt)
image = tf.decode_raw(parsed['image/encoded'], out_type=tf.uint8)
</code></pre>

<p>But it doesn't work. The dataset is empty after reading and generating an iterator with it raises <code>OutOfRangeError: End of sequence</code>.</p>

<p>A short python script for reproduction can be found <a href=""https://pastebin.com/zEG4GKm9"" rel=""nofollow noreferrer"">here</a>. I'm struggling to find exact documentation or examples for this problem.</p>
",2018-09-08 11:18:37,4443082,227,https://stackoverflow.com/questions/52234780,Documentation Replication on Other Examples
52254253,How does tf.layers.dense() interact with inputs of higher dim?,"<p>In tensorflow layers.dense(inputs, units, activation) implements a Multi-Layer Perceptron layer with arbitrary activation function. </p>

<p>Output = activation(matmul(input, weights) + bias)</p>

<p>Typically input has shape=[batch_size, input_size] and might look like this: (units = 128 and activation = tf.nn.relu are chosen arbitrarily)</p>

<pre><code>inputx = tf.placeholder(float, shape=[batch_size, input_size])
dense_layer = tf.layers.dense(inputx, 128, tf.nn.relu)
</code></pre>

<p>I have not found any documentation on what would happen, if i fed higher dimensional input, e.g. because one might have time_steps resulting in a tensor of shape=[time_step, batch_size, input_size]. What one would want here is that the layer is applied to each single input_vector for each timestep for each element of the batch. To put it a bit differently, the internal matmul of layers.dense() should simply use broadcasting in numpy style. Is the behaviour i expect here what actually happens? I.e. is: </p>

<pre><code>inputx = tf.placeholder(float, shape=[time_step, batch_size, input_size])
dense_layer = tf.layers.dense(inputx, 128, tf.nn.relu)
</code></pre>

<p>applying the dense layer to each input of size input_size for each time_step for each element in batch_size? This should then result in a tensor(in dense_layer above) of shape=[time_step, batch_size, 128]
I'm asking, as e.g. tf.matmul does not support broadcasting in the numpy style, so i'm not sure, how tensorflow handles these cases.</p>

<p>Edit: <a href=""https://stackoverflow.com/questions/46697389/reshape-3d-tensor-before-dense-layer"">This post is related, but does not finally answer my question</a></p>
",2018-09-10 08:56:29,6917400,909,https://stackoverflow.com/questions/52254253,Lack of Alternative Solutions/Documentation
52300519,Calculating custom metrics with tf.estimator.DNNRegressor in TensorFlow 1.10,"<p>How to configure a <code>tf.estimator.DNNRegressor</code> to report different metrics like <strong>RMSE</strong> and <strong>MAE</strong> while evaluating?</p>

<p>(One can ask the same question for <code>tf.estimator.DNNClassifier</code> and <strong>AUC</strong> metric)</p>

<blockquote>
  <p><strong>Note:</strong> I know that it must be done in <code>tf.estimator.EstimatorSpec</code> of
  <code>model_fn()</code> for a custom <code>tf.estimator.Estimator</code>, but I don't know how to apply it for a
  <code>tf.estimator.DNNRegressor</code>.</p>
</blockquote>
",2018-09-12 17:24:01,2737801,197,https://stackoverflow.com/questions/52300519,Documentation Replicability
52319765,Swap a TensorFlow Dataset input pipeline with a placeholder after training,"<p>I'm working with the new <code>tf.data.Dataset</code> API and I can't seem to figure out how to perform inference. Ultimately, I want to convert my model to a TensorRT graph and run it on the TX2, and all of the <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/python_api/workflows/tf_to_tensorrt.html#Importing-the-UFF-Model-into-TensorRT-and-Building-an-Engine"" rel=""noreferrer"">examples I have found</a> assume you have a <code>tf.placeholder</code> for the input. Here is pseudocode for how I am training. The [...] is just meant to be a placeholder since I didn't actually run the code. Let's not debate the model, as it is just suppose to give an example:</p>

<pre><code>import tensorflow as tf

# Setup iterator
datain = tf.data.FixedLengthRecordDataset(datafiles, record_bytes1)
labels = tf.data.FixedLengthRecordDataset(labelfiles, record_bytes2)
dataset = tf.data.Dataset.zip((datain, labels))
dataset = dataset.prefetch(batch_size)
dataset = dataset.repeat(n_epoch)
iterator = dataset.make_initializable_iterator()

sess = tf.Session()
sess.run(iterator.initializer)
[batch_x, batch_y] = iterator.get_next()

# Define model function (let's not debate model except as relevant to question)
def model_fn(xin):
    x0 = tf.transpose(tf.reshape(xin, [...], name='input'))
    w = tf.Variable(tf.truncated_normal([...], stddev=0.1))
    x1 = tf.nn.conv2d(x0, w, strides=[...], padding='VALID')
    b = tf.Variable(tf.constant(0.0, shape=[...]))
    x2 = tf.nn.bias_add(x1, b)
    x3 = tf.nn.relu(x2, name='output')
    return x3

# Setup training environment
model = model_fn(batch_x)
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=batch_y))
optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)

# Train Model
while True:
    try:
        sess.run(optimizer)
    except tf.errors.OutOfRangeError:
        break

# Save model
saver = tf.train.Saver(name='saver')
saver.save(sess, 'temp/path')
</code></pre>

<p>My question is how do I get this into TensorRT without having the input be a <code>tf.placeholder</code>? All of the example I can find use a <code>tf.placeholder</code> as the input. <a href=""https://stackoverflow.com/questions/50061416/freezing-graph-in-tensorflow-when-using-tf-image-dataset/"">This example</a> suggests that I can replace the iterator with a placeholder using the <code>SavedModel</code> class, but I cannot seem to find any documentation on how to accomplish that.</p>

<p>Thanks!</p>

<p><strong>EDIT: Here is my solution thanks to the help below</strong></p>

<pre><code>from tensorflow.python.tools import optimize_for_inference_lib
import uff

# You can feed data to the IteratorGetNext node using feed_dict
input_node_name = 'iterator_scope_name/IteratorGetNext'
output_node_name = 'model_scope_name/output'

# Run inference on the trained model:
graph = tf.get_default_graph()
batch_x = graph.get_tensor_by_name(input_node_name + ':0')
networkout = graph.get_tensor_by_name(output_node_name + ':0')
testdata, testlabel = custom_data_reader_fn(data_folder)
# This will evaluate the model
label = sess.run(networkout, feed_dict={batch_x: testdata})

# Freeze model and create a UFF file:
graph_def = graph.as_graph_def() # Convert the graph to a serialized pb
frozen_graph_def = tf.graph_util.convert_variables_to_constants(sess,
    graph_def, [output_node_name])
opt_graph_def = optimize_for_inference_lib.optimize_for_inference(
    frozen_graph_def, [input_node_name], [output_node_name],
    tf.float32.as_datatype_enum)
uff.from_tensorflow(opt_graph_def, [output_node_name], quiet=False,
    output_filename='opt_model.uff')
</code></pre>

<p>that will write out a UFF file that TensorRT can utilize. The biggest issues that I encountered was:</p>

<ol>
<li>I didn't realize that the <code>optimize_for_inference_lib.optimize_for_inference</code> operation replaced the <code>iterator</code> with a <code>tf.placeholder</code></li>
<li>I did not know what node to feed data to for evaluation: you can feed data to the <code>IteratorGetNext</code> node</li>
</ol>
",2018-09-13 18:27:40,8759276,377,https://stackoverflow.com/questions/52319765,Lack of Alternative Solutions/Documentation
52447384,Estimator API: AttributeError: 'NoneType' object has no attribute 'dtype',"<p>I have already looked up the previous answers to this problem but it has not been resolved yet. I am implementing a YOLO algorithm (for object detection) from scratch and am having problem in training part. <br></p>

<p>For training, I am tf.estimator API and am using a code similar to CNN MNIST code in tensorflow <a href=""https://github.com/Hvass-Labs/TensorFlow-Tutorials"" rel=""nofollow noreferrer"">example</a>. I am getting the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""recover_v3.py"", line 663, in &lt;module&gt;
    model.train(input_fn=train_input_fn, steps=1)
  File ""/home/nyu-mmvc-019/miniconda3/envs/tf_0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 376, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/nyu-mmvc-019/miniconda3/envs/tf_0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1145, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/nyu-mmvc-019/miniconda3/envs/tf_0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1170, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/nyu-mmvc-019/miniconda3/envs/tf_0/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1133, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""recover_v3.py"", line 584, in cnn_model_fn
    loss=loss, global_step=tf.train.get_global_step())
  File ""/home/nyu-mmvc-019/miniconda3/envs/tf_0/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 400, in minimize
    grad_loss=grad_loss)
  File ""/home/nyu-mmvc-019/miniconda3/envs/tf_0/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 494, in compute_gradients
    self._assert_valid_dtypes([loss])
  File ""/home/nyu-mmvc-019/miniconda3/envs/tf_0/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 872, in _assert_valid_dtypes
    dtype = t.dtype.base_dtype
AttributeError: 'NoneType' object has no attribute 'dtype'
</code></pre>

<p>The code related to loss function in the main file is as shown(similar to official CNN MNIST example): </p>

<pre><code>if mode == tf.estimator.ModeKeys.TRAIN:
    # This gives the LOSS for each image in the batch.
    # It is importing loss function from another file (called loss_fn)
    # Apparently it returns None (not sure)
    loss = loss_fn.loss_fn(logits, labels)

    optimizer = tf.train.AdamOptimizer(learning_rate=params[""learning_rate""])

    train_op = optimizer.minimize(
        loss=loss, global_step=tf.train.get_global_step())

    # Wrap all of this in an EstimatorSpec.
    spec = tf.estimator.EstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=train_op,
        eval_metric_ops=None)

    return spec
</code></pre>

<p>Previous <a href=""https://stackoverflow.com/questions/48600538/attributeerror-nonetype-object-has-no-attribute-dtype?rq=1"">answers</a> to similar problem suggested that the loss function is returning nothing. However, when I try the loss function with randomly generated arrays, it works fine and yields normal values.</p>

<p>Also, if I return a constant like 10.0 from loss function, I still get the same error. </p>

<p>I am not sure how to proceed now. Also, is there any way I could print the loss returned by the loss function. Apparently, tf.estimator API start a tensorflow session by itself, and if I try to create another session (in order to print the value returned by loss function), I get other errors. </p>
",2018-09-21 15:59:33,10397210,21,https://stackoverflow.com/questions/52447384,Documentation Replication on Other Examples
52471921,Why there is a need of using tf.Variable?,"<p>In the following code I am unable to understand the need of using tf.Variable? I get the same value whether I use tf.Variable or omit it.</p>

<pre><code>`initial = tf.Variable(tf.truncated_normal(shape=[1,10,1], mean=0, 
stddev=0.1,seed=123))`
</code></pre>
",2018-09-24 02:09:32,10333833,155,https://stackoverflow.com/questions/52471921,Documentation Replicability
52473088,How tf.Variable maintains state of the graph?,"<p>I am trying to learn tensorflow. I am really confused with the usage of tf.Variable . I know that in machine learning we have to randomly assign weights to the filter. But this can be done with tf.truncated_normal function. Then what is the role of tf.Variable here? Documentation states that tf.Variable maintains the state of graph. What does it mean? If I omit tf.Variable result is same. So what is the role of tf.Variable? Can someone please help me to understand this?  </p>

<pre><code>`def weight_variable(shape):
    initial = tf.truncated_normal(shape, mean=0, stddev=0.1)
    return tf.Variable(initial)
#function call
filter = weight_variable([1,2,2,1])`
</code></pre>
",2018-09-24 05:24:24,10333833,155,https://stackoverflow.com/questions/52473088,Lack of Alternative Solutions/Documentation
52533156,Weight Initialization Tensorflow tf.estimator,"<p>Is there a way to adjust the weight initialization in the pre-built tf.estimator?
I would like to use the method after Xavier (<code>tf.contrib.layers.xavier_initializer</code>) or from He. Which method is used by default? I couldn't figure it out from the documentation. </p>

<p>I use the DNNRegressor.</p>
",2018-09-27 08:57:41,10203191,31,https://stackoverflow.com/questions/52533156,Documentation Ambiguity
52582188,How can I choose one of three data input pipelines in the graph runtime in the Tensorflow?,"<p>I build three data input pipelines when I construct the graph.</p>

<pre><code>images_pipe_1 = input_images('list1')
images_pipe_2 = input_images('list2')
images_pipe_3 = input_images('list3')
</code></pre>

<p>I want to choose one of them in the graph runtime according to the global_step like this:</p>

<pre><code>if global_step &lt; 2000:
  data input pipeline = images_pipe_1
if global_step &gt;= 2000 and global_step &lt; 5000
  data input pipeline = images_pipe_2
if global_step &gt;= 5000
  data input pipeline = images_pipe_3
</code></pre>

<p>But in the tensorflow, there variables like global_step are tensors, they should be operated by tf functions, not by python.
I have tried to use tf.cond, but it only can solve the problem of two options. </p>

<pre><code>images_pipe = tf.cond(tf.greater(global_step, tf.constant(2000, tf.int64)), lambda:images_pipe_2, lambda:images_pipe_1)
</code></pre>

<p>In this situation, there are three options. I do not know how I can solve it. Thanks for your help in advance.</p>
",2018-09-30 21:08:38,10410925,11,https://stackoverflow.com/questions/52582188,Documentation Replicability
52589043,How to read TFRecord files in TensorFlow from a remote HDFS file system in parallel and efficiently,"<p>I am reading TFRecords data files from a remote HDFS file system through tf.data.TFRecordDataset API in TensorFlow. However, when I increase the num_parallel_reads, say from 1 to 32, not only I don't see improvement in reading speed but I see it takes longer to read the data. Are there any tips to set num_parallel_reads properly to enhance the performance? I know tf.data.TFRecordDataset  uses parallel interleaves which is supposed to be good.</p>
",2018-10-01 10:21:07,4844279,11,https://stackoverflow.com/questions/52589043,Documentation Replication on Other Examples
52591291,Tensorflow Estimator: loss not decreasing when using tf.feature_column.embedding_column for a list of categorical variables,"<p>I'm very new to Tensorflow Estimator. I wonder if it's possible to pass an array of categorical variables as feature to the estimator and it automatically converts it to an array of embeddings. For example, the following is a record in a CSV file. It contains 2 lists of categorical variables(enclosed in brackets), ""country"" and ""watch"", 2 categorical variables, ""day_of_week"" and ""day_period"" and one target, ""movie_id"" in this case.</p>

<pre><code>day_of_week,day_period,country,movie_id,watched
SUNDAY,EVENING,[USA,UK],B2JO1owWbeLn,[WGdZ5qZmLw0,abcdef]
MONDAY,EVENING,[China],xxx,[abc,def,ijk]
</code></pre>

<p>According to the doc <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/feature_column</a>, ""day_of_week"" and ""day_period"" can be represented as ""categorical_column_with_vocabulary_list"". This is straightforward. However, ""country"", and ""watched"" are a list of categorical variables. I'd like to merge each categorical variable in a list to an embedding. From the same doc, a ""tf.feature_column.embedding_column"" would do the trick.</p>

<p>The following function builds columns representing the above input.</p>

<pre><code>def build_model_columns():
    day_of_week = tf.feature_column.categorical_column_with_vocabulary_list('day_of_week', day_of_weeks)
    day_period = tf.feature_column.categorical_column_with_vocabulary_list('day_period', day_periods)
    country = tf.feature_column.categorical_column_with_vocabulary_list('country', countries)
    watched = tf.feature_column.categorical_column_with_vocabulary_list('watched', movie_emb_ids)

    columns = [
        tf.feature_column.indicator_column(day_of_week),
        tf.feature_column.indicator_column(day_period),
        tf.feature_column.embedding_column(country, 8),
        tf.feature_column.embedding_column(watched, 32)
    ]
    return columns
</code></pre>

<p>The following is a function generating training dataset</p>

<pre><code>def tensor_to_array(tensor):
    length = tf.size(tf.string_split([tensor], """"))
    sub = tf.substr(tensor, 1, length-2) # remove the leading '[' and trailing ']'
    splits = tf.string_split([sub], delimiter=',')
    return splits

def train_input_fn():
    train_files = ""train.csv""
    target_files = ""target.csv""
    target_table, target_ids = read_table_lookup(target_files, ""movie"")

    def preprocess(day_of_week, day_period, country, movie_id, watched):

        features = {
            'day_of_week': day_of_week,
            'day_period': day_period,
            'country': tensor_to_array(country),
            'watched': tensor_to_array(watched)

        }
        # target_table is a lookup table converting ""movie_id"" to integer ""id""
        return features, target_table.lookup(movie_id) 

    dataset = (tf.contrib.data.CsvDataset(train_files, record_defaults, header=True)
           .map(preprocess, num_parallel_calls=5)
           .batch(batch_size=batch_size, drop_remainder=False)
           .repeat()
          )

    # iterator = dataset.make_initializable_iterator()
    # tf.add_to_collection(tf.GraphKeys.TABLE_INITIALIZERS, iterator.initializer)

    return dataset 
</code></pre>

<p>The following is a code snippet to create and train an estimator.</p>

<pre><code>hidden_units = [512, 512]
record_defaults = [[""""]] * 5
columns = build_model_columns()
estimator = tf.estimator.DNNClassifier(model_dir=""dir"",
                                   feature_columns=columns,
                                   hidden_units=hidden_units,
                                   n_classes=len(target_ids)) # length of all targets

estimator.train(input_fn=train_input_fn)
</code></pre>

<p>I got no error and it seems like everything should work as expected but the training loss is so huge and fluctuating around 3,xxx and never decreasing. See below</p>

<pre><code>INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /home/cocoza4/movie_models/deep/model.ckpt.
INFO:tensorflow:loss = 6538.0645, step = 0
INFO:tensorflow:global_step/sec: 17.353
INFO:tensorflow:loss = 3596.562, step = 100 (5.764 sec)
INFO:tensorflow:global_step/sec: 17.434
INFO:tensorflow:loss = 3504.936, step = 200 (5.736 sec)
INFO:tensorflow:global_step/sec: 17.4234
INFO:tensorflow:loss = 3500.0488, step = 300 (5.739 sec)
INFO:tensorflow:global_step/sec: 17.5321
INFO:tensorflow:loss = 3480.702, step = 400 (5.705 sec)
INFO:tensorflow:global_step/sec: 17.4534
INFO:tensorflow:loss = 3517.599, step = 500 (5.729 sec)
INFO:tensorflow:global_step/sec: 17.3421
INFO:tensorflow:loss = 3446.142, step = 600 (5.769 sec)
INFO:tensorflow:global_step/sec: 17.313
INFO:tensorflow:loss = 3281.3088, step = 700 (5.776 sec)
INFO:tensorflow:global_step/sec: 17.4421
INFO:tensorflow:loss = 3326.7336, step = 800 (5.731 sec)
INFO:tensorflow:global_step/sec: 17.3619
INFO:tensorflow:loss = 3464.902, step = 900 (5.762 sec)
INFO:tensorflow:global_step/sec: 17.2013
INFO:tensorflow:loss = 3364.2153, step = 1000 (5.813 sec)
INFO:tensorflow:global_step/sec: 17.4429
INFO:tensorflow:loss = 3410.449, step = 1100 (5.734 sec)
INFO:tensorflow:global_step/sec: 17.0483
INFO:tensorflow:loss = 3351.018, step = 1200 (5.866 sec)
INFO:tensorflow:global_step/sec: 17.4214
INFO:tensorflow:loss = 3386.995, step = 1300 (5.740 sec)
INFO:tensorflow:global_step/sec: 17.7965
INFO:tensorflow:loss = 3263.6074, step = 1400 (5.617 sec)
INFO:tensorflow:global_step/sec: 17.6944
INFO:tensorflow:loss = 3321.574, step = 1500 (5.652 sec)
INFO:tensorflow:global_step/sec: 17.3603
INFO:tensorflow:loss = 3234.7761, step = 1600 (5.760 sec)
</code></pre>

<p>I wonder if I've done something wrong when preparing the training data?</p>

<p>thanks</p>

<p>Peeranat F.</p>
",2018-10-01 12:35:53,3079777,83,https://stackoverflow.com/questions/52591291,Documentation Replicability
52597523,How to load_weights to a Keras model from a Tensorflow checkpoint,"<p>I have some python code to train a network using Tensorflow's TFRecords and Dataset APIs. I have built the network using tf.Keras.layers, this being arguably the easiest and fastest way. The handy function model_to_estimator()</p>

<pre><code>modelTF = tf.keras.estimator.model_to_estimator(
    keras_model=model,
    custom_objects=None,
    config=run_config,
    model_dir=checkPointDirectory
)
</code></pre>

<p>converts a Keras model to an estimator, which allows us to take advantage of the Dataset API nicely, and automatically save checkpoints to checkPointDirectory during training, and upon training completion. The estimator API presents some invaluable features, such as automatically distributing the workload over multiple GPUs, with, e.g.</p>

<pre><code>distribution = tf.contrib.distribute.MirroredStrategy()
run_config = tf.estimator.RunConfig(train_distribute=distribution)
</code></pre>

<p>Now for big models and lots of data, it is often useful to execute predictions after training using some form of saved model. It seems that as of Tensorflow 1.10 (see <a href=""https://github.com/tensorflow/tensorflow/issues/19295"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/issues/19295</a>), a tf.keras.model object supports load_weights() from a Tensorflow checkpoint. This is mentioned briefly in the Tensorflow docs, but not the Keras docs, and I can't find anyone showing an example of this. After defining the model layers again in some new .py, I have tried </p>

<pre><code>checkPointPath = os.path.join('.', 'tfCheckPoints', 'keras_model.ckpt.index')
model.load_weights(filepath=checkPointPath, by_name=False)
</code></pre>

<p>but this gives a NotImplementedError:</p>

<pre><code>Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.

2018-10-01 14:24:49.912087:
Traceback (most recent call last):
  File ""C:/Users/User/PycharmProjects/python/mercury.classifier reductions/V3.2/wikiTestv3.2/modelEvaluation3.2.py"", line 141, in &lt;module&gt;
    model.load_weights(filepath=checkPointPath, by_name=False)
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\network.py"", line 1526, in load_weights
    checkpointable_utils.streaming_restore(status=status, session=session)
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\training\checkpointable\util.py"", line 880, in streaming_restore
    ""Streaming restore not supported from name-based checkpoints. File a ""
NotImplementedError: Streaming restore not supported from name-based checkpoints. File a feature request if this limitation bothers you.
</code></pre>

<p>I would like to do as suggested by the Warning and use the 'object-based saver' instead, but I haven't found a way to do this via a RunConfig passed to estimator.train(). </p>

<p>So is there a better way to get the saved weights back into an estimator for use in prediction? The github thread seems to suggest that this is already implemented (though based on the error, probably in a different way than I am attempting above). Has anyone successfully used load_weights() on a TF checkpoint? I haven't been able to find any tutorials/examples on how this can be done, so any help is appreciated. </p>
",2018-10-01 19:18:42,9731282,212,https://stackoverflow.com/questions/52597523,Inadequate Examples
52720886,Does tf.contrib.nn.sampled_sparse_softmax_loss allow for float16 training?,"<p>Currently, tf.nn.sampled_softmax_loss does not allow for using float16. </p>

<p><a href=""https://stackoverflow.com/questions/52711895/how-to-run-define-tensorflow-graph-were-all-variables-are-in-float16-instead-ins"">How to run define Tensorflow graph were all variables are in float16 instead instead of float32</a></p>

<p>I'm looking at </p>

<p>tf.contrib.nn.sampled_sparse_softmax_loss </p>

<p>from </p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/nn/sampled_sparse_softmax_loss"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/nn/sampled_sparse_softmax_loss</a></p>

<p>And it seems that this may allow float16 values. This code for this function is here</p>

<p><a href=""https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/nn/python/ops/sampling_ops.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/nn/python/ops/sampling_ops.py</a></p>

<p>Which seems to use tf.nn.sparse_softmax_cross_entropy_with_logits</p>

<p>Which seems to have support for float16</p>

<blockquote>
  <p>logits: Unscaled log probabilities of shape [d_0, d_1, ..., d_{r-1}, num_classes] and dtype float16, float32, or float64.</p>
</blockquote>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits</a></p>

<p>However, when I try to use it, I get an error</p>

<p>My code</p>

<pre><code>import math
import numpy as np
import tensorflow as tf

vocabulary_size = 10
batch_size = 64 
embedding_size = 100 
num_inputs =4
num_sampled = 128 

graph = tf.Graph()

with graph.as_default(): #took out "" , tf.device('/cpu:0')""


    train_dataset = tf.placeholder(tf.int32, shape=[batch_size, num_inputs ])
    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])

    embeddings = tf.get_variable( 'embeddings', dtype=tf.float16,
        initializer= tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0, dtype=tf.float16) )

    softmax_weights = tf.get_variable( 'softmax_weights', dtype=tf.float16,
        initializer= tf.truncated_normal([vocabulary_size, embedding_size],
                             stddev=1.0 / math.sqrt(embedding_size), dtype=tf.float16 ) )

    softmax_biases = tf.get_variable('softmax_biases', dtype=tf.float16,
        initializer= tf.zeros([vocabulary_size], dtype=tf.float16),  trainable=False )

    embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is

    embed_reshaped = tf.reshape( embed, [batch_size*num_inputs, embedding_size] )

    segments= np.arange(batch_size).repeat(num_inputs)

    averaged_embeds = tf.segment_mean(embed_reshaped, segments, name=None)

    sam_sof_los = tf.contrib.nn.sampled_sparse_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,
                                   labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)

    loss = tf.reduce_mean( sam_sof_los )

    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss) 

    saver = tf.train.Saver()
</code></pre>

<p>My error message</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    509                 as_ref=input_arg.is_ref,
--&gt; 510                 preferred_dtype=default_dtype)
    511           except TypeError as err:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)
   1143     if ret is None:
-&gt; 1144       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1145 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)
    980         ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
--&gt; 981         (dtype.name, t.dtype.name, str(t)))
    982   return t

ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(""sampled_sparse_softmax_loss/Log:0"", shape=(64, 1), dtype=float32)'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-11-b68afd94e9bd&gt; in &lt;module&gt;()
     41 
     42     sam_sof_los = tf.contrib.nn.sampled_sparse_softmax_loss(weights=softmax_weights , biases=softmax_biases , inputs=averaged_embeds,
---&gt; 43                                    labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)
     44 
     45 

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/nn/python/ops/sampling_ops.py in sampled_sparse_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, sampled_values, remove_accidental_hits, partition_strategy, name)
    331       remove_accidental_hits=remove_accidental_hits,
    332       partition_strategy=partition_strategy,
--&gt; 333       name=name)
    334 
    335   # There is only one true label. _compute_sampled_logits puts the true logit

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed)
   1126     if subtract_log_q:
   1127       # Subtract log of Q(l), prior probability that l appears in sampled.
-&gt; 1128       true_logits -= math_ops.log(true_expected_count)
   1129       sampled_logits -= math_ops.log(sampled_expected_count)
   1130 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
    860     with ops.name_scope(None, op_name, [x, y]) as name:
    861       if isinstance(x, ops.Tensor) and isinstance(y, ops.Tensor):
--&gt; 862         return func(x, y, name=name)
    863       elif not isinstance(y, sparse_tensor.SparseTensor):
    864         try:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py in sub(x, y, name)
   8316   if _ctx is None or not _ctx._eager_context.is_eager:
   8317     _, _, _op = _op_def_lib._apply_op_helper(
-&gt; 8318         ""Sub"", x=x, y=y, name=name)
   8319     _result = _op.outputs[:]
   8320     _inputs_flat = _op.inputs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    544                   ""%s type %s of argument '%s'."" %
    545                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
--&gt; 546                    inferred_from[input_arg.type_attr]))
    547 
    548           types = [values.dtype]

TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type float16 of argument 'x'.
</code></pre>
",2018-10-09 12:17:31,3259896,5853,https://stackoverflow.com/questions/52720886,Documentation Replication on Other Examples
52731151,Tesnorflow: How to provide your own `sampled_values` for tf.nn.sampled_softmax_loss?,"<p>In tf.nn.sampled_softmax_loss, one of the optional inputs is to put your own samples values. I would like to provide my own samples values so that I can use float16 (half precision) variables. If <code>sampled_values</code> is left blank, Tensorflow will use <code>log_uniform_candidate_sampler</code> to get values, which can only return float32. </p>

<p>Here are all the inputs. </p>

<pre><code>tf.nn.sampled_softmax_loss(
    weights,
    biases,
    labels,
    inputs,
    num_sampled,
    num_classes,
    num_true=1,
    sampled_values=None,
    remove_accidental_hits=True,
    partition_strategy='mod',
    name='sampled_softmax_loss',
    seed=None
)
</code></pre>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss</a></p>

<p>This is the information they give for the sampled_values arg :</p>

<blockquote>
  <p>sampled_values: a tuple of (sampled_candidates, true_expected_count,
  sampled_expected_count) returned by a *_candidate_sampler function.
  (if None, we default to log_uniform_candidate_sampler)</p>
</blockquote>

<p>I'm trying to figure out how to provide this tuple. What exactly are the <code>sampled_candidates</code>, <code>true_expected_count</code>, <code>sampled_expected_count</code> ? </p>

<p>I know that it's sampling the weights and corresponding biases, so do I put them together in it's own tuple for <code>sampled_candidates</code> ? Also, am I putting the int for the place of the weight in the matrix, or am I putting the whole embedding itself?</p>

<p>I've also looked at Tensorflow's math supplimental on negative sampling but I couldn't find any information for my issue <a href=""https://www.tensorflow.org/extras/candidate_sampling.pdf"" rel=""noreferrer"">https://www.tensorflow.org/extras/candidate_sampling.pdf</a></p>

<p>In my search, I found this very similar question on a google forum</p>

<p><a href=""https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/6IDJ-XAIb9M"" rel=""noreferrer"">https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/6IDJ-XAIb9M</a></p>

<p>The Answer given is </p>

<blockquote>
  <p><code>sampled_values</code> is the tuple returned by our *candidate_sampler
  classes. These classes implement methods that sample contrastive
  labels (not observed, but used during training) according to some
  distribution Q for use in approximate training methods like
  noise-contrastive estimation (NCE) and Sampled Softmax. An example is
  the log_uniform_candidate_sampler, which samples labels according to
  the log-uniform distribution. </p>
  
  <p>You almost never need to provide these yourself. You would simply pass
  in the result of a call to a *candidate_sampler function in the tf.nn
  module (where * can be ""uniform"", ""log_uniform"", ""zipfian_binned"",
  etc), e.g.</p>
  
  <p>sampled_values = tf.nn.zipfian_binned_candidate_sampler(...)</p>
  
  <p>If you just want to get it to work, just leave it to None, and it
  would default to the log_uniform_candidate_sampler (often a good
  choice).</p>
  
  <p>If you are interested in the math behind this, see this document:
  <a href=""https://www.tensorflow.org/versions/r0.8/extras/candidate_sampling.pdf"" rel=""noreferrer"">https://www.tensorflow.org/versions/r0.8/extras/candidate_sampling.pdf</a>.</p>
  
  <p>But to answer your question: For each batch of observed labels L, and
  a candidate sampling distribution Q, the tuple consists of:</p>
  
  <ul>
  <li>the tensor with the actual sampled contrastive labels N, </li>
  <li>the tensor with the log-expected-values of the observed labels L under Q, i.e. log Q(L), and </li>
  <li>the tensor with the log-expected values of the contrastive labels under Q, i.e. log Q(N).</li>
  </ul>
  
  <p>The latter are required for the math to go through (see above
  document). So sampled_values contains(with a hopefully clear abuse of
  notation): </p>
  
  <p>sampled_values = (N, log Q(L), log Q(N)).</p>
</blockquote>

<p>However, I still don't know how to input a value. I'm not sure what the datatypes should be, and if N is the int place in the embedding matrix, or the embedding itself. Also, I'm guessing N should be a list of values itself, the size of the number of negative labels we have to sample. </p>

<p>I was wondering if I could get a example with some values. For example, for a negative sampling of 3, do I do something like this? </p>

<p>sampled_values = ([4,29, 12], [1, 1, 1], [0, 0, 0])</p>

<p>Also, the documentation says that the tuple should be "" returned by a *_candidate_sampler function""</p>

<p>Does that mean I need to provide a function that returns the tuple, instead of the tuple itself?</p>
",2018-10-10 00:50:39,3259896,5853,https://stackoverflow.com/questions/52731151,Documentation Replication on Other Examples
52744559,How to freeze some part of the variable in tensorflow,"<p>I've noticed that a variable can be frozen by setting <code>trainable=False</code>. I'm wondering how to freeze only part of it instead of splitting it into two variables.</p>

<p>For example, I only want to freeze the first element in <code>v = tf.Variable(tf.zeros([2])</code>. It seems that <code>grad_new = tf.multiply(grad, np.array([0,1]))</code> doesn't work.</p>
",2018-10-10 16:10:11,9475497,13,https://stackoverflow.com/questions/52744559,Documentation Replicability
52763539,Compute the mean for each row from a tf.SparseTensor in TensorFlow,"<p>I want to compute the mean for axis=0 for a <code>tf.SparseTensor</code>. I want something like <code>tf.sparse_reduce_sum</code>. TensorFlow doesn't provide a similar function for the mean calculation. Is there any way to count the values in each row in order to divide them with the sum?</p>

<pre><code>indices = np.array([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5],
               [1, 0], [1, 1], [1, 3], [1, 4], [1, 5],
               [2, 1], [2, 2], [2, 3], [2, 4],
               [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5],
               [4, 0], [4, 2], [4, 3], [4, 4], [4, 5]], dtype=np.int64)

values = np.array([7, 6, 7, 4, 5, 4,
                   6, 7, 4, 3, 4,
                   3, 3, 1, 1,
                   1, 2, 2, 3, 3, 4,
                   1, 1, 2, 3, 3], dtype=np.float64)

dense_shape = np.array([5, 6], dtype=np.int64)

tRatings = tf.SparseTensor(indices, values, dense_shape)
</code></pre>
",2018-10-11 15:13:47,9854132,314,https://stackoverflow.com/questions/52763539,Documentation Replication on Other Examples
52802359,Problem with tf.SparseTensor and tf.while_loop,"<p>I face a problem when I try to change the shape of <code>tf.SparseTensor</code> inside a <code>tf.while_loop</code>. Let's say I have this sparse tensor:</p>

<pre><code>indices = np.array([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5],
               [1, 0], [1, 1], [1, 3], [1, 4], [1, 5],
               [2, 1], [2, 2], [2, 3], [2, 4],
               [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5],
               [4, 0], [4, 2], [4, 3], [4, 4], [4, 5]], dtype=np.int64)

values = np.array([7, 6, 7, 4, 5, 4,
              6, 7, 4, 3, 4,
              3, 3, 1, 1,
              1, 2, 2, 3, 3, 4,
              1, 1, 2, 3, 3], dtype=np.float64)

dense_shape = np.array([5, 6], dtype=np.int64)

tRatings = tf.SparseTensor(indices, values, dense_shape)
</code></pre>

<p>So, I want to take a slice from the first 3 rows. I know for that purpose I can use <code>tf.sparse_slice</code> but this is an example. In my real code, I gather multiple rows from the sparse Tensor which they are not serial. The code I wrote is this:</p>

<pre><code>subTensor = tf.sparse_slice(tRatings, [0, 0], [1, 6])

i = tf.constant(1)
def condition(i, sub):
    return tf.less(i, 3)

def body(i, sub):
    tempUser = tf.sparse_slice(tRatings, [i, 0], [1, 6])
    sub = tf.sparse_concat(axis = 0, sp_inputs = [sub, tempUser])
    return [tf.add(i, 1), sub]

subTensor = tf.while_loop(condition1, body1, [i, subTensor], shape_invariants=[i.get_shape(), tf.TensorShape([2])])[1] 
</code></pre>

<p>which does't work for some reason when I run it. I get this:</p>

<pre><code>ValueError: Dimensions 1 and 2 are not compatible
</code></pre>

<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/while_loop</a> it says that:</p>

<p>The shape_invariants argument allows the caller to specify a less specific shape invariant for each loop variable, which is needed if the shape varies between iterations. The tf.Tensor.set_shape function may also be used in the body function to indicate that the output loop variable has a particular shape. The shape invariant for SparseTensor and IndexedSlices are treated specially as follows:</p>

<p>a) If a loop variable is a SparseTensor, the shape invariant must be TensorShape([r]) where r is the rank of the dense tensor represented by the sparse tensor. It means the shapes of the three tensors of the SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here is the shape of the SparseTensor.dense_shape property. It must be the shape of a vector.</p>

<p>What am I missing here?</p>
",2018-10-14 11:54:15,9854132,314,https://stackoverflow.com/questions/52802359,Documentation Replication on Other Examples
52814880,Neuron freezing in Tensorflow,"<p>I need to implement <strong>neurons freezing</strong> in CNN for a deep learning research,
I tried to find any function in the Tensorflow docs, but I didn't find anything.
How can I freeze specific neuron when I implemented the layers with tf.nn.conv2d?</p>
",2018-10-15 10:41:04,6194504,9,https://stackoverflow.com/questions/52814880,Documentation Replicability
52827483,Tensorflow: What if my cond is not a scalar in tf.cond in while loop?,"<p>in <code>tf.cond</code> of tensorflow, <code>cond</code> has to be a scalar, but in my case <code>cond</code> need to be rank 1 with shape [batch_size]. Is there any method to solve this problem? Have tensorflow provided a solution to it?</p>

<pre><code>import tensorflow as tf
seq_len = 10
while_length = 10
batch_size = 4

output_ta = tf.TensorArray(
        dtype=tf.int32,
        size=seq_len,
        tensor_array_name='example_1')

cond_tensor = tf.constant([3, 4, 5, 6])


def _step(time, arrays):
    time_tensor = tf.tile(tf.expand_dims(time, -1), multiples=[batch_size])
    arrays = arrays

    def _true_function():
        return tf.constant([1] * seq_len)

    def _false_function():
        return tf.constant([0] * seq_len)

    bool_cond = tf.less(time_tensor, cond_tensor)
    arrays_write = tf.cond(bool_cond, true_fn=_true_function, false_fn=_false_function)
    arrays = arrays.write(time, arrays_write)
    return time + 1, arrays


trace_time, outputs_tensor_arrays = tf.while_loop(
        cond=lambda time, *_: time &lt; while_length,
        body=_step,
        loop_vars=[0, output_ta],
        parallel_iterations=32,
        swap_memory=True)

axes = [1, 0]
output = tf.transpose(outputs_tensor_arrays, axes)

with tf.Session() as sess:
    sess.run(output)
</code></pre>
",2018-10-16 03:17:22,7547975,31,https://stackoverflow.com/questions/52827483,Documentation Replicability
52888624,What dose zero_debias mean in tf.train.ExponentialMovingAverage?,"<p>tf.train.ExponentialMovingAverage has a parameter 'zero_debias', but I don't know what will happen if I set it to True. So what's this parameter for? </p>

<p>Great thanks in advance.</p>
",2018-10-19 08:32:02,9589731,538,https://stackoverflow.com/questions/52888624,Documentation Replicability
52938457,Tensorflow debugging,"<pre><code>        y1 = tf.stack([55, 0, 55])
        y2 = tf.stack([11 22 44])
        y3 = tf.constant([0., 0., 1.])
        x = tf.stack([y1, y2, y3])
        x1 = tf.reshape(x, [3, 3])
</code></pre>

<p>Is there a way to print or obtain the above tensor <code>x1</code> or <code>x</code> in tensorflow. The <code>tf.print</code> and <code>sess.eval(x1)</code>? It seems to not print the stacked frame.</p>

<p>Tried the <code>tfdg</code> too</p>

<pre><code>sess = tf.Session()
        sess = tf_debug.TensorBoardDebugWrapperSession(sess, ""Host:7000"")
        sess.run(x1)
</code></pre>
",2018-10-22 22:13:22,3129625,91,https://stackoverflow.com/questions/52938457,Documentation Replicability
52956268,tf.data.Dataset: Map fails to split string,"<p>I have a <code>tf.data.Dataset</code> that I've created like this:</p>

<pre><code>dataset = tf.data.Dataset.from_tensor_slices(({""reviews"": x_train}, y_train))
</code></pre>

<p>I want to split just the reviews (strings) on whitespace.  When I do this:</p>

<pre><code>dataset = dataset.map(lambda string: tf.string_split([string]))
</code></pre>

<p>Python complains, telling me:</p>

<pre><code>TypeError: &lt;lambda&gt;() takes exactly 1 argument (2 given)
</code></pre>

<p>I've looked at the docs and it's not obvious why Python thinks I've given two arguments...any ideas?</p>

<p>Thanks!</p>
",2018-10-23 19:07:45,1316501,9011,https://stackoverflow.com/questions/52956268,Documentation Replicability
52966243,Tensorflow: NotImplementedError: The reduce() transformation does not currently support nested datasets as inputs,"<p>In Tensorflow 1.12 the <code>tf.data.Dataset.reduce()</code> and <code>tf.data.Dataset.window()</code> methods are introduced.</p>

<p>From the release notes:</p>

<ul>
<li><p>""New <code>tf.data.Dataset.reduce()</code> API allows users to reduce a finite dataset to a single element using a user-provided reduce function.""</p></li>
<li><p>""New <code>tf.data.Dataset.window()</code> API allows users to create finite windows of input dataset; when combined with the <code>tf.data.Dataset.reduce()</code> API, this allows users to implement customized batching.""</p></li>
</ul>

<p>However how to use these functions?</p>

<pre><code>def reduce_func(old_state, input_element):
    pdb.set_trace()
    return new_state

dataset = tf.data.Dataset.from_generator(frame_generator, (tf.string, tf.string))
dataset = dataset.window(2).reduce(np.int64(0), reduce_func)
</code></pre>

<p>This gives a NotImplementedError:</p>

<blockquote>
  <p>NotImplementedError: The reduce() transformation does not currently<br>
  support nested datasets as inputs. </p>
</blockquote>

<p>I use tensorflow version '1.12.0-rc1'</p>

<p>EDIT:
From <a href=""https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/data/sliding_window_batch"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/data/sliding_window_batch</a></p>

<p><em>THIS FUNCTION IS DEPRECATED.</em> It will be removed in a future version. Instructions for updating: Use <code>tf.data.Dataset.window(size=window_size, shift=window_shift, stride=window_stride).flat_map(lambda x: x.batch(window.size))</code></p>

<p>But how to use this if the dataset is generated with</p>

<pre><code>dataset = tf.data.Dataset.from_generator(frame_generator, (tf.string, tf.string))
</code></pre>

<p>So each item in the dataset contains two elements. Then there is a TypeError:</p>

<blockquote>
  <p>TypeError: () takes 1 positional argument but 2 were given</p>
</blockquote>

<p>EDIT: 
Solved by using zip</p>

<pre><code>dataset = tf.data.Dataset.from_generator(frame_generator, (tf.string, tf.string))
window_size = 2
dataset = dataset.window(window_size).flat_map(lambda x,y: tf.data.Dataset.zip((x,y)).batch(window_size))
dataset = dataset.map(self.parse_function)
</code></pre>
",2018-10-24 10:05:08,987397,1395,https://stackoverflow.com/questions/52966243,Documentation Replication on Other Examples
53027716,differentiable histogram in tensorflow,"<p>How can one get a differentiable histogram function in tensorflow. I want to use the histogram of images to calculate a particular loss function. But the histogram function provided by tensorflow, tf.histogram_fixed_width() are not differentiable. How can I go about this ?</p>
",2018-10-28 01:42:30,4207206,1170,https://stackoverflow.com/questions/53027716,Documentation Replicability
53053649,Tensorflow: Truncating a Tensor Seems to Have No Effect,"<p>I'm using the <code>tf.data.Dataset</code> API and am trying to truncate a bunch of tensors to length 100.  Here's what my <code>dataset</code> looks like:</p>

<pre><code>dataset = tf.data.Dataset.from_tensor_slices(({'reviews': x}, y))
</code></pre>

<p>My reviews are just movie reviews (strings), so I perform some preprocessing and map that function on my dataset:</p>

<pre><code>def preprocess(x, y):
    # split on whitespace
    x['reviews'] = tf.string_split([x['reviews']])
    # turn into integers
    x['reviews'], y = data_table.lookup(x['reviews']), labels_table.lookup(y)
    x['reviews'] = tf.sparse_tensor_to_dense(x['reviews'])
    # truncate at length 100
    x['reviews'] = x['reviews'][:100]
    x['reviews'] = x['reviews'][0]
    x['reviews'] = tf.pad(x['reviews'],
           paddings=[[100 - tf.shape(x['reviews'])[0], 0]],
           mode='CONSTANT',
           name='pad_input',
           constant_values=0)
    return x, y

dataset = dataset.map(preprocess)
</code></pre>

<p>However, my code fails with:</p>

<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Paddings must be non-negative: -140 0
</code></pre>

<p>On an input of length 240. So, it seems like my padding step calculates 100 - 240 = -140 and I get this error.</p>

<p>Here's my question: how is this possible, given that I truncate to length 100 with:</p>

<pre><code>x['reviews'] = x['reviews'][:100]
</code></pre>

<p>It seems clear that this line isn't having any effect, so I'm trying to understand why. The docs are very clear that this is acceptable syntactic sugar for <code>tf.slice</code>: </p>

<pre><code>Note that tf.Tensor.getitem is typically a more pythonic way to 

perform slices, as it allows you to write foo[3:7, :-2] instead of 

tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2]).
</code></pre>

<p>Any ideas?</p>

<p>Thanks!</p>
",2018-10-29 20:54:02,1316501,9011,https://stackoverflow.com/questions/53053649,Documentation Ambiguity
53107594,How do I import and use quantized_matmul and quantized_biasadd operations in tensorflow,"<p>I am trying to use the quantized matmul operation in tensorflow. However I am not sure if I am doing it right. I could not find an example as to how to call the function and use it.</p>

<p>I know that quantized conv2D can be called as tf.nn.conv2D(), just wanted to know a similar way of calling quantized_matmul operation as well.</p>

<p>The class and the functions are present in tensorflow library and are documented below:</p>

<p>Quantized Bias Add:
<a href=""https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/quantized-bias-add"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/quantized-bias-add</a></p>

<p>Quantized Matmul:
<a href=""https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/quantized-mat-mul"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/quantized-mat-mul</a></p>

<p>Thanks and Regards,
Abhinav George</p>
",2018-11-01 18:53:16,9104473,85,https://stackoverflow.com/questions/53107594,Documentation Replication on Other Examples
53164055,training tensorflow data API with procedural on-the-fly data generation,"<p>My question is similar to <a href=""https://stackoverflow.com/questions/47318734/on-the-fly-generation-with-dataset-api-tensorflow"">this</a> one, in that I would like to generate batches of training data on the fly. I have a function <code>get_random_batch(batch_size, input_path, target_path, **other_kwargs)</code> which returns <code>inputs</code> and <code>targets</code>, but it is a pure vanilla python / numpy function, not tensorflow. So it returns numpy arrays, not tensors. (The function is quite a large complex one with some 3rd party libs. To port it to tensorflow is not very feasible. To preprocess everything is also not feasible as the data is huge, and I don't have the space to store it all preprocessed! In fact I don't even train a single epoch, I just take random selections for hundreds of thousands of iterations).</p>

<p>For a few years I've been using tensorflow's low level training API: generate a batch of input-target pairs, run forward pass with feed (into placeholders) and fetch, calculate loss, apply gradients, repeat etc.</p>

<p>Now I finally would like to try out the newer data API (so that I can use the Keras API for building the model and 'fitting' etc), but I can't figure out how to migrate. All of the documentation I've seen assumes that the data loading and preprocessing is part of the graph, and the output of the dataset are already tensors. </p>

<p>--</p>

<p><strong>Update</strong>: Ok this seems to work with <strong>tf.data.Dataset.from_generator</strong></p>

<pre><code>compile_kwargs = dict(
    optimizer = tf.train.AdamOptimizer(3e-4),
    loss = 'mse',
    metrics = ['accuracy', 'mse']
)

def prepare_data():
    x,t = get_random_training_pair() # this returns one training pair (each np.float32 ndarrays)
    yield (x, t)

dataset = tf.data.Dataset.from_generator(prepare_data, (tf.float32, tf.float32))
dataset = dataset.batch(128).repeat()
model = build_keras_model()
model.compile(**compile_kwargs)
model.summary()
model.fit(dataset, epochs=10, steps_per_epoch=100, shuffle=False)
</code></pre>
",2018-11-06 00:05:33,214488,3634,https://stackoverflow.com/questions/53164055,Documentation Ambiguity
53167302,Does tf.keras.layers.Conv2D as first layer in model truly need input_shape?,"<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"" rel=""nofollow noreferrer"">the official document</a> on <code>tf.keras.layers.Conv2D</code>,</p>

<blockquote>
  <p>When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=""channels_last"".</p>
</blockquote>

<p>but actually without input_shape it does work in both graph execution and eager execution environment.</p>

<p>In graph execution, </p>

<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense

class CNN(tf.keras.Model):

    def __init__(self):
        super(CNN, self).__init__()
        self.conv = Conv2D(1, 3, padding='same', data_format='channels_first')
        self.flatten = Flatten()
        self.dense = Dense(1)

    def call(self, inputs):
        x = self.conv(inputs)
        x = self.flatten(x)
        return self.dense(x)


cnn = CNN()
inputs = tf.random_uniform([2, 3, 16, 16])
outputs = cnn(inputs)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    outputs = sess.run(outputs)
    print(outputs)
</code></pre>

<p>works without any error and in eager execution,</p>

<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense
tf.enable_eager_execution()

class CNN(tf.keras.Model):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv = Conv2D(1, 3, padding='same', data_format='channels_first')
        self.flatten = Flatten()
        self.dense = Dense(1)

    def call(self, inputs):
        x = self.conv(inputs)
        x = self.flatten(x)
        return self.dense(x)


cnn = CNN()
inputs = tf.random_uniform([2, 3, 16, 16])
outputs = cnn(inputs)
print(outputs)
</code></pre>

<p>also does.</p>

<p>Q1: Does <code>tf.keras.layers.Conv2D</code> as the first layer in a model truly need to specifying <code>input_shape</code>?</p>

<p>Q2: If not, when is it needed and why is it mentioned so in the official document?</p>

<p>UPDATE1:
<a href=""https://www.tensorflow.org/tutorials/eager/custom_layers#layers_common_sets_of_useful_operations"" rel=""nofollow noreferrer"">Tutorial on tf.keras</a> says </p>

<blockquote>
  <p>The number of input dimensions is often unnecessary, as it can be inferred
  the first time the layer is used, but it can be provided if you want to 
  specify it manually, which is useful in some complex models.</p>
</blockquote>

<p>UPDATE2:
<code>git blame</code> of docstring in TensorFlow source revealed that this document is copied from Keras API (which is not TensorFlow keras API).</p>
",2018-11-06 07:14:54,8384504,374,https://stackoverflow.com/questions/53167302,Documentation Replication on Other Examples
53233123,tf.data: Combining multiple from_generator() datasets to create batches padded across time windows,"<p>I am working on a timeseries problem where each timeseries is fairly long (10^3-10^4 timesteps, and each timeseries is of different length).</p>

<p>For each sequence, I can define a Python generator that yields values one timestep at a time. I am using the <code>tf.data.Dataset.from_generator()</code> constructor to wrap these generators into the tf.data API. The documentation suggests using <code>from_generator()</code> along with the <code>tf.contrib.data.parallel_interleave()</code> transformation to parallelize the extraction from my Python generators.</p>

<p>My downstream use for these data is a stateful RNN (e.g. LSTM or GRU). I want to chunk up the timeseries into smaller (~10^2) windows and use each chunk as a training example (i.e., truncated BPTT). Since my data are streaming, I think that means saving up <code>window_size</code> timesteps of each generator before passing it on through the pipeline, to be batched with the other generators' data. I also want to save the RNN state across these chunks so I can still learn long-term dependencies.</p>

<p>My issue comes with wanting to create padded batches of these generators' batched outputs. Ideally, I would want to present to my neural network windows of the generator outputs, with padding as necessary when some subset of the generators exhaust themselves before others. I know that if I consume the entire generator output for each generator, then use <code>Dataset.padded_batch()</code> I can do this (and can then slice the padded batch across the time dimension into windowed chunks as necessary). However, I want to pass each window to the neural network it becomes available. If one of the generators exhausts itself before the others, I want to pad it with the padding value until all others have, so I can reset the RNN state and begin the next batch of generators with an empty initial RNN state. I am stuck here because the dataset resulting from <code>tf.contrib.data.parallel_interleave()</code> transformation discards each generator when it becomes exhausted, and the timeseries do not maintain a consistent ordering across samples from it.</p>

<p>Here is a small example:</p>

<pre><code>import tensorflow as tf

def stepwise_generator(length):
    for i in range(length):
        yield i

lengths = list(range(1,10,2)) # [1, 3, 5, 7, 9]

window_length = 4
batch_size = 3

dataset = tf.data.Dataset.from_tensor_slices(lengths)

gen = lambda length: tf.data.Dataset.from_generator(
    stepwise_generator, tf.float32, output_shapes=[], args=(length,)
).batch(window_length) # this batching saves window_length timesteps per generator

dataset = dataset.apply(
    tf.contrib.data.parallel_interleave(gen, cycle_length=batch_size)
)

dataset = dataset.padded_batch(batch_size, (-1,), np.inf)
# batching 3 generators at once, and padding exhausted ones with inf.
# using a batch_size value no more than cycle_length above means we
# shouldn't start a new generator mid-batch (i think)

iterator = dataset.make_one_shot_iterator()
tensor = iterator.get_next()

outs = []
with tf.Session() as sess:
    while True:
        try:
            out = sess.run(tensor)
            outs.append(out)
        except tf.errors.OutOfRangeError:
            break

print(np.asarray(outs))
</code></pre>

<p>Output:</p>

<pre><code>[[[ 0. inf inf inf]   # batch 1
  [ 0.  1.  2. inf]
  [ 0.  1.  2.  3.]]

 [[ 4. inf inf inf]   # batch 2 - the generator in index -1 in the
  [ 0.  1.  2.  3.]   # previous batch gets cycled to index 0 and two
  [ 0.  1.  2.  3.]]  # new generators are initiated

 [[ 4.  5.  6. inf]   # batch 3 - more generator cycling, and the one in
  [ 4.  5.  6.  7.]   # index 1 also gets cycled to index 2 in the same
  [ 8. inf inf inf]]] # batch (because we have run out of generators in
                      # parallel_interleave)
</code></pre>

<p>My desired output would be something like</p>

<pre><code>[[[ 0. inf inf inf]   # batch 1
  [ 0.  1.  2. inf]
  [ 0.  1.  2.  3.]]

 [[inf]               # batch 2 - the leftover timestep from a padded 
  [inf]               # batch of the first 3 generators
  [4. ]]

 [[ 0.  1.  2.  3.]   # batch 3 - only two generators are left so this is 
  [ 0.  1.  2.  3.]]  # an end-of-epoch smaller batch

 [[ 4.  5.  6. inf]   # batch 4
  [ 4.  5.  6.  7.]]

 [[inf]               # batch 5
  [ 8.]]]
</code></pre>

<p>Here, the internal states of the RNNs would be reset after batch 2 and 5.</p>

<p>Again, the desired output can be simple to create if I consume the entirety of each generator's output, then pad, batch, and slice, but I want to produce batches as the generators, which may be each receiving data in real-time from e.g. a separate simulation, make them available.</p>
",2018-11-09 20:52:32,10630478,31,https://stackoverflow.com/questions/53233123,Documentation Replication on Other Examples
53247534,"TFRecord IO slower than python hdf5 reader, how do I improve its speed?","<p>I was following the official TF giude to use the <code>tf.data.Dataset</code> API for building data pipeline, but I found it ~2 times slower than my python data pipeline using hdf5.</p>

<h2>Here's my experiment result:</h2>

<pre>
TFRecordDataset: 660 thousand samples/second 
hdf5 reader + feed_dict to placeholder: 1.1 million samples/second
</pre>

<p>My experiment setting is:<br>
    - batch size=1000,<br>
    - print log every 10 million samples to show the time,<br>
    - run a <strong>fake model</strong> that only takes data as input and do not compute anything. </p>

<p>what's worse is that when I set batch size=10000, it becomes:  </p>

<pre>
TFRecordDataset: 760 thousand samples/second 
hdf5 reader + feed_dict to placeholder: 2.1 million samples/second
</pre>

<h2>Here's my code for reading tfrecord</h2>

<pre class=""lang-py prettyprint-override""><code>def parse_tfrecord_batch(record_batch):
    FEATURE_LEN = 29
    dics = {
        'label': tf.FixedLenFeature(shape=(), dtype=tf.int64),
        'feature_id': tf.FixedLenFeature(shape=(FEATURE_LEN,), dtype=tf.int64),
        'feature_val': tf.FixedLenFeature(shape=(FEATURE_LEN,), dtype=tf.float32)
    }
    parsed_example = tf.parse_example(record_batch, dics)
    return parsed_example['feature_id'], parsed_example['feature_val'], parsed_example['label']

class fakeModel:
    def __init__(self, train_filenames):
        self.graph = tf.Graph()
        with self.graph.as_default():
            dataset = tf.data.TFRecordDataset(train_filenames)
            dataset = dataset.repeat()
            dataset = dataset.batch(1000)
            dataset = dataset.map(parse_tfrecord_batch, num_parallel_calls=1)
            dataset = dataset.prefetch(1000)
            self.iterator = dataset.make_initializable_iterator()
            self.id, self.wt, self.label = self.iterator.get_next()

            self.train_preds = tf.identity(self.lbl_hldr)
</code></pre>

<p>I've tune the <code>num_parallel_calls</code> to 2, 10. Not working.  </p>

<p>I've also tuned the <code>prefetch(n)</code> from 1 to 1000, which has little improvement.  </p>

<p>My question is:<br>
Is there any way to improve my tfrecord data pipeline? Am I missing something in my code?   </p>

<p>Appreciate it for any help.</p>
",2018-11-11 09:51:08,6088463,167,https://stackoverflow.com/questions/53247534,Documentation Replicability
53272508,inception v3 using tf.data?,"<p>I'm using a bit of code that is derived from inception v3 as distributed by the Google folks, but it's now complaining that the queue runners used to read the data are deprecated (tf.train.string_input_producer in image_processing.py, and similar).  Apparently I'm supposed to switch to tf.data for this kind of stuff.</p>

<p>Unfortunately, the documentation on tf.data isn't doing much to relieve my concern that I've got too much data to fit in memory, especially given that I want to batch it in a reusable way, etc. I'm confident that the tf.data stuff <em>can</em> do this; I just don't know <em>how</em> to do it. Can anyone point me to a full example of code that uses tf.data to deal with batches of data that won't all fit in memory?  Ideally, it would simply be an updated version of the inception-v3 code, but I'd be happy to try and work with anything.  Thanks!</p>
",2018-11-13 01:35:08,7274120,37,https://stackoverflow.com/questions/53272508,Lack of Alternative Solutions/Documentation
53367734,How to implement average pooling in case of Conv1d in tensorflow?,"<p>I want to implement the average pooling in conv1d. But <code>tf.nn.avg_pool</code> function can only be implemented on 4 dimensional tensor. So what should I do to overcome this problem? </p>

<pre><code>def avg_pool(conv_out):
    return tf.nn.avg_pool(conv_out,ksize=[1,1,2,1],strides=[1,1,2,1],padding='SAME')

i = tf.constant([1, 0, 2, 3, 0, 1], dtype=tf.float32)

data   = tf.reshape(i, [1, int(i.shape[0]), 1], name='data')

kernel = tf.Variable(tf.random_normal([2,1,1]))

conv_out = tf.nn.conv1d(data, kernel, 2, 'VALID')
pool_out = avg_pool(conv_out)
</code></pre>
",2018-11-19 02:59:53,10631580,39,https://stackoverflow.com/questions/53367734,Documentation Replicability
53424304,Failed to make Dataset.filter() work in the model/official/resnet/resnet_run_loop.py file,"<p>In the official resnet model, I want to filters the dataset from test.bin by the value of 'label' when eval_only set to be True. I tried the tf.data.Dataset.filter() function to get only one class of test data but it didn't work.</p>

<pre><code>dataset = dataset.filter(lambda inputs, label: tf.equal(label,15))
</code></pre>

<p>I put this code in the resnet_run_loop.process_record_dataset function, but it raised an error</p>

<pre><code> raise ValueError(""`predicate` must return a scalar boolean tensor."")
</code></pre>

<p>I found that the shape of tensor 'label' is (?,) :'Tensor(""arg1:0"", shape=(?,), dtype=int32, device=/device:CPU:0)' </p>
",2018-11-22 05:18:39,5801328,41,https://stackoverflow.com/questions/53424304,Documentation Replication on Other Examples
53466500,Can't save and load a trained CNN model for binary image classification,"<p>I have built a Binary Image classifier using Convolutional Neural Networks using TensorFlow.It is running fine, however, each time it takes too long to train from scratch. So, I want to save the trained model and load it next time. I can't seem to understand how to implement <a href=""https://www.tensorflow.org/guide/saved_model"" rel=""nofollow noreferrer"">these</a> guides in my program as shown in the TensorFlow documentation. 
Here's the full code: </p>

<pre><code># Python program to create
# Image Classifier using CNN

# Importing the required libraries
import cv2
import os
import numpy as np
from random import shuffle
from tqdm import tqdm
from keras.models import Sequential
'''Setting up the env'''

TRAIN_DIR = 'D:\\Project\\Final_Project\\chest_xray\\train\\'
TEST_DIR = 'D:\\Project\\Final_Project\\chest_xray\\test0\\'
check_point = 'D:\\Project\\Final_Project\\chest_xray\\chkpt\\'
IMG_SIZE = 80
LR = 1e-4

'''Setting up the model which will help with tensorflow models'''
MODEL_NAME = 'NormalVsAbnormalXRays-{}-{}.model'.format(LR, '6conv-basic')

'''Labelling the dataset'''


def label_img(img):
    word_label = img.split('.')[-3]
    # DIY One hot encoder
    if word_label == 'Nor':
        return [1, 0]
    elif word_label == 'Pne':
        return [0, 1]
    else :
        return[0, 0]

'''Creating the training data'''


def create_train_data():
    # Creating an empty list where we should the store the training data
    # after a little preprocessing of the data
    training_data = []

    # tqdm is only used for interactive loading
    # loading the training data
    for img in tqdm(os.listdir(TRAIN_DIR)):
        # labeling the images
        label = label_img(img)

        path = os.path.join(TRAIN_DIR, img)

        # loading the image from the path and then converting them into
        # greyscale for easier covnet prob
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)

        # resizing the image for processing them in the covnet
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))

        # final step-forming the training data list with numpy array of the images
        training_data.append([np.array(img), np.array(label)])

        # shuffling of the training data to preserve the random state of our data
    shuffle(training_data)

    # saving our trained data for further uses if required
    np.save('train_data.npy', training_data)
    return training_data


'''Processing the given test data'''


# Almost same as processing the traning data but
# we dont have to label it.
def process_test_data():
    testing_data = []
    for img in tqdm(os.listdir(TEST_DIR)):
        path = os.path.join(TEST_DIR, img)
        img_num = img.split('.')[0]
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
        testing_data.append([np.array(img), img_num])

    shuffle(testing_data)
    np.save('test_data.npy', testing_data)
    return testing_data


'''Running the training and the testing in the dataset for our model'''
#train_data = create_train_data()
#test_data = process_test_data()

train_data = np.load('train_data.npy')
test_data = np.load('test_data.npy')
'''Creating the neural network using tensorflow'''
# Importing the required libraries
import tflearn
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.estimator import regression

import tensorflow as tf
model = Sequential()
tf.reset_default_graph()


saver = tf.train.import_meta_graph('D:\\Project\\Final_Project\\chest_xray\\check_point-78.meta')
convnet = input_data(shape=[None,IMG_SIZE, IMG_SIZE, 1], name='input')

convnet = conv_2d(convnet, 32, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)


convnet = conv_2d(convnet, 64, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)


convnet = conv_2d(convnet, 128, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)

convnet = conv_2d(convnet, 64, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)

convnet = conv_2d(convnet, 32, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)

convnet = fully_connected(convnet, 1024, activation='relu')
convnet = dropout(convnet, 0.3)

convnet = fully_connected(convnet, 2, activation='softmax')
convnet = regression(convnet, optimizer='adam', learning_rate=LR,
                     loss='categorical_crossentropy', name='targets')

model = tflearn.DNN(convnet, tensorboard_dir='log', checkpoint_path='check_point',best_checkpoint_path= 'check_point',max_checkpoints= 5)

# Splitting the testing data and training data
train = train_data
test = train_data

'''Setting up the features and lables'''
# X-Features &amp; Y-Labels

X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
Y = [i[1] for i in train]
test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
test_y = [i[1] for i in test]

'''Fitting the data into our model'''
# epoch = 40 taken
model.fit({'input': X}, {'targets': Y}, n_epoch=1,
          validation_set=0.05,
          snapshot_step=500, show_metric=True, run_id=MODEL_NAME)
model.save(MODEL_NAME)

'''Testing the data'''
import matplotlib.pyplot as plt

# if you need to create the data:
# test_data = process_test_data()
# if you already have some saved:
test_data = np.load('test_data.npy')

fig = plt.figure(figsize=(80,80))

for num, data in enumerate(test_data[:1]):


    img_num = data[1]
    img_data = data[0]

    y = fig.add_subplot(1, 1, num + 1)
    orig = img_data
    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)

    # model_out = model.predict([data])[0]
    model_out = model.predict([data])[0]

    if np.argmax(model_out) == 1:
        str_label = 'Abnormal'
    else:
        str_label = 'Normal'

    y.imshow(orig, cmap='gray')
    plt.title(str_label,fontsize=20)
    y.axes.get_xaxis().set_visible(False)
    y.axes.get_yaxis().set_visible(False)
 plt.show()
</code></pre>

<p>I have tried to use saver = <code>tf.train.import_meta_graph('D:\\Project\\Final_Project\\chest_xray\\check_point-78.meta')</code> to import the graph but I get this error</p>

<pre><code>Traceback (most recent call last):
  File ""D:/Project/Final_Project/chest_xray/Final_CNN.py"", line 104, in &lt;module&gt;
    saver = tf.train.import_meta_graph('D:\\Project\\Final_Project\\chest_xray\\check_point-78.meta')
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1674, in import_meta_graph
    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1696, in _import_meta_graph_with_return_elements
    **kwargs))
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\meta_graph.py"", line 852, in import_scoped_meta_graph_with_return_elements
    ops.prepend_name_scope(value, scope_to_prepend_to_names))
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3490, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3550, in _as_graph_element_locked
    ""graph."" % repr(name))
KeyError: ""The name 'Adam' refers to an Operation not in the graph.""
</code></pre>

<p>Process finished with exit code 1</p>
",2018-11-25 10:14:35,8023082,83,https://stackoverflow.com/questions/53466500,Documentation Replicability
53527368,Translating tensorflows conv2d to numpy/scipy operations?,"<p>This is the documentation for tf.nn.conv2d: Given an input tensor of shape [batch, in_height, in_width, in_channels] and a filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels], this op performs the following</p>

<ol>
<li>Flattens the filter to a 2-D matrix with shape [filter_height *
filter_width * in_channels, </li>
<li>Extracts image patches from the input tensor to form a virtual tensor of shape [batch, out_height, out_width, filter_height *
filter_width * in_channels].</li>
<li>For each patch, right-multiplies the filter matrix and the image patch vector.</li>
</ol>

<p>In other words, it takes in a tensor of n images and does convolution with out_channel filters. </p>

<p>I am trying to translate to code that uses only numpy operations and the code is the following:</p>

<pre><code>def my_conv2d(x, kernel):
   nf = kernel.shape[-1]  # number of filters
   rf = kernel.shape[0]  # filter size
   w = kernel
   s = 1 # stride

   h_range = int((x.shape[2] - rf) / s) + 1  # (W - F + 2P) / S
   w_range = int((x.shape[1] - rf) / s) + 1  # (W - F + 2P) / S
   np_o = np.zeros((1, h_range, w_range, nf))
   for i in range(x.shape[0]):
     for z in range(nf):
       for _h in range(h_range):
         for _w in range(w_range):
           np_o[0, _h, _w, z] = np.sum(x[i, _h * s:_h * s + rf, _w * s:_w * s 
                                + rf, * w[:, :, :, z])                     
    return np_o
</code></pre>

<p>The problem is that code is extremely slow. Are there any numpy or scipy functions that can replicate what tensorflows' conv2d is doing that is of similar efficiency? I have looked at <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html"" rel=""nofollow noreferrer"">https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html</a> and it does convolution ONCE, meaning I have to pass a 2d tensor alongside a 2d kernel (it does not do multiple filters).
None of the previous stackoverflow questions helped much with this.</p>

<p>Thanks</p>

<p>Edit: did some testing and my code is about 44000% slower than doing tf.nn.conv2d!</p>
",2018-11-28 20:11:34,4505889,43,https://stackoverflow.com/questions/53527368,Documentation Ambiguity
53539040,tf.nn.bidirectional_dynamic_rnn returns single value in Tensorflow,"<p>tf.nn.bidirectional_dynamic_rnn is usually used as follows.</p>

<pre><code> encoder_outputs, encoder_state = tf.nn.bidirectional_dynamic_rnn(cell_fw=fw_cell, cell_bw=bw_cell, 
                                                                  inputs=inputs, sequence_length=sequence_size,
                                                                  dtype=tf.float64)
</code></pre>

<p>However, when I see the following code, I'm not sure what value is returned in _.</p>

<pre><code>output = tf.nn.bidirectional_dynamic_rnn(fw_cell, bw_cell, dtype=tf.float32,
                                          inputs = X, sequence_length = seq_len)
_, ((_, output_fw), (_, output_bw)) = output
</code></pre>

<p>Can you tell me what is returned in _?</p>
",2018-11-29 12:25:46,8940996,11,https://stackoverflow.com/questions/53539040,Documentation Replicability
53572533,What is the second argument of TensorFlow's tf.data.filter() that I find no documentation of?,"<p>I recently had a <code>TypeError</code> when using</p>

<pre><code>def lie_filter(line):
    return tf.equal(line['lie_id'], 2)
</code></pre>

<p>in</p>

<pre><code>dataset = (
    tf.data
    .TextLineDataset('shots.csv')
    .skip(1)
    .map(decode_line)
    .filter(lie_filter)
    .cache())
</code></pre>

<p>The exact error was <code>TypeError: lie_filter() takes 1 positional argument but 2 were given</code>.</p>

<p>Simply changing the function signature to <code>lie_filter(line, x)</code> made the error go away and the filtering appears to work as intended. However, it left me wondering what is this mysterious second argument.</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#filter"" rel=""nofollow noreferrer"">TensorFlow manual for tf.data.filter()</a> only specifies one argument. There are also numerous examples by TensorFlow where filtering is done as per my attempt above. Take a look at, e.g., <a href=""https://github.com/tensorflow/tensorflow/blob/6d14dcba7225d205f2e7834551f42385802aa2cf/tensorflow/examples/get_started/regression/imports85.py#L116"" rel=""nofollow noreferrer"">imports85.py</a>.</p>

<p>Printing the <code>x</code> inside <code>lie_filter</code> yields <code>Tensor(""arg12:0"", shape=(), dtype=float32)</code>.</p>

<p>What is the second argument and where can I find documentation about it?</p>

<p>Thank you!</p>
",2018-12-01 15:56:36,7676920,1139,https://stackoverflow.com/questions/53572533,Documentation Completeness
53583456,What problem does a reinitializable iterator solve?,"<p>From the <a href=""https://www.tensorflow.org/guide/datasets#creating_an_iterator"" rel=""nofollow noreferrer"">tf.data documentation</a>:</p>

<blockquote>
  <p>A reinitializable iterator can be initialized from multiple different
  Dataset objects. For example, you might have a training input pipeline
  that uses random perturbations to the input images to improve
  generalization, and a validation input pipeline that evaluates
  predictions on unmodified data. These pipelines will typically use
  different Dataset objects that have the same structure (i.e. the same
  types and compatible shapes for each component).</p>
</blockquote>

<p>the following example was given:</p>

<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                           training_dataset.output_shapes)
next_element = iterator.get_next()

training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

# Run 20 epochs in which the training dataset is traversed, followed by the
# validation dataset.
for _ in range(20):
  # Initialize an iterator over the training dataset.
  sess.run(training_init_op)
  for _ in range(100):
    sess.run(next_element)

  # Initialize an iterator over the validation dataset.
  sess.run(validation_init_op)
  for _ in range(50):
    sess.run(next_element)
</code></pre>

<p>It is unclear what the benefit of this complexity is.<br>
Why not simply create 2 different iterators?</p>
",2018-12-02 18:46:35,2341218,3739,https://stackoverflow.com/questions/53583456,Documentation Ambiguity
53634736,TensorFlow Estimator API: use numpy functions?,"<p>I have written several custom metrics which I would like to add to <code>tf.summary</code> and view in tensorboard via <code>metrics_op</code> in my <code>EstimatorSpec</code>.</p>

<p>Is it strictly required that I covert these functions to their tf graph equivalents to be compatible, or is there a way to just dump them in, e.g.</p>

<pre><code>def model_fn(...):

    ...
    my_scalar_metric = my_np_func(output, labels)
    tf.summary.scalar('my_metric', my_scalar_metric)
    ...
</code></pre>
",2018-12-05 14:39:35,5623899,4978,https://stackoverflow.com/questions/53634736,Documentation Replicability
53677345,Passing >2GB data to tf.estimator,"<p>I have <code>x_train</code> and <code>y_train</code> numpy arrays, each of >2GB. I want to train model using the tf.estimator API, but I am getting the errors:</p>

<pre><code>ValueError: Cannot create a tensor proto whose content is larger than 2GB
</code></pre>

<p>I am passing the data using:</p>

<pre><code>def input_fn(features, labels=None, batch_size=None,
             shuffle=False, repeats=False):
    if labels is not None:
        inputs = (features, labels)
    else:
        inputs = features
    dataset = tf.data.Dataset.from_tensor_slices(inputs)
    if shuffle:
        dataset = dataset.shuffle(shuffle)
    if batch_size:
        dataset = dataset.batch(batch_size)
    if repeats:
        # if False, evaluate after each epoch
        dataset = dataset.repeat(repeats)
    return dataset

train_spec = tf.estimator.TrainSpec(
    lambda : input_fn(x_train, y_train,
                      batch_size=BATCH_SIZE, shuffle=50),
    max_steps=EPOCHS
)

eval_spec = tf.estimator.EvalSpec(lambda : input_fn(x_dev, y_dev))

tf.estimator.train_and_evaluate(model, train_spec, eval_spec)
</code></pre>

<p>The tf.data documentation <a href=""https://www.tensorflow.org/guide/datasets"" rel=""nofollow noreferrer"">mentions this error</a> and provides solution using traditional TenforFlow API with placeholders. Unfortunately, I don't know how this could be translated into tf.estimator API?</p>
",2018-12-07 22:02:35,3986320,7145,https://stackoverflow.com/questions/53677345,Documentation Replication on Other Examples
53690602,Why tensorflow.contrib.framework.arg_scope not applicable to tf.keras.layers?,"<p>I am trying to move from tf.contrib.slim to tf.keras packages.
I feel comfortable with arg_scope syntax because it reduces many redundant arguments.</p>

<p>I found the related solution with '<a href=""https://stackoverflow.com/questions/48173368/alternative-to-arg-scope-when-using-tf-layers"">Alternative to arg_scope when using tf.layers</a>'</p>

<p>However, for keras layers it is not applicable and raises following error.</p>

<pre><code>from tensorflow.contrib.framework import arg_scope
with arg_scope([tf.keras.layers.Conv2D], padding='SAME', activation='relu'):
  model = tf.keras.layers.Conv2D(kernel_size=[3,3])
</code></pre>

<p>This experimental code results</p>

<blockquote>
  <p>ValueError: ('%s is not decorated with @add_arg_scope', 
     ('tensorflow.python.keras.layers.convolutional', 'Conv2D'))</p>
</blockquote>

<p>I am considering to make a wrapper function for <code>tf.keras.layers</code> that is decorated with the <code>add_arg_scope</code>, but is it a right way of dealing with layers in tf.keras?,
I am also wondering why keras does not support for arg_scope sugar syntax.</p>
",2018-12-09 08:29:24,5011042,41,https://stackoverflow.com/questions/53690602,Documentation Replicability
53787587,"AWS, Cuda, Tensorflow","<p>When I'm running my Python code on the most powerfull AWS GPU instances (with 1 or 8 x Tesla v100 16mb aka. P3.x2large or P3.16xlarge) they are both only 2-3 times faster than my DELL XPS Geforce 1050-Ti laptop?</p>

<p>I'm using Windows, Keras, Cuda 9, Tensorflow 1.12 and the newest Nvidia drivers.</p>

<p>When I check the GPU load via GZU the GPU max. run at 43% load for a very short period - each time. The controller runs at max. 100%...</p>

<p>The dataset I use is matrices in JSON format and the files are located on a Nitro drive at 10TB with MAX 64.000 IOPS. No matter if the folder contains 10TB, 1TB or 100mb...the training is still very very slow per iteration?</p>

<p>All advises are more than welcome!</p>

<p>UPDATE 1:</p>

<p>From the Tensorflow docs:</p>

<p>""<em>To start an input pipeline, you must define a source. For example, to construct a Dataset from some tensors in memory, you can use tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices(). Alternatively, if your input data are on disk in the recommended TFRecord format, you can construct a tf.data.TFRecordDataset.""</em></p>

<p>Before I had matrices stored in JSON format (Made by Node). My TF runs in Python.
I will now only save the coordinates in Node and save it in JSON format.
The question is now: In Python what is the best solution to load data? Can TF use the coordinates only or do I have to make the coordinates back to matrices again or what?</p>
",2018-12-14 22:16:13,5800182,2261,https://stackoverflow.com/questions/53787587,Documentation Replication on Other Examples
53828895,Does distributed TensorFlow requires a distributed file system to save checkpoints?,"<p>I am trying to run some sample codes based on <a href=""https://www.tensorflow.org/deploy/distributed"" rel=""nofollow noreferrer"">this tf official tutorial</a>.<br>
And I watched <a href=""https://www.youtube.com/watch?v=la_M6bCV91M&amp;index=11&amp;list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv"" rel=""nofollow noreferrer"">this video</a> which is really nice.<br>
As mentioned in the video above, the chief worker is responsible for saving checkpoints, and it's implemented by tf.train.MonitoredTrainingSession.<br>
Then I thought that only the chief worker needs a directory to save checkpoints.<br>
When I run the codes with ps0 on machine1, worker0 on machine2, everything seems ok.<br>
But when I run with ps0, worker0 on machine1, ps1 and worker1 on machine2, errors occurs, and the error in worker0's log is like:  </p>

<pre><code>Traceback (most recent call last):
File ""distributed_train.py"", line 136, in &lt;module&gt;
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""distributed_train.py"", line 97, in main
    hooks=hooks) as mon_sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 415, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 712, in create_session
    hook.after_create_session(self.tf_sess, self.coord)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 450, in after_create_session
    self._save(session, global_step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 481, in _save
    self._get_saver().save(session, self._save_path, global_step=step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1669, in save
    raise exc
tensorflow.python.framework.errors_impl.NotFoundError: ./train_dir/dist_worker_0/model.ckpt-0_temp_cf2b45f059b74507a65cae9b7a9ea5b4; No such file or directory
     [[Node: save/SaveV2_1 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:ps/replica:0/task:1/device:CPU:0""](save/ShardedFilename_1, save/SaveV2_1/tensor_names, save/SaveV2_1/shape_and_slices, conv1/biases, conv1/biases/Adagrad, conv2/biases, conv2/biases/Adagrad, local3/biases, local3/biases/Adagrad, local4/biases, local4/biases/Adagrad, softmax_linear/biases, softmax_linear/biases/Adagrad)]]

Caused by op u'save/SaveV2_1', defined at:
  File ""distributed_train.py"", line 136, in &lt;module&gt;
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""distributed_train.py"", line 97, in main
    hooks=hooks) as mon_sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 415, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session
    self._scaffold.finalize()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 772, in _build_internal
    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 363, in _AddShardedSaveOps
    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 337, in _AddShardedSaveOpsForV2
    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/s`enter code here`aver.py"", line 278, in _AddSaveOps
   save = self.save_op(filename_tensor, saveables)

File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 194, in save_op
    tensors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1687, in save_v2
    shape_and_slices=shape_and_slices, tensors=tensors, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): ./train_dir/dist_worker_0/model.ckpt-0_temp_cf2b45f059b74507a65cae9b7a9ea5b4; No such file or directory
     [[Node: save/SaveV2_1 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:ps/replica:0/task:1/device:CPU:0""](save/ShardedFilename_1, save/SaveV2_1/tensor_names, save/SaveV2_1/shape_and_slices, conv1/biases, conv1/biases/Adagrad, conv2/biases, conv2/biases/Adagrad, local3/biases, local3/biases/Adagrad, local4/biases, local4/biases/Adagrad, softmax_linear/biases, softmax_linear/biases/Adagrad)]]
</code></pre>

<p>But the directory ./train_dir/dist_worker_0/model.ckpt-0_temp_cf2b45f059b74507a65cae9b7a9ea5b4  really exists (on machine1).</p>

<p>part of the code (actually from the official tutorial):  </p>

<pre><code>        # The MonitoredTrainingSession takes care of session initialization,
        # restoring from a checkpoint, saving to a checkpoint, and closing when done
        # or an error occurs.
        with tf.train.MonitoredTrainingSession(
                master=server.target,
                config=config,
                is_chief=(FLAGS.task_index == 0),
                checkpoint_dir=""./train_dir/dist_{0}_{1}"".format(FLAGS.job_name,
                                                             FLAGS.task_index),
                hooks=hooks) as mon_sess:
            while not mon_sess.should_stop():
                # Run a training step asynchronously.
                # See &lt;a href=""./../api_docs/python/tf/train/SyncReplicasOptimizer""&gt;&lt;code&gt;tf.train.SyncReplicasOptimizer&lt;/code&gt;&lt;/a&gt; for additional details on how to
                # perform *synchronous* training.
                # mon_sess.run handles AbortedError in case of preempted PS.
                mon_sess.run(train_op)
</code></pre>

<p>I searched some questions on stackoverflow and issues on github, answers to similar questions suggest to use HDFS.<br>
Doesn't ""Chief worker is responsible for saving chechpoints"" mean that I only need a local directory on the machine where the chief worker is located? Am I misunderstanding something? Do I really need to use HDFS or such?  </p>
",2018-12-18 08:20:40,4922937,53,https://stackoverflow.com/questions/53828895,Lack of Alternative Solutions/Documentation
53895757,How can I know which TFRecords file is reading now?,"<p>I have a list named <code>t_list = [a.tfrecords, b.tfrecords, c.tfrecords, d.tfrecords]</code>, which contains 4 TFRecords paths named <code>a.tfrecords</code>, <code>b.tfrecords</code>, <code>c.tfrecords</code> and <code>d.tfrecords</code>. </p>

<p>I'm reading these TFRecords with <code>dataset = tf.data.TFRecordDataset(t_list)</code>. And I set a <code>epoch_num</code> by <code>dataset = dataset.repeat(epoch_num)</code></p>

<p>I have two questions about this function:</p>

<ol>
<li><p>How can I know which TFRecords file is been reading now during training?</p></li>
<li><p>How can I know which epoch is now during training?</p></li>
</ol>

<p>Thanks!</p>
",2018-12-22 12:41:54,10153344,83,https://stackoverflow.com/questions/53895757,Documentation Replication on Other Examples
53915078,"What are b, y, x and c which get flattened and returned along with the max-pooled features in tf.nn.max_pool_with_argmax?","<p>I went through the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/max_pool_with_argmax"" rel=""nofollow noreferrer"">tf.nn.max_pool_with_argmax</a> where it is written</p>

<blockquote>
  <p>Performs max pooling on the input and outputs both max values and indices.</p>
  
  <p>The indices in argmax are flattened, so that a maximum value at
  position [b, y, x, c] becomes flattened index ((b * height + y) *
  width + x) * channels + c.</p>
  
  <p>The indices returned are always in [0, height) x [0, width) before
  flattening, even if padding is involved and the mathematically correct
  answer is outside (either negative or too large). This is a bug, but
  fixing it is difficult to do in a safe backwards compatible way,
  especially due to flattening.</p>
</blockquote>

<p>The variables b, y, x and c haven't been explicitly defined hence I was having issues implementing this method. Can someone please provide the same.</p>
",2018-12-24 15:12:06,7184172,1285,https://stackoverflow.com/questions/53915078,Documentation Replicability
53922040,How does tf.keras.layers.Conv2DTranspose behave with stride and padding?,"<p>While a convolution layer in TensorFlow has a complete description <a href=""https://www.tensorflow.org/api_guides/python/nn#Convolution"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_guides/python/nn#Convolution</a>, transposed convolution does not have one.</p>

<p>Although tf.keras.layers.Conv2DTranspose has a reference to <a href=""https://arxiv.org/pdf/1603.07285.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/1603.07285.pdf</a>, it is not complete.</p>

<p>Is there any documentation that describes how tf.keras.layers.Conv2DTranspose behaves?</p>
",2018-12-25 11:41:26,8384504,374,https://stackoverflow.com/questions/53922040,Documentation Completeness
53924692,Why can tf.random.truncated_normal get a shape that is not a vector even though it says it only receives shape of a vector?,"<p>I am working with TensorFlow in Python. </p>

<p>I read through the documentation of 
<a href=""https://www.tensorflow.org/api_docs/python/tf/random/truncated_normal"" rel=""nofollow noreferrer"">tf.random.truncated_normal</a>
that the input 'shape' gets 1-D tensor or python array, i.e. a vector (according to <a href=""https://www.tensorflow.org/guide/tensors"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/tensors</a>). </p>

<p>However, with the example I'm using, 'shape' is a 4-D tensor. Or is it considered a vector? Perhaps I have problem with the definition of vectors and tensors? </p>

<pre><code>def weight_variable(shape, name = 'noname'):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial, name = name)

W_conv1 = weight_variable([5, 5, 3, 32], 'W_conv1')
</code></pre>
",2018-12-25 18:26:05,10832672,11,https://stackoverflow.com/questions/53924692,Documentation Replicability
53951941,How can I load a saved model from object detection for inference?,"<p>I'm pretty new to Tensorflow and have been running experiments with SSDs with the Tensorflow Object Detection API.  I can successfully train a model, but by default, it only save the last n checkpoints.  I'd like to instead save the last n checkpoints with the lowest loss (I'm assuming that's the best metric to use).</p>

<p>I found tf.estimator.BestExporter and it exports a saved_model.pb along with variables.  However, I have yet to figure out how to load that saved model and run inference on it.  After running models/research/object_detection/export_inference_graph.py on the checkpoiont, I can easily load a checkpoint and run inference on it using the object detection jupyter notebook: <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb"" rel=""nofollow noreferrer"">https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb</a></p>

<p>I've found documentation on loading saved models, and can load a graph like this:</p>

<pre><code>with tf.Session(graph=tf.Graph()) as sess:
        tags = [tag_constants.SERVING]
        meta_graph = tf.saved_model.loader.load(sess, tags, PATH_TO_SAVED_MODEL)
        detection_graph = tf.get_default_graph()
</code></pre>

<p>However, when I use that graph with the above jupyter notebook, I get errors:</p>

<pre><code>---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
&lt;ipython-input-17-9e48f0d04df2&gt; in &lt;module&gt;
      7   image_np_expanded = np.expand_dims(image_np, axis=0)
      8   # Actual detection.
----&gt; 9   output_dict = run_inference_for_single_image(image_np, detection_graph)
     10   # Visualization of the results of a detection.
     11   vis_util.visualize_boxes_and_labels_on_image_array(

&lt;ipython-input-16-0df86999596e&gt; in run_inference_for_single_image(image, graph)
     31             detection_masks_reframed, 0)
     32 
---&gt; 33       image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')
     34       # image_tensor = tf.get_default_graph().get_tensor_by_name('serialized_example')
     35 

~/anaconda3/envs/sb/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in get_tensor_by_name(self, name)
   3664       raise TypeError(""Tensor names are strings (or similar), not %s."" %
   3665                       type(name).__name__)
-&gt; 3666     return self.as_graph_element(name, allow_tensor=True, allow_operation=False)
   3667 
   3668   def _get_tensor_by_tf_output(self, tf_output):

~/anaconda3/envs/sb/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in as_graph_element(self, obj, allow_tensor, allow_operation)
   3488 
   3489     with self._lock:
-&gt; 3490       return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
   3491 
   3492   def _as_graph_element_locked(self, obj, allow_tensor, allow_operation):

~/anaconda3/envs/sb/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _as_graph_element_locked(self, obj, allow_tensor, allow_operation)
   3530           raise KeyError(""The name %s refers to a Tensor which does not ""
   3531                          ""exist. The operation, %s, does not exist in the ""
-&gt; 3532                          ""graph."" % (repr(name), repr(op_name)))
   3533         try:
   3534           return op.outputs[out_n]

KeyError: ""The name 'image_tensor:0' refers to a Tensor which does not exist. The operation, 'image_tensor', does not exist in the graph.""
</code></pre>

<p>Is there a better way to load the saved model or convert it to an inference graph?</p>

<p>Thanks!</p>
",2018-12-27 23:23:22,1192963,386,https://stackoverflow.com/questions/53951941,Documentation Replication on Other Examples
54096360,How to properly use tf.scatter_update for N-Dimensional Updating?,"<p>I've been trying to make an N-Dimensional update using <code>tf.scatter_update</code> (after <code>tf.scatter_nd</code> was failing due to shape mismatch). In general, these will be used to create masks for filtering slices of an incoming tensor.</p>

<p>Presumption is that input Tensor A is of shape (batch, i, j, k(depth)).
I am only interested in modifying <strong>i,j</strong> values for <strong>all k</strong>, and for <strong>all b</strong>.</p>

<p>MWE:</p>

<pre><code>import tensorflow as tf

b, i, j, k = 64, 128, 128, 256
A = tf.random_uniform(shape=(64, 128, 128, 256), dtype='int32', seed=1234) # Batch, i, j, k

mask = tf.ones(shape=(b,i,j,k), dtype='int32')

# Placeholder for more complicated index Tensor. GPU Ignores OOB indices.
indices = tf.random_uniform(shape=(b, 25, k, 2), dtype='int32', seed=4321) # Index number, k, i-j coord.

updates = tf.random_uniform(shape=(i, j, k), dtype='int32', seed=1111)
scatter = tf.scatter_update(mask, indices, updates)

with tf.Session() as sess:
    sess.run(scatter)
</code></pre>

<p>Resulting in:</p>

<blockquote>
  <p>AttributeError: 'Tensor' object has no attribute '_lazy_read'</p>
</blockquote>

<p>I have tried this via Python Script, Python Notebook, and with/without Eager Execution. No luck.</p>

<p>Input absolutely must be a tensor, as the idea is to sparsely update this tensor midway through a series of operations.</p>

<p>Is there something fundamental I'm missing regarding <code>tf.scatter_update</code>? Would <code>tf.scatter_nd</code> be more suited? If so, what are the differences, specifically with indices for the updates.</p>

<p>When referencing <a href=""https://www.tensorflow.org/api_docs/python/tf/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_update</a> documentation, the examples are basic and utilise constants; I'm having difficulty applying this to a more realistic situation and problem.</p>
",2019-01-08 16:55:09,1587808,51,https://stackoverflow.com/questions/54096360,Inadequate Examples
54183967,Using tf.map_fn with multiple GPUs,"<p>I'm trying to extend my single-GPU TensorFlow code to multi-GPU. I have to work on 3 degrees of freedom and unfortunately I need to use tf.map_fn to parallelize over the 3rd one. I tried to use device placement as shown in the official documentation, but it looks like it is impossible to do it with <code>tf.map_fn</code>. Is there a way to run <code>tf.map_fn</code> on multiple GPUs?</p>

<p>Here the error output:</p>

<pre><code>InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'map_1/TensorArray_1': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/device:GPU:1'
Colocation Debug Info:
Colocation group had the following types and devices: 
TensorArrayGatherV3: GPU CPU 
Range: GPU CPU 
TensorArrayWriteV3: GPU CPU 
TensorArraySizeV3: GPU CPU 
MatMul: GPU CPU 
Enter: GPU CPU 
TensorArrayV3: GPU CPU 
Const: GPU CPU 

Colocation members and user-requested devices:
  map_1/TensorArrayStack/range/delta (Const) 
  map_1/TensorArrayStack/range/start (Const) 
  map_1/TensorArray_1 (TensorArrayV3) 
  map_1/while/TensorArrayWrite/TensorArrayWriteV3/Enter (Enter) /device:GPU:1
  map_1/TensorArrayStack/TensorArraySizeV3 (TensorArraySizeV3) 
  map_1/TensorArrayStack/range (Range) 
  map_1/TensorArrayStack/TensorArrayGatherV3 (TensorArrayGatherV3) 
  map_1/while/MatMul (MatMul) /device:GPU:1
  map_1/while/TensorArrayWrite/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1

         [[Node: map_1/TensorArray_1 = TensorArrayV3[clear_after_read=true, dtype=DT_FLOAT, dynamic_size=false, element_shape=&lt;unknown&gt;, identical_element_shapes=true, tensor_array_name=""""](map_1/TensorArray_1/size)]]
</code></pre>

<p>Here a simple code example to reproduce it:</p>

<pre><code>import tensorflow as tf
import numpy

rc = 1000

sess = tf.Session()

for deviceName in ['/cpu:0', '/device:GPU:0', '/device:GPU:1']:
        with tf.device(deviceName):
                matrices = tf.random_uniform([rc,rc,4],minval = 0, maxval = 1, dtype = tf.float32)

                def mult(i):
                        product = tf.matmul(matrices[:,:,i],matrices[:,:,i+1])
                        return product

                mul = tf.zeros([rc,rc,3], dtype = tf.float32)
                mul = tf.map_fn(mult, numpy.array([0,1,2]), dtype = tf.float32, parallel_iterations = 10)

m = sess.run(mul)


</code></pre>
",2019-01-14 15:03:38,6044435,109,https://stackoverflow.com/questions/54183967,Documentation Replicability
54211834,how to use tf.print (not tf.Print) in high-level Estimator api,"<p>Currently, I'm using <code>tf.Print</code> to print(debug) tensor in estimator, but this api is marked deprecated, and recommend me to use tf.print instead. According to the <a href=""https://github.com/tensorflow/community/pull/14/files"" rel=""nofollow noreferrer"">RFC</a>, by using tf.print, I need to have control of the running session, but <code>Estimator</code> is designed to hide session and graph from users. So, how to use <code>tf.print</code> in Estimator?</p>
",2019-01-16 06:58:49,1285444,2371,https://stackoverflow.com/questions/54211834,Documentation Replicability
54509752,How to translate deprecated tf.train.QueueRunners tensorflow approach to importing data to new tf.data.Dataset approach,"<p>Altough tensorflow recommends very much to not use deprecated functions that are going to be replaced by tf.data objects, there seems to be no good documentation for cleanly replacing the deprecated for the modern approach. Moreover, Tensorflow tutorials still use the deprecated functionality to treat file processing (Reading data tutorial: <a href=""https://www.tensorflow.org/api_guides/python/reading_data"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_guides/python/reading_data</a>). </p>

<p>On the other hand, though there is good documentation for using the 'modern' approach (Importing data tutorial: <a href=""https://www.tensorflow.org/guide/datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/datasets</a>), there still exists the old tutorials which will probably lead many, as me, to use the deprecated one first. That is why one would like to cleanly translate the deprecated to the 'modern' approach, and an example for this translation would probably be very useful.</p>

<pre><code>#!/usr/bin/env python3
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import shutil
import os

if not os.path.exists('example'):
    shutil.rmTree('example');
    os.mkdir('example');

batch_sz = 10; epochs = 2; buffer_size = 30; samples = 0;
for i in range(50):
    _x = np.random.randint(0, 256, (10, 10, 3), np.uint8);
    plt.imsave(""example/image_{}.jpg"".format(i), _x)
images = tf.train.match_filenames_once('example/*.jpg')
fname_q = tf.train.string_input_producer(images,epochs, True);
reader = tf.WholeFileReader()
_, value = reader.read(fname_q)
img = tf.image.decode_image(value)
img_batch = tf.train.batch([img], batch_sz, shapes=([10, 10, 3]));
with tf.Session() as sess:
    sess.run([tf.global_variables_initializer(),
        tf.local_variables_initializer()])
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    for _ in range(epochs):
        try:
            while not coord.should_stop():
                sess.run(img_batch)
                samples += batch_sz;
                print(samples, ""samples have been seen"")
        except tf.errors.OutOfRangeError:
            print('Done training -- epoch limit reached')
        finally:
            coord.request_stop();
    coord.join(threads)
</code></pre>

<p>This code runs perfectly well for me, printing to console:</p>

<pre><code>10 samples have been seen
20 samples have been seen
30 samples have been seen
40 samples have been seen
50 samples have been seen
60 samples have been seen
70 samples have been seen
80 samples have been seen
90 samples have been seen
100 samples have been seen
110 samples have been seen
120 samples have been seen
130 samples have been seen
140 samples have been seen
150 samples have been seen
160 samples have been seen
170 samples have been seen
180 samples have been seen
190 samples have been seen
200 samples have been seen
Done training -- epoch limit reached
</code></pre>

<p>As can be seen, it uses deprecated functions and objects as tf.train.string_input_producer() and tf.WholeFileReader(). An equivalent implementation using the 'modern' tf.data.Dataset is needed.</p>

<p><strong>EDIT:</strong></p>

<p>Found already given example for importing CSV data: <a href=""https://stackoverflow.com/questions/53571432/replacing-queue-based-input-pipelines-with-tf-data"">Replacing Queue-based input pipelines with tf.data</a>. I would like to be as complete as possible here, and suppose that more examples are better, so I don't feel it as a repeated question.</p>
",2019-02-04 03:13:58,7906266,1081,https://stackoverflow.com/questions/54509752,Requesting (Additional) Documentation/Examples
54524992,Tensorflow serving trained model saved with saved_model,"<p>I find tf.saved_model documentation not clear, is there any valuable resources how to read trained model within other session?</p>
",2019-02-04 22:04:23,9914396,11,https://stackoverflow.com/questions/54524992,Documentation Replication on Other Examples
54615708,Exporting a Keras model as a TF Estimator: trained model cannot be found,"<p>I encountered the following issue when trying to export a Keras model as a TensorFlow Estimator with the purpose of serving the model. Since the same problem also popped up <a href=""https://stackoverflow.com/questions/54175038/creating-a-serving-graph-separately-from-training-in-tensorflow-for-google-cloud/54178060#54178060"">in an answer to this question</a>, I will illustrate what happens on a toy example and provide my workaround solution for documentation purposes. This behaviour occurs with Tensorflow 1.12.0 and Keras 2.2.4. This happens with actual Keras as well as with <code>tf.keras</code>.</p>

<p>The problem occurs when trying to export an Estimator that was created from a Keras model with <code>tf.keras.estimator.model_to_estimator</code>. Upon calling <code>estimator.export_savedmodel</code>, either a <code>NotFoundError</code> or a <code>ValueError</code> is thrown.</p>

<p>The below code reproduces this for a toy example.</p>

<p>Create a Keras model and save it:</p>

<pre><code>import keras
model = keras.Sequential()
model.add(keras.layers.Dense(units=1,
                                activation='sigmoid',
                                input_shape=(10, )))
model.compile(loss='binary_crossentropy', optimizer='sgd')
model.save('./model.h5')
</code></pre>

<p>Next, convert the model to an estimator with <code>tf.keras.estimator.model_to_estimator</code>, add an input receiver function and export it in the <code>Savedmodel</code> format with <code>estimator.export_savedmodel</code>:</p>

<pre><code># Convert keras model to TF estimator
tf_files_path = './tf'
estimator =\
    tf.keras.estimator.model_to_estimator(keras_model=model,
                                          model_dir=tf_files_path)
def serving_input_receiver_fn():
    return tf.estimator.export.build_raw_serving_input_receiver_fn(
        {model.input_names[0]: tf.placeholder(tf.float32, shape=[None, 10])})

# Export the estimator
export_path = './export'
estimator.export_savedmodel(
    export_path,
    serving_input_receiver_fn=serving_input_receiver_fn())
</code></pre>

<p>This will throw:</p>

<pre><code>ValueError: Couldn't find trained model at ./tf.
</code></pre>
",2019-02-10 11:00:21,5495381,7071,https://stackoverflow.com/questions/54615708,Documentation Replicability
54721543,"tensorrt not support: tf.unpack, tf.slice, tf.tile, tf.expand_dims, tf.fill, tf.cast, tf.floor_div, tf.range","<p>There are lots of unsupported operation for tensorrt when convert from tensorflow model to uff model ( such as: <code>tf.unpack, tf.slice, tf.tile, tf.expand_dims, tf.fill, tf.cast, tf.floor_div, tf.range</code>). Is there a simple method to solve the problem?
This is the warnings when i convert convert from pb to uff model:</p>

<pre><code>Warning: No conversion function registered for layer: Unpack yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Unpack yet.
Warning: No conversion function registered for layer: Unpack yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: FloorDiv yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: FloorDiv yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: ExpandDims yet.
Warning: No conversion function registered for layer: Fill yet.
Warning: No conversion function registered for layer: Slice yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Tile yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Cast yet.
Warning: No conversion function registered for layer: Range yet.
Warning: No conversion function registered for layer: Unpack yet.
</code></pre>
",2019-02-16 09:10:29,988709,4837,https://stackoverflow.com/questions/54721543,Documentation Replicability
54761088,tf.nn.relu vs tf.keras.activations.relu,"<p>I see both <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/relu"" rel=""noreferrer"">tf.nn.relu</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu"" rel=""noreferrer"">tf.keras.activations.relu</a> computes only the ReLU function (no additional fully connected layer or something, as described <a href=""https://stackoverflow.com/questions/42773379/tf-nn-relu-vs-tf-contrib-layers-relu"">here</a>), so what's the difference between them? Does one just wraps the other?</p>
",2019-02-19 07:46:33,5476824,699,https://stackoverflow.com/questions/54761088,Documentation Replicability
54897832,Feeding large numpy arrays into TensorFlow estimators via tf.data.Dataset,"<p>TensorFlow's <a href=""https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code> documentation on consuming numpy arrays</a> states that in order to use numpy arrays in combination with the <code>Dataset</code> API, the arrays have to be small enough (&lt;2 GB in total) to be used as tensors, or they can be fed into the dataset via placeholders.</p>

<p>However, if you use <code>Dataset</code> in conjunction with estimators (where placeholders are not available), the documentation does not provide a solution on working with large arrays without placeholders. </p>

<p>Are there other options for passing placeholder values into estimators that can be used or is the solution to provide the data in <code>tfrecord</code> or <code>csv</code> format?</p>
",2019-02-27 03:58:30,4443082,227,https://stackoverflow.com/questions/54897832,Inadequate Examples
54934603,"tensorflow documentation says ""WARNING: Avoid writing code which relies on the value of a Variable..."" what does it mean?","<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">tf.Variable documentation</a> 
contains the following warning:</p>

<blockquote>
  <p>WARNING: tf.Variable objects by default have a non-intuitive memory model. A Variable is represented internally as a mutable Tensor which can non-deterministically alias other Tensors in a graph. The set of operations which consume a Variable and can lead to aliasing is undetermined and can change across TensorFlow versions. Avoid writing code which relies on the value of a Variable either changing or not changing as other operations happen. For example, using Variable objects or simple functions thereof as predicates in a tf.cond is dangerous and error-prone:</p>
</blockquote>

<pre><code>v = tf.Variable(True)
tf.cond(v, lambda: v.assign(False), my_false_fn)  # Note: this is broken.
</code></pre>

<p>I don't quite understand what time means and why the example above is broken. What does it mean that one cannot rely on the value of a Variable? Is it possible to have an example where the code above works not as expected?</p>
",2019-02-28 21:31:55,1754568,150,https://stackoverflow.com/questions/54934603,Requesting (Additional) Documentation/Examples
54966581,tf.boolean_mask not accepting the axis argument,"<p>Here is my code:  </p>

<pre><code> 44     scores = tf.boolean_mask(box_class_scores,filtering_mask,axis=-1)
 45     boxes = tf.boolean_mask(boxes,filtering_mask,axis=-1)
 46     classes = tf.boolean_mask(box_classes,filtering_mask,axis=-1)
</code></pre>

<p>Error, I'm getting:</p>

<blockquote>
  <p>TypeError: boolean_mask() got an unexpected keyword argument 'axis'</p>
</blockquote>

<p>The <code>tf.boolean_mask()</code> is not accepting the axis argument but is a valid argument as can be seen in the documentation: <a href=""https://www.tensorflow.org/api_docs/python/tf/boolean_mask"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/boolean_mask</a></p>

<p><a href=""https://i.stack.imgur.com/bne6B.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bne6B.png"" alt=""enter image description here""></a></p>
",2019-03-03 07:32:33,9902786,81,https://stackoverflow.com/questions/54966581,Documentation Ambiguity
55044905,"Tensorflow low level api, batch normalization problem","<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">tf.layers.batch_normalization</a> documentation says it will be removed in a future version, and should be replaced by <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""nofollow noreferrer"">tf.keras.layers.BatchNormalization</a>, but i cannot find a way to replace the functionality using tensorflow low level api.</p>

<pre><code>import tensorflow as tf
bn = tf.layers.batch_normalization(tf.constant([0.0]), training=True)
print(tf.get_collection(tf.GraphKeys.UPDATE_OPS))
</code></pre>

<p>which outputs:</p>

<pre><code>[&lt;tf.Operation 'batch_normalization/AssignMovingAvg' type=AssignSub&gt;,
&lt;tf.Operation 'batch_normalization/AssignMovingAvg_1' type=AssignSub&gt;]
</code></pre>

<p>If we instead use keras as suggested in the documentation</p>

<pre><code>bn = tf.keras.layers.BatchNormalization(axis=-1)(tf.constant([0.0]), training=True)
</code></pre>

<p>we get an empty output:</p>

<pre><code>[]
</code></pre>

<p>Since UPDATE_OPS is empty, the model is unable to update the batch normalization moving_avg_mean and moving_avg_variance during training using keras (resulting in a much higer test error). Any suggestion how to solve this is greatly appreciated! </p>

<p>The example above is taken from an older post of how to use <a href=""https://stackoverflow.com/questions/48874558/tensorflow-tf-layers-batch-normalization-doesnt-add-update-ops-to-tf-graphke"">tf.layers.batch_normalization</a></p>
",2019-03-07 13:24:49,10455493,1483,https://stackoverflow.com/questions/55044905,Documentation Replication on Other Examples
55122902,from_tensor_slices() with big numpy array while using tf.keras,"<p>I have some training data in a numpy array - it fits in the memory but it is bigger than 2GB. I'm using tf.keras and the dataset API. To give you a simplified, self-contained example:</p>

<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

model = tf.keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(32,)),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
])

model.compile(optimizer=tf.train.AdamOptimizer(0.001),
          loss='mse',
          metrics=['mae'])

# generate some big input datasets, bigger than 2GB
data = np.random.random((1024*1024*8, 32))
labels = np.random.random((1024*1024*8, 1))
val_data = np.random.random((100, 32))
val_labels = np.random.random((100, 1))

train_dataset = tf.data.Dataset.from_tensor_slices((data, labels))
train_dataset = train_dataset.batch(32).repeat()

val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))
val_dataset = val_dataset.batch(32).repeat()

model.fit(train_dataset, epochs=10, steps_per_epoch=30,
      validation_data=val_dataset, validation_steps=3)
</code></pre>

<p>So, executing this results in an error ""Cannot create a tensor proto whose content is larger than 2GB"". The documentation lists a solution to this problem: <a href=""https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays</a> - just use tf.placeholders and then feed_dict in session run.</p>

<p>Now the main question is: how to do this with tf.keras? I cannot feed anything for the placeholders when I call model.fit() and in fact when I introduced the placeholders I got errors saying ""You must feed a value for placeholder tensor"".</p>
",2019-03-12 13:41:07,1185138,582,https://stackoverflow.com/questions/55122902,Documentation Replicability
55125115,Tensorflow difference between tf.losses.softmax and tf.nn.softmax,"<p>What is the difference between <code>tf.nn.softmax_cross_entropy_with_logits</code> and <code>tf.losses.softmax_cross_entropy</code> and when to use which function??</p>
",2019-03-12 15:24:20,6553104,155,https://stackoverflow.com/questions/55125115,Documentation Replicability
55141486,Unable to see keras model graph in Tensorboard when using TensorFlow 2.0 Alpha,"<p>I am trying custom training on TensorFlow 2.0 alpha and at the same time I am trying to add some metrics and my training graph to TensorBoard. Consider the following contrived example</p>

<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model


def create_model():
    inp = Input((32, ))
    net = Dense(16, activation=""relu"")(inp)
    net = Dense(8, activation=""relu"")(net)
    net = Dense(2, activation=None)(net)
    return Model(inp, net)


@tf.function
def grad(model, loss, x, y):
    with tf.GradientTape() as tape:
        y_ = model(x)
        loss_value = loss(y_true=y, y_pred=y_)
    return loss_value, tape.gradient(loss_value, model.trainable_variables)


@tf.function
def train_step(model, loss, optimizer, features, labels):
    loss_value, grads = grad(model, loss, features, labels)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss_value


def train():
    tf.summary.trace_on(graph=True, profiler=True)

    with tf.summary.create_file_writer(""model"").as_default():
        model = create_model()

        loss = tf.keras.losses.MeanSquaredError()
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

        for i in range(10):
            tf.summary.experimental.set_step(i)

            features = tf.random.normal((16, 32))
            labels = tf.random.normal((16, 2))
            loss_value = train_step(model, loss, optimizer, features, labels)
            print(loss_value)

        tf.summary.trace_export(""model"", profiler_outdir=""model"")


if __name__ == ""__main__"":
    train()
</code></pre>

<p>This, does not show the model graph properly, on doing</p>

<pre><code>tensorboard --logdir model
</code></pre>

<p>In the graphs tab I am seeing <a href=""https://i.stack.imgur.com/TRbqc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/TRbqc.png"" alt=""tensorboard""></a></p>

<p>I am getting the graph when I am training through model.fit or estimator. For example, here is the graphs section when I use <code>model_to_estimator</code> to convert a model</p>

<p><a href=""https://i.stack.imgur.com/h0rBQ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/h0rBQ.png"" alt=""model_to_estiamtor""></a></p>

<p><a href=""https://www.tensorflow.org/alpha/tutorials/eager/custom_training_walkthrough"" rel=""noreferrer"">The guide article</a> does not track metrics through tensorboard, and I did not find any sections on the new workflow for custom adding and tracking of metrics in TensorBoard on alpha (<a href=""https://www.tensorflow.org/alpha"" rel=""noreferrer"">https://www.tensorflow.org/alpha</a>). My contrived implementation is based on the API documentation of tf.summary (<a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/summary"" rel=""noreferrer"">https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/summary</a>) </p>
",2019-03-13 12:04:08,3673043,749,https://stackoverflow.com/questions/55141486,Documentation Replication on Other Examples
55168906,Tensorflow - tf.nn.weighted_cross_entropy_with_logits - logits and targets must have the same shape,"<p>I've just started using tensorflow for a project I'm working on. The program aims to be a binary classifier with input being 12 features. The output is either normal patient or patient with a disease. The prevalence of the disease is quite low and so my dataset is very imbalanced, with 502 examples of normal controls and only 38 diseased patients. For this reason, I'm trying to use <code>tf.nn.weighted_cross_entropy_with_logits</code> as my cost function.</p>

<p>The code is based on the iris custom estimator from the official tensorflow documentation, and works with <code>tf.losses.sparse_softmax_cross_entropy</code> as the cost function. However, when I change to <code>weighted_cross_entropy_with_logits</code>, I get a shape error and I'm not sure how to fix this.</p>

<pre><code>ValueError: logits and targets must have the same shape ((?, 2) vs (?,))
</code></pre>

<p>I have searched and similar problems have been solved by just reshaping the labels - I have tried to do this unsuccessfully (and don't understand why <code>tf.losses.sparse_softmax_cross_entropy</code> works fine and the weighted version does not). </p>

<p>My full code is here
<a href=""https://gist.github.com/revacious/83142573700c17b8d26a4a1b84b0dff7"" rel=""nofollow noreferrer"">https://gist.github.com/revacious/83142573700c17b8d26a4a1b84b0dff7</a></p>

<p>Thanks!</p>
",2019-03-14 17:41:19,11204499,11,https://stackoverflow.com/questions/55168906,Documentation Replication on Other Examples
55190692,Transposed convolution in tf.keras.layers,"<p>How can I convert this function to an equivalent tf.keras (Tensorflow 2.0) implementation?</p>

<pre><code>def deconv2d(inputs,out_channels, name=None):
batch, in_height, in_width, in_channels = [int(d) for d in inputs.get_shape()]
filter = tf.get_variable(name + ""filter"", [4, 4, out_channels, in_channels], initializer= tf.variance_scaling_initializer())
return tf.nn.conv2d_transpose(inputs, filter, [batch, in_height * 2, in_width * 2, out_channels], strides=[1,2,2,1],
                             padding='SAME', name= name)
</code></pre>
",2019-03-15 21:08:58,1050648,1489,https://stackoverflow.com/questions/55190692,Documentation Replicability
55199181,keras v. tf.keras compile command for sequential model,"<p>I've been getting up to speed in keras, not realizing that tf.keras is also a thing (and for newbies, it's easy to get cross ways with imports in python). In trying to convert a script from keras to tf.keras, it appears that the commands are not consistent? In general, is tf.keras supposed to follow the keras documentation, or are they diverging?</p>

<p>My specific issue is that this works with keras, but not tf.keras:</p>

<pre><code>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>This gives error:</p>

<pre><code>ValueError: optimizer must be an instance of tf.train.Optimizer, not a &lt;class 'str'&gt;
</code></pre>

<p>This seems inconsistent with the tf.keras docs (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#compile"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#compile</a>).  Any idea what is going on?</p>
",2019-03-16 16:48:39,2364295,2168,https://stackoverflow.com/questions/55199181,Documentation Ambiguity
55308630,update instruction of the deprecated tensorflow dataset sliding window with tf.data.experimental.CsvDataset,"<p>I am trying without success to update my code with the instruction given in the tensorflow documentation (api r1.13). I am using the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset"" rel=""nofollow noreferrer"">tf.data.experimental.CsvDataset</a> and the deprecated <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/data/sliding_window_batch"" rel=""nofollow noreferrer"">tf.contrib.data.sliding_window_batch</a> for a RNN and all works fine (except the deprecated sliding_window warning message). </p>

<p>For the update I have simply replaced </p>

<pre class=""lang-py prettyprint-override""><code>dataset = dataset.apply(tf.contrib.data.sliding_window_batch(batch_size, 1))
</code></pre>

<p>with</p>

<pre class=""lang-py prettyprint-override""><code>dataset = dataset.window(size=batch_size, stride=1).flat_map(lambda x: x.batch(batch_size))
</code></pre>

<p>and I got the following error for a csv file with 50 columns:</p>

<pre class=""lang-sh prettyprint-override""><code>TypeError: &lt;lambda&gt;() takes 1 positional argument but 50 were given
</code></pre>

<p>How can I solve this problem for any csv file (with any number of columns)?</p>
",2019-03-22 22:33:03,4328242,75,https://stackoverflow.com/questions/55308630,Documentation Replication on Other Examples
55347304,Error when applying sample/class weights to fit generator,"<p>I am using a tf.keras.Model fit_generator (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit_generator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit_generator</a>)  to feed batches of data to a model. According to TensorFlow Documentation, the fit generator should be able to accept size 2 (inputs, targets) or 3 (inputs, targets, sample_weights) tuple. We have the size 2 working, but we have unbalanced classes, so I have determined sample weights. When the fit generator returns a size 3 tuple, I get the error:
”tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got [batch_size]""</p>

<p>I am using tensorflow 1.12</p>

<p>Loss Function is tf.losses.softmax_cross_entropy</p>
",2019-03-25 22:27:41,11257466,21,https://stackoverflow.com/questions/55347304,Documentation Replication on Other Examples
55379830,How do I resize image with unknown size in Tensorflow(tf.shape(input) method doesn't work),"<p>According to <a href=""https://stackoverflow.com/questions/52410154/resizing-tensorflow-images-with-unknown-size"">this post</a>, one can use tf.shape() to resize image with unknown size like placeholder. But the method doesn't seem to work for me. I have some simple code that looks like:</p>

<pre><code>import tensorflow as tf
import numpy as np

def speed_tune(x, lower_bound=0.8, upper_bound=2.0):
    speed_rate = np.random.uniform(lower_bound, upper_bound)
    newshape = tf.shape(x)[1:] # get the tensor shape except for rank 0(None)
    newshape *= speed_rate # randomly stretch or compress the signal 
    return tf.resize(x, newshape)

sess = tf.InteractiveSession()
x = tf.placeholder(tf.int16, (None, 1000)) # x is a 1D audio signal
y = speed_tune(x)
data = np.random.randint(10, size=1000)
output = sess.run(y, feed_dict={x:data})
</code></pre>

<p>Basically, my code does the following: Given an input 1D data x, the program tries to stretch or compress the sequence by some random factor and return the tuned sequence. Since I didn't find any Tensorflow function that directly performs this operation, I use tf.resize by treating the data as 1xD image where D is the length of the signal. But I got an error:</p>

<pre><code>Traceback (most recent call last):
  File ""d:\SVNRepo\Python_codes\scratch.py"", line 33, in &lt;module&gt;
    y = speed_tune(x)
  File ""d:\SVNRepo\Python_codes\scratch.py"", line 28, in speed_tune
    newshape *= speed_rate # randomly stretch or compress the signal 
TypeError: unsupported operand type(s) for *=: 'Tensor' and 'float'
</code></pre>

<p>So it seems like <code>tf.shape(x)</code> returns a Tensor rather than integer values that specify the shape of the tensor(verified by <a href=""https://www.tensorflow.org/api_docs/python/tf/shape"" rel=""nofollow noreferrer"">Tensorflow document</a>). How can I solve this?</p>
",2019-03-27 14:35:31,8577452,473,https://stackoverflow.com/questions/55379830,Documentation Replication on Other Examples
55411824,tf.layers.Conv1D vs tf.keras.layers.Conv1D,"<p>I was using <a href=""https://www.tensorflow.org/tutorials/estimators/cnn"" rel=""nofollow noreferrer""><code>tf.layers.conv1d</code></a> found in <a href=""https://www.tensorflow.org/tutorials/estimators/cnn"" rel=""nofollow noreferrer"">this</a> tutorial but then realised it's been deprecated. Then I discovered <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D"" rel=""nofollow noreferrer""><code>tf.layers.Conv1D</code></a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D"" rel=""nofollow noreferrer""><code>tf.keras.layers.Conv1D</code></a>. I understand the later one is the keras implementation of one dimensional convolutional layer. I'm however not sure which one to use and what's the difference in terms of functionality. It would be great of someone could point out examples of using any of these two where the input data comes from csv files. </p>
",2019-03-29 06:44:13,4426009,862,https://stackoverflow.com/questions/55411824,Requesting (Additional) Documentation/Examples
55414091,Can we not give the name for a tensor in tf.get_variable in tensorflow?,"<p>In <code>tf.get_variable()</code>, there is a need to give a name for a variable. In contrast, it is not a must to specify names for variables in <code>tf.Variable()</code> function and tensorflow will give tensors default names. So, is there any trick for allowing us to omit manual name specification.</p>
",2019-03-29 09:19:31,7309971,61,https://stackoverflow.com/questions/55414091,Documentation Replicability
55420520,How do you apply layer normalization in an RNN using tf.keras?,"<p>I would like to apply <a href=""https://arxiv.org/abs/1607.06450"" rel=""noreferrer"">layer normalization</a> to a recurrent neural network using tf.keras. In TensorFlow 2.0, there is a <code>LayerNormalization</code> class in <code>tf.layers.experimental</code>, but it's unclear how to use it <em>within</em> a recurrent layer like <code>LSTM</code>, at each time step (as it was designed to be used). Should I create a custom cell, or is there a simpler way?</p>

<p>For example, applying dropout at each time step is as easy as setting the <code>recurrent_dropout</code> argument when creating an <code>LSTM</code> layer, but there is no <code>recurrent_layer_normalization</code> argument.</p>
",2019-03-29 15:15:26,38626,47323,https://stackoverflow.com/questions/55420520,Documentation Replication on Other Examples
55421386,"Tensorflow/Keras, How to convert tf.feature_column into input tensors?","<p>I have the following code to average embeddings for list of item-ids.
(Embedding is trained on review_meta_id_input, and used as look up for pirors_input and for getting average embedding)</p>

<pre><code> review_meta_id_input = tf.keras.layers.Input(shape=(1,), dtype='int32', name='review_meta_id')
 priors_input = tf.keras.layers.Input(shape=(None,), dtype='int32', name='priors') # array of ids
 item_embedding_layer = tf.keras.layers.Embedding(
     input_dim=100,      # max number
     output_dim=self.item_embedding_size,
     name='item')

 review_meta_id_embedding = item_embedding_layer(review_meta_id_input)
 selected = tf.nn.embedding_lookup(review_meta_id_embedding, priors_input)
 non_zero_count =  tf.cast(tf.math.count_nonzero(priors_input, axis=1), tf.float32)
 embedding_sum = tf.reduce_sum(selected, axis=1)
 item_average = tf.math.divide(embedding_sum, non_zero_count)
</code></pre>

<p>I also have some feature columns such as.. 
(I just thought feature_column looked cool, but not many documents to look for..)</p>

<pre><code>  kid_youngest_month = feature_column.numeric_column(""kid_youngest_month"")
     kid_age_youngest_buckets = feature_column.bucketized_column(kid_youngest_month, boundaries=[12, 24, 36, 72, 96])
</code></pre>

<p>I'd like to define <code>[review_meta_id_iput, priors_input, (tensors from feature_columns)]</code> as an input to keras Model.</p>

<p>something like:</p>

<pre><code> inputs = [review_meta_id_input, priors_input] + feature_layer
 model = tf.keras.models.Model(inputs=inputs, outputs=o)
</code></pre>

<p>In order to get tensors from feature columns, the closest lead I have now is </p>

<pre><code>fc_to_tensor = {fc: input_layer(features, [fc]) for fc in feature_columns}
</code></pre>

<p>from <a href=""https://github.com/tensorflow/tensorflow/issues/17170"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/17170</a></p>

<p>However I'm not sure what the <code>features</code> are in the code.<br>
There's no clear example on <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/input_layer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/feature_column/input_layer</a> either.  </p>

<p>How should I construct the <code>features</code> variable for <code>fc_to_tensor</code> ?</p>

<p>Or is there a way to use <code>keras.layers.Input</code> and <code>feature_column</code> at the same time?</p>

<p>Or is there an alternative than tf.feature_column to do the bucketing as above? then I'll just drop the feature_column for now;</p>
",2019-03-29 16:06:28,433570,40449,https://stackoverflow.com/questions/55421386,Inadequate Examples
55425811,Implementing Intersection over Union Loss Using Tensorflow,"<p>This may be more of a Tensorflow gradient question. I have been attempting to implement Intersection over Union (IoU) as losses and have been running into some problems. To the point, here is the snippet of my code that computes the IoU:</p>

<pre><code>def get_iou(masks, predictions):
    ious = []
    for i in range(batch_size):
        mask = masks[i]
        pred = predictions[i]
        masks_sum = tf.reduce_sum(mask)
        predictions_sum = tf.reduce_mean(pred)
        intersection = tf.reduce_sum(tf.multiply(mask, pred))
        union = masks_sum + predictions_sum - intersection
        iou = intersection / union
        ious.append(iou)
    return ious

iou = get_iou(masks, predictions)
mean_iou_loss = -tf.log(tf.reduce_sum(iou))
train_op = tf.train.AdamOptimizer(0.001).minimize(mean_iou_loss)
</code></pre>

<p>It works as predicted. However, the issue that I am having is the losses do not decrease. The model does train, though the results are less than ideal so I am wondering if I am implementing it correctly. Do I have to compute the gradients myself? I can compute the gradients for this IoU loss derived by <a href=""https://arxiv.org/pdf/1608.01471.pdf"" rel=""noreferrer"">this paper</a> using <code>tf.gradients()</code>, though I am not sure how to incorporate that with the <code>tf.train.AdamOptimizer()</code>. Reading the documentation, I feel like <code>compute_gradients</code> and <code>apply_gradients</code> are the commands that I need to use, but I can't find any examples on how to use them. My understanding is that the Tensorflow graph should be able to come up with the gradient itself via chain rule. So is a custom gradient even necessary in this problem? If the custom gradient is not necessary then I may just have an ill-posed problem and need to adjust some hyperparameters.</p>

<p><strong>Note:</strong> I have tried Tensorflow's implementation of the IoU, <code>tf.metrics.mean_iou()</code>, but it spits out <code>inf</code> every time so I have abandoned that.</p>
",2019-03-29 21:41:52,9754177,220,https://stackoverflow.com/questions/55425811,Documentation Replication on Other Examples
55451403,How to use tf.data.Options()?,"<p>Is one dataset created accompanied by default options? If not, how to use the tf.data.Options()? Just dataset = dataset.with_options(options)? Is there anything else to be noticed?</p>
",2019-04-01 08:59:41,6128145,143,https://stackoverflow.com/questions/55451403,Documentation Replication on Other Examples
55514435,Keras CuDNNLSTM implicit activation function?,"<p>While in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"" rel=""nofollow noreferrer"">tf.keras.layers.LSTM</a> there is an <code>activation</code> parameter (default <code>tanh</code>) <br>the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/CuDNNLSTM"" rel=""nofollow noreferrer"">CuDNNLSTM</a> doesn't have any, while having a <code>activity_regularizer</code> parameter.<Br>
Am I missing something? <br><br>CuDNNLSTM is not a tf.keras.layers.LSTM wrapper, but a standalone entity, so how do I set the activation function for it?</p>
",2019-04-04 11:08:34,7034613,2349,https://stackoverflow.com/questions/55514435,Documentation Replicability
55590729,How to implement big int or big decimal as a datatype in tensorflow,"<p>Tensorflow has no big integer or big decimal as a dtype. And it says that tf.strings can represent any kind of bytes array. Can I implement big data type using tf.strings? Or is there any other way?</p>
",2019-04-09 10:31:36,7111053,53,https://stackoverflow.com/questions/55590729,Documentation Replicability
55602703,"Can I add tf.keras.backend function in TensorFlow ""custom"" layer?","<p>TensorFlow can implement Keras with <code>tf.keras</code>.</p>

<p>Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.</p>

<p>If I wanted to build a custom layer, can I add <code>tf.keras.backend.theano.tensor.dot</code> and <code>tf.keras.backend.theano.gradient.disconnected_grad</code> in call function?</p>

<p>For example, there is one program in TensorFlow（<a href=""https://www.tensorflow.org/tutorials/eager/custom_layers"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/eager/custom_layers</a>）：</p>

<pre class=""lang-py prettyprint-override""><code>class MyDenseLayer(tf.keras.layers.Layer):
    def __init__(self, num_outputs):
        super(MyDenseLayer, self).__init__()
        self.num_outputs = num_outputs

    def build(self, input_shape):
        self.kernel = self.add_variable(""kernel"", 
                                    shape=[int(input_shape[-1]), 
                                           self.num_outputs])

    def call(self, input):
        return tf.matmul(input, self.kernel)
</code></pre>

<p>Can I change call function into:</p>

<pre class=""lang-py prettyprint-override""><code>def call(self, input):
    return tf.keras.backend.theano.tensor.dot(self.kernel,tf.keras.backend.theano.gradient.disconnected_grad(input))
</code></pre>
",2019-04-09 23:31:42,7241796,2041,https://stackoverflow.com/questions/55602703,Documentation Replication on Other Examples
55718702,How to correctly train with tf.keras.layers.BatchNormalization: Is there still a tf.GraphKeys.UPDATE_OPS dependency?,"<p>My goal is how to correctly train with batch normalizations layers in TensorFlow (TensorFlow version 1.13.1 for Python in Graph Mode) using the recommended tf.keras.layers.BatchNormalization class (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization</a>).</p>

<p>An older recommended approach was to use tf.layers.batch_normalization.  The documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization</a>) indicates that it is currently deprecating instead in favor of tf.keras.layers.BatchNormalization.  </p>

<p>While using the older class, the documentation indicates we must explicitly add dependency on the mean and variance update operations, which would otherwise be dangling nodes outside from any dependencies in training operations:</p>

<pre><code>update_ops_including_from_batch_norms  =  tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
   my_optimizer = tf.super_cool_optimizer(loss)
</code></pre>

<p>My question:  Is this explicit dependence on UPDATE_OPS still needed when training batch norms in TF 1.13 with tf.keras.layers.BatchNormalization?  I don't see this mentioned in the documentation, however, I would be much more comfortable if someone knew for sure (and even better if can point to official documentation or code) that these operation dependencies are implicitly taken care of.</p>
",2019-04-17 01:37:22,6367958,41,https://stackoverflow.com/questions/55718702,Lack of Alternative Solutions/Documentation
55731549,How to use tf.keras Sequential with tf.distribute.ParameterServerStrategy and tf.train.MonitoredSession?,"<p>I'm trying to set up a really easy Minimal Working Example for the following: Use a model built with tf.keras in a tf.train.MonitoredSession using a tf.Server with a tf.distribute.ParameterServerStrategy.</p>

<p>My goal in the end is to use a tf.keras model in a distributed environment using two workers each having one GPU and a parameter server.</p>

<p>The model is built according to the example and documentation found here: <a href=""https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/keras/models/Sequential"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/keras/models/Sequential</a></p>

<p>The parameter server strategy is used according to the documentation found here: <a href=""https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/distribute/ParameterServerStrategy"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/distribute/ParameterServerStrategy</a></p>

<p>The overall setup including the device placement and the use of a MonitoredSession is taken from: <a href=""https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md"" rel=""nofollow noreferrer"">https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md</a></p>

<p>I'm already using the ""allow_soft_placement"" option and I'm ""emulating"" a distributed setup on my local machine having only a single CPU, since there are different problems in the real distributed setup which I'm trying to solve by using a MonitoredSession where the variable initialization is handled automatically.</p>

<p>This Code works with a ""normal"" (not monitored) tf.Session and variable initialization - global, local, model variables and tables etc.</p>

<p>The line which unfreezes the graph is necessary to be able to use a tf.data.Dataset in the tf.keras.Model's fit function, since an iterator has to be created - which causes an error in a frozen graph.</p>

<p>This the code I'm trying to run. I use tensorflow 1.12.0 and python 3.6.7. I've also tried python 2.7, same result.</p>

<p>The code requires no setup besides installing tensorflow.</p>

<pre class=""lang-py prettyprint-override""><code>import sys
import tensorflow as tf

def main(argv):

  # Create local cluster config for run_local_server.sh script.
  cluster = tf.train.ClusterSpec({""worker"": [""localhost:2222""], ""ps"": [""localhost:2223""]})
  task = 0
  job = str(argv[0])

  # Number of GPUs per worker
  GPU_PER_WORKER = 0

  config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
  server = tf.train.Server(cluster, job_name=job, task_index=task,config=config)

  strategy = tf.contrib.distribute.ParameterServerStrategy(num_gpus_per_worker=GPU_PER_WORKER)
  strategy.configure(session_config=config, cluster_spec=cluster,task_type=job,task_id=task)

  with strategy.scope():
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

    x_train = x_train.astype('float32') / 255
    x_test = x_test.astype('float32') / 255

    # Reshape input data from (28, 28) to (28, 28, 1)
    w, h = 28, 28
    x_train = x_train.reshape(x_train.shape[0], w, h, 1)
    x_test = x_test.reshape(x_test.shape[0], w, h, 1)

    # One-hot encode the labels
    y_train = tf.keras.utils.to_categorical(y_train, 10)
    y_test = tf.keras.utils.to_categorical(y_test, 10)

    train_ds = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_train),tf.data.Dataset.from_tensor_slices(y_train))).repeat().shuffle(60000).batch(10)
    val_ds = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_test),tf.data.Dataset.from_tensor_slices(y_test))).repeat().shuffle(10000).batch(10)

    with tf.device(tf.train.replica_device_setter(worker_device=""/job:worker/task:%d"" % task,cluster=cluster)):
      model = tf.keras.models.Sequential()

      conv0 = tf.keras.layers.Conv2D(filters=16, data_format='channels_last', padding=""valid"", kernel_size=4, strides=1, input_shape=(28,28,1), activation=tf.keras.activations.relu)
      model.add(conv0)

      flatten = tf.keras.layers.Flatten()
      model.add(flatten)

      dense1 = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)
      model.add(dense1)

      model.compile(tf.contrib.optimizer_v2.AdamOptimizer(0.001), loss=tf.keras.metrics.mean_absolute_error,metrics=['accuracy'],distribute=strategy)   

    if job == ""ps"":
      server.join()
    elif job == ""worker"":
      with tf.train.MonitoredSession(session_creator=tf.train.ChiefSessionCreator(master=server.target,config=config)) as sess:        
        sess.graph._unsafe_unfinalize()
        history = model.fit(x=train_ds, validation_data=val_ds, validation_steps=1000, steps_per_epoch=100, epochs=60)

if __name__ == ""__main__"":
  main(sys.argv[1:])
</code></pre>

<p>The code requires no extensive setup since the dataset is loaded from the web and converted to a tf.data.Dataset since this is how I want to organize my pipeline with the real data. The MNIST data setup example is taken from 
<a href=""https://www.kaggle.com/margaretmz/mnist-with-tf-keras"" rel=""nofollow noreferrer"">https://www.kaggle.com/margaretmz/mnist-with-tf-keras</a>.</p>

<p>I expect the code to not fail due to wrong variable or operation placement since I'm basically leaving all these decisions to the implementation of tensorflow by using <code>strategy.scope()</code> and <code>tf.device(tf.train.replica_device_setter(worker_device=""/job:worker/task:%d"" % task,cluster=cluster))</code></p>
",2019-04-17 15:50:12,6489953,95,https://stackoverflow.com/questions/55731549,Documentation Replication on Other Examples
55770009,How to use a pre-trained embedding matrix in tensorflow 2.0 RNN as initial weights in an embedding layer?,"<p>I'd like to use a pretrained GloVe embedding as the initial weights for an embedding layer in an RNN encoder/decoder. The code is in Tensorflow 2.0. Simply adding the embedding matrix as a weights = [embedding_matrix] parameter to the tf.keras.layers.Embedding layer won't do it because the encoder is an object and I'm not sure now to effectively pass the embedding_matrix to this object at training time.</p>

<p>My code closely follows the <a href=""https://www.tensorflow.org/alpha/tutorials/text/nmt_with_attention"" rel=""noreferrer"">neural machine translation example in the Tensorflow 2.0 documentation</a>. How would I add a pre-trained embedding matrix to the encoder in this example? The encoder is an object. When I get to training, the GloVe embedding matrix is unavailable to the Tensorflow graph. I get the error message: </p>

<p>RuntimeError: Cannot get value inside Tensorflow graph function. </p>

<p>The code uses the GradientTape method and teacher forcing in the training process. </p>

<p>I've tried modifying the encoder object to include the embedding_matrix at various points, including in the encoder's <strong>init</strong>, call and initialize_hidden_state. All of these fail. The other questions on stackoverflow and elsewhere are for Keras or older versions of Tensorflow, not Tensorflow 2.0.</p>

<pre><code>class Encoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):
        super(Encoder, self).__init__()
        self.batch_sz = batch_sz
        self.enc_units = enc_units
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix])
        self.gru = tf.keras.layers.GRU(self.enc_units,
                                       return_sequences=True,
                                       return_state=True,
                                       recurrent_initializer='glorot_uniform')

    def call(self, x, hidden):
        x = self.embedding(x)
        output, state = self.gru(x, initial_state = hidden)
        return output, state

    def initialize_hidden_state(self):
        return tf.zeros((self.batch_sz, self.enc_units))

encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)

# sample input
sample_hidden = encoder.initialize_hidden_state()
sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)
print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))
print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))

# ... Bahdanau Attention, Decoder layers, and train_step defined, see link to full tensorflow code above ...

# Relevant training code

EPOCHS = 10

training_record = pd.DataFrame(columns = ['epoch', 'training_loss', 'validation_loss', 'epoch_time'])


for epoch in range(EPOCHS):
    template = 'Epoch {}/{}'
    print(template.format(epoch +1,
                 EPOCHS))
    start = time.time()

    enc_hidden = encoder.initialize_hidden_state()
    total_loss = 0
    total_val_loss = 0

    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):
        batch_loss = train_step(inp, targ, enc_hidden)
        total_loss += batch_loss

        if batch % 100 == 0:
            template = 'batch {} ============== train_loss: {}'
            print(template.format(batch +1,
                            round(batch_loss.numpy(),4)))
</code></pre>
",2019-04-20 03:33:30,5875503,61,https://stackoverflow.com/questions/55770009,Documentation Replication on Other Examples
55868686,how to use eager execution to save and restore in TensorFlow？,"<p>We always use <code>tf.train.Saver()</code> to save and restore weights, like in <a href=""https://www.tensorflow.org/guide/saved_model"" rel=""nofollow noreferrer"">this</a> example. </p>

<p>But how to use eager execution to save? how to change the following example? </p>

<p>Another question, is it a good idea to use eager? </p>

<p>I found <code>tf.contrib.eager.Saver</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/eager/Saver"" rel=""nofollow noreferrer"">here</a>, but it says, </p>

<blockquote>
  <p>""Saver's name-based checkpointing strategy is fragile"". </p>
</blockquote>

<p>What does it mean?</p>

<pre><code># Create some variables.
v1 = tf.get_variable(""v1"", shape=[3], initializer = tf.zeros_initializer)
v2 = tf.get_variable(""v2"", shape=[5], initializer = tf.zeros_initializer)

inc_v1 = v1.assign(v1+1)
dec_v2 = v2.assign(v2-1)

# Add an op to initialize the variables.
init_op = tf.global_variables_initializer()

# Add ops to save and restore all the variables.
saver = tf.train.Saver()

# Later, launch the model, initialize the variables, do some work, and save the
# variables to disk.
with tf.Session() as sess:
  sess.run(init_op)
  # Do some work with the model.
  inc_v1.op.run()
  dec_v2.op.run()
  # Save the variables to disk.
  save_path = saver.save(sess, ""/tmp/model.ckpt"")
  print(""Model saved in path: %s"" % save_path)
</code></pre>
",2019-04-26 13:27:57,7241796,2041,https://stackoverflow.com/questions/55868686,Documentation Replication on Other Examples
55904359,TypeError computing gradients with GradientTape.gradient,"

<p>Hello,  </p>

<p>I'm currently trying to compute gradients in <strong>Tensorflow 1.13.1</strong> and using the <code>GradientTape</code> class as explained in the <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">official documentation</a> , but I am getting a <code>TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;</code>.<br>
Below, I will include two simple cases where I get this error, using only out-of-the-box Tensorflow function, the first one being the simpler minimal working example, and the second one that I actually need to solve/get a work-around. For completeness, I am using <strong>Python 3.6.8</strong>.</p>

<h2>Simpler one</h2>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

tf.reset_default_graph()
x = tf.constant([1., 2., 3.])
with tf.GradientTape(persistent=True) as gg:
    gg.watch(x)
    f1 = tf.map_fn(lambda a: a**2, x)
    f2 = x*x

# Computes gradients
d_fx1 = gg.gradient(f1, x)     #Line that causes the error
d_fx2 = gg.gradient(f2, x)     #No error
del gg #delete persistent GradientTape

with tf.Session() as sess:
    d1, d2 = sess.run((d_fx1, d_fx2))
print(d1, d2)
</code></pre>

<p>In this code, <code>f1</code> and <code>f2</code> are computed in different ways, but give the same array. However, when trying to compute the gradients associated with them, the first line one gives the following error, whereas the second line works flawlessly. I report below the stack trace of the error</p>

<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-1-9c59a2cf2d9b&gt; in &lt;module&gt;()
     15 
     16 with tf.Session() as sess:
---&gt; 17     d1, d2 = sess.run((d_fx1, d_fx2))
     18 print(d1, d2)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    927     try:
    928       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 929                          run_metadata_ptr)
    930       if run_metadata:
    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1135     # Create a fetch handler to take care of the structure of fetches.
   1136     fetch_handler = _FetchHandler(
-&gt; 1137         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
   1138 
   1139     # Run request and get response.

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in __init__(self, graph, fetches, feeds, feed_handles)
    469     """"""
    470     with graph.as_default():
--&gt; 471       self._fetch_mapper = _FetchMapper.for_fetch(fetches)
    472     self._fetches = []
    473     self._targets = []

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in for_fetch(fetch)
    259     elif isinstance(fetch, (list, tuple)):
    260       # NOTE(touts): This is also the code path for namedtuples.
--&gt; 261       return _ListFetchMapper(fetch)
    262     elif isinstance(fetch, collections.Mapping):
    263       return _DictFetchMapper(fetch)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in __init__(self, fetches)
    368     """"""
    369     self._fetch_type = type(fetches)
--&gt; 370     self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
    371     self._unique_fetches, self._value_indices = _uniquify_fetches(self._mappers)
    372 

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in &lt;listcomp&gt;(.0)
    368     """"""
    369     self._fetch_type = type(fetches)
--&gt; 370     self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
    371     self._unique_fetches, self._value_indices = _uniquify_fetches(self._mappers)
    372 

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in for_fetch(fetch)
    256     if fetch is None:
    257       raise TypeError('Fetch argument %r has invalid type %r' % (fetch,
--&gt; 258                                                                  type(fetch)))
    259     elif isinstance(fetch, (list, tuple)):
    260       # NOTE(touts): This is also the code path for namedtuples.

TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;
</code></pre>

<p>Please note that I also tried computing only one gradient at a time, i.e with <code>persistent=False</code>, and got the same results.</p>

<h2>Actual need</h2>

<p>Below, I will include also the minimal working example to reproduce the same error I got, but trying to resolve the problem I am actually working on.</p>

<p>In this code, I'm using a <code>RNN</code> to compute an output w.r.t some inputs, and I need to compute the <code>jacobian</code> of this output w.r.t the inputs. </p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tensorflow.keras.layers import RNN, GRUCell

# Define size of variable. TODO: adapt to data
inp_dim = 2
num_units = 50
batch_size = 100
timesteps = 10

# Reset the graph, so as to avoid errors
tf.reset_default_graph()

# Building the model
inputs = tf.ones(shape=(timesteps, batch_size, inp_dim))

# Follow gradient computations
with tf.GradientTape() as g:
    g.watch(inputs)
    cells = [GRUCell(num_units), GRUCell(num_units)]
    rnn = RNN(cells, time_major=True, return_sequences=True)
    f = rnn(inputs)
d_fx = g.batch_jacobian(f, inputs)

# Run graph
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    grads = sess.run(d_fx)
grads.shape
</code></pre>

<p>Regarding the stack trace, I get the same error but with less lines (there are one <code>for_fetch</code>, <code>&lt;listcomp&gt;</code> and <code>__init</code> less in this stack trace). For completeness, I still include it below</p>

<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-5-bb2ce4eebe87&gt; in &lt;module&gt;()
     25 with tf.Session() as sess:
     26     sess.run(tf.global_variables_initializer())
---&gt; 27     grads = sess.run(d_fx)
     28 grads.shape

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    927     try:
    928       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 929                          run_metadata_ptr)
    930       if run_metadata:
    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1135     # Create a fetch handler to take care of the structure of fetches.
   1136     fetch_handler = _FetchHandler(
-&gt; 1137         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
   1138 
   1139     # Run request and get response.

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in __init__(self, graph, fetches, feeds, feed_handles)
    469     """"""
    470     with graph.as_default():
--&gt; 471       self._fetch_mapper = _FetchMapper.for_fetch(fetches)
    472     self._fetches = []
    473     self._targets = []

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in for_fetch(fetch)
    256     if fetch is None:
    257       raise TypeError('Fetch argument %r has invalid type %r' % (fetch,
--&gt; 258                                                                  type(fetch)))
    259     elif isinstance(fetch, (list, tuple)):
    260       # NOTE(touts): This is also the code path for namedtuples.

TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;
</code></pre>

<p>I feel like there is a bug with some Tensorflow function that gets me the error, however I am not sure. At the end, what interest me is getting a <code>tensor</code> containing the <strong>jacobian</strong> of the output of my network w.r.t to the inputs. How can I achieve that using other tools, or correcting my code ?</p>

<p><strong>EDIT</strong>: Ok, so I took into account the comments by danyfang, and tried to look into the issue raised on Github he quoted about <code>tf.gradients</code> returning <code>None</code> instead of <code>0</code> due to some implementation design in low-level Tensorflow.</p>

<p>Therefore, I tried to create a simple case where I am sure that gradient are different from <code>0</code>, by computing <code>tf.matmul(tf.transpose(x), x)</code>. I am posting below a MWE.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

tf.reset_default_graph()
x = tf.constant([[1., 2., 3.]])
with tf.GradientTape(persistent=True) as gg:
    gg.watch(x)
    y = tf.matmul(x, tf.transpose(x))
    f1 = tf.map_fn(lambda a: a, y)

# Computes gradients
d_fx1 = gg.gradient(f1, x)
d_yx = gg.gradient(y, x)
del gg #delete persistent GradientTape

with tf.Session() as sess:
    #d1 = sess.run(d_fx1) # Same error None type
    d2 = sess.run(d_yx) #Works flawlessly. returns array([[2., 4., 6.]], dtype=float32)
d2
</code></pre>

<p>This shows (at least in my opinion) that the error arises not because of the behavior reported by this <a href=""https://github.com/tensorflow/tensorflow/issues/3972"" rel=""nofollow noreferrer"">issue</a>, but another thing due to lower level implementation.</p>
",2019-04-29 13:24:24,9092979,55,https://stackoverflow.com/questions/55904359,Documentation Replication on Other Examples
55936016,TensorFlow 2.0 clip_by_value with dynamic bounds,"<p>It is not clear from the TensorFlow documentation whether I can have dynamic range constraints imposed on a <code>tf.Variable</code> via <code>tf.clip_by_value</code>. From my testing it doesn't seem to work, but I would like to be sure, and if it isn't then I also would like to know how to achieve this (there are certain parts of my parameter space that cause NaNs in my loss function, and these constraints can only be described in terms of combinations of parameters).</p>

<p>Here is my test scenario:</p>

<pre><code>import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd
import numpy as np

N = 2
Ntrials = 100
x = [tf.Variable(np.zeros(Ntrials,dtype='float32'), name='x{0}'.format(i)) for i in range(N)]
eta = [tf.Variable(np.zeros(Ntrials,dtype='float32'),
  constraint=lambda z: tf.clip_by_value(z, -x[i] + 0.0001, np.infty), name='eta{0}'.format(i))
   for i in range(N)]
# i.e. x[i] + eta[i] should always be positive

cov = [[1.0, 0.0],[0.0,1.0]]
mvn0 = tfd.MultivariateNormalFullCovariance([1,1],cov)

# Get samples
samples0 = mvn0.sample(Ntrials) # Ntrials)

print(""samples.shape:"", samples0.shape)

# Get pdf values for samples
etax = None
def get_loss():
   global etax
   etax = [xi + etai for xi,etai in zip(x,eta)]
   # Need to stack eta variables for broadcasting in MultivariateNormalFullCovariance
   all_etax = tf.stack(etax, axis=1, name='all_eta')
   #print(""all_eta.shape:"", all_eta.shape)
   mvnfree = tfd.MultivariateNormalFullCovariance(all_etax,cov)
   p = mvnfree.log_prob(samples0)
   #print(""p:"",p)
   return -2*tf.math.reduce_sum(p,axis=0)

# Minimise
tol = 0.01 * N
delta_loss = 1e9
prev_loss = 1e9
i = 0
print(""tol:"", tol)
opt = tf.optimizers.SGD(0.1)
while delta_loss &gt; tol:
    opt.minimize(get_loss,var_list=eta+x)
    last_loss = get_loss()  
    delta_loss = np.abs(prev_loss -last_loss)
    print(""i:"", i, "" delta_loss:"", delta_loss)
    tf.print(""  x:"", x)
    tf.print(""  eta:"", eta)
    tf.print(""  etax:"", etax)
    i+=1
    prev_loss = last_loss

print(""Finished!"")
</code></pre>

<p>Output:</p>

<pre><code>samples.shape: (100, 2)
tol: 0.02
i: 0  delta_loss: 999999400.0
  x: [[0.186258137 0.269369602 0.520818532 ... 0.354108274 0.137650698 0.25976041], [-0.149198815 0.34362933 0.128372893 ... 0.391129225 0.239100441 0.264151126]]
  eta: [[0.186258137 0.269369602 0.520818532 ... 0.354108274 0.137650698 0.25976041], [0.0001 0.34362933 0.128372893 ... 0.391129225 0.239100441 0.264151126]]
  etax: [[0.372516274 0.538739204 1.04163706 ... 0.708216548 0.275301397 0.519520819], [-0.149098814 0.687258661 0.256745785 ... 0.782258451 0.478200883 0.528302252]]
i: 1  delta_loss: 111.583984
  x: [[0.298013031 0.430991352 0.83330965 ... 0.566573262 0.220241114 0.415616632], [-0.268577874 0.549806893 0.205396622 ... 0.625806808 0.3825607 0.422641814]]
  eta: [[0.298013031 0.430991352 0.83330965 ... 0.566573262 0.220241114 0.415616632], [0.149298817 0.549806893 0.205396622 ... 0.625806808 0.3825607 0.422641814]]
  etax: [[0.596026063 0.861982703 1.6666193 ... 1.13314652 0.440482229 0.831233263], [-0.119279057 1.09961379 0.410793245 ... 1.25161362 0.7651214 0.845283628]]
</code></pre>

<p>The constraint on <code>eta</code> should enforce that <code>x + eta</code> is positive, but already we see negative values appearing in the first two loops.</p>

<p>Or is this perhaps an issue of the order of updating of variables? For example in the minimise loop I guess it is important that the <code>x</code> variables get updated first so that the constraint on the <code>eta</code> variables gets calculated correctly? I guess there is no guarantee of that, and I need to tell TensorFlow to do this? </p>

<p>Edit: I attempted to manually clip the variables in the optimisation loop, like so:</p>

<pre><code>while delta_loss &gt; tol:
    opt.minimize(get_loss,var_list=eta+x)
    # Manually clip variables
    clip_op = [eta[i].assign(tf.clip_by_value(eta[i], -x[i] + 0.0001, np.infty)) for i in range(N)]
    ...
</code></pre>

<p>and it seems to kind of work in this case, but in other test cases it seems to make the minimiser go haywire. I guess because it fights with the minimiser about what values the variables should have. So I'm not sure that this is a good solution.</p>

<p>Edit 2: Well for my specific case I realised that I could solve my problem with math, i.e. by a change of variables I can make the problem not require any explicit constraints. Which is probably the best thing to do if it is possible. But it won't always be, so I am still curious how to do it with constraints.</p>
",2019-05-01 12:05:40,1447953,2477,https://stackoverflow.com/questions/55936016,Documentation Replication on Other Examples
55951969,how to properly use Keras imports since it is embedded in TF?,"<p>how to i properly import anything from keras within tensorflow?</p>

<p>if I e.g., </p>

<p><code>from tensorflow import keras</code></p>

<p><code>from keras.layers.core import Dense</code></p>

<p>does that import from Keras or from tf.keras? </p>
",2019-05-02 11:58:33,6510273,2039,https://stackoverflow.com/questions/55951969,Documentation Replicability
55986982,What is the way to use Tensor flow 2.0 object in open cv2 python and why is it so circuitous?,"<p>I load an image using tensor flow api (2.0) like so : </p>

<pre><code>def load(image_file):
  image = tf.io.read_file(image_file)
  image = tf.image.decode_jpeg(image)
</code></pre>

<p>Now that I have this object, I want to show this image, I can simply use matplotlib.pyplot, and this works. </p>

<pre><code>plt.figure()
plt.imshow(re/255.0)
plt.show()
</code></pre>

<p>However attempting this with OpenCV2 is problematic from the start, most of the examples are from 1.0 with .eval() session based suggestion for numpy conversion. One way would be to first convert tensor flow object to numpy, here is the function to do that from API documentation :</p>

<pre><code>TensorFlow
API r2.0
TensorFlow Core 2.0a
Python
tf.make_ndarray
Create a numpy ndarray from a tensor.
</code></pre>

<p>I dont understand why this does not works and I get a number of errors while all I want is to do something simple and then use some open cv2 functions like remap, resize etc.:</p>

<blockquote>
  <p>File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py"",
  line 426, in <strong>call</strong>
      self._initialize(args, kwds, add_initializers_to=initializer_map)   File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py"",
  line 370, in _initialize
      *args, **kwds))   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py"",
  line 1313, in _get_concrete_function_internal_garbage_collected
      graph_function, _, _ = self._maybe_define_function(args, kwargs)   File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py"",
  line 1580, in _maybe_define_function
      graph_function = self._create_graph_function(args, kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py"",
  line 1512, in _create_graph_function
      capture_by_value=self._capture_by_value),   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\framework\func_graph.py"",
  line 694, in func_graph_from_py_func
      func_outputs = python_func(*func_args, **func_kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py"",
  line 317, in wrapped_fn
      return weak_wrapped_fn().<strong>wrapped</strong>(*args, **kwds)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\framework\func_graph.py"",
  line 686, in wrapper
      ), args, kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\autograph\impl\api.py"",
  line 392, in converted_call
      result = converted_f(*effective_args, **kwargs)   File ""C:\Users\syeda\AppData\Local\Temp\tmpnahp3og4.py"", line 32, in
  tf__random_deform
      im2 = ag__.converted_call('make_ndarray', tf, ag__.ConversionOptions(recursive=True, verbose=0,
  strip_decorators=(tf.function, defun_9, ag__.convert,
  ag__.do_not_convert, ag__.converted_call), force_conversion=False,
  optional_features=(), internal_convert_user_code=True), (real_image,),
  {})   File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\autograph\impl\api.py"",
  line 267, in converted_call
      return _call_unconverted(f, args, kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\autograph\impl\api.py"",
  line 188, in _call_unconverted
      return f(*args, **kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\framework\tensor_util.py"",
  line 596, in MakeNdarray
      shape = [d.size for d in tensor.tensor_shape.dim] AttributeError: 'Tensor' object has no attribute 'tensor_shape'</p>
</blockquote>

<p><strong>Update 5/5/2018 :</strong> After searching more I found out that this has something to do with Tensorflow graph execution. 
I have a function </p>

<pre><code>def load_image_train(image_file):
  input_image, real_image = load(image_file)
 print(type(real_image))
  print(real_image.shape)
  some_image = Open CV operations like filtering, jitter etc performed on real_image
return some_image
</code></pre>

<p>This works nicely when called eagerly with .numpy() attribute, however when called like following code and when you try to inspect what real_image is and its type returns</p>

<blockquote>
  <p>class 'tensorflow.python.framework.ops.Tensor'   (None, None, None)</p>
</blockquote>

<p>Please advice.</p>

<pre><code># Input pipeline
train_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')
train_dataset = train_dataset.shuffle(BUFFER_SIZE)
train_dataset = train_dataset.map(load_image_train,
                               num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_dataset = train_dataset.batch(1)
</code></pre>

<p><strong>Update 5/5/2018 :</strong> I decided to do a preprocessing of the data so I don't have to worry about the using any opencv functionality during the load time of the data. However during training time I still want to do some openCV operations. Now as per the suggestion of @giser_yugang I tried using py_function, I wrap opencv operations in py_function and call that function in a wrapper tf.function. This wrapper tf.function I call in train step. However the output I get from this wrapper function is like so : </p>

<pre><code>class 'tensorflow.python.framework.ops.Tensor'
unknown
</code></pre>

<p>Then if I try to consume this tensor in the next train step operation I get a </p>

<pre><code>incompatible with the layer: its rank is undefined, but the layer requires a defined rank.
</code></pre>

<p>If I don't use this py_function wrapper in my train step and directly try the numpy operations using opencv I get another error </p>

<pre><code>AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>

<p>I guess both ways you cant win !</p>
",2019-05-04 21:33:42,4930939,521,https://stackoverflow.com/questions/55986982,Documentation Ambiguity
56002345,Why get_tensor_by_name can't get the weights of layers defined by tf.keras.layers properly,"<p>I try to get the weights of layers defined by <code>tf.keras.layers</code> by using <code>get_tensor_by_name</code> in <code>tensorflow</code>. The code is presented as follows</p>

<pre><code># encoding: utf-8
import tensorflow as tf

x = tf.placeholder(tf.float32, (None,3))
h = tf.keras.layers.dense(3)(x)
y = tf.keras.layers.dense(1)(h)

for tn in tf.trainable_variables():
    print(tn.name)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
w = tf.get_default_graph().get_tensor_by_name(""dense/kernel:0"")
print(sess.run(w))
</code></pre>

<p>The name of the weight is <code>dense/kernel:0</code>. However, the output of <code>sess.run(w)</code> is weird</p>

<pre><code>[( 10,) ( 44,) ( 47,) (106,) (111,) ( 98,) ( 58,) (108,) (111,) ( 99,)
 ( 97,) (108,) (104,) (111,) (115,) (116,) ( 47,) (114,) (101,) 
 ... ]
</code></pre>

<p>which is not an array of floats. In fact, if I use <code>tf.layers.dense</code> to define the network, everything goes fine. So my question is that how I can get the weights of layers defined by <code>tf.keras.layers</code> by using tensor name properly.</p>
",2019-05-06 09:26:57,8601361,385,https://stackoverflow.com/questions/56002345,Documentation Replication on Other Examples
56166885,How to check evaluation auc after every epoch when using tf.estimator.EstimatorSpec?,"<p>I defined my model using tf.estimator.EstimatorSpec. I know it has train, evaluation and prediction modes. But I want to check some metric scores such as auc after every epoch. Does this API support it like keras?</p>
",2019-05-16 10:52:24,7185861,293,https://stackoverflow.com/questions/56166885,Inadequate Examples
56204555,Is there a simpler method to get slice of a tensors as shown in the following example?,"<p>I want to do slicing of tensors like the following slicing in numpy. How can I do that?</p>

<pre><code># numpy array
a = np.reshape(np.arange(60), (3,2,2,5))
idx = np.array([0, 1, 0])
N = np.shape(a)[0]
mask = a[np.arange(N),:,:,idx]


# I have tried several solutions, but only the following success.
# tensors
import tensorflow as tf
import numpy as np


a = tf.cast(tf.constant(np.reshape(np.arange(60), (3,2,2,5))), tf.int32)
idx2 = tf.constant([0, 1, 0])

fn = lambda i: a[i][:,:,idx2[i]]
idx = tf.range(tf.shape(a)[0])
masks = tf.map_fn(fn, idx)
with tf.Session() as sess:
    print(sess.run(a))
    print(sess.run(tf.shape(masks)))
    print(sess.run(masks))
</code></pre>

<p>Is there a simpler method to achieve this ?</p>

<p>Can I use function <code>tf.gather</code> or <code>tf.gather_nd</code> to achieve this ?
Many thanks!</p>
",2019-05-19 03:34:54,8289138,13,https://stackoverflow.com/questions/56204555,Inadequate Examples
56212366,TensorFlow tf.data processing dev set after each epoch,"<pre class=""lang-py prettyprint-override""><code>batch_size = 2
x_dim = 2
m = 5
m_dev = 4
epochs = 2

# Toy data
X_train = np.random.randn(m, x_dim)
Y_train = np.random.randint(0, 5, size=m).reshape(-1, 1)
X_dev = np.random.randn(m_dev, x_dim)
Y_dev = np.random.randint(0, 5, size=m_dev).reshape(-1, 1)

X = tf.placeholder(X_train.dtype, shape=[None, x_dim], name='X')
Y = tf.placeholder(Y_train.dtype, shape=[None, 1], name='Y')

# Create two separate datasets
train_dataset = tf.data.Dataset.from_tensor_slices((X, Y)).batch(batch_size)
dev_dataset = tf.data.Dataset.from_tensor_slices((X, Y)).batch(X_dev.shape[0])

# Create a generic Iterator
iterator = tf.data.Iterator.from_structure(train_dataset.output_types,
                                           train_dataset.output_shapes)

# Create two init ops
train_init_op = iterator.make_initializer(train_dataset)
dev_init_op = iterator.make_initializer(dev_dataset)

next_data = iterator.get_next()

with tf.Session() as sess:
    for epoch in range(epochs):
        # Training data
        sess.run(train_init_op, feed_dict={X: X_train, Y: Y_train})
        while True:
            try:
                X_batch, Y_batch = sess.run(next_data)
                # process training data
            except tf.errors.OutOfRangeError:
                break

        # Epoch done: process the dev data
        sess.run(dev_init_op, feed_dict={X: X_dev, Y: Y_dev})
        X_dev_all, Y_dev_all = sess.run(next_data)
</code></pre>

<p>I am using <code>tf.data</code> with reinitializable iterator to handle training and dev set data. For each epoch, I initialize the training data set. <a href=""https://www.tensorflow.org/guide/datasets#creating_an_iterator"" rel=""nofollow noreferrer"">The official documentation</a> has similar structure. I think this is not efficient especially if the training set is large. </p>

<p>Some of the resources I found online has <code>sess.run(train_init_op, feed_dict={X: X_train, Y: Y_train})</code> before the for loop to avoid this issue. But then we can't process the dev set after each epoch; we can only process it after we are done iterating over <code>epochs</code> epochs.</p>

<p>Is there a way to efficiently process the dev set after each epoch?</p>
",2019-05-19 22:04:39,6217326,967,https://stackoverflow.com/questions/56212366,Documentation Replication on Other Examples
56213510,Is there an way to apply gradients for multiple output layers in tf.GradientTape?,"<p>I'm trying to gradients apply over two output models, but the result indicates that the model does not learn and loss does not decrease,
I need to your supported 
Thank you.</p>

<p>@tf.function
def train_step(inp, targ, intent, enc_hidden):</p>

<pre><code>loss = 0
intent_loss = 0

with tf.GradientTape(persistent= True) as tape:

    enc_output, enc_hidden = encoder(inp, enc_hidden)

    dec_hidden = enc_hidden




    dec_input = tf.expand_dims([targ_lang.word_index['&lt;start&gt;']] * BATCH_SIZE, 1)

    # Teacher forcing - feeding the target as the next input
    for t in range(1, targ.shape[1]):

        # passing enc_output to the decoder
        predictions, dec_hidden, _ =slot_decoder(dec_input, dec_hidden, enc_output)
        intent_pred, _ = intent_decoder(dec_hidden, enc_output)

        loss += loss_function(targ[:, t], predictions)
        intent_loss = loss_function(intent, intent_pred)

        # using teacher forcing
        dec_input = tf.expand_dims(targ[:, t], 1)

batch_loss = (loss / int(targ.shape[1])) + intent_loss

intent_variables = encoder.trainable_variables + intent_decoder.trainable_variables
slot_variables = encoder.trainable_variables + slot_decoder.trainable_variables

intent_gradients = tape.gradient(intent_loss, intent_variables)
slot_gradients = tape.gradient(loss, slot_variables)


optimizer.apply_gradients(zip(intent_gradients, intent_variables))
optimizer.apply_gradients(zip(slot_gradients, slot_variables))

del tape
return batch_loss + intent_loss
</code></pre>
",2019-05-20 01:56:31,8053884,51,https://stackoverflow.com/questions/56213510,Documentation Replication on Other Examples
56229730,Trouble with zero-padding inputs for Steered Convolution Layer,"<p>I'm using Tensorflow's new graphics library to apply a steered convolution to a series of meshes.  In many cases, you will have a series of meshes that are not the same size and you must zero-pad the smaller ones.  According to the documentation, the ""sizes"" argument of the graph_conv.feature_steered_convolution_layer function takes in an int tensor consisting of the number of non-padded elements of each mesh.  For some reason, when this argument is set something other than ""None"", I get a warning telling me that the sparse array used in the ""neighbors"" argument is being converted to a dense matrix.  This causes my program to run absurdly slowly.  </p>

<p>The issue seems to be tied to the way that it calculates gradients.  If the optimizer is commented out, the error does not come up.  </p>

<p>I read about a similar problem (link below) where the solution to the problem was to use tf.dynamic_partition rather than tf.gather.  However, the tf.gather functions, in this case are located within the graph_convolution library.  I attempted to make some edits in my copy of the library, but to no avail.</p>

<p><a href=""https://stackoverflow.com/questions/45882401/how-to-deal-with-userwarning-converting-sparse-indexedslices-to-a-dense-tensor/45917500#45917500"">How to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape</a></p>

<pre class=""lang-py prettyprint-override""><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl.testing import parameterized
import numpy as np
import tensorflow as tf

from tensorflow_graphics.nn.layer import graph_convolution as graph_conv

#Number of meshes
N = 2
#Number of spatial dimensions
d = 2

#################################
#Data consists of the vertices of two meshes.  The first mesh has 5 vertices and the second has 4.
    #Shape of data is (numberOfMeshes,maxNumberofVertices,numberofSpatialDimensions)

#An array containing the actual size of each non-padded mesh
sz = np.array([5,4],dtype=np.int64)
#The maximum number of vertices in a mesh
datav = 5

#Input placeholder for input data (vertices)
V0 = tf.placeholder(dtype=tf.float64,name=""V0"",shape=(N,datav,d)) 
#Input Placeholder for labels for classification (For now, I'm just using throw-away data as my labels)
L = tf.placeholder(shape=(N,5,1),dtype=tf.float64)
SZ = tf.placeholder(shape=(N),dtype=tf.int64)
#Input placeholder for the sparse array representing the adjacency matrix shape:(numberOfMeshes,datav,datav)
    #The warning is not raised if ""SZ"" is changed to ""None
adj_sp = tf.sparse_placeholder(shape=(SZ.shape[0],datav,datav),dtype=tf.float64,name='SPP')



#The steered graph convolution that is included in Tensorflow's new graphics package
output = graph_conv.feature_steered_convolution_layer(data=V0,neighbors=adj_sp,sizes=SZ,translation_invariant=False,num_weight_matrices=1,num_output_channels=1)

loss = tf.losses.softmax_cross_entropy(L,output, weights=1.0)
optimizer = tf.train.AdamOptimizer(learning_rate=.001).minimize(loss) #Warning not raised if this is commented out
</code></pre>

<p>When the above code is run, I get the following warning:</p>

<pre><code>C:\Python37\lib\site-packages\tensorflow\python\ops\gradients_impl.py:110: 
UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown 
shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
</code></pre>

<p>I am starting to think that this might have more to do with the library itself than with this piece of code.  I have referenced this posed in GitHub in case it requires updates (or additional documentation) to the library.
<a href=""https://github.com/tensorflow/graphics/issues/13"" rel=""nofollow noreferrer"">https://github.com/tensorflow/graphics/issues/13</a></p>
",2019-05-21 00:38:39,11506976,27,https://stackoverflow.com/questions/56229730,Requesting (Additional) Documentation/Examples
56247113,"why DNNClassifier doesn't accept Sparse features, but LinearClassifier does","<p><em>tf.estimator.DNNClassifier</em> doesn't accept sparse feature columns such as <em>categorical_column_with_hash_bucket</em>. It can only accept dense columns which always needed to be wrapped with indicator_column.</p>

<pre><code>category_column = tf.feature_column.categorical_column_with_hash_bucket(key, hash_size)
tf.feature_column.indicator_column(category_column)
</code></pre>

<p><em>tf.estimator.LinearClassifier</em> on the other hand can accept <em>categorical_column_with_hash_bucket</em> directly.</p>

<pre><code>tf.feature_column.categorical_column_with_hash_bucket(key, hash_size)
</code></pre>

<p>According to this <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/feature_column/feature_column_v2.py"" rel=""nofollow noreferrer"">tf source code</a></p>

<p><em>Sparse features can be fed directly into linear models. They behave like an indicator column but with an efficient implementation.</em></p>

<p>I wonder what such efficient implementation is there in Linear as against DNN which restricts DNN to only accept dense columns.</p>
",2019-05-21 22:30:26,2277149,65,https://stackoverflow.com/questions/56247113,Documentation Ambiguity
56284927,tf.keras equivalent code block written in tf.contrib.slim,"<p>I'm trying to re-implement a research paper code in tf.keras, in init block it was written as:</p>

<pre><code>with slim.arg_scope([slim.conv2d,separable_conv],activation_fn=tf.nn.relu6, normalizer_fn=slim.batch_norm):
    with slim.arg_scope([slim.batch_norm], is_training=is_training, activation_fn=None):
        with tf.variable_scope(name):
            net = slim.conv2d(inputs, num_outputs=depth, kernel_size=3, stride=2, scope=""conv"") #padding same
</code></pre>

<p>I didn't find a equivalent in tf.keras.layer.Conv2D arguments for normalizer_fn=slim.batch_norm. How to achieve this in keras?</p>

<p>I tried:</p>

<pre><code>model.add(Conv2D(""some arguments"") #0
model.add(BatchNormalization())
</code></pre>

<p>Is this a valid equivalent to the above tf.contrib.slim code. With limited documentation of tf.contrib.slim, I'm really confused.</p>
",2019-05-24 01:57:15,10544741,51,https://stackoverflow.com/questions/56284927,Documentation Replication on Other Examples
56289685,TensorflowJS predict asynchronously,"<p>I have been trying to figure out how to perform predictions using tensorflowJS in an asynchronous fashion. All my attempts resulted in the predict function blocking my code.</p>

<p>Looking at the <a href=""https://js.tensorflow.org/api/latest/#model"" rel=""nofollow noreferrer"">docs</a>, I see that most of the functions are defined as async functions and return a promise like for example <code>tf.loadLayersModel</code>, which also works for me asynchronously without any blocking.</p>

<p>However, <a href=""https://js.tensorflow.org/api/latest/#tf.LayersModel.predict"" rel=""nofollow noreferrer"">predict</a> doesn't return a promise but directly a <code>tf.Tensor</code>. I tried wrapping the predictions in a customly defined async function like:</p>

<pre class=""lang-javascript prettyprint-override""><code>compute = async(data) =&gt; {
  var tensor = tf.tensor(data, [1, 100])
  var prediction = this.model.predict(tensor)
  return prediction.data()
}
</code></pre>

<p>But still predict is blocking the execution of my code.</p>

<p>What is the right approach to use TensorflowJS for asynchronous inference?</p>
",2019-05-24 09:29:24,9357259,627,https://stackoverflow.com/questions/56289685,Documentation Replicability
56312032,How to use Keras `add_loss` exclusively,"<p>I am implementing a model that has a complicated loss term which requires the Keras <code>add_loss</code> function. I wish to implement my model as a <code>tf.keras.Model</code> (see <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/models/Model"" rel=""nofollow noreferrer"">documentation</a>). Unfortunately, it seems like Keras cannot deal with the case where <code>add_loss</code> is used, but <code>compile</code> does not get a loss function specification.</p>

<p>Here is a minimal example that ""works"" (doesn't do anything interesting, but no errors are raised):</p>

<pre><code>import tensorflow as tf
import numpy as np    

class Model(tf.keras.Model):

    def __init__(self, *args, **kwargs):
        super(Model, self).__init__(*args, **kwargs)    
        self.layer = tf.keras.layers.Dense(3, 
                       activation=tf.keras.activations.relu)

    def call(self, inputs, **kwargs):    
        output = self.layer(inputs)
        return output


if __name__ == '__main__':
    tf.random.set_random_seed(1)
    m = Model()    
    x = np.array([[1., 2., 3.]])
    y = np.array([[0., 1., 0.5]])    
    m.compile(tf.keras.optimizers.SGD(), 
              loss=tf.keras.losses.mean_squared_error)
    m.fit(x, y, epochs=100, verbose=0)
    print(m.predict(x))
    # [[0.         0.99999666 0.5000101 ]]
</code></pre>

<p>However, I don't need the ""external"" loss function, only one specified with <code>add_loss</code>, and this does not work. 
I had hoped that the following code does exactly the same thing as the one above:</p>

<pre><code># Same imports...

class Model(tf.keras.Model):

    # def __init__ ...

    def call(self, inputs, **kwargs):    
        output = self.layer(inputs)
        error = tf.keras.losses.mean_squared_error([0., 1., 0.5], output)
        self.add_loss(error)
        return output


if __name__ == '__main__':    
    tf.random.set_random_seed(1)
    m = Model()    
    x = np.array([[1., 2., 3.]])    
    m.compile(tf.keras.optimizers.SGD())
    m.fit(x, epochs=100, verbose=0)
    print(m.predict(x))
</code></pre>

<p>but it does not work. 
In particular, from <code>m.fit(x)</code> I get the error message</p>

<pre><code>AttributeError: 'Model' object has no attribute 'total_loss'
</code></pre>

<p>One possible workaround is to add a trivial loss function</p>

<pre><code>def no_loss(*args):
    return tf.keras.backend.constant(0.0)
</code></pre>

<p>but I had hoped for a more elegant solution.</p>

<p>I am using Tensorflow 1.13.1. </p>
",2019-05-26 08:50:05,6760298,246,https://stackoverflow.com/questions/56312032,Documentation Ambiguity
56321676,How to use tf.concat() function?,"<p>I found a bug in <code>tf.concat</code>. The problem is:</p>

<blockquote>
  <p>'Tensors in list passed to 'values' of 'ConcatV2' Op have types
  [float32, ] that don't all match'.</p>
</blockquote>

<p>I do not know how to correct it.</p>

<pre><code>for idx in range(1, num_layer):
      layer = Dense(layers[idx], W_regularizer=l2(reg_layers[idx]),activation='relu', name=""layer%d"" % idx)
      mlp_vector = layer(mlp_vector)
predict_vector = tf.concat([mf_vector, mlp_vector],-1)  
</code></pre>
",2019-05-27 07:38:51,11559876,1,https://stackoverflow.com/questions/56321676,Documentation Replication on Other Examples
56344827,"in TF2, how do you save models/weights when not using the tf.keras API?","<p>In the documentation it seems they focus on how to save and restore tf.keras.models, but i was wondering how do you save and restore models trained customly through some basic iteration loop?</p>

<p>Now that there isnt a graph or a session, how do we save structure defined in a tf function that is customly built without using layer abstractions?</p>
",2019-05-28 14:48:29,10038330,172,https://stackoverflow.com/questions/56344827,Lack of Alternative Solutions/Documentation
56436701,tf.data.Dataset.window example from the documentation fails,"<p>I'm trying to use an example from the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"" rel=""nofollow noreferrer"">TF documentation</a> for <code>tf.data.Dataset.window</code> and the example from the documentation is failing.</p>

<p>Code derived from the documentation:</p>

<pre><code>import tensorflow as tf

ds = tf.data.Dataset.range(7).window(2)
next_element = ds.make_one_shot_iterator().get_next()

with tf.Session() as sess:
    print(sess.run(next_element))
</code></pre>

<p>Produces this error (trace removed):</p>

<pre><code>TypeError: Can not convert a _VariantDataset into a Tensor or Operation.
During handling of the above exception, another exception occurred:
TypeError: Fetch argument &lt;_VariantDataset shapes: (), types: tf.int64&gt; has invalid type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;, must be a string or Tensor. (Can not convert a _VariantDataset into a Tensor or Operation.)
</code></pre>

<p>So <code>iterator.get_next()</code> is returning a <code>VariantDataset</code> rather than the usual tensor.</p>

<p><strong>TF Version: 1.13.1</strong></p>
",2019-06-04 02:39:12,4790871,31007,https://stackoverflow.com/questions/56436701,Documentation Replication on Other Examples
56458133,Tensorflow error when adding writing summaries 'Tensor' object has no attribute 'value',"<p>this is my code:</p>

<pre><code>import tensorflow as tf
import tensorboardcolab as tb
tbc = tb.TensorBoardColab()
writer=  tbc.get_writer()
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""/tmp/data/"", one_hot = True)
n_nodes_hl1 = 500
n_nodes_hl2 = 500
n_nodes_hl3 = 500

n_classes = 10
batch_size = 100

tf.reset_default_graph()
x = tf.placeholder('float', [None, 784], name='input_data')
y = tf.placeholder('float', [None, 10], name='labels')
def neural_network_model(data):
  with tf.name_scope('feedforward'):
    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),
                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}

    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),
                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}

    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),
                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}

    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),
                    'biases':tf.Variable(tf.random_normal([n_classes])),}


    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])
    l1 = tf.nn.relu(l1)

    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])
    l2 = tf.nn.relu(l2)

    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])
    l3 = tf.nn.relu(l3)

    tf.summary.histogram(""l1"", l1)
    tf.summary.histogram(""l2"", l2)
    tf.summary.histogram(""l3"", l3)

    output = tf.add(tf.matmul(l3,output_layer['weights']),output_layer['biases'])
    return output

def train_neural_network(x):
    prediction = neural_network_model(x)
    with tf.name_scope('cost'):
      cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )
    optimizer = tf.train.AdamOptimizer().minimize(cost)
    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))

    hm_epochs = 10
    with tf.Session() as sess:
        sess.run(tf.initialize_all_variables())
        writer.add_graph(sess.graph)
        for epoch in range(hm_epochs):
            epoch_loss = 0
            for t in range(int(mnist.train.num_examples/batch_size)):
                epoch_x, epoch_y = mnist.train.next_batch(batch_size)
                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})
                epoch_loss += c
                if t%50 == 0:
                  val_acc = accuracy.eval({x:mnist.test.images, y:mnist.test.labels})
                  print('Accuracy:',val_acc)


            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)


#             acc_summ = tf.summary.scalar('val_acc', val_acc)
#             cost_summ = tf.summary.scalar('epoch_loss',epoch_loss)
#             merged = tf.summary.merge([cost_summ, acc_summ])
#             writer.add_summary(merged)

train_neural_network(x)
</code></pre>

<p>It runs fine when the commented parts are commented out. However, I don't get why when<code>writer.add_summary()</code> is uncommented out I get the following error:</p>

<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-204-e776a1e8e4f1&gt; in &lt;module&gt;()
----&gt; 1 train_neural_network(x)

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/writer/writer.py in add_summary(self, summary, global_step)
    125     # to save space - we just store the metadata on the first value with a
    126     # specific tag.
--&gt; 127     for value in summary.value:
    128       if not value.metadata:
    129         continue

AttributeError: 'Tensor' object has no attribute 'value'
</code></pre>

<p>It doesn't make sense to me. The docs <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter#close"" rel=""nofollow noreferrer"">for the FileWriter class</a> clearly states that it takes in a list of String tensors, and the docs for the <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/scalar"" rel=""nofollow noreferrer"">tf.summary.scalar</a> says that it returns a tensor of type string with summary protocol, so it seems like it should work.</p>

<p>Here's what I've tried, by people who seemed to have the same issue as me, but nothing worked:
<a href=""https://stackoverflow.com/questions/47030644/tensorboard-error-tensor-object-has-no-attribute-value"">Tensorboard expects a string for summary</a>, adding <code>eval()</code> didn't work.</p>

<p><a href=""https://stackoverflow.com/questions/51783265/in-add-summary-for-value-in-summary-value-attributeerror-tensor-object-has-n?rq=1"">The value error is raised because you have to evaluate the summary node within a session.</a> I am already running it in session.</p>

<p><a href=""https://stackoverflow.com/questions/35413618/tensorflow-placeholder-error-when-using-tf-merge-all-summaries"">Merges all summaries in the default graph</a>. Initially, I was using merging all summaries, but now I switched to <code>tf.summary.merge</code>.</p>

<p><a href=""https://github.com/keras-team/keras/issues/7362#issuecomment-341637550"" rel=""nofollow noreferrer"">Coming from improperly connected tensors</a>. I am using <code>tf.matmul</code> and <code>tf.add</code> here instead of regular operands.</p>

<p>Another thing I tried was putting tensor objects into the second argument of <code>tf.summary.scalar</code>, something like replacing the commented part of the code above like this:</p>

<pre><code>    cost_summ = tf.summary.scalar('epoch_loss',c)
    merged = tf.summary.merge([cost_summ])
    writer.add_summary(merged)
</code></pre>

<p>But event that didn't seem to work.</p>

<p>Why doesn't my above code work, while <a href=""https://stackoverflow.com/questions/49951902/in-tensorflow-is-it-possible-to-append-some-summaries-to-already-merged-summary"">this code here</a> works? I don't see a difference.</p>

<pre><code>import tensorflow as tf

a = tf.summary.scalar('a', tf.constant(0))
b = tf.summary.scalar('b', tf.constant(1))
c = tf.summary.scalar('c', tf.constant(2))
d = tf.summary.scalar('d', tf.constant(3))

ab = tf.summary.merge([a, b])
cd = tf.summary.merge([c, d])
abcd = tf.summary.merge([ab, cd])

with tf.Session() as sess:
    writer = tf.summary.FileWriter('.', sess.graph)
    summary = sess.run(abcd)
    writer.add_summary(summary)
</code></pre>

<p>Also, I am using Google Colab, which is why I'm importing tensorboardcolab. </p>
",2019-06-05 09:50:44,9721336,424,https://stackoverflow.com/questions/56458133,Documentation Ambiguity
56465794,Re-write TensorFlow into Keras with tf.keras,"<p>I wan to re-write TensorFlow code into Keras. I just wonder if you can use for this purpose the <code>tf.keras.layers</code> to just replace the <code>tf.layers</code>?</p>

<p>Like</p>

<pre><code>tf.layers.max_pooling2d() 
</code></pre>

<p>to:</p>

<pre><code>tf.keras.layers.max_pooling2d() 
</code></pre>

<p>Can I re-write TensorFlow to Keras in this way?</p>

<p>Does this define a proper Keras model where you can use the <code>model.fit</code> method?</p>
",2019-06-05 18:03:15,9451356,345,https://stackoverflow.com/questions/56465794,Documentation Replication on Other Examples
56491633,What is the difference between tf.scatter_add and tf.scatter_nd when indices is a matrix?,"<p>Both <a href=""https://www.tensorflow.org/api_docs/python/tf/scatter_add"" rel=""nofollow noreferrer"">tf.scatter_add</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_nd</a> allow <code>indices</code> to be a matrix. It is clear from the documentation of tf.scatter_nd that the last dimension of <code>indices</code> contains values that are used to index a tensor of shape <code>shape</code>. The other dimensions of <code>indices</code> define the number of elements/slices to be scattered. Suppose <code>updates</code> has a rank <code>N</code>. First <code>k</code> dimensions of <code>indices</code> (except the last dimension) should match with first <code>k</code> dimensions of <code>updates</code>.  The last <code>(N-k)</code> dimensions of <code>updates</code> should match with the last <code>(N-k)</code> dimensions of <code>shape</code>.</p>

<p>This implies that <code>tf.scatter_nd</code> can be used to perform an <code>N</code>-dimensional scatter. However, <code>tf.scatter_add</code> also takes matrices as <code>indices</code>. But, its not clear which dimensions of <code>indices</code> correspond to the number of scatters to be performed and how do these dimensions align with <code>updates</code>. Can someone provide a clear explanation possibly with examples?</p>
",2019-06-07 09:27:36,1313405,95,https://stackoverflow.com/questions/56491633,Inadequate Examples
56552397,Custom metric: Using scikit learn's AucRoc Calculator with tf.keras,"<p>I'm training a multilabel classifier using tf.keras and horovod that has 14 classes. AucRoc is used as the metric to evaluate the performance of the classifier. I want to be able to use scikit learn's AucRoc calculator as mentioned here: <a href=""https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras"">How to compute Receiving Operating Characteristic (ROC) and AUC in keras?</a>. If I feed the tensors as is for the following function:</p>

<pre><code>def sci_auc_roc(y_true, y_pred):
    return tf.py_func(roc_auc_score(y_true, y_pred), tf.double)
</code></pre>

<p>I get an error that looks like this: </p>

<pre><code>/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.
  warnings.warn('The output shape of `ResNet50(include_top=False)` '
Traceback (most recent call last):
  File ""official_resnet_tf_1.12.0_auc.py"", line 531, in &lt;module&gt;
    main()
  File ""official_resnet_tf_1.12.0_auc.py"", line 420, in main
    model = chexnet_model(FLAGS)
  File ""official_resnet_tf_1.12.0_auc.py"", line 375, in chexnet_model
    metrics=[tf_auc_roc,sci_auc_roc])
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py"", line 474, in _method_wrapper
    method(self, *args, **kwargs)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 648, in compile
    sample_weights=self.sample_weights)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 313, in _handle_metrics
    output, output_mask))
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 270, in _handle_per_output_metrics
    y_true, y_pred, weights=weights, mask=mask)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 598, in weighted
    score_array = fn(y_true, y_pred)
  File ""official_resnet_tf_1.12.0_auc.py"", line 327, in sci_auc_roc
    return tf.py_func(roc_auc_score(y_true, y_pred), tf.double)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/sklearn/metrics/ranking.py"", line 349, in roc_auc_score
    y_type = type_of_target(y_true)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/sklearn/utils/multiclass.py"", line 243, in type_of_target
    'got %r' % y)
ValueError: Expected array-like (array or non-string sequence), got &lt;tf.Tensor 'dense_target:0' shape=(?, ?) dtype=float32&gt;

</code></pre>

<p>I'm trying to convert tf tensors into a numpy array and then feed them to the roc_auc_score method like so: </p>

<pre><code>def sci_auc_roc(y_true, y_pred):
    with tf.Session() as sess:
        y_true, y_pred = sess.run([y_true, y_pred])
    return tf.py_func(roc_auc_score(y_true, y_pred), tf.double)
</code></pre>

<p>I get the following error:</p>

<pre><code> warnings.warn('The output shape of `ResNet50(include_top=False)` '
Traceback (most recent call last):
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,256,256,3]
         [[{{node input_1}} = Placeholder[dtype=DT_FLOAT, shape=[?,256,256,3], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[{{node dense_target/_5}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_2237_dense_target"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""official_resnet_tf_1.12.0_auc.py"", line 531, in &lt;module&gt;
    main()
  File ""official_resnet_tf_1.12.0_auc.py"", line 420, in main
    model = chexnet_model(FLAGS)
  File ""official_resnet_tf_1.12.0_auc.py"", line 375, in chexnet_model
    metrics=[tf_auc_roc,sci_auc_roc])
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py"", line 474, in _method_wrapper
    method(self, *args, **kwargs)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 648, in compile
    sample_weights=self.sample_weights)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 313, in _handle_metrics
    output, output_mask))
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 270, in _handle_per_output_metrics
    y_true, y_pred, weights=weights, mask=mask)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 598, in weighted
    score_array = fn(y_true, y_pred)
  File ""official_resnet_tf_1.12.0_auc.py"", line 324, in sci_auc_roc
    y_true, y_pred = sess.run([y_true, y_pred])
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,256,256,3]
         [[node input_1 (defined at /mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/keras_applications/resnet50.py:214)  = Placeholder[dtype=DT_FLOAT, shape=[?,256,256,3], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[{{node dense_target/_5}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_2237_dense_target"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'input_1', defined at:
  File ""official_resnet_tf_1.12.0_auc.py"", line 531, in &lt;module&gt;
    main()
  File ""official_resnet_tf_1.12.0_auc.py"", line 420, in main
    model = chexnet_model(FLAGS)
  File ""official_resnet_tf_1.12.0_auc.py"", line 339, in chexnet_model
    input_shape=(FLAGS.image_size, FLAGS.image_size, 3))
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/applications/__init__.py"", line 70, in wrapper
    return base_fun(*args, **kwargs)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/applications/resnet50.py"", line 32, in ResNet50
    return resnet50.ResNet50(*args, **kwargs)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/keras_applications/resnet50.py"", line 214, in ResNet50
    img_input = layers.Input(shape=input_shape)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py"", line 229, in Input
    input_tensor=tensor)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_layer.py"", line 112, in __init__
    name=self.name)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1747, in placeholder
    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 5206, in placeholder
    ""Placeholder"", dtype=dtype, shape=shape, name=name)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 488, in new_func
    return func(*args, **kwargs)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3274, in create_op
    op_def=op_def)
  File ""/mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1770, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,256,256,3]
         [[node input_1 (defined at /mnt/lustrefs/rakvee/miniconda3/envs/docker_pip2/lib/python3.6/site-packages/keras_applications/resnet50.py:214)  = Placeholder[dtype=DT_FLOAT, shape=[?,256,256,3], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[{{node dense_target/_5}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_2237_dense_target"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[52342,1],0]
  Exit code:    1
--------------------------------------------------------------------------
</code></pre>

<p>I've also tried tensorflow's <a href=""https://www.tensorflow.org/api_docs/python/tf/metrics/auc"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/metrics/auc</a> like so: </p>

<pre><code>def tf_auc_roc(y_true, y_pred):
    auc = tf.metrics.auc(y_true, y_pred)[1]
    K.get_session().run(tf.local_variables_initializer())
    return auc
</code></pre>

<p>It works just fine. However, it gives me a single number for aucroc. I wonder what that number represents, is it an average aucroc value for all the 14 classes? or max aucscores of all the classes? or how does it get to a single number?</p>

<pre><code>1216/1216 [==============================] - 413s 340ms/step - loss: 0.1513 - tf_auc_roc: 0.7944 - val_loss: 0.2212 - val_tf_auc_roc: 0.8074
Epoch 2/15
 582/1216 [=============&gt;................] - ETA: 3:16 - loss: 0.1459 - tf_auc_roc: 0.8053

</code></pre>

<p>1) How do I fix the error with roc_auc_score? </p>

<p>2) What does that single number represent?</p>
",2019-06-11 22:25:09,10287380,9,https://stackoverflow.com/questions/56552397,Lack of Alternative Solutions/Documentation
56606757,Tensorflow: output of multi-step decay function returns a TypeError,"<p>We are trying to write a multi-step decay function in Tensorflow using tf.train.piecewise_constant() as suggested <a href=""https://stackoverflow.com/a/47174243/5079359"">here</a>. Tensorflow documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/train/piecewise_constant_decay"" rel=""nofollow noreferrer"">here</a> states that:</p>

<p>""When eager execution is enabled, this function returns a function which in turn returns the decayed learning rate Tensor""</p>

<p>However, when we tried running the code, it returned a  TypeError. 
It returns the same error even when lr() is used.</p>

<pre><code>import tensorflow as tf
tf.enable_eager_execution()
import numpy as np

def conv3x3(out_planes, data_format ='channels_last',  stride=1, padding='same', dilation=1, name = None,use_bias = False):
    """"""3x3 convolution with padding""""""
    return  tf.keras.layers.Conv2D(filters = out_planes, kernel_size = 3,data_format= data_format,
                                   strides=(stride, stride), padding='same', use_bias=use_bias,
                                   dilation_rate = (dilation,dilation) , kernel_initializer=tf.initializers.he_normal(),name = name)


def conv1x1(out_planes,data_format ='channels_last', padding = 'same', stride=1):
    """"""1x1 convolution""""""
    return tf.keras.layers.Conv2D(filters = out_planes, kernel_size = 1, strides=(stride, stride),data_format= data_format,
                                  padding=padding, use_bias=False, kernel_initializer=tf.initializers.he_normal())

class BasicBlock(tf.keras.Model):
    expansion = 1

    def __init__(self, planes=1, stride=1, data_format= 'channels_last', downsample=None,  dilation=(1, 1), residual=True, key=None, stage = None):
        super(BasicBlock, self).__init__()
        self.data_format = data_format
        bn_axis = 1 if self.data_format == 'channels_first' else 3
        self.conv1 = conv3x3(out_planes= planes, stride = stride, padding='same' ,
                             data_format = self.data_format, dilation=dilation[0], name = '{}_{}_conv0'.format(key,stage))

        self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis, name = '{}_{}_BN0'.format(key,stage))

        self.conv2 = conv3x3(out_planes =planes, padding='same',
                             data_format = self.data_format, dilation=dilation[0],name = '{}_{}_conv1'.format(key,stage))

        self.bn2 = tf.keras.layers.BatchNormalization(axis=bn_axis,name = '{}_{}_BN1'.format(key,stage))

        self.downsample = downsample
        self.relu = tf.keras.layers.ReLU(name = '{}_{}_Relu'.format(key,stage))
        self.stride = stride
        self.residual = residual

    def get_config(self):
        base_config = {}
        base_config['conv1'] = self.conv1.get_config()
        base_config['bn1'] = self.bn1.get_config()
        base_config['conv2'] = self.conv2.get_config()
        base_config['bn2'] = self.bn2.get_config()
        if self.downsample is not None:
            base_config['downsample'] = self.downsample.get_config()
        return base_config


    def call(self, inputs, training=None):
        residual = inputs
        out = self.conv1(inputs)
        out = self.bn1(out,training = training)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(inputs)
        if self.residual:
            out += residual
        out = self.relu(out)
        return out


class Bottleneck(tf.keras.Model):
    expansion = 4

    def __init__(self, planes, stride=1, data_format = 'channels_last',downsample=None,dilation=(1, 1)):
        super(Bottleneck, self).__init__()

        bn_axis = 1 if data_format == 'channels_first' else 3
        self.conv1 = conv1x1(planes, data_format = data_format)
        self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis)
        self.relu = tf.keras.layers.ReLU()
        self.conv2 = conv3x3(planes, stride, padding= 'same', bias=False,  data_format = data_format, dilation=dilation[1])
        self.bn2 = tf.keras.layers.BatchNormalization(axis=bn_axis)
        self.conv3 =conv1x1( planes * 4, data_format = data_format, )
        self.bn3 =  tf.keras.layers.BatchNormalization(axis=bn_axis) # nn.BatchNorm2d(planes * self.expansion)
        self.downsample = downsample
        self.stride = stride

    def get_config(self):
        base_config = {}
        base_config['conv1'] = self.conv1.get_config()
        base_config['bn1'] = self.bn1.get_config()
        base_config['conv2'] = self.conv2.get_config()
        base_config['bn2'] = self.bn2.get_config()
        base_config['conv3'] = self.conv3.get_config()
        base_config['bn3'] = self.bn3.get_config()
        if self.downsample is not None:
            base_config['downsample'] = self.downsample.get_config()
        return base_config



    def call(self, inputs, training=None):
        identity = inputs
        out = self.conv1(inputs)
        out = self.bn1(out,training = training)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out,training = training)
        out = tf.nn.relu(out)
        out = self.conv3(out)
        out = self.bn3(out,training = training)
        if self.downsample is not None:
            identity = self.downsample(inputs)
        out += identity
        out = self.relu(out)
        return out

class pooling (tf.keras.Model):
    def __init__(self, pool_size, stride = None, data_format='channels_last'):
        super(pooling, self).__init__()
        self.pool_size = pool_size
        self.data_format = data_format
        if stride is None:
            self.stride =self.pool_size
        else:
            self.stride = stride


    def call(self, inputs):
        return tf.layers.average_pooling2d(inputs, strides =self.stride, pool_size = self.pool_size, data_format = self.data_format)


class DRN(tf.keras.Model):
    def __init__(self, block, layers, data_format='channels_last', num_classes=7,channels=(16, 32, 64, 128, 256, 512, 512, 512),
                 out_map=False, out_middle=False, pool_size=28, arch='D'):
        super(DRN, self).__init__()
        self.inplanes = channels[0]
        self.out_map = out_map
        self.out_dim = channels[-1]
        self.out_middle = out_middle
        self.arch = arch
        self.poolsize = pool_size
        self.data_format = data_format
        self.bn_axis = 1 if data_format == 'channels_first' else 3

        self.conv0 = tf.keras.layers.Conv2D(filters=channels[0], kernel_size=7, strides=1,  padding='same',
                                               use_bias=False, data_format = self.data_format, kernel_initializer=tf.initializers.he_normal(), name ='L0_conv0' )
        self.bn0 = tf.keras.layers.BatchNormalization(axis=self.bn_axis,name ='L0_BN0')
        self.relu0 = tf.keras.layers.ReLU(name ='L0_Relu0')


        if arch == 'C':
            self.layer1 = self._make_layer(block = BasicBlock, planes = channels[0], blocks = layers[0], stride=1, data_format = self.data_format, key='CL1')
            self.layer2 = self._make_layer(block = BasicBlock, planes =  channels[1], blocks = layers[1], stride=2, data_format = self.data_format, key='CL2')
        elif arch == 'D':
            self.layer1 = self._make_conv_layers(channels = channels[0],convs = layers[0], stride=1, data_format = self.data_format, key='DL1')
            self.layer2 = self._make_conv_layers(channels = channels[1],convs = layers[1], stride=2, data_format = self.data_format, key='DL2')


        self.layer3 = self._make_layer(block = block, planes = channels[2], blocks = layers[2], stride=2, data_format = self.data_format, key='L3')
        self.layer4 = self._make_layer(block = block, planes = channels[3], blocks = layers[3], stride=2, data_format = self.data_format, key='L4')
        self.layer5 = self._make_layer(block = block, planes = channels[4], blocks = layers[4], dilation=2, new_level=False, data_format = self.data_format, key='L5')
        self.layer6 = None if layers[5] == 0 else self._make_layer(block, channels[5], layers[5], dilation=4, new_level=False, data_format = self.data_format, key='L6')

        if arch == 'C':
            self.layer7 = None if layers[6] == 0 else self._make_layer(BasicBlock, channels[6], layers[6], dilation=2, new_level=False, residual=False, data_format = self.data_format, key='CL7')
            self.layer8 = None if layers[7] == 0 else self._make_layer(BasicBlock, channels[7], layers[7], dilation=1, new_level=False, residual=False, data_format = self.data_format, key='CL8')
        elif arch == 'D':
            self.layer7 = None if layers[6] == 0 else self._make_conv_layers(channels[6], layers[6], dilation=2, data_format = self.data_format, key='DL7')
            self.layer8 = None if layers[7] == 0 else self._make_conv_layers(channels[7], layers[7], dilation=1, data_format = self.data_format, key='DL8')

        if num_classes &gt; 0:
            self.avgpool = tf.keras.layers.GlobalAveragePooling2D(data_format = self.data_format)
            self.fc = tf.keras.layers.Dense(units=num_classes)


    def _make_layer(self, block, planes, blocks, stride=1,dilation=1, new_level=True, data_format = 'channels_last', residual=True, key=None):
        assert dilation == 1 or dilation % 2 == 0
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = tf.keras.Sequential([conv1x1(out_planes = planes * block.expansion,stride = stride, data_format = data_format),
                      tf.keras.layers.BatchNormalization(axis=self.bn_axis)], name = 'downsample')

#
        layers = []
        layers.append(block(planes= planes, stride =  stride, downsample = downsample, dilation=(1, 1) if dilation == 1 else (
                dilation // 2 if new_level else dilation, dilation), data_format=data_format, residual=residual, key = key, stage = '0'))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(planes, residual=residual,dilation=(dilation, dilation), data_format=data_format, key = key, stage = i))
        return tf.keras.Sequential(layers, name = key)


    def _make_conv_layers(self, channels, convs, stride=1, dilation=1 ,data_format = 'channels_last', key = None):
        modules = []
        for i in range(convs):
            modules.extend([
                conv3x3(out_planes= channels, stride=stride if i == 0 else 1,
                          padding= 'same' , use_bias=False, dilation=dilation,  data_format = data_format,name ='{}_{}_Conv'.format(key,i)),
                tf.keras.layers.BatchNormalization(axis=self.bn_axis,name ='{}_{}_BN'.format(key,i)),
                tf.keras.layers.ReLU(name ='{}_{}_Relu'.format(key,i))])
            self.inplanes = channels
        return tf.keras.Sequential(modules,name=key)


    def call(self, x, training=None):
        x = self.conv0(x)
        x = self.bn0(x,training = training)
        x = self.relu0(x)
        x = self.layer1(x,training = training)
        x = self.layer2(x,training = training)
        x = self.layer3(x,training = training)
        x = self.layer4(x,training = training)
        x = self.layer5(x,training = training)

        if self.layer6 is not None:
            x = self.layer6(x,training = training)

        if self.layer7 is not None:
            x = self.layer7(x)
        if self.layer8 is not None:
            x = self.layer8(x)
        if self.out_map:
            x = self.fc(x)
        else:
            x = self.avgpool(x)
            x = self.fc(x)
        return x

def loss(logits, labels):
  return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))

def make_scheduler(policy, init_lr, n_step_epoch, global_step):
    total_steps= n_step_epoch * 10 #10 epochs
    milestones = policy.split('_')
    milestones.pop(0)
    milestones = list(map(lambda x: int(x), milestones))
    boundaries = np.multiply(milestones,n_step_epoch)
    values = [init_lr] + [init_lr/(0.1**-i) for i in  range(1,len(milestones)+1)]
    learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)
    return learning_rate


def train(model, optimizer, step_counter ):
  """"""Trains model on `dataset` using `optimizer`.""""""

  for (batch, i) in enumerate(range(10)):
      print('Training Loop {}'.format(i))
      images = tf.random.uniform((4, 224, 224,3))
      labels = tf.constant(np.random.randint(4, size=4))
      with tf.contrib.summary.record_summaries_every_n_global_steps(10, global_step=step_counter):
          with tf.GradientTape() as tape:
            logits = model(images, training=True)
            loss_value = loss(logits, labels)
          grads = tape.gradient(loss_value, model.variables)
          optimizer.apply_gradients(zip(grads, model.variables), global_step=step_counter)


def test(model):
  """"""Perform an evaluation of `model` on the examples from `dataset`.""""""
  for  i in (range(10)):
    images = tf.random.uniform((4, 225, 225,3))
    logits = model(images, training=False)
    print(logits)

def main():
    model =  DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], arch='C',num_classes = 4)
    device = '/gpu:0'
    step_counter = tf.train.get_or_create_global_step()
    lr = make_scheduler(policy='multistep_2_5',init_lr=0.1,n_step_epoch = 10,global_step= step_counter)
    optimizer = tf.train.MomentumOptimizer(lr,momentum=0.5)

    with tf.device(device):
        for _ in range(10):
           train(model, optimizer,step_counter)
           print(optimizer._lr_t)
           test(model)

if __name__ == '__main__':
  main()

</code></pre>

<blockquote>
  <p>File """", line 1, in 
      runfile('/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py', wdir='/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug')</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 709, in runfile
      execfile(filename, namespace)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 108, in execfile
      exec(compile(f.read(), filename, 'exec'), namespace)</p>
  
  <p>File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 311, in 
      main()</p>
  
  <p>File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 305, in main
      train(model, optimizer,step_counter)</p>
  
  <p>File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 284, in train
      optimizer.apply_gradients(zip(grads, model.variables), global_step=step_counter)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py"", line 598, in apply_gradients
      self._prepare()</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/momentum.py"", line 87, in _prepare
      learning_rate = learning_rate()</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py"", line 171, in decayed_lr
      boundaries = ops.convert_n_to_tensor(boundaries)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1273, in convert_n_to_tensor
      as_ref=False)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in internal_convert_n_to_tensor
      raise TypeError(""values must be a list."")</p>
  
  <p>TypeError: values must be a list.</p>
</blockquote>

<p>The code works as expected when we provide a constant learning rate. Is there something that we are missing?</p>
",2019-06-15 01:51:22,5079359,11,https://stackoverflow.com/questions/56606757,Documentation Ambiguity
56621039,Understanding the graph of tf.cond,"<p>I am trying to understand the inner workings of tf.cond by looking at the graph of low-level ops that are used to build it.</p>

<p>This is the code in question</p>

<pre><code>x = tf.constant(1, name='x')
y = tf.constant(2, name='y')
z = tf.constant(3, name='z')

result = tf.cond(tf.less(x, y), lambda: tf.add(x, z), lambda: tf.square(y))
</code></pre>

<p>And the resulting <a href=""https://i.stack.imgur.com/cIJSx.jpg"" rel=""nofollow noreferrer"">graph</a>.</p>

<p>What I am wondering is the following.</p>

<ul>
<li>What is the separate switch op leading to switch_t and switch_f doing there?</li>
<li>Why does Less output connect to pred_id and Switch Ops? I would expect it to output one predicate (Boolean tensor) leading into all Switch-es for all the inputs into tf.cond.</li>
<li>What is pred_id? Is it just an identity that forks the predicate into three branches?</li>
<li><p>I am trying to understand how does tf.cond evaluate only one branch during runtime. </p>

<p>I understand that when we evaluate the result of tf.cond we are evaluating the tensor coming out of the merge op. Merge must take in (I assume) four tensors as input (two from Add branch and two from Square branch) and three of which much be dead. But we only can know the ""deadness"" of the tensors if we eval them back down the graph, no?</p></li>
<li><p>For the Square branch, for example, I understand that switch takes in as input the y tensor and the predicate and outputs two tensors, y and dead, on the appropriate branches of the switch statement. But this branch is kind of guaranteed already to be for the false branch. So what happens to both T and F outputs of the switch branch? They both go into Square Op? And then into the merge?</p></li>
</ul>

<p>Thank you,</p>

<p>S</p>
",2019-06-16 17:18:09,1620643,93,https://stackoverflow.com/questions/56621039,Documentation Replicability
56635027,Feeding array (shape with rank 1) to TensorFlow tf.case,"<p>Following this example from the <code>tf.case</code> documentation:</p>

<pre><code>def f1(): return tf.constant(17)
def f2(): return tf.constant(23)
def f3(): return tf.constant(-1)
r = tf.case({tf.less(x, y): f1, tf.greater(x, z): f2},
            default=f3, exclusive=True)
</code></pre>

<p>I want to do the same, but allow to use a feed_dict as input, illustrated by this snipped:</p>

<pre><code>x = tf.placeholder(tf.float32, shape=[None])
y = tf.placeholder(tf.float32, shape=[None])
z = tf.placeholder(tf.float32, shape=[None])
def f1(): return tf.constant(17)
def f2(): return tf.constant(23)
def f3(): return tf.constant(-1)
r = tf.case({tf.less(x, y): f1, tf.greater(x, z): f2},
            default=f3, exclusive=True)
print(sess.run(r, feed_dict={x: [0, 1, 2, 3], y: [1, 1, 1, 1], z: [2, 2, 2, 2]}))
# result should be [17, -1, -1, 23]
</code></pre>

<p>So, basically I want to feed three <code>int</code>-arrays of equal length and receive an array of <code>int</code>-values containing either 17, 23, or -1. Unfortunately, there code above gives and error:</p>

<blockquote>
  <p>ValueError: Shape must be rank 0 but is rank 1 for 'case/cond/Switch' (op: 'Switch') with input shapes: [?], [?].</p>
</blockquote>

<p>I understand, that <code>tf.case</code> requires boolean scalar tensor input values but is there any way to achieve what I want? I also tried <code>tf.cond</code> without success.</p>
",2019-06-17 16:02:23,11545782,78,https://stackoverflow.com/questions/56635027,Documentation Replicability
56693863,Why does model.losses return regularization losses?,"<p>I have met a snippet of code of tensorflow 2.0, which is used for calculating the loss. The total loss is composed of two parts: 1) regularization loss, 2) prediction loss. My question is why <code>model.losses</code> is regularization loss? <code>model</code> here is an instance of <code>tf.keras.Model</code>. I'm kind of confused by the tensorflow official API documentation. <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#losses"" rel=""noreferrer"">tf.keras.Model</a>, it says</p>
<blockquote>
<p>Losses which are associated with this Layer.</p>
<p>Variable regularization tensors are created when this property is accessed, so it is eager safe: accessing losses under a <code>tf.GradientTape</code> will propagate gradients back to the corresponding variables.</p>
</blockquote>
<p>Why could we get regularization loss via accessing <code>losses</code> property? Also, what is eager safe? If <code>losses</code> property is returning regularization loss, why is it named <code>losses</code> instead of <code>regularization_loss</code>?</p>
<pre class=""lang-py prettyprint-override""><code>with tf.GradientTape() as tape:
  outputs = model(images, training=True)
  regularization_loss = tf.reduce_sum(model.losses)
  pred_loss = ...
  total_loss = pred_loss + regularization_loss
</code></pre>
",2019-06-20 21:04:45,7212365,4337,https://stackoverflow.com/questions/56693863,Documentation Ambiguity
56754293,TensorflowServing on a trained native Keras model with a preprocessing function for the input,"<p>My final goal is to use the What-If-Tool on tensorboard. In order to do that, I need to serve my Keras model on TensorflowServing, and the data in a TFRecordFile. So the data has to be transformed into tf.Examples.
The tool is supposed to grab the network to run inference on the data.
however, the network cannot handle tf.Examples as an input. So the served model needs to have a preprocessing function.</p>

<p>According to the tensorflow documentation, one way is to create a tensorflow Estimator, and to use ""serving_input_receiver_fn"" to preprocess the data. 
This would have been perfect except for the case that I can't make an already trained native Keras model into an Estimator. It seems that the only way it to create it from a tf.keras model (and not a native keras model like I have), and to train it directly with the estimator.</p>

<p>Another way would be to use the tf.saved_model.simple_save function, and then use TensorflowServing, but I did not find a way to preprocess the tf.Examples to make a correct input for the network.</p>

<p>Since this is not working, I have no clue on how to resolve this.</p>

<p><strong>Edit:</strong> I tried to transform my native keras into a tf.keras model. My model is really big, so I build this function: </p>

<pre><code>def create_tf_keras_model_from_native_keras(native_model):
    list_layers = []
    for i, layer in enumerate(native_model.layers):
        type_layer = str(layer).split('.')[2]
        second_type_layer = str(layer).split('.')[3].split(' ')[0]
        if type_layer == 'input_layer':
            new_layer = tf.keras.layers.InputLayer(**layer.get_config())
        elif type_layer == 'convolutional':
            new_layer = tf.keras.layers.Conv2D(**layer.get_config())
        elif type_layer == 'normalization':
            new_layer = tf.keras.layers.BatchNormalization(**layer.get_config())
        elif type_layer == 'core':
            if second_type_layer == 'Activation':
                new_layer = tf.keras.layers.Activation(**layer.get_config())
            elif second_type_layer == 'Dense':
                new_layer = tf.keras.layers.Dense(**layer.get_config())
            elif second_type_layer == 'Dropout':
                new_layer = tf.keras.layers.Dropout(**layer.get_config())
            elif second_type_layer == 'Lambda':
                config_lambda = layer.get_config()
                print(config_lambda)
                del config_lambda['function_type']
                del config_lambda['output_shape_type']
                new_layer = tf.keras.layers.Lambda(**config_lambda)
        elif type_layer == 'pooling':
            if second_type_layer == 'MaxPooling2D':
                new_layer = tf.keras.layers.MaxPooling2D(**layer.get_config())
            elif second_type_layer == 'AveragePooling2D':
                new_layer = tf.keras.layers.AveragePooling2D(**layer.get_config())
            elif second_type_layer == 'GlobalMaxPooling2D':
                new_layer = tf.keras.layers.GlobalMaxPooling2D(**layer.get_config())
        if new_layer == 'merge':
            new_layer = tf.keras.layers.Concatenate(**layer.get_config())
        list_layers.append(new_layer)
    model = tf.keras.Sequential(list_layers)
    return model
</code></pre>

<p>However, this is not working because of Lambda layer. In the config layer, the function is now written in the form of: </p>

<pre><code>'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQC8ARQAFwBTACkDTukAAAAA6QEA\nAACpACkC2gZpbaBXNjYWxlcgMAAAByAwAAAPp/L2dwZnMvaGFpZmEtcDYvMDMvbXNpZXZl\nX2RldjMvdXNyL3BhdWxkYS9naXRfcmVwb0hJLUltYWdlQW5hbHl0aWNzL3Jlc291cmNlcy9y\ndW5fMTE3NC9jdXN0b21fcHJldHJhaW5lZF9JbmNlcHRpb25SZXNOZXRWMi5wedoIPGxhbWJkYT6d\nAAAA8wAAAAA=\n', None, None)
</code></pre>

<p>Hence, I gave up this method hoping something else would allow to pre-process the input of my serving model.</p>
",2019-06-25 12:39:06,10545585,11,https://stackoverflow.com/questions/56754293,Documentation Replication on Other Examples
56804123,Tensorflow-Lite : Exporting a GraphDef from tf.Session convert failed,"<p>I want to convert my tensorflow Spectrogram session to <code>.tflite</code> file for using in Android.
I try to follow the TFLite <a href=""https://www.tensorflow.org/lite/convert/python_api#exporting_a_graphdef_from_tfsession_"" rel=""nofollow noreferrer"">official example</a> but it is failed during the convert procedure.
Please give me some advice for fixing this error. Thanks a lots!</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tensorflow.signal import stft

# Waveform placeholder
waveform = tf.placeholder(name=""waveform"", dtype=tf.float32, shape=(4000))

# Compute the spectrogram and get the asolute values
stfts = stft(waveform, frame_length=256, frame_step=64, fft_length=256)
spectrograms = tf.abs(stfts)   

def TF_spectrogram(audio):
    # Run the spectrogram session
    with tf.Session() as sess:
        # Run the computation graph and save the png encoded image to a file
        spectrogram = sess.run(spectrograms, feed_dict={waveform: audio}) 
        print(""The Spectrogram size (shape) is : "" + str(spectrogram.shape) + "", type : "" + str(type(spectrogram)))  
        return spectrogram

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    converter = tf.lite.TFLiteConverter.from_session(sess, [waveform], [spectrograms])
    tflite_model = converter.convert()
    open(""spectrogram.tflite"", ""wb"").write(tflite_model)

</code></pre>

<p>I got the error message from Jupyter Notebook</p>

<pre><code>---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
&lt;ipython-input-22-a94c03f6a5ae&gt; in &lt;module&gt;
      2     sess.run(tf.global_variables_initializer())
      3     converter = tf.lite.TFLiteConverter.from_session(sess, [waveform], [spectrograms])
----&gt; 4     tflite_model = converter.convert()
      5     open(""converted_model.tflite"", ""wb"").write(tflite_model)

F:\Anaconda3\envs\tf_py36\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    896           input_tensors=self._input_tensors,
    897           output_tensors=self._output_tensors,
--&gt; 898           **converter_kwargs)
    899     else:
    900       result = _toco_convert_graph_def(

F:\Anaconda3\envs\tf_py36\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, *args, **kwargs)
    402   data = toco_convert_protos(model_flags.SerializeToString(),
    403                              toco_flags.SerializeToString(),
--&gt; 404                              input_data.SerializeToString())
    405   return data
    406 

F:\Anaconda3\envs\tf_py36\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str)
    170       stderr = _try_convert_to_unicode(stderr)
    171       raise ConverterError(
--&gt; 172           ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
    173   finally:
    174     # Must manually cleanup files.

ConverterError: TOCO failed. See console for info.
2019-06-28 17:04:12.512364: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: RFFT
2019-06-28 17:04:12.512817: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""NoOp"" device_type: ""CPU""') for unknown op: NoOp
2019-06-28 17:04:12.513084: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""NoOp"" device_type: ""GPU""') for unknown op: NoOp
2019-06-28 17:04:12.513269: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_HostRecv"" device_type: ""GPU"" host_memory_arg: ""tensor""') for unknown op: _HostRecv
2019-06-28 17:04:12.513564: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_Send"" device_type: ""CPU""') for unknown op: _Send
2019-06-28 17:04:12.513819: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_HostRecv"" device_type: ""CPU""') for unknown op: _HostRecv
2019-06-28 17:04:12.514068: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_Send"" device_type: ""GPU""') for unknown op: _Send
2019-06-28 17:04:12.514254: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_Recv"" device_type: ""CPU""') for unknown op: _Recv
2019-06-28 17:04:12.514431: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_HostSend"" device_type: ""GPU"" host_memory_arg: ""tensor""') for unknown op: _HostSend
2019-06-28 17:04:12.514637: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_Recv"" device_type: ""GPU""') for unknown op: _Recv
2019-06-28 17:04:12.514803: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""_HostSend"" device_type: ""CPU""') for unknown op: _HostSend
2019-06-28 17:04:12.515019: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-06-28 17:04:12.515234: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-28 17:04:12.515498: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-28 17:04:12.515718: E tensorflow/core/framework/op_kernel.cc:1426] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-06-28 17:04:12.516175: I tensorflow/lite/toco/import_tensorflow.cc:1385] Unable to determine output type for op: RFFT
2019-06-28 17:04:12.516336: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ComplexAbs
2019-06-28 17:04:12.516712: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 7 operators, 17 arrays (0 quantized)
2019-06-28 17:04:12.517018: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 7 operators, 17 arrays (0 quantized)
2019-06-28 17:04:12.517417: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 7 operators, 16 arrays (0 quantized)
2019-06-28 17:04:12.517682: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:118] Check failed: dim_x == dim_y (64 vs. 256)Dimensions must match
Fatal Python error: Aborted

Current thread 0x000033dc (most recent call first):
  File ""f:\anaconda3\envs\tf_py36\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 33 in execute
  File ""f:\anaconda3\envs\tf_py36\lib\site-packages\absl\app.py"", line 251 in _run_main
  File ""f:\anaconda3\envs\tf_py36\lib\site-packages\absl\app.py"", line 300 in run
  File ""f:\anaconda3\envs\tf_py36\lib\site-packages\tensorflow\python\platform\app.py"", line 40 in run
  File ""f:\anaconda3\envs\tf_py36\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 59 in main
  File ""F:\Anaconda3\envs\tf_py36\Scripts\toco_from_protos.exe\__main__.py"", line 9 in &lt;module&gt;
  File ""f:\anaconda3\envs\tf_py36\lib\runpy.py"", line 85 in _run_code
  File ""f:\anaconda3\envs\tf_py36\lib\runpy.py"", line 193 in _run_module_as_main
</code></pre>

<p>I want to make customize Spectrogram library by <a href=""https://www.tensorflow.org/api_docs/python/tf/signal/stft"" rel=""nofollow noreferrer""><code>tf.signal.stft</code></a> function, and save to <code>.tflite</code> file for using in Android device.
I can't find anymore tutorial about TFLite converter, only the official document.😭 Please help me to fix this error, thanks a lots !! 🙏</p>
",2019-06-28 09:14:28,7651473,21,https://stackoverflow.com/questions/56804123,Documentation Replication on Other Examples
56905939,Effective way to read images from a csv file and return a tf.data.Dataset object,"<p>I have a csv file that contains two columns:</p>

<ol>
<li>the file path of the image which is stored as <code>numpy</code> arrays</li>
<li>the label of the image</li>
</ol>

<p>Each row in the csv corresponds to one item (sample).</p>

<p>I want to create a <code>tf.data</code> pipeline that reads the file path and loads the numpy array and the label associated with it. How would I go about doing so so that I can return a <code>tf.data.Dataset</code> object?</p>

<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data"" rel=""nofollow noreferrer"">documentation</a> on the website is not very informative and I cannot figure out where to start from.</p>
",2019-07-05 15:37:36,5052482,2094,https://stackoverflow.com/questions/56905939,Lack of Alternative Solutions/Documentation
56930821,Why does embedding vector multiplied by a constant in Transformer model?,"<p>I am learning to apply <strong>Transform model</strong> proposed by <a href=""https://arxiv.org/abs/1706.03762"" rel=""noreferrer"">Attention Is All You Need</a> from tensorflow  official document <a href=""https://www.tensorflow.org/beta/tutorials/text/transformer"" rel=""noreferrer"">Transformer model for language understanding</a>.</p>

<p>As section <a href=""https://www.tensorflow.org/beta/tutorials/text/transformer#positional_encoding"" rel=""noreferrer"">Positional encoding</a> says:</p>

<blockquote>
  <p>Since this model doesn't contain any recurrence or convolution,
  positional encoding is added to give the model some information about
  the relative position of the words in the sentence.</p>
  
  <p><strong>The positional encoding vector is added to the embedding vector</strong>.</p>
</blockquote>

<p>My understanding is to add <code>positional encoding vector</code> directly to <code>embedding vector</code>. But I found <code>embedding vector</code> multiplied by a constant when I looked at the code.</p>

<p>The code in section <a href=""https://www.tensorflow.org/beta/tutorials/text/transformer#encoder"" rel=""noreferrer"">Encoder</a> as follows:</p>

<pre><code>class Encoder(tf.keras.layers.Layer):
  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, 
               rate=0.1):
    super(Encoder, self).__init__()

    self.d_model = d_model
    self.num_layers = num_layers

    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)
    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)


    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) 
                       for _ in range(num_layers)]

    self.dropout = tf.keras.layers.Dropout(rate)

  def call(self, x, training, mask):

    seq_len = tf.shape(x)[1]

    # adding embedding and position encoding.
    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)
    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
    x += self.pos_encoding[:, :seq_len, :]

    x = self.dropout(x, training=training)

    for i in range(self.num_layers):
      x = self.enc_layers[i](x, training, mask)

    return x  # (batch_size, input_seq_len, d_model)
</code></pre>

<p>We can see <code>x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))</code> before <code>x += self.pos_encoding[:, :seq_len, :]</code>.</p>

<p>So why does embedding vector multiplied by a constant before adding positional encoding in Transformer model?</p>
",2019-07-08 08:12:18,7389608,6118,https://stackoverflow.com/questions/56930821,Documentation Replication on Other Examples
56939282,How do you feed a tf.data.Dataset dynamically in eager execution mode where initializable_iterator isn't available?,"<p>What is the new approach (under eager execution) to feeding data through a dataset pipeline in a dynamic fashion, when we need to feed it sample by sample? </p>

<p>I have a <code>tf.data.Dataset</code> which performs some preprocessing steps and reads data from a generator, drawing from a large dataset during training. </p>

<p>Let's say that dataset is represented as:</p>

<pre><code>ds = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])
ds = ds.map(tf.square).shuffle(2).batch(2)
iterator = tf.data.make_one_shot_iterator(ds)
</code></pre>

<p>After training I want to produce various visualizations which require that I feed one sample at a time through the network for inference. I've now got this dataset preprocessing pipeline that I need to feed my raw sample through to be sized and shaped appropriately for the network input.</p>

<p>This seems like a use case for the initializable iterator:</p>

<pre><code>placeholder = tf.placeholder(tf.float32, shape=None)
ds = tf.data.Dataset.from_tensor_slices(placeholder)
ds = ds.map(tf.square).shuffle(2).batch(2)
iterator = tf.data.make_initializable_iterator(ds) 
# now re-initialize for each sample
</code></pre>

<blockquote>
  <p>Keep in mind that the map operation in this example represents a long sequence of preprocessing operations that can't be duplicated for each new data sample being feed in.</p>
</blockquote>

<p><strong>This doesn't work with eager execution</strong>, you can't use the placeholder. The documentation examples all seem to assume a static input such as in the first example here.</p>

<p>The only way I can think of doing this is with a queue and <code>tf.data.Dataset.from_generator(...)</code> which reads from the queue that I push to before predicting on the data. But this feels both hacky, and appears prone to deadlocks that I've yet to solve.</p>

<p>TF 1.14.0</p>
",2019-07-08 16:41:34,4790871,31007,https://stackoverflow.com/questions/56939282,Documentation Replication on Other Examples
56970612,Fitted values and weights in tensorflow (tesorflow DNNRegressor),"<p>I am using tensorflow version 2.0.0-beta1. I have created the input function to feed into tf.estimator.DNNRegressor.</p>

<pre><code>input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,
                                                y=y_train,
                                                batch_size=10,
                                                num_epochs=1000,
                                                shuffle=True)
</code></pre>

<p>Below is the model that I am creating using DNNRegressor. </p>

<pre><code>model = tf.estimator.DNNRegressor(feature_columns=feature_col, hidden_units=[1024, 800, 512, 256])
model.train(input_fn=input_func, steps=10000)
</code></pre>

<p>Now I want to identify </p>

<p><strong>1) Fitted values of my model on training data.</strong></p>

<p><strong>2) Weights associated with each variable in model(i.e. tf.estimator.DNNRegressor)</strong></p>

<p>I have search through the documentation of tensorflow and other sources but didn't get this information. </p>
",2019-07-10 12:23:01,6244166,888,https://stackoverflow.com/questions/56970612,Lack of Alternative Solutions/Documentation
56972492,Profile summary by operation type,"<p>I'm profiling my model in Tensorflow 2.0.  I'm able to get a profile &amp; view with Tensorboard by following the instructions for a function.  I use tf.summary.trace_on &amp; tf.summary.trace_export: 
<a href=""https://www.tensorflow.org/tensorboard/r2/graphs"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tensorboard/r2/graphs</a></p>

<p>Now I'd like to create a summary by operation type, similar to the node type summary in the tflite profiler (<a href=""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark</a>).</p>

<p>TensorFlow 1.14 tf.profile.Profiler looks to be able to do it with the 'cmd' option:
<a href=""https://www.tensorflow.org/api_docs/python/tf/profiler/profile"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/profiler/profile</a></p>

<p>How do I do this with TensorFlow 2.0?</p>
",2019-07-10 14:05:58,10052081,76,https://stackoverflow.com/questions/56972492,Documentation Replication on Other Examples
57056756,Prepare a tensorflow dataset with *.jpeg in a directory with corresponding labels in a .csv file,"<p>Indeed this question is similar to prior but for me attempting prior answers tossed a errors I cannot scale probably due to deprecated functions  and thus update is requested (pleading on my knees really)-- maybe windows 10 is the problem</p>

<p>In the Google tensorflow documentation they trumpet the ease of tensorflow and they of course make it seem easy by having a dataset prepped and ready 
to go such as <code>mnist = tf.keras.datasets.mnist</code></p>

<p>But for people doing real work with new data they are not going to have data so neatly prepared. Instead they (i.e. me) are going to take many pictures of different similar things (say 64 nuclei of cancer cells from 64 patient cases-- 250 by 250 pixels each with RGB) and they will  store the 64 jpegs in a single directory lets say <code>C:\\Users\\dalton\\Desktop\\breast\\nuclei\\*.jpg</code>
There are no other jpgs in the directory other than those of interest</p>

<p>Then in a csv text file (essentially a spreadsheet with one column saved as csv file or could be txt) they record the label corresponding to each picture -- this text file has 64 entries of a 1 or 0 whereby 1= very bad cancer cell and 0= not so bad. Lets say this txt file is located at:
 <code>C:\\Users\\dalton\\Desktop\\breast\\nuclei\\n_labels.txt</code></p>

<p>They (me) will use 32 of the pictures and corresponding labels for train and 32 for test.</p>

<p>So from this basic data of 64 jpegs and 64 labels (as 64 entries in a single text file)how does one get to the same point as given in the loading of an easy example. Or does one need a single <code>spreadsheet</code> with the jpeg filenames in one column and the labels in another so as to prepare a list or tuple?</p>

<p>In essence how does</p>

<p>Real world work join final common pathway same as
 <code>mnist = tf.keras.datasets.mnist</code></p>

<p>I think an answer to this will help many many people besides me. I have tried innumerable examples in <code>GitHub</code>, here, and tried R versions and total frustration.</p>

<p>Sincere thanks to an answer.
LD</p>

<p>attempted solutions used examples as per:</p>

<p><a href=""https://www.tensorflow.org/datasets/datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/datasets/datasets</a></p>

<p><a href=""https://gist.github.com/eerwitt/518b0c9564e500b4b50f"" rel=""nofollow noreferrer"">https://gist.github.com/eerwitt/518b0c9564e500b4b50f</a></p>
",2019-07-16 11:58:58,11791681,1,https://stackoverflow.com/questions/57056756,Documentation Replication on Other Examples
57081006,Create a Keras Layer Subclass using Conv Layers,"<p>I would like to create a custom <code>tf.keras.layers.Layer</code> resembling the below function:</p>

<pre><code>def conv_block(inputs, filters, kernel_size, strides=(1, 1, 1),
                 padding='valid', activation=True, block_name='conv3d'):

    with tf.name_scope(block_name):
      conv = Conv3D(filters=filters, kernel_size=kernel_size, strides=strides,
                    padding=padding, activation=None,
                    name='{}_conv'.format(block_name))(inputs)
      batch_norm = BatchNormalization(
          name='{}_batch_norm'.format(block_name))(conv)

      if activation:
        relu = ReLU(max_value=6, name='{}_relu'.format(block_name))(batch_norm)
        res_layer = relu
      else:
        res_layer = batch_norm
    return res_layer
</code></pre>

<p>I went through the documentation available <a href=""https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models#the_layer_class"" rel=""nofollow noreferrer"">here</a> and <a href=""https://www.tensorflow.org/guide/keras#custom_layers"" rel=""nofollow noreferrer"">here</a> and subsequently I created the below class:</p>

<pre><code>class ConvBlock(tf.keras.layers.Layer):

    def __init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', activation=True, **kwargs):
        super(ConvBlock, self).__init__()
        self.filters = filters
        self.kernel_size = kernel_size
        self.strides = strides
        self.padding = padding
        self.activation = activation

        self.conv_1 = Conv3D(filters=self.filters, 
                             kernel_size=self.kernel_size, 
                             strides=self.strides, 
                             padding=self.padding, 
                             activation=None)

        self.batch_norm_1 = BatchNormalization()
        self.relu_1 = ReLU(max_value=6)

    def call(self, inputs):
        conv = self.conv_1(inputs)
        batch_norm = self.batch_norm_1(conv)

        if self.activation:
            relu = self.relu_1(batch_norm)
            return relu
        else:
            return batch_norm
</code></pre>

<p>I want to use this <code>Layer</code> several times throughout my model. I have several questions around this:</p>

<ol>
<li>The documentation mentions using <code>add_weights()</code> in the <code>build()</code> method. However would it be necessary in this case?</li>
<li>Do I need to include a <code>build()</code>method at all? </li>
<li><p>How do I get the output shape of the layer? The documentation mentions using the below function:</p>

<p>def compute_output_shape(self, input_shape):
    shape = tf.TensorShape(input_shape).as_list()
    shape[-1] = self.output_dim
    return tf.TensorShape(shape)</p></li>
</ol>

<p>How can I use this function to compute the shape of the output layer?</p>
",2019-07-17 17:06:55,5052482,2094,https://stackoverflow.com/questions/57081006,Documentation Replicability
57083881,Tensorflow 2.0 Saving trained parameters to be restored in a new file,"<p>I need to save trained variables of a TensorFlow 2.0 model using one of TF's built in functions like tf.train.Checkpoint or any other, and want to call them in a new file. I am not using tf.Keras.Sequantial and don't want to use something like model.save_weights()</p>

<p>I have tried tf.train.Checkpoint to save variables, but not sure how to restore them. I used to work with tf.train.Saver() in TF 1.0 to save variables using sessions and restore them using tf.train.import_meta_graph and tf.train.latest_checkpoint. However, I haven't been able to find equivalent functionalities in TF 2.0 documentation so far. </p>

<h1>try checkpoint saver in tensorflow 2.0 format to save trained parameters W, b_v, b_h</h1>

<p>saver = tf.train.Checkpoint()</p>

<p>saver.listed = [W, b_v, b_h]</p>

<p>saver.mapped = {'W':saver.listed[0],'b_v':saver.listed[1],
 'b_h':saver.listed[2]}</p>

<p>save_path = saver.save('trained_parameters')</p>

<h1>in a new file:</h1>

<p>restorer = tf.train.Checkpoint()</p>

<p>restorer.restore('trained_parameters')</p>

<h1>calling the parameters by their previously mapped names doesn't work, not sure how to go about this</h1>
",2019-07-17 20:49:11,11799681,11,https://stackoverflow.com/questions/57083881,Documentation Replication on Other Examples
57120680,Deep copy of tensor in tensorflow python,"<p>In some of my code, I have created a neural network using tensorflow and have access to a tensor representing that network's output. I want to make a copy of this tensor so that even if I train the neural network more, I can access the original value of the tensor.</p>

<p>Following other answers and tensorflow documentation, I have tried the tf.identity() function, but it does not seem to be doing what I need. Some other links suggested the use of tf.tile(), but this did not help either. I do not wish to use sess.run(), evaluate the tensor, and store it elsewhere.</p>

<p>Here is a toy example that describes what I need to do:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

t1 = tf.placeholder(tf.float32, [None, 1])
t2 = tf.layers.dense(t1, 1, activation=tf.nn.relu)
expected_out = tf.placeholder(tf.float32, [None, 1])

loss = tf.reduce_mean(tf.square(expected_out - t2))
train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)

sess = tf.Session()

sess.run(tf.global_variables_initializer())

print(sess.run(t2, feed_dict={t1: np.array([1]).reshape(-1,1)}))
t3 = tf.identity(t2) # Need to make copy here
print(sess.run(t3, feed_dict={t1: np.array([1]).reshape(-1,1)}))

print(""\nTraining \n"")

for i in range(1000):
    sess.run(train_op, feed_dict={t1: np.array([1]).reshape(-1,1), expected_out: np.array([1]).reshape(-1,1)})

print(sess.run(t2, feed_dict={t1: np.array([1]).reshape(-1,1)}))
print(sess.run(t3, feed_dict={t1: np.array([1]).reshape(-1,1)}))
</code></pre>

<p>The result of the above code is that <code>t2</code> and <code>t3</code> have the same value. </p>

<pre><code>[[1.5078927]]
[[1.5078927]]

Training

[[1.3262703]]
[[1.3262703]]
</code></pre>

<p>What I want is for <code>t3</code> to keep its value from being copied.</p>

<pre><code>[[1.5078927]]
[[1.5078927]]

Training

[[1.3262703]]
[[1.5078927]]
</code></pre>

<p>Thanks in advance for your help.</p>
",2019-07-19 23:48:55,8083568,83,https://stackoverflow.com/questions/57120680,Documentation Ambiguity
57134808,tf.keras.optimizers.Adam with tf.estimator model in Tensorflow 2.0.beta is crashing,"<p>I am using <code>Tensorflow 2.0.beta</code> with <code>Python 3.6.6</code> on <code>Mac OS</code> (nightly: <code>tf-nightly-2.0-preview</code> <code>2.0.0.dev20190721</code> but I never managed to have it working with compat module in <code>Tensorflow 2.0</code>).</p>

<p>I am traying to migrate a <code>tf.estimator</code> model from <code>Tensorflow 1.12</code> (fully working) to <code>Tensorflow 2.0</code>. Here is the code:</p>

<pre><code># estimator model
def baseline_estimator_model(features, labels, mode, params):
    """"""
    Model function for Estimator
    """"""
    print('model based on keras layer but return an estimator model')

    # gettings the bulding blocks
    model = keras_building_blocks(params['dim_input'], params['num_classes'])

    dense_inpout = features['dense_input']

    # Logits layer
    if mode == tf.estimator.ModeKeys.TRAIN:
        logits = model(dense_inpout, training=True)
    else:
        logits = model(dense_inpout, training=False)


    # Compute predictions
    probabilities = tf.nn.softmax(logits)
    classes = tf.argmax(input=probabilities, axis=1, )

    # made prediction
    predictions = {
        'classes': classes,
        'probabilities': probabilities,
    }

    # to be tested
    predictions_output = tf.estimator.export.PredictOutput(predictions)

    # Provide an estimator spec for `ModeKeys.PREDICT`
    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode,
                                          predictions=predictions,
                                          export_outputs={tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: predictions_output})

    # Compute loss for both TRAIN and EVAL modes
    # old -&gt; loss = tf.compat.v1.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)
    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, logits)

    # Generate necessary evaluation metrics
    # old -&gt; accuracy = tf.compat.v1.metrics.accuracy(labels=tf.argmax(input=labels, axis=1), predictions=classes, name='accuracy')
    accuracy = tf.keras.metrics.CategoricalAccuracy()
    accuracy.update_state(labels, logits)

    eval_metrics = {'accuracy': accuracy}

    tf.summary.scalar('accuracy', accuracy.result())

    # Provide an estimator spec for `ModeKeys.EVAL`
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          eval_metric_ops=eval_metrics)

    # Provide an estimator spec for `ModeKeys.TRAIN`
    if mode == tf.estimator.ModeKeys.TRAIN:

        # old but working -&gt; optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta1=0.9)
        # crashing
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, epsilon=1e-07)

        # old -&gt; train_op = optimizer.minimize(loss, tf.compat.v1.train.get_or_create_global_step())
        train_op = optimizer.minimize(loss,var_list=model.weights)

        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          train_op=train_op)
</code></pre>

<p>predictions=predictions, loss=loss, train_op=train_op, export_outputs=predictions_output)</p>

<p>If I keep the compat.v1 module it is working:</p>

<pre><code>optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta1=0.9)
</code></pre>

<p>If I try to use something without compat.v1 it is crashing:</p>

<pre><code>optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9,epsilon=1e-07)
</code></pre>

<p>with the following error (I am running the code locally for the moment, not on <code>GCP</code>):</p>

<pre><code>I0721 17:33:04.812453 4526515648 estimator.py:209] Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/v3/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x1c37b11b70&gt;, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0721 17:33:04.815697 4526515648 estimator_training.py:186] Not using Distribute Coordinator.
I0721 17:33:04.817899 4526515648 training.py:612] Running training and evaluation locally (non-distributed).
I0721 17:33:04.818665 4526515648 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10 or save_checkpoints_secs None.
I0721 17:33:04.834385 4526515648 model.py:211] input_dataset_fn: TRAIN, train

using keras layer and estimator (recommended way)
exporter &lt;tensorflow_estimator.python.estimator.exporter.LatestExporter object at 0x1c37b115f8&gt;

I0721 17:33:05.117963 4526515648 estimator.py:1145] Calling model_fn.

model based on keras layer but return an estimator model

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;timed exec&gt; in &lt;module&gt;

~/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/src/model_mnist_2_0_v1/trainer/model.py in train_and_evaluate(FLAGS, use_keras)
    589                                       exporters=exporter)
    590 
--&gt; 591     tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
    592 
    593 def train_and_evaluate_old(FLAGS, use_keras):

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    471         '(with task id 0).  Given task id {}'.format(config.task_id))
    472 
--&gt; 473   return executor.run()
    474 
    475 

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in run(self)
    611         config.task_type != run_config_lib.TaskType.EVALUATOR):
    612       logging.info('Running training and evaluation locally (non-distributed).')
--&gt; 613       return self.run_local()
    614 
    615     # Distributed case.

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in run_local(self)
    712         max_steps=self._train_spec.max_steps,
    713         hooks=train_hooks,
--&gt; 714         saving_listeners=saving_listeners)
    715 
    716     eval_result = listener_for_eval.eval_result or _EvalResult(

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    365 
    366       saving_listeners = _check_listeners_type(saving_listeners)
--&gt; 367       loss = self._train_model(input_fn, hooks, saving_listeners)
    368       logging.info('Loss for final step: %s.', loss)
    369       return self

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1156       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1157     else:
-&gt; 1158       return self._train_model_default(input_fn, hooks, saving_listeners)
   1159 
   1160   def _train_model_default(self, input_fn, hooks, saving_listeners):

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
   1186       worker_hooks.extend(input_hooks)
   1187       estimator_spec = self._call_model_fn(
-&gt; 1188           features, labels, ModeKeys.TRAIN, self.config)
   1189       global_step_tensor = training_util.get_global_step(g)
   1190       return self._train_with_estimator_spec(estimator_spec, worker_hooks,

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
   1144 
   1145     logging.info('Calling model_fn.')
-&gt; 1146     model_fn_results = self._model_fn(features=features, **kwargs)
   1147     logging.info('Done calling model_fn.')
   1148 

~/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/src/model_mnist_2_0_v1/trainer/model.py in baseline_estimator_model(features, labels, mode, params)
    442         #train_op = optimizer.minimize(loss, tf.compat.v1.train.get_or_create_global_step())
    443         #train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())
--&gt; 444         train_op = optimizer.minimize(loss,var_list=model.weights)
    445 
    446         print('step 8')

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in minimize(self, loss, var_list, grad_loss, name)
    315     """"""
    316     grads_and_vars = self._compute_gradients(
--&gt; 317         loss, var_list=var_list, grad_loss=grad_loss)
    318 
    319     return self.apply_gradients(grads_and_vars, name=name)

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in _compute_gradients(self, loss, var_list, grad_loss)
    349       if not callable(var_list):
    350         tape.watch(var_list)
--&gt; 351       loss_value = loss()
    352     if callable(var_list):
    353       var_list = var_list()

TypeError: 'Tensor' object is not callable
</code></pre>

<p>Any idea how to fix that ? The error messages was changing over time since <code>Tensorflow 2.0 alpha</code>.</p>

<p>I am also looking for a full working example of tf.estimator working with <code>Tensorflow 2.0</code>. I have issue to export the model as well. In the official documentation of <code>Tensorflow 2.0</code> they only use in their example <code>compat.v1</code> and don't export the model. All the online course on tf.estimator from GCP are using  older version of Tensorflow (1.12 - 1.14).</p>
",2019-07-21 15:58:48,6430839,1576,https://stackoverflow.com/questions/57134808,Inadequate Examples
57140835,How to convert a tf.estimator to a keras model?,"<p>In package <code>tf.estimator</code>, there's a lot of defined estimators. I want to use them in Keras.</p>
<p>I checked TF docs, there's only one converting method that could convert <code>keras. Model</code> to <code>tf. estimator</code>, but no way to convert from <code>estimator</code> to <code>Model</code>.</p>
<p>For example, if we want to convert the following estimator:</p>
<pre><code>tf.estimator.DNNLinearCombinedRegressor
</code></pre>
<p>How could it be converted into Keras Model?</p>
",2019-07-22 07:15:28,5777564,179,https://stackoverflow.com/questions/57140835,Documentation Replicability
57155780,tf.function uses all CPU RAM,"<p>I cannot understand why the function I have posted below uses up all of my RAM. I could understand if I were running it eagerly, but I thought the point of a tf.function was to create a graph that is reused, much like creating an operation and running it in tf 1.x. I am new to tensorflow 2.0 so I might have the wrong idea about what tf.function is doing.</p>

<pre><code>@tf.function
def clip_w(self, weight):
    return tf.clip_by_value(weight, -0.01, 0.01)
</code></pre>

<p>Could anyone help me understand this? Thanks</p>

<p>EDIT: Here is the code where I use this function</p>

<pre><code>def clip_weights(self):
        for l in self.C.layers:
            weights = l.get_weights()
            weights = [self.clip_w(w) for w in weights]
            l.set_weights(weights)
</code></pre>
",2019-07-23 02:08:22,8286551,1,https://stackoverflow.com/questions/57155780,Documentation Replication on Other Examples
57170737,Cannot run tflite model on GPU (Jetson Nano) using Python,"<p>I have a quantized tflite model that I'd like to benchmark for inference on a Nvidia Jetson Nano. I use tf.lite.Interpreter() method for inference. The process doesn't seem to run on the GPU as the inference times on both CPU and GPU are the same.</p>
<p>Is there any way to run a tflite model on GPU using Python?</p>
<p>I tried to force GPU usage by setting tf.device() method but still doesn't work. The official documentation has something called delegates for GPU acceleration but I can't seem to find anything for Python.</p>
<pre><code>with tf.device('/device:GPU:0'):

    interpreter = tf.lite.Interpreter(model_path=&quot;model.tflite&quot;)

    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    input_shape = input_details[0]['shape']
    input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)
    interpreter.set_tensor(input_details[0]['index'], input_data)

    start_time = time.time()

    interpreter.invoke()

    elapsed_time = time.time() - start_time
    print(elapsed_time)

    output_data = interpreter.get_tensor(output_details[0]['index'])
</code></pre>
",2019-07-23 19:09:26,8380398,390,https://stackoverflow.com/questions/57170737,Documentation Replication on Other Examples
57175343,Multiple inputs of keras model with tf.data.Dataset.from_generator in Tensorflow 2,"<p>I am trying to implement a model in keras that will have multiple inputs:</p>

<ul>
<li>image (200x200)</li>
<li>some numbers (1x50)</li>
<li>three 1d signals (1x50000, 2x100000)</li>
</ul>

<p>To feed that model, I want to write a generator to use with <code>tf.data.Dataset.from_generator</code>. From the <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#from_generator"" rel=""noreferrer"">docs of from_generator</a>, its not clear to me how I should provide its parameters <code>output_types</code>, <code>output_shapes</code>. Can anyone help me with this?</p>
",2019-07-24 04:37:03,1113765,574,https://stackoverflow.com/questions/57175343,Inadequate Examples
57277926,Can Keras' model.predict return a dictionary?,"<p>The documentation <a href=""https://keras.io/models/model/#predict"" rel=""noreferrer"">https://keras.io/models/model/#predict</a> says that  <code>model.predict</code> returns Numpy array(s) of predictions.  <strong>In the Keras API, is there is a way to distinguishing which of these arrays are which?</strong>  How about in the TF implementation?</p>

<p>At the top of the same page of documentation, they say that ""models can specify multiple inputs and outputs using lists"".  It seems that nothing breaks if instead, one passes dictionaries:  </p>

<pre><code>my_model = tf.keras.models.Model(inputs=my_inputs_dict, outputs=my_outputs_dict)
</code></pre>

<p>When calling <code>model.fit</code> the same documentation says ""If input layers in the model are named, you can also pass a dictionary mapping input names to Numpy arrays.""</p>

<p>It would be nice if either the keys from <code>my_output_dict</code> or the names of the dictionary values (layers) in <code>my_output_dict</code> were attached to the outputs of <code>my_model.predict(...)</code> </p>

<p>If I save the model to TensorFlow's saved_model format protobuf using 
 <code>tf.keras.model.save</code> the tf.serving API works this way-- with named inputs and outputs... </p>
",2019-07-30 18:24:59,8456120,1334,https://stackoverflow.com/questions/57277926,Lack of Alternative Solutions/Documentation
57392510,TensorFlow simple example help - custom gradient,"<p>How do you pass a custom gradient into a gradient optimization function in TensorFlow.</p>

<p>I have illustrated what I am trying to do, with a simple example (trying to minimize z = 2x^2 + y^2 + 2).</p>

<p>I have been looking at:
<a href=""https://www.tensorflow.org/api_docs/python/tf/train/Optimizer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/Optimizer</a></p>

<p>The problem seems to work if you pass in <code>optimizer = tf.train.GradientDescentOptimizer(0.55)</code> and <code>train = optimizer.minimize(z)</code></p>

<p>This code works:</p>

<pre><code>import tensorflow as tf

x = tf.Variable(11, name='x', dtype=tf.float32)
y = tf.Variable(11, name='x', dtype=tf.float32)
const = tf.constant(2.0, dtype=tf.float32)

z = x**2 + y**2 + const


optimizer = tf.train.GradientDescentOptimizer(0.55)
train = optimizer.minimize(z)

init = tf.global_variables_initializer()

def optimize():
  with tf.Session() as session:
    session.run(init)
    print(""starting at"", ""x:"", session.run(x), ""y:"", session.run(y), ""z:"", session.run(z))
    for step in range(10):  
      session.run(train)
      print(""step"", step, ""x:"", session.run(x), ""y:"", session.run(y), ""z:"", session.run(z))


optimize()
</code></pre>

<p>But I want to specify the gradient in the problem.
aka I am trying to do this:</p>

<pre><code>def function_to_minimize(x,y, const):
    # z = 2x^2 + y^2 + constant
    z = 2*x**2 + y**2 + const
    return z

def calc_grad(x,y):
    # z = 2x^2 + y^2 + constant
    dz_dx = 4*x
    dz_dy = 2*y
    return [(dz_dx, x), (dz_dy, y)]

x = tf.Variable(3, name='x', dtype=tf.float32)
y = tf.Variable(3, name='y', dtype=tf.float32)
const = tf.constant(2.0, dtype=tf.float32)


z = function_to_minimize(x,y, const)
grad = calc_grad(x,y)


init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
print(sess.run(z))
print(sess.run(grad))


optimizer = tf.train.GradientDescentOptimizer(0.5)

grads_and_vars = calc_grad(x,y)

optimizer.apply_gradients(grads_and_vars)

# minimize() takes care of both computing the gradients and applying them to the variables.
#If you want to process the gradients before applying them you can instead use the optimizer in three steps:
#     1. Compute the gradients with compute_gradients().
#     2. Process the gradients as you wish.
#     3. Apply the processed gradients with apply_gradients()
</code></pre>

<p>How do you do this properly?</p>
",2019-08-07 10:39:42,11895031,113,https://stackoverflow.com/questions/57392510,Documentation Replication on Other Examples
57403472,How do I add a new feature column to a tf.data.Dataset object?,"<p>I am building an input pipeline for proprietary data using Tensorflow 2.0's data module and using the tf.data.Dataset object to store my features. Here is my issue - the data source is a CSV file that has only 3 columns, a label column and then two columns which just hold strings referring to JSON files where that data is stored. I have developed functions that access all the data I need, and am able to use Dataset's map function on the columns to get the data, but I don't see how I can add a new column to my tf.data.Dataset object to hold the new data. So if anyone could help with the following questions, it would really help:</p>

<ol>
<li>How can a new feature be appended to a tf.data.Dataset object?</li>
<li>Should this process be done on the entire Dataset before iterating through it, or during (I think during iteration would allow utilization of the performance boost, but I don't know how this functionality works)?</li>
</ol>

<p>I have all the methods for taking the input as the elements from the columns and performing everything required to get the features for each element, I just don't understand how to get this data into the dataset. I could do ""hacky"" workarounds, using a Pandas Dataframe as a  ""mediator"" or something along those lines, but I want to keep everything within the Tensorflow Dataset and pipeline process, for both performance gains and higher quality code.</p>

<p>I have looked through the Tensorflow 2.0 documentation for the Dataset class (<a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset"" rel=""noreferrer"">https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset</a>), but haven't been able to find a method that can manipulate the structure of the object.</p>

<p>Here is the function I use to load the original dataset:</p>

<pre><code>def load_dataset(self):
    # TODO: Function to get max number of available CPU threads
    dataset = tf.data.experimental.make_csv_dataset(self.dataset_path,
                                                    self.batch_size,
                                                    label_name='score',
                                                    shuffle_buffer_size=self.get_dataset_size(),
                                                    shuffle_seed=self.seed,
                                                    num_parallel_reads=1)
    return dataset
</code></pre>

<p>Then, I have methods which allow me to take a string input (column element) and return the actual feature data. And I am able to access the elements from the Dataset using a function like "".map"". But how do I add that as a column?</p>
",2019-08-07 23:41:02,7508594,399,https://stackoverflow.com/questions/57403472,Inadequate Examples
57453826,Write tf.dataset back to TFRecord,"<p>After creating a tf.data.Dataset, I would like to write it to TFRecords.</p>

<p>One way to do that is to iterate through the complete dataset and write after serializeToString into TFRecords. But it is not the most efficient way to do it.</p>

<p>Are there easier ways to do this?
Are there any APIs available in TF2.0?</p>
",2019-08-11 21:41:47,11698102,436,https://stackoverflow.com/questions/57453826,Documentation Replication on Other Examples
57460127,Tensorflow 2 creating custom dataset,"<p>I am trying to build a custom dataset-loader, which laods <a href=""https://rrc.cvc.uab.es/?ch=4"" rel=""nofollow noreferrer"">ICDAR</a>-Dataset.
My frist step was to embed a dataset inside my loader as suggested also
<a href=""https://stackoverflow.com/questions/54373780/create-tensorflow-dataset-with-custom-file-format"">here</a> in this post, but the problem is that you have to implement all the nice features that the tenfsoflow-2 class ""Dataset"" offers manually.</p>

<p>My second try was to subclass the Dataset-Class, something like:</p>

<pre><code>class MyDataset(tf.data.Dataset):
  def __init__(self):
    super(MyDataset, self).init()

  def preprocess_images(self):
    pass
</code></pre>

<p>But the problem is i did not find any documentation what dataset-class internally really does, the only implementation i found was <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L2349"" rel=""nofollow noreferrer"">this one</a>.</p>

<p>So question is does anybody know how to build a custom ""dataset"" in tf2 by subclassing tf.data.Dataset.</p>

<p>By the way i also tried tensorflow_datasets, bit it does not really worked, shince it will downlaod the dataset, and split them manually which is in this is alreay seperated by train and test and also ICDAr can not be downlaoded without registration.</p>

<p><strong>The content of the ICDAR-Dataset is as following:</strong></p>

<blockquote>
  <p>An Image </p>
  
  <p>A List of all texts in each image </p>
  
  <p>A List of Bouding-boxes for each text in each image</p>
</blockquote>

<p><strong>Image:</strong> 
@<a href=""https://rrc.cvc.uab.es/?ch=4"" rel=""nofollow noreferrer"">https://rrc.cvc.uab.es/?ch=4</a> owns the copyrights of this image.
<a href=""https://i.stack.imgur.com/YCVX2.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YCVX2.jpg"" alt=""enter image description here""></a></p>

<p>Words and bounding boxes for the above image:</p>

<pre><code>377,117,463,117,465,130,378,130,Genaxis Theatre
493,115,519,115,519,131,493,131,[06]
374,155,409,155,409,170,374,170,###
492,151,551,151,551,170,492,170,62-03
376,198,422,198,422,212,376,212,Carpark
494,190,539,189,539,205,494,206,###
374,1,494,0,492,85,372,86,###
</code></pre>

<p>Thanks
does anyone know how to </p>
",2019-08-12 11:13:19,2335224,1382,https://stackoverflow.com/questions/57460127,Lack of Alternative Solutions/Documentation
57481282,How to use multiple GPU for a DCGAN using Tensorflow 2.0 - RuntimeError: Replica-local variables may only be assigned in a replica context,"<p>I would like to develop a DCGAN with resolution of 256x256. To do so I need to use multiple GPU since only one it is not enough and it will probably take too much time.</p>

<p>I followed the procedure explained in the documentation at this link
<a href=""https://www.tensorflow.org/beta/guide/distribute_strategy"" rel=""nofollow noreferrer"">https://www.tensorflow.org/beta/guide/distribute_strategy</a></p>

<p>At the top of the script I used</p>

<p><code>strategy = tf.distribute.MirroredStrategy()</code></p>

<p>Then inside the Generator, Discriminator, and Loss functions I used</p>

<p><code>with strategy.scope():</code></p>

<p>The error I get is:</p>

<p><code>RuntimeError: Replica-local variables may only be assigned in a replica context.</code></p>

<pre class=""lang-py prettyprint-override""><code>
strategy = tf.distribute.MirroredStrategy()

path = '/my/dataset/path/'
file_paths = [f for f in glob.glob(path + ""**/*.jpg"", recursive=True)]

tensor_data = np.zeros((len(file_paths), 256, 256, 3)).astype('float32')

for i in range(len(file_paths)): 
  img_tensor = tf.image.decode_image(tf.io.read_file(file_paths[i]))
  tensor_data[i] = img_tensor

for i in range(tensor_data.shape[0]):
  tensor_data[i] = ((tensor_data[i] - 127.5) / 127.5)

BUFFER_SIZE = len(file_paths)
BATCH_SIZE = 256

train_dataset = tf.data.Dataset.from_tensor_slices(tensor_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

def make_generator_model():
    with strategy.scope():
        model = tf.keras.Sequential()
        model.add(layers.Dense(64*64*1536, use_bias=False, input_shape=(100,)))
        model.add(layers.BatchNormalization())
        model.add(layers.LeakyReLU())

        model.add(layers.Reshape((64, 64, 1536)))
        assert model.output_shape == (None, 64, 64, 1536) # Note: None is the batch size

        model.add(layers.Conv2DTranspose(1536, (5, 5), strides=(1, 1), padding='same', use_bias=False))
        assert model.output_shape == (None, 64, 64, 1536)
        model.add(layers.BatchNormalization())
        model.add(layers.LeakyReLU())

        model.add(layers.Conv2DTranspose(768, (5, 5), strides=(2, 2), padding='same', use_bias=False))
        assert model.output_shape == (None, 128, 128, 768)
        model.add(layers.BatchNormalization())
        model.add(layers.LeakyReLU())

        model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
        assert model.output_shape == (None, 256, 256, 3)

        return model

generator = make_generator_model()

noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)

sample = generated_image[0, :, :, :];
sample = tf.cast(sample, tf.int32)

plt.imshow(sample, cmap=None)

def make_discriminator_model():
    with strategy.scope():
        model = tf.keras.Sequential()
        model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same', input_shape=[256, 256, 3]))
        model.add(layers.LeakyReLU())
        model.add(layers.Dropout(0.3))

        model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
        model.add(layers.LeakyReLU())
        model.add(layers.Dropout(0.3))

        model.add(layers.Flatten())
        model.add(layers.Dense(1))

    return model

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    with strategy.scope():
        real_loss = cross_entropy(tf.ones_like(real_output), real_output)
        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
        total_loss = real_loss + fake_loss
        return total_loss

def generator_loss(fake_output):
    with strategy.scope():
        return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

checkpoint_dir = './training_checkpoints/'
checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt"")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

EPOCHS = 2000
noise_dim = 100
num_examples_to_generate = 16

seed = tf.random.normal([num_examples_to_generate, noise_dim])

# Notice the use of `tf.function`
# This annotation causes the function to be ""compiled"".
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      train_step(image_batch)

    # Produce images for the GIF as we go
    display.clear_output(wait=True)
    generate_and_save_images(generator,
                             epoch + 1,
                             seed)

    # Save the model every 15 epochs
    os.makedirs(os.path.dirname(checkpoint_prefix), exist_ok=True)

    if (epoch + 1) % 50 == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # Generate after the final epoch
  display.clear_output(wait=True)
  generate_and_save_images(generator,epochs,seed)

def generate_and_save_images(model, epoch, test_input):
    # Notice `training` is set to False.
    # This is so all layers run in inference mode (batchnorm).
    predictions = model(test_input, training=False)

    fig = plt.figure(figsize=(4,4))

    for i in range(predictions.shape[0]):
      plt.subplot(8, 8, i+1)
      sample = predictions[i, :, :, :] * 127.5 + 127.5
      sample = tf.cast(sample, tf.int32)
      plt.imshow(sample, cmap=None)
      plt.axis('off')

    filename = './screens/eye-256x256/1/image_at_epoch_{:04d}.png'
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    if (epoch + 1) % 10 == 0:
        plt.savefig(filename.format(epoch))
        plt.show()

get_ipython().run_cell_magic('time', '', 'train(train_dataset, EPOCHS)')
</code></pre>

<p>The error is the following</p>

<pre><code>Executing op ExperimentalRebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op ExperimentalAutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op MultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op MultiDeviceIteratorInit in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op MultiDeviceIteratorToStringHandle in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:1
Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:1
Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:GPU:1
Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:GPU:1
Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:GPU:1
Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:1
Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:0
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;timed exec&gt; in &lt;module&gt;

&lt;ipython-input-20-88a9879432c7&gt; in train(dataset, epochs)
      4 
      5     for image_batch in dataset:
----&gt; 6       train_step(image_batch)
      7 
      8     # Produce images for the GIF as we go

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    414     # This is the first call of __call__, so we have to initialize.
    415     initializer_map = {}
--&gt; 416     self._initialize(args, kwds, add_initializers_to=initializer_map)
    417     if self._created_variables:
    418       try:

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    357     self._concrete_stateful_fn = (
    358         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--&gt; 359             *args, **kwds))
    360 
    361     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   1358     if self.input_signature:
   1359       args, kwargs = None, None
-&gt; 1360     graph_function, _, _ = self._maybe_define_function(args, kwargs)
   1361     return graph_function
   1362 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   1646       graph_function = self._function_cache.primary.get(cache_key, None)
   1647       if graph_function is None:
-&gt; 1648         graph_function = self._create_graph_function(args, kwargs)
   1649         self._function_cache.primary[cache_key] = graph_function
   1650       return graph_function, args, kwargs

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   1539             arg_names=arg_names,
   1540             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 1541             capture_by_value=self._capture_by_value),
   1542         self._function_attributes)
   1543 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    714                                           converted_func)
    715 
--&gt; 716       func_outputs = python_func(*func_args, **func_kwargs)
    717 
    718       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    307         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    308         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 309         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    310     weak_wrapped_fn = weakref.ref(wrapped_fn)
    311 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    704           except Exception as e:  # pylint:disable=broad-except
    705             if hasattr(e, ""ag_error_metadata""):
--&gt; 706               raise e.ag_error_metadata.to_exception(type(e))
    707             else:
    708               raise

RuntimeError: in converted code:

    &lt;ipython-input-19-d2ffe8a85706&gt;:9 train_step  *
        generated_images = generator(noise, training=True)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py:667 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/sequential.py:248 call
        return super(Sequential, self).call(inputs, training=training, mask=mask)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py:753 call
        return self._run_internal_graph(inputs, training=training, mask=mask)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py:895 _run_internal_graph
        output_tensors = layer(computed_tensors, **kwargs)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py:667 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/normalization.py:782 call
        self.add_update(mean_update)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:507 new_func
        return func(*args, **kwargs)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py:1095 add_update
        update()
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/normalization.py:775 mean_update
        return tf_utils.smart_cond(training, true_branch, false_branch)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/tf_utils.py:58 smart_cond
        pred, true_fn=true_fn, false_fn=false_fn, name=name)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/smart_cond.py:54 smart_cond
        return true_fn()
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/normalization.py:773 &lt;lambda&gt;
        true_branch = lambda: _do_update(self.moving_mean, new_mean)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/normalization.py:769 _do_update
        inputs_size)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/normalization.py:458 _assign_moving_average
        return state_ops.assign_sub(variable, update_delta, name=scope)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py:164 assign_sub
        return ref.assign_sub(value)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/values.py:1394 assign_sub
        _assert_replica_context(self._distribute_strategy)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/values.py:1381 _assert_replica_context
        ""Replica-local variables may only be assigned in a replica context."")

    RuntimeError: Replica-local variables may only be assigned in a replica context.
</code></pre>
",2019-08-13 15:47:32,10763156,521,https://stackoverflow.com/questions/57481282,Documentation Replicability
57527609,How to show in tensorboard the tf.data.Dataset.map subgraph in Tensorflow 2.0?,"<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">documentation</a>, the <code>tf.data.Datasets</code> work in graph mode (in both eager and graph mode):</p>

<blockquote>
  <p>Note that irrespective of the context in which map_func is defined (eager vs. graph), tf.data traces the function and executes it as a graph</p>
</blockquote>

<p>In Tensorflow 1.X, we can easily plot this graph in Tensorboard: The processing functions are plotted in a subgraph.</p>

<p>For example,</p>

<pre><code>def _parse_function(x):
    return x * 2

x = tf.constant([0 , 1])
dataset = tf.data.Dataset.from_tensor_slices(x)
dataset = dataset.map(_parse_function)
</code></pre>

<p>In Tensorboard, a subgraph appears, corresponding to the _parse_function:
<a href=""https://i.stack.imgur.com/ykIRx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ykIRx.png"" alt=""enter image description here""></a></p>

<p>However, in Tensorflow 2.0, this does not produce any visible element in the Tensorboard graph.
The following code does not produce any graph according to Tensorboard:</p>

<pre><code>def _parse_function(x):
    return x * 2

logdir = 'logs'
writer = tf.summary.create_file_writer(logdir)

tf.summary.trace_on(graph=True, profiler=True)
x = tf.constant([0 , 1])
dataset = tf.data.Dataset.from_tensor_slices(x)
dataset = dataset.map(_parse_function)

with writer.as_default():
  tf.summary.trace_export(
      name=""trace"",
      step=0,
      profiler_outdir=logdir)
</code></pre>

<p>So, since a graph is created when calling the <code>map</code>, is there a way to access/visualize this graph?</p>
",2019-08-16 15:49:36,3860928,1697,https://stackoverflow.com/questions/57527609,Documentation Replicability
56419668,What's the difference between tf.random.normal and tf.distributions.Normal?,"<p>What's the difference between <code>tf.random.normal</code> and <code>tf.distributions.Normal</code>?  Or the difference between <code>tf.distributions.Multinomial</code> and <code>tf.random.multinomial</code> or anything similar?</p>

<p>Is <code>tf.distributions.Normal</code> used as the backend for <code>tf.random.normal</code>?</p>
",2019-06-02 23:17:40,4918159,319,https://stackoverflow.com/questions/56419668,Documentation Replication on Other Examples
56386901,Example for tf. group_by_reducer?,"<p>Can someone show me an example of tf.data.experimental.group_by_reducer? I find the documentation tricky and couldn't understand fully.</p>

<p>How can I use it for calculating average?</p>
",2019-05-30 23:31:24,7418127,517,https://stackoverflow.com/questions/56386901,Documentation Replicability
56385622,Keras model.get_config() returns list instead of dictionary,"<p>I am using tensorflow-gpu==1.10.0 and keras from tensorflow as tf.keras.
I am trying to use source code written by someone else to implement it on my network.</p>

<p>I saved my network using save_model and load it using load_model. when I use model.get_config(), I expect a dictionary, but i""m getting a list. Keras source documentation also says that get_config returns a dictionary (<a href=""https://keras.io/models/about-keras-models/"" rel=""nofollow noreferrer"">https://keras.io/models/about-keras-models/</a>).</p>

<p>I tried to check if it has to do with saving type : save_model or model.save that makes the difference in how it is saved, but both give me this error:</p>

<pre><code>TypeError: list indices must be integers or slices, not str

</code></pre>

<p>my code block : </p>

<pre class=""lang-py prettyprint-override""><code>        model_config = self.keras_model.get_config()
        for layer in model_config['layers']:
            name = layer['name']
            if name in update_layers:
                layer['config']['filters'] = update_layers[name]['filters']
</code></pre>

<p>my pip freeze : </p>

<pre><code>absl-py==0.6.1
astor==0.7.1
bitstring==3.1.5
coverage==4.5.1
cycler==0.10.0
decorator==4.3.0
Django==2.1.3
easydict==1.7
enum34==1.1.6
futures==3.1.1
gast==0.2.0
geopy==1.11.0
grpcio==1.16.1
h5py==2.7.1
image==1.5.15
ImageHash==3.7
imageio==2.5.0
imgaug==0.2.5
Keras==2.1.3
kiwisolver==1.1.0
lxml==4.1.1
Markdown==3.0.1
matplotlib==2.1.0
networkx==2.2
nose==1.3.7
numpy==1.14.1
olefile==0.46
opencv-python==3.3.0.10
pandas==0.20.3
Pillow==4.2.1
prometheus-client==0.4.2
protobuf==3.6.1
pyparsing==2.3.0
pyquaternion==0.9.2
python-dateutil==2.7.5
pytz==2018.7
PyWavelets==1.0.1
PyYAML==3.12
Rtree==0.8.3
scikit-image==0.13.1
scikit-learn==0.19.1
scipy==0.19.1
Shapely==1.6.4.post1
six==1.11.0
sk-video==1.1.8
sklearn-porter==0.6.2
tensorboard==1.10.0
tensorflow-gpu==1.10.0
termcolor==1.1.0
tqdm==4.19.4
utm==0.4.2
vtk==8.1.0
Werkzeug==0.14.1
xlrd==1.1.0
xmltodict==0.11.0
</code></pre>
",2019-05-30 21:04:29,8668650,59,https://stackoverflow.com/questions/56385622,Documentation Replication on Other Examples
55788007,Unexpected results when using tfrecords loaded using tf.data.Dataset.list_files() with shuffle argument,"<p>I'm hoping to get clarification on how the <code>shuffle</code> argument in <code>tf.data.Dataset.list_files()</code> works. The documentation states that when <code>shuffle=True</code>, the filenames will be shuffled randomly. I've made model predictions using a tfrecords dataset that has been loaded using <code>tf.data.Dataset.list_files()</code>, and I would've expected the accuracy metric to be the same no matter the order of the files (i.e. whether shuffle is True or False), but am seeing otherwise. </p>

<p>Is this expected behavior or is there something wrong with my code or intepretation? I have reproducible example code below.</p>

<p>Oddly, as long as <code>tf.random.set_random_seed()</code> is set initially (and it seems it doesn't even matter what seed value is set), then the predictions results are the same no matter whether shuffle is True or False in <code>list_files()</code>.</p>

<p>tensorflow==1.13.1, keras==2.2.4</p>

<p>Thanks for any clarifications!</p>

<p>Edit: re-thinking it through and wondering if <code>Y = [y[0] for _ in range(steps) for y in sess.run(Y)]</code> is a separate and independent call?</p>

<pre><code># Fit and Save a Dummy Model
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from sklearn import datasets, metrics

seed = 7
np.random.seed(seed)
tf.random.set_random_seed(seed)

dataset = datasets.load_iris()

X = dataset.data
Y = dataset.target
dummy_Y = np_utils.to_categorical(Y)

# 150 rows
print(len(X))

model = Sequential()
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X, dummy_Y, epochs=10, batch_size=10,  verbose=2)
model.save('./iris/iris_model')

predictions = model.predict(X)
predictions = np.argmax(predictions, axis=1)

# returns accuracy = 0.3466666666666667
print(metrics.accuracy_score(y_true=Y, y_pred=predictions))
</code></pre>

<p>Split dataset into multiple tfrecords files so we can reload it with list_files() later:</p>

<pre><code>numrows = 15
for i, j in enumerate(range(0, len(X), numrows)):
    with tf.python_io.TFRecordWriter('./iris/iris{}.tfrecord'.format(i)) as writer:
        for x, y in zip(X[j:j+numrows, ], Y[j:j+numrows, ]):
            features = tf.train.Features(feature=
                {'X': tf.train.Feature(float_list=tf.train.FloatList(value=x)), 
                'Y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y]))
                })
            example = tf.train.Example(features=features)
            writer.write(example.SerializeToString())
</code></pre>

<p>At this point, I exit (ipython) and restart again:</p>

<pre><code>import numpy as np
import tensorflow as tf
from keras.models import load_model
from sklearn import metrics

model = load_model('./iris/iris_model')

batch_size = 10
steps = int(150/batch_size)
file_pattern = './iris/iris*.tfrecord'

feature_description = {
    'X': tf.FixedLenFeature([4], tf.float32),
    'Y': tf.FixedLenFeature([1], tf.int64)
}

def _parse_function(example_proto):
    return tf.parse_single_example(example_proto, feature_description)

def load_data(filenames, batch_size):
    raw_dataset = tf.data.TFRecordDataset(filenames)
    dataset = raw_dataset.map(_parse_function)
    dataset = dataset.batch(batch_size, drop_remainder=True)
    dataset = dataset.prefetch(2)
    iterator = dataset.make_one_shot_iterator()
    record = iterator.get_next()
    return record['X'], record['Y']

def get_predictions_accuracy(filenames):
    X, Y = load_data(filenames=filenames, batch_size=batch_size)

    predictions = model.predict([X], steps=steps)
    predictions = np.argmax(predictions, axis=1)
    print(len(predictions))

    with tf.Session() as sess:
        Y = [y[0] for _ in range(steps) for y in sess.run(Y)]

    print(metrics.accuracy_score(y_true=Y, y_pred=predictions))
</code></pre>

<pre><code># No shuffle results:
# Returns expected accuracy = 0.3466666666666667
filenames_noshuffle = tf.data.Dataset.list_files(file_pattern=file_pattern, shuffle=False)
get_predictions_accuracy(filenames_noshuffle)
</code></pre>

<pre><code># Shuffle results, no seed value set:
# Returns UNEXPECTED accuracy (non-deterministic value)
filenames_shuffle_noseed = tf.data.Dataset.list_files(file_pattern=file_pattern, shuffle=True)
get_predictions_accuracy(filenames_shuffle_noseed)
</code></pre>

<pre><code># Shuffle results, seed value set:
# Returns expected accuracy = 0.3466666666666667
# It seems like it doesn't even matter what seed value you set, as long as you you set it
seed = 1000
tf.random.set_random_seed(seed)
filenames_shuffle_seed = tf.data.Dataset.list_files(file_pattern=file_pattern, shuffle=True)
get_predictions_accuracy(filenames_shuffle_seed)
</code></pre>
",2019-04-22 00:46:54,6921786,43,https://stackoverflow.com/questions/55788007,Documentation Replication on Other Examples
55778682,fix/freeze individual kernel weights in a convolutional operation,"<p>I'm trying out a workaround for fixing individual kernel weights in a convolutional operation in TensorFlow using Python 3.7. I do it by creating </p>

<ol>
<li>a trainable variable, </li>
<li>an identical non-trainable variable and </li>
<li>a ""mask"" tensor consisting of <strong>1</strong>s and <strong>0s</strong> with the same shape as the created variables in step 1 and 2 above.</li>
</ol>

<p>A <strong>1</strong> in the ""mask"" tensor indicates that I want to fix/freeze that specific weight during training, i.e. not update it in the backward pass.</p>

<p>Now, this workaround works perfectly fine when applied to a fully connected layer but fails when applied to a convolutional layer and I can't figure out why or how to make it work.</p>

<p>Something seems to be happening in the <strong>tf.nn.conv2d()</strong> function call (see code example below) and according to the documentation this is what they do:</p>

<blockquote>
  <p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code><br>
    and a filter / kernel tensor of shape<br>
   <code>[filter_height, filter_width, in_channels, out_channels]</code>, this op<br>
    performs the following:<br>
    1. Flattens the filter to a 2-D matrix with shape<br>
       <code>[filter_height * filter_width * in_channels, output_channels]</code>.<br>
    2. Extracts image patches from the input tensor to form a <em>virtual</em><br>
       tensor of shape <code>[batch, out_height, out_width,&lt;br&gt;
       filter_height * filter_width * in_channels]</code>.<br>
    3. For each patch, right-multiplies the filter matrix and the image patch<br>
       vector.</p>
</blockquote>

<p>But since I use <strong>weights_frozen</strong> which is a tensor and depends on the trainable variable, non-trainable variable and <strong>mask_weights</strong> it should get zero-valued gradients on the positions where I have a 1 in the <strong>mask_weights</strong> tensor.</p>

<pre class=""lang-py prettyprint-override""><code>def conv(input_, layer_name...):

    weights = tf.get_variable(shape=[filter_height, filter_width, in_channels, out_channels], dtype=tf.float32, initializer=tf.glorot_uniform_initializer(), trainable=True)

    weights_fixed = tf.Variable(tf.identity(weights), trainable=False)

    mask_weights = tf.placeholder(tf.float32, weights.shape)


    weights_frozen = tf.add(tf.multiply(mask_weights, weights_fixed), tf.multiply((1 - mask_weights), weights))


    out_conv = tf.nn.conv2d(input=input_, filter=weights_frozen, strides=strides_, padding='SAME')
    out_add = tf.nn.bias_add(value=out_conv, bias=biases_frozen)

    out = tf.nn.relu(features=out_add)

    return out
</code></pre>

<p>As mentioned, I expect to get zero-valued gradients on the positions where I have a <strong>1</strong> in the <strong>mask_weights</strong> tensor, but instead they are non-zero and therefore those weights are being trained, which is not the behavior I'm trying to achieve.</p>
",2019-04-20 23:43:09,9496160,11,https://stackoverflow.com/questions/55778682,Documentation Ambiguity
57529534,How is tf.data.Dataset use optimised by tf.function in Tensorflow 2.0?,"<p>The <a href=""https://www.tensorflow.org/beta/guide/effective_tf2#combine_tfdatadatasets_and_tffunction"" rel=""noreferrer"">official documentation</a> of Tensorflow 2.0 advices to use <code>tf.data.Dataset</code> along with <code>tf.function</code>.</p>

<p>There are two examples of such uses:</p>

<ul>
<li>Using a <code>Dataset</code> as an argument of a <code>tf.function</code>, as described <a href=""https://www.tensorflow.org/beta/guide/effective_tf2#combine_tfdatadatasets_and_tffunction"" rel=""noreferrer"">here</a>:</li>
</ul>

<pre class=""lang-py prettyprint-override""><code>@tf.function
def train(model, dataset, optimizer):
  for x, y in dataset:
      ....
</code></pre>

<ul>
<li>Creating a local <code>Dataset</code> in a <code>tf.function</code> body, as described <a href=""https://www.tensorflow.org/beta/guide/autograph"" rel=""noreferrer"">here</a>:</li>
</ul>

<pre class=""lang-py prettyprint-override""><code>@tf.function
def train(model, optimizer):
  train_ds = mnist_dataset()
  ...
</code></pre>

<p>Finally, the <a href=""https://www.tensorflow.org/beta/tutorials/eager/tf_function#autograph_and_loops"" rel=""noreferrer"">autograph doc</a> states that the iterating on a <code>Dataset</code> is optimized by <code>tf.function</code>.
<a href=""https://stackoverflow.com/questions/56038372/does-wrapping-tf-data-dataset-into-tf-function-improve-performance"">This SO answer</a> shows indeed that using a <code>Dataset</code> as a parameter of <code>tf.function</code> increases performances.</p>

<p>So, how does <code>tf.data.Dataset</code> benefit from <code>tf.function</code>, and how can it explain the speedup of <a href=""https://stackoverflow.com/questions/56038372/does-wrapping-tf-data-dataset-into-tf-function-improve-performance"">this SO answer</a>:</p>

<ul>
<li>How is the <a href=""https://www.tensorflow.org/beta/tutorials/eager/tf_function#autograph_and_loops"" rel=""noreferrer"">""foor loop optimization""</a> creating a speedup by itself?</li>
<li>How is the <code>Dataset</code> object treated by the <code>tf.function</code> tracer. Like in the parameter or as a local variable examples, how can we use <code>Dataset</code> in a <code>tf.function</code>, even if the <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/function"" rel=""noreferrer""><code>tf.function</code> documentation</a> suggests that the original function should only accept <code>Tensor</code>?</li>
<li>Is there some kind of communication/sharing between the <code>Dataset</code> subgraph (that can then be used in <code>tf.function</code> subgraph), or the two are fully separated (meaning that <code>Dataset</code> is just used as an black-box iterator from <code>tf.function</code>)? </li>
</ul>
",2019-08-16 18:33:49,3860928,1697,https://stackoverflow.com/questions/57529534,Documentation Ambiguity
57570041,"Tensorflow 2.0 ""future proof"" way of using tf.feature_columns in tf.keras subclass api?","<p>I see there are some ways of using features columns wrapped in a tf.keras.layers.DenseFeatures layer:</p>

<p><a href=""https://www.tensorflow.org/beta/tutorials/keras/feature_columns#create_a_feature_layer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/beta/tutorials/keras/feature_columns#create_a_feature_layer</a></p>

<p>This suggests passing datasets into @tf.function wrapped ""def call"" methods?</p>

<p>I don't see any mention (yet) of the interaction between tf.data.DataSet and tf.function. Are tf.data.DataSet considered tensors yet for the purpose of tf.function graph cache or will they be?</p>
",2019-08-20 08:55:54,287238,6640,https://stackoverflow.com/questions/57570041,Documentation Ambiguity
57570385,"How to generate custom mini-batches using Tensorflow 2.0, such as those in the paper ""In defense of the triplet loss""?","<p>I want to implement a custom mini-batch generator in Tensorflow 2.0 using tf.data.Dataset API. Concretely, I have image data, 100 classes with ~200 examples each. For each mini-batch, I want to randomly sample P classes, and K images from each class, for a total of P*K examples in a mini-batch (as described in the paper <a href=""https://arxiv.org/pdf/1703.07737.pdf"" rel=""nofollow noreferrer"">In Defense of the Triplet Loss for Person Re-Identification</a>]).</p>

<p>I've been searching through documentation for <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">tf.data.Dataset</a>, but can't seem to find the right method. I've looked into the <code>from_generator</code> method, but it doesn't seem suitable for this, since it generates a whole dataset from scratch as I understood.</p>

<p>It seems to me that one way to do it would be to make a new class similar to <code>BatchDataset</code> which can be found in <a href=""https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/data/ops/dataset_ops.py#L90-L1536"" rel=""nofollow noreferrer"">tf.data.Dataset source code</a>, where I would somehow implement the logic, but I'm hoping for an easier solution to be honest.</p>
",2019-08-20 09:16:41,4301911,31,https://stackoverflow.com/questions/57570385,Requesting (Additional) Documentation/Examples
57609316,Does TFLiteConverter automatically quantize the Keras model?,"<p>I converted the trained Keras model using tf.lite.TFLiteConverter into tflite_model. Is the converted tflite_model quantized one? Here is the snippet to make the conversion.</p>

<pre><code>import tensorflow as tf

keras_model = ""./Trained_Models/h_vs_o_a_V1.h5""

converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_model)
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)
</code></pre>
",2019-08-22 12:26:06,7830286,447,https://stackoverflow.com/questions/57609316,Documentation Replication on Other Examples
57651287,How to swap tensor axes efficiently in tensorflow?,"<p>I have to swap tensor's axes using <code>tf.transpose</code> to do the batch matrix multiplication (as the code shown below). </p>

<p>tensor input_a: shape [10000, 10000] </p>

<p>tensor input_b: shape [batch_size, 10000, 10] </p>

<p>tensor output:  shape [batch_size, 10000, 10] </p>

<pre><code># reshape_input_b: shape [10000, batch_size, 10]
transpose_input_b = tf.transpose(input_b, [1, 0, 2])

# transpose_input_b : shape [10000, batch_size * 10]
reshape_input_b = tf.reshape(transpose_input_b , [10000, -1])

# ret: shape [10000, batch_size * 10]
ret = tf.matmul(input_a, reshape_input_b, a_is_sparse = True)

# reshape_ret: [10000, batch_size, 10]
reshape_ret = tf.reshape(ret, [10000, -1, 10])

# output : [batch_size, 10000, 10]
output = tf.transpose(reshape_ret, [1, 0, 2])
</code></pre>

<p>However, it seems very slow. I noticed this in the document page of <code>tf.transpose</code>:</p>

<blockquote>
  <p>In numpy transposes are memory-efficient constant time operations as they simply return a new view of the same data with adjusted strides.</p>
  
  <p>TensorFlow does not support strides, <b>so transpose returns a new tensor with the items permuted</b>.</p>
</blockquote>

<p>So, I think it might be the reason why my code run slowly? Is there any way to swap tensor's axes, or do the batch matrix multiplication efficiently?</p>
",2019-08-26 02:58:02,9427280,73,https://stackoverflow.com/questions/57651287,Inadequate Examples
57717004,Tensorflow: Modern way to load large data,"<p>I want to train a convolutional neural network (using tf.keras from Tensorflow version 1.13) using numpy arrays as input data. The training data (which I currently store in a single &gt;30GB '.npz' file) does not fit in RAM all at once. <strong>What is the best way to save and load large data-sets into a neural network for training?</strong> Since I didn't manage to find a good answer to this (surely ubiquitous?) problem, I'm hoping to hear one here. Thank you very much in advance for any help!</p>
<h3>Sources</h3>
<p>Similar questions seem to have been asked many times (e.g. <a href=""https://stackoverflow.com/questions/49169016/training-classifier-from-tfrecords-in-tensorflow"">training-classifier-from-tfrecords-in-tensorflow</a>, <a href=""https://stackoverflow.com/questions/40467990/tensorflow-synchronize-readings-from-tfrecord"">tensorflow-synchronize-readings-from-tfrecord</a>, <a href=""https://stackoverflow.com/questions/51357223/how-to-load-data-parallelly-in-tensorflow"">how-to-load-data-parallelly-in-tensorflow</a>) but are several years old and usually contain no conclusive answer.</p>
<p>My current understanding is that using TFRecord files is a good way to approach this problem. The most promising tutorial I found so far explaining how to use TFRecord files with keras is <a href=""https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36"" rel=""noreferrer"">medium.com</a>. Other helpful sources were <a href=""http://machinelearninguru.com/deep_learning/data_preparation/tfrecord/tfrecord.html"" rel=""noreferrer"">machinelearninguru.com</a> and <a href=""https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564"" rel=""noreferrer"">medium.com_source2</a> and sources therin.</p>
<p>The official tensorflow documentation and tutorials (on <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""noreferrer"">tf.data.Dataset</a>, <a href=""https://www.tensorflow.org/guide/datasets"" rel=""noreferrer"">Importing Data</a>, <a href=""https://www.tensorflow.org/tutorials/load_data/tf_records"" rel=""noreferrer"">tf_records</a> etc.) did not help me. In particular, several of the examples given there didn't work for me even without modifications.</p>
<h3>My Attempt at using TFRecord files</h3>
<p>I'm assuming TFRecords are a good way to solve my problem but I'm having a hard time using them. Here is an example I made based on the tutorial <a href=""https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36"" rel=""noreferrer"">medium.com</a>. I stripped down the code as much as I could.</p>
<pre><code># python 3.6, tensorflow 1.13.
# Adapted from https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36
import tensorflow as tf
import numpy as np
from tensorflow.python import keras as keras


# Helper functions (see also https://www.tensorflow.org/tutorials/load_data/tf_records)
def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))


def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))


def writeTFRecords():
    number_of_samples = 100  # create some random data to play with
    images, labels = (np.random.sample((number_of_samples, 256, 256, 1)), np.random.randint(0, 30, number_of_samples))

    writer = tf.python_io.TFRecordWriter(&quot;bla.tfrecord&quot;)

    for index in range(images.shape[0]):
        image = images[index]
        label = labels[index]

        feature = {'image':  _bytes_feature(tf.compat.as_bytes(image.tostring())),
                   'label':  _int64_feature(int(label))}

        example = tf.train.Example(features=tf.train.Features(feature=feature))
        writer.write(example.SerializeToString())
    writer.close()


def loadTFRecord(data_path):
    with tf.Session() as sess:
        feature = {'train/image': tf.FixedLenFeature([], tf.string),
                   'train/label': tf.FixedLenFeature([], tf.int64)}
        # Create a list of filenames and pass it to a queue
        filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)
        # Define a reader and read the next record
        reader = tf.TFRecordReader()
        _, serialized_example = reader.read(filename_queue)
        # Decode the record read by the reader
        features = tf.parse_single_example(serialized_example, features=feature)
        # Convert the image data from string back to the numbers
        image = tf.decode_raw(features['train/image'], tf.float32)

        # Cast label data into int32
        label = tf.cast(features['train/label'], tf.int32)
        # Reshape image data into the original shape
        image = tf.reshape(image, [256, 256, 1])

        return image, label  # I'm not 100% sure that's how this works...


# ######### generate a TFRecords file in the working directory containing random data. #################################
writeTFRecords()
# ######## Load the TFRecords file and use it to train a simple example neural network. ################################
image, label = loadTFRecord(&quot;bla.tfrecord&quot;)

model_input = keras.layers.Input(tensor=image)
model_output = keras.layers.Flatten(input_shape=(-1, 256, 256, 1))(model_input)
model_output = keras.layers.Dense(16, activation='relu')(model_output)

train_model = keras.models.Model(inputs=model_input, outputs=model_output)
train_model.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001),  
                    loss='mean_squared_error',
                    target_tensors=[label])

print(&quot;\n \n start training \n \n&quot;) # Execution gets stuck on fitting
train_model.fit(epochs=1, steps_per_epoch=10)  # no output or error messages.

</code></pre>
<p>The code creates a TFRecord file and starts fitting, then just gets stuck with no output or error messages. I don't know what the problem is or how I could try to fix it.</p>
",2019-08-29 19:57:26,9988487,1454,https://stackoverflow.com/questions/57717004,Documentation Replication on Other Examples
57719398,Unable to save model with tensorflow 2.0.0 beta1,"<p>I have tried all the options described in the documentation but none of them allowed me to save my model in tensorflow 2.0.0 beta1. I've also tried to upgrade to the (also unstable) TF2-RC but that ruined even the code I had working in beta so I quickly rolled back for now to beta.</p>

<p>See a minimal reproduction code below.</p>

<p>What I have tried: </p>

<ol>
<li><pre><code>model.save(""mymodel.h5"") 
</code></pre></li>
</ol>

<blockquote>
  <p>NotImplementedError: Saving the model to HDF5 format requires the
  model to be a Functional model or a Sequential model. It does not work
  for subclassed models, because such models are defined via the body of
  a Python method, which isn't safely serializable. Consider saving to
  the Tensorflow SavedModel format (by setting save_format=""tf"") or
  using <code>save_weights</code>.</p>
</blockquote>

<ol start=""2"">
<li><pre><code>model.save(""mymodel"", format='tf')
</code></pre></li>
</ol>

<blockquote>
  <p>ValueError: Model &lt;<strong>main</strong>.CVAE object at 0x7f1cac2e7c50> cannot be
  saved because the input shapes have not been set. Usually, input
  shapes are automatically determined from calling .fit() or .predict().
  To manually set the shapes, call model._set_inputs(inputs).</p>
</blockquote>

<p>3.</p>

<pre><code>model._set_input(input_sample)
model.save(""mymodel"", format='tf') 
</code></pre>

<blockquote>
  <p>AssertionError: tf.saved_model.save is not supported inside a traced
  @tf.function. Move the call to the outer eagerly-executed context.</p>
</blockquote>

<p>And this is where I am stuck now because it gives me no reasonable hint whatsoever. That's because I am NOT calling the save() function from a @tf.function, I'm already calling it from the outermost scope possible. In fact, I have no @tf.function at all in this minimal reproduction script below and still getting the same error.</p>

<p>So I really have no idea how to save my model, I've tried every options and they all throw errors and provide no hints.</p>

<p>The minimal reproduction example below works fine if you set save_model=False and it reproduces the error when save_model=True. </p>

<p>It may seem unnecessary in this simplified auto-encoder code example to use a subclassed model but I have lots of custom functions added to it in my original VAE code that I need it for.</p>

<p>Code:</p>

<pre><code>import tensorflow as tf

save_model = True

learning_rate = 1e-4
BATCH_SIZE = 100
TEST_BATCH_SIZE = 10
color_channels = 1
imsize = 28

(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()

train_images = train_images[:5000, ::]
test_images = train_images[:1000, ::]
train_images = train_images.reshape(-1, imsize, imsize, 1).astype('float32')
test_images = test_images.reshape(-1, imsize, imsize, 1).astype('float32')
train_images /= 255.
test_images /= 255.
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE)
test_dataset = tf.data.Dataset.from_tensor_slices(test_images).batch(TEST_BATCH_SIZE)

class AE(tf.keras.Model):
    def __init__(self):
        super(AE, self).__init__()
        self.network = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=(imsize, imsize, color_channels)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(50),
            tf.keras.layers.Dense(imsize**2 * color_channels),
            tf.keras.layers.Reshape(target_shape=(imsize, imsize, color_channels)),
        ])
    def decode(self, input):
        logits = self.network(input)
        return logits

optimizer = tf.keras.optimizers.Adam(learning_rate)
model = AE()

def compute_loss(data):
    logits = model.decode(data)
    loss = tf.reduce_mean(tf.losses.mean_squared_error(logits, data))
    return loss

def train_step(data):
    with tf.GradientTape() as tape:
        loss = compute_loss(data)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss, 0

def test_step(data):
    loss = compute_loss(data)
    return loss

input_shape_set = False
epoch = 0
epochs = 20
for epoch in range(epochs):
    for train_x in train_dataset:
        train_step(train_x)
    if epoch % 1 == 0:
        loss = 0.0
        num_batches = 0
        for test_x in test_dataset:
            loss += test_step(test_x)
            num_batches += 1
        loss /= num_batches
        print(""Epoch: {}, Loss: {}"".format(epoch, loss))

        if save_model:
            print(""Saving model..."")
            if not input_shape_set:
                # Note: Why set input shape manually and why here:
                # 1. If I do not set input shape manually: ValueError: Model &lt;main.CVAE object at 0x7f1cac2e7c50&gt; cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).
                # 2. If I set input shape manually BEFORE the first actual train step, I get: RuntimeError: Attempting to capture an EagerTensor without building a function.
                model._set_inputs(train_dataset.__iter__().next())
                input_shape_set = True
            # Note: Why choose tf format: model.save('MNIST/Models/model.h5') will return NotImplementedError: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=""tf"") or using save_weights.
            model.save('MNIST/Models/model', save_format='tf')
</code></pre>
",2019-08-30 01:23:49,4515762,408,https://stackoverflow.com/questions/57719398,Documentation Replicability
57731214,What tf.keras.backend.clear_session actually do?,"<p>What is <code>tf.keras.backend.clear_session</code> actually do?</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session</a></p>

<p>How it's related to <code>tf.reset_default_graph()</code> and  <code>sess.close()</code> ?</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/reset_default_graph"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/reset_default_graph</a></p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/Session#close"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/Session#close</a></p>
",2019-08-30 17:48:21,1179925,20633,https://stackoverflow.com/questions/57731214,Lack of Alternative Solutions/Documentation
57809049,"tf.while_loop -> Number of inputs and outputs of body must match loop_vars: 1, 2","<p>I need to use a tf.while_loop but I got the following message : </p>

<pre><code>ValueError: Number of inputs and outputs of body must match loop_vars: 1, 2
</code></pre>

<pre><code>total_loss, i = list(), tf.constant(0)
def sampled_softmax_body(i, total_loss):
    loss = tf.nn.sampled_softmax_loss(weights=logits_weights, biases=logits_biases, labels=target, inputs=h2_decoder_outputs[:,i,:], num_sampled=n_sampled_softmax, num_classes=n_fra_words, partition_strategy=""div"")     
    total_loss.append(loss)
    i = i + 1
    return i, total_loss
def condition(i, total_loss):
    return True and i &lt; max_words_per_sentence[""fra""]
tf.while_loop(condition, sampled_softmax_body, [i, total_loss])
</code></pre>
",2019-09-05 15:50:17,11427310,351,https://stackoverflow.com/questions/57809049,Documentation Replicability
57858794,"Why doesn't a Lambda function that returns the result of tf.py_func/tf.numpy_function have an output shape, and how can I correct this behavior?","<p>For example purposes, I've created two Python functions. One takes a value and just returns it; the other is a lambda function that returns a Tensor to evaluate the function:</p>

<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input,Lambda,Dense
def test_func(value):
  return value
test_func = np.vectorize(test_func)
test_op = lambda x: tf.numpy_function(test_func,[x],tf.float32)
input = Input(shape=(1,))
test_layer = Lambda(test_op)
model = Sequential()
model.add(input)
model.add(test_layer)
model.summary()
</code></pre>

<p>When I run this code on Tensorflow 1.14.x + Keras 2.2.x + Python 3.6.x, and even if I set the output_shape parameter of the Lambda layer, I get a Lambda layer with a ""None"" output shape:</p>

<pre class=""lang-none prettyprint-override""><code>Model: ""sequential_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lambda_1 (Lambda)            None                      0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<p>When I test the code using a test tensor, I get the results I might expect:</p>

<pre><code>with tf.Session() as session:
    X = tf.constant([[1.0,2.0],[3.0,4.0]])
    Y = tf.constant(2.0)
    X_out = test_op(X)
    Y_out = test_op(Y)
    print(""X:"",session.run(X))
    print(""X shape: "",session.run(tf.shape(X_out)))
    print(""Y:"",session.run(Y_out))
    print(""Y shape: "", session.run(tf.shape(Y_out)))
</code></pre>

<p>Output:</p>

<blockquote>
  <p>X: [[1. 2.]  [3. 4.]]
  X shape:  [2 2]
  Y: 2.0
  Y shape:  <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda"" rel=""nofollow noreferrer"">1</a>
  <strong>EDIT:</strong></p>
</blockquote>

<p>For comparison purposes, I also created a neural network using the function found in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda"" rel=""nofollow noreferrer"">this page of documentation</a>:</p>

<pre><code>from tensorflow.keras import Model
from tensorflow.keras.layers import Input,Lambda
input = Input(shape=(1,))
def antirectifier(x):
    x -= K.mean(x, axis=1, keepdims=True)
    x = K.l2_normalize(x, axis=1)
    pos = K.relu(x)
    neg = K.relu(-x)
    return K.concatenate([pos, neg], axis=1)
lambda_ = Lambda(antirectifier)
lambda_ = Lambda(antirectifier)(input)
model = Model(inputs=[input],outputs=[lambda_])
model.summary()
</code></pre>

<p>As somewhat expected, this prints:</p>

<pre class=""lang-none prettyprint-override""><code>Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 2)                 0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<p>Now - if I understand correctly - both tf.py_func and K.concatenate return a TensorFlow Tensor object. So, the question is, Why does all the code I posted here work, EXCEPT my tf.numpy_function layer?</p>
",2019-09-09 17:40:37,10083113,279,https://stackoverflow.com/questions/57858794,Documentation Replicability
57872334,parallel inference in tensorflow (CPUs),"<p>this is a really basic question, but I can't get the answer anywhere.</p>

<p>Using tensorflow, can I do inference (<code>tf.keras.Model.predict()</code>) on multiple CPUs in parallel? I am using <code>tf.data.Dataset</code> to represent my data, but from the <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict"" rel=""nofollow noreferrer"">documentation</a> it seems multiprocessing can be used only with generators or tf.keras.Sequence objects. Why is that? Am I supposed to somehow create an ordinary python generator from the <code>Dataset</code> or to manage the parallelism on my own with <code>multiprocessing</code> package? What would be the standard way of doing this?</p>

<p>Thanks for any hints.</p>
",2019-09-10 13:53:50,3447343,1142,https://stackoverflow.com/questions/57872334,Documentation Replication on Other Examples
57873334,Affine Transform in TensorFlow 2.0,"<p>How to code Affine Transform in TensorFlow 2.0 that can work for digital images?</p>

<p>I've tried tf.keras.preprocessing.image.apply_affine_transform from TensorFlow 1.14 but TensorFlow 2.0 has no such transform. Now I need it for TensorFlow 2.0.</p>
",2019-09-10 14:49:03,11160943,742,https://stackoverflow.com/questions/57873334,Documentation Replication on Other Examples
57875937,Inconsistent tf.print results,"<p>I was trying to understand the executing order in tensorflow graph. When I was running the following code. <code>tf.print</code> prints undetermined results. </p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

for _ in range(20):
    tf.reset_default_graph()
    use_resource = False
    v = tf.Variable(0, trainable=False, use_resource=use_resource, name='v')
    v_op1 = v.assign_add(1, name='v_op1')
    v_op2 = v.assign_add(2, name='v_op2')

    with tf.control_dependencies([v_op1]):
        w1 = tf.print('msg1:', v, name='v--w')
    with tf.control_dependencies([w1, v_op2]):
        w2 = tf.print('msg2:', v, '\n', name='w--w')
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(w2)
</code></pre>

<p>Here are the output of 20 repetitions. Sometimes, it prints ""msg1: 3"", sometimes it prints ""msg1: 1"". So what's going on here?  </p>

<pre class=""lang-py prettyprint-override""><code>msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 1
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 3
msg2: 3 

msg1: 1
msg2: 3 
</code></pre>
",2019-09-10 17:46:26,7212365,4337,https://stackoverflow.com/questions/57875937,Documentation Replication on Other Examples
57878623,Error with tf.nn.sparse_softmax_cross_entropy_with_logits,"<p>I am using <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> and when I pass through the labels and logits I get the following error</p>

<blockquote>
  <p>tensorflow.python.framework.errors_impl.InvalidArgumentError: labels
  must be 1-D, but got shape [50,1]</p>
</blockquote>

<p>I don't understnad how having a shape <code>[50,1]</code> is not the same as being 1D</p>
",2019-09-10 21:47:28,9706484,113,https://stackoverflow.com/questions/57878623,Documentation Replication on Other Examples
57881799,How to define custom gradient for keras layer with tensorflow 1.14,"<p>I am trying to implement gradient reversal layer in tf.keras (tf ver 1.14). I defined a custom gradient using tf.custom_gradient but the grad function is never called and the result is wrong.</p>

<p>I am using the following to test the layer</p>

<pre><code>from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras import backend as k
import tensorflow as tf
tf.enable_eager_execution()
import numpy as np

@tf.custom_gradient
def custom_op(x):
    result = x
    def custom_grad(dy):
        grad = tf.negative(dy)
        return grad
    return result, custom_grad

class GradientReversal(tf.keras.layers.Layer):
  def __init__(self):
    super(GradientReversal, self).__init__()

  def call(self, inputs):
    return custom_op(inputs)


a = Input(shape=(2,))
b = GradientReversal()(a)
c = Dense(1)(b)
model = Model(inputs=a, outputs=c)
model.compile(loss='binary_crossentropy', optimizer='sgd')

@tf.function
def test():  
  with tf.GradientTape() as tape:
    out = model(np.ones((1, 2)))
  gradients = tape.gradient(out, model.trainable_variables)
  return gradients

print(test())
</code></pre>
",2019-09-11 03:40:00,5026962,55,https://stackoverflow.com/questions/57881799,Documentation Replicability
57888872,"how to fix ""OperatorNotAllowedInGraphError "" error in Tensorflow 2.0","<p>I'm learn tensorflow2.0 from <a href=""https://www.tensorflow.org/beta/guide/autograph?hl=zh-cn#batching"" rel=""noreferrer"">official tutorials</a>.I can understand the result from below code.</p>

<pre><code>def square_if_positive(x):
  return [i ** 2 if i &gt; 0 else i for i in x]
square_if_positive(range(-5, 5))

# result
[-5, -4, -3, -2, -1, 0, 1, 4, 9, 16]
</code></pre>

<p>But if I change the inputs with tensor not python code, just like this</p>

<pre><code>def square_if_positive(x):
  return [i ** 2 if i &gt; 0 else i for i in x]
square_if_positive(tf.range(-5, 5))

</code></pre>

<p>I get below error!!</p>

<pre><code>OperatorNotAllowedInGraphError            Traceback (most recent call last)
&lt;ipython-input-39-6c17f29a3443&gt; in &lt;module&gt;
      2 def square_if_positive(x):
      3     return [i**2 if i &gt; 0 else i for i in x]
----&gt; 4 square_if_positive(tf.range(10))
      5 # measure_graph_size(square_if_positive, range(10))

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    437     # This is the first call of __call__, so we have to initialize.
    438     initializer_map = {}
--&gt; 439     self._initialize(args, kwds, add_initializers_to=initializer_map)
    440     if self._created_variables:
    441       try:

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    380     self._concrete_stateful_fn = (
    381         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--&gt; 382             *args, **kwds))
    383 
    384     def invalid_creator_scope(*unused_args, **unused_kwds):

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   1793     if self.input_signature:
   1794       args, kwargs = None, None
-&gt; 1795     graph_function, _, _ = self._maybe_define_function(args, kwargs)
   1796     return graph_function
   1797 

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2093         graph_function = self._function_cache.primary.get(cache_key, None)
   2094         if graph_function is None:
-&gt; 2095           graph_function = self._create_graph_function(args, kwargs)
   2096           self._function_cache.primary[cache_key] = graph_function
   2097         return graph_function, args, kwargs

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   1984             arg_names=arg_names,
   1985             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 1986             capture_by_value=self._capture_by_value),
   1987         self._function_attributes,
   1988         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    851                                           converted_func)
    852 
--&gt; 853       func_outputs = python_func(*func_args, **func_kwargs)
    854 
    855       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    323         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    324         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 325         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    326     weak_wrapped_fn = weakref.ref(wrapped_fn)
    327 

~/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    841           except Exception as e:  # pylint:disable=broad-except
    842             if hasattr(e, ""ag_error_metadata""):
--&gt; 843               raise e.ag_error_metadata.to_exception(type(e))
    844             else:
    845               raise

OperatorNotAllowedInGraphError: in converted code:

    &lt;ipython-input-37-6c17f29a3443&gt;:3 square_if_positive  *
        return [i**2 if i &gt; 0 else i for i in x]
    /Users/zhangpan/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:547 __iter__
        self._disallow_iteration()
    /Users/zhangpan/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:540 _disallow_iteration
        self._disallow_when_autograph_enabled(""iterating over `tf.Tensor`"")
    /Users/zhangpan/tf2_workspace/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:518 _disallow_when_autograph_enabled
        "" decorating it directly with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.

</code></pre>

<p>I can't find any specifications about this error. I think the real reason is not ""iterating over <code>tf.Tensor</code> is not allowed"" . Becase I can write like this.</p>

<pre><code>@tf.function
def square_if_positive(x):
    for i in x:
        if i&gt;0:
            tf.print(i**2)
        else:
            tf.print(i)
square_if_positive(tf.range(10))
</code></pre>

<p>I iterate over tensor just like above code.</p>

<p>So my question is what's the <strong>real reason</strong> about this error? Any suggestions will help me. I really can't understand this error through I read a lot of materials.</p>
",2019-09-11 12:12:23,6737375,213,https://stackoverflow.com/questions/57888872,Documentation Replication on Other Examples
57914611,Has tf.Estimator become obsolete in Tensorflow 2.0?,"<p>Today I've set up a custom model using its tf.Estimator high-level API in Tensorflow 2.0.
It was a pain in the *** to get it running, and there are very few complete examples online that implement custom Estimators in Tensorflow 2, which made me questioning the reasons for using this API.</p>

<p>According to the docs, the main advantages of using the tf.Estimator API are:</p>

<ol>
<li><p>You can run Estimator-based models on a local host or on a distributed multi-server environment without changing your model. Furthermore, you can run Estimator-based models on CPUs, GPUs, or TPUs without recoding your model.</p></li>
<li><p>You no longer have to worry about creating the computational graph or sessions since Estimators handle all the ""plumbing"" for you</p></li>
</ol>

<p>Advantage 2. clearly doesn't apply to Tensorflow 2.0 anymore, as it runs in eager mode by default, so you don't have to worry about sessions anyways.</p>

<p>Advantage 1. also seems quite irrelevant in Tensorflow 2.0 - using tf.distribute.Strategy, you can now easily run even high level tf.Keras models in a distributed fashion and on CPUs/GPUs/TPUs.
tf.Keras models are so much easier and faster to set up, so why did they even bother to keep the tf.Estimator API in Tensorflow 2.0? Are there other advantages of using this API?</p>
",2019-09-12 21:16:03,8725045,724,https://stackoverflow.com/questions/57914611,Requesting (Additional) Documentation/Examples
57921463,How tf.data.experimental.group_by_window() operates in Tensorflow 2.0,"<p>I am trying to understand the tf.data.experimental.group_by_window() method in Tensorflow 2 but I have some difficulties.</p>

<p>For a reproducible example I use the one presented in the documentation:</p>

<pre><code>components = np.arange(100).astype(np.int64)
dataset20 = tf.data.Dataset.from_tensor_slices(components)
dataset20 = dataset.apply(tf.data.experimental.group_by_window(key_func=lambda x: x%2, reduce_func=lambda _,\
                                                          els: els.batch(10), window_size=100))

i = 0

for elem in dataset20:

    print('i is {0}\n'.format(i))

    print('elem is {0}'.format(elem.numpy()))

    i += 1

    print('\n--------------------------------\n')

i is 0

elem is [0 2 4 6 8]

--------------------------------

i is 1

elem is [1 3 5 7 9]

--------------------------------
</code></pre>
",2019-09-13 10:00:20,8270077,4751,https://stackoverflow.com/questions/57921463,Documentation Ambiguity
57929803,What is the proper way to convert Tracing Code using RunOptions to Tensorflow 2.0?,"<p>I'm having difficulty finding any documentation on how to migrate tracing code from 1.x to 2.0.</p>

<p>In tensorflow 1.x you could do the following:</p>

<pre><code>run_options = tf.compat.v1.RunOptions(trace_level=tf.compat.v1.RunOptions.FULL_TRACE)
run_metadata = tf.compat.v1.RunMetadata()
final_result = sess.run(result, feed_dict={...},
                        options=run_options,
                        run_metadata=run_metadata)

trace = fetched_timeline = timeline.Timeline(run_metadata.step_stats)
chrome_trace = fetched_timeline.generate_chrome_trace_format()
with open('timeline.json', 'w') as f:
    f.write(chrome_trace)
</code></pre>

<p>How can you do a similar thing with a @tf.function call?</p>

<pre><code>@tf.function
def predict(x1, x2):
    ...
#=============
# Set run options and RunMetadata variables
#=============
#=============
final_result = predict(x1_val, x2_val)

#=============
# Dump Trace (assuming run_metadata is the RunMetaData object we configured previously)
#=============
trace = fetched_timeline = timeline.Timeline(run_metadata.step_stats)
chrome_trace = fetched_timeline.generate_chrome_trace_format()
with open('timeline.json', 'w') as f:
    f.write(chrome_trace)
#=============

</code></pre>
",2019-09-13 20:09:22,314864,317,https://stackoverflow.com/questions/57929803,Inadequate Examples
57970717,Using pretrained convolutional network as a GAN discriminator,"<p>I've pulled some code from TF2.0 documentation to generate images from a custom dataset. The code is <a href=""https://www.tensorflow.org/beta/tutorials/generative/dcgan"" rel=""nofollow noreferrer"">here</a> </p>

<p>Since the documentation uses Keras i figured i might change the discriminator network to a pretrained network e.g InceptionV3, and only train the top layers. I've found <a href=""https://keras.io/applications/"" rel=""nofollow noreferrer"">this</a> code (Fine-tune InceptionV3 on a new set of classes). I cant seem to figure out how to replace the the one with the other. I understand that im trying to replace Sequential mode with the Functional API. But i guess they are somehow interconnected. However, im not a frequent Keras user.</p>

<p>My questions is: How do i replace a custom CNN in Sequential mode with a pretrained one from the Functional API to use as a discriminator?</p>

<p>EDIT: I would be happy if anyone has examples of doing it with the GANEstimator instead as im more used to TF.</p>

<p><strong>Use the generator to generate a random image</strong></p>

<pre><code>def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 3)

    return model

generator = make_generator_model()
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
</code></pre>

<p><strong>The current discriminator and helpers (Outputs tf.Tensor([[-0.0003378]], shape=(1, 1), dtype=float32))</strong></p>

<pre><code>def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))

    return model

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
</code></pre>

<p><strong>The desired discriminator</strong></p>

<pre><code>def make_discriminator_model():
    # create the base pre-trained model
    model = InceptionV3(weights='imagenet', include_top=False)

    # ADD TOP LAYERS

    # FREEZE ALL LAYERS EXCEPT TOP LAYERS

    return model

# COMPILE

def discriminator_loss(real_output, fake_output):
    real_loss = ??? # Real Loss
    fake_loss = ??? # Fake loss
    total_loss = real_loss + fake_loss
    return total_loss

noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
</code></pre>

<p><strong>All imports</strong></p>

<pre><code>  from __future__ import absolute_import, division, print_function, unicode_literals

try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf
print('TF version: {}'.format(tf.__version__))

import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from PIL import Image
from tensorflow.keras import layers
import time

from IPython import display
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import vgg16
import os.path
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras import backend as K
</code></pre>

<p><strong>EDIT:
This was the discriminator i ended up with! Thanks to @pandrey</strong></p>

<pre><code>def make_discriminator_model():
    pre_trained = tf.keras.applications.InceptionV3(
        weights='imagenet', include_top=False, input_shape=IMG_SHAPE
    )
    pre_trained.trainable = False  # mark all weights as non-trainable
    model = tf.keras.Sequential([pre_trained])
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(1))   
    return model
</code></pre>
",2019-09-17 08:54:48,11825110,21,https://stackoverflow.com/questions/57970717,Requesting (Additional) Documentation/Examples
57995171,Need a clear simple approach to distributed learning in Tensorflow/Keras,"<p>I have multiple machines, some with GPUs and some others not. I also have a keras model that works fine on a single machine but I want to train it in a distributed mode because I want to test it with a huge dataset and with a bigger number of layers.
There is quite a lot of pages discussing the distribution strategy in tf.distribute, but at the same time there are a lot other pages showing how to do it with encapsulating keras model with an estimator, setting up the TF_CONFIG parameter and then call <code>tf.estimator.train_and_evaluate</code>.
I used the second approach personally as it was more straightforward and am struggling to tune and debug it. It works anyway, but I am very confused what is the point in all of strategy-related stuff as I don't see any use them in the second approach, and the documentation is not helping to clear it.</p>

<p>I also have some doubt if my file setting environment is correct: My understanding is that the PS server is going to hold the model parameters and the chief server is going to administer the whole training process, distributing data, and saving summaries and checkpoints. So I assume that:</p>

<p>0- I need only one chief server, at least one PS server, possibly some workers, and one evaluator. The data and parameter sharing and communication between all of these servers is done by system and I am not engaged in it.</p>

<p>1- The main python code for all machines should be exactly the same, except in TF_CONFIG definition that defines the task and index for that specific machine.</p>

<p>2- I should have one shared copy of data in a folder available to all chief and workers.</p>

<p>3- I should have one shared log directory accessible by all machines as defined in tf.estimator.RunConfig.</p>

<p>4- Having this setting then a piece of code such as below will do the job (assuming the <code>model</code> has been defined elsewhere and the <code>read_datasets</code> function returns features and labels for running the model):</p>

<pre><code>runConfig = tf.estimator.RunConfig(
        session_config=config,
        model_dir=log_dir,
        save_summary_steps=1,
        save_checkpoints_steps=train_steps
        )
estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig)
train_spec = tf.estimator.TrainSpec(input_fn=lambda: read_datasets(...), max_steps=epochs*train_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=lambda: read_datasets(...), start_delay_secs=1, throttle_secs=1)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</code></pre>

<p>Although the above approach seems to work fine, I still have some difficulties understanding how the chief is partitioning the dataset among the workers and how to set the train_step and batch_size in this approach. Also I don't know how can I report accuracy and other metrics such as precision/recall/F1 in addition to loss when running the <code>tf.estimator.evaluate</code> without writing a custom model_fn for my encapsulated keras estimator.</p>
",2019-09-18 14:28:52,6450489,671,https://stackoverflow.com/questions/57995171,Documentation Replication on Other Examples
58112355,"What, exactly, is eager execution from a programming point of view?","<p>I am trying to understand eager execution. Pages returned by Google describe what it does for you, and I'm ok with that. I am trying to understand it from the point of view of program code. Here is an example from <a href=""https://towardsdatascience.com/eager-execution-tensorflow-8042128ca7be"" rel=""nofollow noreferrer"">this article</a>.</p>

<pre><code>a = tf.constant([[1,2],[3,4]])
</code></pre>

<p>The article says this statement does something different depending on whether you are in eager mode or not. Without eager mode, print(a) gives:</p>

<pre><code>Tensor(""Const:0"", shape=(2, 2), dtype=int32)
</code></pre>

<p>With eager mode, print(a) gives:</p>

<pre><code>tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32)
</code></pre>

<p>Please could someone explain what these two return values are. If they are two different object types, a Tensor and a tf.Tensor, what is the difference between these objects?</p>

<p>I have searched the TensorFlow documentation and can't see anything that addresses this distinction. Any pointers gratefully received.</p>

<p>Thanks,</p>

<p>Julian</p>
",2019-09-26 08:13:33,6691564,191,https://stackoverflow.com/questions/58112355,Inadequate Examples
58162110,How to port a tf.Session to a tf.train.MonitoredSession call while allowing graph modifications,"<p>The code I'm working on is <a href=""https://github.com/tensorflow/tensorrt/blob/master/tftrt/examples/object_detection/object_detection.py"" rel=""nofollow noreferrer"">this</a>.<br>
The code uses tf.session call to take in a graph for object detection tasks.  <a href=""https://github.com/tensorflow/tensorrt/blob/526f3650a550d6ffcceddfd73d112391080066ad/tftrt/examples/object_detection/object_detection.py#L593-L676"" rel=""nofollow noreferrer"">Link</a><br>
My aim here is to profile this code for Nvidia GPUs using the nvtx-plugins-tf to analyze the time taken for different ops. <a href=""https://nvtx-plugins.readthedocs.io/en/latest/templates/api.html#session-hooks"" rel=""nofollow noreferrer"">Link to docs</a></p>

<p>The plugin library provides a function hook for a tf.train.MonitoredSession as given in their example code <a href=""https://github.com/NVIDIA/nvtx-plugins/blob/a5d47ba6cb0548f2a6c15814d409a14aca4d33f8/examples/tf_session_example.py#L19-L95"" rel=""nofollow noreferrer"">here</a>.<br>
The code linked above uses tf.session along with a tf.config and when I try to modify the tf.session call to a tf.train.MonitoredSession call, I can't get my code to work and it fails with an error that graph can't be modified. I went through the tensorflow APIs and it turns out that tf.session doesn't support hook callbacks and tf.train.MonitoredSession doesn't support tf_config as a function argument.</p>

<pre><code>Traceback (most recent call last):
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/mayroy13/Mayank/Mayank/test/tensorrt/tftrt/examples/object_detection/test.py"", line 105, in &lt;module&gt;
    test(args.test_config_path)
  File ""/home/mayroy13/Mayank/Mayank/test/tensorrt/tftrt/examples/object_detection/test.py"", line 81, in test
    **test_config['benchmark_config'])
  File ""/home/mayroy13/Mayank/Mayank/test/tensorrt/tftrt/examples/object_detection/object_detection.py"", line 608, in benchmark_model
    tf.import_graph_def(frozen_graph, name='')
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 443, in import_graph_def
    _ProcessNewOps(graph)
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 236, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3751, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3751, in &lt;listcomp&gt;
    for c_op in c_api_util.new_tf_operations(self)
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3640, in _create_op_from_tf_operation
    self._check_not_finalized()
  File ""/home/mayroy13/anaconda3/envs/trt-py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3225, in _check_not_finalized
    raise RuntimeError(""Graph is finalized and cannot be modified."")
RuntimeError: Graph is finalized and cannot be modified.
</code></pre>

<p>Any directions to go in would be appreciated. If there are ways in tensorflow to use hooks in conjunction with tf.session, that will also work for me.</p>
",2019-09-30 05:50:16,5232265,11,https://stackoverflow.com/questions/58162110,Documentation Replication on Other Examples
58186564,TensorFlow multi class training and prediction,"<p>The following code (working), train a model to recognize cats and make a prediction on the selected picture. (Code TensorFlowJS but the question is generally TensorFlow)<br>
So far it is only predicting one class (""cat""), so that a car or a dog would be for example 80% a cat. 
<br><br>
Question:<br>
How do i add other classes (like ""dog"") ? <br>
Should it look like that (abstracted): model.fit([img1, img2, img3], [label1, label2, label3] ...) ?<br>
<br>
I don't get it:<br>
What is the relation between the labels and the training set.<br></p>

<p>Here is the code (please ignore the ""Predict"" part for now):</p>

<pre><code>&lt;head&gt;
    &lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2.7""&gt; &lt;/script&gt;
    &lt;script src=""https://unpkg.com/@tensorflow-models/mobilenet""&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class=""container mt-5""&gt;
        &lt;div class=""row""&gt;
            &lt;input id =""image-selector"" class=""form-control border-0"" type=""file""/&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col""&gt;
                &lt;h2&gt;Prediction&lt;/h2&gt;
                &lt;ol id=""prediction-list""&gt;&lt;/ol&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-12""&gt;
                &lt;h2 class=""ml-3""&gt;Image&lt;/h2&gt;
                &lt;canvas id=""canvas"" width=""400"" height=""300"" style=""border:1px solid #000000;""&gt;&lt;/canvas&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div  id=""training-images""&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat.jpg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat3.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat4.jpeg"" /&gt;

        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog3.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog4.jpeg"" /&gt;
    &lt;/div&gt;
&lt;/body&gt;

&lt;script&gt;
    const modelType = ""mobilenet"";
    const model = tf.sequential();
    const label = ['cat'];
    var ys, setLabel, input, canvas, context;
    input = document.getElementById(""image-selector"");
    canvas = document.getElementById(""canvas"");
    context = canvas.getContext('2d');

    //-------------------------- Training: --------------------------------
    window.addEventListener('load', (event) =&gt; {
        // Labels
        setLabel = Array.from(new Set(label));
        ys = tf.oneHot(tf.tensor1d(label.map((a) =&gt; setLabel.findIndex(e =&gt; e === a)), 'int32'), 10);
        console.log('ys:::'+ys);

        // Prepare model :
        model.add(tf.layers.conv2d({
            inputShape: [224, 224 , 3],
            kernelSize: 5,
            filters: 8,
            strides: 2,
            activation: 'relu',
            kernelInitializer: 'VarianceScaling'
        }));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.flatten({}));
        model.add(tf.layers.dense({units: 64, activation: 'relu'}));
        model.add(tf.layers.dense({units: 10, activation: 'softmax'}));
        model.compile({
            loss: 'meanSquaredError',
            optimizer : 'sgd'
        });

        // Prepare training images
        var images = [];
        for(var i = 0; i &lt; 40; i++) {
            let img = preprocessImage(document.getElementsByClassName(""cat"")[i], modelType);
            images.push(tf.reshape(img, [1, 224, 224, 3],'resize'));
        }
        console.log(""processed images : "");
        console.log(images);
        trainModel(images);
    });

    async function trainModel(images) {
        for(var i = 0; i &lt; images.length; i++) {
            await model.fit(images[i], ys, {epochs: 100, batchSize: 32}).then((loss) =&gt; {
            const t = model.predict(images[i]);
            console.log('Prediction:::'+t);
            pred = t.argMax(1).dataSync(); // get the class of highest probability
            const labelsPred = Array.from(pred).map(e =&gt; setLabel[e]);
            console.log('labelsPred:::'+labelsPred);
            }).catch((e) =&gt; {
                console.log(e.message);
            })
        }
        console.log(""Training done!"");
    }

    //-------------------------- Predict: --------------------------------
    input.addEventListener(""change"", function() {
        var reader = new FileReader();
        reader.addEventListener(""loadend"", function(arg) {
            var src_image = new Image();
            src_image.onload = function() {
                canvas.height = src_image.height;
                canvas.width = src_image.width;
                context.drawImage(src_image, 0, 0);
                var imageData = canvas.toDataURL(""image/png""); 
                runPrediction(src_image)
            }
            src_image.src = this.result;
        });
        var res = reader.readAsDataURL(this.files[0]);
    });

    async function runPrediction(imageData){
        let tensor = preprocessImage(imageData, ""mobilenet"");
        const resize_image = tf.reshape(tensor, [1, 224, 224, 3],'resize');
        let prediction = await model.predict(tensor).data();
        console.log('prediction:::'+ prediction);

        let top5 = Array.from(prediction)
        .map(function(p,i){
            return {
                probability: p,
                className: prediction[i]
            };
        }).sort(function(a,b){
            return b.probability-a.probability;
        }).slice(0,1);

        $(""#prediction-list"").empty();
        top5.forEach(function(p){
            $(""#prediction-list"").append(`&lt;li&gt;${p.className}:${p.probability.toFixed(6)}&lt;/li&gt;`);
        });
    }

    //-------------------------- Helpers: --------------------------------
    function preprocessImage(image, modelName)
    {
        let tensor = tf.browser.fromPixels(image)
        .resizeNearestNeighbor([224,224])
        .toFloat();

        let offset=tf.scalar(127.5);

        return tensor.sub(offset)
        .div(offset)
        .expandDims();
    }
&lt;/script&gt;
</code></pre>

<p>The code is based on the TFJS documentation and a comment on the github : <a href=""https://github.com/tensorflow/tfjs/issues/1288"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tfjs/issues/1288</a></p>

<p><strong>UPDATE :</strong>
So I need X and Y to be the same length for X:images and Y:labels, with Y1 being the label for X1 and so on...
<br><br>
I tried:</p>

<pre><code>ys:::Tensor (with only 2 classes represented in the training data set) :
    [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]
</code></pre>

<p><br><br>
One image + all labels -> with ""model.fit(images[i], ys, {epochs: 100})..."", I get:
<br>Error: ""Input Tensors should have the same number of samples as target Tensors. Found 1 input sample(s) and 10 target sample(s).""
<br><br>
One image + one label -> with ""model.fit(images[i], ys[i], {epochs: 100})..."", I get:
<br>Error: ""Cannot read property 'shape' of null"", i guess ys is a tensor but y[i] is not.
<br><br>
All images + all labels -> with ""model.fit(images, ys, {epochs: 100})..."", I get:
<br>Error: ""when checking model input: the Array of Tensors that you are passing to your model is not the size the model expected. 
Expected to see 1 Tensor(s), but instead got the following list of Tensor(s): Tensor ...""
<br><br>
Guess: I need to put all images in one tensor with the same structure as ys.</p>

<p><strong>SOLVED :</strong>
<br>
After solving the problem with the labels thanks to Rishabh Sahrawat, I had to merge all tensor(images) in to one with the help of tf.concat(...).</p>

<pre><code>[tensorImg1, tensorImg2, tensorImg3, tensorImg4, ...] x tensor[label1, label2, label3, label4, ...]
-&gt; 
tensor[dataImg1, dataImg2, dataImg3, dataImg4, ...] x tensor[label1, label2, label3, label4, ...]
</code></pre>

<p>Updated code :</p>

<pre><code>&lt;head&gt;
    &lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2.7""&gt; &lt;/script&gt;
    &lt;script src=""https://unpkg.com/@tensorflow-models/mobilenet""&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class=""container mt-5""&gt;
        &lt;div class=""row""&gt;
            &lt;input id =""image-selector"" class=""form-control border-0"" type=""file""/&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col""&gt;
                &lt;h2&gt;Prediction&lt;/h2&gt;
                &lt;ol id=""prediction-list""&gt;&lt;/ol&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-12""&gt;
                &lt;h2 class=""ml-3""&gt;Image&lt;/h2&gt;
                &lt;canvas id=""canvas"" width=""400"" height=""300"" style=""border:1px solid #000000;""&gt;&lt;/canvas&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div  id=""training-images""&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat.jpg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat3.jpeg"" /&gt;

        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog3.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog4.jpeg"" /&gt;
    &lt;/div&gt;
&lt;/body&gt;

&lt;script&gt;
    const modelType = ""mobilenet"";
    const model = tf.sequential();
    var labels = ['cat', 'dog'];
    var ys, setLabel, input, canvas, context;
    input = document.getElementById(""image-selector"");
    canvas = document.getElementById(""canvas"");
    context = canvas.getContext('2d');

    //-------------------------- Training: --------------------------------
    window.addEventListener('load', (event) =&gt; {        
        // Prepare model :
        prepareModel();

        // Prepare training images
        var images = [];
        var trainLabels = []
        for(var i = 0; i &lt; document.getElementsByClassName('train-image').length; i++) {
            let img = preprocessImage(document.getElementsByClassName('train-image')[i], modelType);
            //images.push(tf.reshape(img, [1, 224, 224, 3],'resize'));
            images.push(img);
            if (document.getElementsByClassName('train-image')[i].classList.contains(""cat"")){
                trainLabels.push(0)
            } else {
                trainLabels.push(1)
            }
        }

        console.log(labels)
        setLabel = Array.from(labels);
        ys = tf.oneHot(trainLabels, 2);
        console.log('ys:::'+ys);
        console.log(images);
        trainModel(images);
    });

    async function trainModel(images) {
        for(var i = 0; i &lt; images.length; i++) {
            await model.fit(tf.concat(images, 0), ys, {epochs: 100}).then((loss) =&gt; {
            const t = model.predict(images[i]);
            console.log('Prediction:::'+t);
            pred = t.argMax().dataSync(); // get the class of highest probability
            //const labelsPred = Array.from(pred).map(e =&gt; setLabel[e]);
            //console.log('labelsPred:::'+labelsPred);
            }).catch((e) =&gt; {
                console.log(e.message);
            })

        }
        console.log(""Training done!"");
    }

    //-------------------------- Predict: --------------------------------
    input.addEventListener(""change"", function() {
        var reader = new FileReader();
        reader.addEventListener(""loadend"", function(arg) {
            var src_image = new Image();
            src_image.onload = function() {
                canvas.height = src_image.height;
                canvas.width = src_image.width;
                context.drawImage(src_image, 0, 0);
                var imageData = canvas.toDataURL(""image/png""); 
                runPrediction(src_image)
            }
            src_image.src = this.result;
        });
        var res = reader.readAsDataURL(this.files[0]);
    });

    async function runPrediction(imageData){
        let tensor = preprocessImage(imageData, ""mobilenet"");
        const resize_image = tf.reshape(tensor, [1, 224, 224, 3],'resize');
        let prediction = await model.predict(tensor).data();
        console.log('prediction:::'+ prediction);

        let top5 = Array.from(prediction)
        .map(function(p,i){
            return {
                probability: p,
                className: prediction[i]
            };
        }).sort(function(a,b){
            return b.probability-a.probability;
        }).slice(0,1);

        $(""#prediction-list"").empty();
        top5.forEach(function(p){
            $(""#prediction-list"").append(`&lt;li&gt;${p.className}:${p.probability.toFixed(6)}&lt;/li&gt;`);
        });
    }

    //-------------------------- Helpers: --------------------------------

    function prepareModel(){
        model.add(tf.layers.conv2d({
            inputShape: [224, 224 , 3],
            kernelSize: 5,
            filters: 8,
            strides: 2,
            activation: 'relu',
            kernelInitializer: 'VarianceScaling'
        }));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.flatten({}));
        model.add(tf.layers.dense({units: 64, activation: 'relu'}));
        model.add(tf.layers.dense({units: 2, activation: 'softmax'}));
        model.compile({
            loss: 'meanSquaredError',
            optimizer : 'sgd'
        });
        model.summary()
    }

    function preprocessImage(image, modelName)
    {
        let tensor = tf.browser.fromPixels(image)
        .resizeNearestNeighbor([224,224])
        .toFloat();

        let offset=tf.scalar(127.5);

        return tensor.sub(offset)
        .div(offset)
        .expandDims();
    }
&lt;/script&gt;
</code></pre>
",2019-10-01 14:07:13,6258907,43,https://stackoverflow.com/questions/58186564,Documentation Replication on Other Examples
58248787,Reading TF2 summary file with tf.data.TFRecordDataset,"<p>In TF1, i could use <code>summary_iterator</code> to read summary files. But now, it will throw a warning</p>

<pre><code>WARNING:tensorflow: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
</code></pre>

<p>So i'm wondering how to use <code>tf.data.TFRecordDataset(path)</code> to read tfevent files generated by TF2.</p>
",2019-10-05 13:30:47,4909165,401,https://stackoverflow.com/questions/58248787,Documentation Replication on Other Examples
58317413,how can we get cell state if we use tf.keras.layers.LSTM (tf version is 2.0)?,"<p>In tensorflow version 2 tf.keras.layers.LSTM returns only the hidden state but not the cell state when return_state is checked to be True</p>
",2019-10-10 07:16:57,10187580,1,https://stackoverflow.com/questions/58317413,Documentation Ambiguity
58338310,Predefined layers inside Custom layers,"<p>I want to use predefined layers from tf.keras.layers inside a custom layer. I want to create a custom layer that is a combination of dense and 1D Convolution layers.
Is it possible to do something like that? I could not find an example in the tensorflow pages.</p>
",2019-10-11 09:31:07,11698102,436,https://stackoverflow.com/questions/58338310,Lack of Alternative Solutions/Documentation
58384884,'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction',"<p>I am using Huber loss implementation in tf.keras in tensorflow 1.14.0 as follows:</p>

<pre><code>huber_keras_loss = tf.keras.losses.Huber(
        delta=delta,
        reduction=tf.keras.losses.Reduction.SUM,
        name='huber_loss'
    )
</code></pre>

<p>I am getting the error 
AttributeError: module 'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction'</p>

<p>I have tried using tf.losses.Reduction, tf.compat.v2.losses.Reduction nothing seems to work.</p>

<p>Did tensorflow remove Reduction from tf.keras.losses, it is strange if they did so because their documentation still shows:
<a href=""https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/losses/Huber#args"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/losses/Huber#args</a></p>
",2019-10-14 22:39:09,11986203,11,https://stackoverflow.com/questions/58384884,Documentation Ambiguity
58499116,How to raise an error based on condition in Tensorflow?,"<p>I am writing a function <strong>my_function</strong> to be used as tf.data.Dataset.map argument, using tf.py_function, as recommended in <a href=""https://www.tensorflow.org/guide/data#applying_arbitrary_python_logic"" rel=""nofollow noreferrer"">the doc</a>.</p>

<p>How can I raise a <strong>tf.errors.InvalidArgumentError</strong> in my_function ?</p>

<p><b>my_function</b></p>

<pre><code>def my_function(data, param):
    _, n_freq_bins, n_time_bins, channels = tf.shape(data)
    tf.cond(
        param &lt; n_time_bins,
        lambda: 1,
        &lt;raise tf.errors.InvalidArgumentError&gt;
    )
    ...
</code></pre>

<p><b>In my data pipeline:</b></p>

<pre><code>dataset = dataset.map(lambda data, labels: (tf.py_function(my_function, [data, 100], tf.float32), labels))
</code></pre>
",2019-10-22 07:28:49,326849,36704,https://stackoverflow.com/questions/58499116,Documentation Replicability
58561632,"Keras model_to_estimator doesn't log metrics on estimator.train, but logs on estimator.evaluate","<p>I tried the keras <a href=""https://www.tensorflow.org/tutorials/estimator/keras_model_to_estimator"" rel=""nofollow noreferrer"">model_to_estimator</a> to build an estimator, but found that it wasn't logging metrics during training, although it does during evaluation.</p>

<p>If that doesn't work out of the box, how can I use tf.summary.scalar or hooks in an estimator that consumes a tf.keras model?</p>

<p><a href=""https://i.stack.imgur.com/gMFDC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gMFDC.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/Jw2A3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Jw2A3.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/piAXq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/piAXq.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/zvN8R.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zvN8R.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/FTIVt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FTIVt.png"" alt=""enter image description here""></a></p>
",2019-10-25 15:37:43,3211422,8631,https://stackoverflow.com/questions/58561632,Documentation Replicability
58577878,Seq2Seq Training helper module in tensorflow,"<p>In the latest tf 2.0 update tensorflow removed the contrib module from the framework. Thought they have compensated for most of the function from it in tf.compat.v1 but I couldn't find the substitute for the functions such as tf.contrib.seq2seq.BasicDecoder , tf.contrib.seq2seq.dynamic_decode , tf.contrib.seq2seq.GreedyEmbeddingHelper and tf.contrib.seq2seq.TrainingHelper.
How to use these functions in my model?</p>
",2019-10-27 08:55:48,8103827,353,https://stackoverflow.com/questions/58577878,Documentation Replication on Other Examples
58599039,Understand how to use tf.nn.conv2d function,"<p>I'm trying to understand how does tf.nn.conv2d() function work. Thus, I created a simple tensorflow program for that:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

Nif = 2
Niy = 4
Nix = 4

Nof = 1
Koy =3
Kox = 3

ifmaps  = np.random.randint(3, size=(Nif, Niy, Nix))
print(""ifmaps= "", ifmaps)
weights = np.random.randint(3, size=(Nof, Nif, Koy, Kox))
print(""weights = "", weights)
weights = np.reshape(weights, (Koy, Kox, Nif,Nof)) 

ifmaps = tf.constant(ifmaps, dtype=tf.float64, shape=[Nif, Niy, Nix])
weights = tf.constant(weights, dtype=tf.float64, shape=[Koy, Kox, Nif,Nof])

ifmaps_tf = tf.reshape(ifmaps, shape=[-1, Niy, Nix, Nif]) #NHWC
weights_tf = tf.reshape(weights, shape = [Koy, Kox, Nif, Nof])

res = tf.nn.conv2d(ifmaps_tf, weights_tf, strides=[1, 1, 1, 1], padding='VALID') #S=1, no padding
#reshape it to NCHW format
ofmap = tf.reshape(res, shape=[ Nof, 2, 2])

with tf.Session() as sess:
   print(""ofmap = "", sess.run(ofmap))
</code></pre>

<p>The results that I get are:</p>

<pre><code>ifmaps=  [[[0 2 1 0]
  [2 0 1 0]
  [0 1 2 1]
  [1 0 2 1]]

 [[0 0 2 1]
  [0 0 1 0]
  [2 1 2 1]
  [0 2 0 2]]]

  weights =  [[[[1 1 1]
   [0 1 0]
   [1 0 2]]

  [[2 2 2]
   [2 2 2]
   [0 1 0]]]]

   ofmap =  [[[17. 21.]
  [20. 16.]]]
</code></pre>

<p>The ofmaps value are not correct! Any one can help me in getting what I'm missing?
Thanks in advance.</p>
",2019-10-28 22:09:44,5925476,695,https://stackoverflow.com/questions/58599039,Documentation Replication on Other Examples
58608838,"tf.layers.batch_normalization( training=is_train) is deprecated, what is the alternative?","<pre><code>is_train = tf.compat.v1.placeholder(tf.bool, name='is_train')
conv_norm = tf.layers.batch_normalization(conv, training=self.is_train)
</code></pre>

<p>this code works 
<code>tf.layers.batch_normalizaton</code> is depricated</p>

<p>Are there any alternatives in <code>tf.keras.layers.BatchNormalization()</code>?</p>

<p>I can't find a parameter for ""training"" in it</p>
",2019-10-29 13:54:10,10342859,26,https://stackoverflow.com/questions/58608838,Documentation Ambiguity
58630393,Does tf.keras.metrics.AUC work on multi-class problems?,"<p>I have a multi-class classification problem and I want to measure AUC on training and test data.</p>
<p>tf.keras has implemented AUC metric (tf.keras.metrics.AUC), but I'm not be able to see whether this metric could safely be used in multi-class problems. Even, the example &quot;Classification on imbalanced data&quot; on the official Web page is dedicated to a binary classification problem.</p>
<p>I have implemented a CNN model that predicts six classes, having a softmax layer that gives the probabilities of all the classes. I used this metric as follows</p>
<pre><code>self.model.compile(loss='categorical_crossentropy',
                       optimizer=Adam(hp.get(&quot;learning_rate&quot;)),
                       metrics=['accuracy', AUC()]),
</code></pre>
<p>and the code was executed without any problem. However, sometimes I see some results that are quite strange for me. For example, the model reported an accuracy of 0.78333336 and AUC equal to 0.97327775, Is this possible? Can a model have a low accuracy and an AUC so high?</p>
<p>I wonder that, although the code does not give any error, the AUC metric is computing wrong.</p>
<p>Somebody may confirm me whether or not this metrics support multi-class classification problems?</p>
",2019-10-30 17:01:02,9176854,181,https://stackoverflow.com/questions/58630393,Documentation Replication on Other Examples
58680578,Return from tf.map_fn,"<p>Two types of returns from bbox_organize(). The first one from <code>if statement</code> is [5] and second one from <code>else statement is (2,5)</code>.</p>

<p>How can I put it into boxes_ from <code>tf.map_fn</code>?</p>

<pre><code>import tensorflow as tf
tf.enable_eager_execution();

boxes = tf.constant([[1.0,2.0,2.3,3.4,0,0,0,0],[2.0,3.2,4.2,4.0,0,0,0,0],[3.0,4.0,1.0,2.1,1.2,1.4,1.2,1.5],[1.2,1.3,3.4,4.5,1,2,3,4]])
rows = tf.expand_dims(tf.range(tf.shape(boxes)[0], dtype=tf.int32), 1)
def bbox_organize(box, i):
   if(tf.reduce_sum(box[4:]).numpy() == 0):
      box=tf.slice(box, [0], [4])
      const_=tf.constant(i.numpy()[0], dtype=""float32"", shape=[1])
      box=tf.concat([const_, box], 0)

   else:
      box=tf.reshape(box, [2, 4])
      const_=tf.constant(i.numpy()[0], dtype=""float32"", shape=[2, 1])
      box=tf.concat([const_, box], 1)

   return box 

boxes_=tf.map_fn(lambda x: (bbox_organize(x[0], x[1])), (boxes, rows), dtype=""float32"")
print(boxes_)
</code></pre>
",2019-11-03 13:24:23,2467772,7142,https://stackoverflow.com/questions/58680578,Documentation Replicability
58699961,Problem of predicting with a loaded tensorflow estimator trained beforehand,"<p>I had trained a tensorflow NN estimator to predict something in Python. And I saved the model in my Google drive via Google colab.</p>

<p>Today, I loaded the model and it was a pretty hard work. I finally succeeded to load the estimator using <code>tf.compat.v2.saved_model.load</code> and <code>.signature</code> method. it seems WrappedFunction. This is my code till this step.</p>

<ol>
<li>code for saving</li>
</ol>

<pre><code>serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(
  tf.feature_column.make_parse_example_spec(input_column))
#tf.feature_column.make_parse_example_spec([input_column]))
export_path = dnn_regressor.export_saved_model('/content/gdrive/My Drive',serving_input_fn)
#https://www.tensorflow.org/guide/saved_model#savedmodel%EC%9D%98_%EC%A0%9C%EC%96%B4_%ED%9D%90%EB%A6%84
</code></pre>

<ol start=""2"">
<li>code for loading</li>
</ol>

<pre><code>imported = tf.compat.v2.saved_model.load('/content/gdrive/My Drive/1572596260', tags=None)
infer = imported.signatures[""predict""]
</code></pre>

<p>But still I fail to put a test data to model to make a prediction.</p>

<p>first, I tried:</p>

<pre><code>test_predictions = infer(test_data)
test_predictions = np.array([item['predictions'][0] for item in test_predictions])
</code></pre>

<p>And it return an error</p>

<blockquote>
  <p>ValueError: All inputs to <code>ConcreteFunction</code>s must be Tensors; on invocation >of pruned, the 0-th input ( My data [2513 rows x 45 columns]) was not a >Tensor.</p>
</blockquote>

<p>Secondly, looked for some tensorflow document, I wrote this code</p>

<pre><code>test_predictions = infer(tf.constant(test_data))
test_predictions = np.array([item['predictions'][0] for item in test_predictions])
</code></pre>

<p>This time it return</p>

<blockquote>
  <p>The argument 'examples' (value Tensor(""Const_10:0"", shape=(2513, 45), >dtype=float64)) is not compatible with the shape this function was traced >with. Expected shape (?,), but got shape (2513, 45).</p>
  
  <p>If you called get_concrete_function, you may need to pass a >tf.TensorSpec(..., shape=...) with a less specific shape, having None on axes >which can vary.</p>
</blockquote>

<p>I found dynamic/static shape of tensorflow. But I couldn't fully understand those concept and failed to reshaping.
How can I get the result? Thanks.</p>
",2019-11-04 19:36:30,10541065,23,https://stackoverflow.com/questions/58699961,Documentation Ambiguity
58802573,Pre processing keras dataset using keras tokenizer,"<p>I am trying to do some pre processing using the keras tokenizer on data I read using the following code:</p>

<pre><code> dataset = tf.data.Dataset.from_tensor_slices(filenames)
    dataset = dataset.interleave(lambda x:
        tf.data.TFRecordDataset(x).prefetch(params.num_parallel_readers),
                                     cycle_length=params.num_parallel_readers,
                                     block_length=1)
        dataset = dataset.map(_parse_example, num_parallel_calls = params.num_parallel_calls)
</code></pre>

<p>Now that I have the parsed example (output of _parse_example map function) I want to do some pre-processing on the text using <code>tf.keras.preprocessing.text.Tokenizer</code> method <code>texts_to_sequences</code>.
However, texts_to_sequences expects an input of python strings and I get Tensors in the parsed_example.</p>

<p>I can work around it by using <code>py_func</code> to wrap my code (see <strong>'emb': tf.py_func..</strong> in the code below), but then I will not be able to serialize my model (according to the <code>py_func</code> documentation).</p>

<pre><code>dataset = dataset.map(lambda features, labels: 
                              ({'window': features['window'],
                                'winSize': features['winSize'],
                                'LandingPage': features['LandingPage'],
                                'emb': tf.py_func(getEmb, [features['window']], tf.int32)},
                                tf.one_hot(labels, hparams.numClasses) ))
</code></pre>

<p>Looking for a way to do that (or a link to some similar example)</p>
",2019-11-11 13:43:48,6092553,453,https://stackoverflow.com/questions/58802573,Lack of Alternative Solutions/Documentation
58818679,Why a model using tf.py_function can not be serialized?,"<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer"">documentation</a> of ty.py_function a model using it can't be serialized.</p>

<blockquote>
  <p>The body of the function (i.e. func) will not be serialized in a GraphDef. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</p>
</blockquote>

<p>Why is serialization not possible?</p>

<p>I was looking for an explanation to why this is the case and alternatives to using tf.py_function but did not find helpful ones.</p>

<p>In my specific case I want to use the Keras Tokenizer and its methods expect numpy arrays - so I am calling it using tf.py_function.</p>
",2019-11-12 12:22:53,6092553,453,https://stackoverflow.com/questions/58818679,Lack of Alternative Solutions/Documentation
58822319,How to use tfa.seq2seq.BahdanauAttention with tf.keras functional API?,"<p>I want to use <a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/BahdanauAttention"" rel=""nofollow noreferrer""><code>tfa.seq2seq.BahdanauAttention</code></a> with functional API of <code>tf.keras</code>. I have looked at the example given at <a href=""https://github.com/tensorflow/nmt/blob/master/nmt/attention_model.py"" rel=""nofollow noreferrer"">tensorflow/nmt/attention_model.py</a>. But I couldn't figure out how to use it with <code>tf.keras</code>'s functional API.</p>

<p>So I would like to use <code>tfa.seq2seq.BahdanauAttention</code> for a lipreading task, something like this:</p>

<pre class=""lang-py prettyprint-override""><code>
    # Using tf.keras functional API
    encoder_out = a tensor of shape (batch_size, time_steps, units)
    decoder_out = a tensor of shape (batch_size, time_steps, units)
    attn_out = attention_mechanism()(encoder_out, decoder_out)  # Need help figuring this out

</code></pre>

<p>Thanks in advance.</p>
",2019-11-12 15:58:17,7618706,41,https://stackoverflow.com/questions/58822319,Documentation Ambiguity
58828768,Do I need to switch between tensorflow and numpy?,"<p>Data set is numpy set. Some tutorial said: because it is needed to in advantage of GPU, we should change numpy array to tensorflow tensor. And then use tensorflow model.</p>

<p>But after training, some code use numpy function to test and interactive. But the code in tensorflow official tutorial still use the same tensorflow model and tf.dataset to test.
I want to know:
When testing or real time apply, should I use numpy or tensorflow tensor and model?
In other words, is there some bad influences using tensorflow tensor and function if not traing? </p>

<p>eg.:
we use selected_words =tf.argsort(o_j) </p>

<p>in stead of</p>

<p>selected_words = np.argsort(o_j)</p>
",2019-11-13 00:46:36,7241796,2041,https://stackoverflow.com/questions/58828768,Documentation Replicability
58842107,How do I update a model using a pre-release version of Tensorflow to run in a Google Colab instance?,"<p>I'm trying to use the <a href=""https://github.com/google-research-datasets/wiki-reading"" rel=""nofollow noreferrer"">WikiReading</a> dataset and model in a project and train it using a Google Colaboratory instance. For that purpose, I'm adapting the code to a Jupyter Notebook, which also uses a more recent version of Tensorflow than the provided baseline Bag of Words model did. The original paper and accompanying baseline model was published in August 2016, which predates Tensorflow 1.0.0.</p>

<p>I've gone some way towards the process of updating the model to Tensorflow v1.x, but I appear to have hit a roadblock. From my (fairly limited) understanding, the last step in the model is to apply a softmax function on the results. In the original model, this was done using the following function call:</p>

<pre><code>softmax, loss = tf.contrib.learn.ops.softmax_classifier(
        joint_enc, answers, answer_embeddings, answer_biases)
</code></pre>

<p>This is then used in this statement for the optimization:</p>

<pre><code>train_op = tf.contrib.layers.optimize_loss(
        loss, tf.contrib.framework.get_global_step(),
        learning_rate=LEARNING_RATE,
        optimizer='Adam')
</code></pre>

<p>I can't seem to find any documentation relating to the <code>tf.contrib.learn.ops.softmax_classifier()</code> function online. I'm assuming it takes in 4 tensors in some order, most likely something like the first holds the batch to classify, the second one holds a list of the answers to predict with the 3rd and 4th holding the embedding and biases for each answer.</p>

<p>My problem is that I cannot find a function that maps neatly to that format with the same output and I'm not sure what transformations to apply to my tensors to get a similar result using something like <code>tf.nn.softmax()</code> without access to the documentation of <code>tf.contrib.learn.ops.softmax_classifier()</code>. How should I go about tackling this problem? Should I just rewrite the model_fcn()?</p>

<h2>Original model_fn()</h2>

<pre class=""lang-py prettyprint-override""><code>def bow_model(features, target):
    document = utils.prune_out_of_vocab_ids(features['document_sequence'], VOCAB_SIZE)
    question = utils.prune_out_of_vocab_ids(features['question_sequence'], VOCAB_SIZE)
    answers = tf.squeeze(tf.one_hot(target, ANSWER_NUM, 1.0, 0.0),
                         squeeze_dims=[1])
    embeddings = tf.get_variable('embeddings', [VOCAB_SIZE, EMBED_DIM])
    doc_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], document, None, combiner='sum')
    question_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], question, None, combiner='sum')
    joint_enc = tf.concat(1, [doc_enc, question_enc])
    answer_embeddings = tf.get_variable(
        'answer_embeddings', [ANSWER_DIM, ANSWER_NUM])
    answer_biases = tf.get_variable('answer_biases', [ANSWER_NUM])
    softmax, loss = learn.ops.softmax_classifier(
        joint_enc, answers, answer_embeddings, answer_biases)
    train_op = layers.optimize_loss(
        loss, tf.contrib.framework.get_global_step(),
        learning_rate=LEARNING_RATE,
        optimizer='Adam')
    return softmax, loss, train_op
</code></pre>

<h2>Partially updated model_fn():</h2>

<pre class=""lang-py prettyprint-override""><code>def bow_model(features, labels, mode):
    document = prune_out_of_vocab_ids(features['document_sequence'], VOCAB_SIZE)
    question = prune_out_of_vocab_ids(features['question_sequence'], VOCAB_SIZE)

    answers = tf.squeeze(tf.one_hot(labels, ANSWER_NUM, 1.0, 0.0))

    embeddings = tf.get_variable('embeddings',
                                 [VOCAB_SIZE, EMBED_DIM])
    answer_embeddings = tf.get_variable('answer_embeddings',
                                        [ANSWER_DIM, ANSWER_NUM])
    answer_biases = tf.get_variable('answer_biases',
                                    [ANSWER_NUM])

    doc_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], document, None, combiner='sum')
    question_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], question, None, combiner='sum')
    joint_enc = tf.concat(axis=1, values=[doc_enc, question_enc])

    # softmax, loss = tf.contrib.learn.ops.softmax_classifier(
    #     joint_enc, answers, answer_embeddings, answer_biases)
    # replaced by:
    logits = tf.nn.xw_plus_b(doc_enc, answer_embeddings, answer_biases)
    softmax = tf.nn.softmax(logits)
    loss = tf.losses.softmax_cross_entropy(onehot_labels=answers,
                                           logits=logits,
                                           weights=answer_embeddings)

    train_op = layers.optimize_loss(
        loss, tf.train.get_global_step(),
        learning_rate=LEARNING_RATE,
        optimizer='Adam')

    return learn.EstimatorSpec(mode=mode,
                               predictions=softmax,
                               loss=loss,
                               train_op=train_op)
</code></pre>

<h2>Original input_fn():</h2>

<pre class=""lang-py prettyprint-override""><code>def get_wikireading_input():
    filename = ""../train-*""
    feature_info = {k: tf.VarLenFeature(dtype=tf.int64) for k in SPARSE_FEATURES}
    feature_info['answer_ids'] = tf.VarLenFeature(dtype=tf.int64)
    def input_fn():
        features = learn.read_batch_features(
            filename, BATCH_SIZE, feature_info,
            reader=tf.TFRecordReader)
        target = features.pop('answer_ids')
        target = utils.resize_axis(tf.sparse_tensor_to_dense(target), 1, 1)
        return features, target
    return input_fn
</code></pre>

<h2>Updated input_fn()</h2>

<pre class=""lang-py prettyprint-override""><code>def input_fn():
    features = {'document_sequence': tf.VarLenFeature(dtype=tf.int64),
                'question_sequence': tf.VarLenFeature(dtype=tf.int64),
                'answer_ids': tf.VarLenFeature(dtype=tf.int64)}

    files = tf.data.Dataset.list_files(file_pattern=filename)
    dataset = files.interleave(tf.data.TFRecordDataset,
                          cycle_length=AUTOTUNE,
                          num_parallel_calls=AUTOTUNE)

    def parse_fn(serialized):
        example = tf.io.parse_single_sequence_example(serialized=serialized,
                                                      sequence_features=features)[1]
        labels = example.pop('answer_ids')
        labels = resize_axis(tf.sparse_tensor_to_dense(labels), 1, 1)
        return example, labels

    dataset = dataset.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)
    dataset = dataset.batch(batch_size=BATCH_SIZE)
    dataset = dataset.shuffle(buffer_size=BATCH_SIZE)
    dataset = dataset.prefetch(buffer_size=AUTOTUNE)
    return dataset
</code></pre>

<p>The full Jupyter notebook can be accessed <a href=""https://github.com/ThierrySt-Arnaud/wiki-reading/blob/colab-conversion/colab/wiki_reading_training_en.ipynb"" rel=""nofollow noreferrer"">here</a></p>

<h2>Edit:</h2>

<p>I have found the source for the mentioned function <a href=""https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/contrib/learn/python/learn/ops/losses_ops.py"" rel=""nofollow noreferrer"">here</a>. The deprecation warning  says this about updating this function:</p>

<blockquote>
  <p>'Use <code>tf.losses.softmax_cross_entropy</code> and explicit logits computation.'</p>
</blockquote>

<p>Now, I'm replicating the operations of this function as follows:</p>

<pre class=""lang-py prettyprint-override""><code>  logits = tf.nn.xw_plus_b(doc_enc, answer_embeddings, answer_biases)
  softmax = tf.nn.softmax(logits)
  loss = tf.losses.softmax_cross_entropy(answers, logits, answer_embeddings)
</code></pre>

<p>but this gives me:</p>

<blockquote>
  <p>ValueError Dimensions must be equal, but are 20 and 40 for 'xw_plus_b/MatMul' (op: 'BatchMatMulV2') with input shapes: [?,?,20], [40,5000].</p>
</blockquote>

<p>This makes perfect sense when I look at the constant definitions:</p>

<pre class=""lang-py prettyprint-override""><code>VOCAB_SIZE = 10000
EMBED_DIM = 20
ANSWER_DIM = 2 * EMBED_DIM
ANSWER_NUM = 5000
BATCH_SIZE = 128
LEARNING_RATE = 0.01
HIDDEN_SIZE = 128
</code></pre>

<p>I guess my questions now are:</p>

<ul>
<li>Why is ANSWER_NUM and ANSWER_DIM not equal to VOCAB_SIZE and EMBED_DIM, respectively? Shouldn't they have the same size?</li>
<li>How could this have worked before?</li>
</ul>

<h3>Edit 2:</h3>

<p>As I try to update and train this model, I have grown more and more confused by the way it is defined. This is largely due to my inexperience with machine learning in general and TensorFlow in particular, but there are some things that don't make sense, at least to me. I have adjusted the ANSWER_NUM and ANSWER_DIM as I mention above and updated other functions and parameters (seen in the updated model_fn above) which gives me a valid data graph but the following error when trying to fit:</p>

<blockquote>
  <p>(0) Invalid argument: assertion failed: [weights can not be broadcast to values.] [weights.shape=] [answer_embeddings/read:0] [20 10000] [values.shape=] [softmax_cross_entropy_loss/xentropy/Reshape_2:0] [128 0] [is_scalar=] [0]</p>
</blockquote>

<p>This probably just requires a formatting step (that I'm not entirely sure of yet) before feeding running softmax_cross_entropy(). However, I also noticed that there is no definition of the hidden layers anywhere in the original model and HIDDEN_SIZE is unused. Is there an implicit definition of those layers somewhere in the model that I'm missing?</p>

<p>At this point, I feel like it will be easier to just use a Keras functional model in TensorFlow 2.x to get as close as possible to the <em>perceived</em> original model.</p>
",2019-11-13 17:03:05,12367101,21,https://stackoverflow.com/questions/58842107,Lack of Alternative Solutions/Documentation
58867494,"tf2.0: tf.image.resize_with_pad fails with ""using a `tf.Tensor` as a Python `bool"" with tf.keras.Input","<p>With <code>tensorflow 2.0</code>, <code>resize_with_pad</code> does not seem to work when <code>tf.keras.Input</code> is given as an input, but <code>resize</code> works nicely. For example,</p>

<pre><code>import tensorflow as tf

# with tensorflow constant
img_arr = tf.zeros([1,100,100,3])
tf.image.resize(img_arr, [224, 224]) # works
tf.image.resize_with_pad(img_arr, 224, 224) # works

# with keras input
img_arr = tf.keras.Input(shape = (100,100,3))
tf.image.resize(img_arr, [224, 224]) # works
tf.image.resize_with_pad(img_arr, 224, 224) # doesn't work
</code></pre>

<p>throws an error</p>

<pre><code>---------------------------------------------------------------------------
OperatorNotAllowedInGraphError            Traceback (most recent call last)
&lt;ipython-input-29-aee2cbd13944&gt; in &lt;module&gt;
      9 img_arr = tf.keras.Input(shape = (100,100,3))
     10 tf.image.resize(img_arr, [224, 224]) # works
---&gt; 11 tf.image.resize_with_pad(img_arr, 224, 224) # doesn't work

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in resize_image_with_pad_v2(image, target_height, target_width, method, antialias)
   1472 
   1473   return _resize_image_with_pad_common(image, target_height, target_width,
-&gt; 1474                                        _resize_fn)
   1475 
   1476 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _resize_image_with_pad_common(image, target_height, target_width, resize_fn)
   1337       raise ValueError('\'image\' must have either 3 or 4 dimensions.')
   1338 
-&gt; 1339     assert_ops = _CheckAtLeast3DImage(image, require_static=False)
   1340     assert_ops += _assert(target_width &gt; 0, ValueError,
   1341                           'target_width must be &gt; 0.')

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _CheckAtLeast3DImage(image, require_static)
    226         check_ops.assert_positive(
    227             array_ops.shape(image),
--&gt; 228             [""all dims of 'image.shape' ""
    229              'must be &gt; 0.']),
    230         check_ops.assert_greater_equal(

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_positive(x, data, summarize, message, name)
    266           'x (%s) = ' % name, x]
    267     zero = ops.convert_to_tensor(0, dtype=x.dtype)
--&gt; 268     return assert_less(zero, x, data=data, summarize=summarize)
    269 
    270 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_less(x, y, data, summarize, message, name)
    865       ]
    866     condition = math_ops.reduce_all(math_ops.less(x, y))
--&gt; 867     return control_flow_ops.Assert(condition, data, summarize=summarize)
    868 
    869 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/util/tf_should_use.py in wrapped(*args, **kwargs)
    196   """"""
    197   def wrapped(*args, **kwargs):
--&gt; 198     return _add_should_use_warning(fn(*args, **kwargs))
    199   return tf_decorator.make_decorator(
    200       fn, wrapped, 'should_use_result',

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py in Assert(condition, data, summarize, name)
    147   """"""
    148   if context.executing_eagerly():
--&gt; 149     if not condition:
    150       xs = ops.convert_n_to_tensor(data)
    151       data_str = [_summarize_eager(x, summarize) for x in xs]

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in __bool__(self)
    763       `TypeError`.
    764     """"""
--&gt; 765     self._disallow_bool_casting()
    766 
    767   def __nonzero__(self):

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_bool_casting(self)
    532     else:
    533       # Default: V1-style Graph execution.
--&gt; 534       self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
    535 
    536   def _disallow_iteration(self):

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_in_graph_mode(self, task)
    521     raise errors.OperatorNotAllowedInGraphError(
    522         ""{} is not allowed in Graph execution. Use Eager execution or decorate""
--&gt; 523         "" this function with @tf.function."".format(task))
    524 
    525   def _disallow_bool_casting(self):

OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
</code></pre>
",2019-11-14 22:31:22,6476080,1231,https://stackoverflow.com/questions/58867494,Documentation Replicability
58867635,Build tensorflow dataset with datasource as database,"<p>I have to create a data input pipeline with tensorflow tf.data. The datasource is a mongodb and sql server.  How can I create a tf.data object from a database. All the articles I see have .tfrecords or .csv as datasource for tensorflow.</p>

<p>Thank you.
Appreciate your inputs</p>
",2019-11-14 22:42:49,11093016,11,https://stackoverflow.com/questions/58867635,Documentation Replication on Other Examples
58877056,why not use tensor or tf.data in tensorflow official tutorial?,"<p>I fond the example just use numpy array as input(<a href=""https://www.tensorflow.org/tutorials/keras/classification"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/keras/classification</a>).</p>

<p>Why not change numpy array to tensorflow tensor or tf.data? If both are ok, why need tensorflow tensor?</p>
",2019-11-15 12:25:59,7241796,2041,https://stackoverflow.com/questions/58877056,Documentation Replication on Other Examples
58912135,Performance drawback of tf.numpy_function?,"<p>I'm using a <code>tf.numpy_function</code> to load a file in my tensorflow program.</p>

<p>I can't find sufficient information about the drawbacks of using numpy_function, would there be enough that it's worth the trouble of passing this function to tensorflow compatible code ?</p>

<p>Thanks a lot</p>
",2019-11-18 10:09:55,4064248,407,https://stackoverflow.com/questions/58912135,Documentation Replicability
58963043,What is the difference between tf.keras.metrics.Accuracy and tf.keras.metrics.BinaryAccuracy?,"<p>It seems I can't use <code>tf.keras.metrics.Accuracy</code> instead of <code>tf.keras.metrics.BinaryAccuracy</code>. Why is that?</p>

<p>I have a <code>trainer</code> based on <a href=""https://www.tensorflow.org/tutorials/images/transfer_learning"" rel=""nofollow noreferrer"">this tutorial</a>:</p>

<pre><code>&gt;&gt;&gt;tf.random.set_seed(42)
&gt;&gt;&gt;trainer = CatDogTrainer(initial_epochs=1, model_type='mobile_net')
&gt;&gt;&gt;trainer.metrics
[&lt;tensorflow.python.keras.metrics.BinaryAccuracy at 0x7f2fcc7f72e8&gt;]
&gt;&gt;&gt;trainer.train()
582/582 [==============================] - 55s 94ms/step - loss: 1.8132 - binary_accuracy: 0.7372 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00

&gt;&gt;&gt;tf.random.set_seed(42)
&gt;&gt;&gt;trainer = CatDogTrainer(initial_epochs=1, model_type='mobile_net')
&gt;&gt;&gt;trainer.metrics
[&lt;tensorflow.python.keras.metrics.Accuracy at 0x7f0dfd4f8be0&gt;]
&gt;&gt;&gt;trainer.train()
ValueError: Shapes (None, 2) and (None, 1) are incompatible
</code></pre>

<p>I'm also able to train with <code>metrics=['accuracy']</code>. What class does <code>tf</code> use in this case? By the way <code>tf.keras.metrics.Accuracy</code> has an attribute <code>name</code> which is <code>accuracy</code>.</p>
",2019-11-20 20:41:24,2047442,2271,https://stackoverflow.com/questions/58963043,Documentation Replicability
58963513,TypeError: Cannot convert provided value to EagerTensor. Provided value: 0.0 Requested dtype: int64,"<p>I am trying to train the transformer model available from the tensorflow official models. I am able to train in cpu without any error but when I try gpu I get the following error:</p>

<pre><code>models/official/transformer/v2/transformer.py:143 call  *
    encoder_outputs = self.encode(inputs, attention_bias, training)

models/official/transformer/v2/transformer.py:166 encode
    embedded_inputs = self.embedding_softmax_layer(inputs)

TypeError: Cannot convert provided value to EagerTensor. Provided value: 0.0 Requested dtype: int64
</code></pre>

<p>I tried tf.cast but it doesn't seem to help. </p>
",2019-11-20 21:16:54,8258005,109,https://stackoverflow.com/questions/58963513,Documentation Replicability
58963793,ValueError: Shapes must be equal rank in assign_add(),"<p>I am reading <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">tf.Variable in Tensorflow r2.0</a> in TF2: </p>

<pre><code>import tensorflow as tf

# Create a variable.
w = tf.constant([1, 2, 3, 4], tf.float32, shape=[2, 2])

# Use the variable in the graph like any Tensor.
y = tf.matmul(w,tf.constant([7, 8, 9, 10], tf.float32, shape=[2, 2]))
v= tf.Variable(w)
# The overloaded operators are available too.
z = tf.sigmoid(w + y)
tf.shape(z)
# Assign a new value to the variable with `assign()` or a related method.
v.assign(w + 1)
v.assign_add(tf.constant([1.0, 21]))
</code></pre>

<blockquote>
  <p>ValueError: Shapes must be equal rank, but are 2 and 1 for
  'AssignAddVariableOp_4' (op: 'AssignAddVariableOp') with input shapes:
  [], <a href=""https://youtu.be/Up9CvRLIIIw?t=113"" rel=""nofollow noreferrer"">2</a>.</p>
</blockquote>

<p>And also how come the following returns false?</p>

<pre><code>tf.shape(v) == tf.shape(tf.constant([1.0, 21],tf.float32))
</code></pre>

<p>My other question is that when we are in TF 2, we should not use tf.Session() anymore, correct? It seems <a href=""https://youtu.be/Up9CvRLIIIw?t=113"" rel=""nofollow noreferrer"">we should never run session.run()</a>, but the API document keys doing it with tf.compat.v1, etc. So why they are using it in TF2 docs?</p>

<p>Any help would be appreciated.</p>

<p>CS</p>
",2019-11-20 21:39:48,2277812,761,https://stackoverflow.com/questions/58963793,Documentation Completeness
59056872,Why class name change after saving a keras model?,"<p>i wrote a basic keras model (tf.keras.__version = 2.2.4-tf) using tensorflow (2.0.0) :</p>

<pre><code>import tensorflow as tf

model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(1, activation='linear',input_shape=(1,),name='equation'))
model.compile(optimizer='RMSprop', loss='mean_squared_error')
model.save('c:\\tmp\\oneneuron')
print(""Model saved type : "", type(model))
loaded_model = tf.keras.models.load_model('c:\\tmp\\oneneuron')
print(""Model loaded type : "", type(loaded_model))
print(""compare object model with loaded_model type : "",isinstance(model,type(loaded_model)))
print(""compare object loaded_model with model type : "",isinstance(loaded_model,type(model)))
print(""compare sublclass loaded_model and model type : "",issubclass(type(loaded_model),type(model)))
</code></pre>

<p>Results are </p>

<pre><code>Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; exec(open(r'C:\tmp\myPython\test_type_model.py').read())
2019-11-26 18:49:39.071088: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-11-26 18:49:39.574113: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING: Logging before flag parsing goes to stderr.
W1126 18:49:39.627490 11772 deprecation.py:506] From F:\Program Files\Python\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model saved type :  &lt;class 'tensorflow.python.keras.engine.sequential.Sequential'&gt;
Model loaded type :  &lt;class 'tensorflow.python.keras.saving.saved_model.load.Sequential'&gt;
compare object model with loaded_model type :  False
compare object loaded_model with model type :  True
compare sublclass loaded_model and model type :  True
</code></pre>

<p>Where can I find the difference between tensorflow.python.keras.saving.saved_model.load.Sequential and tensorflow.python.keras.engine.sequential.Sequential in tensorflow or keras documentation?</p>
",2019-11-26 17:59:32,5128148,613,https://stackoverflow.com/questions/59056872,Lack of Alternative Solutions/Documentation
59131008,Most scalable way for using generators with tf.data ? tf.data guide says `from_generator` has limited scalability,"<p>tf.data has a <code>from_generator</code> initializer, it doesn't seem like it's scalable. From the official guide</p>

<blockquote>
  <p>Caution: While this is a convienient approach it has limited
  portability and scalibility. It must run in the same python process
  that created the generator, and is still subject to the Python GIL.</p>
</blockquote>

<p><a href=""https://www.tensorflow.org/guide/data#consuming_python_generators"" rel=""noreferrer"">https://www.tensorflow.org/guide/data#consuming_python_generators</a></p>

<p>And in the official documentation</p>

<blockquote>
  <p>NOTE: The current implementation of Dataset.from_generator() uses
  tf.numpy_function and inherits the same constraints. In particular, it
  requires the Dataset- and Iterator-related operations to be placed on
  a device in the same process as the Python program that called
  Dataset.from_generator(). The body of generator will not be serialized
  in a GraphDef, and you should not use this method if you need to
  serialize your model and restore it in a different environment.</p>
  
  <p>NOTE: If generator depends on mutable global variables or other
  external state, be aware that the runtime may invoke generator
  multiple times (in order to support repeating the Dataset) and at any
  time between the call to Dataset.from_generator() and the production
  of the first element from the generator. Mutating global variables or
  external state can cause undefined behavior, and we recommend that you
  explicitly cache any external state in generator before calling
  Dataset.from_generator().</p>
</blockquote>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator</a></p>

<p>However, generators are the a fairly common method in training over very large amounts of data. So there must be some alternative best practice for this, but the official Tensorflow data guide doesn't not give any information on this. </p>
",2019-12-01 23:37:38,3259896,5853,https://stackoverflow.com/questions/59131008,Lack of Alternative Solutions/Documentation
59142986,serving_input_receiver_fn() function without the deprecated tf.placeholder method in TF 2.0,"<p>I have a functioning tf.estimator pipeline build in TF 1, but now I made the decision to move to TF 2.0, and I have problems in the end of my pipeline, when I want to save the model in the .pb format</p>

<p>I'm using this high level estimator export_saved_model method:</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesRegressor#export_saved_model"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesRegressor#export_saved_model</a></p>

<p>I have two numeric features, 'age' and 'time_spent'</p>

<p>They're defined using tf.feature_column as such: </p>

<pre><code>age = tf.feature_column.numeric_column('age')
time_spent = tf.feature_column.numeric_column('time_spent')

features = [age,time_spent]
</code></pre>

<p>After the model has been trained I turn the list of features into a dict using the method feature_column_make_parse_example_spec()  and feed it to another method build_parsing_serving_input_receiver_fn() excactly as outlied on tensorflow's webpage, <a href=""https://www.tensorflow.org/guide/saved_model"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/saved_model</a> under estimators. </p>

<pre><code>columns_dict = tf.feature_column_make_parse_example_spec(features)
input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(columns_dict)
model.export_saved_model(export_dir,input_receiver_fn)
</code></pre>

<p>I then inspect the output using the CLI tools</p>

<pre><code>saved_model_cli show --dir mydir --all: 
</code></pre>

<p>Resulting in the following: </p>

<p><a href=""https://i.stack.imgur.com/vL8Qh.png"" rel=""nofollow noreferrer"">enter image description here</a></p>

<p>Somehow Tensorflow squashes my two usefull numeric features into a useless string input crap called ""inputs"". </p>

<p>In TF 1 this could be circumvented by creating a custom input_receiver_fn() function using some tf.placeholder method, and I'd get the correct output with two distinct numeric features. But tf.placeholder doesn't exist in TF 2, so now it's pretty useless. </p>

<p>Sorry about the raging, but Tensorflow is horribly documented, and I'm really working with high level API's and it should just be straight out on the horse, but no. </p>

<p>I'd really appreciate any help :)</p>
",2019-12-02 16:27:32,12453038,11,https://stackoverflow.com/questions/59142986,Documentation Ambiguity
59166678,"In tf.function, how to convert dynamic tensor shape getted by tf.shape() to python values but not tensors itself?","<p>I have a padded batch from tf.dataset, because every padded batch's shape is not fixed.So I have to use tf.shape method to get the dynamic shape of padded batch.The question is how can I convert the tensor shape getted by tf.shape to python values under tf.function?</p>

<pre><code>@tf.function
def train_step(padded_batch):
    shape = tf.shape(padded_batch)
    x = np.zeros(shape[0], shape[1])
</code></pre>

<p>As the above code, I want to create a numpy array as the same shape of padded_batch，but 'shape' is a tensor, it can't be used directly in numpy.If there is someway to convert tensor to python values under tf.function.</p>

<p>The tensorflow version I use is tf2.0</p>
",2019-12-03 23:00:55,12476733,41,https://stackoverflow.com/questions/59166678,Documentation Replication on Other Examples
59174710,default tf.gradients in TensorFlow - total or partial derivatives?,"<p>so I'm reading about tf.gradients() in the documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/gradients</a>) and I'm a bit confused.</p>

<p>I've seen people stating that the results of tf.gradients() are </p>

<blockquote>
  <p>symbolic partial derivatives of sum of ys w.r.t. x in xs.</p>
</blockquote>

<p>This is also what I was thinking first. But then the documentation describes one optional arguments of this function as follows:</p>

<blockquote>
  <p>stop_gradients is a Tensor or a list of tensors to be considered constant with respect to all xs. These tensors will not be backpropagated through, as though they had been explicitly disconnected using stop_gradient. Among other things, this allows computation of partial derivatives as opposed to total derivatives. </p>
</blockquote>

<p>So is it only possible to calculate the partial derivatives if I use 'stop_gradient' and otherwise the default values returned in a vector with len(xs) are total derivatives? Probably it's just my misunderstanding, it would be much appreciated if someone could elaborate on this a bit.</p>

<p>Thanks a lot!</p>
",2019-12-04 11:13:55,10274289,11,https://stackoverflow.com/questions/59174710,Requesting (Additional) Documentation/Examples
59177677,Custom aggregation for tf.GradientTape().gradient? (TF2.0),"<p>As far as I know, the tf.gradients function provides option to choose the aggregation method for summarizing the gradients from multiple sources.
<a href=""https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/gradients</a></p>

<p>However according to the Tensorflow API documentation, the tf.GradientTape().gradient method has no such option.
<a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/GradientTape</a></p>

<p>So my questions are as follows:</p>

<ol>
<li><p>Is there any way to change the aggregation method in tf.GradientTape().gradient?</p></li>
<li><p>If not, is there any way to obtain the gradient with a custom aggregation method which is compatible with eager execution?</p></li>
</ol>
",2019-12-04 13:56:29,7386954,360,https://stackoverflow.com/questions/59177677,Documentation Ambiguity
59268676,"How to implement a tensorflow2 layer, tf.nn.conv1d_transpose inside a keras model architecture?","<p>I need to use Transpose Conv1D layer which keras don't have yet , but tensorfow2 does . Till now i can only code in keras. Is there any way to implement a tf.nn.conv1d_transpose layer directly in a keras model along with other keras layers?</p>

<p>Please provide some sample code.</p>
",2019-12-10 13:48:00,8525083,33,https://stackoverflow.com/questions/59268676,Inadequate Examples
59299060,TF 2.0 while_loop and parallel_iterations,"<p>I am trying to use <code>tf.while_loop</code> to run loops in parallel. However, in the following toy examples,loops don't appear to be running in parallel. </p>

<pre><code>iteration = tf.constant(0)
c = lambda i: tf.less(i, 1000)
def print_fun(iteration):
    print(f""This is iteration {iteration}"")
    iteration+=1
    return (iteration,)
r = tf.while_loop(c, print_fun, [iteration], parallel_iterations=10)
</code></pre>

<p>Or</p>

<pre><code>i = tf.constant(0)
c = lambda i: tf.less(i, 1000)
b = lambda i: (tf.add(i, 1),)
r = tf.while_loop(c, b, [i])
</code></pre>

<p>What is preventing the <code>tf.while_loop</code> from parallelizing the loop?</p>

<p>In addition, if anyone who maintain the Tensorflow documentation see this page, he/she should fix the bug in the first example. See the discussion <a href=""https://github.com/tensorflow/tensorflow/issues/18257"" rel=""nofollow noreferrer"">here</a>.</p>

<p>Thanks.</p>
",2019-12-12 06:42:57,12483081,51,https://stackoverflow.com/questions/59299060,Requesting (Additional) Documentation/Examples
59359113,"What is the use of tf.keras.backend nowadays, is it safer/more future proof to code w/ or w/o it?","<p>I understand the historical need for <code>keras.backend</code> in the long gone days of multiframework support. But now that we are talking about <code>tf.keras</code>, and since Keras is scheduled <a href=""https://twitter.com/fchollet/status/1174019142774452224"" rel=""nofollow noreferrer"">to support this toolkit only</a>, I am wondering what is today's use for <code>tf.keras.backend</code>. From what I can see, it exposes only a fraction of the functions available in <code>tf.*</code>, and evolves more slowly.</p>

<p>So, is <code>tf.keras.backend</code></p>

<ul>
<li>better be avoided, because it is an obsolete remnant of the past that is likely to be dropped in a future release?</li>
<li>or, a future-proof alternative to <code>tf.*</code> to be preferred whenever possible, because this API changes at a much slower pace than TF itself and is not going down anytime soon?</li>
<li>or something else?</li>
</ul>
",2019-12-16 14:55:33,9973879,1817,https://stackoverflow.com/questions/59359113,Documentation Replication on Other Examples
59370662,RuntimeError: Invalid quantization params for op GATHER at index 2 in subgraph 0,"<p>I use tflite convert tf.keras h5 model to tflite, and quantized model.</p>

<pre><code>    converter = tf.lite.TFLiteConverter.from_keras_model_file(h5, custom_objects=custom_objects)

    converter.representative_dataset = tf.lite.RepresentativeDataset(
        representative_dataset_gen)
    # converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
    converter.inference_input_type = tf.lite.constants.QUANTIZED_UINT8
    converter.inference_output_type = tf.lite.constants.QUANTIZED_UINT8

    tflite_model = converter.convert()
    open(""{}.tflite"".format(out), ""wb"").write(tflite_model)
</code></pre>

<p>than cause the error:
RuntimeError: Invalid quantization params for op GATHER at index 2 in subgraph 0</p>

<p>does tflite not support GATHER op? how to fix it?</p>
",2019-12-17 08:57:27,7707994,107,https://stackoverflow.com/questions/59370662,Documentation Replicability
59432671,Issue with tf.keras.backend.random_normal?,"<p>I am very new to TF2 and tried to customize the example code on the tensorflow guide documentation:</p>

<p><a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example</a></p>

<p>but my code requires the latent dimension to be =1, and my code returned the:
<strong>ValueError: The last dimension of the inputs to <code>Dense</code> should be defined. Found <code>None</code>.</strong> 
error. After trouble shooting I think the error is in the:</p>

<pre><code>class Sampling(layers.Layer):
  """"""Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.""""""

  def call(self, inputs):
    z_mean, z_log_var = inputs
    batch = tf.shape(z_mean)[0]
    dim = tf.shape(z_mean)[1]
    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon
</code></pre>

<p><strong>where tf.keras.backend.random_normal sets epsilon always to dimensions [None,None]</strong></p>

<p>Then I just copied the example from the guide (<em>reference above</em>) and set the latent dimension to 1.
For training i used the given code:</p>

<pre><code>vae = VariationalAutoEncoder(784, 64, 1)

optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())
vae.fit(x_train, x_train, epochs=3, batch_size=64)
</code></pre>

<p>same error:
<strong>ValueError: The last dimension of the inputs to <code>Dense</code> should be defined. Found <code>None</code>.</strong></p>

<p>The code works fine if latent dimension is more than 1!</p>

<p>Could somebody help me?</p>
",2019-12-21 00:32:11,12573439,53,https://stackoverflow.com/questions/59432671,Documentation Replication on Other Examples
59458980,How to print the tensorflow objects?,"<pre class=""lang-py prettyprint-override""><code>def model_fn_builder(num_labels, learning_rate, num_train_steps,
                     num_warmup_steps):
  """"""Returns `model_fn` closure for TPUEstimator.""""""
  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument
    """"""The `model_fn` for TPUEstimator.""""""

    input_ids = features[""input_ids""]
    input_mask = features[""input_mask""]
    segment_ids = features[""segment_ids""]
    label_ids = features[""label_ids""]

    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)         

    # TRAIN and EVAL
    if not is_predicting:
      (loss, predicted_labels, log_probs) = create_model(
        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)



      train_op = bert.optimization.create_optimizer(
          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)


  # Return the actual model function in the closure
  return model_fn
</code></pre>

<p>I want to print <code>label_ids</code>, <code>predicted_labels</code> and <code>log_probs</code> but I am not able achieve it using <code>tf.print</code>. </p>

<p>My model is having a very poor accuracy so i need to check it step by step. Hence I want to print the tensor objects step by step when I cal the function.
I am using <code>tf 1.15</code>.</p>
",2019-12-23 17:08:48,10900497,95,https://stackoverflow.com/questions/59458980,Documentation Replicability
59497372,Is there an alternative to tf.py_function() for custom Python code?,"<p>I have started using TensorFlow 2.0 and have a little uncertainty with regard to one aspect.</p>

<p>Suppose I have this use case: while ingesting data with the <code>tf.data.Dataset</code> I want to apply some specific augmentation operations upon some images. However, the external libraries that I am using <strong>require</strong> that the <strong>image is a numpy array</strong>, <strong>not a tensor</strong>.</p>

<p>When using <code>tf.data.Dataset.from_tensor_slices()</code>, the flowing data needs to be of type Tensor. Concrete example:</p>

<pre><code>def my_function(tensor_image):
   print(tensor_image.numpy()
   return


data = tf.data.Dataset.from_tensor_slices(tensor_images).map(my_function)
</code></pre>

<p>The code above does not work yielding an </p>

<blockquote>
  <p>'Tensor' object has no attribute 'numpy' error.</p>
</blockquote>

<p>I have read the documentation on TensorFlow 2.0 stating that if one wants to use an arbitrary python logic, one should use <code>tf.py_function</code> <strong>or only TensorFlow primitives</strong> according to:
<a href=""https://stackoverflow.com/questions/56075037/how-to-convert-tensor-to-numpy-array-in-tensorflow"">How to convert &quot;tensor&quot; to &quot;numpy&quot; array in tensorflow?</a> </p>

<p><strong>My question is the following</strong>: Is there another way to use arbitrary python code in a function with a custom decorator/an easier way than to use <code>tf.py_function</code>?</p>

<p>To me honestly it seems that there must be a more elegant way than passing to a <code>tf.py_function</code>, transforming to a numpy array, perform operations A,B,C,D and then retransform to a tensor and yield the result. </p>
",2019-12-27 07:19:50,6117017,14247,https://stackoverflow.com/questions/59497372,Lack of Alternative Solutions/Documentation
59528975,tf.estimator.predict slow with tensorflow ranking module,"<p>I'm currently using the <a href=""https://github.com/tensorflow/ranking"" rel=""nofollow noreferrer"">TensorFlow Ranking module</a> for a recommendation task. Specifically I'm modifying <a href=""https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/tf_ranking_libsvm.py"" rel=""nofollow noreferrer"">this tutorial file</a> for my own purpose. I can't say the tutorial was very friendly to new users. As this is the first time I've interacted with TensorFlow, I'm just trying to make it run.</p>

<p>As you may notice, <a href=""https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/tf_ranking_libsvm.py"" rel=""nofollow noreferrer"">the example file</a> doesn't say how to make predictions, so after I finished training the model, I modified its <a href=""https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/tf_ranking_libsvm.py#L370"" rel=""nofollow noreferrer""><code>train_and_eval()</code></a> function to predict. Here's my code.</p>

<pre><code>def _train_op_fn(loss):
        """"""Defines train op used in ranking head.""""""
        update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)
        minimize_op = optimizer.minimize(
                loss = loss, global_step = tf.compat.v1.train.get_global_step())
        train_op = tf.group([minimize_op, update_ops])
        return train_op

ranking_head = tfr.head.create_ranking_head(
        loss_fn = tfr.losses.make_loss_fn(loss),
        eval_metric_fns = get_eval_metric_fns(),
        train_op_fn = _train_op_fn
)

estimator =tf.estimator.Estimator(
        model_fn=tfr.model.make_groupwise_ranking_fn(
                group_score_fn=make_score_fn(),
                group_size = group_size,
                transform_fn=make_transform_fn(),
                ranking_head=ranking_head),
        config=tf.estimator.RunConfig(
                output_dir, save_checkpoints_steps=1000))

def predict_(feature_dict = {}):
    if feature_dict == {}:
        feature_dict = input_fn()
    pred_fn, pred_hook = get_eval_inputs(feature_dict)
    generator_ = estimator.predict(input_fn = pred_fn, hooks = [pred_hook])
    pred_list = list(generator_)

    return pred_list
</code></pre>

<p>The <code>predict_</code> function takes dictionary </p>

<pre><code>{'feature 1':[doc 1 score, doc 2 score...], 
 'feature 2':[doc 1 score, doc 2 score...], 
 ...}
</code></pre>

<p>and returns a list a scores for all docs in that order. (or at least that's what I think it should do) </p>

<p>The prediction results are very good. Problem is, it's really slow. Prediction for 400 docs takes more than 1 second (I only have 4 features). Is this a normal speed or there's space for optimization in the code? I heard <code>tf.estimator</code> reloads the graph everytime it makes a prediction, but I can't tell if it's the problem here.</p>
",2019-12-30 10:04:11,10289249,657,https://stackoverflow.com/questions/59528975,Documentation Replication on Other Examples
59609732,Equivalent tensorflow.js function for tf.compat.v1.image.resize?,"<p>I want to replicate the functionality of <code>tf.compat.v1.image.resize(inputs, [height, width], align_corners=True)</code> using tensorflow.js. What function or combination of functions in tensorflow.js would give the equivalent result as the above function?</p>
",2020-01-06 09:39:22,4906660,79,https://stackoverflow.com/questions/59609732,Documentation Replicability
59709349,How does tf.dataset interact with keras.conv1D?,"<p>I'm using tf 1.15, i'm trying to make a regression task using a signal.</p>

<p>First of all i load my signals into the pipeline, i have several files, here i simulate the loading using a np.zeros to make the code usable by you.
Every file has this shape (?, 75000, 3), where ? is a random number of elements, 75000 is the number of samples in each element and 3 is the number of signals.</p>

<p>Using the tf.data i unpack them and i get a dataset who output signals with this shape (75000,), and i use them in my keras model.</p>

<p>Everything should be fine until i create the keras model, i copied my input pipeline because during my tests i got different errors using a generic tf.data.dataset or using the dataset built in this way.</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
import tensorflow as tf

# called in the dataset pipeline
def my_func(x):
    p = np.zeros([86, 75000, 3])
    x = p[:,:,0]
    y = p[:, :, 1]
    z = p[:, :, 2]
    return x, y, z

# called in the dataset pipeline
def load_sign(path):
    func = tf.compat.v1.numpy_function(my_func, [path], [tf.float64, tf.float64, tf.float64])
    return func

# Dataset pipeline
s = [1, 2]  # here i have the file paths, i simulate it with numbers
AUTOTUNE = tf.data.experimental.AUTOTUNE  
ds = tf.data.Dataset.from_tensor_slices(s)
# ds = ds.map(load_sign, num_parallel_calls=AUTOTUNE)
ds = ds.map(load_sign, num_parallel_calls=AUTOTUNE).unbatch()
itera = tf.data.make_one_shot_iterator(ds)
ABP, ECG, PLETH = itera.get_next() 

# Until there everything should be fine
# Here i create my convolutional network
signal = tf.keras.layers.Input(shape=(None,75000), dtype='float32')
x = tf.compat.v1.keras.layers.Conv1D(64, (1), strides=1, padding='same')(signal)
x = tf.keras.layers.Dense(75000)(x)
model = tf.keras.Model(inputs=signal, outputs=x, name='resnet18')

# And finally i try to insert my signal into model
logits = model(PLETH)
</code></pre>

<p>I get this error:</p>

<blockquote>
  <p>ValueError: Input 0 of layer conv1d is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.</p>
</blockquote>

<p>Why? And how can i make it works?
Also the input size of my net should be this one according the documentation: </p>

<blockquote>
  <p>3D tensor with shape: (batch_size, steps, input_dim)</p>
</blockquote>

<p>What is the steps? In my case i assume it should be (batch_size, 1, 75000), right?</p>
",2020-01-13 00:29:54,12425142,114,https://stackoverflow.com/questions/59709349,Documentation Replication on Other Examples
59727776,[Tensorflow 2.0][Tensor value printing],"<p>We recently ported our Tensorflow1.12.0 source code to Tensorflow2.0. During debugging, we wanted to print the value of the tensors. For example, consider the following code snippet:</p>

<pre><code> def __build_model():
        input = tf.keras.Input(shape=(None, self.__input_size), name='inputs')
        dense_layer_output = tf.keras.layers.Dense(self.__output_size)(next_input)
        self.__model = tf.keras.Model(inputs=input, outputs=dense_layer_output)
</code></pre>

<p>In order to print the value of the tensor <em>input</em>, we just printed the variable using the <em>tf.print(input)</em> function according to [1] (previously just <em>print(input)</em>). So, the above code snippet can be re-written as follows:</p>

<pre><code>def __build_model():
        input = tf.keras.Input(shape=(None, self.__input_size), name='inputs')
        dense_layer_output = tf.keras.layers.Dense(self.__output_size)(next_input)
        tf.print(input)
        self.__model = tf.keras.Model(inputs=input, outputs=dense_layer_output)
</code></pre>

<p>However, the output that we observed is the tensor object, instead of the exact value of the input tensor. Can anyone help me with the syntax to print the exact tensor values, instead of the tensor object. </p>

<p>[1] <a href=""https://www.tensorflow.org/api_docs/python/tf/print?version=stable"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/print?version=stable</a></p>

<p>Thanks.</p>
",2020-01-14 05:04:57,7881422,76,https://stackoverflow.com/questions/59727776,Documentation Replicability
59729239,ConvLSTMCell in tensorflow 2,"<p>After upgrade to tensorflow version 2 from 1, all modules from tf.contrib were depreciated.</p>

<p>In order to apply <a href=""https://github.com/thushv89/attention_keras/blob/master/layers/attention.py"" rel=""nofollow noreferrer"">attention method</a>, I need every cell's state.</p>

<p>Initially, what I did in tf version 1 was:</p>

<pre><code>
#ConvLSTMCell
convlstm_layer = tf.contrib.rnn.ConvLSTMCell(
                conv_ndims = 2,    
                input_shape = [10, 10, 32],
                output_channels = 32,
                kernel_shape = [2, 2],
                use_bias = True,
                skip_connection = False,
                forget_bias = 1.0,
                initializers = None,
                )


# Run RNN with ConvLSTMCell
outputs, state = tf.compat.v1.nn.dynamic_rnn(convlstm_layer, conv1_out, time_major = False, dtype = input.dtype)
</code></pre>

<p>Now, I am trying to conver this to code in tf version 2.</p>

<p>However, as I mentioned above, both modules (tf.contrib and tf.compat) were depreciated. </p>

<p>I found the alternative of tf.compat.v1.nn.dynamic_rnn which is <strong>tf.keras.layers.rnn</strong></p>

<p>but there's no such function that creates ConvLSTMCell. Any suggestion? </p>
",2020-01-14 07:33:49,10106574,173,https://stackoverflow.com/questions/59729239,Documentation Completeness
59729634,"In tensorflow 2.0, how to compute gradients of loss to input variables?","<p>In tensorflow 2.0, tf.gradients is not supported, and GradientTape only compute gradients to trainable weights, so how to get gradients to input as TF1.0 can do?
thanks, correct me if i'm wrong.</p>
",2020-01-14 08:03:46,12708383,21,https://stackoverflow.com/questions/59729634,Documentation Ambiguity
59743351,Tensorflow 2.0.0: AttributeError: 'TensorSliceDataset' object has no attribute 'as_numpy_iterator',"<p>I am testing tensorflow <code>tf.data.Dataset</code> method <code>as_numpy_iterator</code> using <code>tensorflow 2.0.0</code>. According to the official documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#as_numpy_iterator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#as_numpy_iterator</a>, this function allows directly inspecting the content of a tensorflow dataset. But when I try the given example:</p>

<pre><code>dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) 
for element in dataset.as_numpy_iterator(): 
  print(element) 
</code></pre>

<p>There occurs an error: <code>AttributeError: 'TensorSliceDataset' object has no attribute 'as_numpy_iteractor'</code>. I am wondering if this method is just newly added, beyond the support of tensorflow 2.0.0. If so, is there an alternative to checking the dataset content as the <code>as_numpy_iterator()</code>?</p>
",2020-01-14 23:44:27,6807211,4882,https://stackoverflow.com/questions/59743351,Documentation Replicability
59772316,Multioutput model with custom losses containing dependencies with other outputs and other data,"<p>I have a model with multiple outputs,  the losses for each output can have dependencies with one of the other outputs, as well as some masks computed from the data. The overall loss of the model is a weighted sum over the losses.</p>

<p>My model is subclassing <code>tf.keras.Model</code> and I am trying to write clean code that I can use with <code>compile</code> and <code>fit</code>. I would like the weights of the losses to be given during the compile.</p>

<p>One way I have found addressing the loss dependencies issue (after reading some documentation and <a href=""https://stackoverflow.com/questions/50063613/what-is-the-purpose-of-the-add-loss-function-in-keras"">this answer</a>) is to feed the masks type of data as input of the model and, in the implementation of <code>call</code>, to add the loss of each output with <code>Model.add_loss</code>. Can someone confirm me this? How do I get <code>y_true</code> from there?</p>

<p>If this is a good solution, how do I specify that the overall model loss is a weighted sum of those losses during the <code>compile</code>, how can I access them?</p>

<p>Also would it be better to use <code>add_loss</code> on each layer in the implementation of the model's <code>call</code>? Same question, how do I access them during the <code>compile</code>?</p>

<p>If this was not a good solution, what is a good one?</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

class MyModel(tf.keras.Model):

    def __init__(self, base_trainable=False, feature_extractor=None, n=4, *kwargs):
        super(MyModel, self).__init__(*kwargs)
        if feature_extractor:
            self.feature_extractor = feature_extractor
        else:
            feature_extractor = tf.keras.applications.Resnet101(include_top=False,
                                                                weights='imagenet',
                                                                trainable=base_trainable)

        self.out1 = layers.Conv2D(n, kernel_size=(1,1), activation='sigmoid', name='out1')
        self.out2 = layers.Conv2D(n, kernel_size=(1,1), name='out2')
        self.out3 = layers.Conv2D(2*n, kernel_size=(1,1), 'out3')

    def call(self, inputs):
        img, mask1, mask2 = inputs
        x = self.feature_extractor(img)
        out1 = self.out1(x)
        out2 = self.out2(x)
        out3 = self.out3(x)
        # compute losses for each output? (but how do I access to each y_true?...)
        # ex:
        # 
        # model.add_loss(my_loss_for_out1(y1_true??
        #                                 out1,
        #                                 out2))
        # model.add_loss(my_loss_for_out1(y2_true??
        #                                 out2,
        #                                 mask1))
        # model.add_loss(my_loss_for_out1(y3_true??
        #                                 out3,
        #                                 mask2))


        return out1, out2, out3

model = MyModel()

model.compile(loss=???
              loss_weights=???)
</code></pre>

<p>Thank you</p>
",2020-01-16 14:57:39,7483509,1057,https://stackoverflow.com/questions/59772316,Documentation Replication on Other Examples
59847045,Should I use @tf.function for all functions?,"<p>An <a href=""https://www.tensorflow.org/tutorials/customization/performance"" rel=""noreferrer"">official tutorial</a> on <code>@tf.function</code> says:</p>

<blockquote>
  <p>To get peak performance and to make your model deployable anywhere,
  use tf.function to make graphs out of your programs. Thanks to
  AutoGraph, a surprising amount of Python code just works with
  tf.function, but there are still pitfalls to be wary of.</p>
  
  <p>The main takeaways and recommendations are:</p>
  
  <ul>
  <li>Don't rely on Python side effects like object mutation or list appends.</li>
  <li>tf.function works best with TensorFlow ops, rather than NumPy ops or Python primitives.</li>
  <li>When in doubt, use the for x in y idiom.</li>
  </ul>
</blockquote>

<p>It only mentions <strong>how</strong> to implement <code>@tf.function</code> annotated functions but not <strong>when</strong> to use it.</p>

<p>Is there a heuristic on how to decide whether I should at least try to annotate a function with <code>tf.function</code>? It seems that there are no reasons not to do it, unless I am to lazy to remove side effects or change some things like <code>range()</code>-> <code>tf.range()</code>. But if I am willing to do this...</p>

<p><strong>Is there any reason not to use <code>@tf.function</code> for all functions?</strong></p>
",2020-01-21 18:21:10,502727,2110,https://stackoverflow.com/questions/59847045,Requesting (Additional) Documentation/Examples
59870349,"tf.data for keras model with multiple inputs, one ctc output, ValueError","<p>I'm using tf.version '2.1.0-rc2'</p>

<p>My model has 2 inputs and 1 output and I am struggling to feed it data.</p>

<p>Example <a href=""https://keras.io/examples/image_ocr/"" rel=""nofollow noreferrer"">https://keras.io/examples/image_ocr/</a> uses a generator that output 
a dictionary of numpy arrays.</p>

<pre><code>inputs = {'the_input': X_data,
          'the_labels': labels,
          'input_length': input_length,
          'label_length': label_length,
          'source_str': source_str  # used for visualization only
          }
outputs = {'ctc': np.zeros([size])} 
return (inputs, outputs)
</code></pre>

<p>and fit_generator</p>

<pre><code>   model.fit_generator(
        generator=img_gen.next_train(),
        steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,
        epochs=stop_epoch,
        validation_data=img_gen.next_val(),
        validation_steps=val_words // minibatch_size,
        callbacks=[viz_cb, img_gen],
        initial_epoch=start_epoch)
</code></pre>

<p>but <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Model</a> indicates</p>

<blockquote>
  <p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future
  version. Instructions for updating: Please use Model.fit, which
  supports generators.</p>
</blockquote>

<p>I believe td.data is the recommended way to feed data into tf.keras.
So I would like to figure this out.</p>

<p>First, a simplified dummy model</p>

<pre><code>def why_fail(input_size, one_hot_output_size, model_output_shape):
    ''' A dummy model, to focus on issue of multiple inputs '''

    a = Input(name=""the_image_input"", shape=(320, 128, 1))
    b = Input(name=""the_book_id_input"", shape=(20,))
    print(f""the_image_input.shape = {a.shape}, the_book_id_input.shape = {b.shape}"")
    # the_image_input.shape = (None, 320, 128, 1), the_book_id_input.shape = (None, 20)

    c = Flatten()(a)
    d = Concatenate()([b, c]) # ([b, c])

    # reduce dimension to something we can make 40*xxx
    e = Dense(units=model_output_shape[1]*2)(d )
    f = Reshape( (model_output_shape[1],2) )(e)

    output_data = Dense(units=one_hot_output_size, activation=""softmax"")(f )

    print(f""into ctc output.shape = {output_data.shape}"")
    # into ctc output.shape = (None, 40, 72)

    return Model(inputs=[a,b],  outputs=output_data)
</code></pre>

<p>My generator based on tf.data</p>

<pre><code>def get_tf_dataset(height, width, batch_size, alphabet, record_limit = 10000000, partition_name=""train"", max_string_length=128, angle_in_radians=30/180*math.pi, min_percent_of_target=0.95, dataset=None, full_word_only=True, expensive_safety_checks=False, debug_dir_path=None, sample_output_path=None):

    # my data fits in memory (for now at least)
    my_data = read_dataset(alphabet, record_limit=record_limit, partition_names=[partition_name], max_string_length=max_string_length, expensive_safety_checks=expensive_safety_checks, debug_dir_path=debug_dir_path)

    def generator():
        i = 0
        while True:
            i = (i + 1) % len(my_data[partition_name][""image""])

            img = my_data[partition_name][""image""][i]
            img = kiss_image.phase_2_img_rnd_rot_rnd_size_rnd_position_rnd_noise(image=img, id=id, height=height, width=width, angle_in_radians=angle_in_radians, min_percent_of_target=min_percent_of_target, expensive_safety_checks=expensive_safety_checks, debug_dir_path=debug_dir_path )

            book_id = my_data[partition_name][""book_id""][i]
            text_as_alphabet_index = my_data[partition_name][""text_as_alphabet_index""][i]

            if len(text_as_alphabet_index) &lt;= max_string_length:

                text_as_alphabet_index_array = pad_sequences([text_as_alphabet_index], maxlen=max_string_length, padding=""post"")
                text_as_alphabet_index_array = text_as_alphabet_index_array[0]

                print(f""the_image_input.shape = {img.shape}"")
                print(f""the_book_id_input.shape = {book_id.shape}"")
                print(f""text_as_alphabet_index_array.shape = {text_as_alphabet_index_array.shape}"")

                # the_image_input.shape = (320, 128)
                # the_book_id_input.shape = (20,)
                # text_as_alphabet_index_array.shape = (18,)

                yield {""the_image_input"": img, ""the_book_id_input"": book_id}, text_as_alphabet_index_array


    dataset = tf.data.Dataset.from_generator(generator, output_types=({""the_image_input"": tf.float64, ""the_book_id_input"": tf.float64}, tf.int64))
    dataset = dataset.batch(batch_size)
    return dataset
</code></pre>

<p>Instantiate a train and validation generator from the above</p>

<pre><code>g_train = kiss_grabner.get_tf_dataset(partition_name=""train"", record_limit=1000*2*1, height=height, width=width, batch_size=batch_size, max_string_length=max_string_length, alphabet=alphabet, angle_in_radians=15/180*math.pi, full_word_only=full_word_only, min_percent_of_target=0.95, sample_output_path=sample_output_path)
g_valid = kiss_grabner.get_tf_dataset(partition_name=""valid"", record_limit=1000*2*1, height=height, width=width, batch_size=batch_size, max_string_length=max_string_length, alphabet=alphabet, angle_in_radians=15/180*math.pi, full_word_only=full_word_only, min_percent_of_target=0.95, sample_output_path=sample_output_path)
</code></pre>

<p>Call fit with the td.data generators</p>

<pre><code>model.fit(  x= g_train, #generator.next_train_batch_with_book_id(),
            steps_per_epoch=steps_per_epoch,
            epochs=1000,
            validation_data=g_valid, #generator.next_valid_batch(), #validation_data=generator.next_valid_batch_with_book_id(),
            validation_steps=1000,
            callbacks=callbacks
        )
</code></pre>

<p>The error</p>

<pre><code>Traceback (most recent call last):
  File ""kiss_run_model_on_grabner.py"", line 371, in &lt;module&gt;
    callbacks=callbacks
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 593, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 706, in _process_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 702, in __init__
    x = standardize_function(x)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 684, in standardize_function
    return dataset.map(map_fn, num_parallel_calls=dataset_ops.AUTOTUNE)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1591, in map
    self, map_func, num_parallel_calls, preserve_cardinality=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3926, in __init__
    use_legacy_function=use_legacy_function)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3147, in __init__
    self._function = wrapper_fn._get_concrete_function_internal()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2395, in _get_concrete_function_internal
    *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3140, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3082, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn
        batch_size=None)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors
        exception_prefix='input')
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:526 standardize_input_data
        standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:526 &lt;listcomp&gt;
        standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:451 standardize_single_array
        if (x.shape is not None and len(x.shape) == 1 and
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py:822 __len__
        raise ValueError(""Cannot take the length of shape with unknown rank."")

    ValueError: Cannot take the length of shape with unknown rank.
</code></pre>

<p>I also tried the dictionary approach</p>

<pre><code> def next_train_batch_with_book_id(self):

train = self.dataset[""train""]
while True:
    xy = self.get_batch(train, return_ids_and_text_too=True, angle_in_radians=self.angle_in_radians, min_percent_of_target=self.min_percent_of_target, full_word_only=self.full_word_only)

    an_array_of_images = xy[""image""]
    an_array_of_book_ids = xy[""book_id""]
    an_array_of_1_hot  = xy[""text_as_alphabet_index""]

    print(f""an_array_of_images.shape = {an_array_of_images.shape}"")
    print(f""an_array_of_book_ids.shape = {an_array_of_book_ids.shape}"")
    print(f""an_array_of_1_hot.shape = {an_array_of_1_hot.shape}"")
    # an_array_of_images.shape = (32, 320, 128, 1)
    # an_array_of_book_ids.shape = (32, 20)
    #an_array_of_1_hot.shape = (32, 18)

    # dictionary based input/output to model
    inputs  = { 'the_image_input': an_array_of_images, ""the_book_id_input"": an_array_of_book_ids} 
    outputs = { 'the_text_as_alphabet_index_input' : an_array_of_1_hot }

    # just the data as input
    #inputs = an_array_of_images 
    outputs =  an_array_of_1_hot 

    xy = (inputs, outputs, [])

    yield xy
</code></pre>

<p>...</p>

<p>with model.fit calling as recommended</p>

<pre><code>model.fit(  x=generator.next_train_batch_with_book_id(),
            steps_per_epoch=steps_per_epoch,
            epochs=1000,
            validation_data=generator.next_valid_batch(), #validation_data=generator.next_valid_batch_with_book_id(),
            validation_steps=1000,
            callbacks=callbacks
        )
</code></pre>

<p>But this gives me the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""kiss_run_model_on_grabner.py"", line 371, in &lt;module&gt;
    callbacks=callbacks
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 614, in _process_training_inputs
    distribution_strategy=distribution_strategy)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 706, in _process_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 767, in __init__
    dataset = standardize_function(dataset)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 684, in standardize_function
    return dataset.map(map_fn, num_parallel_calls=dataset_ops.AUTOTUNE)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1591, in map
    self, map_func, num_parallel_calls, preserve_cardinality=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3926, in __init__
    use_legacy_function=use_legacy_function)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3147, in __init__
    self._function = wrapper_fn._get_concrete_function_internal()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2395, in _get_concrete_function_internal
    *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3140, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3082, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn
        batch_size=None)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors
        exception_prefix='input')
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:539 standardize_input_data
        str(data)[:200] + '...')

    ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), for inputs ['the_image_input', 'the_book_id_input'] but instead got the following list of 1 arrays: [&lt;tf.Tensor 'args_0:0' shape=(None, None, None, None) dtype=float32&gt;]...
</code></pre>
",2020-01-23 01:05:19,4547188,1010,https://stackoverflow.com/questions/59870349,Documentation Replicability
60067415,What is the correct usage of tf.image.yuv_to_rgb? Output is distorted,"<p>I need to pass YUV images to my TF model. <code>tf.image.yuv_to_rgb</code> seems like the way to go, however it expects the YUV input to be of size [H,W,3] with Y normalized to [0,1] and UV to [-0.5,0.5] <a href=""https://www.tensorflow.org/api_docs/python/tf/image/yuv_to_rgb"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/image/yuv_to_rgb</a>. </p>

<p>I'm new to the YUV format but this seems strange &amp; non-conventional to me based on other YUV-RGB conversion scripts I've found on the web: </p>

<ul>
<li><a href=""https://picamera.readthedocs.io/en/release-1.9/recipes2.html#unencoded-image-capture-yuv-format"" rel=""nofollow noreferrer"">https://picamera.readthedocs.io/en/release-1.9/recipes2.html#unencoded-image-capture-yuv-format</a></li>
<li><a href=""https://stackoverflow.com/questions/53467655/import-yuv-as-a-byte-array"">Import YUV as a byte array</a></li>
</ul>

<p>My question is: what is the correct usage of <code>tf.image.yuv_to_rgb</code>? Is there a better documentation or a pre-processing method provided by TF? I've tried modifying the above solutions to fit the range expected by <code>tf.image.yuv_to_rgb</code> but was getting distorted outputs. Below is my code (ipynb) and attached are my outputs: </p>

<p><a href=""https://i.stack.imgur.com/yCTHz.png"" rel=""nofollow noreferrer"">outputs</a></p>

<pre class=""lang-python prettyprint-override""><code>import numpy as np
import tensorflow as tf
import imageio
import os
import argparse
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from time import perf_counter

w,h = 520,390
px = w*h

'''
Seems like there are 2 conventions for YUV conversion: 
- ITU-R BT.601 version (SDTV)
- ITU-R BT.709 version (HDTV)
For both of these I performed conversion using numpy mat-mul open source code. 
These look somewhat OK, but I'm clearly losing some chrominance data -- not exactly sure what I'm doing wrong.

These methods do NOT work for tf.image.yuv_to_rgb, as it expects Y:[0,1], UV:[-0.5,0.5] (while YUV is uint8). 
For the TF method I modified the pre-processing of the YUV data to match the range expected by tf.image.yuv_to_rgb.
I was able to visually match the outputs of the above NP methods -- but clearly there's some color loss going on.

One more interesting observation: NP approaches seem faster than TF. Not sure if this changes when tf.image.yuv_to_rgb
runs as part of the tflite model itself
'''

# http://maxsharabayko.blogspot.com/2016/01/fast-yuv-to-rgb-conversion-in-python-3.html
def YUV2RGB( yuv ):
    A = np.array([[1.164,  0.000,  1.793],
                  [1.164, -0.213, -0.533],
                  [1.164,  2.112,  0.000]])
    rgb = np.dot(yuv, A.T).clip(0, 255).astype('uint8')
    return rgb

# https://picamera.readthedocs.io/en/release-1.9/recipes2.html#unencoded-image-capture-yuv-format
def YUV2RGB_sdtv(yuv):
    #              Y       U       V
    M = np.array([[1.164,  0.000,  1.596],    # R
                  [1.164, -0.392, -0.813],    # G
                  [1.164,  2.017,  0.000]])   # B
    # Take the dot product with the matrix to produce RGB output, clamp the
    # results to byte range and convert to bytes
    RGB = YUV.dot(M.T).clip(0, 255).astype(np.uint8)
    return RGB


# https://stackoverflow.com/questions/53467655/import-yuv-as-a-byte-array
def IMG2YUV(img):
    # Read entire file into YUV
    YUV = np.fromfile(img,dtype='uint8')

    # Take first h x w samples and reshape as Y channel
    Y = YUV[0:w*h].reshape(h,w)

    # Take next px/4 samples as U
    U = YUV[px:(px*5)//4].reshape(h//2,w//2)

    # Take next px/4 samples as V
    V = YUV[(px*5)//4:(px*6)//4].reshape(h//2,w//2)

    # Undo subsampling of U and V by doubling h and w
    U = U.repeat(2, axis=0).repeat(2, axis=1)
    V = V.repeat(2, axis=0).repeat(2, axis=1)

    YUV = np.dstack((Y, U, V))[:h, :w, :].astype(np.float32)
    YUV[:,:, 0] = YUV[:,:, 0].clip(16, 235).astype(YUV.dtype) - 16
    YUV[:,:,1:] = YUV[:,:,1:].clip(16, 240).astype(YUV.dtype) - 128
    return YUV

# https://raspberrypi.stackexchange.com/questions/28033/reading-frames-of-uncompressed-yuv-video-file
def IMG2YUV_sdtv(img):
    Y = np.fromfile(img, dtype=np.uint8, count=w*h).\
        reshape((h, w))

    # Load the UV (chrominance) data from the stream, and double its size
    U = np.fromfile(img, dtype=np.uint8, count=(w//2)*(h//2)).\
            reshape((h//2, w//2)).\
            repeat(2, axis=0).repeat(2, axis=1)
    V = np.fromfile(img, dtype=np.uint8, count=(w//2)*(h//2)).\
            reshape((h//2, w//2)).\
            repeat(2, axis=0).repeat(2, axis=1)

    # Stack the YUV channels together, crop the actual resolution, convert to
    # floating point for later calculations, and apply the standard biases
    YUV = np.dstack((Y, U, V))[:h, :w, :].astype(np.float32)

    YUV[:, :, 0]  = YUV[:, :, 0]  - 16   # Offset Y by 16
    YUV[:, :, 1:] = YUV[:, :, 1:] - 128  # Offset UV by 128

    return YUV

# Best guess at normalization, based on https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/image/yuv_to_rgb
def IMG2YUV_tf(img):
    # Read entire file into YUV
    YUV = np.fromfile(img,dtype='uint8')

    # Take first h x w samples and reshape as Y channel
    Y = YUV[0:w*h].reshape(h,w)

    # Take next px/4 samples as U
    U = YUV[px:(px*5)//4].reshape(h//2,w//2)

    # Take next px/4 samples as V
    V = YUV[(px*5)//4:(px*6)//4].reshape(h//2,w//2)

    # Undo subsampling of U and V by doubling h and w
    U = U.repeat(2, axis=0).repeat(2, axis=1)
    V = V.repeat(2, axis=0).repeat(2, axis=1)

    YUV = np.dstack((Y, U, V))[:h, :w, :].astype(np.float32)

    YUV[:, :, 0]  = YUV[:, :, 0]  / 255        # [0,1]
    YUV[:, :, 1:] = YUV[:, :, 1:] / 255 - 0.5  # [-0.5,0.5] 

    return YUV
imgs = [""colors""]

img = imgs[0]
print(""\nImage: {}"".format(img))
YUV = IMG2YUV(img+"".yuv"")
YUV_sdtv = IMG2YUV_sdtv(img+"".yuv"")
YUV_tf = IMG2YUV_tf(img+"".yuv"")
with tf.Session() as sess: 
    s_tf = perf_counter()
    RGB_tf = tf.image.yuv_to_rgb(YUV_tf)
    RGB_tf = RGB_tf.eval()
    e_tf = perf_counter()

    s_tf_sdtv = perf_counter()
    RGB_tf_sdtv = tf.image.yuv_to_rgb(YUV_sdtv)
    RGB_tf_sdtv = RGB_tf_sdtv.eval()
    e_tf_sdtv = perf_counter()

s_np = perf_counter()
RGB_np = YUV2RGB(YUV)
e_np = perf_counter()

s_np_sdtv = perf_counter()
RGB_np_sdtv = YUV2RGB_sdtv(YUV_sdtv)
e_np_sdtv = perf_counter()

PNG = np.float32(imageio.imread(DATA_DIR + img + '.png'))
PNG_norm = (2.0 / 255.0) * PNG - 1.0

print(""TF (using SDTV):"")
print(""{} seconds"".format(e_tf_sdtv - s_tf_sdtv))
plt.imshow(RGB_tf_sdtv)
plt.show()

print(""TF (normalized to Y [0,1], UV [-0.5,0.5]:"")
print(""{} seconds"".format(e_tf - s_tf))
plt.imshow(RGB_tf)
plt.show()

print(""np:"")
print(""{} seconds"".format(e_np - s_np))
plt.imshow(RGB_np)
plt.show()

print(""np_sdtv:"")
print(""{} seconds"".format(e_np_sdtv - s_np_sdtv))
plt.imshow(RGB_np_sdtv)
plt.show()

print(""original:"")
plt.imshow(PNG.astype('uint8'))
plt.show()
</code></pre>
",2020-02-05 00:27:52,6567283,301,https://stackoverflow.com/questions/60067415,Requesting (Additional) Documentation/Examples
60130582,How to convert images to TFRecords with tf.data.Dataset in most efficient way possible,"<p>I am absolutely baffled by how many unhelpful error messages I've received while trying to use this supposedly simple API to write TFRecords in a manner that doesn't take 30 minutes every time I have a new dataset.</p>

<h2>Task:</h2>

<p>I'd like to feed a list of image paths and a list of labels to a tf.data.Dataset, parse them in parallel to read the images and encode as tf.train.Examples, use tf.data.Dataset.shard to distribute them into different TFRecord shards (e.g. train-001-of-010.tfrecord, train-002-of-010.tfrecord, etc.), and for each shard finally write them to the corresponding file.</p>

<p>Since I've been debugging this for hours I haven't gotten any single particular error to fix, otherwise I would provide it. I've struggled to find any up to date tutorial that doesn't either (a) come from 2017 and use queue runners, (b) use a tf.Session (I'm using tensorflow 1.15 but official docs keep telling me to phase out sessions), (c) Conveniently do the record creating in pure python, which makes a simple tutorial but is too slow for any actual application, or (d) use already created TFRecords and just skip the whole process.</p>

<p>If necessary, I can put together an example of what I'm talking about. But since I'm getting stuck at every level of the process, at the moment it seems unhelpful.</p>

<h2>Tldr:</h2>

<p>If anyone has utilized tf.data.Dataset to create TFRecord shards in parallel please point me in a better direction than google has.</p>
",2020-02-08 19:51:23,7590318,41,https://stackoverflow.com/questions/60130582,Documentation Replication on Other Examples
60143153,Is there a way in tensorflow to load batches of data each time?,"<p>So I'm running tensorflow 2+ python in google colab.</p>

<p>Each of my data file is a 3d image with shape [563, 563, 563, 1], so loading all of them throws a resource exhaustion error.</p>

<p>I've spent days and hours searching for a way to load only a batch of my dataset as tensor and unloading/loading new batch each iteration. I'm guessing there might be a way using tf.data.Dataset.list_files, but I can't find the exact way.</p>

<p>Is there any good suggestions on a way to do it or any documents I could try to read? I've read the tf.data document from tensorflow, but couldn't find the information I needed.</p>

<p>Thank you!</p>

<h1>Edit</h1>

<p>so this is the function I want to use to load my image</p>

<pre><code>def load_image(ind):
    file_brain = ""/content/drive/My Drive/brain/"" + str(ind) + "".mgz""
    file_mask = ""/content/drive/My Drive/mask/"" + str(ind) + "".mgz""
    data_brain, affine = load_nifti(file_brain)
    data_mask, affine = load_nifti(file_mask)
    data_brain = affine_transform(data_brain, affine)
    data_mask = affine_transform(data_mask, affine)
    data_brain = normalize(data_brain)
    data_brain = zoom(data_brain, (563/256, 563/256, 563/256))
    data_brain = tf.expand_dims(data_brain, axis=-1)
    data_mask = tf.expand_dims(data_mask, axis=-1)
    return data_brain, data_mask
</code></pre>

<p>and this was the way I was loading the dataset before, which exhausted the resource;</p>

<pre><code>def create_dataset():
    train_data = []
    train_label = []
    test_data = []
    test_label = []
    test_n = np.random.randint(1, 10, 1)
    for i in range(1, 10):
        data_brain, data_mask = load_image(i)
        if i in test_n:
            test_data.append(data_brain)
            test_label.append(data_mask)
            continue
        train_data.append(data_brain)
        train_label.append(data_mask)
        shifted_data = data_brain + tf.random.uniform(shape=(), minval=-0.05, maxval=0.05)
        scaled_data = data_brain * tf.random.uniform(shape=(), minval=0.85, maxval=1.3)
        train_data.append(shifted_data)
        train_label.append(data_mask)
        train_data.append(scaled_data)
        train_label.append(data_mask)
""""""
train_data = tf.data.Dataset.from_tensor_slices(train_data)
train_label = tf.data.Dataset.from_tensor_slices(train_label)
test_data = tf.data.Dataset.from_tensor_slices(test_data)
test_label = tf.data.Dataset.from_tensor_slices(test_label)
return train_data, train_label, test_data, test_label
""""""
</code></pre>
",2020-02-10 01:53:54,12869645,61,https://stackoverflow.com/questions/60143153,Requesting (Additional) Documentation/Examples
60213882,Using Tensorflow Interleave to Improve Performance,"<p>I have an input pipe that is performing poorly with low CPU, GPU, and disk utilization. I've been reading the tensorflow ""Better performance with tf.data API"" doc and the Dataset docs, but I don't understand what's going on well enough to apply it to my situation. Here's my current setup:</p>

<pre><code>img_files = sorted(tf.io.gfile.glob(...))
imgd = tf.data.FixedLengthRecordDataset(img_files, inrez*inrez)
#POINT1A
imgd = imgd.map(lambda s: tf.reshape(tf.io.decode_raw(s, tf.int8), (inrez,inrez,1)))
imgd = imgd.map(lambda x: tf.cast(x, dtype=tf.float32))

out_files = sorted(tf.io.gfile.glob(...))
outd = tf.data.FixedLengthRecordDataset(out_files, 4, compression_type=""GZIP"")
#POINT1B
outd = outd.map(lambda s: tf.io.decode_raw(s, tf.float32))

xsrc = tf.data.Dataset.zip((imgd, outd)).batch(batchsize)
xsrc = xsrc.repeat()        # indefinitely
#POINT2
xsrc = xsrc.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
</code></pre>

<p>Should I interleave the whole pipe right at the end (POINT2), before the prefetch? Or interleave imgd and outd separately, after each FixedLengthRecordDataset (POINT1A, POINT1B), and parallelize the maps? (need to keep the imgd and outd synced up!) What's up with Dataset.range(rvalue)---seems it's necessary but not obvious what rvalue to use? Is there a better overall plan?</p>

<p>Note that the datasets are very large and do not fit in RAM.</p>
",2020-02-13 17:57:07,2076669,143,https://stackoverflow.com/questions/60213882,Documentation Replicability
60222896,How can I calculate pos_weight variable of the tf.nn.weighted_cross_entropy_with_logits for multiple classes?,"<p>I want to use <code>tf.nn.weighted_cross_entropy_with_logits</code>.</p>

<p>There are three classes of the dataset. The number of images in <code>class A is 5500</code>, in <code>class B is 2000</code>, and in <code>class C is 20000</code>. </p>

<p>How can I calculate and use <code>pos_weight</code> variable in <code>tf.nn.weighted_cross_entropy_with_logits</code>?</p>
",2020-02-14 08:52:12,12594959,1,https://stackoverflow.com/questions/60222896,Documentation Replication on Other Examples
60237912,"Is a ""normal"" python object automatically a tensor? e.g. ""a"" or 1","<p>I'm struggling to understand why this function works:   </p>

<pre><code>def tf_load_data(training, batch_size, img_path_list, label_list):

    # Arguments:
    # path_to_image: a Tensor of type string
    # returns 3-D float Tensor of shape [new_height, new_width, channels]
    def get_img(path_to_img):
        # load the raw data, encoded as string.
        raw_img = tf.io.read_file(path_to_img)
        # Creates a 3D uint8 tensor.
        img = ts.io.decode_png(raw_img, channels=3)  # pictures are not saved as Grayscale
        # Changes the values in the tensor to be floats in [0,1). -- Normalization
        img = ts.image.convert_image_dtype(img, tf.float32)
        # Resize all pictures to the same format.
        return ts.image.resize(img, [constant.IMG_WIDTH, constant.IMG_HEIGHT])

    # Arguments:
    # label_string: as byte:32 which represents a string
    # path_to_image: as byte:32 which represents a string
    # returns a pair of two Tensors
    def get_pair(path_to_img, label_string):
        return get_img(path_to_img), lable_string

    # Arguments: -- function is use together with tf.data.Dataset.map or tf.data.Dataset.apply
    # img: is a Tensor of type String
    # label: is a Tensor of type String
    # return: the type is the same as input
    def pre_process(img, label):
        # Do all the pre-processing:
        return img, label

    dataset = tf.data.Dataset.from_tensor_slices((img_path_list, label_list))
    dataset_tensor = dataset.map(map_func=get_pair, num_parallel_calls=None)
</code></pre>

<p>img_path_list and label_list are lists of type string.</p>

<p>The thing that I don't get is that apparently 
<code>dataset = tf.data.Dataset.from_tensor_slices((img_path_list, label_list))</code>
is a Tensor containing tuples (). So when I run the <code>.map(map_func=get_pair, num_parallel_calls=None)</code> two strings are passed, as a tuple, in the <code>get_pair(path_to_img, label_string):</code> function. One these strings is then passed in the <code>get_img(path_to_img)</code> function and finally to <code>tf.io.read_file(path_to_img)</code>.
The problem is that <code>io.read_file()</code> needs an input: ""Tensor of type string"" (see docs : <a href=""https://www.tensorflow.org/api_docs/python/tf/io/read_file"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/io/read_file</a>). 
But string != to Tensor of type string: </p>

<pre><code>isinstance(tf.constant[""hello""], tf.Tensor) == True
</code></pre>

<p><code>isinstance(""hello"", tf.Tensor) == False</code> as well as: <code>isinstance([""hello""], tf.Tensor) == False</code></p>

<p>Thanks for your help!</p>
",2020-02-15 10:36:23,9621080,568,https://stackoverflow.com/questions/60237912,Documentation Ambiguity
60287388,Error loading .npz files in tensorflow dataset,"<p>I'm trying to create a data pipeline in tensorflow, but my data is in .npz files.
Following the documentation at <a href=""https://www.tensorflow.org/guide/data#consuming_sets_of_files"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/data#consuming_sets_of_files</a>, for consuming sets of files, combined with using tf.py_function() for using numpy ops, I wrote a code, a subsection of which is:</p>

<pre><code>def load_data(filename):

    from preprocess import normalize

    # sess = tf.compat.v1.Session()
    # fln = sess.run(filename)
    print ('I AM TRYING TO LOAD : ', filename)
    mels = np.load(filename)['arr_0']
    mels = normalize(mels)

    return mels
</code></pre>

<p>I'm getting an error in np.load(filename), which goes like:</p>

<pre><code>I AM TRYING TO LOAD :  tf.Tensor(b'/media/prabhatk/Datasets/DCASE/features/augmentations=None features=mono fmax=22050 fmin=0 hop_length=1024 mel_htk=True n_fft=2048 n_mels=60 samplerate=44100/airport-lisbon-1000-40000-a.npz', shape=(), dtype=string)
2020-02-18 19:31:31.048435: W tensorflow/core/framework/op_kernel.cc:1610] Invalid argument: TypeError: expected str, bytes or os.PathLike object, not tensorflow.python.framework.ops.EagerTensor

</code></pre>

<p>Fixed this by using np.load(filename.numpy()), as stated by @jdehesa.
Now I run into some shape issues, although I've already reshaped the input in the load_data_wrapper() function.</p>

<p>Can anyone help me with this?</p>

<p>I am attaching the entire code and entire error message below.</p>

<p>CODE:</p>

<pre><code>import os
from os import path
import sys
import argparse

sys.path.insert(1,'../')
from helpers import locations
from helpers import metadata
from helpers import read_settings as Settings
from models import sbcnn

import numpy as np
import pandas as pd
import librosa as lb

from sklearn.preprocessing import LabelEncoder

import tensorflow as tf
# from tf.data.experimental import AUTOTUNE


def load_data(filename):

    from preprocess import normalize

    # sess = tf.compat.v1.Session()
    # fln = sess.run(filename)
    print ('I AM TRYING TO LOAD : ', filename)
    mels = np.load(filename)['arr_0']
    # mels = tf.io.read_file(filename)['arr_0']
    mels = normalize(mels)

    return mels


def load_data_wrapper(filename):

    # print ('INPUT TO LOAD DATA IS : ', filename)
    [mels,] = tf.py_function(
        load_data, [filename], [tf.float32]
        )
    mels.set_shape((1,60,431,1))

    # return mels
    return mels


def get_input_directory(input_dir, feature_settings):

    base_dir = input_dir if (input_dir != '') else locations.FEATURE_DIR_BASE
    assert path.exists(base_dir), 'Feature directory not found!!'

    settings = Settings.load_settings(feature_settings)
    feature_dir = Settings.settings_to_path(settings)
    feature_dir = path.join(base_dir,feature_dir)
    assert path.exists(feature_dir), 'Data not preprocessed according to given settings!!'

    return feature_dir


def construct_dataset(X, y):

    filepaths = tf.data.Dataset.from_tensor_slices(X)
    with tf.device('/device:CPU:*'):
        files = filepaths.map(load_data_wrapper)

    filelabels = tf.data.Dataset.from_tensor_slices(y)

    return tf.data.Dataset.zip((files, filelabels))


def parseArguments():
    parser = argparse.ArgumentParser()

    parser.add_argument('--training_metadata', type=str, default='', help='CSV file containing training file names and lables')
    parser.add_argument('--validation_metadata', type=str, default='', help='CSV file containing validation file names and lables')
    parser.add_argument('--input_dir', type=str, default='', help='Processed features directory')
    parser.add_argument('--feature_settings', type=str, default='', help='Load data with the given settings')

    args = parser.parse_args()

    return args


def main():
    arguments = parseArguments()

    input_dir = get_input_directory(arguments.input_dir, arguments.feature_settings)
    X_tr, y_tr = metadata.train(arguments.training_metadata, input_dir)
    X_val, y_val = metadata.validation(arguments.validation_metadata, input_dir)

    enc = LabelEncoder()
    enc.fit(y_tr)
    y_tr = enc.transform(y_tr)
    y_val = enc.transform(y_val)

    data_tr = construct_dataset(X_tr, y_tr)
    data_val = construct_dataset(X_val, y_val)

    model = sbcnn.build_model()
    model.compile(loss='categorical_crossentropy', 
        optimizer=tf.keras.optimizers.SGD(),
        metrics=['accuracy'])

    model.summary()

    model.fit(data_tr, epochs=10)


if __name__ == '__main__':
    main()
</code></pre>

<p>ERROR:</p>

<pre><code>2020-02-19 10:37:06.375134: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at conv_ops_fused_impl.h:693 : Invalid argument: input must be 4-dimensional[60,431]
2020-02-19 10:37:06.375184: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: input must be 4-dimensional[60,431]
     [[{{node sequential/conv2d/BiasAdd}}]]
      1/Unknown - 0s 389ms/stepTraceback (most recent call last):
  File ""pipeline.py"", line 112, in &lt;module&gt;
    main()
  File ""pipeline.py"", line 108, in main
    model.fit(data_tr, epochs=10)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1141, in _filtered_call
    self.captured_inputs)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 511, in call
    ctx=ctx)
  File ""/home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""&lt;string&gt;"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError:  input must be 4-dimensional[60,431]
     [[node sequential/conv2d/BiasAdd (defined at /home/prabhatk/miniconda3/envs/DL/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_801]

Function call stack:
distributed_function

</code></pre>
",2020-02-18 18:34:54,12920968,1,https://stackoverflow.com/questions/60287388,Documentation Replicability
60311184,how to loop over a tensor object until a condition met,"<p>I have a tensor like this:</p>

<pre><code>masked_bad_col = [[False  True  True False  True  True  True  True  True  True  True False]]
</code></pre>

<p>I want to loop through this tensor untill all elements get <code>True</code>.
So I have another function, which will update this tensor, lets call it <code>uniqueness</code>.</p>

<pre><code>def uniqueness():

   'blah blah blha'
   return tensor1, updated_masked_bad_col
</code></pre>

<p>I looked at the documentation and got to know that I can do that using <code>tf.while_loop</code>. Although, I could not find any example working on boolean stuff.
This is what I have done so far:</p>

<pre><code>tensor1, _ = tf.while_loop(masked_bad_col != True, uniqueness)
</code></pre>

<p>It is obviously incorrect, but don't know how to use each element of <code>masked_bad_col</code> as a condition to continue looping through <code>uniqueness</code> function.</p>

<p><strong>Update 1</strong>
This is the method I am trying to call in the loop:</p>

<pre><code>corpus = load_corpus('path_to_corpus/train.corpus')
topics = []
vocab, docs = corpus['vocab'], corpus['docs']
number_of_topics = 0
encoder_model = load_keras_model(
    'path_to_model/encoder_model',
    custom_objects={""KCompetitive"": KCompetitive})
weights = encoder_model.get_weights()[0]
for idx in range(encoder_model.output_shape[1]):
    token_idx = np.argsort(weights[:, idx])[::-1][:20]
    topics.append([(revdict(vocab)[x]) for x in token_idx])
    number_of_topics += 1

nparr = np.asarray(topics)
# print nparr.shape

unique, indices, count = np.unique(nparr, return_inverse=True, return_counts=True)

tensor1 = (np.sum(count[indices].reshape(nparr.shape), axis=1).reshape(1, nparr.shape[0]) / (
        number_of_topics * 20))

def uniqueness_score():
    corpus = load_corpus('path_to_corpus/train.corpus')
    topics = []
    vocab, docs = corpus['vocab'], corpus['docs']
    number_of_topics = 0
    encoder_model = load_keras_model(
        'path_to_model/encoder_model',
        custom_objects={""KCompetitive"": KCompetitive})
    weights = encoder_model.get_weights()[0]
    for idx in range(encoder_model.output_shape[1]):
        token_idx = np.argsort(weights[:, idx])[::-1][:20]
        topics.append([(revdict(vocab)[x]) for x in token_idx])
        number_of_topics += 1

    nparr = np.asarray(topics)

    unique, indices, count = np.unique(nparr, return_inverse=True, return_counts=True)

    tensor1 = (np.sum(count[indices].reshape(nparr.shape), axis=1).reshape(1, nparr.shape[0]) / (
            number_of_topics * 20))
    return tensor1
</code></pre>

<p>And this is the way I called this method in the <code>while_loop</code></p>

<pre><code>with tf.Session() as sess:

        tensor2, _ = tf.while_loop(
            # Loop condition (negated goal condition)
            lambda tensor1: ~tf.math.reduce_all(tensor1 &gt; tf.reduce_mean(tensor1)),
            # Loop body
            lambda tensor1: uniqueness_score(),
            # Loop variables
            [tensor1])
        # Returned loop value
        print(tensor2.eval())
</code></pre>
",2020-02-20 00:14:01,7934786,2060,https://stackoverflow.com/questions/60311184,Inadequate Examples
60314717,How does shuffle and batch work in tf.data.dataset?,"<p>I'm working on a large dataset with around 10million datapoints so I've decided to use tf.data.dataset api for fetching dataset.</p>

<pre><code>train_dataset = tf.data.Dataset.from_tensor_slices((data))
train = train_dataset.shuffle(100000).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)
</code></pre>

<p>I've few doubts which isn't clear from tensorflow docs. I hope someone can address them.</p>

<p>How does the shuffle work in my case? Because I have 10 million datapoints should I shuffle all 10 million (or) will 100k be enough? Will it have any performance impact choosing a large shuffle? </p>

<p>Will the batch is considered only from shuffled dataset (or) the original dataset?</p>
",2020-02-20 07:19:38,11816060,1959,https://stackoverflow.com/questions/60314717,Documentation Replication on Other Examples
60384790,Difference - tf.gradients vs tf.keras.backend.gradients,"<p>Being new to Tensorflow, I am trying to understand the difference between underlying functionality of tf.gradients and tf.keras.backend.gradients.</p>

<p>The latter finds the gradient of input feature values w.r.t cost function. </p>

<p>But I couldn't get a clear idea on the former whether it computes the gradient over cost function or output probabilities (For example, consider the case of binary classification using a simple feed forward network. Output probability here is referred to the Sigmoid activation outcome of final layer with single neuron. Cost is given by Binary cross entropy)</p>

<p>I have referred the official documentation for tf.gradients, but it is short and vague (for me), and I did not get a clear picture - The documentation mentions it as just 'y' - is it cost or output probability? </p>

<p>Why I need the gradients? 
To implement a basic gradient based feature attribution. </p>
",2020-02-24 22:23:21,11606547,11,https://stackoverflow.com/questions/60384790,Requesting (Additional) Documentation/Examples
60516977,Difficulties in understanding higher order derivatives for tf.custom_gradient(),"<p>Based on the example as quoted in tensorflow's website here: <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/custom_gradient</a></p>

<pre><code>@tf.custom_gradient
def op_with_fused_backprop(x):
     y, x_grad = fused_op(x)

     def first_order_gradient(dy):
         @tf.custom_gradient
         def first_order_custom(unused_x):
             def second_order_and_transpose(ddy):
                 return second_order_for_x(...), gradient_wrt_dy(...)
             return x_grad, second_order_and_transpose
         return dy * first_order_custom(x)
     return y, first_order_gradient
</code></pre>

<p>There is a lack of details on why <code>second_order_and_transpose(ddy)</code> returns two objects. Based on the documentation of tf.custom_gradient, the <code>grad_fn</code> (<em>i.e.</em> <code>second_order_and_transpose()</code>) should return a list of Tensors which are the derivatives of dy w.r.t. <code>unused_x</code>. It is also not even clear why did they name it <code>unused_x</code>. Anyone has any idea on this example or in general create custom gradients for higher order derivatives?</p>
",2020-03-03 23:25:04,4723266,481,https://stackoverflow.com/questions/60516977,Documentation Completeness
60525257,How to apply Non max suppression on batch of images in tensorflow 1.14?,"<p>I have batch of cropped images from original image on which I have to perform object detection, I am trying to apply tensorflow NMS operation. </p>

<p>I looked into tensorflow api docs, and found <code>tf.image.combined_non_max_suppression()</code>, but I am unable to understand it properly.</p>

<p>The flow in my pipeline is of two step.</p>

<ol>
<li>I get some image and apply object detection to get desired region of interests.</li>
<li>On each of these ROIs I have to apply object detection again, so I am passing it as batch.</li>
</ol>

<p>For the first step, I use simple <code>tf.image.non_max_suppression()</code> followed by <code>tf.gather()</code>, but I am not able to understand, how to do it for second step. </p>

<p>Please refer to code snippets below:</p>

<pre><code>with tf.Session(graph = self.detection_graph) as sess:

    # input image tensor
    image_tensor1 = self.detection_graph.get_tensor_by_name('import/image_tensor:0')

    # boxes, scores and classes for first step
    boxesop1 = self.detection_graph.get_tensor_by_name('import/detection_boxes:0')
    scoresop1 = self.detection_graph.get_tensor_by_name('import/detection_scores:0')
    classesop1 = self.detection_graph.get_tensor_by_name('import/detection_classes:0')

    # getting first values, since we are predicting on single image
    boxesop1 = boxesop1[0]
    classesop1 = classesop1[0]
    scoresop1 = scoresop1[0]

    # applying NMS for the first step
    selected_indices1 = tf.image.non_max_suppression(
        boxesop1, scoresop1, 20, iou_threshold = 0.5
    )

    boxesop1 = tf.gather(boxesop1, selected_indices1)
    classesop1 = tf.gather(classesop1, selected_indices1)
    scoresop1 = tf.gather(scoresop1, selected_indices1)


    # boxes, scores and classes for second step
    boxesop2 = self.detection_graph.get_tensor_by_name('import_1/detection_boxes:0')
    scoresop2 = self.detection_graph.get_tensor_by_name('import_1/detection_scores:0')
    classesop2 = self.detection_graph.get_tensor_by_name('import_1/detection_classes:0')

    # applying NMS for the second step
    boxesop2, scoresop2, classesop2, valid_detections = tf.image.combined_non_max_suppression(
        boxesop2, scoresop2, max_output_size_per_class = 10, max_total_size = 30,
        iou_threshold = 0.5
    )

    # predicting for each images
    for imgPath, imgID in img_files:

        # reading image data
        img = cv2.imread(imgPath)
        imageHeight, imageWidth = img.shape[:2]

        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
        image_np_expanded = np.expand_dims(img, axis=0)

        # Run inference
        (boxes1, scores1, classes1, boxes2, scores2, classes2) = sess.run(
            [boxesop1, scoresop1, classesop1, boxesop2, scoresop2, classesop2],
            feed_dict={image_tensor1: image_np_expanded}
        )
</code></pre>

<p>But I got following error, when tried running above:</p>

<pre><code>Traceback (most recent call last):
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: boxes must be 4-D[20,300,4]
         [[{{node combined_non_max_suppression/CombinedNonMaxSuppression}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/prediction.py"", line 159, in predict
    feed_dict={image_tensor1: image_np_expanded}
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: boxes must be 4-D[20,300,4]
         [[node combined_non_max_suppression/CombinedNonMaxSuppression (defined at /home/prediction.py:130) ]]

Errors may have originated from an input operation.
Input Source operations connected to node combined_non_max_suppression/CombinedNonMaxSuppression:
 import_1/detection_boxes (defined at /home/prediction.py:94)

Original stack trace for 'combined_non_max_suppression/CombinedNonMaxSuppression':
  File ""/home/prediction.py"", line 130, in predict
    iou_threshold = 0.5
  File ""../env/lib/python3.5/site-packages/tensorflow/python/ops/image_ops_impl.py"", line 3707, in combined_non_max_suppression
    score_threshold, pad_per_class, clip_boxes)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/ops/gen_image_ops.py"", line 431, in combined_non_max_suppression
    clip_boxes=clip_boxes, name=name)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
</code></pre>

<p><strong>How to solve it and apply NMS for batch of images in tensorflow ?</strong></p>
",2020-03-04 11:41:13,7112271,111,https://stackoverflow.com/questions/60525257,Documentation Replicability
60610007,"Build tf,estimator.DNNClassifier from tf.data.Datasets","<p>I am new to tensorflow in ML, and thought I could build the model from tf.data.Datasets directly. Here is my code, could not figure out why it did not work. Can someone please advise if it's possible to make it work?</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_datasets as tfds

#load the data
train_data, ds_info = tfds.load('mnist', split='train'
                       , shuffle_files=True,with_info=True, as_supervised=True)

feature_columns = [tf.feature_column.numeric_column('x',shape=[28,28])]

#build the model
estimator = tf.estimator.DNNClassifier(
feature_columns=feature_columns,
hidden_units=[300,100],
n_classes=10,
model_dir='/train/DNN')

#train the model
estimator.train(input_fn=train_data)
</code></pre>
",2020-03-10 00:19:15,1741590,1,https://stackoverflow.com/questions/60610007,Documentation Replicability
60616507,Difference between tf.GradientTape and backprop.GradientTape,"<p>When looking at the <code>OptimizerV2</code> code in Tensorflow 1.15 I noticed that they use <code>backprop.GradientTape</code> to compute the gradient.</p>

<p>I can't find any online reference to this class, only to <code>tf.GradientTape</code>.
What is the difference between the two?</p>
",2020-03-10 11:16:11,3936294,884,https://stackoverflow.com/questions/60616507,Lack of Alternative Solutions/Documentation
60678769,Who to do early stopping with the evaluation loss using tf.estimator.train_and_evaluate?,"<p>I am using the Tensorflow estimator and explicitly the method <code>tf.estimator.train_and_evaluate()</code>.
There is an early stopping hook for the training which is  <code>tf.contrib.estimator.stop_if_no_decrease_hook</code>, but I do have the issue that the training loss is too jumpy to use for early stopping.
Does anyone know how to do <em>early stopping</em> with <code>tf.estimator</code> based on the <em>evaluation loss</em>?</p>
",2020-03-14 00:46:33,12227311,41,https://stackoverflow.com/questions/60678769,Documentation Replication on Other Examples
60692861,How can I get trainable_variables from model subclassing the tf.keras.Model?,"<p>I want to get <code>trainable_variables</code> from model which is created by subclassing <code>tf.keras.Model</code>, but it return <code>[]</code>.I know it works when using <code>tf.keras.Sequential</code>.</p>

<pre><code>class MyModel(tf.keras.Model):

    def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
        self.des = tf.constant([[1.,2.]])

    def call(self, inputs):
        x = self.dense1(inputs)
        # y = self.des
        return self.dense2(x)

model = MyModel()
print(model.trainable_variables)  #=&gt;[]
</code></pre>

<p>I tried feedding some values to the model but it still returns <code>[]</code>. </p>
",2020-03-15 12:26:47,11828768,111,https://stackoverflow.com/questions/60692861,Documentation Replication on Other Examples
60778828,higher order gradient through py_function,"<p>I wonder how to calculate higher order gradients through tf.py_function in tf2.0.  The following example (slightly modified from tensorflow doc) produces the correct dy_dx, and aa_x is None.  Thank you.</p>

<pre><code>import tensorflow as tf
import os

def huber(x, delta):
  if tf.abs(x) &lt;= delta:
    return x*x/ (2*delta)
  else:
    return tf.abs(x)-delta/2.0



x = tf.constant ([2.0 ] )         
z = tf.constant ([1.0 ] )

with tf.GradientTape (persistent=True) as g0:
  g0.watch(x)

  with tf.GradientTape (persistent=True) as g :
    g.watch (x)
    y = tf.py_function(func=huber, inp=[x, 3.] , Tout=tf.float32  )

  dy_dx = g.gradient(y, x)
  aa = tf.reduce_sum(dy_dx *z )

aa_x = g0.gradient (aa, x)
print (dy_dx)
print (aa_x)
</code></pre>
",2020-03-20 17:25:18,13096010,13,https://stackoverflow.com/questions/60778828,Documentation Replication on Other Examples
60782077,How do you use tensorflow ctc_batch_cost function with keras?,"<p>I have been trying to implement a CTC loss function in keras for several days now.</p>
<p>Unfortunately, I have yet to find a simple way to do this that fits well with keras. I found tensorflow's <code>tf.keras.backend.ctc_batch_cost</code> function but there is not much documentation on it. I am confused about a few things. First, what are the <code>input_length</code> and <code>label_length</code> parameters? I am trying to make a handwriting recognition model and my images are 32x128, my RNN has 32 time steps, and my character list has a length of 80. I have tried to use 32 for both parameters and this gives me the error below.</p>
<p>Shouldn't the function already know the <code>input_length</code> and <code>label_length</code> from the shape of the first two parameters (<code>y_true</code> and <code>y_pred</code>)?</p>
<p>Secondly, do I need to encode my training data? Is this all done automatically?</p>
<p>I know tensorflow also has a function called <code>tf.keras.backend.ctc_decode</code>. Is this only used when making predictions?</p>
<pre><code>def ctc_cost(y_true, y_pred):
    return tf.keras.backend.ctc_batch_cost(
        y_true, y_pred, 32, 32)


model = tf.keras.Sequential([
    layers.Conv2D(32, 5, padding=&quot;SAME&quot;, input_shape=(32, 128, 1)),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D(2, 2),
    layers.Conv2D(64, 5, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D(2, 2),
    layers.Conv2D(128, 3, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D((1, 2), (1, 2)),
    layers.Conv2D(128, 3, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D((1, 2), (1, 2)),
    layers.Conv2D(256, 3, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D((1, 2), (1, 2)),
    layers.Reshape((32, 256)),
    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),
    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),
    layers.Reshape((-1, 32, 512)),
    layers.Conv2D(80, 1, padding=&quot;SAME&quot;),
    layers.Softmax(-1)
])

print(model.summary())

model.compile(tf.optimizers.RMSprop(0.001), ctc_cost)
</code></pre>
<p><strong>Error:</strong></p>
<p><em>tensorflow.python.framework.errors_impl.InvalidArgumentError: squeeze_dims[0] not in [0,0). for 'loss/softmax_loss/Squeeze' (op: 'Squeeze') with input shapes: []</em></p>
<p><strong>Model:</strong></p>
<pre><code>Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 32, 128, 32)       832
batch_normalization (BatchNo (None, 32, 128, 32)       128
activation (Activation)      (None, 32, 128, 32)       0
max_pooling2d (MaxPooling2D) (None, 16, 64, 32)        0
conv2d_1 (Conv2D)            (None, 16, 64, 64)        51264
batch_normalization_1 (Batch (None, 16, 64, 64)        256
activation_1 (Activation)    (None, 16, 64, 64)        0
max_pooling2d_1 (MaxPooling2 (None, 8, 32, 64)         0
conv2d_2 (Conv2D)            (None, 8, 32, 128)        73856
batch_normalization_2 (Batch (None, 8, 32, 128)        512
activation_2 (Activation)    (None, 8, 32, 128)        0
max_pooling2d_2 (MaxPooling2 (None, 8, 16, 128)        0
conv2d_3 (Conv2D)            (None, 8, 16, 128)        147584
batch_normalization_3 (Batch (None, 8, 16, 128)        512
activation_3 (Activation)    (None, 8, 16, 128)        0
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0
conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168
batch_normalization_4 (Batch (None, 8, 8, 256)         1024
activation_4 (Activation)    (None, 8, 8, 256)         0
max_pooling2d_4 (MaxPooling2 (None, 8, 4, 256)         0
reshape (Reshape)            (None, 32, 256)           0
bidirectional (Bidirectional (None, 32, 512)           1050624
bidirectional_1 (Bidirection (None, 32, 512)           1574912
reshape_1 (Reshape)          (None, None, 32, 512)     0
conv2d_5 (Conv2D)            (None, None, 32, 80)      41040     
softmax (Softmax)            (None, None, 32, 80)      0
</code></pre>
<p><strong>Here is the tensorflow documentation I was referencing:</strong></p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_batch_cost"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_batch_cost</a></p>
",2020-03-20 21:51:18,11900339,53,https://stackoverflow.com/questions/60782077,Documentation Ambiguity
60801403,NotFoundError: No registered 'PyFunc' OpKernel for 'CPU' devices compatible with node {{node PyFunc}} . Registered: <no registered kernels>,"<p>I am getting an error while trying to access data from a tf.data.Dataset object.
The dataset object is built from a generator. Any help will be appreciated.
I'm using TensorFlow 2 and trying to run the example from <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator</a></p>

<pre><code>def gen(): 
  for i in itertools.count(1): 
    yield (i, [1] * i) 

dataset = tf.data.Dataset.from_generator( 
     gen, 
     (tf.int64, tf.int64), 
     (tf.TensorShape([]), tf.TensorShape([None]))) 

list(dataset.take(3).as_numpy_iterator()) 
</code></pre>

<p>The  error is : </p>

<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)
    662         # Fast path for the case `self._structure` is not a nested structure.
--&gt; 663         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    664       except AttributeError:

AttributeError: 'tuple' object has no attribute '_from_compatible_tensor_list'

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py in execution_mode(mode)
   1896     ctx.executor = executor_new
-&gt; 1897     yield
   1898   finally:



...  
NotFoundError                             Traceback (most recent call last)
&lt;ipython-input-25-ac0e933e02b3&gt; in &lt;module&gt;
----&gt; 1 list(dataset.take(3).as_numpy_iterator())

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in __next__(self)
   3640 
   3641   def __next__(self):
-&gt; 3642     return self.next()
   3643 
   3644 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in next(self)
   3637 
   3638   def next(self):
-&gt; 3639     return nest.map_structure(lambda x: x.numpy(), next(self._iterator))
   3640 
   3641   def __next__(self):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in __next__(self)
    628 
    629   def __next__(self):  # For Python 3 compatibility
--&gt; 630     return self.next()
    631 
    632   def _next_internal(self):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in next(self)
    672     """"""Returns a nested structure of `Tensor`s containing the next element.""""""
    673     try:
--&gt; 674       return self._next_internal()
    675     except errors.OutOfRangeError:
    676       raise StopIteration

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)
    663         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    664       except AttributeError:
--&gt; 665         return structure.from_compatible_tensor_list(self._element_spec, ret)
    666 
    667   @property

/opt/conda/lib/python3.6/contextlib.py in __exit__(self, type, value, traceback)
     97                 value = type()
     98             try:
---&gt; 99                 self.gen.throw(type, value, traceback)
    100             except StopIteration as exc:
    101                 # Suppress StopIteration *unless* it's the same exception that

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py in execution_mode(mode)
   1898   finally:
   1899     ctx.executor = executor_old
-&gt; 1900     executor_new.wait()
   1901 
   1902 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/executor.py in wait(self)
     65   def wait(self):
     66     """"""Waits for ops dispatched in this executor to finish.""""""
---&gt; 67     pywrap_tensorflow.TFE_ExecutorWaitForAllPendingNodes(self._handle)
     68 
     69   def clear_error(self):

NotFoundError: No registered 'PyFunc' OpKernel for 'CPU' devices compatible with node {{node PyFunc}}
    .  Registered:  &lt;no registered kernels&gt;
</code></pre>
",2020-03-22 15:45:48,7849569,454,https://stackoverflow.com/questions/60801403,Documentation Replicability
60919434,String to one_hot tensor in Tensorflow,"<p>I have found in tensorflow doc the following function to compute and apply a vocabulary onto a string tensor but it was still using <code>tf.session</code> and I can't make it work with <code>tf.function</code>:</p>

<pre><code>import tensorflow as tf
import tensorflow_transform as tft


@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.string),))
def string_to_one_hot(labels):
    codes = tft.compute_and_apply_vocabulary(labels)
    return tf.one_hot(codes, depth=tf.cast(tf.reduce_max(codes), tf.int32))


test_labels = tf.constant(['a', 'b', 'a', 'c'])
test_one_hot = string_to_one_hot(test_labels)

&gt; tensorflow.python.framework.errors_impl.InvalidArgumentError:  You must feed a value for placeholder tensor 'compute_and_apply_vocabulary/vocabulary/Placeholder' with dtype string
     [[node compute_and_apply_vocabulary/vocabulary/Placeholder (defined at /Users/clementwalter/.pyenv/versions/keras_fsl/lib/python3.6/site-packages/tensorflow_transform/analyzer_nodes.py:102) ]] [Op:__inference_string_to_one_hot_52]

</code></pre>

<h2>EDIT</h2>

<p>I have been able to build such a function with direct use of the hash facilities. However I have had to use a hard-coded bucket_size/depth param. Any ideas?</p>

<pre><code>@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.string),))
def string_to_one_hot(labels):
    one_hot = tf.one_hot(tf.strings.to_hash_bucket_fast(labels, 1024), depth=1024)
    return tf.boolean_mask(one_hot, tf.reduce_sum(one_hot, axis=0) &gt; 0, axis=1)
</code></pre>
",2020-03-29 19:09:25,4444546,4964,https://stackoverflow.com/questions/60919434,Documentation Replicability
60977051,Split a tf.data.Dataset in to two distincts Input and Target tf.data.Dataset,"<p>How can I create two distincts Input and Target tf.data.Dataset from a tf.data.Dataset containing both Input and Target data so that I can uses them as x and y parameters of the model.fit function?</p>

<p>I use the code below to load the dataset</p>

<pre><code>    dataset = tf.data.TFRecordDataset(
        dataset_file_path, 
        compression_type='GZIP', 
        buffer_size=None, 
        num_parallel_reads=None
    )
</code></pre>
",2020-04-01 17:43:08,9560337,21,https://stackoverflow.com/questions/60977051,Documentation Replicability
61026862,"why ""NumPy operations convert Tensors to numpy arrays automatically""? how does this feature been implemented?","<p>Reading TensorFlow docs: <a href=""https://www.tensorflow.org/tutorials/customization/basics#numpy_compatibility"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/customization/basics#numpy_compatibility</a></p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np

ndarray = np.ones([3, 3])

print(""TensorFlow operations convert numpy arrays to Tensors automatically"")
tensor = tf.multiply(ndarray, 42)
print(tensor)


print(""And NumPy operations convert Tensors to numpy arrays automatically"")
print(np.add(tensor, 1))

print(""The .numpy() method explicitly converts a Tensor to a numpy array"")
print(tensor.numpy())
</code></pre>

<blockquote>
  <p>tensor = tf.multiply(ndarray, 42)</p>
</blockquote>

<p>TF APIs support NumPy objects as inputs and this is easy to understand because TF APIs are just implemented to handle NumPy objects by TensorFlow Team.</p>

<p>But</p>

<blockquote>
  <p>print(np.add(tensor, 1))</p>
</blockquote>

<p>On the contrary, why NumPy APIs could handle a tf.Tensor is quite amazing to me.
Is this a mechanism that NumPy provided to handle any type of objects? 
Or just supported by Python in language level ? (I am new to Python)</p>
",2020-04-04 10:40:23,6770916,167,https://stackoverflow.com/questions/61026862,Documentation Replication on Other Examples
61031226,How to use Keras tf.data with generator ( flow_from_dataframe ) ? to form a perfect input pipeline,"<p><strong>Using the input pipelines with tf.data</strong></p>

<p><a href=""https://i.stack.imgur.com/c5ps5.png"" rel=""nofollow noreferrer"">Generating the Dataset using tf.data.Dataset.from_generator()</a></p>

<p><a href=""https://i.stack.imgur.com/jJuok.png"" rel=""nofollow noreferrer"">The output I got after fitting the model with the train_dataset</a></p>
",2020-04-04 16:31:14,8706702,1,https://stackoverflow.com/questions/61031226,Documentation Replicability
61059725,Why does tf.constant give a dtype error if we pass in a tensor?,"<p>The following code</p>

<pre><code>a = tf.range(10)
b = tf.constant(a, dtype=tf.float32)
</code></pre>

<p>gives the following error:</p>

<pre><code>TypeError: Expected tensor with type tf.float32 not tf.int32
</code></pre>

<p>Although from the <a href=""https://www.tensorflow.org/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">documentation</a>, setting <code>dtype</code> means that <code>tf.constant</code> is supposed to cast <code>a</code> to the specified data type. So I don't see why this should give a type error.</p>

<p>I also know that:</p>

<pre><code>a = np.arange(10)
b = tf.constant(a, dtype=tf.float32)
</code></pre>

<p>does not give an error.</p>

<p>So actually, I'm mainly wondering about what's happening under the hood here.</p>
",2020-04-06 12:20:03,4391249,2921,https://stackoverflow.com/questions/61059725,Documentation Ambiguity
61175291,Why is optimizer.minimize not working if we pass loss as tf.constant?,"<p>I simply have <code>train = optimizer.minimize(loss = tf.constant(4,dtype=""float32""))</code> Line of code that i change before everything is working. <br/></p>

<p>Why it is giving error ? Because documentation say it can be tensor <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam#minimize"" rel=""nofollow noreferrer"">Here is Docs</a> </p>

<pre><code>W = tf.Variable([0.5],tf.float32)
b = tf.Variable([0.1],tf.float32)
x = tf.placeholder(tf.float32)
y= tf.placeholder(tf.float32)
discounted_reward = tf.placeholder(tf.float32,shape=[4,], name=""discounted_reward"")
linear_model = W*x + b

squared_delta = tf.square(linear_model - y)
print(squared_delta)
loss = tf.reduce_sum(squared_delta*discounted_reward)
print(loss)
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss = tf.constant(4,dtype=""float32""))
init = tf.global_variables_initializer()
sess = tf.Session()

sess.run(init)

for i in range(3):
    sess.run(train,{x:[1,2,3,4],y:[0,-1,-2,-3],discounted_reward:[1,2,3,4]})

print(sess.run([W,b]))
</code></pre>

<hr>

<p>I really need this thing to work. In this particular example we can have other ways to solve it but i need it to work as my actual code can do this only </p>

<p><hr/> Error is</p>

<pre><code>&gt; ValueError: No gradients provided for any variable, check your graph
&gt; for ops that do not support gradients, between variables
&gt; [""&lt;tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_2:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_3:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_4:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_5:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_6:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_7:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_8:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_9:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_10:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_11:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_12:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_13:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_14:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_15:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_16:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_17:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_18:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_19:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_20:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_21:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_22:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_23:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_24:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_25:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_26:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_27:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_28:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_29:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_30:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_31:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_32:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_33:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_34:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_35:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_36:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_37:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_38:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_39:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_40:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_41:0' shape=(1,) dtype=float32_ref&gt;""] and loss
&gt; Tensor(""Const_4:0"", shape=(), dtype=float32).
</code></pre>
",2020-04-12 17:16:58,6543342,2453,https://stackoverflow.com/questions/61175291,Documentation Replication on Other Examples
61245158,Failed to apply vectorizing mapping for tf.data in Tensorflow 2.1.0,"<p>I wrote a program to load data by tf.data with Tensorflow 2.1.0. I wanted to speed up data pipeline and I studied the document in <a href=""https://www.tensorflow.org/guide/data_performance#vectorizing_mapping"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/data_performance#vectorizing_mapping</a>.</p>

<p>I would like to apply vectorizing mapping for tf.data and the code snippet is listed as below:</p>

<pre><code>import tensorflow as tf

data = tf.data.TFRecordDataset(['images.tfrecord'])

image_feature_description = {
    'height': tf.io.FixedLenFeature([], tf.int64),
    'width': tf.io.FixedLenFeature([], tf.int64),
    'depth': tf.io.FixedLenFeature([], tf.int64),
    'bboxes': tf.io.VarLenFeature(tf.int64),
    'image_raw': tf.io.FixedLenFeature([], tf.string),
}

def parse_example(example):
    data = tf.io.parse_example(example, image_feature_description)

    img = tf.io.decode_jpeg(data['image_raw'])

    img = tf.image.resize(img, (416, 416))

    bboxes = data['bboxes']
    bboxes = tf.sparse.to_dense(bboxes)
    bboxes = tf.reshape(bboxes, [-1, 5])

    return img, bboxes


#data = data.map(parse_example).batch(1)  # this works
data = data.batch(1).map(parse_example)  # apply vectorizing mapping but it raises errors
</code></pre>

<p>The errors are listed as below:</p>

<pre><code>Traceback (most recent call last):
  File ""test_tfrecord.py"", line 28, in &lt;module&gt;
    data = data.batch(1).map(parse_example)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1588, in map
    return MapDataset(self, map_func, preserve_cardinality=True)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3888, in __init__
    use_legacy_function=use_legacy_function)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3147, in __init__
    self._function = wrapper_fn._get_concrete_function_internal()
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2395, in _get_concrete_function_internal
    *args, **kwargs)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3140, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3082, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

test_tfrecord.py:16 parse_example  *
    img = tf.io.decode_jpeg(data['image_raw'])
/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_image_ops.py:1092 decode_jpeg
    dct_method=dct_method, name=name)
/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper
    attrs=attr_protos, op_def=op_def)
/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal
    compute_device)
/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal
    op_def=op_def)
/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__
    control_input_ops)
/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op
    raise ValueError(str(e))

ValueError: Shape must be rank 0 but is rank 1 for 'DecodeJpeg' (op: 'DecodeJpeg') with input shapes: [?].
</code></pre>

<p>How should I fix it? Thanks</p>
",2020-04-16 07:49:16,6244978,586,https://stackoverflow.com/questions/61245158,Documentation Replicability
61273445,Tensorflow MapDataset iterator fails,"<p>I am trying to implement the method suggested by the tensorflow documentation over here (<a href=""https://www.tensorflow.org/tutorials/load_data/images"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/load_data/images</a>) to load images from local directory as a tensorflow dataset. Especially I am interested in loading using tf.data as a tf.data.Dataset object as it is suggested that the performance is better that way. I pretty much took the exact code from the documentation page and also made sure that the tensorflow version matches to the one in the documentation</p>

<p>The problem happens when I try to iterate over the MapDataset object using take().</p>

<pre><code>import os
import sys
import pathlib

import IPython.display as display
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf

AUTOTUNE = tf.data.experimental.AUTOTUNE

BATCH_SIZE = 32
IMG_HEIGHT = 224
IMG_WIDTH = 224
STEPS_PER_EPOCH = np.ceil(3670/BATCH_SIZE)
CLASS_NAMES = None

#https://www.tensorflow.org/tutorials/load_data/images

def get_label(file_path):
    # convert the path to a list of path components
    #parts = tf.strings.split(file_path, result_type = 'RaggedTensor')
    parts = tf.strings.split(file_path)

    # The second to last is the class-directory
    return parts[-2] == CLASS_NAMES

def decode_img(img):
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_jpeg(img, channels=3)

    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)

    # resize the image to the desired size.
    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])

def process_path(file_path):
    label = get_label(file_path)

    # load the raw data from the file as a string
    img = tf.io.read_file(file_path)
    img = decode_img(img)

    return img, label

def test():

    data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
                                         fname='flower_photos', untar=True)

    data_dir = pathlib.Path(data_dir)

    global CLASS_NAMES
    CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != ""LICENSE.txt""])

    list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))

    labeled_ds = list_ds.map(process_path)
    print('type: ', type(labeled_ds))

    for image, label in labeled_ds.take(1):
        print(""Image shape: "", image.numpy().shape)
        print(""Label: "", label.numpy())

def main():
    test()  

if __name__ == '__main__':
    main()

</code></pre>

<p>I get the following error and have no idea how to go about resolving this</p>

<pre><code>2020-04-17 09:47:53.816123: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.
2020-04-17 09:47:53.820082: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at iterator_ops.cc:941 : Invalid argument: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
Traceback (most recent call last):
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\eager\context.py"", line 1897, in execution_mode
    yield
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 659, in _next_internal
    output_shapes=self._flat_output_shapes)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_dataset_ops.py"", line 2478, in iterator_get_next_sync
    _ops.raise_from_not_ok_status(e, name)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 6606, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""&lt;string&gt;"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]] [Op:IteratorGetNextSync]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "".\img_sub_model.py"", line 150, in &lt;module&gt;
    main()
  File "".\img_sub_model.py"", line 145, in main
    test()
  File "".\img_sub_model.py"", line 136, in test
    for image, label in labeled_ds.take(1):
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 630, in __next__
    return self.next()
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 674, in next
    return self._next_internal()
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 665, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\eager\context.py"", line 1900, in execution_mode
    executor_new.wait()
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\eager\executor.py"", line 67, in wait
    pywrap_tensorflow.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
</code></pre>

<p>By some random coincidence I found that when CLASS_NAMES is set to None, the code runs and the lebel object of labeled_ds has a value 'False'</p>

<p>See output below</p>

<pre><code>type:  &lt;class 'tensorflow.python.data.ops.dataset_ops.MapDataset'&gt;
Image shape:  (224, 224, 3)
Label:  False
</code></pre>
",2020-04-17 13:59:50,3357373,71,https://stackoverflow.com/questions/61273445,Documentation Replication on Other Examples
61280184,Model with multiple outputs and custom loss function,"<p>I'm trying to train a model that has multiple outputs and a custom loss function using keras, but I'm getting some error <code>tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: iterating over ``tf.Tensor`` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.</code></p>

<p>It's hard to debug it because I'm doing <code>model.compile</code> and <code>model.fit</code>. I think it has something to do with how models are supposed to be defined when having multiple outputs, but I can't find good documentation on this. The guide specifies how to have models with multiple outputs suing the functional API, and has an example for this, but it doesn't clarify how custom loss functions should work when subclassing the <code>Model</code> API. My code is as follows:</p>

<pre><code>class DeepEnsembles(Model):

    def __init__(self, **kwargs):
        super(DeepEnsembles, self).__init__()

        self.num_models = kwargs.get('num_models')
        model = kwargs.get('model')

        self.mean = [model(**dict(**kwargs)) for _ in range(self.num_models)]

        self.variance = [model(**dict(**kwargs)) for _ in range(self.num_models)]

    def call(self, inputs, training=None, mask=None):
        mean_predictions = []
        variance_predictions = []
        for idx in range(self.num_models):
            mean_predictions.append(self.mean[idx](inputs, training=training))
            variance_predictions.append(self.variance[idx](inputs, training=training))
        mean_stack = tf.stack(mean_predictions)
        variance_stack = tf.stack(variance_predictions)

        return mean_stack, variance_stack
</code></pre>

<p>And where MLP is the following:</p>

<pre><code>class MLP(Model):
    def __init__(self, **kwargs):
        super(MLP, self).__init__()

        # Initialization parameters
        self.num_inputs = kwargs.get('num_inputs', 779)
        self.num_outputs = kwargs.get('num_outputs', 1)
        self.hidden_size = kwargs.get('hidden_size', 256)
        self.activation = kwargs.get('activation', 'relu')

        # Optional parameters
        self.p = kwargs.get('p', 0.05)

        self.model = tf.keras.Sequential([
            layers.Dense(self.hidden_size, activation=self.activation, input_shape=(self.num_inputs,)),
            layers.Dropout(self.p),
            layers.Dense(self.hidden_size, activation=self.activation),
            layers.Dropout(self.p),
            layers.Dense(self.num_outputs)
         ])

    def call(self, inputs, training=None, mask=None):
        output = self.model(inputs, training=training)
        return output

</code></pre>

<p>I'm trying to minimize a custom loss function </p>

<pre><code>class GaussianNLL(Loss):

    def __init__(self):
        super(GaussianNLL, self).__init__()

    def call(self, y_true, y_pred):

        mean, variance = y_pred
        variance = variance + 0.0001
        nll = (tf.math.log(variance) / 2 + ((y_true - mean) ** 2) / (2 * variance))
        nll = tf.math.reduce_mean(nll)
        return nll

</code></pre>

<p>Finally, this is how I try to train it:</p>

<pre><code>    ensembles_params = {'num_models': 5, 'model': MLP, 'p': 0}
    model = DeepEnsembles(**ensembles_params)
    loss_fn = GaussianNLL()
    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)
    epochs = 10000

    model.compile(optimizer='adam',
                  loss=loss_fn,
                  metrics=['mse', 'mae'])
    history = model.fit(x_train, y_train,
                        batch_size=2048,
                        epochs=10000,
                        verbose=0,
                        validation_data=(x_val, y_val))
</code></pre>

<p>Which results in the above error. Any pointers? In particular, the whole stack trace is </p>

<pre><code>Traceback (most recent call last):
  File ""/home/emilio/anaconda3/lib/python3.7/contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py"", line 2803, in variable_creator_scope
    yield
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 593, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 646, in _process_inputs
    x, y, sample_weight=sample_weights)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2360, in _standardize_user_data
    self._compile_from_inputs(all_inputs, y_input, x, y)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2618, in _compile_from_inputs
    experimental_run_tf_function=self._experimental_run_tf_function)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 446, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1592, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1652, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File ""/home/emilio/fault_detection/tensorflow_code/tf_utils/loss.py"", line 13, in call
    mean, variance = y_pred
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 539, in __iter__
    self._disallow_iteration()
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 535, in _disallow_iteration
    self._disallow_in_graph_mode(""iterating over `tf.Tensor`"")
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 515, in _disallow_in_graph_mode
    "" this function with @tf.function."".format(task))
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.


</code></pre>

<p>So it's clearly related to the loss function. But the model's forward pass outputs a tuple, which I unpack in the loss function, so I don't know why is this an issue.</p>
",2020-04-17 20:31:59,4934261,91,https://stackoverflow.com/questions/61280184,Lack of Alternative Solutions/Documentation
61293983,How does a tf.train.Int64LIst hold dtype unint64?,"<p>From the tensorflow docs for <a href=""https://www.tensorflow.org/tutorials/load_data/tfrecord"" rel=""nofollow noreferrer"">TFRecords and tf.Example</a>, it states on the topic of <code>tf.train.Feature</code>:</p>

<blockquote>
  <p>The <code>tf.train.Feature</code> message type can accept one of the following three types (See the .proto file for reference). Most other generic types can be coerced into one of these:</p>
  
  <p><code>tf.train.BytesList</code></p>
  
  <p>...</p>
  
  <p><code>tf.train.FloatList</code></p>
  
  <p>...</p>
  
  <p><code>tf.train.Int64List</code> (the following types can be coerced)</p>
  
  <ul>
  <li>bool</li>
  <li>enum</li>
  <li>int32</li>
  <li>uint32</li>
  <li>int64</li>
  <li>uint64</li>
  </ul>
</blockquote>

<p>How is it possible to store a <code>uint64</code> dtype into a <code>Int64List</code>?</p>
",2020-04-18 18:13:35,11070463,3868,https://stackoverflow.com/questions/61293983,Documentation Replicability
61355289,When will tf.print ACTUALLY WORK as expected (i.e. print the values of tensors and variables)?,"<p>First of all, I am using TensorFlow 2.0 and I only care about this version or higher (and I am already caring too much for such a piece of software that only produces headaches).</p>

<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/print"" rel=""nofollow noreferrer"">TensorFlow documentation</a> of <code>tf.print</code> says </p>

<blockquote>
  <p>Print the specified inputs.</p>
</blockquote>

<p>and then</p>

<blockquote>
  <p>A TensorFlow operator that prints the specified inputs to a desired output stream or logging level. The inputs may be </p>
  
  <ul>
  <li><strong>dense</strong> or </li>
  <li><strong>sparse Tensors</strong>, </li>
  <li><strong>primitive python objects</strong>, </li>
  <li><strong>data structures that contain tensors</strong>, and </li>
  <li><strong>printable Python objects</strong>. </li>
  </ul>
  
  <p>Printed tensors will recursively show the first and last elements of each dimension to summarize. </p>
</blockquote>

<p>This is all very nice, but I still don't get where <code>tf.print</code> will ACTUALLY WORK (i.e. print the VALUES of variables and tensors) in my code. Of course, needless to say, I couldn't care less about the symbolic representations of tensors, variables or whatever. Whenever I try to use <code>tf.print</code>, I want to see the VALUES (real numbers, vectors or matrices). </p>

<p>I've tried to use <code>tf.print</code> in multiple cases and in multiple places, e.g. </p>

<ul>
<li><p>in a method that is called from the <code>__init__</code> method of a custom layer that is called during model building (so before compiling the model) in order to print the value of a tensor (at least, this is what the <code>type(my_var)</code> returns, i.e. it returns <code>&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;</code>), but nothing is printed. If I try to add <code>@tf.function</code> (I still don't get the usage of this function!), nothing changes. According to the documentation above <code>tf.print</code> is supposed to print tensors, my variable is a tensor and TensorFlow decides to ignore my call, and then one wonders why did I decide to use TF? Why? </p>

<p>Also, I am using TF 2.0 and, even if I don't use the decorator <code>@tf.function</code>, <code>print(tf.executing_eagerly())</code> prints False, which is really what I was expecting.</p></li>
<li><p>in a custom loss function, where a similar behaviour happens (i.e. sometimes something is printed, sometimes it is not, sometimes I try to add the decorator <code>@tf.function</code> to the custom loss function and see if something changes, but nothing changes, or maybe yes).</p></li>
</ul>

<p>Ok, so, as you can see, I have no idea where <code>tf.print</code> will do what I want, i.e. I want to see the values of tensors. If something is a tensor, it must have a value. Similarly for variables.</p>

<p>So, when will <code>tf.print</code> ACTUALLY PRINT THE VALUES OF TENSORS? </p>

<p>I am looking for answers that say e.g., ""<code>tf.print</code> will NEVER work"" or ""it will only work if you are dreaming"". Apart from the jokes and sarcasm, I am really looking for answers that tell me exactly in which places of my code or which stages of developing a model with TF <code>tf.print</code>  will actually do what it is supposed to do. Please, don't tell me that <code>tf.print</code> will work when the input is a tensor!! </p>
",2020-04-22 00:14:30,3924118,15714,https://stackoverflow.com/questions/61355289,Documentation Ambiguity
61355474,Why does tf.executing_eagerly() return False in TensorFlow 2?,"<p>Let me explain my set up. I am using TensorFlow 2.1, the Keras version shipped with TF, and TensorFlow Probability 0.9.</p>

<p>I have a function <code>get_model</code> that creates (with the functional API) and returns a model using Keras and custom layers. In the <code>__init__</code> method of these custom layers <code>A</code>, I call a method <code>A.m</code>, which executes the statement <code>print(tf.executing_eagerly())</code>, but it returns <code>False</code>. Why?</p>

<p>To be more precise, this is roughly my setup</p>

<pre><code>def get_model():
    inp = Input(...)
    x = A(...)(inp) 
    x = A(...)(x)
    ...
    model = Model(inp, out)
    model.compile(...)
    return model

class A(tfp.layers.DenseFlipout): # TensorFlow Probability
    def __init__(...):
        self.m()

    def m(self): 
        print(tf.executing_eagerly()) # Prints False
</code></pre>

<p>The documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/executing_eagerly"" rel=""nofollow noreferrer""><code>tf.executing_eagerly</code></a> says</p>

<blockquote>
  <p>Eager execution is enabled by default and this API returns True in most of cases. However, this API might return False in the following use cases.</p>
  
  <ul>
  <li>Executing inside <code>tf.function</code>, unless under <code>tf.init_scope</code> or <code>tf.config.experimental_run_functions_eagerly(True)</code> is previously called.</li>
  <li>Executing inside a transformation function for <code>tf.dataset</code>.</li>
  <li><code>tf.compat.v1.disable_eager_execution()</code> is called.</li>
  </ul>
</blockquote>

<p>But these cases are not my case, so <code>tf.executing_eagerly()</code> should return <code>True</code> in my case, but no. Why?</p>

<p>Here's a simple complete example (in TF 2.1) that illustrates the problem.</p>

<pre><code>import tensorflow as tf


class MyLayer(tf.keras.layers.Layer):
    def call(self, inputs):
        tf.print(""tf.executing_eagerly() ="", tf.executing_eagerly())
        return inputs


def get_model():
    inp = tf.keras.layers.Input(shape=(1,))
    out = MyLayer(8)(inp)
    model = tf.keras.Model(inputs=inp, outputs=out)
    model.summary()
    return model


def train():
    model = get_model()
    model.compile(optimizer=""adam"", loss=""mae"")
    x_train = [2, 3, 4, 1, 2, 6]
    y_train = [1, 0, 1, 0, 1, 1]
    model.fit(x_train, y_train)


if __name__ == '__main__':
    train()
</code></pre>

<p>This example prints <code>tf.executing_eagerly() = False</code>.</p>

<p>See <a href=""https://github.com/tensorflow/tensorflow/issues/38775"" rel=""nofollow noreferrer"">the related Github issue</a>.</p>
",2020-04-22 00:39:24,3924118,15714,https://stackoverflow.com/questions/61355474,Documentation Replicability
61428918,tensorflow2: keras: model.fit() callbacks and eager mode,"<p>I am running Tensorflow 2.1 with keras API. I am following the following coding style:</p>

<pre><code>    model = tf.keras.Sequential()
    ...
    model.fit(..., callbacks=callbacks)
</code></pre>

<p>Now, I would like to save some intermediate layer tensor value as image summary (as a sample what is happening at n-th training step). In order to do this, I've implemented my own callback class. I've also learned how <code>keras.callbacks.TensorBoard</code> is implemented, since it can save layer weights as image summaries.
I do the following in my <code>on_epoch_end</code>:</p>

<pre><code>tensor = self.model.get_layer(layer_name).output

with context.eager_mode():
    with ops.init_scope():
        tensor = tf.keras.backend.get_value(tensor)
    tf.summary.image(layer_name, tensor, step=step, max_outputs=1)
</code></pre>

<p>Unfortunately, I am still getting issue related to eager/graph modes:</p>

<pre><code>    tensor = tf.keras.backend.get_value(tensor)
  File ""/home/matwey/lab/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 3241, in get_value
    return x.numpy()
AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>

<p>Unfortunately, there is a little to no documentation on how to correctly combine keras callbacks and <code>tf.summary.image</code>. How could I overcome this issue?</p>

<p><strong>upd:</strong> tf_nightly-2.2.0.dev20200427 has the same behaviour.</p>
",2020-04-25 16:30:24,1879547,908,https://stackoverflow.com/questions/61428918,Lack of Alternative Solutions/Documentation
61480051,How to make Google Cloud AI Platform detect `tf.summary.scalar` calls during training?,"<p>(Note: I have also asked this question <a href=""https://github.com/GoogleCloudPlatform/cloudml-hypertune/issues/4"" rel=""noreferrer"">here</a>)</p>

<h3>Problem</h3>

<p>I have been trying to get Google Cloud's AI platform to display the accuracy of a Keras model, trained on the AI platform. I configured the hyperparameter tuning with <code>hptuning_config.yaml</code> and it works. However I can't get AI platform to pick up <code>tf.summary.scalar</code> calls during training.</p>

<h3>Documentation</h3>

<p>I have been following the following documentation pages:</p>

<p><strong>1. <a href=""https://cloud.google.com/ai-platform/training/docs/hyperparameter-tuning-overview"" rel=""noreferrer"">Overview of hyperparameter tuning</a></strong></p>

<p><strong>2. <a href=""https://cloud.google.com/ai-platform/training/docs/using-hyperparameter-tuning"" rel=""noreferrer"">Using hyperparameter tuning</a></strong></p>

<p>According to <strong>[1]</strong>:</p>

<blockquote>
  <p><strong>How AI Platform Training gets your metric</strong>
  You may notice that there are no instructions in this documentation for passing your hyperparameter metric to the AI Platform Training training service. That's because the service monitors TensorFlow summary events generated by your training application and retrieves the metric.""</p>
</blockquote>

<p>And according to <strong>[2]</strong>, one way of generating such a Tensorflow summary event is by creating a callback class as so:</p>

<pre><code>class MyMetricCallback(tf.keras.callbacks.Callback):

    def on_epoch_end(self, epoch, logs=None):
        tf.summary.scalar('metric1', logs['RootMeanSquaredError'], epoch)
</code></pre>

<h3>My code</h3>

<p>So in my code I included:</p>

<pre><code># hptuning_config.yaml

trainingInput:
  hyperparameters:
    goal: MAXIMIZE
    maxTrials: 4
    maxParallelTrials: 2
    hyperparameterMetricTag: val_accuracy
    params:
    - parameterName: learning_rate
      type: DOUBLE
      minValue: 0.001
      maxValue: 0.01
      scaleType: UNIT_LOG_SCALE
</code></pre>

<pre><code># model.py

class MetricCallback(tf.keras.callbacks.Callback):

    def on_epoch_end(self, epoch, logs):
        tf.summary.scalar('val_accuracy', logs['val_accuracy'], epoch)
</code></pre>

<p>I even tried</p>

<pre><code># model.py

class MetricCallback(tf.keras.callbacks.Callback):
    def __init__(self, logdir):
        self.writer = tf.summary.create_file_writer(logdir)

    def on_epoch_end(self, epoch, logs):
        with writer.as_default():
            tf.summary.scalar('val_accuracy', logs['val_accuracy'], epoch)
</code></pre>

<p>Which successfully saved the 'val_accuracy' metric to Google storage (I can also see this with TensorBoard). But this does not get picked up by the AI platform, despite the claim made in <strong>[1]</strong>.</p>

<h3>Partial solution:</h3>

<p>Using the <a href=""https://github.com/GoogleCloudPlatform/cloudml-hypertune"" rel=""noreferrer"">Cloud ML Hypertune</a> package, I created the following class:</p>

<pre><code># model.py

class MetricCallback(tf.keras.callbacks.Callback):
    def __init__(self):
        self.hpt = hypertune.HyperTune()

    def on_epoch_end(self, epoch, logs):
        self.hpt.report_hyperparameter_tuning_metric(
            hyperparameter_metric_tag='val_accuracy',
            metric_value=logs['val_accuracy'],
            global_step=epoch
        )
</code></pre>

<p>which works! But I don't see how, since it all it seems to do is write to a file on the AI platform <strong>worker</strong> at <code>/tmp/hypertune/*</code>. There is nothing in the Google Cloud documentation that explains how this is getting picked up by the AI platform...</p>

<p>Am I missing something in order to get <code>tf.summary.scalar</code> events to be displayed?</p>
",2020-04-28 12:20:22,10143615,305,https://stackoverflow.com/questions/61480051,Documentation Replication on Other Examples
61513032,Another use case of funtools.partial in T5 tutorial code,"<p>I was reading this code. From <code>T5</code> <a href=""https://colab.research.google.com/github/google-research/text-to-text-transfer-transformer/blob/master/notebooks/t5-trivia.ipynb"" rel=""nofollow noreferrer"">tutorial</a>.. I found this snippet.</p>

<pre><code>def nq_dataset_fn(split, shuffle_files=False):
  # We only have one file for each split.
  del shuffle_files

  # Load lines from the text file as examples.
  ds = tf.data.TextLineDataset(nq_tsv_path[split])
  # Split each ""&lt;question&gt;\t&lt;answer&gt;"" example into (question, answer) tuple.
  ds = ds.map(
      functools.partial(tf.io.decode_csv, record_defaults=["""", """"],
                        field_delim=""\t"", use_quote_delim=False),
      num_parallel_calls=tf.data.experimental.AUTOTUNE)
  # Map each tuple to a {""question"": ... ""answer"": ...} dict.
  ds = ds.map(lambda *ex: dict(zip([""question"", ""answer""], ex)))
  return ds
</code></pre>

<p>What did I understand reading this? Well, <code>functools.partial</code> is used for creating a wrapper around some known to manipulate the arguments or to reduce the number of arguments, but what is the use case here? It is confusing, given that we could simply call <code>tf.io.decode_csv</code>? </p>
",2020-04-29 22:49:33,13132388,486,https://stackoverflow.com/questions/61513032,Documentation Ambiguity
61526556,Serializing a tensor and writing to tfrecord from within a graph,"<p>I would like to write tensorflow example records to a TFRecordWriter from inside an AutoGraph generated graph.</p>

<p>The documentation for tensorflow 2.0 states the following:</p>

<blockquote>
  <p>The simplest way to handle non-scalar features is to use tf.serialize_tensor to convert tensors to binary-strings. Strings are scalars in tensorflow.</p>
</blockquote>

<p>However, <code>tf.io.serialize_tensor</code> returns a tensor of byte-string. Creating an Example proto requires a bytes list, not a tensor. </p>

<p>How do I write a tf.train.Example to a tf record from inside a graph?</p>

<p>Code to reproduce:</p>

<pre><code>%tensorflow_version 2.x
import tensorflow as tf

@tf.function
def example_write():
  writer = tf.io.TFRecordWriter(""test.tfr"")
  x = tf.constant([[0, 1], [2, 3]])
  x = tf.io.serialize_tensor(x)
  feature = {
      ""data"": tf.train.Features(
        bytes_list=tf.train.BytesList(value=[x]))
  }
  ex = tf.train.Example(features=tf.train.Features(
      feature=feature))
  writer.write(ex.SerializeToString())

example_write()
</code></pre>

<p>and the error</p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-df8a97eb17c9&gt; in &lt;module&gt;()
     12   writer.write(ex.SerializeToString())
     13 
---&gt; 14 example_write()

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

TypeError: in user code:

    &lt;ipython-input-6-df8a97eb17c9&gt;:6 example_write  *
        feature = {

    TypeError: &lt;tf.Tensor 'SerializeTensor:0' shape=() dtype=string&gt; has type Tensor, but expected one of: bytes
</code></pre>
",2020-04-30 15:03:28,1189782,31,https://stackoverflow.com/questions/61526556,Documentation Replication on Other Examples
61564748,What is the difference in purpose between tf.py_function and tf.function?,"<p>The difference between the two is muddled in my head, notwithstanding the nuances of what is eager and what isn't. From what I gather, the <code>@tf.function</code> decorator has two benefits in that </p>

<ol>
<li>it converts functions into TensorFlow graphs for performance, and</li>
<li>allows for a more Pythonic style of coding by interpreting many (but not all) common-place Python operations into tensor operations, e.g. <code>if</code> into <code>tf.cond</code>, etc.</li>
</ol>

<p>From the definition of <code>tf.py_function</code>, it seems that it does just #2 above. Hence, why bother with <code>tf.py_function</code> when <code>tf.function</code> does the job with a performance improvement to boot and without the inability of the former to serialize?</p>
",2020-05-02 18:55:19,5640161,791,https://stackoverflow.com/questions/61564748,Documentation Ambiguity
61628845,Alternative to tf.compat.v1,"<p>I was trying to migrate my tf1 codes into tf2.</p>

<p>For this purpose, I changed the following functions as follows:</p>

<p><code>tf.losses.softmax_cross_entropy()</code>into<code>tf.compat.v1.losses.softmax_cross_entropy()</code>
<code>tf.train.MomentumOptimizer()</code>into<code>tf.compat.v1.train.MomentumOptimizer()</code>
<code>tf.train.get_or_create_global_step()</code>
into  <code>tf.compat.v1.train.get_or_create_global_step()</code></p>

<p>However, I want to rewrite my codes in tf2 directly without using <code>tf.compat.v1</code></p>

<p>How is it?</p>
",2020-05-06 06:35:12,4088201,3107,https://stackoverflow.com/questions/61628845,Documentation Replication on Other Examples
61692802,How to migrate from TensorFlow 1.x to TensorFlow 2.x,"<pre><code>class Model:
    def __init__(
        self,
        learning_rate,
        num_layers,
        size,
        size_layer,
        output_size,
        forget_bias = 0.1,
    ):
        def lstm_cell(size_layer):
            return tf.compat.v1.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)

        rnn_cells = tf.compat.v1.nn.rnn_cell.MultiRNNCell(
            [lstm_cell(size_layer) for _ in range(num_layers)],
            state_is_tuple = False,
        )
        self.X = tf.compat.v1.placeholder(tf.float32, (None, None, size))
        self.Y = tf.compat.v1.placeholder(tf.float32, (None, output_size))
        drop = tf.compat.v1.nn.rnn_cell.DropoutWrapper(
            rnn_cells, output_keep_prob = forget_bias
        )
        self.hidden_layer = tf.compat.v1.placeholder(
            tf.float32, (None, num_layers * 2 * size_layer)
        )
        self.outputs, self.last_state = tf.compat.v1.nn.dynamic_rnn(
            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32
        )
        self.logits = tf.compat.v1.layers.dense(self.outputs[-1], output_size)
        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))
        self.optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(
            self.cost
        ) 
</code></pre>

<p>i want to convert this code above to relevant TensorFlow 2.x without eager execution, anyone can help?
I been trying to to change few things like: changing <code>tf.compat.v1.nn.rnn_cell.LSTMCell</code> to <code>tf.keras.layers.LSTMCell</code> and <code>tf.compat.v1.nn.rnn_cell.MultiRNNCell</code> to <code>tf.keras.layers.StackedRNNCells</code> also <code>tf.compat.v1.nn.dynamic_rnn</code> to <code>tf.keras.layers.RNN</code>
how do i do this?</p>
",2020-05-09 06:40:20,9359081,11,https://stackoverflow.com/questions/61692802,Documentation Replication on Other Examples
61713523,does tf.function create graph for other functions that it called as well?,"<p>I dont know how exactly the <code>tf.function</code> traces the function that is calling other decorated functions. What is the difference between calling, from within a decorated function, the functions that are decorated vs the functions that are not decorated</p>

<pre><code>@tf.function
def x1(a,b):
  return a+b
</code></pre>

<pre><code>def x2(a,b):
  return a+b
</code></pre>

<pre><code>@tf function
def y(a,b):
  return a+b+x1(a,b)+x2(a,b)
</code></pre>

<p>What happens when the function y is traced by tf.function? If this is the only use <code>x1</code> and <code>x2</code> are ever going to serve then does it make sense to decorate <code>x1</code> with @tf.function?</p>
",2020-05-10 14:19:03,6546694,5020,https://stackoverflow.com/questions/61713523,Documentation Replicability
61717694,Embed trainable bijector into Keras model,"<p>I am trying to implement normalizing flows embedded in a Keras model. In all examples I can find, such as the documentation of <a href=""https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/MaskedAutoregressiveFlow"" rel=""nofollow noreferrer"">MAF</a>, the bijectors which constitute the normalizing flows are embedded into a <code>TransformedDistribution</code> and exposed directly for training etc.</p>

<p>I am trying to embed this TransformedDistribution in a keras Model to match the architecture of other models I have which are inheriting from keras Model. </p>

<p>Unfortunately all my attempts (see code) so far fail at transferring the trainable variables inside the transformed distribution to the keras Model.</p>

<p>I have tried to make the bijector inherit from <code>tf.keras.layers.Layer</code>, which did not change anything.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import tensorflow_probability as tfp

tfd = tfp.distributions
tfb = tfp.bijectors


class Flow(tfb.Bijector, tf.Module):
    """"""
    tf.Module to register trainable_variables
    """"""

    def __init__(self, d, init_sigma=0.1, **kwargs):
        super(Flow, self).__init__(
            dtype=tf.float32,
            forward_min_event_ndims=0,
            inverse_min_event_ndims=0,
            **kwargs
        )
        # Shape of the flow goes from Rd to Rd
        self.d = d
        # Weights/Variables initializer
        self.init_sigma = init_sigma
        w_init = tf.random_normal_initializer(stddev=self.init_sigma)
        # Variables
        self.u = tf.Variable(
            w_init(shape=[1, self.d], dtype=tf.float32),
            dtype=tf.float32,
            name='u',
            trainable=True,
        )

    def _forward(self, x):
        return x

    def _inverse(self, y):
        return y


class Flows(tf.keras.Model):

    def __init__(self, d=2, shape=(100, 2), n_flows=10, ):
        super(Flows, self).__init__()
        # Parameters
        self.d = d
        self.shape = shape
        self.n_flows = n_flows
        # Base distribution - MF = Multivariate normal diag
        base_distribution = tfd.MultivariateNormalDiag(
            loc=tf.zeros(shape=shape, dtype=tf.float32)
        )
        # Flows as chain of bijector
        flows = []
        for n in range(n_flows):
            flows.append(Flow(self.d, name=f""flow_{n + 1}""))
        bijector = tfb.Chain(list(reversed(flows)))
        self.flow = tfd.TransformedDistribution(
            distribution=base_distribution,
            bijector=bijector
        )

    def call(self, *inputs):
        return self.flow.bijector.forward(*inputs)

    def log_prob(self, *inputs):
        return self.flow.log_prob(*inputs)

    def sample(self, num):
        return self.flow.sample(num)


q = Flows()
# Call to instantiate variables
q(tf.zeros(q.shape))
# Prints no trainable params
print(q.summary())
# Prints expected trainable params
print(q.flow.trainable_variables)
</code></pre>

<p>Any idea if this is even possible? Thanks!</p>
",2020-05-10 19:34:30,11552392,436,https://stackoverflow.com/questions/61717694,Documentation Replicability
61762324,why tf.divide does not return a tensor,"<p>If I run the following code using tf2</p>

<pre><code>import tensorflow as tf
import math as m

print(tf.add(5, 2))
print(tf.multiply(5, 2))
print(tf.divide(5, 2))
print(tf.multiply(tf.add(3, 2), tf.add(14, 32)))
print(tf.multiply(2.54, tf.divide(8, 2.6)))
print(tf.subtract(6.3, 2.1045))
print(tf.pow(3.6, 2))
print(tf.add(1, tf.pow(2, 2)))
print(tf.sqrt(5.0))
print(tf.cos(m.pi))
</code></pre>

<p>I get this as an ouput </p>

<pre><code>tf.Tensor(7, shape=(), dtype=int32)
tf.Tensor(10, shape=(), dtype=int32)
2.5
tf.Tensor(230, shape=(), dtype=int32)
tf.Tensor(7.815385, shape=(), dtype=float32)
tf.Tensor(4.1955004, shape=(), dtype=float32)
tf.Tensor(12.959999, shape=(), dtype=float32)
tf.Tensor(5, shape=(), dtype=int32)
tf.Tensor(2.236068, shape=(), dtype=float32)
tf.Tensor(-1.0, shape=(), dtype=float32)
</code></pre>

<p>Why only tf.divide does not return a tensor?</p>
",2020-05-12 21:30:01,3926152,1040,https://stackoverflow.com/questions/61762324,Documentation Replicability
61797375,Boolean Column as Tensorflow Feature Columns,"<p>I like to add a boolean type column into the feature columns for the input layers. How can I do that? I can't find any class of tf.feature_column that I can treat the boolean type data. Thanks in advance! </p>

<pre><code>CATEGORICAL_COLUMNS = ['A','B','C','D','E','F']
BOOLEAN_COLUMNS = 'G'

def one_hot_cat_column(feature_name, vocab):
  return tf.feature_column.indicator_column(
      tf.feature_column.categorical_column_with_vocabulary_list(feature_name,
                                                 vocab))
feature_columns = []
for feature_name in CATEGORICAL_COLUMNS:
  # Need to one-hot encode categorical features.
  vocabulary = df[feature_name].unique()
  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))
</code></pre>
",2020-05-14 12:29:41,13479017,395,https://stackoverflow.com/questions/61797375,Inadequate Examples
61829273,Error trying to feed a tf.keras model with a tf.data.Dataset instead of tensors,"<p>Why does the following tf2 tf.keras model 'work' when fitted with tensors but generates a ValueError when attempting to fit the same tensors in tf.data.Dataset.from_tensor_slices form?</p>

<p>EDIT: Put another way, having developed/fitted/tested etc the model below using numpy arrays. How do those same numpy arrays need to be reshaped(?) so that they can be used to create a dataset with tf.data.Dataset.from_tensor_slices that works with the model?</p>

<pre><code>embed = ""https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1""
hub_layer = hub.KerasLayer(embed, output_shape=[20], input_shape=[], 
                           dtype=tf.string, trainable=True, name='hub_layer')

# from tf hub docs.  hub_layer takes a 1D tensor of strings.

input_tensor = tf.keras.Input(shape=(), name=""input_enquiry"", dtype=tf.string) # Note tf.string. Ref: https://github.com/tensorflow/hub/issues/483
hub_tensor = hub_layer(input_tensor)
x = tf.keras.layers.Dense(16, activation='relu')(hub_tensor)
main_output = tf.keras.layers.Dense(units=4, activation='softmax', name='main_output')(x)

model = tf.keras.models.Model(inputs=[input_tensor], outputs=[main_output])
model.compile(optimizer='adam', loss=tf.losses.CategoricalCrossentropy(),metrics='acc')

# Input and target
X = tf.constant([['The quick brown fox'], ['Hello World']])
y = tf.constant([[0,0,0,1], [0,0,1,0]])

# Works OK
model.fit(X, y) # fit on tensors

X_ds = tf.data.Dataset.from_tensor_slices(X)

# Works OK
model.predict(X_ds) # predict on dataset

y_ds = tf.data.Dataset.from_tensor_slices(y)

ds = tf.data.Dataset.zip((X_ds, y_ds))

# Fails with ValueError
model.fit(ds)
</code></pre>

<p>ValueError:</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in 
     30 
     31 # Fails with ValueError
---&gt; 32 model.fit(ds)
     33 
     34 

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---&gt; 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    846                 batch_size=batch_size):
    847               callbacks.on_train_batch_begin(step)
--&gt; 848               tmp_logs = train_function(iterator)
    849               # Catch OutOfRangeError for Datasets of unknown size.
    850               # This blocks until the batch has finished executing.

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--&gt; 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    609       # In this case we have created variables on the first call, so we run the
    610       # defunned version which is guaranteed to never create variables.
--&gt; 611       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    612     elif self._stateful_fn is not None:
    613       # Release the lock early so that multiple threads can perform the call

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2417     """"""Calls a graph function specialized to the inputs.""""""
   2418     with self._lock:
-&gt; 2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2421 

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2772           and self.input_signature is None
   2773           and call_context_key in self._function_cache.missed):
-&gt; 2774         return self._define_function_with_shape_relaxation(args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _define_function_with_shape_relaxation(self, args, kwargs)
   2704         relaxed_arg_shapes)
   2705     graph_function = self._create_graph_function(
-&gt; 2706         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
   2707     self._function_cache.arg_relaxed[rank_only_cache_key] = graph_function
   2708 

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

~/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:533 train_step  **
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:143 __call__
        losses = self.call(y_true, y_pred)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:246 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy
        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)
    /home/karl/projects/email_analysis/email_venv/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with
        raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))

    ValueError: Shapes (4, 1) and (1, 4) are incompatible
</code></pre>

<p>If instead of using "".from_tensor_slices"" we use "".from_tensors"" to create X_ds and y_ds then, after zipping, all works well.  However, the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">docs</a> give me the impression "".from_tensors"" is memory heavy and not desirable.  Also, I believe that the single element "".from_tensors"" dataset is simply providing the model with two 2D tensors whereas the from_tensor_slices version is a sequence of 1D elements. </p>
",2020-05-15 22:22:30,9763431,41,https://stackoverflow.com/questions/61829273,Documentation Replication on Other Examples
61879049,tf.keras.Model doesn't find assigned variables,"<p>Look at this code (assume Tensorflow 2.1 or 2.2):</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

inputs = tf.keras.Input([])
var = tf.Variable(3.0)
out = var*inputs

model = tf.keras.Model(inputs=inputs, outputs=out)
print(model.variables)             # prints []

model.saved_vars = tf.Module()
model.saved_vars.var = var

print(model.saved_vars.variables)  # prints (&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0&gt;,)
print(model.variables)             # prints []
</code></pre>

<p>Why is <code>model.variables</code> empy? I would expect to contain <code>var</code>.
As I understant the <code>tf.Module</code>, it works as a namescope and also records <code>tf.Variable</code> assigned to their attributes. Since a <code>tf.keras.Model</code> is a <code>tf.Module</code>, it should do the same recursively, shouldn't it?</p>
",2020-05-18 21:11:02,6788571,31,https://stackoverflow.com/questions/61879049,Documentation Replicability
61884176,Understanding tf.name_scope,"<p>I am trying to understand tf.name_scope. The documentation mentions the following:</p>

<p>""This context manager pushes a name scope, which will make the name of all operations added within it have a prefix.</p>

<p>For example, to define a new Python op called my_op:</p>

<pre><code>def my_op(a, b, c, name=None):
  with tf.name_scope(""MyOp"") as scope:
    a = tf.convert_to_tensor(a, name=""a"")
    b = tf.convert_to_tensor(b, name=""b"")
    c = tf.convert_to_tensor(c, name=""c"")
    # Define some computation that uses `a`, `b`, and `c`.
    return foo_op(..., name=scope)
</code></pre>

<p>When executed, the Tensors a, b, c, will have names MyOp/a, MyOp/b, and MyOp/c.""</p>

<p>My understanding is that the with block does not introduce a new local scope in Python. Under normal situation, the tensor variable a will also refer to the local parameter a of function my_op.   How is the name prefixing with ""MyOp/"" implemented using Python context? In the source code link for tf.name_scope (<a href=""https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/framework/ops.py#L6423-L6442"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/framework/ops.py#L6423-L6442</a>) there is an invocation of </p>

<pre><code>ctx = context.context()
</code></pre>

<p>but I could not find the semantics of context.context(). Most context manager discussion talk about <strong>enter</strong> and <strong>exit</strong>, but no mention of variable renaming with some prefix. Is this some introspective mechanism in Python that allows the manipulation of Python variable scopes? Many thanks for any insights.</p>
",2020-05-19 05:57:02,13572195,1,https://stackoverflow.com/questions/61884176,Documentation Replicability
61925035,TensorflowException: Invalid GraphDef (TensorFlow 2.0),"<p>I'm building a model using tf.keras.models.Sequential and saving it as a SavedModel object which contains a saved_model.pb file. The model is then going to be used in a C# service using ML.net.</p>

<p>Here is the code (pulled and adapted from docs)</p>

<pre><code>(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
train_labels = train_labels[:1000]
test_labels = test_labels[:1000]
train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0
test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0

# Define a simple sequential model
def create_model():
    model = tf.keras.models.Sequential([
    keras.layers.Dense(512, activation='relu', input_shape=(784,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10)
    ])

    model.compile(optimizer='adam',
                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])

    return model

# Create a basic model instance
model = create_model()
model.fit(train_images, train_labels, epochs=5)

# Save model
#model.save('/Users/fco/Desktop/saved_model/test.h5', save_format='tf') 
tf.saved_model.save(model, '/Users/fco/Desktop/saved_model')

# Load model
new_model = tf.keras.models.load_model('/Users/fco/Desktop/saved_model')
print(new_model.predict(test_images).shape)
</code></pre>

<p>When loading the saved_model.pb file in ML.NET I get the following exception.</p>

<pre><code>TensorflowException: Invalid GraphDef
</code></pre>

<p>When I search for this error - it references freezing weights on model, but the solutions are for TF1. TF2 seems to have a more streamlined method of saving model, but I cannot understand what is wrong.</p>

<p>Does anyone know what I'm missing?</p>
",2020-05-21 00:12:29,7953944,179,https://stackoverflow.com/questions/61925035,Documentation Replicability
61946509,tf.estimator input_fn and eager mode,"<p>I tried to use <code>numpy</code> inside <code>cnn_model.evaluate()</code>, but it gave <code>AttributeError: 'Tensor' object has no attribute 'numpy'</code>. I used <code>numpy</code> to calculate accuracy and mean squared error using <code>tf.keras.metrics.Accuracy()</code> and <code>tf.keras.metrics.MeanSquaredError()</code> inside <code>cnn_model.evaluate()</code></p>

<p>I googled it, and in tensorflow documentation, it said </p>

<p><strong>""Calling methods of Estimator will work while eager execution is enabled. However, the model_fn and input_fn is not executed eagerly, Estimator will switch to graph mode before calling all user-provided functions (incl. hooks), so their code has to be compatible with graph mode execution.""</strong>  </p>

<p>So, I was wondering how I can update the current tf 1.x code to tf 2.1.0 code, while also using above information.</p>

<p>My current code is:</p>

<pre><code>eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(
    x={""x"": np.array(train_inputs, dtype=np.float32)},
    y=np.array(train_labels, dtype=np.float32),
    #y=np.array(train_labels),
    batch_size=1,
    num_epochs=1,
    shuffle=False)

eval_results = CNN.evaluate(input_fn=eval_input_fn)
</code></pre>

<p>What I have tried so far is add <code>tf.compat.v1.enable_eager_execution()</code> to the 1) beginning of the code after all the imports, 2) next line right after importing tf, 3) line right before declaring eval_input_fn, 4) line right before calling eval_results, 5) inside CNN model definition. It all failed to turn on the eager mode.</p>

<p>One other option that I found was remove @tf.function decorator, but I have no idea what that means and how to pass input_fn if @tf.function is removed.</p>
",2020-05-22 01:37:37,12997689,81,https://stackoverflow.com/questions/61946509,Documentation Replication on Other Examples
61986166,How can I save a Tensorflow 2.2.0 model with a custom training loop?,"<p>I am struggling to save a tf.keras model to easily load and be able to use it. I have used the tf.keras.Model subclass method to construct a MLP model with a custom loss function, as you can see below:</p>

<pre><code>class MyModel(tf.keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = Dense(400, activation='relu', kernel_initializer=initializers.glorot_uniform(), input_dim=5)
        self.dense2 = Dense(400, activation='relu', kernel_initializer=initializers.glorot_uniform())
        self.dense3 = Dense(400, activation='relu', kernel_initializer=initializers.glorot_uniform())
        self.dense4 = Dense(400, activation='relu', kernel_initializer=initializers.glorot_uniform())
        self.dense_out = Dense(1, activation='relu', kernel_initializer=initializers.glorot_uniform())

    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 5), dtype=tf.float32, name='inputs')])   #CHECK tf.saved_model.save docs!
    def call(self, inputs, **kwargs):
        x = self.dense1(inputs)
        x = self.dense2(x)
        x = self.dense3(x)
        x = self.dense4(x)
        return self.dense_out(x)

    def get_loss(self, X, Y):
        with tf.GradientTape() as tape:
            tape.watch(tf.convert_to_tensor(X))
            Y_pred = self.call(X)
        return tf.reduce_mean(tf.math.square(Y_pred-Y)) + tf.reduce_mean(tf.maximum(0, tape.gradient(Y_pred, X)[:, 2]))

    def get_grad_and_loss(self, X, Y):
        with tf.GradientTape() as tape:
            tape.watch(tf.convert_to_tensor(X))
            L = self.get_loss(X, Y)
        g = tape.gradient(L, self.trainable_weights)
        return g, L
</code></pre>

<p>I then make an instance of the model and proceed with a standard training loop:</p>

<pre><code>model = MyModel()
epochs = 5
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25)
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch)
val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch)
val_acc_metric = tf.keras.metrics.MeanAbsoluteError()


## TRAINING LOOP
losses = []
for epoch in range(epochs):
    print(f'############ START OF EPOCH {epoch + 1} ################')
    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
        grads, L = model.get_grad_and_loss(x_batch_train, y_batch_train)
        losses.append(float(L))
        optimizer.apply_gradients(zip(grads, model.trainable_weights))

        if step % 100 == 0:
            print('Training loss (for one batch) at step %s: %s' % (step, float(L)))
            print(f'Seen so far: {(step+1)*batch} samples')

    # Run a validation loop at the end of each epoch.
    for val_step, (x_batch_val, y_batch_val) in enumerate(val_dataset):
        val_logits = model.call(x_batch_val)
        # Update val metrics
        val_acc_metric(y_batch_val, val_logits)
    val_acc = val_acc_metric.result()
    val_acc_metric.reset_states()
    print(f'Validation acc: {val_acc}')
</code></pre>

<p>I have tried to follow the steps outlined <a href=""https://stackoverflow.com/questions/60930158/tensorflow-saving-subclass-model-which-has-multiple-arguments-to-call-method"">here</a>. I call the model on a random input in order to trigger model.build internally, and then I attempt to save the model using the following:</p>

<pre><code>model.save('mymodel', signatures=model.call.get_concrete_function([tf.TensorSpec(shape=(None, 5), dtype=tf.float32, name='inputs')]))
</code></pre>

<p>I then get this following error:</p>

<pre><code>Traceback (most recent call last):
File ""&lt;input&gt;"", line 1, in &lt;module&gt;
File ""/Users/Maximocravero/opt/miniconda3/envs/finance_research/lib/python3.8/site- 
packages/tensorflow/python/eager/def_function.py"", line 959, in get_concrete_function
concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
File ""/Users/Maximocravero/opt/miniconda3/envs/finance_research/lib/python3.8/site- 
packages/tensorflow/python/eager/def_function.py"", line 871, in 
_get_concrete_function_garbage_collected
return self._stateless_fn._get_concrete_function_garbage_collected(  # pylint: 
disable=protected-access
File ""/Users/Maximocravero/opt/miniconda3/envs/finance_research/lib/python3.8/site- 
packages/tensorflow/python/eager/function.py"", line 2480, in 
_get_concrete_function_garbage_collected
raise ValueError(""Structure of Python function inputs does not match ""
ValueError: Structure of Python function inputs does not match input_signature.
</code></pre>

<p>I don't understand this issue as I specify the same TensorSpec as in the tf.function above the model.call attribute. I attempted this without including the tf.function above the model call, which leads to an error relating to the input dimensions having to be set. I am able to address this by calling the model on an arbitrary input, which does allow me to save the model but I have to compile it prior to using it and I get the following warning:</p>

<pre><code>WARNING:tensorflow:From 
/Users/Maximocravero/opt/miniconda3/envs/finance_research/lib/python3.8/site- 
packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling 
BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with 
constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
</code></pre>

<p>My question is whether or not I am completely missing something or if it is usual to have to compile loaded custom models? I am running <a href=""https://github.com/tensorflow/tensorflow/releases"" rel=""noreferrer"">TensorFlow 2.2.0</a> with Python 3.8.2, and based on the <a href=""https://www.tensorflow.org/guide/keras/save_and_serialize#whole-model_saving_loading"" rel=""noreferrer"">documentation</a> for saving models this should really be quite simple. I am new to TensorFlow so it may well be that it's a silly mistake, but ultimately it's still a basic model with 5 inputs and a single output. Any help would be greatly appreciated. </p>
",2020-05-24 12:45:21,12860541,101,https://stackoverflow.com/questions/61986166,Documentation Replication on Other Examples
61994285,TensorFlow: Error using weighted_categorical_column,"<p>I work on a binary classification problem containing a field STREET. In a first step I used the Tokenization to the get a word list (frequency of how often one word appears in the different datasets). Then I used this information to create two columns in my Dataframe describing the word and how often it was used:</p>

<pre><code>def buildWeightList(indexes, tokenizer):
    weights = []
    for index in indexes:
        if index == 0:
            weights.append(0)
        else:
            weights.append(tokenizer.index_docs.get(index))
    return weights
</code></pre>

<pre><code>street_tokenized = ts.texts_to_sequences(data['STREETPRO'])
data['STREETPRO'] = tf.keras.preprocessing.sequence.pad_sequences(street_tokenized, maxlen=1)
data['STREETFREQ']  = buildWeightList(data['STREETPRO'], ts)
</code></pre>

<p>After I converted the Dataframe to a TensorFlow Dataset I have used the following code to add it to my future columns:</p>

<pre><code>vocabulary_list = np.arange(0, street_num_words + 1, 1).tolist()
street_voc = tf.feature_column.categorical_column_with_vocabulary_list(
    key='STREETPRO', vocabulary_list=vocabulary_list, dtype=tf.dtypes.int64)

weighted_street = tf.feature_column.weighted_categorical_column(categorical_column=street_voc, weight_feature_key='STREETFREQ', dtype=tf.dtypes.int64)
street_one_hot = feature_column.indicator_column(weighted_street)

feature_columns.append(street_one_hot)
</code></pre>

<p>As you can see I used the function tf.feature_column.weighted_categorical_column. Unfortunately I get the following error when I try to train my model:</p>

<pre><code>InvalidArgumentError:  indices and values rows (indexing dimension) must match. (indices = 5, values = 1)
     [[node sequential/dense_features_2/STREETPRO_weighted_by_STREETFREQ_indicator/SparseMerge/SparseReorder (defined at &lt;ipython-input-40-964101dd1dc8&gt;:3) ]] [Op:__inference_train_function_986]
</code></pre>

<p>Furthermore I get the following warning:</p>

<pre><code>WARNING:tensorflow:From ...\feature_column\feature_column_v2.py:4366: sparse_merge (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
</code></pre>

<p>Now I have two questions:</p>

<p><strong>First</strong>: does it make sense to use this function for my described problem? Unfortunately, I couldn’t find a detailed description how this function works (only this short documentations: <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/weighted_categorical_column"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/feature_column/weighted_categorical_column</a>) </p>

<p><strong>Second</strong>: How can I fix the described error?</p>
",2020-05-25 01:00:57,11986067,439,https://stackoverflow.com/questions/61994285,Lack of Alternative Solutions/Documentation
62039068,Advice on how to create a custom tf.keras optimizer (optimizer_v2),"<p>I want to make an <em>accumulated SGD optimizer</em> for <code>tf.keras</code> (not <code>keras</code> standalone). I have found a couple of implementations of standalone <code>keras</code> accumulated SGD optimizers including this <a href=""https://pypi.org/project/runai/"" rel=""nofollow noreferrer"">one</a> on pypi. Nevertheless, I am using a project which make use of <code>tf.keras</code>. And as I have seen it's not a good idea to mix them together. </p>

<p>The problem is that the documentation for achieving this custom optimizer is not really straight forward. The base class (which I should inherit from) is <a href=""https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"" rel=""nofollow noreferrer"">Optimizer_v2.py</a> which contains some information in the comment section about the task.</p>

<p>The required methods that should be overridden are:
    - <code>resource_apply_dense</code> (update variable given gradient tensor is dense)
    - <code>resource_apply_sparse</code> (update variable given gradient tensor is sparse)
    - <code>create_slots</code> (if your optimizer algorithm requires additional variables)
    - <code>get_config</code> (serialization of the optimizer, include all hyper parameters)</p>

<p>Of course of these ones only <code>get_config()</code> actually exists in the base class. <code>resource_apply_dense</code> is actually <code>_resource_apply_dense</code>, <code>resource_apply_sparse</code> is <code>_resource_apply_sparse</code> and <code>create_slots</code> does not even exist in base class. In subclasses as <code>SGD</code> in <code>gradient_decent.py</code>, <code>create_slots</code> also exists as <code>_create_slots</code>. </p>

<p>Anyway, apparently the documentation is not updated (there is also an issue regarding this in git but I don't remember the link which pointed this lack of consistency with the documentation) but this makes the whole procedure difficult. For example in <code>SGD</code> I have to override the <code>_resource_apply_dense()</code> method but I cannot understand where the gradients are being calculated and where they are updated.</p>

<p>The actual code is given below:</p>

<pre><code>def _resource_apply_dense(self, grad, var, apply_state=None):
        var_device, var_dtype = var.device, var.dtype.base_dtype
        coefficients = ((apply_state or {}).get((var_device, var_dtype))
                        or self._fallback_apply_state(var_device, var_dtype))

        if self._momentum:
          momentum_var = self.get_slot(var, ""momentum"")
          return training_ops.resource_apply_keras_momentum(
              var.handle,
            momentum_var.handle,
            coefficients[""lr_t""],
            grad,
            coefficients[""momentum""],
            use_locking=self._use_locking,
            use_nesterov=self.nesterov)
        else:
            return training_ops.resource_apply_gradient_descent(
                var.handle, coefficients[""lr_t""], grad, use_locking=self._use_locking)
</code></pre>

<p>which obviously rely on <code>training_ops.resource_apply_keras_momentum</code> and <code>training_ops.resource_apply_gradient_descent</code> to do the actual job. How can I split the 2 parts mentioned in the <code>minimize()</code> method in <code>OptimizerV2</code> from the above code? The 2 parts are:
<code>_compute_gradients()</code> and <code>apply_gradients()</code>.</p>

<p>There are a lot of parts that are confusing in this comments like for example in the base class:</p>

<blockquote>
  <p>Many optimizer subclasses, such as <code>Adam</code> and <code>Adagrad</code> allocate and
  manage   additional variables associated with the variables to train. 
  These are called   <i>Slots</i>.  Slots have names and you can ask the
  optimizer for the names of   the slots that it uses.</p>
</blockquote>

<p>although if I declare an Adam optimizer and ask for slot names I get an empty list (?).</p>

<pre><code>optimizer = Adam(lr=1e-3)    
optimizer.get_slot_names()

[]
</code></pre>

<p>Another confusing issue is the use of private methods which is not clear when they are called and what's their purpose. For example <code>_prepare_local()</code> is contained within <code>SGD</code> and includes a line:</p>

<pre><code>apply_state[(var_device, var_dtype)][""momentum""] = array_ops.identity(self._get_hyper(""momentum"", var_dtype))
</code></pre>

<p>Anyway, the problem here is that I do not know which exactly approach to follow to create a custom <code>tf.keras</code> optimizer. Instructions included in comments seem to contradict with the actual implemented subclasses, and the latter also seem to assign the dirty work to the actual C++ function without being clear how this is done or how (in my case) to separate the actions (like the gradient calculation and application). So, is there any advice someone can provide on how to proceed and steps to follow to accomplish this (relatively) simple task?</p>

<p>I am using tf 1.15 by the way (so the links are from there).</p>
",2020-05-27 08:52:06,3584765,5505,https://stackoverflow.com/questions/62039068,Documentation Replication on Other Examples
62086633,Conditional branches using tf.function,"<p>I am having problems calculating the gradient using the gradient tape when using a <code>tf.function</code> with conditional branches.</p>

<p>Inside a gradient tape scope, I am trying to calculate the gradient of <code>z</code> w.r.t <code>self.LMn</code>. This works perfectly fine when I do not annotate the function with <code>@tf.function</code>. The error originates in a subclassed <code>tf.keras.layers.Layer</code> call function:</p>

<pre><code>def call(self, x, training=None, labels=None, cur_switch=None, basis_filters=None):
    if basis_filters is None:
        basis_filters = self.initial_basis_filters

    gap = tf.reduce_mean(x, axis=[1, 2])
    z = tf.einsum('bc,cd-&gt;bd', gap, self.LMn)

    # ... code for out

    return out, z
</code></pre>

<p>The actual error is given as follows:</p>

<pre><code>....
C:\...\ops\cond_v2.py:387 &lt;lambda&gt;
    lambda: _grad_fn(func_graph, grads), [], {},
C:\...\ops\cond_v2.py:363 _grad_fn
    assert len(func_graph.outputs) == len(grads)

AssertionError: 
</code></pre>

<p>More specifically,</p>

<pre><code>func_graphs.outputs = [&lt;tf.Tensor 'vgg16/block1a/block1a_conv/cond_2/Identity:0' shape=(128, 32, 32, None) dtype=float32&gt;, &lt;tf.Tensor 'vgg16/block1a/block1a_conv/cond_2/OptionalFromValue:0' shape=() dtype=variant&gt;, &lt;tf.Tensor 'vgg16/block1a/block1a_conv/cond_2/OptionalFromValue_1:0' shape=() dtype=variant&gt;]
</code></pre>

<p>and </p>

<pre><code>grads = (&lt;tf.Tensor 'gradient_tape/vgg16/block1a/block1a_conv/strided_slice_3/StridedSliceGrad_1:0' shape=(128, 32, 32, None) dtype=float32&gt;,)
</code></pre>

<p>I can assume that each of these outputs corresponds to the cases for some set of conditional branches outputs that are then fed into the <code>tf.einsum</code> function. I have read over all of the edge cases and precautions in the gradient tape documentation as this seems to the problem. Just a note that I am only performing conditional computation using hyperparameters (passed into <code>tf.function</code> as pythonic variables, such as <code>basis_filters</code>). There are also some conditional branches using (tensorflow ops) functions of these hyperparameters, is this allowed? or do I need to compute these values outside <code>tf.function</code> and pass these in as pythonic variables too?</p>

<p>I know the question is not completely clear and I can provide any extra information if needed. It would very helpful to have some guidance on what to look for with this kind of problem.</p>

<p>Thanks!</p>
",2020-05-29 13:01:24,1582331,3127,https://stackoverflow.com/questions/62086633,Documentation Replication on Other Examples
62211822,TF2 Keras - Feature Engineering in Keras saved model via Tensorflow Serving,"<p>The Tensorflow 2 documentation for preprocessing / feature engineering over a Keras model seems to be quite confusing and isn't very friendly.</p>

<p>Currently I have a simple Keras N-layer model with TF feature columns feeding as dense layer. For training I have CSV files read using <code>tf.dataset</code> API and I have written a feature engineering function that creates new features using <code>dataset.map</code> function.</p>

<pre><code>def feature_engg_features(features):
  #Add new features
  features['nodlgrbyvpatd'] = features['NODLGR'] / features['VPATD']

  return(features)
</code></pre>

<p>I can save the model easily using <code>tf.keras.models.save_model</code> method. However I am having trouble figuring out how to attach the <code>feature_engineering</code> steps in the serving function.</p>

<p><strong>Requirement</strong>: Now I want to take the same feature engineering function above and attach it to my <code>serving function</code> so that in JSON input via <code>tensorflow_model_server</code> the same feature engineering steps are applied. I know about the lambda Layer option in Keras but I want to do this via <code>saved_model</code> method but there are a lot of difficulties here.</p>

<p>For Example, below code gives error:</p>

<pre><code>def feature_engg_features(features):
  #Add new features
  features['nodlgrbyvpatd'] = features['NODLGR'] / features['VPATD']
  return(features)

@tf.function
def serving(data):
    data = tf.map_fn(feature_engg_features, data, dtype=tf.float32)

    # Predict
    predictions = m_(data)

version = ""1""
tf.keras.models.save_model(
    m_,
    ""./exported_model/"" + version,
    overwrite=True,
    include_optimizer=True,
    save_format=None,
    signatures=serving,
    options=None
)
</code></pre>

<p>Error:</p>

<pre><code>Only `tf.functions` with an input signature or concrete functions can be used as a signature.
</code></pre>

<p>The above error is because I have not provided InputSignature of my Keras model but I am not able to understand that I have 13 input fields, what is expected as input signature.</p>

<p>So I wanted to know if anyone knows the shortest way of solving this out. This is a very basic requirement and Tensorflow seems to have kept this quite complicated for Keras Tensorflow model serving.</p>

<p>GIST: <a href=""https://colab.research.google.com/gist/rafiqhasan/6abe93ac454e942317005febef59a459/copy-of-dl-e2e-structured-mixed-data-tf-2-keras-estimator.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/gist/rafiqhasan/6abe93ac454e942317005febef59a459/copy-of-dl-e2e-structured-mixed-data-tf-2-keras-estimator.ipynb</a></p>

<p><strong>EDIT:</strong>
I fixed it, so TensorSpec has to be generated and passed for each feature and also model( ) has to be called in serving function.</p>

<pre><code>@tf.function
def serving(WERKS, DIFGRIRD, SCENARIO, TOTIRQTY, VSTATU, EKGRP, TOTGRQTY, VPATD, EKORG, NODLGR, DIFGRIRV, NODLIR, KTOKK):
    ##Feature engineering
    nodlgrbyvpatd = tf.cast(NODLGR / VPATD, tf.float32)

    payload = {
        'WERKS': WERKS,
        'DIFGRIRD': DIFGRIRD,
        'SCENARIO': SCENARIO,
        'TOTIRQTY': TOTIRQTY,
        'VSTATU': VSTATU,
        'EKGRP': EKGRP,
        'TOTGRQTY': TOTGRQTY,
        'VPATD': VPATD,
        'EKORG': EKORG,
        'NODLGR': NODLGR,
        'DIFGRIRV': DIFGRIRV,
        'NODLIR': NODLIR,
        'KTOKK': KTOKK,
        'nodlgrbyvpatd': nodlgrbyvpatd,        
    }

    ## Predict
    ##IF THERE IS AN ERROR IN NUMBER OF PARAMS PASSED HERE OR DATA TYPE THEN IT GIVES ERROR, ""COULDN'T COMPUTE OUTPUT TENSOR""
    predictions = m_(payload)
    return predictions

serving = serving.get_concrete_function(WERKS=tf.TensorSpec([None,], dtype= tf.string, name='WERKS'), 
                                        DIFGRIRD=tf.TensorSpec([None,], name='DIFGRIRD'),
                                        SCENARIO=tf.TensorSpec([None,], dtype= tf.string, name='SCENARIO'), 
                                        TOTIRQTY=tf.TensorSpec([None,], name='TOTIRQTY'),
                                        VSTATU=tf.TensorSpec([None,], dtype= tf.string, name='VSTATU'), 
                                        EKGRP=tf.TensorSpec([None,], dtype= tf.string, name='EKGRP'),
                                        TOTGRQTY=tf.TensorSpec([None,], name='TOTGRQTY'), 
                                        VPATD=tf.TensorSpec([None,], name='VPATD'),
                                        EKORG=tf.TensorSpec([None,], dtype= tf.string, name='EKORG'), 
                                        NODLGR=tf.TensorSpec([None,], name='NODLGR'),
                                        DIFGRIRV=tf.TensorSpec([None,], name='DIFGRIRV'),
                                        NODLIR=tf.TensorSpec([None,], name='NODLIR'),
                                        KTOKK=tf.TensorSpec([None,], dtype= tf.string, name='KTOKK')
                                        )

version = ""1""
tf.saved_model.save(
    m_,
    ""./exported_model/"" + version,
    signatures=serving
)
</code></pre>
",2020-06-05 09:07:53,9334184,81,https://stackoverflow.com/questions/62211822,Documentation Replication on Other Examples
62237432,In which cases we use the attribute trainable_variables over trainable_weights and vice-versa of a tf.keras.Model in TF2?,"<p>I was studying how to do transfer learning in TF 2 and I saw that at <a href=""https://www.tensorflow.org/tutorials/images/transfer_learning#compile_the_model"" rel=""nofollow noreferrer"">this tutorial from Tensorflow</a> they use the attribute <code>trainable_variables</code> to reference the trainable variables of a model but in this <a href=""https://keras.io/guides/transfer_learning/"" rel=""nofollow noreferrer"">other tutorial from the keras documentation</a> they use the attribute <code>trainable_weights</code> of a <code>tf.keras.Model</code>.</p>

<p>I checked both attributes with a simple model, and they give me the same result. </p>

<pre><code>import tensorflow as tf
print(tf.__version__)

inputs = tf.keras.layers.Input(shape=[64, 64, 3])

x = tf.keras.layers.Conv2D(128, kernel_size=3, strides=2)(inputs)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)

model = tf.keras.Model(inputs=inputs, outputs=x)

print(""\nTrainable weights"")
vars_model = [var.name for var in model.trainable_weights]
print(*vars_model, sep=""\n"")

print(""\nTrainable variables"")
vars_model = [var.name for var in model.trainable_variables]
print(*vars_model, sep=""\n"")
</code></pre>

<p>Output: </p>

<pre><code>2.2.0

Trainable weights
conv2d/kernel:0
conv2d/bias:0
batch_normalization/gamma:0
batch_normalization/beta:0

Trainable variables
conv2d/kernel:0
conv2d/bias:0
batch_normalization/gamma:0
batch_normalization/beta:0
</code></pre>

<p>I checked this <a href=""https://stackoverflow.com/q/49020732"">other issue</a> and tried to follow the definition of both attributes: <code>trainable_variables</code> seems to be <a href=""https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/engine/base_layer.py#L1971"" rel=""nofollow noreferrer"">here</a> and <code>trainable_weights</code> seems to be <a href=""https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/engine/base_layer.py#L1072"" rel=""nofollow noreferrer"">here</a> and <a href=""https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/engine/network.py#L566"" rel=""nofollow noreferrer"">here</a>, since <code>td.keras.Model</code> also inherits from <code>network.Network</code>. The former seems to be returning the <code>trainable_weights</code> variable. But, I am not sure that this happens in ""all"" cases.</p>

<p>So, I am wondering in which cases we use <code>trainable_variables</code> over <code>trainable_weights</code> and vice-versa? and why?</p>
",2020-06-06 20:08:53,10530728,466,https://stackoverflow.com/questions/62237432,Documentation Replication on Other Examples
62264567,Does tf.stop_gradient() help memory wise?,"<p>Does <code>tf.stop_gradient</code> actually help save GPU memory. I'm asking since some intermediate outputs of layers behind the stop_gradient might not have to be stored (which would've otherwise been necessary for gradient computation). </p>
",2020-06-08 14:39:09,13706836,21,https://stackoverflow.com/questions/62264567,Documentation Replicability
62284095,What are the parameters to tf.GradientTape()'s __exit__ function?,"<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">documentation</a> for <code>tf.GradientTape</code>, its <code>__exit__()</code> method takes three positional arguments: <code>typ, value, traceback</code>.</p>

<p><strong>What exactly are these parameters?</strong> </p>

<p>How does the <code>with</code> statement infer them? </p>

<p>What values should I give them in the code below (where I'm <em>not</em> using a <code>with</code> statement):</p>

<pre><code>x = tf.Variable(5)

gt = tf.GradientTape()
gt.__enter__()
y = x ** 2
gt.__exit__(typ = __, value = __, traceback = __)
</code></pre>
",2020-06-09 13:43:05,1403340,202,https://stackoverflow.com/questions/62284095,Documentation Replicability
62318212,Is it possible to create an Estimator with arbitrarily many input Tensors for Predict SignatureDef without placeholders in TensorFlow 2.X?,"<p><strong>The Problem</strong></p>

<p>I am converting my Tensorflow 1.14 estimator to TensorFlow 2.1. My current workflow involves training my tensorflow model on gcloud's ai-platform <a href=""https://cloud.google.com/ai-platform/training/docs/training-jobs"" rel=""nofollow noreferrer"">(training on gcloud)</a> and using their model service to deploy my model for online predictions <a href=""https://cloud.google.com/ai-platform/prediction/docs/deploying-models"" rel=""nofollow noreferrer"">(model service)</a>. </p>

<p>The issue when upgrading to TensorFlow 2 is that they have done away with placeholders, which is affecting my <code>serving_input_fn</code> and how I export my estimator model. With tensorflow 2, if I export a model without the use of placeholders, my model's ""predict"" <code>SignatureDef</code> only has a single ""examples"" tensor whereas previously it had many inputs named appropriately through my <code>serving_input_fn</code>. </p>

<p>The previous set up for my estimator was as follows: </p>

<pre><code>def serving_input_fn():

    inputs = {
        'feature1': tf.compat.v1.placeholder(shape=None, dtype=tf.string),
        'feature2': tf.compat.v1.placeholder(shape=None, dtype=tf.string),
        'feature3': tf.compat.v1.placeholder(shape=None, dtype=tf.string),
        ...
    }

    return tf.estimator.export.ServingInputReceiver(features=split_features, receiver_tensors=inputs)

exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)

eval_spec = tf.estimator.EvalSpec(
    input_fn=lambda: input_eval_fn(args.test_dir),
    exporters=[exporter],
    start_delay_secs=10,
    throttle_secs=0)

...

tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</code></pre>

<p>And this has worked fine in the past, it has allowed me to have a multi-input ""predict"" SignatureDef where I can send a json of the inputs to ai-platforms model service and get predictions back. But since I am trying to not rely on the <code>tf.compat.v1</code> library, I want to avoid using placeholders. </p>

<p><strong>What I've tried</strong></p>

<p>Following the documentation linked <a href=""https://www.tensorflow.org/guide/saved_model#savedmodels_from_estimators"" rel=""nofollow noreferrer"">here</a> I've replaced my serving_input_fn with the <code>tf.estimator.export.build_parsing_serving_input_receiver_fn</code> method: </p>

<pre><code>feature_columns = ... # list of feature columns 
serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(
  tf.feature_column.make_parse_example_spec(feature_columns))
</code></pre>

<p>However, this gives me the following ""predict"" SignatureDef:</p>

<pre><code>signature_def['predict']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['examples'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: input_example_tensor:0
</code></pre>

<p>whereas before my ""predict"" SignatureDef was as follows:</p>

<pre><code>signature_def['predict']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['feature1'] tensor_info:
        dtype: DT_STRING
        shape: unknown_rank
        name: Placeholder:0
    inputs['feature2'] tensor_info:
        dtype: DT_STRING
        shape: unknown_rank
        name: Placeholder_1:0
    inputs['feature3'] tensor_info:
        dtype: DT_STRING
        shape: unknown_rank
        name: Placeholder_2:0
</code></pre>

<p>I've also tried using the <code>tf.estimator.export.build_raw_serving_input_receiver_fn</code>, but my understanding is that this method requires actual Tensors in order to be used instead of a feature spec. Unless I use placeholders, I don't really understand where to grab these serving Tensors from.</p>

<p><strong>So my main questions are:</strong></p>

<ul>
<li>Is it possible to create a multi-input ""predict"" signature def from an estimator model without using placeholders in Tensorflow 2? </li>
<li>If it is not possible, how am I supposed to provide the instances to gcloud predictions service for the ""examples"" tensor in the ""predict"" signature def? </li>
</ul>

<p>Thanks! </p>
",2020-06-11 06:17:10,10438511,168,https://stackoverflow.com/questions/62318212,Documentation Replication on Other Examples
62395187,"In tensorflow graph mode, why doesn't tensor.shape work, but tf.shape(tensor) does?","<p>In tensorflow, when running something in graph mode, tensor.shape does not work, but tf.shape(Tensor) does. </p>

<p>I am wondering if there's any reason for this. </p>
",2020-06-15 19:05:37,3259896,5853,https://stackoverflow.com/questions/62395187,Documentation Ambiguity
62405592,Tensorflow 2 Metrics produce wrong results with 2 GPUs,"<p>I took this piece of code from tensorflow documentation about distributed training with custom loop <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/distribute/custom_training</a> and I just fixed it to work with the tf.keras.metrics.AUC and run it with 2 GPUS (2 Nvidia V100 from a DGX machine). </p>

<pre><code># Import TensorFlow
import tensorflow as tf

# Helper libraries
import numpy as np


print(tf.__version__)


fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# Adding a dimension to the array -&gt; new shape == (28, 28, 1)
# We are doing this because the first layer in our model is a convolutional
# layer and it requires a 4D input (batch_size, height, width, channels).
# batch_size dimension will be added later on.
train_images = train_images[..., None]
test_images = test_images[..., None]

# One hot
train_labels = tf.keras.utils.to_categorical(train_labels, 10)
test_labels = tf.keras.utils.to_categorical(test_labels, 10)

# Getting the images in [0, 1] range.
train_images = train_images / np.float32(255)
test_images = test_images / np.float32(255)

# If the list of devices is not specified in the
# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.
GPUS = [0, 1]
devices = [""/gpu:"" + str(gpu_id) for gpu_id in GPUS]
strategy = tf.distribute.MirroredStrategy(devices=devices)

print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))


BUFFER_SIZE = len(train_images)

BATCH_SIZE_PER_REPLICA = 64
GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

EPOCHS = 10


train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)

train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)
test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)


def create_model():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu'),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Conv2D(64, 3, activation='relu'),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10, activation='softmax')
    ])

  return model


with strategy.scope():
  # Set reduction to `none` so we can do the reduction afterwards and divide by
  # global batch size.
  loss_object = tf.keras.losses.CategoricalCrossentropy(
      from_logits=True,
      reduction=tf.keras.losses.Reduction.NONE)
  def compute_loss(labels, predictions):
    per_example_loss = loss_object(labels, predictions)
    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)


with strategy.scope():
  test_loss = tf.keras.metrics.Mean(name='test_loss')

  train_accuracy = tf.keras.metrics.CategoricalAccuracy(
      name='train_accuracy')
  test_accuracy = tf.keras.metrics.CategoricalAccuracy(
      name='test_accuracy')
  train_auc = tf.keras.metrics.AUC(name='train_auc')
  test_auc = tf.keras.metrics.AUC(name='test_auc')


# model, optimizer, and checkpoint must be created under `strategy.scope`.
with strategy.scope():
  model = create_model()

  optimizer = tf.keras.optimizers.Adam()


def train_step(inputs):
  images, labels = inputs

  with tf.GradientTape() as tape:
    predictions = model(images, training=True)
    loss = compute_loss(labels, predictions)

  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

  train_accuracy(labels, predictions)
  train_auc(labels, predictions)
  return loss

def test_step(inputs):
  images, labels = inputs

  predictions = model(images, training=False)
  t_loss = loss_object(labels, predictions)

  test_loss.update_state(t_loss)
  test_accuracy(labels, predictions)
  test_auc(labels, predictions)


# `run` replicates the provided computation and runs it
# with the distributed input.
@tf.function
def distributed_train_step(dataset_inputs):
  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))
  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                         axis=None)

@tf.function
def distributed_test_step(dataset_inputs):
  return strategy.run(test_step, args=(dataset_inputs,))


for epoch in range(EPOCHS):
  # TRAIN LOOP
  total_loss = 0.0
  num_batches = 0
  for x in train_dist_dataset:
    total_loss += distributed_train_step(x)
    num_batches += 1
  train_loss = total_loss / num_batches

  # TEST LOOP
  for x in test_dist_dataset:
    distributed_test_step(x)

  template = (""Epoch {}, Loss: {}, Accuracy: {}, AUC: {},""
              ""Test Loss: {}, Test Accuracy: {}, Test AUC: {}"")
  print (template.format(epoch+1,
                         train_loss, train_accuracy.result()*100, train_auc.result()*100,
                         test_loss.result(), test_accuracy.result()*100, test_auc.result()*100))

  test_loss.reset_states()
  train_accuracy.reset_states()
  test_accuracy.reset_states()
  train_auc.reset_states()
  test_auc.reset_states()
</code></pre>

<p>The problem is that AUC's evaluation is definitely wrong cause it exceeds its range (should be from 0-100) and i get theese results by running the above code for one time:</p>

<pre><code>Epoch 1, Loss: 1.8061423301696777, Accuracy: 66.00833892822266, AUC: 321.8688659667969,Test Loss: 1.742477536201477, Test Accuracy: 72.0999984741211, Test AUC: 331.33709716796875
Epoch 2, Loss: 1.7129968404769897, Accuracy: 74.9816665649414, AUC: 337.37017822265625,Test Loss: 1.7084736824035645, Test Accuracy: 75.52999877929688, Test AUC: 337.1878967285156
Epoch 3, Loss: 1.643971562385559, Accuracy: 81.83333587646484, AUC: 355.96209716796875,Test Loss: 1.6072628498077393, Test Accuracy: 85.3499984741211, Test AUC: 370.603759765625
Epoch 4, Loss: 1.5887378454208374, Accuracy: 87.27833557128906, AUC: 373.6204528808594,Test Loss: 1.5906082391738892, Test Accuracy: 87.13999938964844, Test AUC: 371.9998474121094
Epoch 5, Loss: 1.581775426864624, Accuracy: 88.0, AUC: 373.9468994140625,Test Loss: 1.5964380502700806, Test Accuracy: 86.68000030517578, Test AUC: 371.0227355957031
Epoch 6, Loss: 1.5764907598495483, Accuracy: 88.49166870117188, AUC: 375.2404479980469,Test Loss: 1.5832056999206543, Test Accuracy: 87.94000244140625, Test AUC: 373.41998291015625
Epoch 7, Loss: 1.5698528289794922, Accuracy: 89.19166564941406, AUC: 376.473876953125,Test Loss: 1.5770654678344727, Test Accuracy: 88.58000183105469, Test AUC: 375.5516662597656
Epoch 8, Loss: 1.564456820487976, Accuracy: 89.71833801269531, AUC: 377.8564758300781,Test Loss: 1.5792100429534912, Test Accuracy: 88.27000427246094, Test AUC: 373.1791687011719
Epoch 9, Loss: 1.5612279176712036, Accuracy: 90.02000427246094, AUC: 377.9949645996094,Test Loss: 1.5729509592056274, Test Accuracy: 88.9800033569336, Test AUC: 375.5257263183594
Epoch 10, Loss: 1.5562015771865845, Accuracy: 90.54000091552734, AUC: 378.9789123535156,Test Loss: 1.56815767288208, Test Accuracy: 89.3499984741211, Test AUC: 375.8636474609375
</code></pre>

<p>Accuracy is ok but it seems that it's the only one metric that behaves nice. I tried other metrics too but they are not evaluated correctly. It seems that the problems come when using more than one GPU, cause when I run this code with one GPU it produce the right results. </p>
",2020-06-16 09:44:33,10687511,184,https://stackoverflow.com/questions/62405592,Documentation Replication on Other Examples
62413757,Loading a saved BertClassifer model,"<p>I am using the following example from this colab notebook:
<a href=""https://github.com/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb"" rel=""nofollow noreferrer"">https://github.com/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb</a></p>

<p>It saves a fine-tuned model using the model.save() functionality.</p>

<p>I am trying to load that same model using tf.keras.models.load_model() but am getting the following error:</p>

<pre><code>KeyError: 'name'
KeyError                                  Traceback (most recent call last)
in engine
----&gt; 1 model = tf.keras.models.load_model('./saved_model/test')

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    183     if isinstance(filepath, six.string_types):
    184       loader_impl.parse_saved_model(filepath)
--&gt; 185       return saved_model_load.load(filepath, compile)
    186 
    187   raise IOError(

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile)
    114   # TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.
    115   # TODO(kathywu): Add code to load from objects that contain all endpoints
--&gt; 116   model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
    117 
    118   # pylint: disable=protected-access

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, loader_cls)
    605       loader = loader_cls(object_graph_proto,
    606                           saved_model_proto,
--&gt; 607                           export_dir)
    608       root = loader.get(0)
    609       if isinstance(loader, Loader):

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in __init__(self, *args, **kwargs)
    186     self._models_to_reconstruct = []
    187 
--&gt; 188     super(KerasObjectLoader, self).__init__(*args, **kwargs)
    189 
    190     # Now that the node object has been fully loaded, and the checkpoint has

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir)
    121       self._concrete_functions[name] = _WrapperFunction(concrete_function)
    122 
--&gt; 123     self._load_all()
    124     self._restore_checkpoint()
    125 

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_all(self)
    207     # loaded from config may create variables / other objects during
    208     # initialization. These are recorded in `_nodes_recreated_from_config`.
--&gt; 209     self._layer_nodes = self._load_layers()
    210 
    211     # Load all other nodes and functions.

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_layers(self)
    307         continue
    308 
--&gt; 309       layers[node_id] = self._load_layer(proto.user_object, node_id)
    310 
    311     for node_id, proto in metric_list:

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_layer(self, proto, node_id)
    333     # Detect whether this object can be revived from the config. If not, then
    334     # revive from the SavedModel instead.
--&gt; 335     obj, setter = self._revive_from_config(proto.identifier, metadata, node_id)
    336     if obj is None:
    337       obj, setter = revive_custom_object(proto.identifier, metadata)

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _revive_from_config(self, identifier, metadata, node_id)
    350     else:
    351       obj = (
--&gt; 352           self._revive_graph_network(metadata, node_id) or
    353           self._revive_layer_from_config(metadata, node_id))
    354 

/home/cdsw/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _revive_graph_network(self, metadata, node_id)
    386     else:
    387       model = models_lib.Functional(
--&gt; 388           inputs=[], outputs=[], name=config['name'])
    389 
    390     # Record this model and its layers. This will later be used to reconstruct

KeyError: 'name'
</code></pre>

<p>Can someone please advise what I am doing wrong or if I should be doing something else to load this model? Thanks!</p>
",2020-06-16 16:57:34,11392855,11,https://stackoverflow.com/questions/62413757,Documentation Replicability
62418856,The differences between tf.nest.map_structure vs tf.map_fn in speed and in results,"<p>My question may be summarized as follows:</p>

<ol>
<li><strong>Why does <code>tf.map_fn</code> generate slightly different results compared to <code>tf.nest.map_structure</code>?</strong></li>
<li><strong>Why is <code>tf.map_fn</code> much slower than <code>tf.nest.map_structure</code>?</strong></li>
<li><strong>To apply a specific function to each example of a large batch, which one is a more preferred way?</strong></li>
</ol>

<p>Now, let me explain the problem that I had in more detail.</p>

<p>I need to apply a certain function to each example in a batch. At first, I tried the <code>tf.map_fn</code> method described in:
<a href=""https://www.tensorflow.org/api_docs/python/tf/map_fn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/map_fn</a>.</p>

<p>After implementing using <code>tf.map_fn</code>, I realize that the code is terribly slow.
I did some search, and it seems that many people have experienced similar issues.
(e.g. <a href=""https://github.com/tensorflow/tensorflow/issues/24774"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/24774</a>)</p>

<p>When I replaced <code>tf.map_fn</code> with <code>tf.nest.map_structure</code>, the speed was much better. However, the results were slightly different.</p>

<p>I made the following toy example to check this case.</p>

<pre><code>#!/usr/bin/python

import tensorflow as tf

def func(x):
    return tf.math.sqrt(x) 

x = tf.reshape(tf.range(24, dtype=tf.float32), (4, 6)) 

y1 = tf.nest.map_structure(func, x) 
print (y1)

y2 = tf.map_fn(func, x)
print (y2)

y3 = tf.math.sqrt(x)
print (y3)

print (tf.math.reduce_all(tf.equal(y1, y2)))
print (tf.math.reduce_all(tf.equal(y1, y3)))
</code></pre>

<p>y1 and y3 are exactly the same but y2 and y3 are slightly different. y2 and y3 are not totally different, but still similar.</p>

<p>The following is the result:</p>

<pre><code>tf.Tensor(
[[0.         0.99999994 1.4142134  1.7320508  1.9999999  2.236068  ]
 [2.4494896  2.6457512  2.8284268  2.9999998  3.1622777  3.3166249 ]
 [3.4641016  3.6055508  3.7416573  3.8729832  3.9999998  4.1231055 ]
 [4.2426405  4.3588986  4.472136   4.5825753  4.6904154  4.7958307 ]], shape=(4, 6), dtype=float32)
tf.Tensor(
[[0.        1.        1.4142135 1.7320508 2.        2.236068 ]
 [2.4494898 2.6457512 2.828427  3.        3.1622777 3.3166249]
 [3.4641016 3.6055512 3.7416575 3.8729835 4.        4.1231055]
 [4.2426405 4.358899  4.472136  4.582576  4.690416  4.7958317]], shape=(4, 6), dtype=float32)
tf.Tensor(
[[0.         0.99999994 1.4142134  1.7320508  1.9999999  2.236068  ]
 [2.4494896  2.6457512  2.8284268  2.9999998  3.1622777  3.3166249 ]
 [3.4641016  3.6055508  3.7416573  3.8729832  3.9999998  4.1231055 ]
 [4.2426405  4.3588986  4.472136   4.5825753  4.6904154  4.7958307 ]], shape=(4, 6), dtype=float32)
tf.Tensor(False, shape=(), dtype=bool)
tf.Tensor(True, shape=(), dtype=bool)
</code></pre>
",2020-06-16 22:58:39,735008,4480,https://stackoverflow.com/questions/62418856,Documentation Replication on Other Examples
62449998,using keras h5 weights in tf.keras model,"<p>I have h5 weights from a Keras model.</p>

<p>I want to rewrite the Keras model into a tf.keras model (using TF2.x). </p>

<p>I know that only the high level API changed, but <strong>do you know if I still can use the h5 weights?</strong> 
Most likely they can be loaded, but is the structure different between Keras and tf.keras weights? </p>

<p>Thanks</p>
",2020-06-18 12:29:22,6510273,2039,https://stackoverflow.com/questions/62449998,Documentation Ambiguity
62476015,TF 2.2 Saved_model from keras with custom signatures and preprocessing,"<p>I am trying to use the <code>tf.saved_model.save</code> after a training a Transformer Model in order to deploy it.
My model has multiple inputs and outputs. If I am using the saved_model function for serving, I add some issue about the input shape with the first input, and the second input is not visible when I am using the <code>saved_model_cli show</code> function. I found a way to solve that issue by wrapping the main transformer block by a model module and then save the model.</p>
<pre><code>def build_model(MAX_LEN, transformer_layer):
    inp = Input(shape=(MAX_LEN,), dtype=tf.int32, name=&quot;input_word_ids&quot;)
    inp2 = Input(shape=(MAX_LEN,), dtype=tf.int32, name=&quot;attention_mask&quot;)
    sequence_output, pooled_output = transformer_layer(inp, attention_mask = inp2)
    out = Dense(1, activation='sigmoid', name='outputs')(pooled_output)
    model = Model(inputs=[inp], outputs=[out])
    return model
</code></pre>
<p>But, I see in the documentation there is another way which consist in using signatures to indicate the inputs/outputs during the  <code>tf.saved_model.save</code>. To do that, we need to use the <code>tf.Module</code> class but I haven't understood how to use it in the case we have multiple inputs/outputs exactly (how to make understand the module that inputs tensor should be related to that inputs for the model?) .
Does anyone know how to do that with the second method ?  Morever can we do preprocessing of the data through the signature ?https://www.tensorflow.org/guide/saved_model</p>
<pre><code>class CustomModule(tf.Module):

  def __init__(self):
    super(CustomModule, self).__init__()
    self.v = tf.Variable(1.)

  @tf.function
  def __call__(self, x):
    print('Tracing with', x)
    return x * self.v

  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])
  def mutate(self, new_v):
    self.v.assign(new_v)

module = CustomModule()
</code></pre>
",2020-06-19 17:57:23,8401969,805,https://stackoverflow.com/questions/62476015,Documentation Replication on Other Examples
62530401,How to set the min_frequency while using tf.keras.preprocessing.text.tokenizer and ignore the words which are less then min_frequency?,"<p>Is there any way to set the 'min_frequency' in tf.keras.preprocessing.text.tokenizer, just like the 'min_frequency' in tf.contrib.learn.preprocessing.VocabularyProcessor?</p>
",2020-06-23 08:20:52,12746574,243,https://stackoverflow.com/questions/62530401,Documentation Replicability
62571896,question about tf.data.Dataset.from_generator for bert,"<p>I searched regarding this, but I cant find how to do.
usually, they use tf.constant or tf.data.TFrecord.</p>
<p>I want to make bert input dataset api using generator from reading csv file.
I try several hours, but various error happened.
I confused hot to use output_types, and output_shape</p>
<p>below is my code.
what is the problem??</p>
<pre><code>import tensorflow as tf
print(tf.__version__)
import tensorflow_datasets
from transformers import *
import pandas as pd
import numpy as np
from tensorflow import keras

from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tqdm.notebook import tqdm
# from wandb.keras import WandbCallback
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import feed
from feed import *
import time

train_df = pd.read_csv('files/train.csv')
from transformers import AlbertTokenizer, TFAlbertForSequenceClassification

tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')
model = TFAlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=Num_class)

# usually error happened here or next line
train_dataset = create_dataset('files/train.csv',batch_size=32, 
                               tokenizer=tokenizer, max_seq_len=128 )

al_inputs,  label = next(iter(train_dataset))
</code></pre>
<p>feed.py</p>
<pre><code>def convert_single_example(tokenizer, example, max_seq_length=512):
    &quot;&quot;&quot;Converts a single `InputExample` into a single `InputFeatures`.&quot;&quot;&quot;
    if isinstance(example, PaddingInputExample):
        input_ids = [0] * max_seq_length
        input_mask = [0] * max_seq_length
        segment_ids = [0] * max_seq_length
        label = 0
        return input_ids, input_mask, segment_ids, label

    tokens_a = tokenizer.tokenize(example.text_a)
    if len(tokens_a) &gt; max_seq_length - 2:
        tokens_a = tokens_a[0 : (max_seq_length - 2)]

    tokens = []
    segment_ids = []
    tokens.append(&quot;[CLS]&quot;)
    segment_ids.append(0)
    for token in tokens_a:
        tokens.append(token)
        segment_ids.append(0)
    tokens.append(&quot;[SEP]&quot;)
    segment_ids.append(0)
    
    #print(tokens)
    input_ids = tokenizer.convert_tokens_to_ids(tokens)

    # The mask has 1 for real tokens and 0 for padding tokens. Only real
    # tokens are attended to.
    input_mask = [1] * len(input_ids)

    # Zero-pad up to the sequence length.
    while len(input_ids) &lt; max_seq_length:
        input_ids.append(0)
        input_mask.append(0)
        segment_ids.append(0)

    assert len(input_ids) == max_seq_length
    assert len(input_mask) == max_seq_length
    assert len(segment_ids) == max_seq_length

    return input_ids, input_mask, segment_ids, example.label

def convert_text_to_features(texts, labels, tokenizer, max_seq_len) :
    InputExamples = []
#     for text, label in zip(texts, labels) :
    InputExamples.append(
        InputExample(guid=None, text_a=texts, text_b=None, label=labels)
    )
        
    input_ids, input_masks, segment_ids, labels = [], [], [], []
    for example in (InputExamples) :
        input_id, input_mask, segment_id, label = convert_single_example(
            tokenizer, example, max_seq_len
        )
        input_ids.append(input_id)
        input_masks.append(input_mask)
        segment_ids.append(segment_id)
        labels.append(label)   
    return (np.array(input_ids), np.array(input_masks),np.array(segment_ids)),np.array(labels).reshape(-1, 1)

def read_csvs(csv_files):
    sets = []
    for csv in csv_files:
        file = pandas.read_csv(csv, encoding='utf-8', na_filter=False)
        #FIXME: not cross-platform
#         csv_dir = os.path.dirname(os.path.abspath(csv))
        sets.append(file)
    # Concat all sets, drop any extra columns, re-index the final result as 0..N
    return pandas.concat(sets, join='inner', ignore_index=True)

def create_dataset(csvs, batch_size, tokenizer, max_seq_len):
    print(max_seq_len)
    csvs = csvs.split(',')
    df = read_csvs(csvs)

    def generate_values() :
        for _, row in df.iterrows() :
            yield convert_text_to_features(row.text, row.label_id, 
                                tokenizer=tokenizer,max_seq_len=max_seq_len)
    
   
    dataset = tf.data.Dataset.from_generator(generate_values, 
                                            output_types=((tf.int32, tf.int32, tf.int32), tf.int32), output_shapes=(tf.TensorShape([1, max_seq_len]), tf.TensorShape([1, max_seq_len]), tf.TensorShape([1, max_seq_len]), tf.TensorShape([1, 1])))
    
    dataset = dataset.shuffle(100, reshuffle_each_iteration = True).repeat(2).batch(batch_size, drop_remainder=True)

    return dataset
</code></pre>
",2020-06-25 09:13:36,10748392,177,https://stackoverflow.com/questions/62571896,Documentation Replication on Other Examples
62643330,Tensorflow: '+' operator,"<p>I'd like to ask: is the symbol '+' used in Tensorflow? I mean. in Pytorch I can sum/subtract tensors using + and - operators, while in Tensorflow is good use to exploit tf.add for example.
Could you please help me figure it out?</p>
<p>Thanks</p>
",2020-06-29 17:12:17,13835960,1,https://stackoverflow.com/questions/62643330,Documentation Replication on Other Examples
62755661,Multi-threaded processing using custom data generator in tensorflow2,"<p>I have been using a custom data generator in keras, tensorflow 1, with</p>
<pre><code>model.fit_generator(generator=training_generator,
                    validation_data=validation_generator, 
                    use_multiprocessing=True, epochs=epochs,
                    workers=workers, callbacks=callbacks_list, verbose=2)
</code></pre>
<p>It worked great. Now when I switched to tensorflow2, I found out that multi_gpu_model(model) is no longer supported.</p>
<p>As suggested in the docs, I switched to tf.distribute.MirroredStrategy(), since I am running on a headless server with 4 GPUs. I also switched my generator ('training_generator') to tf.data.Dataset format:</p>
<pre><code>train_ds = tf.data.Dataset.from_generator(lambda: training_generator,
                                      output_types=((tf.float32, tf.float32, tf.float32, tf.float32), tf.float32),
                                      output_shapes=(([None, 224, 224, 3],
                                                    [None, 625],
                                                    [None, 224, 224, 3],
                                                    [None, 224, 224, 3]),
                                                    [None, 2])
                                      )
</code></pre>
<p>But how to make it run with multiple threads? Here is what I tried (both from here: <a href=""https://medium.com/@nimatajbakhsh/building-multi-threaded-custom-data-pipelines-for-tensorflow-f76e9b1a32f5"" rel=""nofollow noreferrer"">https://medium.com/@nimatajbakhsh/building-multi-threaded-custom-data-pipelines-for-tensorflow-f76e9b1a32f5</a>):</p>
<ol>
<li>Wrapping it with 'map'. This works, but still runs in a single thread, since my CPU is not fully loaded and GPUs are starving.</li>
</ol>
<p><code>train_dataset = train_ds.map(lambda x,y: (x,y), num_parallel_calls=workers)</code></p>
<ol start=""2"">
<li>Using 'interleave'</li>
</ol>
<p><code>generators = tf.data.Dataset.from_tensor_slices(['Gen_0', 'Gen_1', 'Gen_2', 'Gen_3', 'Gen_4', 'Gen_5', 'Gen_6', 'Gen_7','Gen_8','Gen_9', 'Gen_10'])</code></p>
<pre><code>train_dataset = generators.interleave(lambda x: tf.data.Dataset.from_generator(lambda: training_generator,
                                      output_types=((tf.float32, tf.float32, tf.float32, tf.float32), tf.float32),
                                      output_shapes=(([None, 224, 224, 3],
                                                    [None, 625],
                                                    [None, 224, 224, 3],
                                                    [None, 224, 224, 3]),
                                                    [None, 2])
                                      ),
                    
                    num_parallel_calls=tf.data.experimental.AUTOTUNE)
</code></pre>
<p>`
This loads the CPU and feeds the GPUs well, but it seems to create copies of my dataset. All I want is to run through the whole dataset once, generating batches in parallel as was possible before in model.fit_generator()</p>
<p>Any help or insights are appreciated!</p>
",2020-07-06 12:02:32,3224242,135,https://stackoverflow.com/questions/62755661,Documentation Replication on Other Examples
62786629,how model info is sent to keras model,"<p>below is the code in tensorflow document.
(<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Model</a>)</p>
<pre><code>inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
</code></pre>
<p>in tf.keras.Model, input and output tensor related info is sent.</p>
<p>But there is no info about modeling( two dense layer and activation funtion)</p>
<p>How modeling info is sent to tf.keras.Model??</p>
<p>thanks.</p>
",2020-07-08 02:27:36,10748392,177,https://stackoverflow.com/questions/62786629,Inadequate Examples
62818943,Tensorflow pretrained models input channel range,"<p>I came across this <a href=""https://www.tensorflow.org/tutorials/images/transfer_learning"" rel=""nofollow noreferrer"">example</a> which implements a pretrained model. It says:</p>
<blockquote>
<p>Format the Data</p>
<p>Use the tf.image module to format the images for the task.</p>
<p>Resize the images to a fixed input size, and rescale the input
channels to a range of [-1,1]</p>
</blockquote>
<pre><code>IMG_SIZE = 160 # All images will be resized to 160x160

def format_example(image, label):
  image = tf.cast(image, tf.float32)
  image = (image/127.5) - 1
  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
  return image, label
</code></pre>
<p>I was wondering about this. What I understand is that <code>image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))</code> resizes the images (which can have any size) to one consistent size. I understand that <code>image = (image/127.5) - 1</code> does not change the actual size of the images, but changes the values (pixels) (which are between 0 to 255) to a range of [-1,1]. In other examples I saw normalization/standardization being done to a range of [0,1], so rescaling by 1.0/255. I do not understand when I have to use which. If I use my own model, it is up to me to scale to a range of [-1,1] or [0,1]? However, when I use a pretrained model I need to know what is required. I googled the mobilenetv2 model, but could not find any documentation telling me that the required input channel is [-1,1]. In this <a href=""https://github.com/tensorflow/tensorflow/issues/35336#issuecomment-568572711"" rel=""nofollow noreferrer"">comment</a> it says all pretrained tensorflow models require an input channel of [-1,1]. Is that true? Especially, is that true that all models in the <a href=""https://tfhub.dev/"" rel=""nofollow noreferrer"">tensorflow hub</a> (if about images) require a range of [-1,1]?</p>
<p>Finally, how do I find out what the required range is for a pretrained model? I would not have figured out the [-1,1] in case of MobileNetv2 by my own. On the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2"" rel=""nofollow noreferrer"">tensorflow MobileNetv2</a> page I could not find this information.</p>
<p>Furthermore: Is there a way to basically have this done automatically? So that I use a function and it automatically checks the pretrained tensorflow dataset (which has an object storing that information) and applies it (assuming 0-255 is my input)? I think <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/preprocess_input"" rel=""nofollow noreferrer"">tf.keras.applications.mobilenet_v2.preprocess_input</a> is doing something else (I am not really understanding what it does)? And it is also just for mobilenetv2.</p>
",2020-07-09 15:58:29,2165335,833,https://stackoverflow.com/questions/62818943,Documentation Replication on Other Examples
62994289,Saving TFrecords with TPU,"<p>I'm trying to use <code>tf.data.experimental.TFRecordWriter</code> to save dataset on Google cloud bucket using TPU. The code from the example in documentation works:</p>
<pre><code>dataset = tf.data.Dataset.range(3)
dataset = dataset.map(tf.io.serialize_tensor)
writer = tf.data.experimental.TFRecordWriter(&quot;gs://oleg-zyablov/test.tfrec&quot;)
writer.write(dataset)
</code></pre>
<p>But I have dataset of tuples (string, int64), where first is jpg-encoded image and second is label. When I pass it to writer.write() method, it says: 'tuple' object has no attribute 'is_compatible_with'.</p>
<p>I guess I have to pack image and label into tf.train.Example to make it work. I use the following code:</p>
<pre><code>def serialize(image, class_idx):
  tfrecord = tf.train.Example(features = tf.train.Features(feature = {
    'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image.numpy()])),
    'class': tf.train.Feature(int64_list = tf.train.Int64List(value = [class_idx.numpy()]))
  }))
  return tfrecord.SerializeToString()

#saving_pipeline is a dataset of (string, int64) tuples
saving_pipeline_serialized = saving_pipeline.map(serialize)

writer = tf.data.experimental.TFRecordWriter(&quot;gs://oleg-zyablov/car-classification/train_tfrecords/test.tfrecord&quot;)
writer.write(saving_pipeline_serialized)
</code></pre>
<p>But I get the following error:</p>
<pre><code>'Tensor' object has no attribute 'numpy'
</code></pre>
<p>Although I didn't turn off eager mode and this code <code>tf.constant([], dtype = float).numpy()</code> works. Maybe TPU works not in eager mode? Ok, I changed .numpy() to .eval() in the code above. Then I get the foloowing error:</p>
<pre><code>Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`
</code></pre>
<p>What session does TPU use and how do I specify it? When I run the code below:</p>
<pre><code>with tf.compat.v1.Session():
  saving_pipeline_serialized = saving_pipeline.map(serialize)
</code></pre>
<p>I get an error:</p>
<pre><code>Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`.
</code></pre>
<p>But I don't know how to get the current graph and pass it to tf.compat.v1.Session(). When I go another way and type:</p>
<pre><code>image.eval(session = tf.compat.v1.get_default_session())
</code></pre>
<p>It says:</p>
<pre><code>Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`
</code></pre>
<p>Is it possible to use .eval() on TPU? Or how do I perform my task another way?</p>
",2020-07-20 11:21:22,13959198,11,https://stackoverflow.com/questions/62994289,Documentation Replication on Other Examples
63014913,return the top_k items of each row for sparse tensor,"<p>For the dense tensor, we can use tf.nn.topk to find values and indices of the k largest entries for the last dimension.</p>
<p>For the sparse tensor, I would like to efficiently get the top n items of each row, without converting the sparse tensor to dense.</p>
",2020-07-21 12:48:02,13969647,11,https://stackoverflow.com/questions/63014913,Documentation Replicability
63020800,"Understanding Tensorflow Object-Detection API, kwargs for Checkpoint class, what is `_base_tower_layers_for_heads`?","<p>Currently, I've been learning how to use Object-Detection API from Tensorflow. I follow a quick start tutorial for training with custom data with <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb"" rel=""nofollow noreferrer"">this notebook</a> as suggested by them. In the effort to understanding each line of the code, I stumbled upon this snippet code in the &quot;Create Model and Restore Weight&quot; part.</p>
<pre><code>fake_box_predictor = tf.compat.v2.train.Checkpoint(
    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,
    # _prediction_heads=detection_model._box_predictor._prediction_heads,
    #    (i.e., the classification head that we *will not* restore)
    _box_prediction_head=detection_model._box_predictor._box_prediction_head,
    )
</code></pre>
<p>I don't really understand what are the keyword arguments that are available for the <code>Checkpoint</code> class in that particular snippet code. My question is; is there any documentation out there that shows the list of the keyword arguments? or at least explain what are <code>_base_tower_layers_for_heads</code> and<code>_box_prediction_head</code>?</p>
<p>I've read the <code>tf.train.Checkpoint</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"" rel=""nofollow noreferrer"">documentation</a>. It says that we can provide <code>models</code> or <code>optimizers</code> for the constructor's keyword argument. I am already familiar with this class to restore the weights to my model, however, I find it is alien to see <code>_base_tower_layers_for_heads</code> or <code>_box_prediction_head</code> for the keyword argument.</p>
<p>I do know about 'heads' and different types of 'heads' in the object detection architecture and their relation to transfer learning, what I don't understand is in the context of their data structure. How do I know, these keyword arguments exist? and is there any other else? I would really appreciate it if somebody could give me insights or at least tell me where can I find documentation that I can read to understand it more.</p>
",2020-07-21 18:22:58,8410038,53,https://stackoverflow.com/questions/63020800,Requesting (Additional) Documentation/Examples
63158314,Tensorflow 2.3.0 - Warning: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version,"<p>I've just updated to TF-2.3. In a model using <code>tf.data.Dataset.from_tensor_slices</code> as data source, I get the folowing warning:</p>
<pre><code>WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Iterator.get_next_as_optional()` instead.
</code></pre>
<p>I didn't find the instructions on the documentation on how to use the updated methods.</p>
<pre><code>train_dataset = tf.data.Dataset.from_tensor_slices(
    (
        {&quot;input_1&quot;: x1_train, 
         &quot;input_2&quot;: x2_train}, 
        {&quot;output&quot;: y_train},
    )
)

train_batches = train_dataset.batch(GLOBAL_BATCH_SIZE)
</code></pre>
<p>Training:</p>
<pre><code>history = model.fit(
    x = train_batches,
    epochs=30,
    verbose = 1,
)
</code></pre>
<p>Thanks in advance.</p>
",2020-07-29 16:33:28,11524722,111,https://stackoverflow.com/questions/63158314,Lack of Alternative Solutions/Documentation
63186177,What is the difference between <tf.io.parse_single_example> and <tf.data.experimental.parse_example_dataset>?,"<p>I am beginner in tensorflow and studying how to use tfrecord dataset.</p>
<p>is there any difference between &lt;tf.io.parse_single_example&gt; and &lt;tf.data.experimental.parse_example_dataset&gt; ??</p>
<p>version of tensorflow is 2.3.0</p>
<h1>for Mnist example</h1>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist

def feature_float_list(l):
    return tf.train.Feature(float_list=tf.train.FloatList(value=l))

def record2example(r_x, r_y):
    return tf.train.Example(features=tf.train.Features(feature={
        &quot;x&quot;: feature_float_list(r_x),
        &quot;y&quot;: feature_float_list(r_y)
    }))

filename_test  = &quot;test.tfrecords&quot;

# Data of MNIST to tfrecord file
_, (x_test, y_test) = mnist.load_data()
print(&quot;x_test: &quot;, x_test.shape)  # x_test    :  (10000, 28, 28)
print(&quot;y_test: &quot;, y_test.shape)  # y_test    :  (10000,)
x_test  = x_test.reshape((-1, 28*28)).astype(&quot;float32&quot;) / 255.0
y_test  = y_test.reshape((-1, 1)).astype(&quot;float32&quot;)

with tf.io.TFRecordWriter(filename_test) as writer:
    for r_x, r_y in zip(x_test, y_test):
        ex = record2example(r_x, r_y)
        writer.write(ex.SerializeToString())

#output
#x_test:(10000, 28, 28)
#y_test:(10000,)

</code></pre>
<h1>and,load tfrecord dataset  like below</h1>
<pre><code>
feature_dim=784 

def parse_example(example):
    features = tf.io.parse_single_example(example, features={
        &quot;x&quot;: tf.io.FixedLenFeature([feature_dim], dtype=tf.float32),
        &quot;y&quot;: tf.io.FixedLenFeature([], dtype=tf.float32)
    })
    x = features[&quot;x&quot;]
    y = features[&quot;y&quot;]
    return x, y

#-----tf.io.parse_single_example -----ver-----

def create_dataset_1():
    
    dataset = tf.data.TFRecordDataset([&quot;test.tfrecords&quot;]).map(parse_example)

    dataset = dataset.repeat()

    buffer_size=10
    dataset = dataset.shuffle(buffer_size)
    
    #batchsize
    batch_size=10
    dataset = dataset.batch(batch_size)
    
    # set iterator
    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)
    image, label = iterator.get_next()

    return image, label

image,label=create_dataset_1()
print(image.shape)
print(label.shape)

#(10, 784)
#(10,)
</code></pre>
<pre><code>#-----tf.data.experimental.parse_example_dataset -----ver-----

def dict2tuple(feature):
    return feature[&quot;x&quot;], feature[&quot;y&quot;]

def create_dataset_2():

    feature_dim=784
    dataset = tf.data.TFRecordDataset([&quot;test.tfrecords&quot;]).batch(100).apply(tf.data.experimental.parse_example_dataset(
        {
              &quot;x&quot;: tf.io.FixedLenFeature([feature_dim], dtype=tf.float32),
              &quot;y&quot;: tf.io.FixedLenFeature([], dtype=tf.float32)
          })).map(dict2tuple)
        
    #set repeat and shuffle
    dataset = dataset.repeat()
    
    dataset = dataset.shuffle(10)
    
    # batchsize
    #batch_size=10
    #dataset = dataset.batch(batch_size)
    
    #iterator
    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)
    
    image, label = iterator.get_next()

    return image, label

image,label=create_dataset_2()
print(image.shape)
print(label.shape)

#(100, 784)
#(100,)


</code></pre>
<p>I tried to look it up but,could not find this,think both outputs is the same....,
which should I use &lt;tf.io.parse_single_example&gt; and &lt;tf.data.experimental.parse_example_dataset&gt; ?</p>
",2020-07-31 05:20:27,11899917,115,https://stackoverflow.com/questions/63186177,Documentation Ambiguity
63228543,How to use embedding_column with BoostedTreesClassifier,"<p>I am learning the GBDT example on the tensorflow official website:<a href=""https://www.tensorflow.org/tutorials/estimator/boosted_trees?hl=en"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/estimator/boosted_trees?hl=en</a>
The example on the official website is one-hot processing of classification features.
But I want to convert discrete features into dense vectors through embedding. In the process, I encountered an unsolvable problem.
The following code is an example from the official website.</p>
<pre><code>CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',
                       'embark_town', 'alone']
NUMERIC_COLUMNS = ['age', 'fare']

def one_hot_cat_column(feature_name, vocab):
return tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(feature_name,vocab))

for feature_name in CATEGORICAL_COLUMNS:
    vocabulary = dftrain[feature_name].unique()
    feature_columns.append(one_hot_cat_column(feature_name, vocabulary))

for feature_name in NUMERIC_COLUMNS:
    feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype=tf.float32))
</code></pre>
<p>But when I change the'indicator_column' to'embedding_column' and run the'boostedtreeclassifier', an error is reported.</p>
<pre><code>def embedding_column(feature_name,vocab):
return tf.feature_column.embedding_column(categorical_column=tf.feature_column.categorical_column_with_vocabulary_list(
                                          feature_name,vocab),dimension=4,combiner='sum')
feature_columns = []
for feature_name in CATEGORICAL_COLUMNS:
    vocabulary = dftrain[feature_name].unique()
    feature_columns.append(embedding_column(feature_name,vocabulary))
 
for feature_name in NUMERIC_COLUMNS:
    feature_columns.append(tf.feature_column.numeric_column(feature_name,
                                           dtype=tf.float32))
</code></pre>
<p>Next, I have not made any changes to the data input method of the official website.</p>
<pre><code>NUM_EXAMPLES = len(y_train)
def make_input_fn(X,y,n_epochs=None,shuffle=True):
    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((dict(X),y))
        if shuffle:
            dataset = dataset.shuffle(NUM_EXAMPLES)
        dataset = dataset.repeat(n_epochs)
        dataset = dataset.batch(NUM_EXAMPLES)
        return dataset
    return input_fn
    
</code></pre>
<p>Then I start to initialize the model and train, and an error will be reported here.</p>
<pre><code>n_batches = 1
est = tf.estimator.BoostedTreesClassifier(feature_columns,n_batches_per_layer=n_batches)
train_input_fn = make_input_fn(dftrain,y_train)

est.train(train_input_fn,max_steps=100)
</code></pre>
<p>The above says: '# NOTE: GBDT requires that all DenseColumns expose a dtype attribute.'
'AttributeError:'EmbeddingColumn' object has no attribute'dtype''.
I use 'estimator.LinearClassifier' and there is no problem, but when I use 'tf.estimator.BoostedTreesClassifier', this problem occurs.
<a href=""https://i.stack.imgur.com/KeTxw.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
",2020-08-03 11:24:26,14041249,31,https://stackoverflow.com/questions/63228543,Documentation Replication on Other Examples
63359268,TensorFlow 2: Re-saving a SavedModel?,"<p>I am trying to load a model saved in <a href=""https://www.tensorflow.org/guide/saved_model"" rel=""nofollow noreferrer"">SavedModel</a> format, and then apply some calculations on top of it and re-save the whole pipeline. A minimal code is the following (from <a href=""https://www.kaggle.com/camaskew/host-baseline-example"" rel=""nofollow noreferrer"">this Kaggle kernel</a>):</p>
<pre class=""lang-python prettyprint-override""><code># Load the model. After that, the `delg_model` will be of the type
# `tensorflow.python.training.tracking.tracking.AutoTrackable`
delg_model = tf.saved_model.load('path/to/saved/model/dir')

# we don't need the whole model, so we prune it. After that, the
# `global_feature_extraction_fn` will be of the type
# `tensorflow.python.eager.wrap_function.WrappedFunction`
delg_input_tensor_names = ['input_image:0', 'input_scales:0']
global_feature_extraction_fn = delg_model.prune(
    delg_input_tensor_names, ['global_descriptors:0'])
</code></pre>
<blockquote>
<p><strong>Question:</strong> Now, I want to save the <code>global_feature_extraction_fn</code>, with some other TF ops to post-process the output, in the same SavedModel format. What is the correct way to do that?</p>
</blockquote>
<hr />
<h2>What I have tried</h2>
<p>I have tried to follow the TensorFlow documentation of <a href=""https://www.tensorflow.org/guide/saved_model#saving_a_custom_model"" rel=""nofollow noreferrer"">saving custom models to SavedModel format</a> and define a <code>tf.Module</code>:</p>
<pre class=""lang-python prettyprint-override""><code>class DelgModule(tf.Module):
    def __init__(self):
        super().__init__()

    @tf.function(input_signature=[
        tf.TensorSpec(shape=[None, None, 3], name='input_image')
    ])
    def call(self, input_tensor):
        # custom function on top of the model's output
        embedding = tf.nn.l2_normalize(
            global_feature_extraction_fn(
                input_tensor,                         # input_image
                tf.convert_to_tensor([0.7, 1.0, 1.4]) # input_scales
            )[0],
            axis=1, name='l2_normalized_output')
        return output_tensors = {
            'global_descriptor': embedding
        }

delg_module = DelgModule()
</code></pre>
<p>Then I ran it on the test image to build the <code>tf.function</code> and make sure that it works correctly (produces the right output). But when I tried to save it as follows:</p>
<pre class=""lang-python prettyprint-override""><code>tf.saved_model.save(
    delg_module, export_dir='./delg_resaved',
    signatures={
        'serving_default': delg_module.call
    })
</code></pre>
<p>the resulting model was incorrect. The original one weighted 90 MB while the one in <code>delg_resaved</code> weights only 800 KB. I also tried doing <code>tf.saved_model.load</code> <strong>inside</strong> the <code>DelgModule.call</code> function, so that the graph creation and variables loading is done entirely inside that <code>tf.function</code>, but the results remained the same.</p>
",2020-08-11 13:32:43,4789373,10034,https://stackoverflow.com/questions/63359268,Documentation Replication on Other Examples
63379008,How to make a diagonal tensor and why doesn't Tensorflow linalg.tensor_diag do that?,"<p>What I would consider a diagonal tensor is a tensor t of shape (d1, ..., dr) which is all zero except when the components are equal.
So t[i,j,k,l] = 0 unless i == j == k == l.
A function to create such a tensor should take in a shape (d1, ..., dr) and a vector [a1, ..., ak] of length min(d1, ..., dr), placing these values along the diagonal.</p>
<p>I would like to do this in Tensorflow, and the most relevant function I could find was <a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/tensor_diag"" rel=""nofollow noreferrer"">tf.linalg.tensor_diag</a>, but it doesn't do what I want. For instance, the diagonal input is a tensor, and the output tensor always has twice the rank, and so it can never output tensors of odd rank.</p>
<p>The documentation says &quot;Given a diagonal, this operation returns a tensor with the diagonal and everything else padded with zeros&quot;, but I don't know how to square that with its actual behavior.</p>
<p>My question is two parts:</p>
<ol>
<li><p>What is the best way in TF to do create what I am calling a diagonal tensor. Is there another name for this?</p>
</li>
<li><p>Why does linalg.tensor_diag work like this? What is the intended use?</p>
</li>
</ol>
<p>Here is an example output:</p>
<pre><code>&gt;&gt;&gt; tf.linalg.tensor_diag([1,2],[3,4]])

&lt;tf.Tensor: shape=(2, 2, 2, 2), dtype=int32, numpy=
array([[[[1, 0],
         [0, 0]],

        [[0, 2],
         [0, 0]]],


       [[[0, 0],
         [3, 0]],

        [[0, 0],
         [0, 4]]]], dtype=int32)&gt;```
</code></pre>
",2020-08-12 14:44:41,6667924,121,https://stackoverflow.com/questions/63379008,Documentation Ambiguity
63399368,Error with exporting TF2.2.0 model with tf.lookup.StaticHashTable for Serving,"<p>I'm using <code>StaticHashTable</code> as in one Lambda layer after the output layer of my tf.keras model. It's quite simple actually: I've a text classification models and I'm adding a simple lambda layer that takes the <code>model.output</code> and convert the model_id to more general labels. I can save this version of model with model.save(... as H5 format..) without any issue, and can load it back and use it without any problem.</p>
<p>Issue is, when I try to export my TF2.2.0 model for TF-Serving, I can't find how I can export it. Here is what I can do with TF1.X or with <code>TF2.X + tf.compat.v1.disable_eager_execution()</code></p>
<pre class=""lang-py prettyprint-override""><code>tf.compat.v1.disable_eager_execution()
version = 1
name = 'tmp_model'
export_path = f'/opt/tf_serving/{name}/{version}'
builder = saved_model_builder.SavedModelBuilder(export_path)

model_signature = tf.compat.v1.saved_model.predict_signature_def(
    inputs={
        'input': model.input
    }, 
    outputs={
        'output': model.output
    }
)

with tf.compat.v1.keras.backend.get_session() as sess:
    builder.add_meta_graph_and_variables(
        sess=sess,
        tags=[tf.compat.v1.saved_model.tag_constants.SERVING],
        signature_def_map={
            'predict': model_signature
        },
        # For initializing Hashtables
        main_op=tf.compat.v1.tables_initializer()
    )
    builder.save()
</code></pre>
<p>This will save my models with TF1.X format for serving and I can use it without any issue. Things is, I'm using LSTM layer and I want to use my model on GPU. By the documentation, if I disable the eager mode, I can't use the GPU-version of LSTM with TF2.2. And without going through above mentioned code, I can't save my model for serving wrt TF2.2 standard and StaticHashTables.</p>
<p>Here is how I'm trying to export my TF2.2 model which is using StaticHashTables in final layer; and which is giving error as below:</p>
<pre class=""lang-py prettyprint-override""><code>class MyModule(tf.Module):

    def __init__(self, model):
        super(MyModule, self).__init__()
        self.model = model
    
    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 16), dtype=tf.int32, name='input')])
    def predict(self, input):
        result = self.model(input)
        return {&quot;output&quot;: result}

version = 1
name = 'tmp_model'
export_path = f'/opt/tf_serving/{name}/{version}'

module = MyModule(model)
tf.saved_model.save(module, export_path, signatures={&quot;predict&quot;: module.predict.get_concrete_function()})
</code></pre>
<p><strong>Error:</strong></p>
<pre class=""lang-sh prettyprint-override""><code>AssertionError: Tried to export a function which references untracked object Tensor(&quot;2907:0&quot;, shape=(), dtype=resource).
TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
</code></pre>
<p>Any suggestion or am I missing anything on exporting TF2.2 model which is using the <code>StaticHashTables</code> in final Lambda layer for TensorFlow Serving?</p>
<p>More info here: <a href=""https://github.com/tensorflow/serving/issues/1719"" rel=""noreferrer"">https://github.com/tensorflow/serving/issues/1719</a></p>
<p>Thanks!</p>
",2020-08-13 16:25:41,4496896,747,https://stackoverflow.com/questions/63399368,Documentation Replication on Other Examples
63482945,How does tf.nn.dilation2d compute gradient and learn its filters,"<p>I want to understand how the tf.nn.dilation2d is working and how the &quot;filters&quot;, which refers to a structural element are learned.</p>
<p>The official documentation is available here : <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dilation2d"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dilation2d</a></p>
<p>The documentation didn't reference a scientific paper, and I found a lot of different idea in scientific literature, about morphological filters in deep learnign. Here just some examples :</p>
<ul>
<li><a href=""https://arxiv.org/abs/1906.01751"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1906.01751</a></li>
<li><a href=""https://arxiv.org/abs/1909.01532"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1909.01532</a></li>
<li><a href=""https://doi.org/10.1109/TNNLS.2018.2890334"" rel=""nofollow noreferrer"">https://doi.org/10.1109/TNNLS.2018.2890334</a></li>
<li><a href=""https://doi.org/10.1142/S0218001419540247"" rel=""nofollow noreferrer"">https://doi.org/10.1142/S0218001419540247</a></li>
</ul>
<p>I searched into the code (<a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/nn_ops.py#L327-L392"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/nn_ops.py#L327-L392</a>), but the tf.nn.dilation2d only call gen_nn_ops.dilation2d</p>
<pre><code>@tf_export(&quot;nn.dilation2d&quot;, v1=[])
@dispatch.add_dispatch_support
def dilation2d_v2(input, filters, strides, padding, data_format, dilations, name=None):
  if data_format != &quot;NHWC&quot;:
    raise ValueError(&quot;Data formats other than NHWC are not yet supported&quot;)
  return gen_nn_ops.dilation2d(input=input,
                               filter=filters,
                               strides=strides,
                               rates=dilations,
                               padding=padding,
                               name=name)
</code></pre>
<p>I searched into gen_nn_ops.py (which I found inside my python lib folder, probably because it's generated from somewhere else) but I didn't understand what the code is doing.</p>
<pre><code>def dilation2d(input, filter, strides, rates, padding, name=None):
  r&quot;&quot;&quot;Computes the grayscale dilation of 4-D `input` and 3-D `filter` tensors.

  The `input` tensor has shape `[batch, in_height, in_width, depth]` and the
  `filter` tensor has shape `[filter_height, filter_width, depth]`, i.e., each
  input channel is processed independently of the others with its own structuring
  function. The `output` tensor has shape
  `[batch, out_height, out_width, depth]`. The spatial dimensions of the output
  tensor depend on the `padding` algorithm. We currently only support the default
  &quot;NHWC&quot; `data_format`.

  In detail, the grayscale morphological 2-D dilation is the max-sum correlation
  (for consistency with `conv2d`, we use unmirrored filters):

      output[b, y, x, c] =
         max_{dy, dx} input[b,
                            strides[1] * y + rates[1] * dy,
                            strides[2] * x + rates[2] * dx,
                            c] +
                      filter[dy, dx, c]

  Max-pooling is a special case when the filter has size equal to the pooling
  kernel size and contains all zeros.

  Note on duality: The dilation of `input` by the `filter` is equal to the
  negation of the erosion of `-input` by the reflected `filter`.

  Args:
    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
      4-D with shape `[batch, in_height, in_width, depth]`.
    filter: A `Tensor`. Must have the same type as `input`.
      3-D with shape `[filter_height, filter_width, depth]`.
    strides: A list of `ints` that has length `&gt;= 4`.
      The stride of the sliding window for each dimension of the input
      tensor. Must be: `[1, stride_height, stride_width, 1]`.
    rates: A list of `ints` that has length `&gt;= 4`.
      The input stride for atrous morphological dilation. Must be:
      `[1, rate_height, rate_width, 1]`.
    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.
      The type of padding algorithm to use.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `input`.
  &quot;&quot;&quot;
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = pywrap_tfe.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, &quot;Dilation2D&quot;, name,
        tld.op_callbacks, input, filter, &quot;strides&quot;, strides, &quot;rates&quot;, rates,
        &quot;padding&quot;, padding)
      return _result
    except _core._FallbackException:
      try:
        return dilation2d_eager_fallback(
            input, filter, strides=strides, rates=rates, padding=padding,
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _, _, _op, _outputs = _op_def_library._apply_op_helper(
        &quot;Dilation2D&quot;, input=input, filter=filter, strides=strides,
                      rates=rates, padding=padding, name=name)
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = (&quot;T&quot;, _op._get_attr_type(&quot;T&quot;), &quot;strides&quot;,
              _op.get_attr(&quot;strides&quot;), &quot;rates&quot;, _op.get_attr(&quot;rates&quot;),
              &quot;padding&quot;, _op.get_attr(&quot;padding&quot;))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        &quot;Dilation2D&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Dilation2D = tf_export(&quot;raw_ops.Dilation2D&quot;)(_ops.to_raw_op(dilation2d))


def dilation2d_eager_fallback(input, filter, strides, rates, padding, name, ctx):
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter], ctx)
  (input, filter) = _inputs_T
  _inputs_flat = [input, filter]
  _attrs = (&quot;T&quot;, _attr_T, &quot;strides&quot;, strides, &quot;rates&quot;, rates, &quot;padding&quot;,
  padding)
  _result = _execute.execute(b&quot;Dilation2D&quot;, 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        &quot;Dilation2D&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


def dilation2d_backprop_filter(input, filter, out_backprop, strides, rates, padding, name=None):
  r&quot;&quot;&quot;Computes the gradient of morphological 2-D dilation with respect to the filter.

  Args:
    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
      4-D with shape `[batch, in_height, in_width, depth]`.
    filter: A `Tensor`. Must have the same type as `input`.
      3-D with shape `[filter_height, filter_width, depth]`.
    out_backprop: A `Tensor`. Must have the same type as `input`.
      4-D with shape `[batch, out_height, out_width, depth]`.
    strides: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The stride of the sliding window for each dimension of
      the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
    rates: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The input stride for atrous morphological dilation.
      Must be: `[1, rate_height, rate_width, 1]`.
    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.
      The type of padding algorithm to use.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `input`.
  &quot;&quot;&quot;
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = pywrap_tfe.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, &quot;Dilation2DBackpropFilter&quot;,
        name, tld.op_callbacks, input, filter, out_backprop, &quot;strides&quot;,
        strides, &quot;rates&quot;, rates, &quot;padding&quot;, padding)
      return _result
    except _core._FallbackException:
      try:
        return dilation2d_backprop_filter_eager_fallback(
            input, filter, out_backprop, strides=strides, rates=rates,
            padding=padding, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _, _, _op, _outputs = _op_def_library._apply_op_helper(
        &quot;Dilation2DBackpropFilter&quot;, input=input, filter=filter,
                                    out_backprop=out_backprop,
                                    strides=strides, rates=rates,
                                    padding=padding, name=name)
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = (&quot;T&quot;, _op._get_attr_type(&quot;T&quot;), &quot;strides&quot;,
              _op.get_attr(&quot;strides&quot;), &quot;rates&quot;, _op.get_attr(&quot;rates&quot;),
              &quot;padding&quot;, _op.get_attr(&quot;padding&quot;))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        &quot;Dilation2DBackpropFilter&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Dilation2DBackpropFilter = tf_export(&quot;raw_ops.Dilation2DBackpropFilter&quot;)(_ops.to_raw_op(dilation2d_backprop_filter))


def dilation2d_backprop_filter_eager_fallback(input, filter, out_backprop, strides, rates, padding, name, ctx):
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter, out_backprop], ctx)
  (input, filter, out_backprop) = _inputs_T
  _inputs_flat = [input, filter, out_backprop]
  _attrs = (&quot;T&quot;, _attr_T, &quot;strides&quot;, strides, &quot;rates&quot;, rates, &quot;padding&quot;,
  padding)
  _result = _execute.execute(b&quot;Dilation2DBackpropFilter&quot;, 1,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        &quot;Dilation2DBackpropFilter&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


def dilation2d_backprop_input(input, filter, out_backprop, strides, rates, padding, name=None):
  r&quot;&quot;&quot;Computes the gradient of morphological 2-D dilation with respect to the input.

  Args:
    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
      4-D with shape `[batch, in_height, in_width, depth]`.
    filter: A `Tensor`. Must have the same type as `input`.
      3-D with shape `[filter_height, filter_width, depth]`.
    out_backprop: A `Tensor`. Must have the same type as `input`.
      4-D with shape `[batch, out_height, out_width, depth]`.
    strides: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The stride of the sliding window for each dimension of
      the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
    rates: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The input stride for atrous morphological dilation.
      Must be: `[1, rate_height, rate_width, 1]`.
    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.
      The type of padding algorithm to use.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `input`.
  &quot;&quot;&quot;
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = pywrap_tfe.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, &quot;Dilation2DBackpropInput&quot;,
        name, tld.op_callbacks, input, filter, out_backprop, &quot;strides&quot;,
        strides, &quot;rates&quot;, rates, &quot;padding&quot;, padding)
      return _result
    except _core._FallbackException:
      try:
        return dilation2d_backprop_input_eager_fallback(
            input, filter, out_backprop, strides=strides, rates=rates,
            padding=padding, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _, _, _op, _outputs = _op_def_library._apply_op_helper(
        &quot;Dilation2DBackpropInput&quot;, input=input, filter=filter,
                                   out_backprop=out_backprop, strides=strides,
                                   rates=rates, padding=padding, name=name)
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = (&quot;T&quot;, _op._get_attr_type(&quot;T&quot;), &quot;strides&quot;,
              _op.get_attr(&quot;strides&quot;), &quot;rates&quot;, _op.get_attr(&quot;rates&quot;),
              &quot;padding&quot;, _op.get_attr(&quot;padding&quot;))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        &quot;Dilation2DBackpropInput&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Dilation2DBackpropInput = tf_export(&quot;raw_ops.Dilation2DBackpropInput&quot;)(_ops.to_raw_op(dilation2d_backprop_input))


def dilation2d_backprop_input_eager_fallback(input, filter, out_backprop, strides, rates, padding, name, ctx):
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter, out_backprop], ctx)
  (input, filter, out_backprop) = _inputs_T
  _inputs_flat = [input, filter, out_backprop]
  _attrs = (&quot;T&quot;, _attr_T, &quot;strides&quot;, strides, &quot;rates&quot;, rates, &quot;padding&quot;,
  padding)
  _result = _execute.execute(b&quot;Dilation2DBackpropInput&quot;, 1,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        &quot;Dilation2DBackpropInput&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result
</code></pre>
<p>Thank you for your time.</p>
",2020-08-19 08:27:13,14130094,21,https://stackoverflow.com/questions/63482945,Documentation Replicability
63495568,Is there a difference in speed between tf.keras.Model subclass implementation and equivalent tf functional API implementation?,"<p>Let's assume we have two equivalent models which have the same inputs, layers and outputs, except one is implemented as a tf.keras.Model subclass, and the other is implemented in the tf functional API. Is there a difference in the speed of inference or training of these models?</p>
",2020-08-19 22:06:03,11781546,721,https://stackoverflow.com/questions/63495568,Documentation Replicability
63558891,"Tensorflow 2.2, tf.nn.conv1d in Lambda layer","<p>I'd like to perform a convolution in a Lambda layer, but I can't get it to work any way.</p>
<pre class=""lang-py prettyprint-override""><code>    kernel = [1.0,2.0,1.0]  # weighted moving average
    x = [   # history_size=5, num_features=10
      [1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],
      [2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0],
      [3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0],
      [4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0],
      [5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0],
    ]
    k = tf.constant(kernel, dtype=tf.float32)
    y = tf.nn.conv1d(x, k, stride=1, padding='SAME')
</code></pre>
<p>I realize dimensions are not correct in the above example, but that's my data's actual format. The training samples have a shape of <code>(history_size, num_features)</code> and the kernel has to convolve along history_size, each feature separately. Any help would be appreciated. I cannot find an example on how to perform tf.nn.conv1d manually.</p>
",2020-08-24 10:05:50,4328352,487,https://stackoverflow.com/questions/63558891,Documentation Replication on Other Examples
63578924,Use tf operations when building tf.keras model,"<p>I found it hard to use simple tf operations when building tf.keras model. For a toy example, let's say I want to stack two tensors from previous layers into one, keras doesn't have a stack function but tf does, but in order to use it, I have to do something like:</p>
<pre class=""lang-py prettyprint-override""><code>t1 = ...
t1 = ...
t_stack = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=-1))([t1, t2])
</code></pre>
<p>I'm just using <code>tf.stack</code> as a toy example, it could be any tf operations that keras doesn't have (such as <code>tf.image.resize</code>, lots of <code>tf.math</code> operations etc.).</p>
<p>I want to know if there is a easy way to use arbitrary tf operations in keras? What about using <code>tf.keras.backend</code> operations? I recon it is probably better to keep every operation as a keras layer. Will using backend operations break that rule?</p>
",2020-08-25 12:31:52,11939660,391,https://stackoverflow.com/questions/63578924,Documentation Replicability
63598808,Why should I import keras again even if after importing tensorflow2?,"<p>In TensorFlow version2, when I want to use tf.keras, all the example codes import keras again even if tensorflow has imported like below example.</p>
<pre><code>import tensorflow as tf
from tensorflow import keras

tf.kera...
</code></pre>
<p>Can't I just skip second line which is <code>from tensorflow import keras</code>?? Why should I import keras separately even if I use keras in forms of <code>tf.keras</code>??</p>
",2020-08-26 13:31:25,9531939,119,https://stackoverflow.com/questions/63598808,Documentation Replicability
63624699,how to transform a model built with tensorflow to keras api?,"<p>So in a current projet i have to modify the official code from this <a href=""https://www.ijcai.org/Proceedings/2018/0308.pdf"" rel=""nofollow noreferrer"">paper</a> , and i'm pretty new to tensorflow and all his concepts, i worked with tf.keras but the actual code is written with tensorflow (version 1.7 which is old...), i wonder if someone can explain how the model works or had an idea for an equivalent to write it with keras and a recent version of tensorflow(tf version 2) the original code is in this <a href=""https://github.com/duxy-me/ConvNCF"" rel=""nofollow noreferrer"">repo</a>(ConvNCF.py)</p>
<pre class=""lang-py prettyprint-override""><code># prediction model
class ConvNCF:
    def __init__(self, num_users, num_items, args):#TODO:why the other arguments are useful?
        self.num_items = num_items
        self.num_users = num_users
        self.embedding_size = args.embed_size
        self.lr_embed = args.lr_embed
        self.lr_net = args.lr_net
        #TODO:what ara those things?
        self.hidden_size = args.hidden_size#nombre de couche ou nombre de neurones par couche?
        self.nc = eval(args.net_channel)#le nombre de map par couche (feature map )
        regs = eval(args.regs)
        self.lambda_bilinear = regs[0]
        self.gamma_bilinear = regs[1]
        self.lambda_weight = regs[2]
        self.dns = args.dns
        self.train_auc = args.train_auc
        self.prepared = False

    def _create_placeholders(self):
        with tf.name_scope(&quot;input_data&quot;):
            self.user_input = tf.placeholder(tf.int32, shape = [None, 1], name = &quot;user_input&quot;)
            self.item_input_pos = tf.placeholder(tf.int32, shape = [None, 1], name = &quot;item_input_pos&quot;)
            self.item_input_neg = tf.placeholder(tf.int32, shape = [None, 1], name = &quot;item_input_neg&quot;)
            self.keep_prob = tf.placeholder(tf.float32, name = &quot;keep_prob&quot;)#TODO:why this thing is useful?

    def _conv_weight(self, isz, osz):
        return (weight_variable([2,2,isz,osz]), bias_variable([osz]))

    def _conv_layer(self, input, P):
        conv = tf.nn.conv2d(input, P[0], strides=[1, 2, 2, 1], padding='SAME')
        return tf.nn.relu(conv + P[1])
    
    def _create_variables(self):
        with tf.name_scope(&quot;embedding&quot;):
            self.embedding_P = tf.Variable(tf.truncated_normal(shape=[self.num_users, self.embedding_size], mean=0.0, stddev=0.01),
                                                                name='embedding_P', dtype=tf.float32)  #(users, embedding_size)
            self.embedding_Q = tf.Variable(tf.truncated_normal(shape=[self.num_items, self.embedding_size], mean=0.0, stddev=0.01),
                                                                name='embedding_Q', dtype=tf.float32)  #(items, embedding_size)

            # here should have 6 iszs due to the size of outer products is 64x64
            iszs = [1] + self.nc[:-1]
            oszs = self.nc
            self.P = []
            for isz, osz in zip(iszs, oszs):
                self.P.append(self._conv_weight(isz, osz))

            self.W = weight_variable([self.nc[-1], 1])
            self.b = weight_variable([1])


    

    def _create_inference(self, item_input):
        with tf.name_scope(&quot;inference&quot;):
            # embedding look up
            self.embedding_p = tf.nn.embedding_lookup(self.embedding_P, self.user_input)
            self.embedding_q = tf.nn.embedding_lookup(self.embedding_Q, item_input)

            # outer product of P_u and Q_i
            self.relation = tf.matmul(tf.transpose(self.embedding_p, perm=[0, 2, 1]), self.embedding_q)
            self.net_input = tf.expand_dims(self.relation, -1)

            # CNN
            self.layer = []
            input = self.net_input
            for p in self.P:
                self.layer.append(self._conv_layer(input, p))
                input = self.layer[-1]

            # prediction
            self.dropout = tf.nn.dropout(self.layer[-1], self.keep_prob)
            self.output_layer = tf.matmul(tf.reshape(self.dropout,[-1,self.nc[-1]]), self.W) + self.b

            return self.embedding_p, self.embedding_q, self.output_layer


    def _regular(self, params):
        res = 0
        for param in params:
            res += tf.reduce_sum(tf.square(param[0])) + tf.reduce_sum(tf.square(param[1]))
        return res

    def _create_loss(self):
        with tf.name_scope(&quot;loss&quot;):
            # BPR loss for L(Theta)
            self.p1, self.q1, self.output = self._create_inference(self.item_input_pos)
            self.p2, self.q2, self.output_neg = self._create_inference(self.item_input_neg)
            self.result = self.output - self.output_neg
            self.loss = tf.reduce_sum(tf.log(1 + tf.exp(-self.result)))

            self.opt_loss = self.loss + self.lambda_bilinear * ( tf.reduce_sum(tf.square(self.p1)) \
                                    + tf.reduce_sum(tf.square(self.q2)) + tf.reduce_sum(tf.square(self.q1)))\
                                    + self.gamma_bilinear * self._regular([(self.W, self.b)]) \
                                    + self.lambda_weight * (self._regular(self.P) + self._regular([(self.W, self.b)]))

    # used at the first time when emgeddings are pretrained yet network are randomly initialized
    # if not, the parameters may be NaN.
    def _create_pre_optimizer(self):
        self.pre_opt = tf.train.AdagradOptimizer(learning_rate=0.01).minimize(self.loss)

    def _create_optimizer(self):
        # seperated optimizer
        var_list1 = [self.embedding_P, self.embedding_Q]
        #[self.W1,self.W2,self.W3,self.W4,self.b1,self.b2,self.b3,self.b4,self.P1,self.P2,self.P3]
        var_list2 = list(set(tf.trainable_variables()) - set(var_list1))
        opt1 = tf.train.AdagradOptimizer(self.lr_embed)
        opt2 = tf.train.AdagradOptimizer(self.lr_net)
        grads = tf.gradients(self.opt_loss, var_list1 + var_list2)
        grads1 = grads[:len(var_list1)]
        grads2 = grads[len(var_list1):]
        train_op1 = opt1.apply_gradients(list(zip(grads1, var_list1)))
        train_op2 = opt2.apply_gradients(list(zip(grads2, var_list2)))
        self.optimizer = tf.group(train_op1, train_op2)


    def build_graph(self):
        self._create_placeholders()
        self._create_variables()
        self._create_loss()
        self._create_pre_optimizer()
        self._create_optimizer()

    def load_parameter_MF(self, sess, path):
        ps = np.load(path)
        ap = tf.assign(self.embedding_P, ps[0])
        aq = tf.assign(self.embedding_Q, ps[1])
        #ah = tf.assign(self.h, np.diag(ps[2][:,0]).reshape(4096,1))
        sess.run([ap,aq])
        print(&quot;parameter loaded&quot;)

    def load_parameter_logloss(self, sess, path):
        ps = np.load(path).tolist()
        ap = tf.assign(self.embedding_P, ps['P'])
        aq = tf.assign(self.embedding_Q, ps['Q'])
        sess.run([ap,aq])
        print(&quot;logloss parameter loaded&quot;)

    def save_net_parameters(self, sess, path):
        pass

    def get_optimizer(self):
        if self.prepared:  # common optimize
            return self.optimizer
        else:
            # do a previous optimizing with none regularizations if it is the first time to optimize the neural network.
            # if not, the parameters may be NaN.
            return self.pre_opt

</code></pre>
",2020-08-27 22:01:12,12987394,25,https://stackoverflow.com/questions/63624699,Documentation Replicability
63730066,How to use tf.data.Dataset with kedro?,"<p>I am using <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code></a> to prepare a streaming dataset which is used to train a tf.kears model. With <a href=""https://kedro.readthedocs.io/en/stable/index.html"" rel=""nofollow noreferrer"">kedro</a>, is there a way to create a node and return the created <code>tf.data.Dataset</code> to use it in the next training node?</p>
<p>The <a href=""https://kedro.readthedocs.io/en/stable/kedro.io.MemoryDataSet.html?highlight=memorydataset#"" rel=""nofollow noreferrer""><code>MemoryDataset</code></a> will probably not work because <code>tf.data.Dataset</code> cannot be pickled (<code>deepcopy</code> isn't possible), see also <a href=""https://stackoverflow.com/questions/56862492/how-to-save-tf-data-dataset-object"">this SO question</a>. According to <a href=""https://github.com/quantumblacklabs/kedro/issues/91"" rel=""nofollow noreferrer"">issue #91</a> the deep copy in <code>MemoryDataset</code> is done to avoid modifying the data by some other node. Can someone please elaborate a bit more on why/how this concurrent modification could happen?</p>
<p>From the <a href=""https://kedro.readthedocs.io/en/stable/kedro.io.MemoryDataSet.html#kedro.io.MemoryDataSet.__init__"" rel=""nofollow noreferrer"">docs</a>, there seems to be a <code>copy_mode = &quot;assign&quot;</code>. Would it be possible to use this option in case the data is not picklable?</p>
<p>Another solution (also mentioned in issue 91) is to use just a function to generate the streaming <code>tf.data.Dataset</code> inside the training node, without having the preceding dataset generation node. However, I am not sure what the drawbacks of this approach will be (if any). Would be greate if someone could give some examples.</p>
<p>Also, I would like to avoid storing the complete output of the streaming dataset, for example using <a href=""https://www.tensorflow.org/tutorials/load_data/tfrecord"" rel=""nofollow noreferrer""><code>tfrecords</code></a> or <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/save"" rel=""nofollow noreferrer""><code>tf.data.experimental.save</code></a> as these options would use a lot of disk storage.</p>
<p>Is there a way to pass just the created <code>tf.data.Dataset</code> object to use it for the training node?</p>
",2020-09-03 18:59:47,2137370,1960,https://stackoverflow.com/questions/63730066,Inadequate Examples
63751223,Is there an Adaptive Instance Normalization layer in Keras?,"<p>I was looking through the concept of Adaptive Instance Normalization and was wondering if there is a tf.keras.layers.AdaIN() somewhere.</p>
<p>If not, can someone please give any pointers to implement it using keras backend?</p>
",2020-09-05 06:48:18,10013648,338,https://stackoverflow.com/questions/63751223,Documentation Replication on Other Examples
63882987,Is there a tf.keras.optimizers implementation for L-BFGS?,"<p>Does anybody have a Tensorflow 2 tf.keras subclass for the L-BFGS algorithm? If one wants to use L-BFGS, one has currently two (official) options:</p>
<ol>
<li>TF Probability</li>
<li>SciPy optimization</li>
</ol>
<p>These two options are quite cumbersome to use, especially when using custom models. So I am planning to implement a custom subclass of tf.keras.optimizers to use L-BFGS. But before I start, I was curious, whether somebody already tackled this task?</p>
",2020-09-14 11:02:21,11908003,51,https://stackoverflow.com/questions/63882987,Documentation Replication on Other Examples
63894153,TypeError: 'Tensor' object cannot be interpreted as an integer when using tf.map_fn(),"<p>I am trying to construct label-dependent convolutional filters in keras/tensorflow. Therefore, the convolutional filter(s) depend on each example in the batch.</p>
<pre><code># function used for tf.map_fn
def single_conv(tupl):
    x, kernel = tupl
    return tf.nn.conv2d(x, kernel, strides=(1, 1, 1, 1), padding='SAME')

# first dimension is None (batch size)
input_img = tf.keras.layers.Input(shape=(28,28,1), dtype=tf.float32)
label = tf.keras.layers.Input(shape=(10,), dtype=tf.float32) 

# the network is learning a mapping for the label
label_encoded = tf.keras.layers.Dense(9, activation='relu')(label) 
# turn mapping into conv filter 
kernels = tf.keras.layers.Reshape((3,3,1,1))(label_encoded) 

# class dependent filter(s)
conditional_conv = tf.map_fn(single_conv, (tf.expand_dims(input_img, 1), kernels), fn_output_signature=tf.float32) 
</code></pre>
<p>When I run this code snippet, I get a <code>TypeError: 'Tensor' object cannot be interpreted as an integer</code> for the last line. Since the last line uses <code>tf.map_fn</code>, I saw that  tf.map_fn results in a TypeError if either the function used (single_conv in this case) is not callable or the structure of the output of function and fn_output_signature do not match: <a href=""https://www.tensorflow.org/api_docs/python/tf/map_fn#raises"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/map_fn#raises</a>.</p>
<p>However, I'm still not sure why this is happening? I feel like both of those reasons should not be an issue?</p>
",2020-09-15 02:22:50,7375754,3217,https://stackoverflow.com/questions/63894153,Documentation Replication on Other Examples
63905839,Incompatible shapes between op input and calculated input gradient. conv2d_transpose any idea how to solve it?,"<pre><code>def deconv2d(input_, output_shape,
         k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,
         name=&quot;deconv2d&quot;, with_w=False):
with tf.variable_scope(name):
    # filter : [height, width, output_channels, in_channels]
</code></pre>
<p>w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],
initializer=tf.random_normal_initializer(stddev=stddev))</p>
<pre><code>    try:
        deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape,
                            strides=[1, d_h, d_w, 1])

    # Support for verisons of TensorFlow before 0.7.0
    except AttributeError:
        deconv = tf.nn.deconv2d(input_, w, output_shape=output_shape,
                            strides=[1, d_h, d_w, 1])

    biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))
    deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())

    if with_w:
        return deconv, w, biases
    else:
        return deconv
</code></pre>
",2020-09-15 16:08:03,8343298,3,https://stackoverflow.com/questions/63905839,Documentation Replication on Other Examples
63953040,How to use a TFRecord file for batch prediction on GCP AI Platform?,"<p>TL;DR
How does Google Cloud AI Platform unpack <code>TFRecord</code> files when doing batch predictions?</p>
<p>I have deployed a trained Keras model to Google Cloud AI Platform, but I'm having trouble with the file format for batch predictions. For training I'm using a <code>tf.data.TFRecordDataset</code> to read a list of <code>TFRecord</code> like the following which all works fine.</p>
<pre><code>def unpack_tfrecord(record):
    parsed = tf.io.parse_example(record, {
        'chunk': tf.io.FixedLenFeature([128, 2, 3], tf.float32),  # Input
        'class': tf.io.FixedLenFeature([2], tf.int64),            # One-hot classification (binary)
    })

    return (parsed['chunk'], parsed['class'])

files = [str(p) for p in training_chunks_path.glob('*.tfrecord')]
dataset = tf.data.TFRecordDataset(files).batch(32).map(unpack_tfrecord)
model.fit(x=dataset, epochs=train_epochs)
tf.saved_model.save(model, model_save_path)
</code></pre>
<p>I upload the saved model to Cloud Storage and create a new model in AI Platform. AI Platform documentation states that &quot;Batch with gcloud tool [supports] Text file with JSON instance strings or TFRecord file (may be compressed)&quot; (<a href=""https://cloud.google.com/ai-platform/prediction/docs/overview#prediction_input_data"" rel=""nofollow noreferrer"">https://cloud.google.com/ai-platform/prediction/docs/overview#prediction_input_data</a>). But when I provide a TFRecord file i get the error:</p>
<pre><code>(&quot;'utf-8' codec can't decode byte 0xa4 in position 1: invalid start byte&quot;, 8)
</code></pre>
<p>My TFRecord file contains a bunch of Protobuf encoded <code>tf.train.Example</code>. I'm not providing the <code>unpack_tfrecord</code> function to AI Platform, so I guess it makes sense that it can not unpack it properly, but I have node idea where to go from here. I'm not interested in using the JSON format as the data is too large.</p>
",2020-09-18 09:28:52,417385,4847,https://stackoverflow.com/questions/63953040,Documentation Replication on Other Examples
63958039,How do I interpret tf.keras.Model.predict() output?,"<p>I am having trouble finding the documentation I need on this. To summarize the issue, I have trained a tf.keras model using two classes of images, labeled as '0' or '1'. I now want to use this model to predict whether new images are a '0' or '1'. My question is as follows: <code>model.predict()</code> returns a number between 1 and 0, but I can't seem to find what exactly this is. Is it correct to say that this is it's prediction (ie, closer to 1 means the image is likely a 1, and closer to 0 means the image is likely a 0)? Or is there something else going on here. I have included the code, and some output, below. In this case, is <code>pred</code> the probability the image is a 1, and <code>1 - pred</code> the probability the image is a 0?</p>
<p>Thanks for any and all help.</p>
<pre><code>for img_path in test_filenames:
   img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMAGE_SIZE,IMAGE_SIZE))
   img_array = tf.keras.preprocessing.image.img_to_array(img)
   img_array = tf.expand_dims(img_array, 0)
   pred = model.predict(img_array)
   print(pred)
</code></pre>
<p>Returns</p>
<pre><code>[[0.8361757]]
[[0.26765466]]
[[0.2722953]]
[[0.81938094]]
[[0.24995388]]
[[0.45974937]]
</code></pre>
",2020-09-18 14:50:53,14301246,43,https://stackoverflow.com/questions/63958039,Lack of Alternative Solutions/Documentation
63958998,Tensorflow/AI Cloud Platform: HyperTune trials failed to report the hyperparameter tuning metric,"<p>I'm using the <code>tf.estimator</code> API with TensorFlow 2.1 on Google AI Platform to build a DNN Regressor. To use AI Platform Training hyperparameter tuning, I followed <a href=""https://cloud.google.com/ai-platform/training/docs/using-hyperparameter-tuning"" rel=""nofollow noreferrer"">Google's docs</a>.
I used the following configuration parameters:</p>
<p>config.yaml:</p>
<pre><code>trainingInput:
    scaleTier: BASIC
    hyperparameters:
        goal: MINIMIZE
        maxTrials: 2
        maxParallelTrials: 2
        hyperparameterMetricTag: rmse
        enableTrialEarlyStopping: True
        params:
        - parameterName: batch_size
          type: DISCRETE
          discreteValues:
          - 100
          - 200
          - 300
        - parameterName: lr
          type: DOUBLE
          minValue: 0.0001
          maxValue: 0.1
          scaleType: UNIT_LOG_SCALE 
</code></pre>
<p>And to add the metric to my summary, I used the following code for my DNNRegressor:</p>
<pre><code>def rmse(labels, predictions):
    pred_values = predictions['predictions']
    rmse = tf.keras.metrics.RootMeanSquaredError(name='root_mean_squared_error')
    rmse.update_state(labels, pred_values)
    return {'rmse': rmse}

def train_and_evaluate(hparams):
    ...
    estimator = tf.estimator.DNNRegressor(
                       model_dir = output_dir,
                       feature_columns = get_cols(),
                       hidden_units = [max(2, int(FIRST_LAYER_SIZE * SCALE_FACTOR ** i))
                        for i in range(NUM_LAYERS)],
                       optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
                       config = run_config)
    estimator = tf.estimator.add_metrics(estimator, rmse)
</code></pre>
<p>According to Google's documentation, the <code>add_metric</code> function creates a new estimator with the metric specified, which is then used as the hyperparameter metric. However, the AI Platform Training service doesn't recognise this metric:
<a href=""https://i.stack.imgur.com/Hwzq1.png"" rel=""nofollow noreferrer"">Job details on AI Platform</a></p>
<p>On running the code locally, the rmse metric does get outputted in the logs.
So, <strong>how do I make the metric available to the Training job on AI Platform using Estimators?</strong></p>
<p>Additionally, there is an option of reporting the metrics through the <code>cloudml-hypertune</code> Python package. But it requires the value of the metric as one of the input arguments. <strong>How do I extract the metric from <code>tf.estimator.train_and_evaluate</code> function</strong> (since that's the function I use to train/evaluate my estimator) to input into the <code>report_hyperparameter_tuning_metric</code> function?</p>
<pre><code>hpt = hypertune.HyperTune()
hpt.report_hyperparameter_tuning_metric(
    hyperparameter_metric_tag='rmse',
    metric_value=??,
    global_step=1000
)
</code></pre>
<p>ETA: <a href=""https://i.stack.imgur.com/jSfPw.png"" rel=""nofollow noreferrer"">Logs show no error</a>. It says that the job completed successfully even though it fails.</p>
",2020-09-18 15:52:50,14301413,1,https://stackoverflow.com/questions/63958998,Documentation Replication on Other Examples
64017646,How to create an empty tf.Variable with None dimension,"<p>How to create empty tf.Variable. I try to make this but get errors</p>
<pre><code>def __init__(self):
    super(ConcatLayer, self).__init__(dtype=tf.float64)
    self.total = tf.Variable(shape=tf.TensorShape([None, 3]), dtype=tf.float64)
</code></pre>
<p>ValueError: initial_value must be specified.</p>
<p>Which initial_value should I put?
Thx</p>
",2020-09-22 21:03:56,5546244,871,https://stackoverflow.com/questions/64017646,Documentation Ambiguity
64039233,difference keras and tf.keras,"<p>I found tf.keras is quite different with keras, in keras, bug occur when you use normal function instead Lambda wrapper function, bug is &quot;AttributeError: 'NoneType' object has no attribute '_inbound_nodes'&quot;, while in tf.keras, it is allowed use normal function and tf.keras.layers. funtion simultaneously.
keras seems use different data structure, create innode between layers.</p>
",2020-09-24 03:46:03,14331377,1,https://stackoverflow.com/questions/64039233,Documentation Replicability
64093750,Example of inferencing a Tensorflow lite model with parsing_serving_input_receiver_fn using C++ API,"<p>I have followed the Tensorflow2 documentation to convert my trained tf.estimator model to tflite model; in order to convert my model, first I had to save my model in saved_model format with an input_receiver_fn and then convert it with SELECT_OPS flag:</p>
<pre><code>classifier = tf.estimator.LinearClassifier(n_classes=2, model_dir = classifier_dir, feature_columns=features)
classifier.train(input_fn = lambda: trian_fn(features = train_datas, labels = trian_labels))

serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(tf.feature_column.make_parse_example_spec(features))

classifier.export_saved_model(classifier_dir+&quot;\saved_model&quot;, serving_input_fn)

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir = saved_model_dir , signature_keys=['serving_default']) 
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
</code></pre>
<p>I wanted to run my tflite model on an ARM device without python support so I built the C++ interpreter shared libs with Bazel as it is explained in the documentation :</p>
<p><a href=""https://www.tensorflow.org/lite/guide/ops_select#c"" rel=""nofollow noreferrer"">Cross-compile for armhf with Bazel</a></p>
<p><a href=""https://www.tensorflow.org/lite/guide/ops_select#c"" rel=""nofollow noreferrer"">Select TensorFlow operators C++</a></p>
<p>My model has 3 input features but when I try to use the following <a href=""https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_c"" rel=""nofollow noreferrer"">guide</a> for inferencing I get a segmentation fault.
I used the following code to extract my model details:</p>
<pre><code>interpreter = tf.lite.Interpreter(model_path=&quot;./model.tflite&quot;)
interpreter.allocate_tensors()
print(&quot;all ok&quot;)
# Print input shape and type
inputs = interpreter.get_input_details()
print('{} input(s):'.format(len(inputs)))
for i in range(0, len(inputs)):
    print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))

# Print output shape and type
outputs = interpreter.get_output_details()
print('\n{} output(s):'.format(len(outputs)))
for i in range(0, len(outputs)):
    print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))
</code></pre>
<p>I got the following output:</p>
<pre><code>all ok
1 input(s):
[1] &lt;class 'numpy.bytes_'&gt;

2 output(s):
[1 2] &lt;class 'numpy.bytes_'&gt;
[1 2] &lt;class 'numpy.float32'&gt;
</code></pre>
<p>first few lines of the output of tflite::PrintInterpreterState(interpreter.get()) are:</p>
<pre><code>INFO: Created TensorFlow Lite delegate for select TF ops.
INFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 25 nodes with 1 partitions.

Interpreter has 54 tensors and 26 nodes
Inputs: 0
Outputs: 38 34

Tensor   0 input_example_tensor kTfLiteString  kTfLiteDynamic          0 bytes ( 0.0 MB)  1
</code></pre>
<p>The output illustrates that the input shape is not the same as the original model, also the input type is &lt;class 'numpy.bytes_'&gt; but the Tensorflow 2 model inputs are [numpy.float32, numpy.float32, numpy.float32].
my input dictionary for prediction in TF2 model is something like : {'feature0' : data0, 'feature1' : data1, 'feature2' : data2}</p>
<p>here is the Google Colab <a href=""https://colab.research.google.com/drive/1fkj8zM2FM-xd6cajWkStcasmzliZWF9s?usp=sharing"" rel=""nofollow noreferrer"">link</a> to the Tensorflow model
I didn't have previous experience with inferencing TensorFlow Lite models so I searched first and found out these related questions that helped me write below C++ code:</p>
<p><a href=""https://stackoverflow.com/questions/56837288/tensorflow-lite-c-api-example-for-inference"">TensorFlow Lite C++ API example for inference</a></p>
<p><a href=""https://stackoverflow.com/questions/59424842/how-to-give-multi-dimensional-inputs-to-tflite-via-c-api"">How to give multi-dimensional inputs to tflite via C++ API</a></p>
<p>I tried to fill the input buffer with a vector of zeros but it was without success. Here is my C++ code to load a tflite model and feed it inputs for prediction. can someone please point me to the right direction since I could not find any examples or related documentation for feeding inputs to converted tf.estimator with a serving_input_fn.</p>
<pre><code>#include &lt;cstdio&gt;
#include &quot;tensorflow/lite/interpreter.h&quot;
#include &quot;tensorflow/lite/kernels/register.h&quot;
#include &quot;tensorflow/lite/model.h&quot;
#include &quot;tensorflow/lite/optional_debug_tools.h&quot;

int main()
{
  // Load model
      std::unique_ptr&lt;tflite::FlatBufferModel&gt; model = tflite::FlatBufferModel::BuildFromFile(&quot;model.tflite&quot;);
      
  // Build the interpreter with the InterpreterBuilder.
  tflite::ops::builtin::BuiltinOpResolver resolver;
  tflite::InterpreterBuilder builder(*model, resolver);
  std::unique_ptr&lt;tflite::Interpreter&gt; interpreter;
  builder(&amp;interpreter);
  tflite::PrintInterpreterState(interpreter.get());
  
  // Allocate tensor buffers.
  interpreter-&gt;AllocateTensors();
  printf(&quot;=== Pre-invoke Interpreter State ===\n&quot;);
  tflite::PrintInterpreterState(interpreter.get());

  // Fill input buffers
  std::vector&lt;float&gt; tensor(3, 0);  //Vector of zeros
  int input = interpreter-&gt;inputs()[0];
  float* input_data_ptr = interpreter-&gt;typed_input_tensor&lt;float&gt;(input);
  for(int i = 0; i &lt; 3; ++i)
  {
    *(input_data_ptr) = (float)tensor[i];
    input_data_ptr++;
  }
  // Run inference
  interpreter-&gt;Invoke();
  printf(&quot;\n\n=== Post-invoke Interpreter State ===\n&quot;);
  
  return 0;
}
</code></pre>
<h1><strong>EDIT 1:</strong></h1>
<p>I also asked this question in Tensorflow's GitHub and got a comment mentioning that I have to feed my inputs in the form of an &quot;example proto&quot;, now the problem is reduced to what is an &quot;example proto&quot; and how can one feed inputs to a tflite model in from of an example proto?</p>
<p><a href=""https://github.com/tensorflow/tensorflow/issues/43607"" rel=""nofollow noreferrer"">Github issue link</a></p>
",2020-09-27 22:05:48,11358743,71,https://stackoverflow.com/questions/64093750,Inadequate Examples
64095538,Can I replace tf.keras.backend with tf?,"<p>Implementations in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend"" rel=""nofollow noreferrer"">tf.keras.backend</a> have duplicates in pure tensorflow. For example: <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/ones"" rel=""nofollow noreferrer"">tf.keras.backend.ones</a> vs <a href=""https://www.tensorflow.org/api_docs/python/tf/ones"" rel=""nofollow noreferrer"">tf.ones</a>.</p>
<p>My question: Can I use tensorflow instead of tf.keras.backend, by just replacing it? Both are same API?</p>
",2020-09-28 03:23:55,5102533,135,https://stackoverflow.com/questions/64095538,Documentation Replicability
64119612,Join ragged character tensor,"<p>I have a ragged tensor of characters (copy/pastable code to reproduce):</p>
<pre class=""lang-py prettyprint-override""><code>flat_values = [
    b'7', b'2', b'1', b'0', b'4', b'1', b'4', b'5', b'0', b'6', b'0',
    b'1', b'5', b'7', b'8', b'4', b'6', b'6', b'5', b'4', b'0', b'7',
    b'4', b'0', b'1', b'3', b'1', b'3', b'4', b'7', b'2', b'7', b'1',
    b'2', b'1', b'1', b'7', b'4', b'2', b'3', b'5', b'1', b'2', b'4',
    b'4', b'6', b'3', b'5', b'5', b'6', b'0', b'4', b'1', b'5', b'7',
    b'8', b'3', b'7', b'4', b'6', b'4', b'3', b'0', b'7', b'0', b'2',
    b'1', b'7', b'3', b'2', b'7', b'7', b'6', b'2', b'7', b'8', b'4',
    b'7', b'3', b'6', b'1', b'3', b'6', b'3', b'1', b'4', b'1', b'7',
    b'6', b'6', b'0', b'5', b'4', b'2', b'1', b'4', b'8', b'7', b'3',
    b'7', b'4', b'4', b'2', b'5', b'4', b'7', b'6', b'7', b'0', b'5',
    b'8', b'5', b'6', b'6', b'5', b'7', b'8', b'1', b'0', b'1', b'6',
    b'4', b'6', b'7', b'3', b'1', b'7', b'1', b'8', b'2', b'0', b'2',
]

row_lengths = [
    6, 4, 4, 5, 6, 6, 6, 6, 6, 5, 5, 6,
    5, 5, 6, 5, 5, 4, 4, 4, 5, 6, 6, 6, 6,
]

x = tf.RaggedTensor.from_nested_row_lengths(
    flat_values,
    (row_lengths,),
)
</code></pre>
<p>I want to join the rows as strings, but I would like to do it in the graph. I can accomplish this by evaluating the tensor:</p>
<pre><code>&gt;&gt;&gt; [''.join([c.decode() for c in i]) for i in x.to_list()]
['721041',
 '4506',
 '0157',
 '84665',
 '407401',
 '313472',
 '712117',
 '423512',
 '446355',
 '60415',
 '78374',
 '643070',
 '21732',
 '77627',
 '847361',
 '36314',
 '17660',
 '5421',
 '4873',
 '7442',
 '54767',
 '058566',
 '578101',
 '646731',
 '718202']
</code></pre>
<p>But as this is the output of my network (trained in graph mode) I would like to be able to express this operation in tensorflow so that it can be evaluated in validation steps. Two things I've tried that do not work:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; tf.strings.join(x)
InvalidArgumentError: Input shapes do not match: [6] vs. [4] [Op:StringJoin]

&gt;&gt;&gt; tf.ragged.map_flat_values(tf.strings.join, x)
ValueError: Shape () must have rank at least 1
</code></pre>
<p>Frustratingly, the <a href=""https://tensorflow.google.cn/api_docs/python/tf/strings/join#used-in-the-notebooks"" rel=""nofollow noreferrer"">documentation for <code>tf.strings.join</code></a> mentions ragged tensors but does not give an example of them. What am I missing? It seems there should be an obvious solution to this.</p>
",2020-09-29 12:27:19,3015734,6960,https://stackoverflow.com/questions/64119612,Inadequate Examples
64172765,Tensorflow custom gradients don't backpropagate,"<p>I'm trying to understand custom gradients in tensorflow with <code>tf.custom_gradient</code>, so I was trying to reproduce a simple matrix multiplication with its gradients, where I'm only interested with the gradient with respect to the weight matrix.</p>
<pre><code>@tf.custom_gradient
def matrixmul(x, weight):
    res = tf.matmul(x, weight)

    def grad(dy):
        grad_x = None
        grad_w = tf.matmul(x, dy, transpose_a=True)
        return grad_x, grad_w

    return res, grad
</code></pre>
<p>This gives the right gradient whenever I don't my custom gradient is not used in the backpropagation, but when I do multiple multiplications the gradient doesn't propagate back and I get <code>None</code> as a result for <code>grad_w1</code>.</p>
<p>For example:</p>
<pre><code>with tf.GradientTape() as tape:
    temp = matrixmul(x, w1)
    pred = tf.matmul(temp, w2)
    loss = tf.reduce_sum(tf.norm(pred - y, axis=-1))
grad_w1 = tape.gradient(loss, w1)

</code></pre>
<pre><code>with tf.GradientTape() as tape:
    temp = tf.matmul(x, w1)
    pred = matrixmul(temp, w2)
    loss = tf.reduce_sum(tf.norm(pred - y, axis=-1))
grad_w1 = tape.gradient(loss, w1)

</code></pre>
<p>The first snippet gives the right gradients, but the second snippet results in <code>None</code>.</p>
",2020-10-02 13:54:02,12404907,57,https://stackoverflow.com/questions/64172765,Documentation Replication on Other Examples
64297691,Keras model evaluate returns triggered tf.function retracing warning,"<p>I am training the following model using Keras as shown:</p>
<pre><code>model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(256, 256, 3)),
tf.keras.layers.MaxPooling2D(2, 2),
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Flatten(), 
tf.keras.layers.Dense(12, activation=tf.nn.relu),
tf.keras.layers.Dense(10, activation=tf.nn.relu),
tf.keras.layers.Dense(1, activation=tf.sigmoid)])

model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),loss,'binary_crossentropy, metrics=['accuracy'])

model.fit(X_train, y_train, epochs=20)

</code></pre>
<p>When running the following to check the accuracy on the test set</p>
<pre><code>model.evaluate(X_test,y_test)
</code></pre>
<p>I get the following warning:</p>
<p><em>WARNING:tensorflow:5 out of the last 13 calls to &lt;function Model.make_test_function..test_function at 0x000001E51AA92AE8&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to <a href=""https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/function</a> for  more details.
2/2 [==============================] - 0s 94ms/step - loss: 0.6660 - accuracy: 0.5909</em></p>
<p><strong>Can you please help me understand why?</strong></p>
",2020-10-10 19:57:29,1525553,308,https://stackoverflow.com/questions/64297691,Documentation Replicability
64348896,How to feed images to Keras model that have multiple inputs with tf.data.Dataset generator?,"<p>When the model has only one input, I used <em>tf.keras.preprocessing.image_dataset_from_directory</em> method to feed images and labels. If the model has two or more inputs like the following model, how to feed them with <em>tf.data.Dataset</em> generator or better way?</p>
<pre class=""lang-python prettyprint-override""><code># One input
dataset = tf.keras.preprocessing.image_dataset_from_directory(...)
model.fit(dataset)

# Two or more inputs?
</code></pre>
<p><a href=""https://i.stack.imgur.com/VOvZ6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VOvZ6.png"" alt=""example model"" /></a></p>
",2020-10-14 07:53:31,3119984,138,https://stackoverflow.com/questions/64348896,Inadequate Examples
64356209,How does Model.fit() method's shuffle deals with Batches when using a tf.data.Dataset?,"<p>I am using tensorflow 2.</p>
<p>When using the <code>Model.fit()</code> method with a <code>tf.data.Dataset</code>, the argument '<code>batch_size</code>' is ignored. Thus to train my model on batches, I have to first change my dataset of samples into a dataset of batches of samples by calling <code>tf.data.Dataset.batch(batch_size)</code>.</p>
<p>Then, after reading the documentation, I don't understand clearly how the <code>.fit()</code> method will shuffle my dataset at each epoch.</p>
<p><strong>Since my dataset is a dataset of batches, will it shuffle the batches among each other</strong> (the batches remain unchanged) <strong>? Or will it shuffle all the samples and then regroup them into new batches</strong> (which is the desired behaviour) <strong>?</strong></p>
<p>Thanks a lot for your help.</p>
",2020-10-14 15:04:24,14449900,31,https://stackoverflow.com/questions/64356209,Documentation Replicability
64424397,Keras - Custom layer with multiple inputs,"<p>I would like to implement a custom <code>tf.keras</code> layer called <code>MyLayer</code> which has three inputs and contains a sub layer which in turn has three inputs, like in the figure below:</p>
<p><a href=""https://i.stack.imgur.com/Um7yn.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Um7yn.jpg"" alt=""MyLayer"" /></a></p>
<p>I assume that the right thing to do would be to create a <code>MyLayer</code> class that extends <code>tf.keras.layers.Layer</code> and implement the <code>__init__</code>, <code>build</code> and <code>call</code> methods, as mentioned in the <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">official documentation</a>.</p>
<p>Now, the examples provided in the documentation are relative to pretty simple layers that are composed of several sublayers connected in a sequential manner, that is one after the other. For instance, the <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models#layers_are_recursively_composable"" rel=""nofollow noreferrer""><code>MLPBlock</code></a> layer consists of 3 linear layers ordered sequentially.</p>
<p>In general, however, sublayers are not ordered sequentially, but can form branches. This suggests that those layers could be run in parallel, since they are not connected to one another.
Going back to the custom layer I would like to implement, you can see that <code>Layer1</code>, <code>Layer2</code> and <code>Layer3</code> could be run in parallel. Once their outputs are computed, they can be fed to <code>Layer4</code>. The point is: how do I run them in parallel? I couldn't find any &quot;ParallelCombinator&quot; or things like that among the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers"" rel=""nofollow noreferrer"">available Keras layers</a>.</p>
<p>If I were to follow the examples provided in the documentation, I would write something along these lines:</p>
<pre class=""lang-py prettyprint-override""><code>class MyLayer(keras.layers.Layer):
    def __init__(self, ...):
        super(MyLayer, self).__init__()
        self.layer_1 = Layer1(...)
        self.layer_2 = Layer2(...)
        self.layer_3 = Layer3(...)
        self.layer_4 = Layer4(...)

    def call(self, inputs):
        tmp_1 = self.layer_1(inputs[0])
        tmp_2 = self.layer_2(inputs[1])
        tmp_3 = self.layer_3(inputs[2])
        return self.layer4([tmp_1, tmp_2, tmp_3])
</code></pre>
<p>This, however, would imply that <code>Layer1</code>, <code>Layer2</code> and <code>Layer3</code> are run sequentially, not in parallel.</p>
<p>One possible solution that I came up with involves structuring <code>MyLayer</code> as a <code>tf.keras.Model</code> built with Keras's functional API rather than as a subclass of <code>tf.keras.Layer</code>, like so:</p>
<pre class=""lang-py prettyprint-override""><code>def MyLayer(...):
    input_1 = tf.keras.layers.Input(...)
    input_2 = tf.keras.layers.Input(...)
    input_3 = tf.keras.layers.Input(...)

    layer_1 = Layer1(...)(input_1)
    layer_2 = Layer2(...)(input_2)
    layer_3 = Layer3(...)(input_3)
    output_1 = Layer4(...)([layer_1, layer_2, layer_3])

    return tf.keras.Model(inputs=[input_1, input_2, input_3], outputs=output_1)

if __name__ == '__main__':
    my_layer = MyLayer(...)
    input_1 = ...
    input_2 = ...
    input_3 = ...
    output = my_layer([input_1, input_2, input_3])
</code></pre>
<p>The reason why I think this would work is that I assume that when I feed some inputs to a <code>tf.keras.Model</code>, as in <code>output = my_layer([input_1, input_2, input_3])</code>, the layers that <em>can</em> be run in parallel are effectively run in parallel (or are they?). This solution, however, feels like a hack to me, as <code>MyLayer</code> is supposed to be a layer, <em>not</em> a model. In fact, a <code>tf.keras.Model</code> instance exposes methods like <code>fit(...)</code> that aren't meant to be called on a layer.</p>
<p>Does anybody know what's the best approach to implement <code>MyLayer</code>?</p>
",2020-10-19 09:16:15,9079812,738,https://stackoverflow.com/questions/64424397,Documentation Replication on Other Examples
64496955,"Using albumentation's augmentation in tensorflow dataset API is giving this error : Incompatible shapes expected [?,224,224,3] but got [8,1,224,224,3]","<p>I am getting this error while trying to augment the images using the albumentations library which uses tf.numpy_function to wrap the python function for augmentation in tensorflow from this link :<a href=""https://albumentations.ai/docs/examples/tensorflow-example/"" rel=""nofollow noreferrer"">https://albumentations.ai/docs/examples/tensorflow-example/</a></p>
<p>I have loaded my dataset of images and target label using tensorflow dataset API.
The code :</p>
<pre><code>img_paths = df['image_path'].values
target = df['target_label'].values

path_lis = tf.data.Dataset.from_tensor_slices(img_paths)
target_lis = tf.data.Dataset.from_tensor_slices(target)
list_ds = tf.data.Dataset.zip((path_lis, target_lis))

image_count = len(df)
val_size = int(image_count * 0.3)
train = list_ds.skip(val_size)
val = list_ds.take(val_size)


def process_path(file_path, target):

  # load the raw data from the file as a string
  img = tf.io.read_file(file_path)
  img = tf.image.decode_jpeg(img, channels=3)

  return img, target

# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.
train_data = train.map(process_path, num_parallel_calls=AUTOTUNE)
val_data = val.map(process_path, num_parallel_calls=AUTOTUNE)

# Augmentation using albumentations library
transforms = A.Compose([
            A.Rotate(limit=40),
            A.RandomBrightness(limit=0.1),
            A.RandomContrast(limit=0.9, p=1),
            A.HorizontalFlip(),
            A.Resize(224, 224)
            ])

def aug_fn(image):

    data = {&quot;image&quot;: image}
    aug_data = transforms(**data)
    aug_img = aug_data[&quot;image&quot;]
    #target = aug_data[&quot;keypoints&quot;][0]
    aug_img = tf.cast(aug_img/255.0, tf.float32)
    #aug_img = tf.image.resize(aug_img, size=[224, 224])

    return aug_img

def process_aug(img, label):

    aug_img = tf.numpy_function(func=aug_fn, inp=[img], Tout=[tf.float32])
    return aug_img, label

# create dataset
train_ds = train_data.map(process_aug, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)
val_ds = val_data.map(process_aug, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)

def set_shapes(img, label):

    img.set_shape([224, 224, 3])
    label.set_shape([])

    return img, label

train_ds = train_ds.map(set_shapes, num_parallel_calls=AUTOTUNE).batch(8).prefetch(AUTOTUNE)
val_ds = val_ds.map(set_shapes, num_parallel_calls=AUTOTUNE).batch(8).prefetch(AUTOTUNE)


def view_image(ds):

    image, label = next(iter(ds)) # extract 1 batch from the dataset
    image = image.numpy()
    label = label.numpy()

    fig = plt.figure(figsize=(22, 22))
    for i in range(20):
        ax = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])
        ax.imshow(image[i])
        ax.set_title(f&quot;Label: {label[i]}&quot;)

view_image(train_ds)

</code></pre>
<p>The full error message:</p>
<pre><code>Traceback (most recent call last):
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\eager\context.py&quot;, line 2102, in execution_mode
    yield
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py&quot;, line 758, in _next_internal
    output_shapes=self._flat_output_shapes)
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_dataset_ops.py&quot;, line 2610, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py&quot;, line 6843, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File &quot;&lt;string&gt;&quot;, line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes at component 0: expected [?,224,224,3] but got [4,1,224,224,3]. [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py&quot;, line 2963, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &quot;&lt;ipython-input-20-23a37450bee7&gt;&quot;, line 13, in &lt;module&gt;
    view_image(train_ds)
  File &quot;&lt;ipython-input-20-23a37450bee7&gt;&quot;, line 3, in view_image
    image, label = next(iter(ds)) # extract 1 batch from the dataset
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py&quot;, line 736, in __next__
    return self.next()
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py&quot;, line 772, in next
    return self._next_internal()
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py&quot;, line 764, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File &quot;C:\Users\Arun\Anaconda3\lib\contextlib.py&quot;, line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\eager\context.py&quot;, line 2105, in execution_mode
    executor_new.wait()
  File &quot;C:\Users\Arun\Anaconda3\lib\site-packages\tensorflow\python\eager\executor.py&quot;, line 67, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)

tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes at component 0: expected [?,224,224,3] but got [8,1,224,224,3].
</code></pre>
<p>Can someone can at least tell me why this error is happening? Thanks in advance!</p>
",2020-10-23 08:55:52,10432635,59,https://stackoverflow.com/questions/64496955,Documentation Replicability
64552543,Tensorflow 2.2.0 :- WARNING:tensorflow:Gradients do not exist for variables when minimizing the loss,"<p>After implementing Custom Loss class as per the tensorflow api documentation and when invoking model.fit , facing this warning alongwith below error:- This is reference link on github and they have asked to raise here in stack overflow.https://github.com/tensorflow/tensorflow/issues/42542# TypeError: An op outside of the function building code is being passed a &quot;Graph&quot; tensor. It is possible to have Graph tensors leak out of the function building context by including a tf.init_scope in your function building code. For example, the following function will fail:</p>
<hr />
<blockquote>
<p>@tf.function   def has_init_scope():
my_constant = tf.constant(1.)
with tf.init_scope():
added = my_constant * 2 The graph tensor has name: ident33/Relu_5:0</p>
</blockquote>
",2020-10-27 10:32:22,6926418,101,https://stackoverflow.com/questions/64552543,Documentation Replication on Other Examples
64578310,tfrecordswriter does not write,"<p>I am trying to create a <code>tf.data.Dataset</code> from a generator I wrote, and following this great answer: <a href=""https://stackoverflow.com/questions/54519309/split-tfrecords-file-into-many-tfrecords-files"">Split .tfrecords file into many .tfrecords files</a></p>
<h2>Generator Code</h2>
<pre><code>def get_examples_generator(num_variants, vcf_reader):
    def generator():
        counter = 0
        for vcf_read in vcf_reader:
            is_vcf_ok = ... # checking whether this &quot;vcf&quot; example is ok

            if is_vcf_ok and counter &lt; num_variants:

                counter += 1

                # features extraction ...

                # we create an example
                example = make_example(img=img, label=label) # returns a SerializedExample

                yield example
    return generator
</code></pre>
<h2>TFRecordsWriter Usage Code</h2>
<pre><code>def write_sharded_tfrecords(filename, path, vcf_reader,
                            num_variants,
                            shard_len):
    assert Path(path).exists(), &quot;path does not exist&quot;

    generator = get_examples_generator(num_variants=num_variants,
                                       vcf_reader=vcf_reader,
                                       cfdna_bam_reader=cfdna_bam_reader)

    dataset = tf.data.Dataset.from_generator(generator,
                                             output_types=tf.string,
                                             output_shapes=())

    num_shards = int(np.ceil(num_variants/shard_len))
    formatter = lambda batch_idx: f'{path}/{filename}-{batch_idx:05d}-of-' \
                                  f'{num_shards:05d}.tfrecord'
    # inspired by https://stackoverflow.com/questions/54519309/split-tfrecords-file-into-many-tfrecords-files
    for i in range(num_shards):
        shard_path = formatter(i)
        writer = tf.data.experimental.TFRecordWriter(shard_path)
        shard = dataset.shard(num_shards, index=i)
        writer.write(shard)
</code></pre>
<p>This is supposed to be a straight-forward use of tfrecords writer. However, It does not write any files at all. Does anyone understand why this doesn't work?</p>
",2020-10-28 17:34:51,13608754,649,https://stackoverflow.com/questions/64578310,Documentation Replication on Other Examples
64612657,Manually change weights of Keras convolutional layer,"<p>There is a way to change manually the weights for the tf.layers.Conv2d (<a href=""https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers/Conv2D"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers/Conv2D</a>)? Because this class takes in only the input, the number of kernels to use, etc... and the weights are automatically stored and computed by Tensorflow, but I would a way (like in tf.nn.conv2d - <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/conv2d</a>) to pass directly the weights to the class.</p>
<p>Anyone have a suggestion?</p>
<p>Maybe one could be to load and change manually the value for the variable associate at that layer? I found this solution very bad but it could work.</p>
<p>Thank you.</p>
",2020-10-30 16:55:33,14548310,455,https://stackoverflow.com/questions/64612657,Documentation Replication on Other Examples
64737363,TensorFlow training gets slower every batch,"<p>I am new to TensorFlow and I get my code running successfully by modifying tutorials from the official website.</p>
<p>I checked some other answers on StackOverflow, which says my problem is likely due to something is being added to the graph every time. However, I have no idea where to look for the code that might have caused this.</p>
<p>Also, I used tf.py_function to map the dataset because I really need to enable eagerly mode in the mapping.</p>
<pre><code>def get_dataset(data_index):
    # data_index is a Pandas Dataframe that contains image/label pair info, each row is one pair
    data_index = prepare_data_index(data_index)
    # shuffle dataframe here because dataset.shuffle is taking very long time.
    data_index = data_index.sample(data_index.shape[0])

    path = path_to_img_dir

    # list of dataframe indices indicating rows that are going to be included in the dataset for training. 
    indices_ls = ['{}_L'.format(x) for x in list(data_index.index)] + ['{}_R'.format(x) for x in list(data_index.index)]
  
    # around 310k images
    image_count = len(indices_ls)

    list_ds = tf.data.Dataset.from_tensor_slices(indices_ls)
    # dataset.shuffle is commented out because it takes too much time
    # list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)

    val_size = int(image_count * 0.2)
    train_ds = list_ds.skip(val_size)
    val_ds = list_ds.take(val_size)

    def get_label(index):
        index = str(np.array(index).astype(str))
        delim = index.split('_')
        state = delim[1]
        index = int(delim[0])

        if state == 'R':
            label = data_index.loc[index][right_labels].to_numpy().flatten()
        elif state == 'L':
            label = data_index.loc[index][left_labels].to_numpy().flatten()

        return tf.convert_to_tensor(label , dtype=tf.float16)

    def get_img(index):
        index = str(np.array(index).astype(str))
        delim = index.split('_')
        state = delim[1]
        index = int(delim[0])

        file_path = '{}_{}.jpg'.format(data_index.loc[index, 'sub_folder'],
                                   str(int(data_index.loc[index, 'img_index'])).zfill(4)
                                   )
        img = tf.io.read_file(os.path.join(path, file_path))
        img = tf.image.decode_jpeg(img, channels=3)
        full_width = 320
        img = tf.image.resize(img, [height, full_width])

        # Crop half of the image depending on the state
        if state == 'R':
            
            img = tf.image.crop_to_bounding_box(img, offset_height=0, offset_width=0, target_height=height,
                                            target_width=int(full_width / 2))
            img = tf.image.flip_left_right(img)
        elif state == 'L':
            
            img = tf.image.crop_to_bounding_box(img, offset_height=0, offset_width=int(full_width / 2), target_height=height,
                                            target_width=int(full_width / 2))
        img = tf.image.resize(img, [height, width])
        img = tf.keras.preprocessing.image.array_to_img(
        img.numpy(), data_format=None, scale=True, dtype=None
    )
        # Apply auto white balancing, output an np array
        img = AWB(img)
        img = tf.convert_to_tensor(img, dtype=tf.float16)

        return img

    def process_path(index):
        label = get_label(index)
        img = get_img(index)
        return img, label

    AUTOTUNE = tf.data.experimental.AUTOTUNE

    train_ds = train_ds.map(lambda x: tf.py_function(
    process_path,
    [x], (tf.float16, tf.float16)), num_parallel_calls=AUTOTUNE)
    val_ds = val_ds.map(lambda x: tf.py_function(
    process_path,
    [x], (tf.float16, tf.float16)), num_parallel_calls=AUTOTUNE)

    def configure_for_performance(ds):
        ds = ds.cache()
        # ds = ds.shuffle(buffer_size=image_count)
        ds = ds.batch(batch_size)
        ds = ds.prefetch(buffer_size=AUTOTUNE)
        return ds

    train_ds = configure_for_performance(train_ds)
    val_ds = configure_for_performance(val_ds)

    return train_ds, val_ds
</code></pre>
<p>Can anyone please help me? Thanks!</p>
<p>Here is the rest of my code.</p>
<pre><code>def initialize_model():
    IMG_SIZE = (height, width)

    preprocess_input = tf.keras.applications.vgg19.preprocess_input

    IMG_SHAPE = IMG_SIZE + (3,)
    base_model = tf.keras.applications.VGG19(input_shape=IMG_SHAPE,
                                         include_top=False,
                                         weights='imagenet')

    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
    prediction_layer = tf.keras.layers.Dense(class_num, activation=tf.nn.sigmoid, use_bias=True)

    inputs = tf.keras.Input(shape=(height, width, 3))
    x = preprocess_input(inputs)
    x = base_model(x, training=True)
    x = global_average_layer(x)
    outputs = prediction_layer(x)
    model = tf.keras.Model(inputs, outputs)

    def custom_loss(y_gt, y_pred):
        
        L1_loss_out = tf.math.abs(tf.math.subtract(y_gt, y_pred))
        scaler = tf.pow(50.0, y_gt)
        scaled_loss = tf.math.multiply(L1_loss_out, scaler)
        scaled_loss = tf.math.reduce_mean(
            scaled_loss, axis=None, keepdims=False, name=None
        )
        return scaled_loss

    base_learning_rate = 0.001
    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate, momentum=0.9),
                  loss=custom_loss,
                  metrics=['mean_absolute_error']
                  )

    return model


def train(data_index, epoch_num, save_path):
    train_dataset, validation_dataset = get_dataset(data_index)
    model = initialize_model()
    model.summary()

    history = model.fit(train_dataset,
                        epochs=epoch_num,
                        validation_data=validation_dataset)
    model.save_weights(save_path)

    return model, history
</code></pre>
",2020-11-08 11:09:25,9712687,109,https://stackoverflow.com/questions/64737363,Documentation Replication on Other Examples
64769187,"Tensorflow - Interpreting the tf.estimator.ProfilerHook ""_Send"" op","<p>I have a deep CNN/RNN that I train on Google AI platform. I distribute the training on 8 GPUs using the <code>tf.distribute.MirroredStrategy</code>. I recently upgraded my runtime version from 1.13 to 1.15 and my training is more than 2x slower than before. I read that <code>tf.estimator.ProfilerHook</code> can be used to identify performance bottlenecks. So I collected the profiling information and rendered it at <code>chrome://tracing</code>. I got this</p>
<p><a href=""https://i.stack.imgur.com/l5hDZ.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/l5hDZ.jpg"" alt=""profiling screenshot"" /></a></p>
<p>A training step spends an entire 1 second on these <code>_Send</code> ops. What is this? I can't find any documentation on the op or why it's in my graph. What does this mean?</p>
",2020-11-10 12:44:46,6078821,3743,https://stackoverflow.com/questions/64769187,Lack of Alternative Solutions/Documentation
64776769,Why tf.contrib.layers.instance_norm layer contain StopGradient operation?,"<p>Why <code>tf.contrib.layers.instance_norm</code> layer contain <code>StopGradient</code> operation? i.e. why it's needed?</p>
<p><a href=""https://i.stack.imgur.com/fnXbj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fnXbj.png"" alt=""enter image description here"" /></a></p>
<p>Seems there is <code>StopGradient</code> even in simpler layer <code>tf.nn.moments</code> (that can be building block of <code>tf.contrib.layers.instance_norm</code>).</p>
<pre><code>x_m, x_v = tf.nn.moments(x, [1, 2], keep_dims=True)
</code></pre>
<p><a href=""https://i.stack.imgur.com/g0QWX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/g0QWX.png"" alt=""enter image description here"" /></a></p>
<p>Also I find a note on <code>StopGradient</code> in <code>tf.nn.moments</code> source code:</p>
<pre><code># The dynamic range of fp16 is too limited to support the collection of
# sufficient statistics. As a workaround we simply perform the operations
# on 32-bit floats before converting the mean and variance back to fp16
y = math_ops.cast(x, dtypes.float32) if x.dtype == dtypes.float16 else x
# Compute true mean while keeping the dims for proper broadcasting.
mean = math_ops.reduce_mean(y, axes, keepdims=True, name=&quot;mean&quot;)
# sample variance, not unbiased variance
# Note: stop_gradient does not change the gradient that gets
#       backpropagated to the mean from the variance calculation,
#       because that gradient is zero
variance = math_ops.reduce_mean(
    math_ops.squared_difference(y, array_ops.stop_gradient(mean)),
    axes,
    keepdims=True,
    name=&quot;variance&quot;)
</code></pre>
<p>So it's sort of optimisation because gradient is always zero?</p>
",2020-11-10 21:06:32,1179925,20633,https://stackoverflow.com/questions/64776769,Documentation Replicability
64780641,Whats the equivalent of tf.keras.Input() in pytorch?,"<p>can someone tell me what the equivalent of tf.keras.Input() in pytorch is?</p>
<p>At the documentation it says, &quot;Initiates a Keras Tensor&quot;, so does it just creates a new empty tensor?</p>
<p>Thanks</p>
",2020-11-11 04:51:39,8677804,21,https://stackoverflow.com/questions/64780641,Lack of Alternative Solutions/Documentation
64837612,Google AI platform can't write to Cloud Storage,"<p>Running a <a href=""https://github.com/tensorflow/cloud"" rel=""nofollow noreferrer"">tensorflow-cloud</a> job on Google AI Platform, the entrypoint of the job is the following:</p>
<pre><code>import tensorflow as tf

filename = r'gs://my_bucket_name/hello.txt'
with tf.io.gfile.GFile(filename, mode='w') as w:
  w.write(&quot;Hello, world!&quot;)

with tf.io.gfile.GFile(filename, mode='r') as r:
  print(r.read())
</code></pre>
<p>The job completed successfully, in the logs it prints &quot;hello world&quot;.</p>
<p>The bucket and the job are both in the same region.</p>
<p>But I can't find the file in Cloud Storage. It is not there. I ran some other tests, where I did <code>tf.io.gfile.listdir</code> then wrote a new file and again <code>tf.io.gfile.listdir</code>, I printed the before and after, it seems that a file was added but when I open cloud storage, I can't find it there. Also was able to read files from storage.</p>
<p>I'm not getting any permissions errors, and as the official docs say, AI Platform already has the permission to read/write to Cloud Storage.</p>
<p>Here is my <code>main.py</code> file:</p>
<pre><code>import tensorflow_cloud as tfc

tfc.run(
   entry_point=&quot;run_me.py&quot;,
   requirements_txt=&quot;requirements.txt&quot;,
   chief_config=tfc.COMMON_MACHINE_CONFIGS['CPU'],
   docker_config=tfc.DockerConfig(
      image_build_bucket=&quot;test_ai_storage&quot;),
)
</code></pre>
<p>This is the most minimal version where I can reproduce the problem.</p>
",2020-11-14 19:08:49,4465386,3750,https://stackoverflow.com/questions/64837612,Documentation Replication on Other Examples
64847875,"tf.keras.Model save: ""AssertionError: Tried to export a function which references untracked object Tensor""","<p>I'm running this Tensorflow NMT tutorial: <a href=""https://github.com/tensorflow/addons/blob/master/docs/tutorials/networks_seq2seq_nmt.ipynb"" rel=""nofollow noreferrer"">https://github.com/tensorflow/addons/blob/master/docs/tutorials/networks_seq2seq_nmt.ipynb</a></p>
<p>When I try to save the decoder:
<code>decoder.save('decoder')</code>, I get:</p>
<p><code>AssertionError: Tried to export a function which references untracked object Tensor(&quot;LuongAttention/memory_layer/Tensordot:0&quot;, shape=(1024, 23, 256), dtype=float32).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.</code></p>
<p>I also tried registering the LuongAttention object like:</p>
<pre><code>attention_mechanism = tfa.seq2seq.LuongAttention(units=units, memory=None, memory_sequence_length=BATCH_SIZE*[max_length_input])
custom_objects = {&quot;LuongAttention&quot;: attention_mechanism}
with tf.keras.utils.custom_object_scope(custom_objects):
  decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, attention_mechanism)```
</code></pre>
",2020-11-15 17:55:47,14643783,41,https://stackoverflow.com/questions/64847875,Documentation Replicability
64947184,"converting very large raw file to csv file, tf.data.Dataset","<p>I have a 200GB .raw file with tab as column separator (It has a tab before first column too). I want to convert this file to .csv file with comma as column separator. I used the following commands:</p>
<pre><code>sed ‘s/\t/,/g’ File1.raw &gt; File2.csv
</code></pre>
<p>However, when I want to read this csv file (File2.csv) with tf.data.Dataset (<a href=""https://colab.research.google.com/github/adammichaelwood/tf-docs/blob/csv-feature-columns/site/en/r2/tutorials/load_data/csv.ipynb#scrollTo=sUtoed20cRJJ"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/adammichaelwood/tf-docs/blob/csv-feature-columns/site/en/r2/tutorials/load_data/csv.ipynb#scrollTo=sUtoed20cRJJ</a>), then I get this error:</p>
<pre><code>raise ValueError(&quot;Cannot have duplicate column names.&quot;)
ValueError: Cannot have duplicate column names.
</code></pre>
<p>I am sure my .raw file is fine. How can I convert File1.raw file to File2.csv file with comma as column separator without producing duplicated columns?</p>
",2020-11-21 19:26:51,8155727,1166,https://stackoverflow.com/questions/64947184,Documentation Replication on Other Examples
65099915,how do i convert a tf.Variable to numpy?,"<p>How could I convert a <code>tf.Variable</code> to a numpy array?</p>
<pre class=""lang-py prettyprint-override""><code>var1 = tf.Variable(4.0)
</code></pre>
<p>I want to get <code>[4.0]</code></p>
",2020-12-01 23:07:32,11069811,397,https://stackoverflow.com/questions/65099915,Documentation Replicability
65157852,How to mix tensorflow keras model and transformers,"<p>I am trying to import a pretrained model from Huggingface's transformers library and extend it with a few layers for classification using tensorflow keras. When I directly use transformers model (Method 1), the model trains well and reaches a validation accuracy of 0.93 after 1 epoch. However, when trying to use the model as a layer within a tf.keras model (Method 2), the model can't get above 0.32 accuracy. As far as I can tell based on the documentation, the two approaches should be equivalent. My goal is to get Method 2 working so that I can add more layers to it instead of directly using the logits produced by Huggingface's classifier head but I'm stuck at this stage.</p>
<pre><code>import tensorflow as tf

from transformers import TFRobertaForSequenceClassification
</code></pre>
<p>Method 1:</p>
<pre><code>model = TFRobertaForSequenceClassification.from_pretrained(&quot;roberta-base&quot;, num_labels=6)
</code></pre>
<p>Method 2:</p>
<pre><code>input_ids = tf.keras.Input(shape=(128,), dtype='int32')

attention_mask = tf.keras.Input(shape=(128, ), dtype='int32')

transformer = TFRobertaForSequenceClassification.from_pretrained(&quot;roberta-base&quot;, num_labels=6)

encoded = transformer([input_ids, attention_mask])

logits = encoded[0]

model = tf.keras.models.Model(inputs = [input_ids, attention_mask], outputs = logits)

</code></pre>
<p>Rest of the code for either method is identical,</p>
<pre><code>model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), 
              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])
</code></pre>
<p>I am using Tensorflow 2.3.0 and have tried with transformers versions 3.5.0 and 4.0.0.</p>
",2020-12-05 14:15:46,8840524,121,https://stackoverflow.com/questions/65157852,Documentation Replication on Other Examples
65201252,How to shuffle TFrecords files before feeding them to the model,"<p>I am fitting a Neural network model using TFrecords and keras. I have a relatively big dataset which is pretty heterogeneous. I already used the shuffle my dataset during the training of the model like in the documentation exemple :<a href=""https://keras.io/examples/keras_recipes/tfrecord/"" rel=""nofollow noreferrer"">https://keras.io/examples/keras_recipes/tfrecord/</a>  (but can't shuffle all because it would cost too much memory) and I also separated my dataset into small shards each of equal size.</p>
<p>However I have reasons to think that this &quot;approximate&quot; shuffling is not enough and I also think that feeding already shuffled data would increase training speed.</p>
<p>So now my question is: After I have separated my dataset into Tfrecords shards, Is it possible to efficiently make code that takes randomly 2 shards, load them, shuffle them and then rewrite 2 shards (which are now shuffled between two shards). So that I can repeat this process a lot of time, which would result in correctly shuffled TFrecords files.</p>
<p>More precisely, I take 2 shards: shard1.tfrec and shard2.tfrec, load them into one tf.data.dataset, shuffle it, and then output 2 shards of equal size again.</p>
",2020-12-08 14:55:46,14485071,41,https://stackoverflow.com/questions/65201252,Documentation Ambiguity
65277703,image normalization and TPU,"<p>I'm trying to incorporate image normalization in my keras model to run on Google's cloud TPU. Therefore I inserted a line into my code:</p>
<pre><code>with strategy.scope():
     input_shape=(128,128,3)
     image_0 = Input(shape=input_shape)
     **image_1 = tf.image.per_image_standardization(image_0)**
     ...
</code></pre>
<p>There was nor error thrown, but according the documentation of google tf.image.per_image_standardization
is not a supported function. Does anybody know if it works anyhow, or does anybody have an idea how to check if it works?</p>
",2020-12-13 16:07:44,14818604,1,https://stackoverflow.com/questions/65277703,Documentation Replicability
65408472,Tensorflow: How to handle preprocessing.Normalization returning NaN,"<p>I am building a keras model and trying to use the tf.keras.layers.experimental.preprocessing.Normalization from <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization</a> to normalize the input training data as such:</p>
<pre><code>normalize = preprocessing.Normalization()
normalize.adapt(trainX)
model = Sequential([
    normalize,
    Dense(dim + 1, input_dim=dim, activation=&quot;relu&quot;),
    Dense(dim / 2, activation=&quot;relu&quot;),
])
</code></pre>
<p>The goal is to save the normalization within the saved model. I am running into the issue where the <code>normalize(trainX)</code> is normalizing some of the inputs to <code>nan</code> due to most likely a division of zero in the variance. E.g. a row of the output: <code>[ 0.00000000e+00, nan, 9.40457404e-01, 9.40672755e-01, 9.40672755e-01, 9.40672755e-01, 9.40672755e-01, nan, nan, nan, nan, nan]</code></p>
<p><strong>Is there a way to handle division of zero in <code>preprocessing.Normalization()</code> or is this there another way of normalization I should consider that I can save within the model?</strong></p>
",2020-12-22 12:08:57,6372640,428,https://stackoverflow.com/questions/65408472,Documentation Replicability
65413136,Tensorflow — Cannot call `tf.keras.Model.add_metric` when `tf.distribute.MirroredStrategy` is used,"<p>I have a model class that inherits from <code>tf.keras.Model</code>. I can train, evaluate, and <em>export</em> it using 8 GPUs, distributing it with <code>tf.distribute.MirroredStrategy</code>. However, I need custom metrics, and when I call the <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_add_metric_method"" rel=""nofollow noreferrer"">add_metric</a> method, it throws an error when trying to <strong>export</strong>.</p>
<pre><code>Traceback (most recent call last):
  File &quot;repro/vae.py&quot;, line 80, in &lt;module&gt;
    vae.save(&quot;vae&quot;)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py&quot;, line 1979, in save
    signatures, options)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py&quot;, line 134, in save_model
    signatures, options)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py&quot;, line 80, in save
    save_lib.save(model, filepath, signatures, options)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py&quot;, line 976, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py&quot;, line 1047, in _build_meta_graph
    checkpoint_graph_view)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py&quot;, line 75, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py&quot;, line 145, in list_functions
    self._serialization_cache)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py&quot;, line 2590, in _list_functions_for_serialization
    Model, self)._list_functions_for_serialization(serialization_cache)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py&quot;, line 3019, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py&quot;, line 87, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py&quot;, line 79, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py&quot;, line 95, in _get_serialized_attributes
    serialization_cache)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py&quot;, line 51, in _get_serialized_attributes_internal
    default_signature = save_impl.default_save_signature(self.obj)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py&quot;, line 205, in default_save_signature
    fn.get_concrete_function()
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 1167, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 1073, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 697, in _initialize
    *args, **kwds))
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3075, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py&quot;, line 134, in _wrapped_model
    outputs = model(inputs, training=False)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py&quot;, line 985, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py&quot;, line 302, in wrapper
    return func(*args, **kwargs)
  File &quot;repro/vae.py&quot;, line 63, in call
    self.add_metric([0.], name=&quot;foo&quot;)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py&quot;, line 1705, in add_metric
    metric_obj(value)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py&quot;, line 231, in __call__
    replica_local_fn, *args, **kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py&quot;, line 1133, in call_replica_local_fn
    return fn(*args, **kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py&quot;, line 211, in replica_local_fn
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py&quot;, line 90, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py&quot;, line 176, in update_state_fn
    return ag_update_state(*args, **kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py&quot;, line 302, in wrapper
    return func(*args, **kwargs)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py&quot;, line 373, in update_state
    update_total_op = self.total.assign_add(value_sum)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/distribute/values.py&quot;, line 1015, in assign_add
    self, value, read_value=read_value)
  File &quot;/Users/acarlson/anaconda3/envs/ed-autocoder-dev/lib/python3.7/site-packages/tensorflow/python/distribute/values_util.py&quot;, line 95, in on_read_assign_add_cross_replica
    &quot;SyncOnReadVariable does not support `assign_add` in &quot;
ValueError: SyncOnReadVariable does not support `assign_add` in cross-replica context when aggregation is set to `tf.VariableAggregation.SUM`.
</code></pre>
<p>I have created a simple reproduction which shows this error here:</p>
<pre><code>import tensorflow as tf


class Sampling(tf.keras.layers.Layer):
    &quot;&quot;&quot;Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.&quot;&quot;&quot;

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


class Encoder(tf.keras.layers.Layer):
    &quot;&quot;&quot;Maps MNIST digits to a triplet (z_mean, z_log_var, z).&quot;&quot;&quot;

    def __init__(self, latent_dim=32, intermediate_dim=64, name=&quot;encoder&quot;, **kwargs):
        super(Encoder, self).__init__(name=name, **kwargs)
        self.dense_proj = tf.keras.layers.Dense(intermediate_dim, activation=&quot;relu&quot;)
        self.dense_mean = tf.keras.layers.Dense(latent_dim)
        self.dense_log_var = tf.keras.layers.Dense(latent_dim)
        self.sampling = Sampling()

    def call(self, inputs):
        x = self.dense_proj(inputs)
        z_mean = self.dense_mean(x)
        z_log_var = self.dense_log_var(x)
        z = self.sampling((z_mean, z_log_var))
        return z_mean, z_log_var, z


class Decoder(tf.keras.layers.Layer):
    &quot;&quot;&quot;Converts z, the encoded digit vector, back into a readable digit.&quot;&quot;&quot;

    def __init__(self, original_dim, intermediate_dim=64, name=&quot;decoder&quot;, **kwargs):
        super(Decoder, self).__init__(name=name, **kwargs)
        self.dense_proj = tf.keras.layers.Dense(intermediate_dim, activation=&quot;relu&quot;)
        self.dense_output = tf.keras.layers.Dense(original_dim, activation=&quot;sigmoid&quot;)

    def call(self, inputs):
        x = self.dense_proj(inputs)
        return self.dense_output(x)


class VariationalAutoEncoder(tf.keras.Model):
    &quot;&quot;&quot;Combines the encoder and decoder into an end-to-end model for training.&quot;&quot;&quot;

    def __init__(self, original_dim, intermediate_dim=64, latent_dim=32, name=&quot;autoencoder&quot;, **kwargs):
        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)
        self.original_dim = original_dim
        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)
        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)

    def call(self, inputs):
        z_mean, z_log_var, z = self.encoder(inputs)
        reconstructed = self.decoder(z)
        # Add KL divergence regularization loss.
        kl_loss = -0.5 * tf.reduce_mean(
            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1
        )
        self.add_loss(kl_loss)
        self.add_metric([0.], name=&quot;foo&quot;)
        return reconstructed


(x_train, _), _ = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape(60000, 784).astype(&quot;float32&quot;) / 255

original_dim = 784

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    vae = VariationalAutoEncoder(original_dim, 64, 32)
    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
    vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())

vae.fit(x_train, x_train, epochs=3, batch_size=64)
vae.save(&quot;vae&quot;)
</code></pre>
<p>I apologize for so much code, but most of it isn't important. The important part is that this model is instantiated and compiled inside the <code>tf.distribute.MirroredStrategy</code> scope. There is also a <code>self.add_metric([0.], name=&quot;foo&quot;)</code> in the model. If you remove that <code>add_metric</code> call, then it works. It will export correctly.</p>
<p>Therefore, using the <code>tf.keras.Model.add_metric</code> method with <code>tf.distribute.MirroredStrategy</code>. I need to be able to add my custom metrics with a distributed model.</p>
<p>Note: Metrics are <strong>supposed</strong> to be calculated in the strategy scope, as mentioned in <a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy#scope"" rel=""nofollow noreferrer"">the docs</a></p>
<blockquote>
<p>&quot;Common things that create variables in TF: models, optimizers, metrics. These should always be created inside the scope.&quot;</p>
</blockquote>
<p>As for versions, I'm using the Google <a href=""https://cloud.google.com/ai-platform/training/docs/runtime-version-list#2.3"" rel=""nofollow noreferrer"">AI platform runtime version 2.3</a></p>
",2020-12-22 17:25:18,6078821,3743,https://stackoverflow.com/questions/65413136,Documentation Replicability
65437493,convert string to float array in csv using tf.data,"<p>I have a csv like this :</p>
<pre><code>kw_text,kw_text_weight
amazon google,0.5 0.5
google facebook microsoft,0.5 0.3 0.2
</code></pre>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>kw_text</th>
<th>kw_text_weight</th>
</tr>
</thead>
<tbody>
<tr>
<td>amazon google</td>
<td>0.5 0.5</td>
</tr>
<tr>
<td>google facebook microsoft</td>
<td>0.5 0.3 0.2</td>
</tr>
</tbody>
</table>
</div>
<p>I want to convert column <code>text_weight</code> to <code>tf.data</code> . But I find nothing about it in tensorflow document website .</p>
",2020-12-24 11:09:18,6862189,1245,https://stackoverflow.com/questions/65437493,Lack of Alternative Solutions/Documentation
65481591,Keras Generator to tf.data.Dataset,"<p>I am working with the Mask RCNN keras implementation but the data generator hard locks on my systems when using <code>use_multiprocessing=True</code>. The data generator runs fine in single thread. I am trying to convert the data generator to a <code>tf.data.Dataset</code> as recommended by tensorflow. I have no idea how to do this and have been unable to find any documentation on this.</p>
<p>Mask RCNN data generator:</p>
<pre><code>class DataGenerator(KU.Sequence):
    &quot;&quot;&quot;An iterable that returns images and corresponding target class ids,
        bounding box deltas, and masks. It inherits from keras.utils.Sequence to avoid data redundancy
        when multiprocessing=True.

        dataset: The Dataset object to pick data from
        config: The model config object
        shuffle: If True, shuffles the samples before every epoch
        augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.
            For example, passing imgaug.augmenters.Fliplr(0.5) flips images
            right/left 50% of the time.
        random_rois: If &gt; 0 then generate proposals to be used to train the
                     network classifier and mask heads. Useful if training
                     the Mask RCNN part without the RPN.
        detection_targets: If True, generate detection targets (class IDs, bbox
            deltas, and masks). Typically for debugging or visualizations because
            in trainig detection targets are generated by DetectionTargetLayer.

        Returns a Python iterable. Upon calling __getitem__() on it, the
        iterable returns two lists, inputs and outputs. The contents
        of the lists differ depending on the received arguments:
        inputs list:
        - images: [batch, H, W, C]
        - image_meta: [batch, (meta data)] Image details. See compose_image_meta()
        - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)
        - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.
        - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs
        - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]
        - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width
                    are those of the image unless use_mini_mask is True, in which
                    case they are defined in MINI_MASK_SHAPE.

        outputs list: Usually empty in regular training. But if detection_targets
            is True then the outputs list contains target class_ids, bbox deltas,
            and masks.
        &quot;&quot;&quot;

    def __init__(self, dataset, config, shuffle=True, augmentation=None,
                 random_rois=0, detection_targets=False):

        self.image_ids = np.copy(dataset.image_ids)
        self.dataset = dataset
        self.config = config

        # Anchors
        # [anchor_count, (y1, x1, y2, x2)]
        self.backbone_shapes = compute_backbone_shapes(config, config.IMAGE_SHAPE)
        self.anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,
                                                      config.RPN_ANCHOR_RATIOS,
                                                      self.backbone_shapes,
                                                      config.BACKBONE_STRIDES,
                                                      config.RPN_ANCHOR_STRIDE)

        self.shuffle = shuffle
        self.augmentation = augmentation
        self.random_rois = random_rois
        self.batch_size = self.config.BATCH_SIZE
        self.detection_targets = detection_targets

    def __len__(self):
        return int(np.ceil(len(self.image_ids) / float(self.batch_size)))

    def __getitem__(self, idx):
        b = 0
        image_index = -1
        while b &lt; self.batch_size:
            
            # Increment index to pick next image. Shuffle if at the start of an epoch.
            image_index = (image_index + 1) % len(self.image_ids)

            if self.shuffle and image_index == 0:
                np.random.shuffle(self.image_ids)

            # Get GT bounding boxes and masks for image.
            image_id = self.image_ids[image_index]
            image, image_meta, gt_class_ids, gt_boxes, gt_masks = \
                load_image_gt(self.dataset, self.config, image_id,
                              augmentation=self.augmentation)

            # Skip images that have no instances. This can happen in cases
            # where we train on a subset of classes and the image doesn't
            # have any of the classes we care about.
            if not np.any(gt_class_ids &gt; 0):
                continue

            # RPN Targets
            rpn_match, rpn_bbox = build_rpn_targets(image.shape, self.anchors,
                                                    gt_class_ids, gt_boxes, self.config)

            # Mask R-CNN Targets
            if self.random_rois:
                rpn_rois = generate_random_rois(
                    image.shape, self.random_rois, gt_class_ids, gt_boxes)
                if self.detection_targets:
                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask = \
                        build_detection_targets(
                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, self.config)

            # Init batch arrays
            if b == 0:
                batch_image_meta = np.zeros((self.batch_size,) + image_meta.shape, dtype=image_meta.dtype)
                batch_rpn_match = np.zeros([self.batch_size, self.anchors.shape[0], 1], dtype=rpn_match.dtype)
                batch_rpn_bbox = np.zeros([self.batch_size, self.config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4], dtype=rpn_bbox.dtype)
                batch_images = np.zeros((self.batch_size,) + image.shape, dtype=np.float32)
                batch_gt_class_ids = np.zeros((self.batch_size, self.config.MAX_GT_INSTANCES), dtype=np.int32)
                batch_gt_boxes = np.zeros((self.batch_size, self.config.MAX_GT_INSTANCES, 4), dtype=np.int32)
                batch_gt_masks = np.zeros((self.batch_size, gt_masks.shape[0], gt_masks.shape[1],self.config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)
                if self.random_rois:
                    batch_rpn_rois = np.zeros((self.batch_size, rpn_rois.shape[0], 4), dtype=rpn_rois.dtype)
                    if self.detection_targets:
                        batch_rois = np.zeros((self.batch_size,) + rois.shape, dtype=rois.dtype)
                        batch_mrcnn_class_ids = np.zeros((self.batch_size,) + mrcnn_class_ids.shape, dtype=mrcnn_class_ids.dtype)
                        batch_mrcnn_bbox = np.zeros((self.batch_size,) + mrcnn_bbox.shape, dtype=mrcnn_bbox.dtype)
                        batch_mrcnn_mask = np.zeros((self.batch_size,) + mrcnn_mask.shape, dtype=mrcnn_mask.dtype)

            # If more instances than fits in the array, sub-sample from them.
            if gt_boxes.shape[0] &gt; self.config.MAX_GT_INSTANCES:
                ids = np.random.choice(
                    np.arange(gt_boxes.shape[0]), self.config.MAX_GT_INSTANCES, replace=False)
                gt_class_ids = gt_class_ids[ids]
                gt_boxes = gt_boxes[ids]
                gt_masks = gt_masks[:, :, ids]

            # Add to batch
            batch_image_meta[b] = image_meta
            batch_rpn_match[b] = rpn_match[:, np.newaxis]
            batch_rpn_bbox[b] = rpn_bbox
            batch_images[b] = mold_image(image.astype(np.float32), self.config)
            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids
            batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes
            batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks
            if self.random_rois:
                batch_rpn_rois[b] = rpn_rois
                if self.detection_targets:
                    batch_rois[b] = rois
                    batch_mrcnn_class_ids[b] = mrcnn_class_ids
                    batch_mrcnn_bbox[b] = mrcnn_bbox
                    batch_mrcnn_mask[b] = mrcnn_mask
            b += 1

        inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,
                  batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]
        outputs = []

        if self.random_rois:
            inputs.extend([batch_rpn_rois])
            if self.detection_targets:
                inputs.extend([batch_rois])
                # Keras requires that output and targets have the same number of dimensions
                batch_mrcnn_class_ids = np.expand_dims(
                    batch_mrcnn_class_ids, -1)
                outputs.extend(
                    [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])

        return inputs, outputs
</code></pre>
<p>I have tried to use the <code>tf.data.Dataset.from_generator()</code> however it requires the <code>output_types=</code> argument and the Mask RCNN outputs a number of lists, I can not figure out how to define <code>output_types=</code>.</p>
<p>I am using <code>python3.7</code>, <code>keras==2.2.5</code>, <code>tensorflow==2.2.0</code></p>
",2020-12-28 17:31:25,2600161,505,https://stackoverflow.com/questions/65481591,Documentation Replication on Other Examples
65525687,My model.fit and model.evaluate are not working properly and I am getting an error,"<pre><code>train_x = train['text']
valid_x = valid[&quot;text&quot;]
train_y = train[&quot;label&quot;]
valid_y = valid[&quot;label&quot;]
train_y = train_y.values.reshape(-1,1)

vectorizer = TfidfVectorizer()
vectorizer.fit_transform(train_x)

x_train_count = vectorizer.fit_transform(train_x)

x_valid_count = vectorizer.fit_transform(valid_x)

x_test_count  = vectorizer.fit_transform(test[&quot;text&quot;])

model = tf.keras.Sequential() 

model.add(Dense(50,input_dim=x_train_count.shape[1], kernel_initializer=&quot;uniform&quot;, activation=&quot;relu&quot;)) 
model.add(Dense(1, kernel_initializer=&quot;uniform&quot;, activation=&quot;sigmoid&quot;)) 
model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;])
# # Fit the model
history = model.fit(x_train_count, train_y, validation_data=(x_valid_count,valid_y), epochs=3, batch_size=128)

loss, acc = model.evaluate(x_test_count, test[&quot;label&quot;], verbose=0)
</code></pre>
<h1>Error</h1>
<pre><code>--------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-1-be49478b4c50&gt; in &lt;module&gt;
         71 model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;])
         72 # # Fit the model
    ---&gt; 73 history = model.fit(x_train_count, train_y, validation_data=(x_valid_count,valid_y), epochs=3, batch_size=128)
         74 
         75 loss, acc = model.evaluate(x_test_count, test[&quot;label&quot;], verbose=0)

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1048          training_utils.RespectCompiledTrainableState(self):
   1049       # Creates a `tf.data.Dataset` and handles batch and epoch iteration.
-&gt; 1050       data_handler = data_adapter.DataHandler(
   1051           x=x,
   1052           y=y,

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)
   1098 
   1099     adapter_cls = select_data_adapter(x, y)
-&gt; 1100     self._adapter = adapter_cls(
   1101         x,
   1102         y,

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, steps, shuffle, **kwargs)
    564     inputs = pack_x_y_sample_weight(x, y, sample_weights)
    565 
--&gt; 566     dataset = dataset_ops.DatasetV2.from_tensor_slices(inputs)
    567     num_samples = int(nest.flatten(x)[0].shape[0])
    568     if shuffle:

~\anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in from_tensor_slices(tensors)
    689       Dataset: A `Dataset`.
    690     &quot;&quot;&quot;
--&gt; 691     return TensorSliceDataset(tensors)
    692 
    693   class _GeneratorState(object):

~\anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py in __init__(self, element)
   3155     element = structure.normalize_element(element)
   3156     batched_spec = structure.type_spec_from_value(element)
-&gt; 3157     self._tensors = structure.to_batched_tensor_list(batched_spec, element)
   3158     self._structure = nest.map_structure(
   3159         lambda component_spec: component_spec._unbatch(), batched_spec)  # pylint: disable=protected-access

~\anaconda3\lib\site-packages\tensorflow\python\data\util\structure.py in to_batched_tensor_list(element_spec, element)
    362   # pylint: disable=protected-access
    363   # pylint: disable=g-long-lambda
--&gt; 364   return _to_tensor_list_helper(
    365       lambda state, spec, component: state + spec._to_batched_tensor_list(
    366           component), element_spec, element)

~\anaconda3\lib\site-packages\tensorflow\python\data\util\structure.py in _to_tensor_list_helper(encode_fn, element_spec, element)
    337     return encode_fn(state, spec, component)
    338 
--&gt; 339   return functools.reduce(
    340       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])
    341 

~\anaconda3\lib\site-packages\tensorflow\python\data\util\structure.py in reduce_fn(state, value)
    335   def reduce_fn(state, value):
    336     spec, component = value
--&gt; 337     return encode_fn(state, spec, component)
    338 
    339   return functools.reduce(

~\anaconda3\lib\site-packages\tensorflow\python\data\util\structure.py in &lt;lambda&gt;(state, spec, component)
    363   # pylint: disable=g-long-lambda
    364   return _to_tensor_list_helper(
--&gt; 365       lambda state, spec, component: state + spec._to_batched_tensor_list(
    366           component), element_spec, element)
    367 

~\anaconda3\lib\site-packages\tensorflow\python\framework\sparse_tensor.py in _to_batched_tensor_list(self, value)
    367       raise ValueError(
    368           &quot;Unbatching a sparse tensor is only supported for rank &gt;= 1&quot;)
--&gt; 369     return [gen_sparse_ops.serialize_many_sparse(
    370         value.indices, value.values, value.dense_shape,
    371         out_type=dtypes.variant)]

~\anaconda3\lib\site-packages\tensorflow\python\ops\gen_sparse_ops.py in serialize_many_sparse(sparse_indices, sparse_values, sparse_shape, out_type, name)
    493       return _result
    494     except _core._NotOkStatusException as e:
--&gt; 495       _ops.raise_from_not_ok_status(e, name)
    496     except _core._FallbackException:
    497       pass

~\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py in raise_from_not_ok_status(e, name)
   6860   message = e.message + (&quot; name: &quot; + name if name is not None else &quot;&quot;)
   6861   # pylint: disable=protected-access
-&gt; 6862   six.raise_from(core._status_to_exception(e.code, message), None)
   6863   # pylint: enable=protected-access
   6864 

~\anaconda3\lib\site-packages\six.py in raise_from(value, from_value)
</code></pre>
<p>InvalidArgumentError: indices[1] = [0,40295] is out of order. Many sparse ops require sorted indices.
Use <code>tf.sparse.reorder</code> to create a correctly ordered copy.</p>
",2020-12-31 21:29:08,14920348,1,https://stackoverflow.com/questions/65525687,Documentation Replicability
65547615,How to create variables inside tf.function decorated method?,"<p>Cannot create a <code>tf.Variable</code> (while I should) in a <code>tf.function</code> decorated method:</p>
<pre><code>@tf.function
def some_func():
    x = tf.Variable([1, 2, 3])
</code></pre>
<p>I get:</p>
<pre><code>/usr/local/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:262 __call__  **
    return cls._variable_v2_call(*args, **kwargs)
/usr/local/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:244 _variable_v2_call
    return previous_getter(
/usr/local/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:67 getter
    return captured_getter(captured_previous, **kwargs)
/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:716 invalid_creator_scope
    raise ValueError(

ValueError: tf.function-decorated function tried to create variables on non-first call.
</code></pre>
<p>I think there is some workaround using:</p>
<pre><code>tf.config.experimental_run_functions_eagerly(True)
</code></pre>
<p>but I also think that it affects performance, which the whole point of <code>tf.function</code> in the first place.</p>
",2021-01-03 07:34:36,20280771,1,https://stackoverflow.com/questions/65547615,Documentation Replicability
65585095,Why tf.keras.optimizers.SGD has no global_step,"<p>In TF 1.14, below code will raise exception.</p>
<pre><code> optimizer = tf.keras.optimizers.SGD(learning_rate=params['lr'])
 train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())
</code></pre>
<p>The exception is</p>
<pre><code>TypeError: minimize() got an unexpected keyword argument 'global_step'
</code></pre>
<p>It seems that <code>tf.keras.optimizers</code> in unavailable in TF 1.14. However, why the <code>global_step</code> is gone in tf.keras.optimizers.SGD? It is supposed to be there in <code>tf.train.Optimizer</code> of TF 1.14</p>
",2021-01-05 19:08:24,5405823,963,https://stackoverflow.com/questions/65585095,Documentation Replicability
65596022,How to convert ragged tensor to list of tensors inside a graph,"<p>I have a ragged tensor with variable shape in the 2nd dimension N x ? x 4, I'd like to convert it to a list of tensors.</p>
<p>Down below is a function that works, but only when it's not decorated with tf.function. I need this function to run inside a tf graph.</p>
<pre><code>import tensorflow as tf

raggedTensor = tf.ragged.constant([[[0.7688891291618347, 0.3979208469390869, 0.9807137250900269, 0.5825483798980713], 
                                    [0.69159334897995, 0.48753976821899414, 0.7804230451583862, 0.5539296865463257]], 
                                   
                                   [[0.5818965435028076, 0.343869686126709, 0.8541288375854492, 0.6288187503814697], 
                                    [0.636405348777771, 0.6720571517944336, 0.7466434240341187, 0.7985518574714661]], 
                                   
                                   [[0.65436190366745, 0.47322067618370056, 0.9061073660850525, 0.6343377828598022]], 
                                   
                                   [[0.7395644187927246, 0.6922436356544495, 0.9913792610168457, 1.0], 
                                    [0.7860392928123474, 0.44102346897125244, 0.8941574096679688, 0.637432873249054]]])


def convertGT(x):
    out = []
    for i in range(x.nrows()):
        out.append(x[i].to_tensor())
        
    return out

#runs fine
convertGT(raggedTensor)

[&lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
 array([[0.7688891 , 0.39792085, 0.9807137 , 0.5825484 ],
        [0.69159335, 0.48753977, 0.78042305, 0.5539297 ]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
 array([[0.58189654, 0.3438697 , 0.85412884, 0.62881875],
        [0.63640535, 0.67205715, 0.7466434 , 0.79855186]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.6543619 , 0.47322068, 0.90610737, 0.6343378 ]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
 array([[0.7395644 , 0.69224364, 0.99137926, 1.        ],
        [0.7860393 , 0.44102347, 0.8941574 , 0.6374329 ]], dtype=float32)&gt;]


@tf.function
def convertGT(x):
    out = []
    for i in range(x.nrows()):
        out.append(x[i].to_tensor())
        
    return out

#this will throw the error
convertGT(raggedTensor)

InaccessibleTensorError: The tensor 'Tensor(&quot;while/RaggedToTensor/RaggedTensorToTensor:0&quot;, shape=(None, None), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_4893, id=140025401503696); accessed from: FuncGraph(name=convertGT, id=140025402568040).
</code></pre>
",2021-01-06 12:45:56,8161411,318,https://stackoverflow.com/questions/65596022,Documentation Replication on Other Examples
65634172,What's the difference between tf.math.reduce_mean and tf.keras.metrics.Mean?,"<p>I'm confused what function to use. They look the same and do the same work. I understand that tf.keras.metrics.Mean is metric, but can't I use it somewhere else?</p>
",2021-01-08 18:05:17,13781254,163,https://stackoverflow.com/questions/65634172,Documentation Ambiguity
65640885,CRNN tf.keras.backend.ctc_decode. What is log probability?,"<p>Based on <a href=""https://docs.w3cub.com/tensorflow%7Epython/tf/keras/backend/ctc_decode"" rel=""nofollow noreferrer"">the documentation</a>, the function <code>tf.keras.backend.ctc_decode</code> is supposed to return a <code>Tuple</code>. Its first field contains the best path (let's assume we use greedy search), whereas the second one contains its <code>log probability</code>.</p>
<p>Is this probability actually the accuracy of the prediction?</p>
<p>If not how am I supposed to calculate it?</p>
<p>I've tried on some test images and this was my output:</p>
<pre><code>True value: test0, prediction: test0, acc: 1.841524362564087
True value: test1, prediction: test1, acc: 0.9661365151405334
True value: test2, prediction: test2, acc: 1.0634151697158813
True value: test3, prediction: test3, acc: 2.471940755844116
True value: test4, prediction: test4, acc: 1.4866207838058472
True value: test5, prediction: test5, acc: 0.7630811333656311
True value: test6, prediction: test6, acc: 0.35642576217651367
True value: test7, prediction: test7, acc: 1.5693446397781372
True value: test8, prediction: test8, acc: 0.9700028896331787
True value: test9, prediction: test9, acc: 1.4783780574798584
</code></pre>
<p>During the training part, the final CTC loss was around 0.1 and the prediction is always correct. However what I think it's the probability seems not to be what I expect. They looks like completely random numbers, even grater than 1 or 2! What am I doing wrong?</p>
",2021-01-09 08:56:44,14967854,51,https://stackoverflow.com/questions/65640885,Documentation Replication on Other Examples
65696549,How to clean \xc2\xa0 using tf.strings.regex_replace?,"<p>I tried the the following but does not work:</p>
<pre><code>tf.strings.regex_replace(_string, &quot;\xc2\xa0&quot;, ' ')
</code></pre>
<p>or</p>
<pre><code>tf.strings.regex_replace(_string, &quot;\%xc2\%xa0&quot;, ' ')
</code></pre>
<p>But both don't work. the python string replace method should work but as part of tf.data.Dataset pipeline that can potentially part of a model layer, i will have to use tf.string.replace(...). I also could do the string processing outside of tf pipeline but it is not elegant/robust solution.</p>
",2021-01-13 06:10:14,1762295,3759,https://stackoverflow.com/questions/65696549,Documentation Replication on Other Examples
65754675,tf.sparse.reshape(tf.sparse.split()) : TypeError: Input must be a SparseTensor,"<p>I am trying to convert a dense matrix to sparse matrix calcualtion on tensorflow. There is an error when trying to <code>reshape</code> after using <code>tf.sparse.split(</code>. Following is a toy example to demonstrate the issue.</p>
<p><strong>Tensorflow dense matrix</strong></p>
<pre><code>import numpy as np
import tensorflow as tf
a = np.array([[1, 0, 2, 0,0,1], [3, 0, 0, 4,1,0]])

a_t = tf.constant(a)
a_t_rshp = tf.reshape(tf.split(a_t,2,axis = 1),[2,2,3])
</code></pre>
<p><strong>Tensorflow sparse matrix</strong></p>
<pre><code>a_t_st = tf.sparse.from_dense(a_t)
a_t_st_rshp = tf.sparse.reshape(tf.sparse.split(a_t_st,2,axis = 1),[2,2,3])

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-14-3dff37aef5b4&gt; in &lt;module&gt;
----&gt; 1 a_t_st_rshp = tf.sparse.reshape(tf.sparse.split(a_t_st,2,axis = 1),[2,2,3])

/Users/Mine/Python/tf2_4_env/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py in sparse_reshape(sp_input, shape, name)
    886     ValueError:  If `shape` has more than one inferred (== -1) dimension.
    887   &quot;&quot;&quot;
--&gt; 888   sp_input = _convert_to_sparse_tensor(sp_input)
    889   shape = math_ops.cast(shape, dtype=dtypes.int64)
    890 

/Users/Mine/Python/tf2_4_env/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py in _convert_to_sparse_tensor(sp_input)
     70     return sparse_tensor.SparseTensor.from_value(sp_input)
     71   if not isinstance(sp_input, sparse_tensor.SparseTensor):
---&gt; 72     raise TypeError(&quot;Input must be a SparseTensor.&quot;)
     73   return sp_input
     74 
</code></pre>
<p>can you please help me to overcome this issue?</p>
",2021-01-16 21:00:36,6830120,874,https://stackoverflow.com/questions/65754675,Documentation Replicability
65779087,How to use tf.gradients within a model and still use a custom training loop?,"<p>I would like to make a TensorFlow model where the outputs respect a mathematical condition, namely that output 0 is a scalar function and all subsequent outputs are its partial derivatives w.r.t. the input. This is because my observations are the scalar function and its partials, and not using the partials for training would be a waste of information.</p>
<p>For now, using simply tf.gradients works if I don't build a custom training loop, i.e. when I don't utilize eager execution. The model is built like this, and training works as expected:</p>
<pre><code>import tensorflow as tf


from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras import callbacks

# Creating a model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Dense,
    Dropout,
    Flatten,
    Concatenate,
    Input,
    Lambda,
)

# Custom activation function
from tensorflow.keras.layers import Activation
from tensorflow.keras import backend as K

import numpy
import matplotlib.pyplot as plt

import tensorboard

layer_width = 200
dense_layer_number = 3

def lambda_gradient(args):
    layer = args[0]
    inputs = args[1]
    return tf.gradients(layer, inputs)[0]

# Input is a 2 dimensional vector
inputs = tf.keras.Input(shape=(2,), name=&quot;coordinate_input&quot;)

# Build `dense_layer_number` times a dense layers of width `layer_width`
stream = inputs
for i in range(dense_layer_number):
    stream = Dense(
        layer_width, activation=&quot;relu&quot;, name=f&quot;dense_layer_{i}&quot;
    )(stream)

# Build one dense layer that reduces the 200 nodes to a scalar output
scalar = Dense(1, name=&quot;network_to_scalar&quot;, activation=custom_activation)(stream)

# Take the gradient of the scalar w.r.t. the model input
gradient = Lambda(lambda_gradient, name=&quot;gradient_layer&quot;)([scalar, inputs])

# Combine them to form the model output
concat = Concatenate(name=&quot;concat_scalar_gradient&quot;)([scalar, gradient])

# Wrap everything in a model
model = tf.keras.Model(inputs=inputs, outputs=concat)

loss = &quot;MSE&quot;
optimizer = &quot;Adam&quot;

# And compile
model.compile(loss=loss, optimizer=optimizer)
</code></pre>
<p>However, them problem now comes when I want to do online training (i.e. with an incremental dataset). In this case, I wouldn't compile my model at the very end. Instead, I write a loop as such (before calling model.compile):</p>
<pre><code># ... continue from previous minus model.compile

loss_fn = tf.keras.losses.MeanSquaredError()
optimizer = tf.keras.optimizers.Adam()

# Iterate over the batches of a dataset and train.
for i_batch in range(number_of_batches):

    with tf.GradientTape() as tape:
        # Predict w.r.t. the inputs X
        prediction_Y = model(batches_X[i_batch])
        
        # Compare batch prediction to batch observation
        loss_value = loss_fn(batches_Y[i_batch], prediction_Y)

    gradients = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(gradients, model.trainable_weights))
</code></pre>
<p>This however gives the following exception at <code>prediction_Y = model(batches_X[i_batch])</code>:</p>
<pre><code>RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
</code></pre>
<p>As most examples, tutorials and documentation solely deal with using gradients to do training, and not within the model, I can't find any good resources how to deal with this. I tried to find how to use gradient tape, but I can't figure out how to use it in the model design phase. Any pointers would be appreciated!</p>
<p>Versions used:</p>
<pre><code>$ python --version                                         
Python 3.8.5
$ python -c &quot;import tensorflow as tf;print(tf.__version__);print(tf.keras.__version__)&quot;
2.2.0
2.3.0-tf
</code></pre>
",2021-01-18 17:13:32,6848887,163,https://stackoverflow.com/questions/65779087,Inadequate Examples
65794527,"Example of output_signature , output_types & output_shapes for complex object called by tf.data.Dataset.from_generator","<p>I've a generator function that yields the following tuple: <code>yield (transformed_input_array, set_y)</code></p>
<p><em>transformed_input_array</em> is a list of ndarrays with the following shape: <em>(1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140)</em>  and the following types: <em>tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64</em>
<em>set_y</em> is a ndarray of shape <em>1024</em> and type of <em>int64</em></p>
<p>I've wrapped my generator with tf.data.Dataset.from_generator function, here is the code:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
    generator,
    # output_signature=(
    #     tf.TensorSpec(shape=(), dtype=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64)),
    #     tf.TensorSpec(shape=1024, dtype=tf.int64))
    output_types=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64, tf.int64),
    output_shapes=((1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140), 1024)
)
</code></pre>
<p>But when I run the training, I get the following error:</p>
<blockquote>
<p>ValueError: Data is expected to be in format <code>x</code>, <code>(x,)</code>, <code>(x, y)</code>,
or <code>(x, y, sample_weight)</code>, found: (&lt;tf.Tensor 'IteratorGetNext:0'
shape=(1024, 104) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:1'
shape=(1024, 142) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:2'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'It eratorGetNext:3'
shape=(1024, 1) dtype=int16&gt;, &lt;tf.Tensor 'IteratorGetNext:4'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:5'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:6'
shape=(1024, 140) dtype=float64&gt;, &lt;tf.Tensor 'ExpandDims:0'
shape=(1024, 1) dtype=int64&gt;)</p>
</blockquote>
<p>If I try to run with output_signature param (commented out code), I get the following error:</p>
<blockquote>
<p>TypeError: Cannot convert value (tf.float64, tf.float64, tf.int8,
tf.int16, tf.int8, tf.int8, tf.float64) to a TensorFlow DType.</p>
</blockquote>
<p><strong>Can someone provide an example, of how I should treat complex type (list of ndarrays)?</strong> Couldn't find any example in TF documentation..</p>
",2021-01-19 15:29:20,336558,700,https://stackoverflow.com/questions/65794527,Inadequate Examples
65835387,ValueError: too many values to unpack (expected 2) when using tf.keras.preprocessing.image_dataset_from_directory,"<p>I want to create a dataset-variable as well as a labels-variable using the function tf.keras.preprocessing.image_dataset_from_directory (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory</a>).
The documentation states:</p>
<blockquote>
<p>Returns:
A tf.data.Dataset object.
If label_mode is None, it yields
float32 tensors of shape (batch_size, image_size[0], image_size[1],
num_channels), encoding images (see below for rules regarding
num_channels).
Otherwise, it yields a tuple (images, labels), where
images has shape (batch_size, image_size[0], image_size[1],
num_channels), and labels follows the format described below.</p>
</blockquote>
<p>My code is the following:</p>
<pre><code>train_ds, labels = tf.keras.preprocessing.image_dataset_from_directory(
  directory = data_dir,
  labels='inferred',
  label_mode = &quot;int&quot;,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
</code></pre>
<p>I expect to get a tuple as return values, but instead I get the error message:</p>
<pre><code>Found 2160 files belonging to 2160 classes.
Using 1728 files for training.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-168-ed9d42ed2ab9&gt; in &lt;module&gt;
      7   seed=123,
      8   image_size=(img_height, img_width),
----&gt; 9   batch_size=batch_size)

ValueError: too many values to unpack (expected 2)
</code></pre>
<p>When I save the output in one variable (just train_ds) and I inspect the variable, I get the following output:</p>
<pre><code>&lt;BatchDataset shapes: ((None, 120, 30, 3), (None,)), types: (tf.float32, tf.int32)&gt;
</code></pre>
<p>How can I access the two tuples inside seperatly?</p>
",2021-01-21 20:39:17,12336925,156,https://stackoverflow.com/questions/65835387,Documentation Ambiguity
65863738,Changing order of Input Image in 3D convolutions,"<p>According to the official documentation of tf.keras.layers.Conv3D</p>
<blockquote>
<p>5+D tensor with shape: batch_shape + (channels, conv_dim1, conv_dim2,
conv_dim3) if data_format='channels_first' or 5+D tensor with shape:
batch_shape + (conv_dim1, conv_dim2, conv_dim3, channels) if
data_format='channels_last'</p>
</blockquote>
<p>. Now the whole idea around channels and batch shape makes sense, but will changing the general order of (conv_dim1, conv_dim2,conv_dim2) as (x,y,z) to say (z,x,y) affect the performance.</p>
<p>Does Conv3D worry about order of x-y-z dimension ?</p>
<p>I was training a U-net segmentation model and upon changing the order of axis I saw difference in performance. (x,y,z) order converges faster as compared to (y,x,z).</p>
<p>I just wanted to make sure what's the correct way..</p>
",2021-01-23 19:54:08,5066344,79,https://stackoverflow.com/questions/65863738,Documentation Ambiguity
65953591,Which format should have time series input for LSTM-Model in Tensorflow?,"<p>I have a problem with the input for the fit-function of an LSTM-Model in TensorFlow. I have an input with the following shape:<br />
(5, 128, 78, 80)<br />
The fields are: (number of samples, timesteps, feature1, feature2)</p>
<p>The output has the shape: (5, 128, 78, 2)</p>
<p>This is my model:</p>
<pre><code>from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation

batch_size=5

time_model = tf.keras.Sequential()
time_model.add(tf.keras.layers.LSTM(512,return_sequences=True,input_shape=(128,2)))
time_model.add(Activation('sigmoid'))
time_model.add(Dense(2,name=&quot;dense&quot;))
time_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')


time_model.fit(x=time_input,y=time_output, epochs=10, batch_size=batch_size)
</code></pre>
<p>I get the following error:<br />
<code>ValueError: Input 0 of layer sequential_38 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (5, 128, 78, 80)</code></p>
<p>So I think, I have to change the shape of my data, but I don't know how. I tried already different values for input and  input_shape-attribute.<br />
I read in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM</a> that the input has to be a tensor with shape <code>[batch, timesteps, feature]</code>. So I put the two features in a nested array, and gave <code>[batch, timesteps, array of the features]</code> to the fit-function. But it told me that the data could not be converted to a tensor. Also explicit converting with <code>tf.convert_to_tensor</code> did not work.</p>
<p>I would be really glad, if someone could explain me, how I can pass input data with two features to an LSTM-model.</p>
",2021-01-29 11:27:07,11535546,36,https://stackoverflow.com/questions/65953591,Documentation Ambiguity
66019998,"How to get a processed dataset, if the processing steps are not tensor operations?","<p>I have an instance of <code>tf.data.Dataset()</code>, of images, basically, acquired this way:</p>
<pre><code>import tensorflow as tf

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_directory,
    image_size = (image_height, image_width),
    batch_size = batch_size
)
</code></pre>
<p>So, this dataset has <code>(data, label)</code> where the data is a tensor of shape <code>(batch_size, image_height, image_width, channels)</code> [I don't really need the labels it assigns]. So far so good. The problem is, I need to process this dataset, applying certain operations to the images, and, this dataset is too big to load everything in memory (that's why <code>batch_size</code> is there). According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">tensorflow documentation</a>, <code>tf.data.Dataset.map()</code> is the function I need (or so I assume....).</p>
<pre><code>def image_processing(data):
    print(data.shape)
    
    # Do some operations.
    # Do some copies [because np.arrays help me more...].
    copy = np.array(data, copy=True)

    # Change some pixels, like, zero out a square in this image
    # It sad that TensorFlow can't do this assignment if it were a tf.Tensor:
    copy[10:80,10:80] = np.array([0,0,0])

    # Do more things, and when done return.
    return something


processed_dataset = dataset.map(lambda image, label: (image_processing(image), label))
</code></pre>
<p>First of all, the shape returned by the print: <code>(None, 200, 200, 3)</code> instead of <code>(32, 200, 200, 3)</code>, or, instead of <code>(200, 200, 3)</code> [which is what I'd expect from reading the documentation] [let's assume batch of 32, and images 200x200], and this is messing my code, because, I need to do assigments, like, take the ith image, and change a couple pixels: <code>data[i][12:15,40:50] = np.array([1,2,3])</code> and things like that.</p>
<p>Basically, that's the error message: <code>TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'</code>.</p>
<hr />
<p><strong>In summary, my question:</strong> How can I get a <code>processed_dataset</code>, where the processing steps will not be whole tensor operations, but instead, will be changing individual values in the data (say, individual pixels), for certain images (say, the ith image, jth image, etc)?</p>
<hr />
<p>If you must know, I am running this in Ubuntu. Tensorflow version is:</p>
<pre><code>&gt;&gt;&gt; tf.__version__
'2.4.0'
</code></pre>
",2021-02-03 01:28:57,15049194,33,https://stackoverflow.com/questions/66019998,Documentation Replication on Other Examples
66030439,TensorFlow profiler using tf.profiler.experimental.client.trace gives empty trace data,"<p>I'm unable to collect trace data using <code>tf.profiler.experimental.client.trace</code> Please can someone help? I'm following the (CPU/GPU) example usage here <a href=""https://www.tensorflow.org/api_docs/python/tf/profiler/experimental/client/trace"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/profiler/experimental/client/trace</a> which looks simple enough.</p>
<p>I have a very simple model, and I'm able to collect trace data from it using <code>tf.profiler.experimental.start</code> and <code>tf.profiler.experimental.stop</code>.</p>
<p>But <code>tf.profiler.experimental.client.trace</code> gives me empty trace data.</p>
<p>My code is as follows:</p>
<pre><code>import tensorflow as tf
import numpy as np
                                                                                                    
def mnist_dataset(batch_size):
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()                                              
    x_train = x_train / np.float32(255)
    y_train = y_train.astype(np.int64)
    train_dataset = tf.data.Dataset.from_tensor_slices(
        (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)
    return train_dataset

batch_size = 64
dataset = mnist_dataset(batch_size)

model = tf.keras.Sequential([
    tf.keras.Input(shape=(28, 28)),
    tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
    metrics=['accuracy'])
                                                                                           
#tf.profiler.experimental.start('./logs/tb_log')                                                                        
tf.profiler.experimental.server.start(6009)

model.fit(dataset, epochs=10, steps_per_epoch=70)

tf.profiler.experimental.client.trace('grpc://localhost:6009', './logs/tbc_log', 20000)
#tf.profiler.experimental.stop()         
</code></pre>
<p>The code runs through the epochs, and then outputs</p>
<pre><code>2021-02-02 17:49:44.943933: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288184943887718 [2021-02-02T17:49:44.943887718+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 2
2021-02-02 17:49:44.944037: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:49:44.944197: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:49:44.944316: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:49:44.944340: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:49:44.946274: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:49:44.947547: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:49:44.946338176+00:00) for the scheduled start (2021-02-02T17:49:44.943887718+00:00) and will start immediately.
2021-02-02 17:49:44.947582: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:49:44.947660: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 2 GPUs
2021-02-02 17:49:44.949656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.11.0
2021-02-02 17:50:08.435260: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-02-02 17:50:08.435591: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-02-02 17:50:08.635192: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. 
2021-02-02 17:50:08.648616: I tensorflow/core/profiler/rpc/profiler_service_impl.cc:67] Collecting XSpace to repository: ./logs/tbc_log/plugins/profile/2021_02_02_17_49_44/localhost_6009.xplane.pb
2021-02-02 17:50:08.650309: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-02-02 17:50:08.650676: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
No trace event is collected. Automatically retrying.

2021-02-02 17:50:08.651046: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288208651017638 [2021-02-02T17:50:08.651017638+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 1
2021-02-02 17:50:08.651123: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:50:08.651274: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:50:08.651391: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:50:08.651420: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:50:08.652492: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:50:08.652570: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:50:08.652539729+00:00) for the scheduled start (2021-02-02T17:50:08.651017638+00:00) and will start immediately.
2021-02-02 17:50:08.652591: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:50:31.280828: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-02-02 17:50:31.281134: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-02-02 17:50:31.510697: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. 
2021-02-02 17:50:31.515475: I tensorflow/core/profiler/rpc/profiler_service_impl.cc:67] Collecting XSpace to repository: ./logs/tbc_log/plugins/profile/2021_02_02_17_49_44/localhost_6009.xplane.pb
2021-02-02 17:50:31.518037: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-02-02 17:50:31.518440: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
No trace event is collected. Automatically retrying.

2021-02-02 17:50:31.518819: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288231518793164 [2021-02-02T17:50:31.518793164+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 0
2021-02-02 17:50:31.518889: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:50:31.519021: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:50:31.519124: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:50:31.519147: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:50:31.520067: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:50:31.520136: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:50:31.520095781+00:00) for the scheduled start (2021-02-02T17:50:31.518793164+00:00) and will start immediately.
2021-02-02 17:50:31.520152: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:50:44.891412: W tensorflow/core/profiler/rpc/client/profiler_client.cc:152] Deadline exceeded: Deadline Exceeded
2021-02-02 17:50:44.891501: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
2021-02-02 17:50:44.891526: W tensorflow/core/profiler/rpc/client/capture_profile.cc:145] localhost:6009 returned Deadline exceeded: Deadline Exceeded
No trace event is collected after 3 attempt(s). Perhaps, you want to try again (with more attempts?).
Tip: increase number of attempts with --num_tracing_attempts.
2021-02-02 17:50:44.891848: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
Traceback (most recent call last):
  File &quot;keras_singleworker_2.py&quot;, line 37, in &lt;module&gt;
2021-02-02 17:50:44.893228: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
    tf.profiler.experimental.client.trace('grpc://localhost:6009', './logs/tbc_log', 20000)
  File &quot;/fserver/jonathanb/miniconda3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/profiler/profiler_client.py&quot;, line 131, in trace
    _pywrap_profiler.trace(
tensorflow.python.framework.errors_impl.UnavailableError: No trace event was collected because there were no responses from clients or the responses did not have trace data.
</code></pre>
<p>I've tried locating tf.profiler.experimental.server.start and tf.profiler.experimental.client.trace in other locations in the code, but with no success.</p>
",2021-02-03 15:19:57,15131641,71,https://stackoverflow.com/questions/66030439,Documentation Ambiguity
66038861,Why are both branches in tf.cond being executed? And why does tf.while_loop finish the loop even though the condition still true?,"<p>I am using keras for a while now, but usually I don't have to use customized layers or perform some more complex flow control, so I'm struggling trying to understand somethings.</p>
<p>I am modeling a neural network with a customized layer on the top. This customized layer calls another function (<code>search_sigma</code>)  and inside this function I execute <code>tf.while_loop</code> and inside of <code>tf.while_loop</code> I execute <code>tf.cond</code>.</p>
<p>I cannot understand why the conditions are not working.</p>
<ul>
<li><code>tf.while_loop</code> stops even though the condition (<code>l1</code>) still true</li>
<li><code>tf.cond executes</code> both <code>f1</code> and <code>f2</code> (callables <code>true_fn</code> and <code>false_fn</code>)</li>
</ul>
<p>Could someone help me understand what I am missing?</p>
<p>I already tried to change both tf.cond and tf.while_loop conditions for true tensors, just to see what would happen. The behavior (exactly same errors) remained the same.</p>
<p>I also tried to write this code without implementing a class (using just functions). Nothing changed.</p>
<p>I tried to find solutions looking at tensorflow documentation, other stack overflow doubts and websites talking about tf.while_loop and tf.cond.</p>
<p>I left some <code>print()</code>s in the body of the code to try to track what was happening.</p>
<pre><code>class find_sigma:
    
    def __init__ (self, t_inputs,  inputs,  expected_perp=10. ):       
        self.sigma, self.cluster = t_inputs
        self.inputs = inputs
        self.expected_perp = expected_perp
        self.min_sigma=tf.constant([0.01],tf.float32)
        self.max_sigma=tf.constant([50.],tf.float32)
 

    def search_sigma(self):

        
        def cond(s,sigma_not_found): return sigma_not_found


        def body(s,sigma_not_found):   

            print('loop')
            pi = K.exp( - K.sum( (K.expand_dims(self.inputs, axis=1) - self.cluster)**2, axis=2  )/(2*s**2) )        
            pi = pi / K.sum(pi)
            MACHINE_EPSILON = np.finfo(np.double).eps
            pi = K.maximum(pi, MACHINE_EPSILON)
            H = - K.sum ( pi*(K.log(pi)/K.log(2.)) , axis=0 )
            perp = 2**H

            print('0')

            l1 = tf.logical_and (tf.less(perp , self.expected_perp), tf.less(0.01, self.max_sigma-s))
            l2 = tf.logical_and (tf.less(  self.expected_perp , perp) , tf.less(0.01, s-self.min_sigma) )
    
            def f1():
                print('f1')
                self.min_sigma = s 
                s2 = (s+self.max_sigma)/2 
                return  [s2, tf.constant([True])]
                

            def f2(l2): 
                tf.cond( l2, true_fn=f3 , false_fn = f4)

            def f3(): 
                print('f3')
                self.max_sigma = s 
                s2 = (s+self.min_sigma)/2
                return [s2, tf.constant([True])]

            def f4(): 
                print('f4')
                return [s, tf.constant([False])]
            
            output = tf.cond( l1, f1 ,  f4 ) #colocar f2 no lugar de f4

            s, sigma_not_found = output
            
            print('sigma_not_found = ',sigma_not_found)
            return [s,sigma_not_found]

        print('01')

        sigma_not_found = tf.constant([True])

        new_sigma,sigma_not_found=sigma_not_found = tf.while_loop(
            cond , body, loop_vars=[self.sigma,sigma_not_found]
        )

        print('saiu')
        
        print(new_sigma)

        return new_sigma
</code></pre>
<p>The piece of code that calls the above code is:</p>
<pre><code>self.sigma = tf.map_fn(fn=lambda t: find_sigma(t,  inputs).search_sigma() , elems=(self.sigma,self.clusters), dtype=tf.float32)
</code></pre>
<p>'inputs' is a <code>(None, 10)</code> size tensor</p>
<p>'self.sigma' is a <code>(10,)</code> size tensor</p>
<p>'self.clusters' is a <code>(N, 10)</code> size tensor</p>
",2021-02-04 03:12:10,15141021,1,https://stackoverflow.com/questions/66038861,Inadequate Examples
66049816,Custom layer in sequential model tensorflow,"<p>I'm trying to create a custom layer for my model, which can be used the classic Dense layer of Keras. Here my custom layer:</p>
<pre><code>class MyDenseLayer(tf.keras.layers.Layer):
    def __init__(self, num_outputs):
        super(MyDenseLayer, self).__init__()
        self.num_outputs = num_outputs
    def build(self, input_shape):
        self.kernel = self.add_weight(&quot;kernel&quot;, 
                                      shape=[int(input_shape[-1]),
                                      self.num_outputs])
    def call(self, input):
        return tf.matmul(input, self.kernel)
</code></pre>
<p>It does not do anything 'custom' for now.</p>
<p>But when I add it to my model</p>
<pre><code>def build_model():
    model = keras.Sequential([
        MyDenseLayer(10)(normed_x_train),
        layers.Activation(tf.nn.relu),
        layers.Dense(1, activation=tf.nn.relu)
        ])
    return model
</code></pre>
<p>I get this:</p>
<pre><code>The added layer must be an instance of class Layer. Found: tf.Tensor(
[....])
</code></pre>
<p>Because probably I'm creating directly the object of class Custom Layer. But I do not find in the tf documentation how to add other properties to make it work as a normal layer, i.e. as something like <code>layers.Dense(100, activation=tf.nn.relu)</code></p>
<p>Is there a way to make it work like that ?</p>
",2021-02-04 16:31:55,12338521,181,https://stackoverflow.com/questions/66049816,Lack of Alternative Solutions/Documentation
66052849,Storing pickle object in Google Cloud Storage using Tensorflow.io.gfile,"<p>I am trying to store a pickle object in a Google Cloud Storage bucket. This is a part of a machine learning pipeline [tutorial][1] provided by Google that I am following. I broke down the code to a minimal example that still throws the same error. In my actual code, the object is a class instance.</p>
<pre><code>import tensorflow as tf
import dill as pickle
obj = {'foo': 'bar'}
with tf.io.gfile.GFile(filename, 'wb') as f:
    pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)
</code></pre>
<p>When I run this, I get</p>
<blockquote>
<p>TypeError: Expected binary or unicode string, got &lt;memory at 0x7fdc66d7d7c0&gt;</p>
</blockquote>
<p>On the tutorial this step worked fine as it used Tensorflow 1 and tf.io.gfile.Open(), which was removed in Tensorflow 2 and replaced by the command above. Simply using open() also works, but of course that doesn't help me writing to a bucket. I also tried</p>
<pre><code>with tf.io.gfile.GFile(filename, 'wb') as f:
   f.write(obj)
</code></pre>
<p>but it returns the same error. Please let me know know what I am doing wrong or if there is an alternative approach to store a pickled object directly to a bucket? Many thanks for your help!
[1]: <a href=""https://cloud.google.com/dataflow/docs/samples/molecules-walkthrough#overview"" rel=""nofollow noreferrer"">https://cloud.google.com/dataflow/docs/samples/molecules-walkthrough#overview</a></p>
",2021-02-04 19:51:08,13127573,35,https://stackoverflow.com/questions/66052849,Documentation Replication on Other Examples
66062973,TensorFlow custom loss function error: No gradients provided for any variable,"<p>I am creating a custom loss function using <em>tf.raw_ops</em> namespace to train my model using keras. Here is my loss function:</p>
<p><strong>Loss(pred,label)= { 0.0 if pred−label&lt;=0.1, 1.0 elsewhere</strong></p>
<pre><code>comparing_tensor = tf.convert_to_tensor([0.1, 0.1, 0.1])
def custom_loss(y_pred, y_true):
    loss_tensor = tf.raw_ops.Abs(x=y_pred - y_true) # get the abs diff between y_true and y_pred
    boolean_tensor = tf.raw_ops.Greater(x=loss_tensor, y=comparing_tensor) # get a boolean tensor based on Greater operation. Example: [True, False, True] 
    binary_tensor = tf.raw_ops.Cast(x=boolean_tensor, DstT=tf.float32) # convert boolean to bianry tensor Example: [1.0, 0.0, 1.0]
    mean_tensor= tf.raw_ops.Mean(input=binary_tensor, axis=-1) # get mean of binary tensor, 2/3=0.66 
    loss = tf.raw_ops.Reshape(tensor=mean_tensor, shape=(1,1), name=None) # reshape mean tensor to get desired shape
    return loss
</code></pre>
<p>And then I am using this in my</p>
<pre><code>Keras.model.compile(opt=SDG, loss=custom_loss, metrics=['mse])
</code></pre>
<p>I am getting an error</p>
<blockquote>
<p>ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'dense/kernel:0', 'dense/bias:0', 'x/kernel:0', 'x/bias:0'].**</p>
</blockquote>
<p>I know this may be because some of the <code>tf.operations</code> that I am using are not differentiable, or doesn't have a gradient. However, I have checked this page <strong><a href=""https://docs.w3cub.com/tensorflow%7E2.3/raw_ops"" rel=""nofollow noreferrer"">https://docs.w3cub.com/tensorflow~2.3/raw_ops</a></strong> It shows which operations are differentiable and which are not. All of my operations are differentiable. I am not sure what am I missing. Any help is appreciated.</p>
",2021-02-05 12:04:21,14408155,11,https://stackoverflow.com/questions/66062973,Documentation Ambiguity
66084126,how to convert grayscale image to rgb RGB image?,"<p>I'm trying to convert a grayscale image to rgb image,does tensorflow.js have an function like tf.image.grayscale_to_rgb in tensorflow to do this?</p>
",2021-02-07 02:50:53,15136301,1,https://stackoverflow.com/questions/66084126,Inadequate Examples
66146394,How do I retrieve the one-hot-encoded feature names in tensorflow.keras preprocessing layers,"<p>What is the tf.keras equivalent of encoder.get_feature_names found in sklearn? <a href=""https://stackoverflow.com/questions/54570947/feature-names-from-onehotencoder"">As shown shown in this SO question</a>
Need this to get all the one-hot encoded feature names created &quot;from tensorflow.keras.layers.experimental import preprocessing&quot;. I will appreciate any post with example.</p>
",2021-02-10 23:00:49,8855052,79,https://stackoverflow.com/questions/66146394,Inadequate Examples
66287320,Tensorflow 2.0: flat_map() to flatten Dataset of Dataset returns cardinality -2,"<p>I am trying to run the following code (as given in Tensorflow documentation) to create windows of my data and then flatten the dataset of datasets.</p>
<pre><code>window_size = 5

windows = range_ds.window(window_size, shift=1)
for sub_ds in windows.take(5):
    print(sub_ds)

flat_windows = windows.flat_map(lambda x: x)
</code></pre>
<p>The problem is that <code>flat_windows.cardinality().numpy()</code> returns cardinality to be -2 which is creating problem for me during training. I tried looking for ways to set_cardinality of a dataset but couldn't find anything. I also tried other ways of flattening a dataset of datasets, but again no success.</p>
<p><strong>Edit-1:</strong> The problem with the training is that the shape is unknown (at Linear and Dense layers) when I am training a subclass model (given below). The model trains well when I train the model eagerly (through <code>tf.config.run_functions_eagerly(True)</code>) but that is slow. Therefore I want the input data to be known for the model training.</p>
<h1>Neural Network</h1>
<pre><code>class NeuralNetworkModel(tf.keras.Model): 
    def __init__(self):
        super(NeuralNetworkModel, self).__init__()
        self.encoder = Encoder()        
    
    def train_step(self, inputs):       
        X        = inputs[0]
        Y        = inputs[1] 
        
        with tf.GradientTape() as tape:
            enc_X    = self.encoder(X)
            enc_Y    = self.encoder(Y)    

            # loss:        
            loss   = tf.norm(enc_Y - enc_X, axis = [0, 1], ord = 'fro')
                
        # Compute gradients
        trainable_vars = self.encoder.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)

        # Update weights
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        # Compute our own metrics
        loss_tracker.update_state(loss)
        
        # Return a dict mapping metric names to current value.
        # Note that it will include the loss (tracked in self.metrics).
        return {&quot;loss&quot;: loss_tracker.result()}
        
    @property
    def metrics(self):
        # We list our `Metric` objects here so that `reset_states()` can be
        # called automatically at the start of each epoch
        # or at the start of `evaluate()`.
        # If you don't implement this property, you have to call
        # `reset_states()` yourself at the time of your choosing.
        return [loss_tracker]
    
    def test_step(self, inputs):       
        X = inputs[0]
        Y = inputs[1] 

        Psi_X    = self.encoder(X)
        Psi_Y    = self.encoder(Y)    

        # loss:        
        loss   = tf.norm(Psi_Y - Psi_X, axis = [0, 1], ord = 'fro')

        # Compute our own metrics
        loss_tracker.update_state(loss)
        
        # Return a dict mapping metric names to current value.
        # Note that it will include the loss (tracked in self.metrics).
        return {&quot;loss&quot;: loss_tracker.result()}
        
class Encoder(tf.keras.Model):
    def __init__(self):
        super(Encoder, self).__init__(dtype = 'float64', name = 'Encoder')
        self.input_layer   = DenseLayer(128)
        self.hidden_layer1 = DenseLayer(128)
        self.hidden_layer2 = DenseLayer(64)        
        self.hidden_layer3 = DenseLayer(64)
        self.output_layer  = LinearLayer(64)
        
    def call(self, input_data, training):
        fx = self.input_layer(input_data)        
        fx = self.hidden_layer1(fx)
        fx = self.hidden_layer2(fx)
        fx = self.hidden_layer3(fx)
        return self.output_layer(fx)    

class LinearLayer(tf.keras.layers.Layer):
    def __init__(self, units):
        super(LinearLayer, self).__init__(dtype = 'float64')
        self.units = units

    def build(self, input_shape):
        input_dim = input_shape[-1]
        self.w = self.add_weight(shape = (input_dim, self.units), 
                             initializer = &quot;random_normal&quot;, 
                             trainable = True)
        self.b = self.add_weight(shape = (self.units,),    
                             initializer = tf.zeros_initializer(),
                             trainable = True)

    def call(self, inputs):
        return tf.matmul(inputs, self.w) + self.b

class DenseLayer(tf.keras.layers.Layer):
    def __init__(self, units):
        super(DenseLayer, self).__init__(dtype = 'float64')
        self.units = units
    
    def build(self, input_shape):
        input_dim = input_shape[-1]
        self.w = self.add_weight(shape = (input_dim, self.units), 
                             initializer = &quot;random_normal&quot;, 
                             trainable = True)
        self.b = self.add_weight(shape = (self.units,),    
                             initializer = tf.zeros_initializer(),
                             trainable = True)

    def call(self, inputs):
        x = tf.matmul(inputs, self.w) + self.b
        return tf.nn.elu(x)
</code></pre>
",2021-02-20 02:10:07,1434693,499,https://stackoverflow.com/questions/66287320,Documentation Replication on Other Examples
66367312,Possible to use tf.distribute.Strategy.mirroredstrategy on parts of the graph rather than entire train_step for GAN custom training script?,"<p>I'm writing CTGAN code and want it to train in a distributed way.
Therefore I'm using <a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy"" rel=""nofollow noreferrer"">tf.distribute.Strategy.mirroredstrategy()</a>
In the <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">tensorflow docs tutorial</a> I'm following, it is mentioned that you should call your train_step code from a function called distribute_trainstep(), and decorate that with a tf.function. like so:</p>
<pre><code>@tf.function
def distributed_train_step(dataset_inputs):
  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))
  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                         axis=None)
</code></pre>
<p>This is straightforward, but decorating all within train_step in a tf.function renders all numpy code within the train_step useless. What should I do? Is there an alternative, by only wrapping functions within train_step selectively? Or will I have to replace all numpy operations with tensorflow's?</p>
",2021-02-25 11:07:25,7528024,542,https://stackoverflow.com/questions/66367312,Documentation Replicability
66385626,How does TensorFlow SavedModel handle additional dependencies,"<p>I am trying to export my TF model using the <code>tf.saved_model.save()</code> function. However, I'm using additional external libraries during preprocessing. A working code using the example of nltk looks like this:</p>
<pre><code>import tensorflow as tf
import nltk
import tensorflow_datasets as tfds
from tensorflow.python.ops import gen_string_ops
from tensorflow.python.ops import string_ops

train_data, val_data, test_data = train_data, validation_data, test_data = tfds.load(
    name=&quot;imdb_reviews&quot;, 
    split=('train[:60%]', 'train[60%:]', 'test'),
    as_supervised=True)


def remove_stops(text):
    nltk.download('stopwords')
    stop_words = nltk.corpus.stopwords.words('english')
    for w in stop_words:
        text = string_ops.regex_replace(text, '\\b{}\\b'.format(w),'')  # remove all stopwords
    text = tf.strings.strip(text)  # remove trailing whitespaces
    return text

vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization( # this gives me a BOW representation of my data...
    max_tokens=1000,
    standardize=remove_stops,  # ...using my method to remove stopwords
    output_mode='count') 

train_feats = list(map(lambda x: x[0], train_data)) # bc PrefetchDatasets don't allow direct access
vectorize_layer.adapt(train_feats)  # BOW needs to be trained beforehand to get vector reps

# define some simple network
input_layer = tf.keras.Input(shape=(), name='input_text', dtype=tf.string)
model = tf.keras.Sequential()
model.add(input_layer)
model.add(vectorize_layer)
model.add(tf.keras.layers.Dense(units=64, activation='softmax')) 
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))
model.compile(optimizer='adam',loss='binary_crossentropy', metrics = ['binary_accuracy'])
model.fit(train_data.shuffle(10000).batch(512),
             epochs=2,
             validation_data=val_data.batch(512))

tf.saved_model.save(model, './save_here')
</code></pre>
<p>As far as I've understood the <a href=""https://www.tensorflow.org/guide/saved_model"" rel=""nofollow noreferrer"">docs</a>, a savedModel includes the trained parameters and computations, but NOT my code. But when I load the same model in another script like so (i.e. without importing my external library at all)</p>
<pre><code>import tensorflow as tf
loaded_model = tf.saved_model.load('./save_here')
loaded_model(tf.constant(['test me pls']))
</code></pre>
<p>I get my output without any errors</p>
<pre><code>&lt;tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5086063]], dtype=float32)&gt;
</code></pre>
<p>This is especially baffling to me as I am even using nltk to download a dataset of stopwords. How exactly do SavedModels deal with these external libraries during exportation?</p>
",2021-02-26 12:12:04,8921867,1864,https://stackoverflow.com/questions/66385626,Documentation Replicability
66467746,How to use sklearn.preprocessing in tf.data.Dataset.map?,"<p>I would like to find a way to use <code>sklearn.preprocessing</code> inside <code>tf.data.Dataset.map()</code> in TF2.</p>
<p>Let's say I have a dataset generated from</p>
<pre><code>import tensorflow as tf
ds = tf.data.Dataset.from_tensor_slices((tf.random.uniform((3, 3))))
ds = ds.batch(1)
x = tf.concat(list(ds.as_numpy_iterator()), axis=0)
print(x)
# tf.Tensor(
# [[0.51869464 0.9198195  0.87195873]
#  [0.5842893  0.5363847  0.93642473]
#  [0.0109899  0.7908174  0.25996208]], shape=(3, 3), dtype=float32)
</code></pre>
<p>Then calculate the QuantileTransformer</p>
<pre><code>from sklearn.preprocessing import QuantileTransformer
qt = QuantileTransformer(n_quantiles=2, random_state=0)
qt.fit_transform(x)
print(qt.quantiles_)
# [[0.0109899  0.5363847  0.25996208]
#  [0.58428931 0.91981947 0.93642473]]
</code></pre>
<p>However, I was not able to use <code>QuantileTransformer</code> in <code>tf.data.Dataset.map</code>. For example,</p>
<pre><code>ds.map(lambda x: qt.transform(x))
</code></pre>
<p>gives error</p>
<pre><code>TypeError: in user code:

    &lt;ipython-input-106-867a262b9b69&gt;:13 None  *
        lambda x: qt.transform(x)
    /lib/python3.8/site-packages/sklearn/preprocessing/_data.py:2769 transform  *
        X = self._check_inputs(X, in_fit=False, copy=self.copy)
    /lib/python3.8/site-packages/sklearn/preprocessing/_data.py:2699 _check_inputs  *
        X = self._validate_data(X, reset=in_fit,
    /lib/python3.8/site-packages/sklearn/base.py:420 _validate_data  *
        X = check_array(X, **check_params)
    /lib/python3.8/site-packages/sklearn/utils/validation.py:981 inner_f  *
        return f(*args, **kwargs)
    /lib/python3.8/site-packages/sklearn/utils/validation.py:616 check_array  *
        array = np.asarray(array, order=order, dtype=dtype)
    /lib/python3.8/site-packages/numpy/core/_asarray.py:83 asarray  **
        return array(a, dtype, copy=False, order=order)

    TypeError: __array__() takes 1 positional argument but 2 were given```
</code></pre>
",2021-03-04 02:31:04,5310949,358,https://stackoverflow.com/questions/66467746,Documentation Replicability
66514664,Convert tf.Tensor to numpy array and than save it as image in without eager_execution,"<p>My OC is big sur for apple M1, therefore my tensorflow version is 2.4 which has been installed from official apple github repo(<a href=""https://github.com/apple/tensorflow_macos"" rel=""nofollow noreferrer"">https://github.com/apple/tensorflow_macos</a>). When i use code bellow, i get tensor(&lt;tf.Tensor 'StatefulPartitionedCall:0' shape=(1, 2880, 4320, 3) dtype=float32&gt;)</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import tensorflow_hub as hub
from PIL import Image
import numpy as np

from tensorflow.python.compiler.mlcompute import mlcompute
from tensorflow.python.framework.ops import disable_eager_execution
disable_eager_execution()
mlcompute.set_mlc_device(device_name='gpu') # Available options are 'cpu', 'gpu', and 'any'.
tf.config.run_functions_eagerly(False)
print(tf.executing_eagerly())

image = np.asarray(Image.open('/Users/alex26/Downloads/face.jpg'))
image = tf.cast(image, tf.float32)
image = tf.expand_dims(image, 0)

model = hub.load(&quot;https://tfhub.dev/captain-pool/esrgan-tf2/1&quot;)
sr = model(image) #&lt;tf.Tensor 'StatefulPartitionedCall:0' shape=(1, 2880, 4320, 3)dtype=float32&gt;
</code></pre>
<p><strong>How to get image from sr Tensor?</strong></p>
",2021-03-07 08:44:44,14426701,81,https://stackoverflow.com/questions/66514664,Documentation Replication on Other Examples
66546321,Proper way to input a scalar into a Tensorflow 2 model,"<p>In my Tensorflow 2 model, I want my batch size to be parametric, such that I can build tensors which have appropriate batch size dynamically. I have the following code:</p>
<pre><code>batch_size_param = 128

tf_batch_size = tf.keras.Input(shape=(), name=&quot;tf_batch_size&quot;, dtype=tf.int32)
batch_indices = tf.range(0, tf_batch_size, 1)

md = tf.keras.Model(inputs={&quot;tf_batch_size&quot;: tf_batch_size}, outputs=[batch_indices])
res = md(inputs={&quot;tf_batch_size&quot;: batch_size_param})
</code></pre>
<p>The code throws an error in <code>tf.range</code>:</p>
<pre><code>ValueError: Shape must be rank 0 but is rank 1
 for 'limit' for '{{node Range}} = Range[Tidx=DT_INT32](Range/start, tf_batch_size, Range/delta)' with input shapes: [], [?], []
</code></pre>
<p>I think the problem is with the fact that <code>tf.keras.Input</code> automatically tries to expand the input array at the first dimension, since it expects the partial shape of the input without the batch size and will attach the batch size according to the shape of the input array, which in my case a scalar. I can just feed the scalar value as a constant integer into <code>tf.range</code> but this time, I won't be able to change it after the model graph has been compiled.</p>
<p>Interestingly, I failed to find a proper way to input only a scalar into a TF-2 model even though I checked the documentation, too. So, what would be the best way to handle such a case?</p>
",2021-03-09 11:49:17,1538049,3591,https://stackoverflow.com/questions/66546321,Documentation Replication on Other Examples
66570237,TensorFlow model to Keras functional API?,"<p>I want to have this model as a functional model that uses Keras API, but not sure how. I want my model to be in the form of <code>model = tf.keras.model.Model(....)</code> so I can just evaluate or export the model by calling <code>model</code>. But I don't know how to do this with attention layers in the model. The <a href=""https://keras.io/api/layers/attention_layers/attention/"" rel=""nofollow noreferrer"">Keras attention layer documentation</a> stops at that very step and leave it to the user to figure it out.</p>
<p>FYI, my model uses IMDB reviews for sentiment analysis.</p>
<pre class=""lang-py prettyprint-override""><code>query_layer = tf.keras.layers.Conv1D(filters=100, kernel_size=4, padding='same')
value_layer = tf.keras.layers.Conv1D(filters=100, kernel_size=4, padding='same')

attention = tf.keras.layers.Attention()
concat = tf.keras.layers.Concatenate()

cells = [tf.keras.layers.LSTMCell(256), tf.keras.layers.LSTMCell(64)]
rnn = tf.keras.layers.RNN(cells)
output_layer = tf.keras.layers.Dense(1)

for batch in ds['train'].batch(32):
    text = batch['text']
    embeddings = embedding_layer(vectorize_layer(text))
    query = query_layer(embeddings)
    value = value_layer(embeddings)
    query_value_attention = attention([query, value])
    attended_values = concat([query, query_value_attention])
    logits = output_layer(rnn(attended_values))
    loss = binary_crossentropy(tf.expand_dims(batch['label'], -1),
                                               logits, from_logits=True)
</code></pre>
",2021-03-10 17:50:58,12655251,317,https://stackoverflow.com/questions/66570237,Documentation Replicability
66582647,Tensorflow Random segmentation faults,"<p>I am trying to run the demo code from official tensorflow <a href=""https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch"" rel=""nofollow noreferrer"">website</a>
I am attaching the full code (copied and arranged) here for ease</p>
<pre><code>import tensorflow as tf

# print(&quot;1&quot;)
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import time
import os

# print(&quot;2&quot;)
os.environ[&quot;TF_CPP_MIN_LOG_LEVEL&quot;] = &quot;3&quot;


# @tf.function
def train_step(x, y):
    with tf.GradientTape() as tape:
        logits = model(x, training=True)
        loss_value = loss_fn(y, logits)
    grads = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(grads, model.trainable_weights))
    train_acc_metric.update_state(y, logits)
    return loss_value


# @tf.function
def test_step(x, y):
    val_logits = model(x, training=False)
    val_acc_metric.update_state(y, val_logits)


inputs = keras.Input(shape=(784,), name=&quot;digits&quot;)
x1 = layers.Dense(64, activation=&quot;relu&quot;)(inputs)
x2 = layers.Dense(64, activation=&quot;relu&quot;)(x1)
outputs = layers.Dense(10, name=&quot;predictions&quot;)(x2)
model = keras.Model(inputs=inputs, outputs=outputs)

# Instantiate an optimizer.
optimizer = keras.optimizers.SGD(learning_rate=1e-3)
# Instantiate a loss function.
loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
train_acc_metric = keras.metrics.SparseCategoricalAccuracy()
val_acc_metric = keras.metrics.SparseCategoricalAccuracy()
# Prepare the training dataset.
batch_size = 64
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = np.reshape(x_train, (-1, 784))
x_test = np.reshape(x_test, (-1, 784))

# Reserve 10,000 samples for validation.
x_val = x_train[-10000:]
y_val = y_train[-10000:]
x_train = x_train[:-10000]
y_train = y_train[:-10000]

# Prepare the training dataset.
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)

# Prepare the validation dataset.
val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_dataset = val_dataset.batch(batch_size)

epochs = 2
for epoch in range(epochs):
    print(&quot;\nStart of epoch %d&quot; % (epoch,))
    start_time = time.time()

    # Iterate over the batches of the dataset.
    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
        loss_value = train_step(x_batch_train, y_batch_train)

        # Log every 200 batches.
        if step % 200 == 0:
            print(
                &quot;Training loss (for one batch) at step %d: %.4f&quot;
                % (step, float(loss_value))
            )
            print(&quot;Seen so far: %d samples&quot; % ((step + 1) * 64))

    # Display metrics at the end of each epoch.
    train_acc = train_acc_metric.result()
    print(&quot;Training acc over epoch: %.4f&quot; % (float(train_acc),))

    # Reset training metrics at the end of each epoch
    train_acc_metric.reset_states()

    # Run a validation loop at the end of each epoch.
    for x_batch_val, y_batch_val in val_dataset:
        test_step(x_batch_val, y_batch_val)

    val_acc = val_acc_metric.result()
    val_acc_metric.reset_states()
    print(&quot;Validation acc: %.4f&quot; % (float(val_acc),))
    print(&quot;Time taken: %.2fs&quot; % (time.time() - start_time))
    print(&quot;end&quot;)
</code></pre>
<p>Without any reason, this code enters Segmentation Fault in Tensorflow 2.3.1 right at the beginning</p>
<pre><code>&gt;python dummy.py 
2021-03-11 17:45:52.231509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Segmentation fault (core dumped)
</code></pre>
<p>Interestingly if I put some random print statements at the very start(those <code>print(&quot;1&quot;)</code> etc statements, the code will execute till the end and suffer segmentation fault at the end(redundant output not shown)</p>
<pre><code>Start of epoch 1
Training loss (for one batch) at step 0: 1.0215
Seen so far: 64 samples
Training loss (for one batch) at step 200: 0.9116
Seen so far: 12864 samples
Training loss (for one batch) at step 400: 0.4894
Seen so far: 25664 samples
Training loss (for one batch) at step 600: 0.5636
Seen so far: 38464 samples
Training acc over epoch: 0.8416
Validation acc: 0.8296
Time taken: 3.16s
end
Segmentation fault (core dumped)
</code></pre>
<p>Another observation is, if I uncomment the <code>@tf.function</code> on top of my <code>trainStep</code> and <code>testStep</code> functions, the code enters into segfault again but after it prints
<code>Start of epoch 0</code></p>
<p>Can someone explain what is going wrong with my Tensorflow package?</p>
",2021-03-11 12:31:47,9598527,121,https://stackoverflow.com/questions/66582647,Documentation Ambiguity
66916390,Error when adapting batch size in tf.keras.utils.Sequence,"<p>I study using tf.keras.utils.Sequence on Tensorflow 2.4.1. I used the example code in Sequence in API document (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence</a>) and finetuned by adding <code>on_epoch_end</code> function to adaptively change the <code>batch_size</code> value on every epoch.</p>
<pre><code>from skimage.io import imread
from skimage.transform import resize
import numpy as np
import random
import math

# Here, `x_set` is list of path to the images
# and `y_set` are the associated classes.

class CIFAR10Sequence(tensorflow.keras.utils.Sequence):

    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def on_epoch_end(self):
        print(self.batch_size)
        self.batch_size = int(random.randint(10, 100))

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        return np.array([
            resize(imread(file_name), (200, 200))
               for file_name in batch_x]), np.array(batch_y)
</code></pre>
<p>However, in practice, the number of steps per epoch, which expected to change depending on the number of batches, remains unchanged. In fact, Tensorflow returns a WARNING, informing that they run out of data, and stop the training immediately. This problem happens when the initialize <code>batch_size</code> is smaller than the current <code>self.batch_size</code>.</p>
<pre><code>WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches
</code></pre>
<p>Here is my guess, Tensorflow did adapt the batch size after every epoch, but somehow the model was still keeping the initial value. This problem never happened in Keras version 1. So far, I have no clue on solving this problem.
Edit 1: The number of training data is much larger than the number of batches.</p>
",2021-04-02 08:16:37,5169676,69,https://stackoverflow.com/questions/66916390,Documentation Replicability
66968102,python type hint - can tensorflow data type be used?,"<p>Is it possible to use the Tensorflow data types <a href=""https://www.tensorflow.org/api_docs/python/tf/dtypes/DType"" rel=""noreferrer"">tf.dtypes.DType</a> such as tf.int32 in Python type hint?</p>
<pre><code>from typing import (
    Union,
)
import tensorflow as tf
import numpy as np


def f(
    a: Union[tf.int32, tf.float32]  # &lt;----
): 
    return a * 2


def g(a: Union[np.int32, np.float32]):
    return a * 2


def test_a():
    f(tf.cast(1.0, dtype=tf.float32))  # &lt;----
    g(np.float32(1.0))                 # Numpy type has no issue

</code></pre>
<p>It causes the error below and wonder if this is possible.</p>
<pre><code>python3.8/typing.py:149: in _type_check
    raise TypeError(f&quot;{msg} Got {arg!r:.100}.&quot;)
E   TypeError: Union[arg, ...]: each arg must be a type. Got tf.int32.
</code></pre>
",2021-04-06 11:50:18,4281353,20088,https://stackoverflow.com/questions/66968102,Documentation Replicability
66997498,Get python string from Tensor without the numpy function,"<p>I'm following the tutorial on <a href=""https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/word_embeddings.ipynb"" rel=""nofollow noreferrer"">https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/word_embeddings.ipynb</a></p>
<p>TextVectorization by defalut splits on whitespace but I want to implement custom split. I want to keep punctuations (which I have implemented in custom_standardization), and split between words and punctuations.</p>
<p>For instance, &quot;fn(1,2)=1+2=3&quot; needs to split to <code>[&quot;fn&quot;,&quot;(&quot;,&quot;1&quot;,&quot;,&quot;,&quot;2&quot;,&quot;)&quot;,&quot;=&quot;,&quot;1&quot;,&quot;+&quot;,&quot;2&quot;,&quot;=&quot;,&quot;3&quot;]</code>.</p>
<pre><code>def custom_split(input_data: tf.Tensor):
    assert input_data.dtype.name=='string'
    assert hasattr(input_data,'numpy') == False
    ???
    


vectorize_layer = TextVectorization(
    standardize=custom_standardization,
    split=custom_split,
    output_mode='int',
    output_sequence_length=sequence_length)
</code></pre>
<p>I'm confident in such spliting given a standard Python string. However the input is tf.Tensor and following the aforementioned tutorial, input_data does not have numpy() function.</p>
<p>What's the proper way to do such spliting? Is it possible to retrieve Python string from string Tensor?</p>
",2021-04-08 04:47:20,746461,5985,https://stackoverflow.com/questions/66997498,Documentation Replicability
67049850,Tensorflow tf.switch_case not working with keras Input,"<p>I want to use tf.switch_case to be able to redirect learning flow for different branchs of the network using inputs however tf.switch_case does not work with Keras.Tensor ...</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Input
def f1(): return tf.constant(17)
def f2(): return tf.constant(31)
def f3(): return tf.constant(-1)
t_input = Input(shape=(1,), name=&quot;t_input&quot;)
r = tf.switch_case(t_input, branch_fns={0: f1, 1: f2}, default=f3)
</code></pre>
<pre><code>Traceback (most recent call last):
  File &quot;C:\Users\gen06917\PycharmProjects\BaysianTarnet\.venv\lib\site-packages\IPython\core\interactiveshell.py&quot;, line 3437, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &quot;&lt;ipython-input-9-bd285228541c&gt;&quot;, line 5, in &lt;module&gt;
    r = tf.switch_case(t_input, branch_fns={0: f1, 1: f2}, default=f3)
  File &quot;C:\Users\gen06917\PycharmProjects\BaysianTarnet\.venv\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 3616, in switch_case
    return _indexed_case_helper(branch_fns, default, branch_index, name)
  File &quot;C:\Users\gen06917\PycharmProjects\BaysianTarnet\.venv\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 3315, in _indexed_case_helper
    branch_fns, default, branch_index)
  File &quot;C:\Users\gen06917\PycharmProjects\BaysianTarnet\.venv\lib\site-packages\tensorflow\python\ops\control_flow_ops.py&quot;, line 3249, in _indexed_case_verify_and_canonicalize_args
    type(branch_index)))
TypeError: branch_index must a Tensor, got &lt;class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'&gt;
</code></pre>
",2021-04-11 20:23:07,7182711,362,https://stackoverflow.com/questions/67049850,Documentation Ambiguity
67066760,Configuring labels in TensorFlow BinaryCrossentropy loss function,"<p>I want to compute cross-entropy loss using <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy"" rel=""nofollow noreferrer"">tf.keras.losses.BinaryCrossentropy</a>. The documentation has the following example, and specifies that true labels and predicted labels should have the shape <code>[batch_size]</code>:</p>
<pre><code>y_true = [[0., 1.], [0., 0.]]
y_pred = [[0.6, 0.4], [0.4, 0.6]]

bce = tf.keras.losses.BinaryCrossentropy()
bce(y_true, y_pred).numpy()
</code></pre>
<p>From the example, it is inferred that each sample's label should be formatted as [probability of belonging to Class 0, probability of belonging to Class 1]. Is it correct? If it is, why <code>y_true[1]</code> probabilities do not add up to 1?</p>
",2021-04-12 23:09:59,5425172,4449,https://stackoverflow.com/questions/67066760,Documentation Ambiguity
67101417,Using saved models from TF hub to extract feature vectors,"<p>I've been playing with different models from TF hub to extract feture vectors:</p>
<pre><code>module = hub.load('https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4')
features = module(image)
</code></pre>
<p>What i don't quite understand is how input image should be preprocessed.
Every model from the hub has this generic instruction:</p>
<blockquote>
<p>The input image1 are expected to have color values in the range [0,1], following the common image input conventions. The expected size of the input images is height x width = 299 x 299 pixels by default, but other input sizes are possible (within limits).
where &quot;common image input&quot; is a link to a the following:
A signature that takes a batch of images as input accepts them as a dense 4-D tensor of dtype float32 and shape [batch_size, height, width, 3] whose elements are RGB color values of pixels normalized to the range [0, 1]. This is what you get from tf.image.decode_*() followed by tf.image.convert_image_dtype(..., tf.float32).</p>
</blockquote>
<p>and this is indeed what i see quite often online:</p>
<pre><code>image = tf.io.read_file(path)

# Decodes the image to W x H x 3 shape tensor with type of uint8
image = tf.io.decode_jpeg(image, channels=3)

# Resize the image to for model
image = tf.image.resize(image, [model_input_size, model_input_size])

# 1 x model_input_size x model_input_size x 3 tensor with the data type of float32
image = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]
</code></pre>
<p>BUT, color values are expected to be in range [0,1], in this case colors are in range [0,255] and should be scaled down:</p>
<pre><code>image = numpy.array(image) * (1. / 255)
</code></pre>
<p>Is it just a common mistake or is the TF documentation is not up to date?</p>
<p>I was playing with models from tf.keras.applications and reading source code in github. I noticed in some of the models (EfficientNet) first layer is:</p>
<pre><code>x = layers.Rescaling(1. / 255.)(x)
</code></pre>
<p>but in some models there is no such layer, instead and an utility function scales colors to [0,1] range, for example tf.keras.applications.mobilenet.preprocess_input.</p>
<p>So, how important for TF hub saved models image colors to be in [0,1] range?</p>
",2021-04-15 02:26:58,15641209,21,https://stackoverflow.com/questions/67101417,Documentation Replication on Other Examples
67211152,Tensorlow - please decipher what the tf.where document says,"<p>Please decipher what the <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer"">tf.where</a> documentation says about what it does when both x and y are provided.</p>
<p>I suppose it tries to say it will produce a result by:</p>
<ol>
<li>Broadcast y to the result shape.</li>
<li>Broadcast x to the result shape.</li>
<li>Update y with x elements where the condition is true.</li>
</ol>
<p>Is this correct?</p>
<blockquote>
<p>If x and y are provided (both have non-None values):
tf.where will choose an output shape from the shapes of condition, x, and y that all three shapes are broadcastable to.</p>
<p><strong>Returns</strong>
If x and y are provided: A Tensor with the same type as x and y, and shape that is broadcast from condition, x, and y. Otherwise, a Tensor with shape (num_true, dim_size(condition)).</p>
</blockquote>
",2021-04-22 10:07:35,4281353,20088,https://stackoverflow.com/questions/67211152,Documentation Replicability
67226579,What causes stated console output in Tensorflow?,"<p>Tensorflow puts out a lot of output in console, could you tell me what code in my program causes this output? Also, how do I suppress it?<br />
<em>
....
Variable/Initializer/initial_value/7859, Variable/Initializer/initial_value/7860, Variable/Initializer/initial_value/7861, Variable/Initializer/initial_value/7862, Variable/Initializer/initial_value/7863, Variable/Initializer/initial_value/7864, Variable/Initializer/initial_value/7865, Variable/Initializer/initial_value/7866, Variable/Initializer/initial_value/7867, Variable/Initializer/initial_value/7868, Variable/Initializer/initial_value/7869, Variable/Initializer/initial_value/7870, Variable/Initializer/initial_value/7871, Variable/Initializer/initial_value/7872, Variable/Initializer/initial_value/7873, Variable/Initializer/initial_value/7874, Variable/Initializer/initial_value/7875, Variable/Initializer/initial_value/7876, Variable/Initializer/initial_value/7877, Variable/Initializer/initial_value/7878, Variable/Initializer/initial_value/7879, Variable/Initializer/initial_value/7880, Variable/Initializer/initial_value/7881, Variable/Initializer/initial_value/7882, Variable/Initializer/initial_value/7883, Variable/Initializer/initial_value/7884, Variable/Initializer/initial_value/7885, Variable/Initializer/initial_value/7886, Variable/Initializer/initial_value/7887, Variable/Initializer/initial_value/7888, Variable/Initializer/initial_value/7889, Variable/Initializer/initial_value/7890, Variable/Initializer/initial_value/7891, Variable/Initializer/initial_value/7892, Variable/Initializer/initial_value/7893, Variable/Initializer/initial_value/7894, Variable/Initializer/initial_value/7895, Variable/Initializer/initial_value/7896, Variable/Initializer/initial_value/7897, Variable/Initializer/initial_value/7898, Variable/Initializer/initial_value/7899, Variable/Initializer/initial_value/7900, Variable/Initializer/initial_value/7901, Variable/Initializer/initial_value/7902, Variable/Initializer/initial_value/7903, Variable/Initializer/initial_value/7904)' with input shapes: [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [6], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7],
[7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7],
[7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7],
[7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7], [7],.....
</em><br />
Here is my code</p>
<pre class=""lang-py prettyprint-override""><code>class LSTMmodel(tf.Module):
    def __init__(self, arg_name=None):
        super().__init__(name=arg_name)
        self.__input = tf.Variable(initial_value=[0.0 for x in range(7)], dtype=tf.float32)
        self.__input_reshaped = tf.reshape(self.__input, [1, 7, 1])
        self.__network = tf.keras.layers.LSTM(units=7, input_shape=(7,1))
        self.__output = tf.Variable(initial_value=[0.0 for x in range(7)], dtype=tf.float32)
        self.__output = tf.reshape(self.__output, [1, 7, 1])
    @tf.function
    def networkTraining(self, arg_data_train, arg_labels, arg_learning_rate):
        with tf.GradientTape() as t:
            print('loc 1')
            self.__input = tf.Variable(arg_data_train)
            print('loc 2')
            self.__input_reshaped = tf.reshape(self.__input, [1, 7, 1])
            self.__output = self.__network(self.__input_reshaped)
            print('loc 3')
            loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=arg_labels, logits=self.__output)
            print('loc 4')
            dw, db = t.gradient(loss, [self.w, self.b])
            print('loc 5')
        self.w.assign_sub(arg_learning_rate * dw)
        self.b.assign_sub(arg_learning_rate * db)

    @tf.function
    def __call__(self, arg_input=[0 for x in range(7)]):
        self.__input = tf.Variable(arg_input)
        self.__output = self.__network(self.__input)
        return self.__output

# some other code
#
#
#
modela.networkTraining(cgm ,labels, 0.4)
</code></pre>
<p>EDIT:<br />
The 'Variable/Ini..../&lt;a_number&gt;' happens right before the <code>print('loc 4')</code></p>
<pre class=""lang-py prettyprint-override""><code># ###########################FULL-CODE
import pandas
import scipy.io as loader
import tensorflow as tf
import keras
import numpy

tf.get_logger().setLevel('INFO')
class LSTMmodel(tf.Module):
    def __init__(self, arg_name=None):
        super().__init__(name=arg_name)
        self.__input = tf.Variable(initial_value=[0.0 for x in range(7)], dtype=tf.float32)
        self.__input_reshaped = tf.reshape(self.__input, [1, 7, 1])
        self.__network = tf.keras.layers.LSTM(units=7, input_shape=(7,1))
        self.__output = tf.Variable(initial_value=[0.0 for x in range(7)], dtype=tf.float32)
        self.__output = tf.reshape(self.__output, [1, 7, 1])
    @tf.function
    def networkTraining(self, arg_data_train, arg_labels, arg_learning_rate):
        with tf.GradientTape() as t:
            print('loc 1')
            self.__input = tf.Variable(arg_data_train)
            print('loc 2')
            self.__input_reshaped = tf.reshape(self.__input, [1, 7, 1])
            self.__output = self.__network(self.__input_reshaped)
            print('loc 3')
            loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=arg_labels, logits=self.__output)
            print('loc 4')
            dw, db = t.gradient(loss, [self.w, self.b])
            print('loc 5')
        self.w.assign_sub(arg_learning_rate * dw)
        self.b.assign_sub(arg_learning_rate * db)

    @tf.function
    def __call__(self, arg_input=[0 for x in range(7)]):
        self.__input = tf.Variable(arg_input)
        self.__output = self.__network(self.__input)
        return self.__output
    # tf.nn.sigmoid_cross_entropy_with_logits(labels=None, logits=None)

correct = numpy.load('save.npy')
# link for the .mat file for your convenience
# https://drive.google.com/file/d/1NOZOeRm1oLOU12p3J4-zw3RrPnJZvw4-/view?usp=sharing
insulin = loader.loadmat('InsulinGlucoseData2.mat')
also = pandas.read_csv('dates222.csv')

# print(type(insulin['numCGM'][0:5]))
# quit()
cgm = []
temp = []
labels = []
# print(insulin['numCGM'])
# print(insulin['actBolusDelivered'])
counter = also.shape[0] - 1
counta = 0
# print(len(insulin['numCGM']))
while counter &gt;= 0:
    if also['classification2'][counter] == 1:
        cgm.append(insulin['numCGM'][0][counter:counter + 6])
        labels.append([0, 0, 0, 0, 0, 0, 1])
        counter = counter - 7
    elif also['classification2'][counter] == 0:
        counter = counter - 1
        counta = counta + 1
        temp.append(insulin['numCGM'][0][counter])
        if counta == 7:
            counta = 0
            cgm.append(temp)
            temp = []
            labels.append([0, 0, 0, 0, 0, 0, 0])
    if counter - 7 &lt; 0: break
    # print(counter)
# print(len(cgm[0]))
# quit()
modela = LSTMmodel(arg_name='ghajini_disease')
# print('------------------------------------------------')
# cgm = numpy.array(cgm, numpy.float32)
for each in labels:
    for each_one in each:
        each_one = float(each_one)
# print(len(labels))
# print('------------------------------------------------')
modela.networkTraining(cgm ,labels, 0.4)

out = modela(cgm)
print(out)

for each in out:
    su = su + each[-1]

train_accuracy = su/sum(labels) * 100

test = modela(new)
</code></pre>
<p>EDIT:<br />
I suspect that this problem is being caused in the line <code>self.__input = tf.Variable(arg_data_train)</code>. <code>arg_data_train</code> is actually a python list of python lists. I still don't understand the console output though.</p>
",2021-04-23 08:30:46,7971339,231,https://stackoverflow.com/questions/67226579,Documentation Replicability
67308892,ANN : I cannot train my custom loss function using gradient descent,"<p>I am trying to train my multi-input (100 features) multi-output (3 outputs) model using <strong>gradient descent but the loss function does not tends towards 0.</strong></p>
<p><strong>The loss function is on the following picture :</strong> <a href=""https://i.stack.imgur.com/6u4k2.png"" rel=""nofollow noreferrer"">loss(y_true, y_pred)</a>. This loss function rewards the classification (if you get the right sign) of data with large value.</p>
<p>Here is the code of my loss function :</p>
<pre><code>def my_loss_fn(y_true, y_pred) : 
    d = tf.raw_ops.Sum(input = tf.raw_ops.Abs(x= y_true, name = None), axis = -1, keep_dims = False, name = None)
    n = tf.raw_ops.Sum(input = tf.raw_ops.Sign(x = y_true*y_pred, name = None)*tf.raw_ops.Abs(x = y_true, name = None), axis = -1, keep_dims = False, name = None)
    return 1-n/d
</code></pre>
<p>I am using <code>tf.raw_ops</code> because it seems that <code>sign()</code> and <code>abs()</code> are <strong>differentiable</strong> (weird..) : <a href=""https://www.tensorflow.org/api_docs/python/tf/raw_ops"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/raw_ops</a> .</p>
<p>I implemented this loss function to train the following model (ANN with 3 layers with 50 nodes each) :</p>
<pre><code>from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout

classifier = Sequential()

#Layers 
classifier.add(Dense(units = 50, input_shape = (100, ), activation = &quot;relu&quot;))
classifier.add(Dropout(0.2))
classifier.add(Dense(units = 50, activation = &quot;relu&quot;))
classifier.add(Dropout(0.2))
classifier.add(Dense(units = 50, activation = &quot;relu&quot;))
classifier.add(Dropout(0.2))

# Output layer
classifier.add(Dense(units=3, activation = 'tanh'))

# Compilation
classifier.compile(optimizer = 'adam', loss = my_loss_fn) 

#Training
nb_epochs = 300
history = classifier.fit(X_train, y_train, epochs = nb_epochs, batch_size = 128, verbose = True)
</code></pre>
<p>The loss does not tend towards zero and varies between 0.99 and 1.05.</p>
<p>I am using <strong>tensorflow 1.14.0</strong>.</p>
<p>Can you help me with this problem ?</p>
<p>Thank you all in advance !</p>
",2021-04-28 22:50:14,15788458,1,https://stackoverflow.com/questions/67308892,Documentation Replicability
67344068,TensorFlow 2 - does NumPy numerical values and arrays cause new graphs for TF Function?,"<p>Does &quot;<strong>numerical Python values</strong>&quot; stated in the <a href=""https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/"" rel=""nofollow noreferrer"">Hands on ML 2</a> include NumPy int, float, and array? Do we need to explicitly create a TF Tensor or a TF DataSet from a NumPy construct as the argument of a TF Function?</p>
<p><a href=""https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/"" rel=""nofollow noreferrer"">Hands on ML 2</a> Chapter 12 Auto Graph and Tracing:</p>
<blockquote>
<p>By default, a TF Function generates a new graph for every unique set
of intput shapes and data types and caches it for subsequent calls.
... However <em><strong>this is only true for tensor arguments</strong></em>: if you pass
numerical Python values to a TF Function, a new graph will be
generated for every distinct value. ...</p>
<p>if you pass <strong>numerical Python values</strong> to a TF function, a new graph will
be generated for every distinct values. If you call a TF function many
times with different numerical Python values, then many graphs will be
generated, slowing down your program and using up a lot of RAM (you
must delete the TF Function to release it).</p>
<p>Python values should be reserved for arguments that will have few
unique values, such as hyper parameters like the number of neurons per
layer. This allows TensorFlow to better optimize each variant fo yor
model.</p>
</blockquote>
<p>The 3rd rule stated in the TensorFlow document <a href=""https://www.tensorflow.org/guide/function#rules_of_tracing"" rel=""nofollow noreferrer"">Rules of tracing</a> corresponds with Python int, float, boolean, str , etc that will cause a new graph part. But not sure if the 5th rule (all other Python types) applies to NumPy constructs.</p>
<blockquote>
<p>A Function determines whether to reuse a traced ConcreteFunction by computing a cache key from an input's args and kwargs.  A cache key is a key that identifies a ConcreteFunction based on the
input args and kwargs of the Function call, according to the following
rules (which may change):</p>
<ol>
<li><p>The key generated for a tf.Tensor is its shape and dtype.</p>
</li>
<li><p>The key generated for a tf.Variable is a unique variable id.</p>
</li>
<li><p>The key generated for a Python primitive (like int, float, str) is its value.</p>
</li>
<li><p>The key generated for nested dicts, lists, tuples, namedtuples, and attrs is the flattened tuple of leaf-keys (see nest.flatten). (As a
result of this flattening, calling a concrete function with a
different nesting structure than the one used during tracing will
result in a TypeError).</p>
</li>
<li><p>For all other Python types the key is unique to the object. This way a
function or method is traced independently for each instance it is
called with.</p>
</li>
</ol>
</blockquote>
<p>I suppose the fact <a href=""https://www.tensorflow.org/api_docs/python/tf/numpy_function"" rel=""nofollow noreferrer"">tf.numpy_function</a> exists suggests that the TF Function tracing will generate a new graph, but need a definite confirmation.</p>
",2021-05-01 07:55:02,4281353,20088,https://stackoverflow.com/questions/67344068,Documentation Replication on Other Examples
67462119,How to convert TF object detection models to tf.keras?,"<p>Is there a way to convert TF object detection models from <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"" rel=""nofollow noreferrer"">here</a> to tf.keras? If not, how can I get the total number of variables in the model?</p>
",2021-05-09 20:34:28,15571511,11,https://stackoverflow.com/questions/67462119,Documentation Replication on Other Examples
67523944,"Tensorflow2 - Use ""tf.data.experimental.make_csv_dataset"" with ""tf.keras.preprocessing.timeseries_dataset_from_array""","<p>I am trying to get TensorFlow to read +100 CSV files that <em><strong>don't</strong></em> fit in memory (+1GB size each). The files contain time series data (EEG signals), with the labels in the first column. From the TensorFlow documentation it seems like I should be able to use the <em>tf.data</em> API to load my data off-disk.</p>
<p>For the sake of simplicity and reproducibility, let's consider the following &quot;<em>sample_data.csv</em>&quot; dataset:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Label</th>
<th>Feature 1</th>
<th>Feature 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Apple</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>Banana</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>Coconut</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>Durian</td>
<td>7</td>
<td>8</td>
</tr>
</tbody>
</table>
</div>
<p>I've tried using <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset"" rel=""nofollow noreferrer"">tf.data.experimental.make_csv_dataset</a> to load the CSV files into <em>tf.data.Dataset</em> objects, and then <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array"" rel=""nofollow noreferrer"">tf.keras.preprocessing.timeseries_dataset_from_array</a> to process the data into sliding windows with overlap. For the dataset above, I would do:</p>
<pre><code>import tensorflow as tf

input_data = tf.data.experimental.make_csv_dataset(
    'sample_data.csv',
    batch_size=1,
    column_names=['Label', 'Feature 1', 'Feature 2']
    label_name='Label',
    num_epochs=1,
    shuffle=False
)
</code></pre>
<p>Which we can check works correctly by looking at the output from <code>list(input_data.as_numpy_iterator())</code>. We can then feed <code>input_data</code> to the next function:</p>
<pre><code>my_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(
    input_data,
    targets=None,
    sequence_length=3,
    sequence_stride=2,
    sampling_rate=1,  
    batch_size=1,
    shuffle=False
)
</code></pre>
<p>Which unfortunately <strong>throws this error</strong>:</p>
<blockquote>
<p>TypeError: dataset length is unknown.</p>
</blockquote>
<p>I also tried using <code>my_dataset = input_data.window(3, shift=2)</code> (see the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"" rel=""nofollow noreferrer"">tf.data.Dataset.window</a> documentation) and it didn't throw an error, but
it seems to be returning an <strong>empty dataset</strong>? See &quot;<em>_VariantDataset shapes: (None,)</em>&quot; in the output:</p>
<pre><code>list(input_data.window(3, shift=2))

[344]:
[(OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;),
 (OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;),
 (OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;)]
</code></pre>
<p>If I load the &quot;<em>sample_data.csv</em>&quot; in memory using pandas and then feed the <em>timeseries_dataset_from_array</em> function a numpy array instead, it works correctly.</p>
<p>Any ideas on how to solve this? <strong>What's the best method to input overlapping windows from off-memory time-series data into TensorFlow</strong>?</p>
<p>Thank you!</p>
",2021-05-13 17:54:55,6395699,13,https://stackoverflow.com/questions/67523944,Documentation Replication on Other Examples
67557800,How to increase the rank (ndim) of input of BERT keras hub layer for learning-to-rank,"<p>I am trying to implement a learning-to-rank model using a pre-trained BERT available on tensorflow hub. I am using a variation of ListNet loss function, which requires each training instance to be a list of several ranked documents in relation to a query. I need the model to be able to accept data in a shape (batch_size, list_size, sentence_length), where the model loops over the 'list_size' axis in each training instance, returns the ranks and passes them to the loss function. In a simple model that only consists of dense layers, this is easily done by augmenting the dimensions of the input layer. For example:</p>
<pre><code>from tensorflow.keras.layers import Dense, Input
from tensorflow.keras import Model

input = Input([6,10])
x = Dense(20,activation='relu')(input)
output = Dense(1, activation='sigmoid')(x)
model = Model(inputs=input, outputs=output)
</code></pre>
<p>...now the model will perform 6 forward passes over vectors of length 10 before calculating the loss and updating gradients.</p>
<p>I am trying to do the same with the BERT model and its preprocessing layer:</p>
<pre><code>import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_text as text

bert_preprocess_model = hub.KerasLayer('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1')
bert_model = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')
    
text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
processed_input = bert_preprocess_model(text_input)
output = bert_model(processed_input)
model = tf.keras.Model(text_input, output)
</code></pre>
<p>But when I try to change the shape of 'text_input' to, say, (6), or meddle with it in any way really, it always results in the same type of error:</p>
<pre><code> ValueError: Could not find matching function to call loaded from the SavedModel. Got:
      Positional arguments (3 total):
        * Tensor(&quot;inputs:0&quot;, shape=(None, 6), dtype=string)
        * False
        * None
      Keyword arguments: {}
    
    Expected these arguments to match one of the following 4 option(s):
    
    Option 1:
      Positional arguments (3 total):
        * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')
        * False
        * None
      Keyword arguments: {}
     ....
</code></pre>
<p>As per <a href=""https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer</a>, it seems like you can configure the input shape of hub.KerasLayer via tf.keras.layers.InputSpec. In my case, I guess it would be something like this:</p>
<pre><code>bert_preprocess_model.input_spec = tf.keras.layers.InputSpec(ndim=2)
bert_model.input_spec = tf.keras.layers.InputSpec(ndim=2)
</code></pre>
<p>When I run the above code, the attributes indeed get changed, but when trying to build the model, the same exact error appears.</p>
<p>Is there any way to easily resolve this without the necessity to create a custom training loop?</p>
",2021-05-16 14:27:54,14913631,11,https://stackoverflow.com/questions/67557800,Documentation Replication on Other Examples
67563475,How to convert a tensorflow model and load as tfds,"<p>I need help converting my dataset from how I usually make it using
<code>tf.keras.preprocessing.image_dataset_from_directory</code>
To be used to replace this in an example</p>
<pre><code>dataset, info = tfds.load(name='mnist', split=split, with_info=True,

as_supervised=True, try_gcs=True)
</code></pre>
<p>How can I do so? I am unable to find related documentation so if you can link that it would be amazing.
Thanks</p>
<p>This is how the dataset is used in the example</p>
<pre><code>  split = 'train' if is_training else 'test'
  dataset, info = tfds.load(name='mnist', split=split, with_info=True,
                            as_supervised=True, try_gcs=True)


  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255.0

    return image, label

  dataset = dataset.map(scale)
</code></pre>
",2021-05-17 02:58:44,15760012,3,https://stackoverflow.com/questions/67563475,Documentation Ambiguity
67723809,Memory leak when using tf.data Datasets with shuffle,"<p>I have a memory leak somehow when I create my tf.data.dataset pipeline, but I don't know where.
My code works fine with ImageDataGenerator but is really slow.
Reading a lot of documentation I thought it might be albumentations.</p>
<p>However I now switched my transform to be entirely in tensorflow:</p>
<pre><code>def map_data(inputs, outputs):
image = inputs['image_input']
image = parse_image(image)
image = tf.cast(image, tf.float32) / 255.0
image = tf.image.resize(image, size = [224, 224])
image = tf.image.random_flip_left_right(image)
image = tf.image.random_flip_up_down(image)
image = tf.image.random_brightness(image, max_delta = 0.5)
#image = tf.expand_dims(image, axis=3)
other = parse_image(inputs['other_input'])
other = tf.cast(other, tf.float32) / 255.0
other = tf.image.resize(other, size = [224, 224])
other = tf.image.random_flip_left_right(other)
other = tf.image.random_flip_up_down(other)
other = tf.image.random_brightness(other, max_delta = 0.5)


return {'image_input': image, 'other_input': other}, outputs
</code></pre>
<p>And I made the shuffle buffer extremely small:</p>
<pre><code>        #dataset = dataset.prefetch(tf.data.AUTOTUNE)
    AUTOTUNE = tf.data.AUTOTUNE
    dataset = (dataset
        .shuffle(32)
        .map(map_data, num_parallel_calls=AUTOTUNE)
        .cache()
        .batch(32)
        .prefetch(AUTOTUNE)
    )
</code></pre>
<p>Could autotune cause this?
On Colab I usually hit the RAM restart at 500 batches</p>
<p>I would like to use tf.data.datasets because it's really much faster if possible.</p>
<p>Thank you for anyone who can point me to the flaw in my code, I have always used generators and only recently made the switch.</p>
",2021-05-27 14:03:59,11106507,976,https://stackoverflow.com/questions/67723809,Documentation Replication on Other Examples
67740346,TimeDistributed layer to apply several convolutional layers error,"<p>I have an issue with the tf.keras.layers.TimeDistributed layer (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed</a>).</p>
<p>I am aware that TimeDistributed can be used to apply a single layer (dense, convolutional...) to a set of inputs, obtaining a set of outputs.</p>
<p>Not only that, but until recently I was able to use it to apply an entire &quot;submodel&quot; to all the inputs. That is, a series of layers, not just one. An example of this is explained here by Patrice Ferlet (<a href=""https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f"" rel=""nofollow noreferrer"">https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f</a>).</p>
<p>Using that source as example I can define a sequential &quot;submodel&quot; like this:</p>
<pre><code>import keras
from keras.layers import Conv2D, BatchNormalization, \
MaxPool2D, GlobalMaxPool2D

def build_convnet(shape=(112, 112, 3)):
  momentum = .9
  model = keras.Sequential()
  model.add(Conv2D(64, (3,3), input_shape=shape,
      padding='same', activation='relu'))
  model.add(Conv2D(64, (3,3), padding='same', activation='relu'))
  model.add(BatchNormalization(momentum=momentum))

  model.add(MaxPool2D())

  model.add(Conv2D(128, (3,3), padding='same', activation='relu'))
  model.add(Conv2D(128, (3,3), padding='same', activation='relu'))
  model.add(BatchNormalization(momentum=momentum))

  model.add(MaxPool2D())

  model.add(Conv2D(256, (3,3), padding='same', activation='relu'))
  model.add(Conv2D(256, (3,3), padding='same', activation='relu'))
  model.add(BatchNormalization(momentum=momentum))

  model.add(MaxPool2D())

  model.add(Conv2D(512, (3,3), padding='same', activation='relu'))
  model.add(Conv2D(512, (3,3), padding='same', activation='relu'))
  model.add(BatchNormalization(momentum=momentum))

  # flatten...
  model.add(GlobalMaxPool2D())
  return model
</code></pre>
<p>And then include this submodel inside a superior model which calls TimeDistributed with the whole initial submodel (convnet).</p>
<pre><code>from keras.layers import TimeDistributed, GRU, Dense, Dropout

def action_model(shape=(5, 112, 112, 3), nbout=3):
  # Create our convnet with (112, 112, 3) input shape
  convnet = build_convnet(shape[1:])

  # then create our final model
  model = keras.Sequential()
  # add the convnet with (5, 112, 112, 3) shape
  model.add(TimeDistributed(convnet, input_shape=shape))
  # here, you can also use GRU or LSTM
  model.add(GRU(64))
  # and finally, we make a decision network
  model.add(Dense(1024, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(512, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(128, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(nbout, activation='softmax'))
  return model
</code></pre>
<p>Now this works well, and I can get the model structure calling</p>
<pre><code>mod=action_model()
mod.summary()
</code></pre>
<p>But if instead of this I define the convnet model using as backbone a predefined arquitecture from keras, like VGG16, there seems to be an error. (I also needed to change as well keras.Sequential by tf.keras.models.Sequential)</p>
<pre><code>import tensorflow as tf
from keras.layers import Flatten

def build_convnet():

    prevModel = tf.keras.applications.vgg16.VGG16(
        include_top=False,
        input_shape=(112, 112, 3),
        weights='imagenet'  # ImageNet weights
    )

    model = tf.keras.models.Sequential()

    model.add(prevModel)
    model.add(Flatten())

    return model

def action_model(shape=(5, 112, 112, 3), nbout=3):
  # Create our convnet with (112, 112, 3) input shape
  convnet = build_convnet()

  # then create our final model
  model = tf.keras.models.Sequential()
  # add the convnet with (5, 112, 112, 3) shape
  model.add(TimeDistributed(convnet, input_shape=shape))
  # here, you can also use GRU or LSTM
  model.add(GRU(64))
  # and finally, we make a decision network
  model.add(Dense(1024, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(512, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(128, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(nbout, activation='softmax'))
  return model
</code></pre>
<p>When I run this after defining my VGG16-based architecture</p>
<pre><code>mod=action_model()
mod.summary()
</code></pre>
<p>I get the following error:</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-106-c8c6108a1d66&gt; in &lt;module&gt;()
----&gt; 1 mod=action_model()
      2 mod.summary()

1 frames
/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py in __init__(self, layer, **kwargs)
    121           'Please initialize `TimeDistributed` layer with a '
    122           '`tf.keras.layers.Layer` instance. You passed: {input}'.format(
--&gt; 123               input=layer))
    124     super(TimeDistributed, self).__init__(layer, **kwargs)
    125     self.supports_masking = True

ValueError: Please initialize `TimeDistributed` layer with a `tf.keras.layers.Layer` instance. You passed: &lt;tensorflow.python.keras.engine.sequential.Sequential object at 0x7fbb36266a50&gt;
</code></pre>
<p>So now it appears like python is complaining that I am using an input for TimeDistributed that is not a single layer. This doesn't make any sense, since the initial example works well and also involves using several layers with TimeDistributed. Apart from that, the VGG16 model also worked fine some weeks ago.</p>
<p>I am running all of this in Google CoLab.</p>
<p>Could someone help me figure out what is going on here? Is this caused by the new tensorflow 2.5.0 version? Everywhere I look I see people using TimeDistributed to apply a single layer, but applying a whole sequential model worked just fine until now (despite no apparent mention in the documentation).</p>
<p>Thank you!</p>
",2021-05-28 14:03:26,16059221,11,https://stackoverflow.com/questions/67740346,Documentation Replication on Other Examples
67747314,Finding precision and recall for the tutorial federated learning model on MNIST,"<p>I'm using this tutorial to try to learn how federated models work through TensorFlow's tutorial here: <a href=""https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb</a></p>
<p>Currently, the model is defined like this which uses accuracy as its metric.</p>
<pre><code>def model_fn():
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec = preprocessed_example_dataset.element_spec,
      loss = tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy()]
  )
</code></pre>
<p>I want to either use precision and recall as metrics, or find them after the model is trained, but I can't figure out how to do so.</p>
<p>I tried adding precision to metrics like this <code>metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(), tf.keras.metrics.Precision()]</code> and run this code but it gives me an error.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01),
    server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.5))
</code></pre>
<p>Error output:</p>
<pre><code>ValueError                                Traceback (most recent call last)

&lt;ipython-input-13-f8ac3534e325&gt; in &lt;module&gt;()
      2     model_fn,
      3     client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01),
----&gt; 4     server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.5))

ValueError: Shapes (None, 10) and (None, 1) are incompatible
</code></pre>
<p>Previously, I asked a similar question for a regular <a href=""https://stackoverflow.com/questions/67729973/finding-precision-and-recall-for-mnist-dataset-using-tensorflow/67730576#67730576"">centralized model here</a>, but I don't think I can use that same method since you can't get the results of the predictions back in the same way from what I've found.
I've also tried looking at other documentation <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression#training_the_model_and_outputting_training_metrics"" rel=""nofollow noreferrer"">such as this</a>, but it also uses accuracy as the metric, so that wasn't helpful. How can I get the precision and recall of this federated model?</p>
",2021-05-29 02:50:38,8105367,195,https://stackoverflow.com/questions/67747314,Lack of Alternative Solutions/Documentation
67759756,"How do I use ""text_dataset_from_directory"" to do binary text classification from tf.dataset object?","<p>Sorry, I am still relatively new to text classification and Tensorflow, so this may look like a very dumb question.</p>
<p>I have the song lyrics of two different singers. What I am trying to achieve is to build a binary text classification model to predict whether a song fits to the style of singer A or singer B more.
I have the training data (the lyrics text files) of both classes in sub-directories. The directory structure is similar to,</p>
<pre><code>Classification/
...Singer_A/
......A_song_1.txt
......A_song_2.txt
...Singer_B/
......B_song_1.txt
......B_song_2.txt
</code></pre>
<p>And from what I read on the Tensorflow documentation, I could easily construct a dataset by using the
<code>text_dataset_from_directory</code> method. So something like,</p>
<pre><code>dataset = text_dataset_from_directory(
    'Classification', labels='inferred', label_mode='int',
    batch_size=32
)
</code></pre>
<p>However, I don't know how I could go on from there. I would suppose that the created <code>tf.data.Dataset</code> object would still need Tokenization in the texts component, and the tokenized text would then need padding and embedding before feeding it into a logistic model. But I don't know how to further process it in the <code>tf.data.Dataset</code> object.</p>
<p>I saw <a href=""https://www.tensorflow.org/text/guide/word_embeddings"" rel=""nofollow noreferrer"">Tensorflow's Text Embedding Tutorial</a>, but don't really see how it could be changed to become a binary model.</p>
",2021-05-30 09:43:06,10230473,86,https://stackoverflow.com/questions/67759756,Documentation Replicability
67760450,How to achieve Tensorflow Python model() (__call__) performance in C(++) API for small inputs?,"<p><strong>The problem</strong></p>
<p>I have a (very) small and fast model saved in the SavedModel format which I can load and run with the following code:</p>
<pre><code>model = tf.keras.models.load_model(&quot;./&lt;SavedModelDir&gt;&quot;)
outputs = model(inputs, training=False)
</code></pre>
<p>The predict function runs in 0.05 seconds with a batch of 5 inputs (on a Nvidia GPU).
If however I use <code>model.predict_on_batch(inputs)</code> or <code>model.predict(inputs)</code> the performance drops significantly to 0.65 - 0.80 seconds for a batch of 5. This is consistent with the documentation that states that using <code>model() (__call__)</code> is usually faster for smaller inputs.</p>
<p>The problem I am having is the fact that I am trying to port my model to a C(++) program. And using <code>TF_SessionRun()</code> for the C api and <code>model_bundle.GetSession()-&gt;Run()</code> I am getting performance similar to &quot;slow&quot; Python inference methods.</p>
<p><strong>What I have tried</strong></p>
<p>Another (very) small model with small batch, same result.</p>
<p>I tried disabling optimizations with <code>tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': False})</code> to make sure this does not negatively impact performance but this made things even slower.</p>
<p>I also tried converting the SavedModel to a TensorRT SavedModel. This increases the performance of the <code>model() (__call__)</code> method even further but all the other methods stop working in Python and in the downloaded precompiled Tensorflow C GPU api (2.5.0) and the C++ API compiled with Tensorflow_CC I get an error about the operation not being found (TensorRT does not seem to work).</p>
<p>All the performance numbers given were run after a few warmup runs.
Performance measured both with Tensorflow profiler and Python's time.time</p>
<p>I checked if <code>model() (__call__)</code> is working correctly by checking the output and it is.</p>
<p><strong>My question(s)</strong></p>
<p>Is there a way to get <code>model() (__call__)</code> performance with the Tensorflow C(++) API?</p>
<p>The problem seems to be somewhere in Tensorflows optimization for larger batch sizes which decreases the performance of smaller batch sizes. Is there another API that allows faster inference on small batches out of the box (TensorRT C++ API?)?</p>
",2021-05-30 11:08:04,16075630,26,https://stackoverflow.com/questions/67760450,Documentation Replication on Other Examples
67811443,Argmax on tf.sparse.SparseTensor,"<p>Given a Sparse Tensor x of shape [B, d, d', v], how can I calculate <code>tf.argmax(x, axis=2)</code> while keeping sparsity?</p>
<pre><code>x = tf.sparse.SparseTensor(values=..., indices=..., shape=[B, d1, d2, v])
# How to implement something like
sparse_argmax(x, axis=2)
</code></pre>
<p>Thanks in advance!</p>
",2021-06-02 19:35:17,3162981,351,https://stackoverflow.com/questions/67811443,Documentation Replicability
67872566,cProfile with tensorflow tf.functions,"<p>When using cProfiler with tf.function-decorated functions, it seems to show the time it takes for first building the graph only. Is there a way to also see, how much time is spent in total in these graphs?</p>
<pre class=""lang-py prettyprint-override""><code>@tf.function
def test_profiler_easyToFindLabel():
    for i in range(10):
        x = tf.random.uniform((2000,2000))
        y = tf.random.uniform((2000,2000))
        costly_expression_easyToFindLabel(x,y)

@tf.function
def costly_expression_easyToFindLabel(x,y):
    z = tf.matmul(x,y)


profiler = cProfile.Profile()
profiler.enable()
test_profiler_easyToFindLabel()
profiler.disable()
stats = pstats.Stats(profiler).sort_stats('cumtime')
stats.print_stats(5)
stats.print_stats(&quot;easyToFindLabel&quot;)
</code></pre>
<p>This yields:</p>
<pre><code>348788 function calls (323538 primitive calls) in 0.565 seconds

   Ordered by: cumulative time
   List reduced from 1272 to 5 due to restriction &lt;5&gt;

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        2    0.000    0.000    0.565    0.283 C:\Users\lxx\Anaconda3\envs\new_test\lib\site-packages\IPython\core\interactiveshell.py:3396(run_code)
      4/2    0.000    0.000    0.565    0.283 {built-in method builtins.exec}
        1    0.000    0.000    0.565    0.565 &lt;ipython-input-5-5fa3a402c436&gt;:17(&lt;module&gt;)
     11/1    0.000    0.000    0.565    0.565 C:\Users\lxx\Anaconda3\envs\new_test\lib\site-packages\tensorflow\python\eager\def_function.py:757(__call__)
     11/1    0.000    0.000    0.565    0.565 C:\Users\lxx\Anaconda3\envs\new_test\lib\site-packages\tensorflow\python\eager\def_function.py:798(_call)


348788 function calls (323538 primitive calls) in 0.565 seconds

   Ordered by: cumulative time
   List reduced from 1272 to 2 due to restriction &lt;'easyToFindLabel'&gt;

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.085    0.085 C:\Users\lxx\AppData\Local\Temp\tmpmvjs_747.py:6(tf__test_profiler_easyToFindLabel)
        1    0.000    0.000    0.001    0.001 C:\Users\lxx\AppData\Local\Temp\tmp5zd7ybjs.py:6(tf__costly_expression_easyToFindLabel)
</code></pre>
",2021-06-07 13:29:19,15746088,59,https://stackoverflow.com/questions/67872566,Documentation Replicability
67947583,"Defining a callable ""loss"" function","<p>I am trying to optimize a loss function (defined using evidence lower bound) with <code>tf.train.AdamOptimizer.minimize()</code> on Tensorflow version <code>1.15.2</code> with eager execution enabled. I tried the following:</p>
<pre><code>learning_rate = 0.01
optim = tf.train.AdamOptimizer(learning_rate=learning_rate)
train_op = optim.minimize(loss)
</code></pre>
<p>and got the following : <code>RuntimeError: &quot;loss&quot; passed to Optimizer.compute_gradients should be a function when eager execution is enabled.</code></p>
<p>This works fine if I disable eager execution but since I need to save a tensorflow variable as a <code>numpy</code> array so I need eager execution enabled. The documentation mentions that when eager execution is enabled, the loss must be a <strong>callable</strong>. So the loss function should be defined in a way that it takes no inputs but gives out loss. I am not exactly sure how do I achieve such a thing.</p>
<p>I tried <code>train_op = optim.minimize(lambda: loss)</code> but got <code>ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [] and loss &lt;function &lt;lambda&gt; at 0x7f3c67a93b00&gt;</code></p>
",2021-06-12 09:45:30,6639856,332,https://stackoverflow.com/questions/67947583,Documentation Replication on Other Examples
68002490,Make tf.nn.conv2d_transpose in Pytorch,"<p>My question is how to make operation of <code>tf.nn.conv2d_transpose</code> in <a href=""/questions/tagged/pytorch"" class=""post-tag"" title=""show questions tagged &#39;pytorch&#39;"" rel=""tag"">pytorch</a>.</p>
<p>See the example below:</p>
<pre><code>np.random.seed(42)
y_val = np.random.rand(1, 32, 32, 1024)
feats_val = np.random.rand(3, 3, 128, 1024)

y_tf = tf.Variable(y_val)
feats_tf = tf.Variable(feats_val)

y_tor = torch.tensor(y_val)
feats_tor = torch.tensor(feats_val)

y_up_tf = tf.nn.conv2d_transpose(y_tf, feats_tf, [1, 64, 64, 128], strides=[1,2,2,1])
</code></pre>
<p>I want to get the same result than <code>y_up_tf</code> using <code>y_tor</code> and <code>feats_tor</code> in Pytorch.</p>
",2021-06-16 12:16:46,16243152,23,https://stackoverflow.com/questions/68002490,Documentation Replicability
68095664,problem in converting tensorflow 1.x code to tensorflow 2.x,"<p>I have a code in tf 1.x which I have converted in tf 2.x using 'tf upgrade v2.....' command but
there is 1 segment which I am having trouble in converting,i.e.</p>
<pre><code>x=tf.placeholder(tf.float32, [None, None, None, 4])
y=tf.placeholder(tf.float32, [None, None, None, 3])
</code></pre>
<p>I want to change the above two lines such that eager execution is not disabled</p>
<p>and one more line which is:</p>
<pre><code>conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')
</code></pre>
<p>In the above line I don't want to use keras.layers.conv2D but I want to use tf.nn.conv2d().</p>
",2021-06-23 07:46:29,16296144,11,https://stackoverflow.com/questions/68095664,Documentation Replicability
68162847,Wrapping image_data_generator.flow_from_dataframe in tf.data pipeline.. what step should I take?,"<pre><code>train_generator=datagen.flow_from_dataframe(dataframe=train_df, #directory=data_path, 
                                            x_col=&quot;Path&quot;, y_col=&quot;feature_string&quot;, seed = 42, classes = chexpert_targets,
                                            class_mode=&quot;categorical&quot;, target_size=(image_size,image_size), batch_size=32, subset = &quot;training&quot;)

validation_generator = datagen.flow_from_dataframe(dataframe=train_df, #directory=data_path, 
                                                   x_col=&quot;Path&quot;, y_col=&quot;feature_string&quot;, seed = 42, classes = chexpert_targets,
                                                      class_mode=&quot;categorical&quot;, target_size=(image_size,image_size), batch_size=16, subset = &quot;validation&quot;)
    
test_generator = test_datagen.flow_from_dataframe(dataframe=valid_only_df, #directory=data_path, 
                                                  target_size=(image_size,image_size),class_mode='categorical',
                                                  batch_size=1, shuffle=False, classes = chexpert_targets,
                                                  x_col=&quot;Path&quot;, y_col=&quot;feature_string&quot;)
    
x_col, y_col = next(train_generator)
ds = tf.data.Dataset.from_generator(
    lambda: train_generator, 
    output_types=(tf.float32, tf.float32), 
    output_shapes=([32,320,320,3], [32,14])
)
</code></pre>
<p>I am trying to wrap the <code>image_data_generator.flow_from_dataframe</code> using <code>tf.data</code> but I am finding difficulties, I would really appreciate some help?</p>
",2021-06-28 11:48:57,13430221,13,https://stackoverflow.com/questions/68162847,Documentation Replicability
68217076,How to parse a tfds.features.Sequence object ? It is not compatible with tf.io.FixedLenSequenceFeature,"<p>Recently I was trying to train a model on the Wider-Face Dataset. I found it is prebuilt into tfds (<a href=""https://www.tensorflow.org/datasets/catalog/wider_face"" rel=""nofollow noreferrer"">https://www.tensorflow.org/datasets/catalog/wider_face</a>). However I am having difficulty parsing it. It's feature map is of the following form -</p>
<pre><code>FeaturesDict({
'faces': Sequence({
    'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),
    'blur': tf.uint8,
    'expression': tf.bool,
    'illumination': tf.bool,
    'invalid': tf.bool,
    'occlusion': tf.uint8,
    'pose': tf.bool,
}),
'image': Image(shape=(None, None, 3), dtype=tf.uint8),
'image/filename': Text(shape=(), dtype=tf.string),})
</code></pre>
<p>So I passed the following nested dictionary to tf.io.parse_single_example</p>
<pre><code>feature_description = {'faces': {
    'bbox': tf.io.FixedLenFeature([], dtype=tf.float32),
    'blur': tf.io.FixedLenFeature([], dtype=tf.uint8),
    'expression': tf.io.FixedLenFeature([], dtype=tf.bool),
    'illumination': tf.io.FixedLenFeature([], dtype=tf.bool),
    'invalid': tf.io.FixedLenFeature([], dtype=tf.bool),
    'occlusion': tf.io.FixedLenFeature([], dtype=tf.uint8),
    'pose': tf.io.FixedLenFeature([], dtype=tf.bool),
},
'image': tf.io.FixedLenFeature([], dtype=tf.uint8),
'image/filename': tf.io.FixedLenFeature([], dtype=tf.string),} 
</code></pre>
<p>But it gives me a value error of ValueError: Unsupported dict. Later I also learnt that Sequence does not support features which are of type tf.io.FixedLenSequenceFeature.</p>
<p>Please let me know how can I parse this type of TFRecords. I didn't find much documentation of how to use the object detection datasets that are build into Tensorflow, so providing some links with examples will also be helpful.</p>
<p>Thanks</p>
",2021-07-01 21:21:10,16361344,545,https://stackoverflow.com/questions/68217076,Inadequate Examples
68319579,tfa.optimizers.MultiOptimizer - TypeError: 'Not JSON Serializable:',"<p>I'm trying to use tfa.optimizers.MultiOptimizer(). I did everything according to the docs (<a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/MultiOptimizer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/MultiOptimizer</a>) yet I'm getting the following error:</p>
<p>TypeError: ('Not JSON Serializable:', &lt;tf.Tensor 'gradient_tape/model_80/dense_3/Tensordot/MatMul/MatMul:0' shape=(1, 1) dtype=float32&gt;)</p>
<p>Below is a minimal, working example that reproduces the error, just copy and paste it. The error occurs when the first epoch is finished and the callback trys to save the model.</p>
<pre><code>##############################################################################

import tensorflow as tf
import tensorflow_addons as tfa
import tensorflow.keras.layers as l
import tensorflow_addons.layers as la
import tensorflow.keras as ke
import numpy as np

##############################################################################

def build_model_1():

    model_input = l.Input(shape=(32,1))

    x = l.Dense(1)(model_input)

    model = ke.Model(inputs=model_input, outputs=x)

##########  
    
    optimizers = [tf.keras.optimizers.Adam(),
                  tf.keras.optimizers.Adam()]
    
    optimizers_and_layers = [(optimizers[0], model.layers[:5]), (optimizers[1], model.layers[5:])]
    
    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)
    
    model.compile(optimizer=optimizer, loss='mse', metrics='mse')

    test = tf.keras.optimizers.serialize(optimizer)

    return model

##############################################################################

input_data =  np.arange( 0, 10000, 1).reshape(10000,1)
target_data = np.arange(-10000, 0, 1).reshape(10000,1)

model = build_model_1()

model_checkpoint = ke.callbacks.ModelCheckpoint('best_model.h5',
                                                monitor='val_mse',
                                                mode='min',
                                                save_best_only=True,
                                                verbose=1)

training_history = model.fit(x = input_data,
                             y = target_data,
                             validation_split = 0.2,
                             epochs = 5,
                             verbose = 1,
                             callbacks = [model_checkpoint])
    
##############################################################################
</code></pre>
",2021-07-09 15:51:58,16300082,13,https://stackoverflow.com/questions/68319579,Documentation Replicability
68354367,Getting an error when using tf.keras.metrics.Mean in functional Keras API,"<p>I'm trying to add a Mean metric to a Keras functional model (Tensorflow 2.5), and am getting the following error:</p>
<pre><code>ValueError: Expected a symbolic Tensor for the metric value, received: tf.Tensor(0.0, shape=(), dtype=float32)
</code></pre>
<p>Here is the code:</p>
<pre><code>x = [1, 2, 3, 4, 5, 6, 7, 8]
y = [5 + i * 3 for i in x]
a = Input(shape=(1,))
output = Dense(1)(a)
model = Model(inputs=a,outputs=output)
model.add_metric(tf.keras.metrics.Mean()(output))
model.compile(loss='mse')
model.fit(x=x, y=y, epochs=100)
</code></pre>
<p>If I remove the following line (from which the exception is thrown):</p>
<pre><code>model.add_metric(tf.keras.metrics.Mean()(output))
</code></pre>
<p>the code works as expected.
<br><br>I Tried disabling eager execution, but I get the following error instead:</p>
<pre><code>ValueError: Using the result of calling a `Metric` object when calling `add_metric` on a Functional Model is not supported. Please pass the Tensor to monitor directly.
</code></pre>
<p>The above usage was pretty much copied from the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Mean"" rel=""nofollow noreferrer"">tf.keras.metrics.Mean</a> documentation (see <em>Usage with compile() API</em>)</p>
",2021-07-12 22:09:01,6133787,361,https://stackoverflow.com/questions/68354367,Lack of Alternative Solutions/Documentation
68367159,Adding inputs to a `tf.data.generator` in tensorflow.js,"<p>I'm trying to create a data generator, which I verified was working by itself in pure js. TFJS documentation for it is here, with two examples:
<a href=""https://js.tensorflow.org/api/latest/#data.generator"" rel=""nofollow noreferrer"">https://js.tensorflow.org/api/latest/#data.generator</a></p>
<p>I'd like to use a <code>tf.data.generator</code> as this datasets requires elaborate preprocessing. A minimal example is as follows:</p>
<pre class=""lang-js prettyprint-override""><code>const tf = require('@tensorflow/tfjs-node');
class dataGeneratorGenerator {
    constructor(test) {
        this.test = test
    }
    * dataGenerator() {
        let len = this.test.length
        let idx = 0
        while (idx &lt; len) {
            idx++
            console.log(idx)
            yield this.test[idx]
        }
    }
}
let dgg = new dataGeneratorGenerator(['hi', 'hi2', 'hi3'])
let trainDs = tf.data.generator(dgg.dataGenerator);
trainDs.forEachAsync(e =&gt; console.log(e));
</code></pre>
<p>The error is as follows:</p>
<pre><code>TypeError: Error thrown while iterating through a dataset: Cannot read property 'test' of undefined
</code></pre>
<p>Iterating through our datagenerator in pure javascript works:</p>
<pre class=""lang-js prettyprint-override""><code>let dgg = new dataGeneratorGenerator(['hi', 'hi2', 'hi3'])
let dg = dgg.dataGenerator()
console.log(dgg.next())
console.log(dgg.next())
console.log(dgg.next())
</code></pre>
<p>My understanding is that we are only passing <code>dataGenerator</code> into <code>tf.data.generator</code> instead of the entire class. Then, how is it possible to input variables into <code>tf.data.generator</code>? Thanks.</p>
",2021-07-13 17:44:42,13610744,821,https://stackoverflow.com/questions/68367159,Documentation Ambiguity
68434740,"calculate the gradient wrt to multiple inputs using tf.gradienttape, but return none","<p>pre-trained DNN model takes two inputs, and I want to compute gradient of output wrt two inputs</p>
<pre><code>ta = tf.cast(input1,tf.float32) #ta in 2 dimension, tb in 3 dimension
tb = tf.cast(input2,tf.float32)
inp_tensor_list = [ta,tb]

with tf.GradientTape() as tape:
    pred = model(inp_tensor_list)  #pred return correct value here
grad = tape.gradient(pred, inp_tensor_list)
</code></pre>
<p>grad [none,none]</p>
<p>How to fix it? Thanks</p>
<p><strong>Solved Update</strong></p>
<p>use tf.Variable instead of tf.cast</p>
",2021-07-19 03:16:23,16477354,21,https://stackoverflow.com/questions/68434740,Documentation Replicability
68439286,Tensorflow tf.gfile.GFile,"<p>I have tried changing <code>tf.gfile.GFile</code> to tf.io.gfile.GFile and also tried <code>import tensorflow.compat.v1 as tf</code> but nothing worked. It is not reading the newly saved file. I have saved it after changes.</p>
<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-52-efc7822bb0d7&gt; in &lt;module&gt;
----&gt; 1 config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)

~/opt/anaconda3/lib/python3.8/site-packages/object_detection/utils/config_util.py in get_configs_from_pipeline_file(pipeline_config_path, config_override)
     94   &quot;&quot;&quot;
     95   pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()
---&gt; 96   with tf.gfile.GFile(pipeline_config_path, &quot;r&quot;) as f:
     97     proto_str = f.read()
     98     text_format.Merge(proto_str, pipeline_config)

AttributeError: module 'tensorflow' has no attribute 'gfile''''

</code></pre>
",2021-07-19 10:52:52,15998918,1,https://stackoverflow.com/questions/68439286,Documentation Replicability
68707494,Tensorflow assign sparse input over axis,"<p>I have sparse data over one axis, e.g.</p>
<pre><code>[[0,0,0],
 [1,2,3],
 [0,0,0],
 [0,0,0],
 [4,5,6]]
</code></pre>
<p>For efficiency, I would like to input batches in the format</p>
<pre><code>sparse_axes = [1,4]
sparse_data = [[1,2,3],[4,6,6]]
</code></pre>
<p>and in tensorflow, de-sparse that data.</p>
<p>I know there is the function <code>tf.sparse</code> but that doesn't work over axes, which is inefficient in this case. Is there a function in tensorflow to do something like this:</p>
<pre><code>&gt; dense_data = tf.zeros((5,3))
&gt; dense_data.assign(sparse_axes, sparse_data) # &lt;--- this is the function I am looking for. 
&gt; dense_data
[[0,0,0],
 [1,2,3],
 [0,0,0],
 [0,0,0],
 [4,5,6]]
</code></pre>
",2021-08-09 06:06:27,200663,1400,https://stackoverflow.com/questions/68707494,Documentation Replication on Other Examples
68782423,TensorFlow reshape after text_dataset_from_directory,"<p>After the data is loaded with tf.keras.preprocessing.text_dataset_from_directory, the shape is (10, 1). However, the shape needs to be (10,). How could the shape be changed?</p>
<pre><code>train_data = tf.keras.preprocessing.text_dataset_from_directory(
    &quot;data/text&quot;,
    batch_size=1)

train_features_batch, train_labels_batch = next(iter(train_data.batch(10)))
# (10, 1) (10, 1), but model needs (10,) (10,)
print(train_features_batch.shape, train_labels_batch.shape)


model = tf.keras.Sequential()
model.add(hub.KerasLayer(embedding, input_shape=[], trainable=True))
model.add(tf.keras.layers.Dense(16, activation=&quot;relu&quot;))
model.add(tf.keras.layers.Dense(1))
</code></pre>
",2021-08-14 10:26:07,14637258,309,https://stackoverflow.com/questions/68782423,Documentation Replicability
68869097,How to make Tensorflow checkpoints compatible between minor versions when using tf.keras.mixed_precision.experimental?,"<p>I'm new to Tensorflow so I'm learning about model saving/loading schemes. I am working with a library which provides a model checkpoint (.index and .data files only) which was saved in Tensorflow 2.2. I would like to load this checkpoint using the same library but with Tensorflow 2.6 so that it may be run in Google Colab. When I load the checkpoint in Tensorflow 2.2 (with associated CUDA version), the model works fine. However, if I load the same checkpoint in Tensorflow 2.6 (with latest CUDA versions), the model runs without throwing any errors but the output is completely different.</p>
<p>To note, the library does make use of some experimental API's which may be responsible for the version compatibility issues (as noted in the official guide <a href=""https://www.tensorflow.org/guide/versions#compatibility_of_graphs_and_checkpoints"" rel=""nofollow noreferrer"">here</a>). In particular, it uses <em>tensorflow.keras.mixed_precision.experimental</em> extensively, as well as <em>tf.config.experimental.set_memory_growth</em>, <em>tf.data.experimental.copy_to_device</em>, and <em>tf.data.experimental.AUTOTUNE</em>. Intuitively, <em>mixed_precision.experimental</em> seems likely to significantly impact the weight saving/loading across minor versions.</p>
<p>I do receive the following warnings. They disappear if I switch to using <em>tf.keras.mixed_precision</em> (no experimental), however the model output is still completely wrong.</p>
<blockquote>
<p>WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.<strong>init</strong> (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.</p>
</blockquote>
<blockquote>
<p>Instructions for updating: Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale</p>
</blockquote>
<blockquote>
<p>WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py:1361: NameBasedSaverStatus.<strong>init</strong> (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.</p>
</blockquote>
<blockquote>
<p>Instructions for updating: Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.</p>
</blockquote>
<p>Any recommendations for saving a mixed_precision model checkpoint so that it is compatible across minor versions? Or dealing with experimental Tensorflow API's in general?</p>
",2021-08-20 23:57:08,16580520,21,https://stackoverflow.com/questions/68869097,Documentation Replication on Other Examples
68878231,tf.gradients() vs tf.gradientTape.gradient() in graph mode,"<p>I had a question regarding the behavior of tf.gradients() as opposed tf.gradientTape.gradient() in graph mode.</p>
<p>Given a differentiable function y = f(x), where x and y are each single tensorflow tensors, is there any difference between the behavior of tf.gradient(y, x) vs tape.gradient(y, x) where tape is an instance of tf.gradientTape (assuming the use of graph mode) ?</p>
<p>Not sure why tensorflow has two different gradient methods which can be used with graph mode - maybe there are some subtle differences in the implementations? I’ve looked at the documentation for gradientTape and tf.gradients but it’s not clear whether there is any difference between the behavior of these methods for a single (x, y) pair, or whether it’s just that tf.gradients() can be used in this case for a speedup when using graph mode.</p>
<p>Thank you so much for your help!</p>
",2021-08-22 03:16:13,16569549,51,https://stackoverflow.com/questions/68878231,Documentation Replication on Other Examples
69344858,How do I get the first 3 max numbers from tensor,"<p>How do i get first 3 max number from <code>y_classe = tf.argmax(preds, axis=1, output_type=tf.int32)</code>?</p>
",2021-09-27 10:09:25,9591542,41,https://stackoverflow.com/questions/69344858,Documentation Replicability
69370662,How to get Value and Index number of tensor?,"<pre><code>preds = model([img_feat, ques_feat])
sorted_a = tf.sort(preds, direction='DESCENDING')
print(sorted_a[0][1])
</code></pre>
<p>It will print <code>tf.Tensor(0.35625213, shape=(), dtype=float32)</code>.</p>
<p>Here I just need the number 0.35625213 and its index.</p>
",2021-09-29 05:03:33,9591542,41,https://stackoverflow.com/questions/69370662,Documentation Replicability
69458522,What does tf.squeeze does to the audio and how can I load an mp3?,"<p>I'm using TensorFlow and I would like to be able to load audio and generate a spectrogram from it. I have little knowledge of how audio internally works.
Currently, this is the code I'm using:</p>
<pre><code>import pathlib
import tensorflow as tf
import tensorflow_io as tfio
import matplotlib.pyplot as plt

from IPython.display import Audio

data_dir = pathlib.Path('recordings')
sample_file = data_dir/'testA.mp3'
audio = tfio.audio.AudioIOTensor(str(sample_file))

# remove last dimension
audio_slice = audio[100:]
audio_tensor = tf.squeeze(audio_slice, axis=[-1])
#audio_tensor = audio.to_tensor()
tensor = tf.cast(audio_tensor, tf.float32) / 32768.0

print(&quot;Audio Tensor: &quot; + str(tensor))

plt.figure()
plt.plot(tensor.numpy())
plt.show()

# Convert to spectrogram
spectrogram = tfio.audio.spectrogram(tensor, nfft=512, window=512, stride=256)
    
plt.figure()
plt.imshow(tf.math.log(spectrogram).numpy())
plt.show()
</code></pre>
<p>I have been reading the documentation and in order to create a tensor I need to either use the tf.squeeze method or audio.to_tensor(). I have no clue what the tf.squeeze method does, but when I use it I get the error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 2 [Op:Squeeze]
</code></pre>
<p>If I instead use the method audio.to_tensor(), I'm unable to display the created spectrogram on the plt and instead I get the following error:</p>
<pre><code>TypeError: Invalid shape (28224, 1, 257) for image data
</code></pre>
",2021-10-06 00:12:25,4999534,121,https://stackoverflow.com/questions/69458522,Documentation Replication on Other Examples
69509388,TF BERT input packer on more than two inputs,"<p>Some of the TensorFlow examples using BERT models show a use of the BERT preprocessor to &quot;pack&quot; inputs. E.g. in <a href=""https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/bert_glue.ipynb"" rel=""nofollow noreferrer"">this example</a>,</p>
<p><code>text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok], tf.constant(20))</code></p>
<p>The documentation implies that this works equally well with more than two input sentences, such that (I would expect) one can do something like:</p>
<p><code>text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok, tok], tf.constant(20))</code></p>
<p>However, so doing causes the error at the bottom[1] of this post.</p>
<p>I get that there isn't a matching signature; if I read this correctly (and I may not!), there's a signature for a single input and one for two. But what's the recommended way to pack more than two sentences into input suitable for a classification task, as suggested in the above colab?</p>
<p>1.</p>
<pre><code>ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (2 total):
    * [tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(&quot;inputs:0&quot;, shape=(None,), dtype=int32), row_splits=Tensor(&quot;inputs_2:0&quot;, shape=(None,), dtype=int64)), row_splits=Tensor(&quot;inputs_1:0&quot;, shape=(2,), dtype=int64)), tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(&quot;inputs_3:0&quot;, shape=(None,), dtype=int32), row_splits=Tensor(&quot;inputs_5:0&quot;, shape=(None,), dtype=int64)), row_splits=Tensor(&quot;inputs_4:0&quot;, shape=(2,), dtype=int64)), tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(&quot;inputs_6:0&quot;, shape=(None,), dtype=int32), row_splits=Tensor(&quot;inputs_8:0&quot;, shape=(None,), dtype=int64)), row_splits=Tensor(&quot;inputs_7:0&quot;, shape=(2,), dtype=int64))]
    * Tensor(&quot;seq_length:0&quot;, shape=(), dtype=int32)
  Keyword arguments: {}

Expected these arguments to match one of the following 4 option(s):

Option 1:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}

Option 2:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}

Option 3:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64), RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}

Option 4:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}```
</code></pre>
",2021-10-09 18:11:22,211714,210,https://stackoverflow.com/questions/69509388,Inadequate Examples
69526735,Using tf.train.Feature and tf.train.Example with ragged tensors,"<p>How can we use <code>tf.train.Feature</code> and <code>tf.train.Example</code> to save Ragged Tensors to TFRecords?</p>
<p>I have this piece of code:</p>
<pre><code>d = [[], [1, 3], [5]]
d_tf = tf.ragged.constant(d)
</code></pre>
<p>How can I write it to TFRecords along with other regular tensors?</p>
<p>Normally I do something like:</p>
<pre><code>feature = {&quot;feat_name&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=feat_val))}
examples = tf.train.Example(features=tf.train.Features(feature=feature))
examples.SerializeToString()
</code></pre>
<p>Thanks</p>
",2021-10-11 13:06:22,11970084,985,https://stackoverflow.com/questions/69526735,Documentation Replication on Other Examples
69587392,How to apply map() when working with a batched Dataset?,"<p>I am creating a timeseries Dataset using <code>tf.keras.utils.timeseries_dataset_from_array</code>.
According to the docs, it returns a <code>tf.data.Dataset</code> instance.
I also pass the batch size argument when calling the <code>timeseries_dataset_from_array</code> function, so my dataset is a BatchDataset.
I am using map on this batched Dataset (<code>ds</code>), passing <code>my_fun</code>.
Data in the code below is a pandas dataframe containing continuous timesteps.</p>
<p>What does the <code>my_fun</code> function expect as input parameters - aka what does it apply on each iteration? Whole batches of shape (samples, sequence_length, features) or a single element of shape (None, sequence_length, features)?</p>
<p>I am confused because when I print the single argument that I define in my <code>my_fun</code> function, it yields a shape of (None, None, features), but I cannot inspect it further...</p>
<p>My code is inspired from the TF tutorial (see split_window function)
<a href=""https://www.tensorflow.org/tutorials/structured_data/time_series"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/structured_data/time_series</a></p>
<pre class=""lang-py prettyprint-override""><code>def split_window(self, features):
   inputs = features[:, self.input_slice, :]
   labels = features[:, self.labels_slice, :]
   if self.label_columns is not None:
     labels = tf.stack(
         [labels[:, :, self.column_indices[name]] for name in 
          self.label_columns],
             axis=-1)

   # Slicing doesn't preserve static shape information, so set the shapes
   # manually. This way the `tf.data.Datasets` are easier to inspect.
   inputs.set_shape([None, self.input_width, None])
   labels.set_shape([None, self.label_width, None])

   return inputs, labels

data = np.array(data, dtype=np.float32)
ds = timeseries_dataset_from_array(
        data=data,
        targets=None,
        sequence_length=24,
        sequence_stride=1,
        shuffle=True,
        batch_size=32)
 
ds = ds.map(split_window)
</code></pre>
",2021-10-15 15:49:52,17161135,121,https://stackoverflow.com/questions/69587392,Documentation Replication on Other Examples
69672777,Compute Hessian of lossfunction in Tensorflow,"<p>I would like to compute the hessian of a loss function of a neural network in Tensorflow with respect to all the parameters (or trainable variables). By modifying the example code from the Tensorflow documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/GradientTape</a>) I managed to compute the hessian w.r.t the weight matrix for the first layer (if I'm not mistaken):</p>
<pre><code>with tf.GradientTape(persistent=True) as tape:
    loss = tf.reduce_mean(model(x,training=True)**2)
    g = tape.gradient(loss,model.trainable_variables[0]) 
    h=tape.jacobian(g,model.trainable_variables[0])
</code></pre>
<p>If I try to compute it w.r.t model.trainable_variables instead the tape.jacobian complains that 'list object has no attribute shape'. I instead tried to flatten the model.trainable_variables and compute it w.r.t the flattened vector:</p>
<pre><code>with tf.GradientTape(persistent=True) as tape:
    loss = tf.reduce_mean(model(x,training=True)**2)
    source = tf.concat([tf.reshape(x,[-1]) for x in model.trainable_variables],axis=0)
    g = tape.gradient(loss,source) 
    h=tape.jacobian(g,source)
   
</code></pre>
<p>The problem now is that g is empty (NoneType) for some reason. I noticed that source is tf.Tensor-type but model.trainable_variables[0] was of type tf.ResourceVariable so I tried changing this by declaring source as</p>
<pre><code>source = resource_variable_ops.ResourceVariable(tf.concat([tf.reshape(x,[-1]) for x in model.trainable_variables],axis=0))
</code></pre>
<p>This didn't change anything though, so I'm guessing that this is not the issue. I also thought that the problem might be that the source-variable is not watched, but it seems that it is set to trainable and even if i do tape.watch(source), g is still empty.</p>
<p>Does anybody know how I can solve this?</p>
",2021-10-22 07:16:21,9163968,211,https://stackoverflow.com/questions/69672777,Documentation Replication on Other Examples
69777802,How to create the same structure of tf.data.experimental.make_csv_dataset from pandas,"<p><code>tf.data.experimental.make_csv_dataset</code> creates a TF Dataset ready for Kears supervised training.</p>
<pre><code>titanic_file = tf.keras.utils.get_file(&quot;titanic_train.csv&quot;, &quot;https://storage.googleapis.com/tf-datasets/titanic/train.csv&quot;)
titanic = tf.data.experimental.make_csv_dataset(
    titanic_file,
    label_name=&quot;survived&quot;,
    batch_size=1,   # To compre with the head of CSV
    shuffle=False,  # To compre with the head of CSV
    header=True,
)
for row in titanic.take(1):  # Take the first batch 
    features = row[0]        # Diectionary
    label = row[1]
    
    for feature, value in features.items():
        print(f&quot;{feature:20s}: {value}&quot;)
    
    print(f&quot;label/survived      : {label}&quot;)    
-----
sex                 : [b'male']
age                 : [22.]
n_siblings_spouses  : [1]
parch               : [0]
fare                : [7.25]
class               : [b'Third']
deck                : [b'unknown']
embark_town         : [b'Southampton']
alone               : [b'n']
label/survived      : [0]
</code></pre>
<p>How to create the same from Pandas? Tried below but the label is dictionary instead of int32.</p>
<pre><code>df = pd.read_csv(titanic_file)
titanic_from_pandas = tf.data.Dataset.from_tensor_slices((
    dict(df.loc[:, df.columns != 'survived']),
    dict(df.loc[:, ['survived']])
))
for row in titanic_from_pandas.batch(1).take(1):  # Take the first batch 
    features = row[0]        # Diectionary
    label = row[1]
    
    for feature, value in features.items():
        print(f&quot;{feature:20s}: {value}&quot;)
    
    print(f&quot;label/survived      : {label}&quot;)    
---
sex                 : [b'male']
age                 : [22.]
n_siblings_spouses  : [1]
parch               : [0]
fare                : [7.25]
class               : [b'Third']
deck                : [b'unknown']
embark_town         : [b'Southampton']
alone               : [b'n']
label/survived      : {'survived': &lt;tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])&gt;}  &lt;-----
</code></pre>
<p>By the way, the data structure ready for Keras supervised training is (features, labels) but which document defines it?</p>
",2021-10-30 08:01:07,4281353,20088,https://stackoverflow.com/questions/69777802,Lack of Alternative Solutions/Documentation
69792031,Explanation of tf.keras.layers.CategoryEncoding output_mode='multi_hot' behavior,"<h1>Question</h1>
<p>Please help understand the definition of <strong>multi hot encoding</strong> of tf.keras.layers.CategoryEncoding and the behavior of <code>output_mode='multi_hot'</code>.</p>
<h1>Background</h1>
<p>According to <a href=""https://stats.stackexchange.com/a/467672"">What exactly is multi-hot encoding and how is it different from one-hot?</a>:</p>
<blockquote>
<p>If you would use multi-hot-encoding you would first label-encode your classes, thus having only a single number which represents the presence of a class (e.g. 1 for 'dog') and then convert the numerical labels to binary vectors of size log2(5)=3.<br />
Examples:</p>
<pre><code>'cat'  = [0,0,0]  
'dog'  = [0,0,1]  
'fish' = [0,1,0]  
'bird' = [0,1,1]  
'ant'  = [1,0,0]   
</code></pre>
</blockquote>
<h1>Behaviour of <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding"" rel=""nofollow noreferrer"">tf.keras.layers.CategoryEncoding</a></h1>
<p>The document says <code>num_tokens</code> is the total number of tokens the layer should support.</p>
<blockquote>
<h3>args</h3>
<h4>num_tokens</h4>
<p>The total number of tokens the layer should support. All inputs to the layer must integers in the range 0 &lt;= value &lt; num_tokens, or an error will be thrown.</p>
<h4>output_mode</h4>
<ul>
<li>&quot;one_hot&quot;: Encodes each individual element in the input into an array of num_tokens size, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output.</li>
<li>&quot;multi_hot&quot;: Encodes each sample in the input into <strong>a single array of num_tokens size, containing a 1 for each vocabulary term present in the sample</strong>. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens).</li>
</ul>
</blockquote>
<p>According to the definitions of multi hot encoding above, I expected <code>tf.keras.layers.CategoryEncoding(num_tokens=5, output_mode=&quot;multi_hot&quot;)</code> encodes 5 tokens into an array of size 3.</p>
<p>However, the document says &quot;multi_hot&quot; encodes each sample into <strong>a single array of num_tokens size</strong>, containing a 1 for each vocabulary term present in the sample, and behaves as such.</p>
<pre><code>dataset = tf.data.Dataset.from_tensor_slices(tf.constant(['cat', 'dog', 'fish', 'bird']))

lookup = tf.keras.layers.StringLookup(max_tokens=5, oov_token='[UNK]')
lookup.adapt(dataset)
lookup.get_vocabulary()
---
['[UNK]', 'fish', 'dog', 'cat', 'bird']

mhe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=&quot;multi_hot&quot;)
print(f&quot;cat: {mhe(lookup(tf.constant('cat'))).numpy()}&quot;)
print(f&quot;dog: {mhe(lookup(tf.constant('dog'))).numpy()}&quot;)
---
cat: [0. 0. 0. 1. 0.]
dog: [0. 0. 1. 0. 0.]
</code></pre>
<p>Which has no difference from One Hot Encoding.</p>
<pre><code>ohe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=&quot;one_hot&quot;)
print(f&quot;cat: {ohe(lookup(tf.constant('cat'))).numpy()}&quot;)
print(f&quot;dog: {ohe(lookup(tf.constant('dog'))).numpy()}&quot;)
---
cat: [0. 0. 0. 1. 0.]
dog: [0. 0. 1. 0. 0.]
</code></pre>
<p>For multi value inputs, multi_hot only handles the first value.</p>
<pre><code>print(ohe(lookup(tf.constant(['cat', 'dog']))).numpy())
---
[[0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0.]]

print(mhe(lookup(tf.constant(['cat', 'dog']))).numpy())
---
[0. 0. 1. 1. 0.]
</code></pre>
<p>To handle multiple inputs, need to be 2D array.</p>
<pre><code>print(mhe(lookup(tf.constant([['cat'], ['dog']]))).numpy())
---
[[0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0.]]
</code></pre>
<p>Apparently the definition of <strong>multi hot encoding</strong> of <code>tf.keras.layers.CategoryEncoding</code> is not the same with the one in <a href=""https://stats.stackexchange.com/a/467672"">What exactly is multi-hot encoding and how is it different from one-hot?</a>.</p>
<h1>Related</h1>
<ul>
<li><a href=""https://github.com/tensorflow/tensorflow/issues/52892"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/52892</a></li>
</ul>
",2021-11-01 02:11:57,4281353,20088,https://stackoverflow.com/questions/69792031,Lack of Alternative Solutions/Documentation
69843239,How does tf.keras.util.array_to_image() work with regards to memory?,"<p>I have image data that I want to use in a TensorFlow model, but I have to retrieve the image as an (Numpy) array of pixel values. From what I've read, TensorFlow has to read an image in as some image format and from some location. I know that <code>tf.keras.util.array_to_image()</code> can convert an array to a PIL instance of an image, and I know that there are several other libraries that have similar functionality, such as <code>PIL.Image.fromarray()</code>.</p>
<p>My problem is that I don't want to duplicate the image data by copying it to a new format. The API documentation for the <code>tf.keras.util.array_to_image()</code> says that it returns a &quot;PIL image instance&quot;. Does that mean that it is copying all array values to a new data structure and returning that, or is it creating an image data structure that references the original array pixel values?</p>
<p>As a follow-up question, if the keras method does duplicate the data (by having both the original array and the image instance have independent values), is there a way to have TensorFlow accept an array representation of an image without needing to duplicate it as a separate image file?</p>
",2021-11-04 17:10:04,11626498,33,https://stackoverflow.com/questions/69843239,Documentation Replication on Other Examples
69942590,Load tf.data.Dataset with dynamic batch size,"<p>I am wondering if there is a way to load <code>tf.data.Dataset</code> with dynamic batch size instead of using fixed size like in <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch"" rel=""nofollow noreferrer"">here</a>?
Thanks</p>
",2021-11-12 11:57:52,11970084,985,https://stackoverflow.com/questions/69942590,Documentation Replicability
70196272,Overcoming incompatibilities between tensorflow 1.x and 2.x when trying to view layer activity with backend,"<p>I would like to run newer tensorflow routines like:</p>
<pre><code>    from tensorflow.keras.preprocessing import image_dataset_from_directory
</code></pre>
<p>for which I get error in 1.x:</p>
<p>ImportError: cannot import name image_dataset_from_directory</p>
<p>while preserving older functionality of 1.x like running the routine to see activations in various layers like:</p>
<pre><code>    K=tf.keras.backend
    func = K.function([base_model.input, K.learning_phase()],[layer.output for layer in base_model.layers if layer.output is not base_model.input]) 
</code></pre>
<p>for which I get the following error in tf 2.x:</p>
<p>ValueError: Input tensors to a Functional must come from <code>tf.keras.Input</code>. Received: 0 (missing previous layer metadata).</p>
<p>The code:</p>
<pre><code>    import tensorflow as tf
    from tensorflow.keras.preprocessing import image_dataset_from_directory

    IMG_SHAPE = (160, 160) + (3,)
    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                                   include_top=False,
                                                   weights='imagenet')

    K=tf.keras.backend
    func = K.function([base_model.input, K.learning_phase()],[layer.output for layer in base_model.layers if layer.output is not base_model.input])
</code></pre>
<p>The documentation I looked at suggests the problem may have something to do with eager computation mode eg <a href=""https://github.com/tensorflow/tensorflow/issues/34201"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/34201</a></p>
<p>But I cannot figure out how to resolve this.
Thank you for suggestions!</p>
",2021-12-02 08:33:52,11726927,11,https://stackoverflow.com/questions/70196272,Lack of Alternative Solutions/Documentation
70219114,Define a tensor of constants for tf.while_loop,"<p>I want to somehow maintain a list of constants in <code>tf.while_loop</code> that can support the following functions</p>
<ol>
<li>I am able to read and write (multiple times) a constant value at an index</li>
<li>I am able to run <code>tf.cond</code> on it by checking its value at an index vs some constant</li>
</ol>
<p><code>TensorArray</code> would not work here since it does not support rewrites.
What other options do I have?</p>
",2021-12-03 18:29:46,14370198,197,https://stackoverflow.com/questions/70219114,Documentation Replicability
70303232,why am i getting a tensorflow warning when running this script?,"<pre><code>import glob
import os
from mtcnn.mtcnn import MTCNN
import warnings
import time

from numpy import asarray
from PIL import Image
#warnings.filterwarnings(&quot;ignore&quot;)
#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

directory = input(&quot;insert input path \n&quot;)

output_directory = input(&quot;insert output path \n&quot;)
#mode=input(&quot;do you want to conver the outputs to Grayscale ?&quot;)
img_names=glob.glob(os.path.join(directory+&quot;/*.jpg&quot;))

detector = MTCNN()
def process_image(img_name,mode='L',output_size=(160,160)):
    img = Image.open(directory+img_name)
    img.thumbnail((160,160))
    pixels=asarray(img)
    results = detector.detect_faces(pixels)
    if results:
        # extract the bounding box from the requested face
        x1 ,y1,width,height=results[0]['box']
        x1,y1=abs(x1),abs(y1)
        x2,y2=x1 + width,y1 + height
        # extract the face by slicing
        face_boundary = pixels[y1:y2, x1:x2]
        # resize pixels to the model size
        #image1 = Image.fromarray(face_boundary)
        #image1 = image.resize(required_size)
        image=Image.fromarray(face_boundary)
        #if mode=='L':
         #   image=image.convert('L')
        image = image.resize(output_size)
        #image.thumbnail((160,160))
        #image = image.resize(())
        #face_array = asarray(image)
    #image.save(f&quot;/kaggle/input/rashaa/rasha{img_name}&quot;)
        image.save(f'{output_directory}{img_name}')     
        print(f'{img_name} was processed...')
#for img in img_names:
 #       x.append(img.replace(directory,&quot;&quot;))
x=[img.replace(directory,&quot;&quot;) for img in img_names]
t1 = time.perf_counter()
y=[process_image(img) for img in x]

t2=time.perf_counter()
print(t2-t1)
</code></pre>
<p>the code does the job by detecting and extracting the faces from the input folder and putting the extracted faces in the output folder without any issues
but i wanna know why is this warning is showing up in the first place and is there any way i can fix it &quot;properly&quot; instead of suppressing it</p>
<p><strong>details</strong></p>
<ul>
<li><p>TensorFlow version (CPU):2.7.0</p>
</li>
<li><p>python version 3.8.4</p>
</li>
</ul>
<p>the warning message is <strong>WARNING:tensorflow:5 out of the last 9 calls to &lt;function Model.make_predict_function..predict_function at 0x0000000013E161F0&gt; triggered tf.function retracing. Tracing
is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python
objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument
shapes that can avoid unnecessary retracing. For (3), please refer to <a href=""https://www.tensorflow.org/guide/function#controlling_retracing"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/function#controlling_retracing</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/function</a> for  more details.</strong></p>
",2021-12-10 10:42:13,10662486,9,https://stackoverflow.com/questions/70303232,Documentation Replication on Other Examples
70319286,Question about Google Colab Transformer Tutorial,"<p>I'm trying to follow the Tensorflow Transformer tutorial here:</p>
<p><a href=""https://github.com/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb"" rel=""nofollow noreferrer"">https://github.com/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb</a></p>
<p>In the tutorial, they reproduce the image of the Transformer model from the original &quot;Attention is All You Need&quot; paper. In the image the final layers of the Transformer model are a Dense layer followed by Softmax Activation. However in the code I only see something like this:</p>
<p><code>self.final_layer = tf.keras.layers.Dense(target_vocab_size)</code></p>
<p>where the Dense layer is defined. But I cannot find the Softmax Activation applied anywhere in the tutorial.</p>
<p>What am I missing? Thanks in advance for your assistance.</p>
",2021-12-11 21:43:23,11470040,1,https://stackoverflow.com/questions/70319286,Lack of Alternative Solutions/Documentation
70328363,Extra dimension to MaxPool1D layer from Conv1D layer,"<p>I'm very new to Tensorflow (this is my first project using it), and I don't really understand how input shapes work. I am trying to train a CNN-LSTM on a set of financial time series data.</p>
<p>For my use case, I have a <code>tf.keras.data.DataLoader</code> object which is meant to serve batches of training data to the model.</p>
<p>One training instance corresponds to the price history over the last 30 days, and hence should have shape <code>(30,)</code>.</p>
<p>running the following code:</p>
<pre><code>for x, y in train_ds:
    print(x, y)
    print(x.shape)
    break
</code></pre>
<p>I get that <code>x.shape</code> is <code>(4, 30)</code>, where the <code>Dataset</code> object I have defined serves training instances in batches of 4.</p>
<p>Here is my code:</p>
<pre><code># driver code for experiments
import keras
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from keras import layers

WIDTH = 30
BATCH_SIZE = 4

# load datasets (prepended with 'n' for 'normalized' )

nXtrain = np.load('cad_90s_nXtrain.npy')
nytrain = np.load('cad_90s_nytrain.npy')
nXval = np.load('cad_90s_nXval.npy')
nyval = np.load('cad_90s_nyval.npy')
nXtest = np.load('cad_90s_nXtest.npy')
nytest = np.load('cad_90s_nytest.npy')

# instantiate tensorflow Datasets
train_ds = tf.data.Dataset.from_tensor_slices((nXtrain, nytrain)).batch(BATCH_SIZE)
val_ds = tf.data.Dataset.from_tensor_slices((nXval, nyval)).batch(BATCH_SIZE)
test_ds = tf.data.Dataset.from_tensor_slices((nXtest, nytest)).batch(BATCH_SIZE)


input_shape = (BATCH_SIZE, WIDTH, 1 )

testnet = tf.keras.Sequential([
    layers.InputLayer(input_shape=input_shape),
    layers.Conv1D(filters=32,
                  kernel_size=3,
                  activation='tanh',
                  padding='same',
                  strides=1),
    layers.MaxPool1D(pool_size=2,
                     padding='same'),
    layers.ReLU(),
    layers.LSTM(units=64, dropout=0.2, activation='tanh'),
    layers.Dense(units=1)
])

testnet.build()
testnet.summary()
</code></pre>
<p>with accompanying error message:</p>
<pre><code>ValueError: Input 0 of layer &quot;max_pooling1d&quot; is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 4, 30, 32)

</code></pre>
<p>I don't understand what's going on--why is there an extra dimension coming out of the <code>Conv1D</code> layer? I mean, should the output of 1-D convolution not simply be
<code>(BATCH_SIZE, WIDTH, 32)</code> (padding was set to <code>'same'</code>)?</p>
<p>I apologize if this is addressed in the documentation, but I have been looking everywhere for an answer and I can't seem to fix this problem. I would really appreciate some help here.</p>
<p>Thanks!</p>
",2021-12-12 22:57:00,8163401,289,https://stackoverflow.com/questions/70328363,Lack of Alternative Solutions/Documentation
70363340,Question about tensorflow.tile with a tensor of 5 dimensions,"<p>I'm trying to understand the following thing from an implementation of a paper I'm currently reading:</p>
<p>In <code>tensorflow</code>, if I have a tensor <code>x</code> of shape <code>(4,64,5,5)</code></p>
<ul>
<li><p>Then I create a new dimension by doing</p>
<pre><code>x = x[:,:,tf.newaxis]
</code></pre>
<p>ending with a new tensor of <code>shape</code> <code>(4,64,1,5,5)</code></p>
</li>
<li><p>Then I do</p>
<pre><code>x = tf.tile(x, (1, 1, 5, 1, 1))
</code></pre>
</li>
</ul>
<p>ending up with something of shape <code>(4,64,5,5,5)</code></p>
<p>Reading the documentation for <code>tf.tile</code>, I still don't understand what is it exactly doing in this case. Am I replicating the new dimension for 5 times? And if yes, what is exactly placed in the new dimension by tensorflow? What am I exactly replicating?</p>
",2021-12-15 11:59:51,14824108,596,https://stackoverflow.com/questions/70363340,Documentation Ambiguity
70381758,Equivalent of tf.linalg.diag_part in PyTorch,"<p>As I'm reimplementing some code, I'm wondering if there is any equivalent of <code>tf.linalg.diag_part</code> (<a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/diag"" rel=""nofollow noreferrer"">docs</a>) in <code>PyTorch</code> ..?</p>
",2021-12-16 15:37:56,14824108,596,https://stackoverflow.com/questions/70381758,Documentation Replicability
70399567,How to type a `tensorflow.data.Dataset`,"<p>I have some functions that accept instances of <code>tensorflow.data.Dataset</code>. I would like to type those functions so that the caller knows what is expected. However, doing <code>data: Dataset</code>, is not good enough, because people wouldn't know what kind of structure is produced by the object (shape of tensors, whether is tuple or dictionary, etc).</p>
<p>There is another object, <code>tensorflow.data.DatasetSpec</code>, which can be used to document the objects that will be produces by the <code>tensorflow.data.Dataset</code>. However, I am not sure how to put those things together for a typing annotation, and I am left to describe the structure in docstring, which I do not think is ideal.</p>
<p>I would love to see something like a generic, where you pass the type it accepts, like <code>Dataset[Spec]</code>(like in lists we do <code>List[int]</code>), but I am happy to learn some other ways to achieve more descriptive typing than just <code>data: tf.data.Dataset</code>.</p>
<p>Thanks a lot!</p>
",2021-12-17 22:45:02,4833773,507,https://stackoverflow.com/questions/70399567,Lack of Alternative Solutions/Documentation
70932051,How to improve the execution time of gradient estimation using tf.GradientTape in tensorflow 2.x,"<p><strong>The objective</strong> is to implement <a href=""https://web.casadi.org/blog/tensorflow/"" rel=""nofollow noreferrer"">https://web.casadi.org/blog/tensorflow/</a>, which was written using Tensorflow 1.x and gpflow 1.x, using Tensorflow 2.x and gpflow 2.x .</p>
<p>I have implemented it in Tensorflow 2.x (I attached them at the end of the question). However, still, I could not get as faster as the initial implementation, i.e., using Tensorflow 1.x and gpflow 1.x.</p>
<p>Here are execution time</p>
<p><strong>Using Tensorflow 1.x and gpflow 1.x.</strong></p>
<pre><code>  EXIT: Optimal Solution Found.
          solver  :   t_proc      (avg)   t_wall      (avg)    n_eval
           nlp_f  |  50.62ms (  1.63ms)  15.51ms (500.32us)        31
           nlp_g  |   4.16ms (134.16us)   4.15ms (133.90us)        31
      nlp_grad_f  | 216.76ms (  6.77ms) 153.84ms (  4.81ms)        32
       nlp_jac_g  |  21.29ms (665.25us)  21.46ms (670.63us)        32
           total  | 332.16ms (332.16ms) 233.83ms (233.83ms)         1
    Ncalls 63
    Total time [s] 0.08702826499938965
</code></pre>
<p><strong>Using Tensorflow 2.x and gpflow 2.x.</strong></p>
<pre><code> EXIT: Optimal Solution Found.
        solver  :   t_proc      (avg)   t_wall      (avg)    n_eval
         nlp_f  |  14.11ms (  1.76ms)   5.78ms (722.38us)         8
         nlp_g  |   1.03ms (129.00us)   1.05ms (130.77us)         8
    nlp_grad_f  |   1.23 s (136.79ms)   1.21 s (134.41ms)         9
     nlp_jac_g  |   6.03ms (670.00us)   6.03ms (670.34us)         9
         total  |   1.26 s (  1.26 s)   1.23 s (  1.23 s)         1
  Ncalls 17
  Total time [s] 0.8965554237365723
</code></pre>
<p>According to these execution times, it mainly depends on the gradient estimation <strong>nlp_grad_f</strong>. Tensorflow 1.x uses <strong>graph-based</strong> gradient estimation which seems to be rather faster than <strong>Tensorflow 2.x tf.GradientTape</strong></p>
<p><strong>My question</strong> as follows:
What's the proper way to implement the gradient estimation in Tensorflow 2.x or how to improve this code further? I've checked <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/function</a> and what I could to make it faster. I want it to reduce as faster as I get in Tensorflow 1.x.</p>
<pre><code>    @tf.function
    def f_k(input_dat, get_grad_val=None):
        xf_tensor = input_dat
        if(get_grad_val is not None):
            with tf.GradientTape(persistent=True) as tape:
                tape.watch(xf_tensor)
                mean, _ = model.predict_y(xf_tensor)
            grad_mean = tape.gradient(mean, xf_tensor, output_gradients=get_grad_val)
        else:
            mean, _ = model.predict_y(xf_tensor)
            grad_mean = None
        return mean, grad_mean
</code></pre>
<p>For reference, I include all the codebase, in case someone wants to execute and see it.</p>
<p><strong>ocp.py</strong></p>
<pre><code>from casadi import *
T = 10. # Time horizon
N = 20 # number of control intervals

# Declare model variables
x1 = MX.sym('x1')
x2 = MX.sym('x2')
x = vertcat(x1, x2)
u = MX.sym('u')

# Model equations
xdot = vertcat((1-x2**2)*x1 - x2 + u, x1)


# Formulate discrete time dynamics
if False:
   # CVODES from the SUNDIALS suite
   dae = {'x':x, 'p':u, 'ode':xdot}
   opts = {'tf':T/N}
   F = integrator('F', 'cvodes', dae, opts)
else:
   # Fixed step Runge-Kutta 4 integrator
   M = 4 # RK4 steps per interval
   DT = T/N/M
   f = Function('f', [x, u], [xdot])
   X0 = MX.sym('X0', 2)
   U = MX.sym('U')
   X = X0
   Q = 0
   for j in range(M):
       k1 = f(X, U)
       k2 = f(X + DT/2 * k1, U)
       k3 = f(X + DT/2 * k2, U)
       k4 = f(X + DT * k3, U)
       X=X+DT/6*(k1 +2*k2 +2*k3 +k4)
   F = Function('F', [X0, U], [X],['x0','p'],['xf'])

# Start with an empty NLP
w=[]
w0 = []
lbw = []
ubw = []
g=[]
lbg = []
ubg = []

# &quot;Lift&quot; initial conditions
Xk = MX.sym('X0', 2)
w += [Xk]
lbw += [0, 1]
ubw += [0, 1]
w0 += [0, 1]

# Formulate the NLP
for k in range(N):
    # New NLP variable for the control
    Uk = MX.sym('U_' + str(k))
    w   += [Uk]
    lbw += [-1]
    ubw += [1]
    w0  += [0]

    # Integrate till the end of the interval
    Fk = F(x0=Xk, p=Uk)
    Xk_end = Fk['xf']

    # New NLP variable for state at end of interval
    Xk = MX.sym('X_' + str(k+1), 2)
    w   += [Xk]
    lbw += [-0.25, -inf]
    ubw += [  inf,  inf]
    w0  += [0, 0]

    # Add equality constraint
    g   += [Xk_end-Xk]
    lbg += [0, 0]
    ubg += [0, 0]

nd = N+1

import gpflow
import time
import tensorflow as tf 
from tensorflow_casadi_mod_ocp import TensorFlowEvaluator

class GPR(TensorFlowEvaluator):
  def __init__(self, model, opts={}):
    initializer = tf.random_normal_initializer(mean=1., stddev=2.)
    X = tf.Variable(initializer(shape=[1,nd], dtype=tf.float64), trainable=False)

    @tf.function
    def f_k(input_dat, get_grad_val=None):
        xf_tensor = input_dat
        if(get_grad_val is not None):
            with tf.GradientTape(persistent=True) as tape:
                tape.watch(xf_tensor)
                mean, _ = model.predict_y(xf_tensor)
            grad_mean = tape.gradient(mean, xf_tensor, output_gradients=get_grad_val)
        else:
            mean, _ = model.predict_y(xf_tensor)
            grad_mean = None
        return mean, grad_mean
    
    TensorFlowEvaluator.__init__(self, [X], [f_k], model, opts=opts)
    self.counter = 0
    self.time = 0

  def eval(self,arg):
    self.counter += 1
    t0 = time.time()
    ret = TensorFlowEvaluator.eval(self, arg)
    self.time += time.time()-t0
    return [ret]



# Create
np.random.seed(0)
data = np.random.normal(loc=0.5,scale=1,size=(N,nd))
value = np.random.random((N,1))

model = gpflow.models.GPR(data=(data, value), kernel=gpflow.kernels.Constant(nd) + gpflow.kernels.Linear(nd) + gpflow.kernels.White(nd) + gpflow.kernels.RBF(nd))
optimizer = gpflow.optimizers.Scipy()
optimizer.minimize(
    model.training_loss,
    variables = model.trainable_variables,
    options=dict(disp=True, maxiter=100),
)

import tensorflow as tf

opts = {}
opts[&quot;output_dim&quot;] = [1, 1]
opts[&quot;grad_dim&quot;] = [1, nd]
GPR = GPR(model, opts=opts)
w = vertcat(*w)

# # Create an NLP solver
prob = {'f': GPR(w[0::3]), 'x': w , 'g': vertcat(*g)}
# options = {&quot;ipopt&quot;: {&quot;hessian_approximation&quot;: &quot;limited-memory&quot;}}
options = {&quot;ipopt&quot;: {&quot;hessian_approximation&quot;: &quot;limited-memory&quot;}}
solver = nlpsol('solver', 'ipopt', prob,options);
sol = solver(x0=w0, lbx=lbw, ubx=ubw, lbg=lbg, ubg=ubg)

print(&quot;Ncalls&quot;,GPR.counter)
print(&quot;Total time [s]&quot;,GPR.time)
w_opt = sol['x'].full().flatten()

# Plot the solution
x1_opt = w_opt[0::3]
x2_opt = w_opt[1::3]
u_opt = w_opt[2::3]

tgrid = [T/N*k for k in range(N+1)]
import matplotlib.pyplot as plt
plt.figure(1)
plt.clf()
plt.plot(tgrid, x1_opt, '--')
plt.plot(tgrid, x2_opt, '-')
plt.step(tgrid, vertcat(DM.nan(1), u_opt), '-.')
plt.xlabel('t')
plt.legend(['x1','x2','u'])
plt.grid()
plt.show()
</code></pre>
<p><strong>tensorflow_casadi_mod_ocp.py</strong></p>
<pre><code>import casadi as ca
import tensorflow as tf
from casadi import Sparsity
import gpflow 
import numpy as np

class TensorFlowEvaluator(ca.Callback):
  def __init__(self, t_in, t_out, model, set_init=False, opts={}):
  
    self.set_init = set_init
    self.opts = opts
    ca.Callback.__init__(self)
    assert isinstance(t_in,list)
    self.t_in = t_in
    assert isinstance(t_out, list)
    self.t_out = t_out
    self.output_shapes = []
    self.construct(&quot;TensorFlowEvaluator&quot;, {})
    self.refs = []
    self.model = model
    

  def get_n_in(self): return len(self.t_in)

  def get_n_out(self): return len(self.t_out)

  def get_sparsity_in(self, i):
      tesnor_shape = self.t_in[i].shape
      return Sparsity.dense(tesnor_shape[0], tesnor_shape[1])

  def get_sparsity_out(self, i):
      if(i == 0 and self.set_init is False):
        tensor_shape = [self.opts[&quot;output_dim&quot;][0], self.opts[&quot;output_dim&quot;][1]]
      elif (i == 0 and self.set_init is True):
        tensor_shape = [self.opts[&quot;grad_dim&quot;][0], self.opts[&quot;grad_dim&quot;][1]]
      else:
         tensor_shape = [self.opts[&quot;output_dim&quot;][0], self.opts[&quot;output_dim&quot;][1]]
      return Sparsity.dense(tensor_shape[0], tensor_shape[1])

  def eval(self, arg):
    updated_t = []
    for i,v in enumerate(self.t_in):
        updated_t.append(tf.Variable(arg[i].toarray()))
    if(len(updated_t) == 1):
      out_, grad_estimate = self.t_out[0](tf.convert_to_tensor(updated_t[0]))
    else:
      out_, grad_estimate = self.t_out[0](tf.convert_to_tensor(updated_t[0]), tf.convert_to_tensor(updated_t[1]))

    if(len(updated_t) == 1):
          selected_set =  out_.numpy() 
    else:
          selected_set = grad_estimate.numpy()
    return [selected_set]

  # Vanilla tensorflow offers just the reverse mode AD
  def has_reverse(self,nadj): return nadj==1
  
  def get_reverse(self, nadj, name, inames, onames, opts):
    initializer = tf.random_normal_initializer(mean=1., stddev=2.)
    adj_seed = [ tf.Variable(initializer(shape=self.sparsity_out(i).shape, dtype=tf.float64)) for i in range(self.n_out())]

    callback = TensorFlowEvaluator(self.t_in + adj_seed, [self.t_out[0]], self.model, set_init=True, opts=self.opts)
    self.refs.append(callback)

    nominal_in = self.mx_in()
    nominal_out = self.mx_out()
    adj_seed = self.mx_out()
    casadi_bal = callback.call(nominal_in + adj_seed)
    return ca.Function(name, nominal_in+nominal_out+adj_seed, casadi_bal, inames, onames)
</code></pre>
",2022-01-31 19:53:13,1574779,7522,https://stackoverflow.com/questions/70932051,Documentation Replication on Other Examples
70950860,How to update tf.contrib.layers.real_valued_column code to tf 2.0,"<p>I came across a Gaussian Kernel classifier tutorial in Python that utilizes tensorflow. In part of the tutorial,  <code>tf.contrib.layers.real_valued_column</code> is referenced. However, as far as I know,  <code>tf.contrib</code> is deprecated.</p>
<p>How can I change the statement to work in <code>tensorflow 2.0</code> ?</p>
<p>I tried using  <code>tf_slim</code> and  <code>tf.keras</code>, but I was unable to find the equivalent statements. Thanks in advance.</p>
",2022-02-02 05:26:16,18096774,1,https://stackoverflow.com/questions/70950860,Lack of Alternative Solutions/Documentation
71068368,"Tensorflow custom op, gpu kernel returns a tensor of zeros","<p>I am trying to implement a custom op and I am using the example in the <a href=""https://www.tensorflow.org/guide/create_op"" rel=""nofollow noreferrer"">official documentation</a> as a benchmark to test the correct compilation of the op, I've just modified the gpu kernel in order to see if it was actually executed but when I test the op it returns all zeros.</p>
<p>kernel_example.h</p>
<pre class=""lang-py prettyprint-override""><code>// kernel_example.h
#ifndef KERNEL_EXAMPLE_H_
#define KERNEL_EXAMPLE_H_

#include &lt;unsupported/Eigen/CXX11/Tensor&gt;

template &lt;typename Device, typename T&gt;
struct ExampleFunctor {
  void operator()(const Device&amp; d, int size, const T* in, T* out);
};

#if GOOGLE_CUDA
// Partially specialize functor for GpuDevice.
template &lt;typename T&gt;
struct ExampleFunctor&lt;Eigen::GpuDevice, T&gt; {
  void operator()(const Eigen::GpuDevice&amp; d, int size, const T* in, T* out);
};
#endif

#endif
</code></pre>
<p>kernel_example.cc</p>
<pre class=""lang-py prettyprint-override""><code>// kernel_example.cc
#include &quot;kernel_example.h&quot;

#include &quot;tensorflow/core/framework/op.h&quot;
#include &quot;tensorflow/core/framework/shape_inference.h&quot;
#include &quot;tensorflow/core/framework/op_kernel.h&quot;

using namespace tensorflow;

using CPUDevice = Eigen::ThreadPoolDevice;
using GPUDevice = Eigen::GpuDevice;

REGISTER_OP(&quot;Example&quot;)
    .Attr(&quot;T: numbertype&quot;)
    .Input(&quot;input: T&quot;)
    .Output(&quot;input_times_two: T&quot;)
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      c-&gt;set_output(0, c-&gt;input(0));
      return Status::OK();
    });

// CPU specialization of actual computation.
template &lt;typename T&gt;
struct ExampleFunctor&lt;CPUDevice, T&gt; {
  void operator()(const CPUDevice&amp; d, int size, const T* in, T* out) {
    for (int i = 0; i &lt; size; ++i) {
      out[i] = 2 * in[i];
    }
  }
};

// OpKernel definition.
// template parameter &lt;T&gt; is the datatype of the tensors.
template &lt;typename Device, typename T&gt;
class ExampleOp : public OpKernel {
 public:
  explicit ExampleOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor&amp; input_tensor = context-&gt;input(0);

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(),
                                                     &amp;output_tensor));

    // Do the computation.
    OP_REQUIRES(context, input_tensor.NumElements() &lt;= tensorflow::kint32max,
                errors::InvalidArgument(&quot;Too many elements in tensor&quot;));
    ExampleFunctor&lt;Device, T&gt;()(
        context-&gt;eigen_device&lt;Device&gt;(),
        static_cast&lt;int&gt;(input_tensor.NumElements()),
        input_tensor.flat&lt;T&gt;().data(),
        output_tensor-&gt;flat&lt;T&gt;().data());
  }
};

// Register the CPU kernels.
#define REGISTER_CPU(T)                                          \
  REGISTER_KERNEL_BUILDER(                                       \
      Name(&quot;Example&quot;).Device(DEVICE_CPU).TypeConstraint&lt;T&gt;(&quot;T&quot;), \
      ExampleOp&lt;CPUDevice, T&gt;);
REGISTER_CPU(float);
REGISTER_CPU(int32);

// Register the GPU kernels.
#ifdef GOOGLE_CUDA
#define REGISTER_GPU(T)                                          \
  /* Declare explicit instantiations in kernel_example.cu.cc. */ \
  extern template class ExampleFunctor&lt;GPUDevice, T&gt;;            \
  REGISTER_KERNEL_BUILDER(                                       \
      Name(&quot;Example&quot;).Device(DEVICE_GPU).TypeConstraint&lt;T&gt;(&quot;T&quot;), \
      ExampleOp&lt;GPUDevice, T&gt;);
REGISTER_GPU(float);
REGISTER_GPU(int32);
#endif  // GOOGLE_CUDA
</code></pre>
<p>kernel_example.cu.cc</p>
<pre class=""lang-py prettyprint-override""><code>// kernel_example.cu.cc
#ifdef GOOGLE_CUDA
#define EIGEN_USE_GPU
#include &quot;kernel_example.h&quot;
#include &quot;tensorflow/core/util/gpu_kernel_helper.h&quot;

using namespace tensorflow;

using GPUDevice = Eigen::GpuDevice;

// Define the CUDA kernel.
template &lt;typename T&gt;
__global__ void ExampleCudaKernel(const int size, const T* in, T* out) {
  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; size;
       i += blockDim.x * gridDim.x) {
    out[i] = 3 * __ldg(in + i); # modified to check if it is executed
  }
}

// Define the GPU implementation that launches the CUDA kernel.
template &lt;typename T&gt;
void ExampleFunctor&lt;GPUDevice, T&gt;::operator()(
    const GPUDevice&amp; d, int size, const T* in, T* out) {
  // Launch the cuda kernel.
  //
  // See core/util/gpu_kernel_helper.h for example of computing
  // block count and thread_per_block count.
  int block_count = 1024;
  int thread_per_block = 20;
  ExampleCudaKernel&lt;T&gt;
      &lt;&lt;&lt;block_count, thread_per_block, 0, d.stream()&gt;&gt;&gt;(size, in, out);
}

// Explicitly instantiate functors for the types of OpKernels registered.
template struct ExampleFunctor&lt;GPUDevice, float&gt;;
template struct ExampleFunctor&lt;GPUDevice, int32&gt;;

#endif  // GOOGLE_CUDA
</code></pre>
<p>To compile the op I use the following Makefile</p>
<pre><code># Makefile
TF_COM = `python -c &quot;import tensorflow as tf; print(' '.join(tf.sysconfig.get_compile_flags()))&quot;`
TF_INC = `python -c &quot;import tensorflow as tf; print(tf.sysconfig.get_include())&quot;`
TF_LIN = `python -c &quot;import tensorflow as tf; print(' '.join(tf.sysconfig.get_link_flags()))&quot;`

CC        = gcc -O2 -pthread
GPUDEF    = -D GOOGLE_CUDA=1

# nvcc: cuda kernel compilation to obtain .o file
GPUCC     = nvcc
GPUCFLAGS = -std=c++14 -I$(TF_INC) --expt-relaxed-constexpr -c
GPULFLAGS = -x cu -Xcompiler -fPIC

GPUSRC    = kernel_example.cu.cc
GPUPROD   = kernel_example.cu.o


# g++: combines the source .cc and the gpu prod .o to create a .so
CXX       = g++ -O2
CFLAGS    = -std=c++14 $(TF_COM)
LFLAGS    = -shared -fPIC $(TF_LIN) 
LCUDA     = -lcuda -L /usr/local/cuda-11.0/lib64/

SRC       = kernel_example.cc
PROD      = kernel_example.so


default: gpu

cpu:
    $(CXX) $(CFLAGS) $(SRC) $(LFLAGS) -o $(PROD)

gpu:
    $(GPUCC) $(GPUCFLAGS) $(GPUSRC) $(GPULFLAGS) $(GPUDEF) -o $(GPUPROD)
    $(CXX) $(CFLAGS) $(SRC) $(GPUPROD) $(LFLAGS) $(LCUDA) $(GPUDEF) -o $(PROD)

clean:
    rm -f $(PROD) $(GPUPROD)
</code></pre>
<p>I'm currently working directly on google Colab, loading the previous files in <code>/content</code> and running the compilation with the following lines</p>
<pre><code>!mkdir -p /usr/local/lib/python3.7/dist-packages/tensorflow/include/third_party/gpus/cuda/
!ln -s /usr/local/cuda/include /usr/local/lib/python3.7/dist-packages/tensorflow/include/third_party/gpus/cuda/
!make gpu
</code></pre>
<p>The cpu op compilation works fine. The gpu op compilation does not give any error but when I test the op it does not work properly.</p>
<p>With an input of <code>input = tf.ones((4,))</code>, considered the update I made in the gpu kernel, I expect to get <code>[3., 3., 3., 3.]</code> but I actually get <code>[0., 0., 0., 0.]</code>, when eager execution is active.</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

kernel_example_module = tf.load_op_library('/content/kernel_example.so')
example = kernel_example_module.example

input = tf.ones((4,))
output = .example(input)
print(output.numpy())
</code></pre>
<p>Whereas when I run the same in graph mode I get <code>[2., 2., 2., 2.]</code>, which is the result I obtain from the cpu implementation, this makes me think the gpu kernel is kind not executed.</p>
<pre><code>import tensorflow as tf
tf.compat.v1.disable_eager_execution()

kernel_example_module = tf.load_op_library('/content/kernel_example.so')
example = kernel_example_module.example

with tf.device('/gpu:0'):
    input = tf.ones((4,))
    output = example(input)

with tf.compat.v1.Session() as sess:
    print(sess.run(output))
</code></pre>
<p>I've tried to link the cuda path in the Makefile (LCUDA), as suggested in another similar question, but this did not solve my problem. I feel something is wrong with compiling options but I really cannot find what the problem could be.</p>
<p>Any idea how to make the gpu kernel work correctly ?</p>
",2022-02-10 16:04:35,18090135,11,https://stackoverflow.com/questions/71068368,Documentation Replication on Other Examples
71074606,tf.TensorArray as a FIFO?,"<p><a href=""https://github.com/keras-team/keras/issues/16015"" rel=""nofollow noreferrer"">Here</a> I was pointed to use <code>tf.TensorArray</code> instead of <code>tf.Variable</code> or <code>tf.queue.FIFOQueue</code> for making FIFO contained in custom layer. Is it an effective way? Exist any alternative here?</p>
<p>If it's the most effective method how can I replace <code>self.queue.assign(tf.concat([self.queue[timesteps:, :], inputs], axis=0))</code> with methods of <code>tf.TensorArray</code>?</p>
<h2>Code</h2>
<pre class=""lang-py prettyprint-override""><code>class FIFOLayer(Layer):
    def __init__(self, window_size, **kwargs):
        super(FIFOLayer, self).__init__(**kwargs)

        self.window_size = window_size
        self.count = 0

    def build(self, input_shape):
        super(FIFOLayer, self).build(input_shape)

        self.queue = self.add_weight(
            name=&quot;queue&quot;,
            shape=(self.window_size, input_shape[-1]),
            initializer=tf.initializers.Constant(value=np.nan),
            trainable=False,
        )

    def call(self, inputs, training):
        timesteps = tf.shape(inputs)[0]

        # check if batch_size is more than queue capacity
        if timesteps &gt; self.window_size:
            raise ValueError()

        # 1. append new state to queue
        self.queue.assign(tf.concat([self.queue[timesteps:, :], inputs], axis=0))
        self.count += timesteps

        # 2. feed-forward
        if self.count &lt; self.window_size:
            # generate mask
            attention_mask = tf.cast(
                tf.math.reduce_all(
                    tf.math.logical_not(tf.math.is_nan(self.queue)), axis=-1
                ),
                dtype=tf.float32,
            )
            attention_mask = tf.matmul(
                attention_mask[..., tf.newaxis],
                attention_mask[..., tf.newaxis],
                transpose_b=True,
            )
            return self.queue[tf.newaxis, ...], attention_mask
        # !!! check overflow
        elif self.count &gt; self.window_size:
            self.count = self.window_size

        return self.queue[tf.newaxis, ...], None

    @property
    def is_full(self):
        return self.count == self.window_size

    def clear(self):
        self.count = 0
        self.queue.assign(tf.fill(self.queue.shape, np.nan))


l = FIFOLayer(window_size=10)
for i in range(6):
    x = tf.random.normal((2, 12))
    y = l(x)
    print(y)

print(l.is_full, &quot;\n\n&quot;)

l.clear()

print(l(x))
print(l.is_full, &quot;\n\n&quot;)
</code></pre>
",2022-02-11 02:12:38,14986336,125,https://stackoverflow.com/questions/71074606,Documentation Replication on Other Examples
71130645,Correct axes to use dot product to evaluate the final output of a listwise learning to rank model,"<p>I'm not being able to find the correct configuration to pass to a tf.keras.layers.Dot to make a pairwise dot product when the entries each have lists of values, like from a listwise learning to rank model. For instance, suppose:</p>
<pre><code>repeated_query_vector = [
  [[1, 2], [1, 2]],
  [[3, 4], [3, 4]]
]

document_vectors = [
  [[5, 6], [7, 8]],
  [[9, 10], [11, 12]],
]
</code></pre>
<p>Calling tf.keras.layers.Dot(axes=??)([repeated_query_vector, document_vectors]) I want the output to be like:</p>
<pre><code>[
  [1*5 + 2*6, 1*7 + 2*8]
  [3*9 + 4*10, 3*11 + 4*12]
]
</code></pre>
<p>All examples I found in the documentation have one dimension less than my use case. What would be the correct value of axes for this call?</p>
",2022-02-15 17:15:52,13262684,35,https://stackoverflow.com/questions/71130645,Inadequate Examples
71292087,How to stack tensors without using tf.stack?,"<p>Is there any way to merge Tensors in Tensorflow?
For example:
I have 128 Tensor shape all are <strong>(40, 10)</strong>, Now, I want merge them to shape(128, 40, 10).
I can't use <em><code>*tf.stack([Tensor1, Tensor2, Tensor3, ...])*</code></em> directly.</p>
<p>So, Is there any function that can help achieve this?</p>
",2022-02-28 08:05:44,16647718,65,https://stackoverflow.com/questions/71292087,Documentation Replication on Other Examples
71294464,@tf_gradient peculiar implementation in StyleGan,"<p>I've been reading the source code for the StyleGAN implementation, and I cannot understand the peculiar use of the <code>@tf_gradient</code> decorator. Let us take the concrete example of their implementation of <code>Leaky_Relu</code>. The way I would do it is as follows :</p>
<pre><code>def myLRelu(x,alpha=0.2):
    alpha = tf.constant(alpha, dtype=x.dtype, name='alpha')
    @tf.custom_gradient
    def func(x):
        y = tf.maximum(x, x * alpha)
        def grad(dy):
            dx = tf.where(y &gt;= 0, dy, dy * alpha)
            return dx
        return y, grad
    return func(x)
</code></pre>
<p>Which follows the tf documentation for the use of tf.custom_gradient. But in the styleGan paper, they implement it as follows (I removed the &quot;variable_scope&quot; in my implementation as I'm not sure what it does):</p>
<pre><code>def leaky_relu(x, alpha=0.2):
    with tf.variable_scope('LeakyReLU'):
        alpha = tf.constant(alpha, dtype=x.dtype, name='alpha')
        @tf.custom_gradient
        def func(x):
            y = tf.maximum(x, x * alpha)
            @tf.custom_gradient
            def grad(dy):
                dx = tf.where(y &gt;= 0, dy, dy * alpha)
                return dx, lambda ddx: tf.where(y &gt;= 0, ddx, ddx * alpha)
            return y, grad
        return func(x)
</code></pre>
<p>There are two <code>@tf.custom_gradient</code> decorators used, and I don't understand why since there clearly aren't any second order derivatives being computed (as they are identically 0 anyway for LRelu). Is this a trick to somehow speed up computations ? If so, how does it work ?</p>
<p>EDIT : To clarify why I think this is somehow a &quot;trick&quot; to make computations of gradients faster, the authors make the following comment in the code :</p>
<pre><code># High-level ops for manipulating 4D activation tensors.
# The gradients of these are meant to be as efficient as possible.
</code></pre>
<p>And for completeness, here is the <a href=""https://github.com/NVlabs/stylegan/"" rel=""nofollow noreferrer"">repo</a> from which I took the code from</p>
",2022-02-28 11:38:33,3842374,153,https://stackoverflow.com/questions/71294464,Documentation Replication on Other Examples
71446995,Problem with tensorflow function when function is called within itself,"<p>It seems tensorflow cannot build @tf.function when the function is called within itself. Consider below for a simple calculation of factorial of a number:</p>
<pre><code>import tensorflow as tf
#@tf.function
def f(n):
    out = tf.cond(tf.equal(n,0), lambda: 1, lambda: tf.multiply(n, f(n-1)))
    return out
f(5)
</code></pre>
<p>When @tf.function is commented, it works fine but with @tf.function it runs forever. Any ideas how to fix this condition?</p>
",2022-03-12 04:30:13,18444524,11,https://stackoverflow.com/questions/71446995,Documentation Replication on Other Examples
71588962,Solving a set of linear systems in tensorflow,"<p>I'm having a problem understanding the working mechanism of tensorflow's function: tf.linalg.solve.
I want to solve a set of linear systems (AX = Y), where the linear coefficients (A) were shared but there are multiple batches of Y, which are different.
Using numpy, I can simply do it via:</p>
<pre><code>np.random.seed(0)
mtx = np.random.uniform(size= (1,4,4))
vec = np.random.uniform(size= (100,4,1))
solution = np.linalg.solve(mtx,vec)
print(abs(np.matmul(mtx,solution) - vec).max())
# 5.551115123125783e-16
</code></pre>
<p>which gives me a quite consistent solution.
But when I switch to tensorflow, it gives me the results:</p>
<pre><code>mtx = tf.random.uniform(shape = (1,4,4))
vec = tf.random.uniform(shape = (100,4,1))
solution = tf.linalg.solve(mtx,vec)
print(tf.math.reduce_max(abs(tf.matmul(mtx,solution) - vec))) 
# tf.Tensor(1.3136615, shape=(), dtype=float32)
</code></pre>
<p>According to the document, I assume the solution should be solved according to the corresponding vec. But it does not seem to give me the expected results in tensorflow. Since I'm a new user, I could have messed up something.
It would be appreciated if any information could be offered.</p>
",2022-03-23 14:27:58,12416654,63,https://stackoverflow.com/questions/71588962,Documentation Ambiguity
71619495,Image normalization by tf.image.convert_image_dtype function,"<p>According to documentation <code>tf.image.convert_image_dtype</code> &quot;Images that are represented using floating point values are expected to have values in the range [0,1).&quot;</p>
<p>But in the keras tutorial(<a href=""https://keras.io/examples/vision/cutmix/"" rel=""nofollow noreferrer"">https://keras.io/examples/vision/cutmix/</a>) i have seen the following preprocessing function:</p>
<pre><code>def preprocess_image(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0
    return image, label
</code></pre>
<p>My question is: why did they divide by 255, when <code>tf.image.convert_image_dtype</code> already did that job?</p>
",2022-03-25 15:32:07,5094589,915,https://stackoverflow.com/questions/71619495,Documentation Ambiguity
71711292,Tensorflow - mapping images with labels,"<p>I need the solution, that works with TPU, neither ImageDataGenerator or tf.py_function doesn't work.</p>
<p>My code for CPU:</p>
<pre><code>def get_label(file_path):
    file_name = tf.strings.split(file_path, os.path.sep)[-1]
    label = image_name_to_label[file_name.numpy().decode('utf-8')]
    label = tf.constant([label])
    return label
def decode_img(img):
    img = tf.io.decode_jpeg(img, channels=3)
    return tf.image.resize(img, [img_height, img_width])
def process_path(file_path):
    label = tf.py_function(func=get_label, inp=[file_path], Tout=tf.int32)
    label.set_shape((1,))
    img = tf.io.read_file(file_path)
    img = decode_img(img)
    return img, label
</code></pre>
<p>image_name_to_label is a python dict</p>
<p>I don't want to convert data to tfrecords</p>
",2022-04-01 18:22:14,5558021,1353,https://stackoverflow.com/questions/71711292,Documentation Replicability
71813366,How to add loss function with activity regularizer in distributed training,"<p>I have an deep autoencoder with an activity_regularizer <strong>in the bottleneck layer</strong>:</p>
<pre class=""lang-py prettyprint-override""><code>keras.layers.Dense(input_dim, ...)
...
keras.layers.Dense(2, activity_regularizer=keras.regularizers.l1())
...
outputs = keras.layers.Dense(input_dim, ...)
...
model.compile(loss='mse')
</code></pre>
<p>I then added some <a href=""https://www.tensorflow.org/guide/migrate/migrating_feature_columns#feature_column_equivalence_table"" rel=""nofollow noreferrer"">tf2 preprocessing feature layers</a>:</p>
<pre class=""lang-py prettyprint-override""><code>inputs = {
  'a': keras.Input(shape=()),
  'b': keras.Input(shape=()), # some other preprocessing applied afterwards
}
preprocessed = keras.layers.Concatenate()(inputs.values())

keras.layers.Dense(input_dim, ...)(preprocessed)
...
keras.layers.Dense(2, activity_regularizer=keras.regularizers.l1())
...
outputs = keras.layers.Dense(input_dim, ...)
...
model.compile(loss='mse')
</code></pre>
<p>So now I can't just add a loss function like <code>model.compile(loss='mse')</code> since the input are raw features and the outputs are scalars. I need to compute the loss based on the output of <code>preprocessed</code> and the final <code>outputs</code>.</p>
<p>This <a href=""https://stackoverflow.com/a/71614473/7242490"">answer</a> suggested I use the <code>model.add_loss()</code> function like:</p>
<pre class=""lang-py prettyprint-override""><code>model.add_loss(keras.losses.MeanSquaredError()(preprocessed, outputs))
</code></pre>
<p>This worked but when I tried training this using <code>tf.distribute.MultiWorkerMirroredStrategy()</code> I got the error:</p>
<pre><code>ValueError: Please use `tf.keras.losses.Reduction.SUM` or `tf.keras.losses.Reduction.NONE` for loss reduction when losses are used with `tf.distribute.Strategy` outside of the built-in training loops. You can implement `tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE` using global batch size like:

with strategy.scope():
    loss_obj = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)
    ....
    loss = tf.reduce_sum(loss_obj(labels, predictions)) * (1. / global_batch_size)

Please see https://www.tensorflow.org/tutorials/distribute/custom_training for more details.
</code></pre>
<p>Reading <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/distribute/custom_training</a> the documentation states:</p>
<blockquote>
<p>If you are using regularization losses in your model then you need to scale the loss value by number of replicas. You can do this by using the tf.nn.scale_regularization_loss function.</p>
</blockquote>
<p>So I'm now a bit confused. Does the above statement apply to the <code>activity_regularizer</code> I added? How does this work with the <code>global_batch_size</code>?</p>
<p>How can I solve this in distributed training?</p>
<hr />
<p><strong>TLDR: Do I need to &quot;scale the loss value by number of replicas&quot; when using hidden layer <code>activity_regularizer</code> in distributed training?</strong></p>
",2022-04-10 02:35:47,7242490,2383,https://stackoverflow.com/questions/71813366,Documentation Ambiguity
71893462,How to retrieve file paths from a tf.data.Dataset created with from_tensor_slices() and shuffled after every epoch,"<p>First of all, I would like to say that this is my first question in stackOverflow, so I hope that the question as a whole respects the rules. I realize that the question is a bit long, but I would like to provide as much background and detail as possible .</p>
<p>I am currently developing a real-time image binary classification system based on Tensorflow 2.8.0 and I am quite new at it. Here are some of the peculiarities of the data that I have for the mentioned project:</p>
<ul>
<li>Too big to fit in memory: I have more than 200 GB of data. Keep in mind that I have labeled only a small portion of it, but <strong>I want to write code that could manage the whole dataset in the future</strong>.</li>
<li>Some files are not directly compatible with Tensorflow: I have .FITS and .FIT files that cannot be opened directly with Tensorflow. Due to this issue, I use a library called Astropy to open these files.</li>
<li>The classes are very unbalanced.</li>
</ul>
<p>After reading the official documentation and tutorials, I thought that, in order to load, preprocess and feed data to my CNN, the best option was to build an input pipeline using the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">tf.data.Dataset</a> class due to the ease of opening FITS files. My general procedure follows this idea:</p>
<ol>
<li>Get a list of file paths and split it into train, val and test partitions if desired.</li>
<li>Create a tf.data.Dataset with the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices"" rel=""nofollow noreferrer"">from_tensor_slices()</a> method</li>
<li>Shuffle the data (before the heavier reading and image processing operations)</li>
<li>Read and process every path with <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">map()</a></li>
<li>Batch and prefetch</li>
</ol>
<p>Here are some code fragments in case they help to understand my goal:</p>
<pre><code>(...)

import config as cfg    # Custom .py file
import tensorflow as tf

# x_train, x_val and x_test are previously split file paths lists
train_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in x_train])
val_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in x_val])
test_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in x_test])

train_ds = configure_tf_ds(train_ds)
val_ds = configure_tf_ds(val_ds)
test_ds = configure_tf_ds(test_ds)

def configure_tf_ds(self, tf_ds, buf_size):
    # reshuffle_each_iteration=True ensures that data is shuffled each time it is iterated
    tf_ds = tf_ds.shuffle(buffer_size=cfg.SHUFFLE_BUF_SIZE, seed=cfg.seed, reshuffle_each_iteration=True)
    
    tf_ds = tf_ds.map(lambda x: tf.py_function(self.process_path, [x], [self.img_dtpye, self.label_dtype]))

    tf_ds = tf_ds.batch(self.batch_size) 

    tf_ds = tf_ds.prefetch(buffer_size=tf.data.AUTOTUNE)

    return tf_ds

def process_path(self, file_path):
    # Labels are extracted from the file path, not relevant for my problem
    label = get_label(file_path)
    path = bytes.decode(file_path.numpy()).lower()
    img = None
    # Open and process images depending on their file paths' extension: FITS, FIT, JPG
    if &quot;fit&quot; in path:
        img = tf.py_function(func=self.decode_fits, inp=[file_path], Tout=self.img_dtpye)  
    else:
        img = tf.py_function(func=self.decode_img, inp=[file_path], Tout=self.img_dtpye)  

    return img, label

model.fit(train_ds, epochs=50, validation_data=val_ds)

# Then, I would like to obtain predictions, plot results, and so on but knowing which file paths I am working with

(...)

</code></pre>
<p>Following the previous idea, I have successfully created and tested different types of pipelines for different types of partitions of my dataset: unlabeled (remember that only a portion of the data is labeled), labeled and weighted labeled (I wanted to see if my models improve by specifying class weights when training).</p>
<p>However, in order to monitor results and make proper adjustments to my model, I would like to retrieve the usual predictions, real labels and images next to the file paths <strong>preserving the ability to shuffle the data after every epoch</strong>.
I have managed to solve my question if I do not shuffle data with .shuffle(reshuffle_each_iteration=True), but models' performance is supposed to increase if data is shuffled after each epoch, according to several sources.</p>
<p>I have read different posts in stackOverflow related to my question. I will list those posts next to the problems that I have found for my particular use case:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/67072660/tensorflow-how-to-retain-file-names-in-tf-data-dataset-from-generator"">Solution 1:</a> My dataset cannot be fed to the model as X, y because it is a tf.data.Dataset</li>
<li><a href=""https://stackoverflow.com/questions/51162500/how-can-i-access-the-filenames-gathered-by-tf-data-dataset-list-files"">Solution 2:</a> I want to obtain the image and the label too.</li>
<li><a href=""https://stackoverflow.com/questions/54752287/get-input-filenames-from-tensorflow-dataset-iterators"">Solution 3:</a> This works, but it would not respect the expected tf.data.Dataset format in the future .fit() call <a href=""https://keras.io/api/models/model_training_apis/#fit-method"" rel=""nofollow noreferrer"">as stated here</a>:</li>
</ul>
<blockquote>
<p>A tf.data dataset. Should return a tuple of either (inputs, targets)
or (inputs, targets, sample_weights)</p>
</blockquote>
<p>I have also tried to keep a separate tf.data.Dataset with only the file paths but if I call the shuffle method with the reshuffle_each_iteration=True option in both tf.data.Dataset instances, the order of their elements does not match even if I set the same seed.</p>
<p>In short, is it possible to achieve what I want? If so, how should I proceed?</p>
<p>Thank you very much in advance.</p>
",2022-04-16 11:22:27,18816743,21,https://stackoverflow.com/questions/71893462,Documentation Replication on Other Examples
71933464,How to make true_fn of tf.cond skip a for loop in tensorflow v1.0/python?,"<p>I want to use <code>tf.cond</code> to mimic the python <code>if-else</code> logic in the <code>_preprocessing_fn</code> of <code>transform.py</code>.</p>
<p>Specifically, if the condition of <code>tf.cond</code> is true, I want to skip the current iteration of the for loop.</p>
<p>This seems problematic because <code>true_fn</code> and <code>false_fn</code> parameters of <code>tf.cond</code> are expected to return Tensors according to the documentation.</p>
<p>However, in my case, I want <code>true_fn</code> (aka <code>skip_feature_fn</code>)to simply &quot;continue&quot; to the next for loop iteration. Also, I want <code>false_fn</code> to take in two inputs (<code>feature</code> and <code>sp</code>) and simply feed them to some other API (e.g. <code>tft.vocabulary</code>).
I don't expect either of <code>true_fn</code> or <code>false_fn</code> to return anything.</p>
<p>Could someone help me accomplish my goal?</p>
<p>Here is the code snippet I'm working with:</p>
<pre><code>def _preprocessing_fn(inputs, category_features=features.STRING_FEATURES):
  outputs = transform_lib.preprocessing_helper_fn(
      inputs, used_features=category_features)

  for feature in category_features:
    if feature:
      sp = outputs[feature]
      tf.cond(
          tf.equal(sp.dense_shape[1], 0), skip_feature_fn, lambda: process_feature_further(
              feature,
              sp,
          ))

  return outputs
</code></pre>
<p>Thank you.</p>
",2022-04-20 02:33:19,4982651,117,https://stackoverflow.com/questions/71933464,Documentation Replication on Other Examples
71992472,"Deep dream ""guide"" image in tensorflow","<p>I'm trying to modify the deep dream code from the Tensorflow docs here:
<a href=""https://www.tensorflow.org/tutorials/generative/deepdream"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/generative/deepdream</a></p>
<p>Specifically, I want to use a &quot;guide image&quot; to produce the dream features. This was originally shown in Caffe in this notebook (at the bottom):
<a href=""https://github.com/google/deepdream/blob/master/dream.ipynb"" rel=""nofollow noreferrer"">https://github.com/google/deepdream/blob/master/dream.ipynb</a></p>
<p>In their example, they used an image of flowers and produced flower-like features on top of an image of clouds. To do this, they provide an alternate loss function. From the Caffe notebook:</p>
<blockquote>
<p>Instead of maximizing the L2-norm of current image activations, we try to maximize the dot-products between activations of current image, and their best matching correspondences from the guide image.</p>
</blockquote>
<p>In Caffe, it looks like this:</p>
<pre><code>end = 'inception_3b/output'
h, w = guide.shape[:2]
src, dst = net.blobs['data'], net.blobs[end]
src.reshape(1,3,h,w)
src.data[0] = preprocess(net, guide)
net.forward(end=end)
guide_features = dst.data[0].copy()

def objective_guide(dst):
    x = dst.data[0].copy()
    y = guide_features
    ch = x.shape[0]
    x = x.reshape(ch,-1)
    y = y.reshape(ch,-1)
    A = x.T.dot(y) # compute the matrix of dot-products with guide features
    dst.diff[0].reshape(ch,-1)[:] = y[:,A.argmax(1)] # select ones that match best
</code></pre>
<p>I translated this to Tensorflow like so:</p>
<pre><code>def get_activations(img, model):
    # Pass forward the image through the model to retrieve the activations.
    # Converts the image into a batch of size 1.
    img_batch = tf.expand_dims(img, axis=0)
    layer_activations = model(img_batch)
    if len(layer_activations) == 1:
        layer_activations = [layer_activations]
    return layer_activations

guide_activations = get_activations(img, model)

def maximize_to_guide(img, model):
    layer_activations = get_activations(img, model)
    losses = []
    for guide_activation in guide_activations:
        for layer_activation in layer_activations:
            ch = layer_activation.shape[-1]
            layer_activation = tf.reshape(layer_activation, (ch, -1))
            guide_activation = tf.reshape(guide_activation, (ch, -1))
            dot = tf.matmul(tf.transpose(layer_activation), guide_activation)
            max_act_idx = tf.math.argmax(dot, axis=1)
            max_act = tf.gather(guide_activation, max_act_idx, axis=1)
            loss = tf.math.reduce_mean(max_act)
            losses.append(loss)
    return tf.reduce_sum(losses)
</code></pre>
<p>However, <code>tape.gradient(loss, img)</code> returns <code>None</code>. I thought that it was because <code>argmax</code> is not differentiable. However, if I gather from the <code>layer_activations</code> instead -- <code>tf.gather(layer_activation, max_act_idx, axis=1)</code> -- then it produces a gradient (but not the desired image). So it's clearly able to step back through the tape, from the returned loss value to the input image, but only in this second case. What's going on here?</p>
",2022-04-24 21:26:36,1431917,300,https://stackoverflow.com/questions/71992472,Documentation Ambiguity
72041726,Is there a difference between creating tf.Variable and keras.layers.Layer.add_weight(),"<p>I've seen both approaches in Tensorflow documentation:</p>
<hr />
<p>#1</p>
<pre><code>class MyDenseLayer(tf.keras.layers.Layer):
  def __init__(self, num_outputs):
    super(MyDenseLayer, self).__init__()
    self.num_outputs = num_outputs

  def build(self, input_shape):
    self.kernel = self.add_weight(&quot;kernel&quot;,
                                  shape=[int(input_shape[-1]),
                                         self.num_outputs])

  def call(self, inputs):
    return tf.matmul(inputs, self.kernel)
</code></pre>
<hr />
<p>#2</p>
<pre><code>class Linear(keras.layers.Layer):
    def __init__(self, units=32, input_dim=32):
        super(Linear, self).__init__()
        w_init = tf.random_normal_initializer()
        self.w = tf.Variable(
            initial_value=w_init(shape=(input_dim, units), dtype=&quot;float32&quot;),
            trainable=True,
        )
        b_init = tf.zeros_initializer()
        self.b = tf.Variable(
            initial_value=b_init(shape=(units,), dtype=&quot;float32&quot;), trainable=True
        )

    def call(self, inputs):
        return tf.matmul(inputs, self.w) + self.b
</code></pre>
<hr />
<p>Is there a fundamental difference between creating a variable with self.add_weight() or tf.Variable() inside your custom layers? Examples are taken from
<a href=""https://www.tensorflow.org/tutorials/customization/custom_layers"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/customization/custom_layers</a> and <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/custom_layers_and_models</a> respectively.</p>
",2022-04-28 10:01:34,16241829,63,https://stackoverflow.com/questions/72041726,Documentation Replicability
72184958,Pydantic: Type hinting tensorflow tensor,"<p>any idea of how to type-hint tf tensors using pydantic??. Tried default tf.Tensor</p>
<pre><code>RuntimeError: no validator found for &lt;class 'tensorflow.python.framework.ops.Tensor'&gt;, see `arbitrary_types_allowed` in Config
</code></pre>
<p>and tf.flaot32</p>
<pre><code>RuntimeError: error checking inheritance of tf.float32 (type: DType)
</code></pre>
<p>Looking at documentation in pydantic, i believe something like this arbitrary class need to be defined...</p>
<pre><code>class Tensor:
    def __init__(self, Tensor):

        self.Tensor = Union[
            tensorflow.python.framework.ops.Tensor,
            tensorflow.python.framework.sparse_tensor.SparseTensor,
            tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor,
            tensorflow.python.framework.ops.EagerTensor,
        ]
</code></pre>
<p>with following in main..</p>
<pre><code> class Main(BaseModel):
     tensor : Tensor


 class Config:
    arbitary_types_allowed = True
</code></pre>
",2022-05-10 10:47:47,10027860,147,https://stackoverflow.com/questions/72184958,Documentation Replicability
72329108,Is there a simple way to know which Tensorflow ops have a registered GPU kernel?,"<p>I have been trying to optimize some Tensorflow code that was pretty memory inefficient (use of large dense tensors containing very sparse information), and would thus limit batch size and scalability, by trying to make use of SparseTensors.
After some struggle I finally come up with a decent solution with satisfactory speedup on CPU and very low memory usage, and when the time comes to use a GPU I realize that the previous memory inefficient is orders of magnitude faster...</p>
<p>Using tensorboard profiling I've discovered that two of the operations I have used in my &quot;&quot;optimized&quot;&quot; version only run on CPU (namely UniqueV2 and sparse_dense_matmul), but I could not see any hint of that in the documentation.</p>
<p>The only related piece of <a href=""https://www.tensorflow.org/guide/gpu#overview"" rel=""nofollow noreferrer"">documentation</a> states:</p>
<blockquote>
<p>If a TensorFlow operation has no corresponding GPU implementation,
then the operation falls back to the CPU device. For example, since
tf.cast only has a CPU kernel, on a system with devices CPU:0 and
GPU:0, the CPU:0 device is selected to run tf.cast, even if requested
to run on the GPU:0 device.</p>
</blockquote>
<p>In turn there is nothing in the tf.cast documentation hinting that the op has no GPU kernel.</p>
<p>Thus, is there a simple way to know whether a TF ops has a registered GPU kernel, without having to use a GPU to find it out?</p>
<p>The <a href=""https://www.tensorflow.org/guide/create_op#gpu_support"" rel=""nofollow noreferrer"">custom ops</a> guide suggest that this could be seen by looking at the ops C files, but this seems a rather cumbersome way to do it...</p>
<p>I'm using TF v2.8</p>
<p>Thanks!</p>
",2022-05-21 11:25:40,19167343,11,https://stackoverflow.com/questions/72329108,Inadequate Examples
72360420,How to evaluate only a random subset of all possible operations per pass inside a graph?,"<pre><code>import tensorflow as tf

operations = [
    tf.keras.layers.Dense(64, activation='sigmoid'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(64, activation=None),
]


def call(x):
    # Sample 2 of the 3 operations.
    sampled_ids = tf.random.categorical(
        tf.zeros((1, len(operations))), num_samples=2, dtype=tf.int32,
    )[0]

    # Compute their output given x.
    op_results_eager = tf.stack([operations[op_id](x) for op_id in sampled_ids])

    # Try to replicate op_results_eager in graph_mode without evaluating all operations!
    op_result_functs = [lambda: op(x) for op in operations]
    op_results_graph = tf.stack([tf.switch_case(branch_index=op_id, branch_fns=op_result_functs) for op_id in sampled_ids])

    tf.print(tf.reduce_all(tf.equal(op_results_eager, op_results_graph)))

    return op_results_graph


for _ in range(1000):
    call(tf.ones(shape=(1, 5)))
</code></pre>
<p>I need the same result as in op_results_eager but with statements that allow wrapping call() as tf.function while still <strong>evaluating only the sampled operations</strong>.</p>
<p>As you can see, I tried to build the indexing as a switch case, but that doesn't even give the right result in eager execution.</p>
",2022-05-24 09:25:34,8690766,61,https://stackoverflow.com/questions/72360420,Documentation Replication on Other Examples
72379091,Tf.data.Dataset store a array column Error,"<p>Is there any way to store inside a tf.data.Dataset formed from a pandas dataframe, a column where each cell corresponds to an array of floats?</p>
<p>I have a pandas dataframe where a column has a list of floats for each row, and I transform it to a tf.data.Dataset in the following way to send it to a Tensorflow model:</p>
<pre><code>ds = tf.data.Dataset.from_tensor_slices((dict(dataframe)))
</code></pre>
<p>But I can't store the array column, is there any way to do it?</p>
<blockquote>
<p>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).</p>
</blockquote>
",2022-05-25 14:02:36,15692031,41,https://stackoverflow.com/questions/72379091,Documentation Replication on Other Examples
72465331,not able to embed python tensorflow code in c++,"<p>I am building NIST FRVT11 library. I have core code in python, that I want to call from c++, I have followed offical Python C API docs to use python functions in c++.</p>
<p>I am able to load and predict with keras model once during initialization stage. But cannot predict from the same model after that <code>model.predict</code> function takes inifite time.
I'm not even able to load the model, this time <code>tf.keras.models.load_model</code> takes inifite time.</p>
<p>I am not getting any error that I can paste here :(</p>
<p>NIST wants everything to be packaged within library, so I have built python locally and attaching that in the submission.</p>
<p>python: 3.9.13
tensorflow: 2.8.0
keras: 2.8.0</p>
<p>python code</p>
<pre><code>import tensorflow as tf
def get_model(model_path):
    embedding_model = tf.keras.models.load_model(model_path)
    return embedding_model 

def predict(model, img):
    out= model.predict(img)
    return out
</code></pre>
<p>c++ code</p>
<pre><code>int call_python_code(const std::string &amp;configDir)
{
    this-&gt;configDir = configDir;
    // add directory to sys path
    std::string command_sys_path_to_append = &quot;import sys, os\n&quot;
                &quot;sys.path.append(os.path.join(os.getcwd(), '&quot; + this- 
               &gt;configDir + &quot;'))\n&quot;;
    PyRun_SimpleString(command_sys_path_to_append.c_str());

    Py_Initialize();
    PyObject *p_module_name = PyUnicode_DecodeFSDefault(&quot;fr&quot;); // fr.py file
    this-&gt;p_module = PyImport_Import(p_module_name);

    // load the model from c++
    PyObject *outer_tuple_2 = PyTuple_New(1);
    PyTuple_SetItem(outer_tuple_2, 0, PyUnicode_DecodeFSDefault(this-&gt;configDir.c_str()));
    PyObject *p_fucntion_model = PyObject_GetAttrString(p_module, &quot;get_model&quot;);
this-&gt;p_embedding_model_object = PyObject_CallObject(p_fucntion_model, outer_tuple_2);

 

 // get prediction 

    PyObject *p_function_predict= PyObject_GetAttrString(p_module, &quot;predict&quot;);


PyObject *full_args = PyTuple_New(2); 
PyTuple_SetItem(full_args, 0, this-&gt;p_fucntion_model);
PyTuple_SetItem(full_args, 1, &lt;image array&gt;);
PyObject *outer_tuple = PyTuple_New(1);
PyTuple_SetItem(outer_tuple, 0, full_args);
PyObject *p_return_tuple = PyObject_CallObject(p_function_predict, outer_tuple);

}
</code></pre>
",2022-06-01 16:37:16,10412923,336,https://stackoverflow.com/questions/72465331,Documentation Replication on Other Examples
72707453,How to save a tensorflow dataset to multiple shards without using enumerate,"<p>I have a tensorflow dataset with some elements in it, and I want to save it with <code>tf.data.Dataset.save</code> such that each element gets its own shard. Thus if the dataset contains 2,000 elements, it would be saved to 2,000 shards.</p>
<p>The documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#save"" rel=""nofollow noreferrer"">here</a> specifies how to create 1 shard only, but not how to make a shard for each element.</p>
<p>Below, I am able to do it with enumerate, but is there another way to do it without also saving the index from <code>enumerate</code>?</p>
<pre><code>tuple_data = np.array([3, 4])
data = tf.data.Dataset.from_tensor_slices(tuple_data)
data = data.enumerate()
print(list(data.as_numpy_iterator()))
# [(0, 3), (1, 4)]

data.save(path='~/Desktop/1', shard_func=lambda i, x: i)
</code></pre>
",2022-06-21 21:47:20,9909857,341,https://stackoverflow.com/questions/72707453,Documentation Replicability
72720129,Understanding tf.keras.metrics.Precision and Recall for multiclass classification,"<p>I am building a model for a multiclass classification problem. So I want to evaluate the model performance using the Recall and Precision.
I have 4 classes in the dataset and it is provided in <code>one hot</code> representation.</p>
<p>I was reading the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision"" rel=""nofollow noreferrer"">Precision</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall"" rel=""nofollow noreferrer"">Recall</a> <code>tf.keras</code> documentation, and have some questions:</p>
<ol>
<li>When it calculating the Precision and Recall for the multi-class classification, how can we take the average of all of the labels, meaning the global precision &amp; Recall? is it calculated with <code>macro</code> or <code>micro</code> since it is not specified in the documentation as in the <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html"" rel=""nofollow noreferrer"">Sikit learn</a>.</li>
<li>If I want to calculate the precision &amp; Recall for each label separately, can I use the argument <code>class_id</code> for each label to do  <code>one_vs_rest</code> or <code>binary</code> classification. Like what I have done in the code below?</li>
<li>can I use the argument <code>top_k</code> with the value <code>top_k=2</code> would be helpful here or it is not suitable for my classification of 4 classes only?</li>
<li>While I am measuring the performance of each class, What could be the difference, when I set the <code>top_k=1</code> and not setting <code>top_k</code>overall?</li>
</ol>
<pre><code>model.compile(
      optimizer='sgd',
      loss=tf.keras.losses.CategoricalCrossentropy(),
      metrics=[tf.keras.metrics.CategoricalAccuracy(),
               ##class 0
               tf.keras.metrics.Precision(class_id=0,top_k=2), 
               tf.keras.metrics.Recall(class_id=0,top_k=2),
              ##class 1
               tf.keras.metrics.Precision(class_id=1,top_k=2), 
               tf.keras.metrics.Recall(class_id=1,top_k=2),
              ##class 2
               tf.keras.metrics.Precision(class_id=2,top_k=2), 
               tf.keras.metrics.Recall(class_id=2,top_k=2),
              ##class 3
               tf.keras.metrics.Precision(class_id=3,top_k=2), 
               tf.keras.metrics.Recall(class_id=3,top_k=2),
])
</code></pre>
<p>Any clarification of this function will be appreciated.
Thanks in advance</p>
",2022-06-22 18:04:09,17534198,325,https://stackoverflow.com/questions/72720129,Documentation Replicability
72749893,Optimizer.apply_gradients creating variables in tf.function,"<p>I have created a neural style transfer with Eager Execution, but it does not work when I  try to turn it into a tf.function.
The error message says:</p>
<pre><code>ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
</code></pre>
<p>However, no variable is being created inside the function. Here is a simplified version of the code, which is just a neural style transfer with one image (the goal is to make the generated image look exactly like the content image):</p>
<pre><code>import tensorflow as tf
import numpy as np
from PIL import Image

#Get and process the images
image = np.array(Image.open(&quot;frame7766.jpg&quot;)).reshape(1, 720, 1280, 3)/255
content_image = tf.convert_to_tensor(image, dtype = tf.float32)
# variable is defined outside of tf.function
generated_image = tf.Variable(np.random.rand(1, 720, 1280, 3)/2 + content_image/2, dtype = tf.float32)

def clip_0_1(image): # keeps image values between 0 and 1
    return tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)

@ tf.function
def train_step(generated_image, content_image): #turn generated image into tf variable
    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)
    with tf.GradientTape() as tape:
        cost = tf.reduce_sum(tf.square(generated_image - content_image))
    grad = tape.gradient(cost, generated_image) 
    optimizer.apply_gradients([(grad, generated_image)]) # More information below
    generated_image.assign(clip_0_1(generated_image))
    return generated_image

generated_image = train_step(generated_image, content_image)
</code></pre>
<p>The error message points to the line</p>
<pre><code>optimizer.apply_gradients([(grad, generated_image)]) 
</code></pre>
<p>I have tried to change the input of <code> optimizer.apply_gradients</code> to <code>zip([grad], [generated_image])</code>, and every combination of lists and tuples I can think of, but the error still remains. I have also looked through <a href=""https://www.tensorflow.org/guide/function#creating_tfvariables"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/function#creating_tfvariables</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer</a>, but neither of them shows examples where the variable is not explicitly defined.
The only conclusion that I can come to is that one of my commands (most likely <code>optimizer.apply_gradients</code>) creates a variable because of an issue in my earlier code. Is that correct?</p>
",2022-06-24 22:17:40,17819542,13,https://stackoverflow.com/questions/72749893,Documentation Replication on Other Examples
72772487,Memory Leak With Custom Object Detection Model Tensorflow,"<p>I am biggner in tensorflow. I used transfer learning machanism and create custom object detection model using &quot;ssd_resnet101_v1_fpn_keras&quot; pre-trained model.</p>
<p>I follow the below documentation for custom traning:</p>
<pre><code>https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html
</code></pre>
<p>I observed one issue while I used it for detection it takes lot of RAM and not releasing it.</p>
<p>I am sharing you the code snippet where it took lot of RAM and not releasing it.</p>
<pre><code>detect_fn = tf.saved_model.load(visa_icon_model)

visa_icon_detections = detect_fn(input_tensor
</code></pre>
<p><strong>Memory profiler info:</strong></p>
<pre><code>301   1675.0 MiB    191.8 MiB           1           visa_icon_detections = detect_fn(input_tensor)
</code></pre>
<p>As you can see, it's take 191.8 Mb RAM. It's not releasing it after competion the process.</p>
<p>I used gc.collect() and tf.keras.backend.clear_session() for releasing the memory.</p>
<p>Both is not working for me.</p>
<p>Please anyone can help me how can I solve this problem.</p>
",2022-06-27 12:56:46,8938829,109,https://stackoverflow.com/questions/72772487,Documentation Replication on Other Examples
72850120,"Keras - Specifying from_logits=False when using tf.keras.layers.Dense(1,activation='sigmoid')(x)","<p>I am working on a binary classification problem, using transfer learning and image inputs and have a question regarding the</p>
<p>I have been working through using the correct activation layers (e.g. Softmax or Sigmoid - sigmoid for binary softmax for multiclass) and noticed when I specify 'sigmoid' as part of the <code>Dense()</code> output layer, I no longer need to specify <code>from_logits=True</code> during <code>model.compile()</code>.</p>
<p>This means when I am obtaining predictions, I don't use the <code>tf.nn.sigmoid()</code> function and instead simply check if the value is greater than 0.5, then 1, else 0. Is this correct? Here is my code:</p>
<pre><code>i = keras.Input(shape=(150, 150, 3))
                scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)
                mt = scale_layer(i)
                mt = base_model(model_top, training=False)
                mt = keras.layers.GlobalAveragePooling2D()(mt)
                mt = keras.layers.Dropout(dropout)(mt)  # Regularize with dropout
                o = keras.layers.Dense(1,activation='sigmoid')(mt)
                model = keras.Model(i, o)

....

model.compile(optimizer=keras.optimizers.Adam(lr),loss=keras.losses.BinaryCrossentropy(from_logits=False)
                )
</code></pre>
<p>And then when I obtain predictions, I have the following:</p>
<pre><code>                pred = model.predict(test)
                pred = tf.where(pred &lt; 0.5, 0, 1)
                pred = pred.numpy()
</code></pre>
<p>My intuition is that as I am specifying the sigmoid activation function during the Dense layer build, I no longer work with 'logits' and therefore do not need to apply the sigmoid function later on. In the documentation, I've seen both examples used but it's quite sparse on information when working with <code>model.predict()</code>, would appreciate any guidance.</p>
",2022-07-03 21:42:54,6419012,35,https://stackoverflow.com/questions/72850120,Documentation Replicability
73049510,How to dynamically set pool size for AveragePooling2D layer/ How to pass external value to an sequential layer,"<p>Trying to understand <a href=""https://www.tensorflow.org/recommenders/examples/listwise_ranking"" rel=""nofollow noreferrer"">listwise documentation</a></p>
<p>while trying to replicate by mixing <a href=""https://www.tensorflow.org/recommenders/examples/deep_recommenders"" rel=""nofollow noreferrer"">deep model</a> to listwise I am stuck at point where I am not able to set the pool size inside the sequential layer in an dynamic manner. For example consider below code</p>
<pre><code>!pip install -q tensorflow-recommenders
!pip install -q --upgrade tensorflow-datasets
!pip install -q tensorflow-ranking
import pprint

import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_ranking as tfr
import tensorflow_recommenders as tfrs
from typing import Dict, Text
import os
import tempfile
import datetime
ratings = tfds.load(&quot;movielens/100k-ratings&quot;, split=&quot;train&quot;)
movies = tfds.load(&quot;movielens/100k-movies&quot;, split=&quot;train&quot;)

ratings = ratings.map(lambda x: {
    &quot;movie_title&quot;: x[&quot;movie_title&quot;],
    &quot;user_id&quot;: x[&quot;user_id&quot;],
    &quot;user_rating&quot;: x[&quot;user_rating&quot;],
    # &quot;timestamp&quot;: x[&quot;timestamp&quot;],
})
movies = movies.map(lambda x: x[&quot;movie_title&quot;])

unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))
unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(
    lambda x: x[&quot;user_id&quot;]))))


class MovieModel(tf.keras.Model):

  def __init__(self):
    super().__init__()

    max_tokens = 10_000_00

    self.title_vectorizer = tf.keras.layers.TextVectorization(
        max_tokens=max_tokens)

    self.title_text_embedding = tf.keras.Sequential([
      # tf.keras.layers.Flatten(),
      self.title_vectorizer,
      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),
      tf.keras.layers.AveragePooling2D(pool_size=(1,4),strides=1,    padding='valid',),
    ])
    self.title_vectorizer.adapt(movies)

  def call(self, titles):
    return self.title_text_embedding(titles)
</code></pre>
<p>After we create movie model lets try to test it before we can use it on proper movie data</p>
<p>below is the test code</p>
<pre><code>test_movie_titles = [[&quot;M*A*S*H (1970)&quot;, &quot;Dances with Wolves (1990)&quot;, &quot;Speed (1994)&quot;,&quot;Dances with Wolves (1990)&quot;, &quot;Speed (1994)&quot;]]
md = MovieModel()
test_ratings = md(tf.constant(tf.reshape(test_movie_titles,[1,5,1])) )  
test_ratings
</code></pre>
<p>This now works perfect and I will get an output as below</p>
<pre><code>&lt;tf.Tensor: shape=(1, 5, 1, 32), dtype=float32, numpy=
array([[[[ 0.00778975, -0.00899004,  0.02926993, -0.00527342,
           0.00706512,  0.02012717,  0.03438753,  0.01971687,
          -0.00543808, -0.00754605, -0.02241766,  0.00045748,
          -0.00785657, -0.00291913,  0.00670988,  0.01176082,
          -0.02052191, -0.00751739, -0.01433057,  0.008
-----
----
</code></pre>
<p>Now if you notice in the code above I have hardcoded the pool_size as 1,4 ( <code>tf.keras.layers.AveragePooling2D(pool_size=(1,4),strides=1,    padding='valid',),</code>) because the test sample I had used above only have maximum 4 words, so the vectorization will produce vector of size 4, now problem is how to I ensure the right pool size when I pass the whole dataset (movies) to the model. How can I pass such external value (pool_size) to an sequential layer from outside?</p>
<p>The above code was run on google colab using tensorflow version 2.9.1</p>
",2022-07-20 09:55:30,12271381,939,https://stackoverflow.com/questions/73049510,Documentation Replication on Other Examples
73074491,Replace tf.gather with other OPs which are supported by TFLite GPU delegate,"<p>Does anyone know how to replace <code>tf.gather</code> with other OPs which are supported by TFLite GPU delegate? I want to convert a TensorFlow model with a <code>warp</code> operation to a TFLite model to be used on Android devices, but the <code>warp</code> needs to use <code>tf.gather</code> to get corner pixel values and <code>tf.gather</code> seems not supported by GPU on Android.</p>
<pre><code>def gather(y_coords, x_coords, name):
    with tf.name_scope(&quot;gather-&quot; + name):
        linear_coordinates = batch_offsets + y_coords * width + x_coords
        gathered_values = tf.gather(flattened_grid, linear_coordinates)
        return tf.reshape(gathered_values, [batch_size, num_queries, channels])
</code></pre>
",2022-07-22 02:27:33,15080050,21,https://stackoverflow.com/questions/73074491,Documentation Replication on Other Examples
73179836,tensorflow.py_function fails to temporarily switch to eager execution while in graph mode,"<p>I'm not sure if this is a Tensorflow bug or my misunderstanding about what this function is supposed to do, but I can't get <code>tf.py_function</code> to return an <code>EagerTensor</code> <em>while in graph mode</em>. Consequently, calling <code>.numpy()</code> on the output of this function fails.</p>
<p>The issue can be reproduced using the exact example given in the official documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/py_function</a>):</p>
<pre><code>import tensorflow as tf

tf.compat.v1.disable_eager_execution()

def log_huber(x, m):
  if tf.abs(x) &lt;= m:
    return x**2
  else:
    return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))

x = tf.constant(1.0)
m = tf.constant(2.0)

with tf.GradientTape() as t:
  t.watch([x, m])
  y = tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32)

dy_dx = t.gradient(y, x)
assert dy_dx.numpy() == 2.0

</code></pre>
<p>This generates the following error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;&lt;input&gt;&quot;, line 17, in &lt;module&gt;
  File &quot;C:\Users\...\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\framework\ops.py&quot;, line 446, in __getattr__
    self.__getattribute__(name)
AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>
<h3>About version</h3>
<p>I am running Python 3.8 and Tensorflow v2.9.1.</p>
<p>Any help would be greatly appreciated!</p>
",2022-07-31 00:03:10,10453038,86,https://stackoverflow.com/questions/73179836,Documentation Replicability
73206182,"Why is the gradient of `where(x > 1, log(x), 0)` nan?","<p>Why is the gradient of <code>tf.where(x &gt; 1, tf.math.log(x), 0)</code> <code>nan</code> when <code>x</code> is <code>0.0</code>, but not when it's <code>-1</code> or <code>1</code>?</p>
<p>Minimal example:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

x = tf.constant([-1, 0, 1], tf.float32)

with tf.GradientTape() as g:
  g.watch(x)
  y = tf.where(x &gt; 1, tf.math.log(x), 0)

print(y)

dy_dx = g.gradient(y, x)
print(dy_dx)
</code></pre>
<p>Output:</p>
<pre><code>tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
tf.Tensor([-0. nan  0.], shape=(3,), dtype=float32)
</code></pre>
",2022-08-02 10:44:18,2491528,1965,https://stackoverflow.com/questions/73206182,Documentation Replicability
73279782,Tensorboard profiling a predict call using Cloud TPU Node,"<p>I've been trying to profile a predict call of a custom NN model using a Cloud TPU v2-8 Node.</p>
<p>It is important to say that my prediction call takes about 2 minutes to finish and I do it using data divided in TFRecord batches.</p>
<p>I followed the official documentation &quot;<a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools"" rel=""nofollow noreferrer"">Profile your model with Cloud TPU Tools</a>&quot; and I tryied to capture a profile:</p>
<ol>
<li>Using <a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_a_profile_using_tensorboard"" rel=""nofollow noreferrer"">Tensorboard UI</a> and</li>
<li>The &quot;<a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_a_profile_programmatically"" rel=""nofollow noreferrer"">programatic way</a>&quot; with a tf.profiler.experimental.start() and tf.profilier.experimental.stop() wrapping the predict call, but I had no success in both cases.</li>
</ol>
<pre><code># TPU Node connection is done before...

# TPU at this point is already running
logdir_path = &quot;logs/predict&quot;
tf.profiler.experimental.start(logdir_path)
# Tensorflow predict call here
tf.profiler.experimental.stop()
</code></pre>
<p>I could generate some data in both cases (Tensorboard UI and profiler call), but when I try to open it in Tensorboard pointing the logdir path, I received a &quot;No dashboard are active for the current data set&quot; message.</p>
<p><strong>Is there any way to profile a Tensorflow/Keras prediction call with a model running in a Cloud TPU Node?</strong>
<br>
<br>
<br>
<br>
<strong>Curious fact</strong> - There seems to be an inconsistency in the Tensorflow docs and Cloud TPU docs: in <a href=""https://www.tensorflow.org/guide/profiler#profiling_use_cases"" rel=""nofollow noreferrer"">Tensorflow Optimization Docs</a> we can see that tf.profiler.experimental.start/stop calls are not supported by TPU hardware, but in <a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_a_profile_programmatically"" rel=""nofollow noreferrer"">Google Cloud docs</a> this is the recommended method to capture a profile in TPU.</p>
<p>Config:</p>
<ul>
<li>Tensorflow 2.6.1</li>
<li>Tensorboard 2.9.1</li>
<li>Python 3.8</li>
<li>Cloud TPU Node v2-8</li>
</ul>
",2022-08-08 14:46:40,11648055,21,https://stackoverflow.com/questions/73279782,Documentation Replication on Other Examples
73328337,Tensorflow 2 SSD MobileNet model breaks during conversion to tflite,"<p>I've been trying to follow this process to run an object detector (SSD MobileNet) on the Google Coral Edge TPU:
<a href=""https://i.stack.imgur.com/Hm22L.png"" rel=""nofollow noreferrer"">Edge TPU model workflow</a></p>
<p>I've successfully trained and evaluated my model with the Object Detection API. I have the model both in checkpoint format as well as tf SavedModel format. As per the documentation, the next step is to convert to .tflite format using post-training quantization.</p>
<p>I am to attempting to follow <a href=""https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/convert_odt_model_to_TFLite.ipynb"" rel=""nofollow noreferrer"">this</a> example. The export_tflite_graph_tf2.py script and the conversion code that comes after run without errors, but I see some weird behavior when I try to actually use the model to run inference.</p>
<ol>
<li>I am unable to use the saved_model generated by export_tflite_graph_tf2.py. When running the following code, I get an error:</li>
</ol>
<pre><code>print('loading model...')
model = tf.saved_model.load(tflite_base)
print('model loaded!')
results = model(image_np)
</code></pre>
<blockquote>
<p>TypeError: '_UserObject' object is not callable --&gt; results = model(image_np)</p>
</blockquote>
<p>As a result, I have no way to tell if the script broke my model or not before I even convert it to tflite. Why would model not be callable in this way? I have even verified that the type returned by tf.saved_model.load() is the same when I pass in a saved_model before it went through the export_tflite_graph_tf2.py script and after. The only possible explanation I can think of is that the script alters the object in some way that causes it to break.</p>
<ol start=""2"">
<li>I convert to tflite with post-training quantization with the following code:</li>
</ol>
<pre><code>def representative_data_gen():
  dataset_list = tf.data.Dataset.list_files(images_dir + '/*')
  for i in range(100):
    image = next(iter(dataset_list))
    image = tf.io.read_file(image)
    # supports PNG as well
    image = tf.io.decode_image(image, channels=3)
    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
    image = tf.cast(image / 255., tf.float32) 
    image = tf.expand_dims(image, 0)
    if i == 0:
      print(image.dtype)
    yield [image]

# This enables quantization
# This sets the representative dataset for quantization
converter = tf.lite.TFLiteConverter.from_saved_model(base_saved_model)
# converter = tf.lite.TFLiteConverter.from_keras(model)

converter.optimizations = [tf.lite.Optimize.DEFAULT] # issue here?
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [
  # tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  # tf.lite.OpsSet.SELECT_TF_OPS, # enable TensorFlow ops.
  tf.lite.OpsSet.TFLITE_BUILTINS_INT8 # This ensures that if any ops can't be quantized, the converter throws an error
]

# This ensures that if any ops can't be quantized, the converter throws an error
# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.
converter.target_spec.supported_types = [tf.int8]
converter.target_spec.supported_ops += [tf.lite.OpsSet.TFLITE_BUILTINS]
# These set the input and output tensors to uint8 (added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_model_quantized = converter.convert()
</code></pre>
<p>Everything runs with no errors, but when I try to actually run an image through the model, it returns garbage. I tried removing the quantization to see if that was the issue, but even without quantization it returns seemingly random bounding boxes that are completely off from the model's performance prior to conversion. The shape of the output tensors look fine, it's just the content is all wrong.</p>
<p>What's the right way to get this model converted to a quantized tflite form? I should note that I can't use the tflite_convert utility because I need to quantize the model, and it appears according to the source code that the quantize_weights flag is deprecated? There are a bunch of conflicting resources I see from TF1 and TF2 about this conversion process so I'm pretty confused.</p>
<p>Note: I'm using a retrained SSD MobileNet from the model zoo. I have not made any changes to the architecture in my training workflow. I've confirmed that the errors persist even on the base model pulled directly from the object detection model zoo.</p>
",2022-08-12 01:14:33,19746925,11,https://stackoverflow.com/questions/73328337,Documentation Ambiguity
73336326,computing gradients in parallel in Tensorflow,"<p>I need to compute gradient of a scalar valued function with vector inputs for various inputs. I am currently doing something like below. But no matter what value I set for <code>parallel_iterations</code> of the <code>tf.while_loop</code>, it is only computing gradients for one input at a time. What am I missing?</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import time

@tf.function
def f(x):
    x_hat = tf.signal.rfft(x)
    x_recon = tf.signal.irfft(x_hat)
    lnp = tf.reduce_sum(x_recon)
    tf.print(lnp)
    return lnp


@tf.function
def ode_fn(x):
    return -x + 1.0


@tf.function
def integrate(x, nsteps, time_step):
    y = tf.TensorArray(dtype=tf.float32, size=nsteps)
    x_next = x
    for i in tf.range(nsteps):
        x_next = x_next + time_step * ode_fn(x_next)
        y = y.write(i, x_next)
    return y.stack()


@tf.function
def compute_grads(x):
    lnpgrad = tf.TensorArray(dtype=tf.float32, size=x.shape[0])

    def cond(i, lnpgrad):
        return tf.less(i, x.shape[0])

    def body(i, lnpgrad):
        x_i = x[i]
        with tf.GradientTape() as tape:
            tape.watch(x_i)
            lnp_i = tf.reduce_sum(integrate(x_i, 20000, 0.1))
        tf.print(lnp_i)
        lnpgrad = lnpgrad.write(i, tape.gradient(lnp_i, x_i))
        return i + 1, lnpgrad

    i = tf.constant(0, dtype=tf.int32)
    i, lnpgrad = tf.while_loop(cond,
                               body,
                               loop_vars=[i, lnpgrad],
                               parallel_iterations=5)
    lnpgrad = lnpgrad.stack()
    return lnpgrad


x = tf.random.normal(shape=[10, 5000],
                     mean=10.0,
                     stddev=1.0,
                     dtype=tf.float32)

start = time.time()
fx_grads = compute_grads(x)
end = time.time()
print(f&quot;Elapsed {end - start} seconds&quot;)
</code></pre>
",2022-08-12 15:15:05,1794777,11,https://stackoverflow.com/questions/73336326,Documentation Replicability
73437417,"tf.keras.utils.image_dataset_from_directory, but labels are from csv?","<p>Please tell me where I'm going wrong. I am working on the kaggle dog breed classification challenge and I want to try one-hot encoding vs label encoding. The images are not split in the images directory so I can not use 'inferred' with tf.keras.utils.image_dataset_from_directory, the labels are in a separate csv file that I put into a df (label_int).</p>
<pre><code>cat_count = 120 #depth or the number of categories
oh_input = tf.one_hot(label_int, cat_count) #apply one-hot encoding
</code></pre>
<p>label_int is a list of all my labels in integer form, in the same order as my images in the directory. oh_input is a list of one-hot vectors.</p>
<pre><code>batch_size = 32
img_height = 224
img_width = 224

train_ds = tf.keras.utils.image_dataset_from_directory(train_dir,labels = oh_input,label_mode = 'categorical',validation_split=0.2,subset=&quot;training&quot;,seed=123,image_size=(img_height, img_width),batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(train_dir,labels = oh_input,label_mode = 'categorical',validation_split=0.2,subset=&quot;validation&quot;,seed=123,image_size=(img_height, img_width),batch_size=batch_size)
</code></pre>
<p>The error:</p>
<pre><code>154 if kwargs:

155 raise TypeError(f'Unknown keywords argument(s): {tuple(kwargs.keys())}') --&gt; 156 if labels not in ('inferred', None):

...

100 dtype = dtypes.as_dtype(dtype).as_datatype_enum 101 ctx.ensure_initialized() --&gt; 102 return ops.EagerTensor(value, ctx.device_name, dtype) TypeError: Cannot convert 'inferred' to EagerTensor of dtype int64
</code></pre>
<p>I have tried other datatypes in the tf.one_hot function and none of them working. I'm guessing I am just missing some fundamental syntax error.</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory</a></p>
<p>I have also tried labels= *(a numpy array of integer values) with label_mode =int and that gave me another error. I also tried labels = None and it says 'Found 10222 files belonging to 1 classes.' so I'm not sure if I can add in the labels later to the fit function.</p>
",2022-08-21 18:58:29,7525231,47,https://stackoverflow.com/questions/73437417,Documentation Replication on Other Examples
73461248,Is there an alternative to tf.keras.utils.image_dataset_from_directory if images are not organized in class-folders?,"<p>I want to train an image classification network.</p>
<p>I have all images in one folder and a .json file with labels and a lot of meta data.
I wrote a couple of functions to extract the images which correspond to the classes I want to train for, shuffle them and randomly split them into a train- and a val-list.
So currently I have something like this:</p>
<pre><code>list_imagepath_train = [' C:\Users\someuser\Pictures\randomimagename1.jpg', ' C:\Users\someuser\Pictures\randomimagename2.jpg', ' C:\Users\someuser\Pictures\randomimagename5.jpg', ' C:\Users\someuser\Pictures\randomimagename8.jpg', ' C:\Users\someuser\Pictures\randomimagename9.jpg', ' C:\Users\someuser\Pictures\randomimagename10.jpg', ' C:\Users\someuser\Pictures\randomimagename12.jpg']

list_corresponding_classlabels_train = ['5', '5', '2', '3', '2', '2', '5']
    
list_imagepath_val = [' C:\Users\someuser\Pictures\randomimagename3.jpg', ' C:\Users\someuser\Pictures\randomimagename4.jpg', ' C:\Users\someuser\Pictures\randomimagename6.jpg', ' C:\Users\someuser\Pictures\randomimagename7.jpg']
    
list_corresponding_classlabels_val = ['2', '3', '5', '2']
</code></pre>
<p>And now I want to convert those lists to a train- and a val-dataset to use in Tensorflow.
The thing is that I can't use <code>tf.keras.utils.image_dataset_from_directory</code> because alle images, independent of their label, are in the same folder and it seems a bit pointless to me to move them around every time I start a new training. <code>tf.keras.preprocessing.image.ImageDataGenerator</code> is deprecated (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator</a>) and now I am not sure which function to use to convert the lists into the needed dataset.
This is all very new to me, so any input or hint is very welcome!</p>
",2022-08-23 15:18:25,19399312,142,https://stackoverflow.com/questions/73461248,Documentation Replicability
73645574,Why keras AUC returns zero when multi-label is set?,"<p>I'm trying to understand how <code>tf.keras.metrics.AUC(multi_label=True)</code> works. From the docs, I'm led to understand that when working with multi-label vectors, each class is computed individually, then averaged.</p>
<p>However, I can't seem to get the following trivial case to compute correctly. That is, if the prediction is the same as the expected vector, why is the output not <code>1.0</code>?</p>
<pre><code>y_true = [
    [1, 0, 0, 0, 1],
]

acc = tf.keras.metrics.AUC(multi_label=True, num_labels=5)

acc.reset_state()
acc.update_state(tf.constant(y_true), tf.constant(y_true))
acc.result().numpy()

&gt;&gt;&gt; 0.0
</code></pre>
",2022-09-08 07:58:50,774907,12738,https://stackoverflow.com/questions/73645574,Documentation Ambiguity
73657854,Is SageMaker Distributed Data-Parallel (SMDDP) supported for keras models?,"<p>Is SageMaker Distributed Data-Parallel (SMDDP) supported for keras models?</p>
<p>In documentation it says &quot;SageMaker distributed data parallel is adaptable to TensorFlow training scripts composed of tf core modules except tf.keras modules. SageMaker distributed data parallel does not support TensorFlow with Keras implementation.&quot; <a href=""https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp.html</a></p>
<p>But inside the training script and how to modify it, I can see the tf.keras and tf.keras.model is used. <a href=""https://sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.html"" rel=""nofollow noreferrer"">https://sagemaker.readthedocs.io/en/stable/api/training/sdp_versions/v1.0.0/smd_data_parallel_tensorflow.html</a></p>
",2022-09-09 05:56:11,19947257,126,https://stackoverflow.com/questions/73657854,Documentation Replication on Other Examples
73726034,Getting Attribute Error TensorDataset object has no attribute 'output_shapes' issue,"<p>Getting attribute error issue using tf.data.Dataset</p>
<pre><code>import numpy as np
import tensorflow as tf

x, y = np.array([1, 2, 3, 4]), np.array([5, 6, 7, 8])
d = tf.data.Dataset.from_tensors((x,y))

print(d.output_shapes) 


</code></pre>
<p><code>AttributeError: 'TensorDataset' object has no attribute 'output_shapes'</code></p>
<p><a href=""https://i.stack.imgur.com/WEpML.png"" rel=""nofollow noreferrer"">Screenshot</a></p>
<p>How to find output shapes?</p>
",2022-09-15 05:30:07,13697791,51,https://stackoverflow.com/questions/73726034,Documentation Replicability
73794766,what is the meaning of axis=-1 in tf.keras.layers.Normalization?,"<p>I'm trying to learn deep learning using keras and tensorflow and I came across a code explaining linear regression at <a href=""https://www.tensorflow.org/tutorials/keras/regression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/keras/regression</a> wherein they have created a normalization layer using normalizer = tf.keras.layers.Normalization(axis=-1). Someone please explain the meaning of axis =-1 . I tried looking at the API documentation but I couldnt understand the explanation from there?I know that axis=0 represent rows and axis=1 columns, right?
Thanks in advance</p>
",2022-09-21 02:31:00,19986715,1,https://stackoverflow.com/questions/73794766,Documentation Completeness
74060508,How to Save a Tensorflow Dataset,"<p>As the title says I'm trying to save a <code>TensorSliceDataset</code> object to file. Viewing tensorflow's <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">website</a> it seems that the <code>tf.data.Dataset</code> class has a save function but it is not implemented for <code>TensorSliceDataset</code> objects. Pickling also did not work for me.</p>
<p>Example code</p>
<pre><code>import tensorflow as tf
t = tf.range(10)
ds = tf.data.Dataset.from_tensor_slices(t)
ds.save()
</code></pre>
<p>returns error: <code>AttributeError: 'TensorSliceDataset' object has no attribute 'save'</code></p>
",2022-10-13 18:54:28,7875444,298,https://stackoverflow.com/questions/74060508,Documentation Replicability
74182037,"How to ""update"" from module tf.keras.preprocessing.image to tf.keras.utils.image_dataset_from_directory for features extraction","<p>This code part is common to both &quot;problematic&quot; codes below:</p>
<pre><code>BATCH_SIZE = 32
IM_DIR = '/content/drive/My Drive/101_ObjectCategories/'
IM_HEIGHT = 224
IM_WIDTH = 224
NUM_IM = 8686
NUM_EPOCHS = int(math.ceil(NUM_IM / BATCH_SIZE))

#load pre-trained base model
model = ResNet50(weights='imagenet',
                 include_top=False,
                 input_shape=(IM_WIDTH, IM_HEIGHT, CH),
                 pooling='max')
</code></pre>
<p>The following code I successfully use to extract features of a set of images using module <code>tf.keras.preprocessing.image</code>.</p>
<pre><code>datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)
dataset = datagen.flow_from_directory(IM_DIR,
                                      target_size=(IM_HEIGHT, IM_WIDTH),
                                      class_mode=None,
                                      shuffle=False)

feature_list = []
feature_list = model.predict(dataset, num_epochs)
</code></pre>
<p>Thereafter I train a simple nearest-neighbor model using brute-force algorithm and I'm able to find three other images that are really similar to the query image as you can see below:</p>
<p><a href=""https://i.stack.imgur.com/qPi7q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qPi7q.png"" alt=""Right results"" /></a></p>
<p>But as pointed in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image"" rel=""nofollow noreferrer"">documentation</a> this preprocessing module is deprecated.<br />
So, I would like to &quot;update&quot; the code as suggested in the documentation: &quot;Prefer loading data with <code>tf.keras.utils.image_dataset_from_directory</code>, and then transforming the output <code>tf.data.Dataset</code> with preprocessing layers&quot;.<br />
For that I'm trying the following:</p>
<pre><code>#load images
dataset = tf.keras.utils.image_dataset_from_directory(
  IM_DIR,
  labels='inferred', #'inferred', None
  label_mode='categorical',  #'int', 'categorical', 'binary' or None
  class_names=None,
  color_mode='rgb',  #'grayscale', 'rgb' or 'rgba'
  batch_size=BATCH_SIZE,
  image_size=(IM_HEIGHT, IM_WIDTH),
  shuffle=True,
  seed=51719,
  validation_split=None,
  subset=None,                #'training', 'validation' or 'both'
  interpolation='bilinear',   #'bilinear', 'nearest', 'bicubic', 'area', 'lanczos3', 'lanczos5', 'gaussian' or 'mitchellcubic'
  follow_links=False,
  crop_to_aspect_ratio=False
)

#&quot;transforming the output with preprocessing layers&quot;
#rescale (normalize) dataset
rescale_layer = tf.keras.layers.Rescaling(1./255)

rescaled_dataset = dataset.map(lambda x, y: (rescale_layer(x), y))
im_batch, labels_batch = next(iter(rescaled_dataset))


#configure dataset for performance
#https://www.tensorflow.org/tutorials/load_data/images#configure_the_dataset_for_performance

AUTOTUNE = tf.data.AUTOTUNE
tuned_dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)
</code></pre>
<p>And now I begin with the features extraction</p>
<pre><code>#features extraction
#https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict
feature_list = []

feature_list = model.predict(
    tuned_dataset,
    batch_size=None,
    verbose='auto',
    steps=None,
    callbacks=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False
)

#save features
pickle.dump(
    feature_list,
    open(DATA_DIR + 'features.pickle', 'wb'))
</code></pre>
<p>After that I do the same and train the nearest neighbor model with this features, but the results are catastrophic as you can see below:</p>
<p><a href=""https://i.stack.imgur.com/18Wsa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/18Wsa.png"" alt=""Bad results"" /></a></p>
<p>What I'm doing so wrong that I have such different results?</p>
<p><strong>== EDIT 1 ==</strong></p>
<p>Answering @DWKOT using the same image we have following results:</p>
<pre><code>#Query image with first code
im_idx = 75
distances, indices = neighbors.kneighbors([feature_list[im_idx]])
plt.imshow(mpimg.imread(filenames[im_idx]), interpolation='lanczos')
</code></pre>
<p><a href=""https://i.stack.imgur.com/V7EdQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/V7EdQ.png"" alt=""Query image"" /></a></p>
<pre><code>#Similar image
plt.imshow(mpimg.imread(filenames[indices[0][1]]), interpolation='lanczos')
</code></pre>
<p><a href=""https://i.stack.imgur.com/UfUG8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UfUG8.png"" alt=""Similar image"" /></a></p>
<p>And the code that give us the distance to the 5 nearest neighbors:</p>
<pre><code>for i in range(5):
    print(distances[0][i])
</code></pre>
<p>With the following results:</p>
<pre><code>0.0
185.60701
185.75049
195.71657
196.4056
</code></pre>
<p>With the second code we have following result for query / similar image:</p>
<p><a href=""https://i.stack.imgur.com/V7EdQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/V7EdQ.png"" alt=""Query image"" /></a> / <a href=""https://i.stack.imgur.com/lW4n1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lW4n1.png"" alt=""Similar image 2"" /></a></p>
<p>And following results for the first five &quot;similar&quot; images:</p>
<pre><code>0.0
0.81401
0.88622
0.92734
0.9346
</code></pre>
<p>What is also strange as I would expect similar images having values next to zero and different ones far from zero...</p>
",2022-10-24 13:44:48,3499881,843,https://stackoverflow.com/questions/74182037,Documentation Replication on Other Examples
74330500,Keras GradCam implementation that can process batches of images instead of a single image at a time,"<p>I'm following the GradCam example from the Keras documentation <a href=""https://keras.io/examples/vision/grad_cam/"" rel=""nofollow noreferrer"">https://keras.io/examples/vision/grad_cam/</a> and want to modify it so that it can process a batch of images instead of only a single image at a time.</p>
<p>I was already able to accomplish this but had to use a call to <code>tf.map_fn</code> which I would like to get rid of in the hopes of a performance improvement.</p>
<p>My progress so far (whole code at <a href=""https://colab.research.google.com/drive/1ptoRzS3WpThhHokX4p2nv-e2I-Oaq9bq?usp=sharing"" rel=""nofollow noreferrer"">Google Coolab</a>):</p>
<pre class=""lang-py prettyprint-override""><code>#https://keras.io/examples/vision/grad_cam/
def make_gradcam_heatmap(grad_model, images, pred_index=None):
    images = tf.cast(images, tf.float32)

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        tape.watch(images)
        last_conv_layer_output, preds = grad_model(images)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)
    assert grads is not None, &quot;GradientTape returned gradients=None&quot;

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(1, 2))

    # We multiply each channel in the feature map array
    # by &quot;how important this channel is&quot; with regard to the top predicted class
    # then sum all the channels to obtain the heatmap class activation
    def single_image(index):
        return last_conv_layer_output[index] @ pooled_grads[index][tf.newaxis, ..., tf.newaxis]

    heatmaps = tf.map_fn(single_image, tf.range(tf.shape(grads)[0]), dtype=tf.float32)

    # normalize the whole batch to [0, 1]
    heatmaps -= tf.math.reduce_min(heatmaps, axis=(0,1,2,3))
    heatmaps /= tf.math.reduce_max(heatmaps, axis=(0,1,2,3))

    return heatmaps
</code></pre>
<hr />
<p>Is there any way to rewrite this code in such a way that it doesn't use <code>tf.map_fn</code>?</p>
<pre class=""lang-py prettyprint-override""><code>    def single_image(index):
        return last_conv_layer_output[index] @ pooled_grads[index][tf.newaxis, ..., tf.newaxis]

heatmaps = tf.map_fn(single_image, tf.range(tf.shape(grads)[0]), dtype=tf.float32)
</code></pre>
",2022-11-05 18:37:49,2422125,3839,https://stackoverflow.com/questions/74330500,Documentation Replication on Other Examples
74434308,Setting only global level seed gives same output in consecutive iterations of loop in Tensorflow,"<p>I am testing out the <code>tf.random.set_seed</code> according to the rules given at - <a href=""https://www.tensorflow.org/api_docs/python/tf/random/set_seed"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/random/set_seed</a></p>
<p>In particular I am testing the second rule - where we set only global level seed and no operation level seed.</p>
<p>According to the documentation (the link is mentioned above), the second rule is:</p>
<blockquote>
<p>If the global seed is set, but the operation seed is not: The system deterministically picks an operation seed in conjunction with the global seed so that it gets a unique random sequence.</p>
</blockquote>
<p>To explain the second rule, the documentation uses the following snippet:</p>
<pre><code>tf.random.set_seed(1234)
print(tf.random.uniform([1]))  # generates 'A1'
print(tf.random.uniform([1]))  # generates 'A2'
</code></pre>
<p>and states that</p>
<blockquote>
<p>The reason we get 'A2' instead 'A1' on the second call of tf.random.uniform above is because the second call uses a different operation seed.</p>
</blockquote>
<p>Now, I tested this rule on a 1D tensor of shape (3,) to check if the output of shuffling the tensor does not give the same sequence within consecutive iterations of the loop as follows:</p>
<pre><code>import tensorflow as tf


&quot;&quot;&quot;
Only global level seed
&quot;&quot;&quot;

tf.random.set_seed(1234)
   
constant_tensor = tf.constant([1,2,3])

for i in range(1, 15):
    shuffled_tensor = tf.random.shuffle(constant_tensor)
    print(shuffled_tensor)
</code></pre>
<p>I got the following output:</p>
<pre><code>tf.Tensor([3 1 2], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([1 3 2], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([1 2 3], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
</code></pre>
<p>From the output you can see that the sequence on line number 7 and 8 match.
Also the sequence on line number 13 and 14 match.</p>
<p>According to the documentation, tensorflow should not output the same sequence in a consecutive iteration.</p>
<p>Then why am I getting this kind of output? Have I misunderstood the concept?</p>
<p>To test this further, I also tested to following snippet which I used to generate 14 1-D tensors and check if any tensor is repeated within consecutive runs as follows:</p>
<pre><code>import tensorflow as tf
tf.random.set_seed(1234)
for i in range(1, 15):
    print(tf.random.uniform(shape=[1], minval=1, maxval=15, dtype=tf.int32))
</code></pre>
<p>And I got the following output:</p>
<pre><code>tf.Tensor([12], shape=(1,), dtype=int32)
tf.Tensor([8], shape=(1,), dtype=int32)
tf.Tensor([1], shape=(1,), dtype=int32)
tf.Tensor([2], shape=(1,), dtype=int32)
tf.Tensor([4], shape=(1,), dtype=int32)
tf.Tensor([3], shape=(1,), dtype=int32)
tf.Tensor([2], shape=(1,), dtype=int32)
tf.Tensor([7], shape=(1,), dtype=int32)
tf.Tensor([13], shape=(1,), dtype=int32)
tf.Tensor([11], shape=(1,), dtype=int32)
tf.Tensor([8], shape=(1,), dtype=int32)
tf.Tensor([3], shape=(1,), dtype=int32)
tf.Tensor([1], shape=(1,), dtype=int32)
tf.Tensor([4], shape=(1,), dtype=int32)
</code></pre>
<p>You can see that no two consecutive tensors are repeated. Why didn't I see this behaviour for my first snippet?</p>
",2022-11-14 15:44:35,7422352,5021,https://stackoverflow.com/questions/74434308,Documentation Ambiguity
74442047,How to calculate the matrix's inverse using tflite,"<p>as far as i known, the matrix's inverse is a common operator.</p>
<p>while tf.raw_ops.MatrixInverse is not supported in tflite and BatchMatrixInverse is not available in GraphDef version 1205.</p>
<p>How can i calculate the inverse of the matrix in tflite?</p>
<p>Best wishes</p>
",2022-11-15 07:36:45,7693201,21,https://stackoverflow.com/questions/74442047,Documentation Replicability
74456127,AttributeError: type object 'DatasetV2' has no attribute 'save',"<pre><code>test_ds.save(path)
</code></pre>
<p>I want to save the tf.data.Dataset,but get the message &quot;AttributeError: type object 'DatasetV2' has no attribute 'save'&quot;</p>
",2022-11-16 06:37:02,20517027,1,https://stackoverflow.com/questions/74456127,Documentation Replicability
74545053,Is there an equivalent of tf.gradients function in tensorflow C or C++ API?,"<p>I want to implement a tensorflows function <a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">tf.gradients</a> in C or C++ API? Tensorflow C++ has the <a href=""https://www.tensorflow.org/api_docs/cc"" rel=""nofollow noreferrer"">worst documentation</a> in the world and C API aren't documented at all. Can you suggest if there is an implementation or which API parts should I use to develop this myself.</p>
",2022-11-23 10:10:02,2426998,393,https://stackoverflow.com/questions/74545053,Documentation Completeness
74809872,How can I use a function like tf.TensorArray in Pytorch?,"<p>I need to change code from tensorflow to pytorch. Is there a similar function like <code>tf.TensorArray</code>?</p>
<p>For example:</p>
<pre><code>iou_mask = tf.TensorArray(dtype=tf.float32, size=1, dynamic_size=True)
</code></pre>
",2022-12-15 10:09:47,20781411,1,https://stackoverflow.com/questions/74809872,Documentation Replicability
74861849,How to fix the batch size in keras subclassing model?,"<p>In tf.keras functional API, I can fix the batch size like below:</p>
<pre><code>import tensorflow as tf

inputs = tf.keras.Input(shape=(64, 64, 3), batch_size=1)    # I can fix batch size like this
x = tf.keras.layers.Conv2DTranspose(3, 3, strides=2, padding=&quot;same&quot;, activation=&quot;relu&quot;)(inputs)
outputs = x
model = keras.Model(inputs=inputs, outputs=outputs, name=&quot;custom&quot;)
</code></pre>
<p>My question is, how do I can fix the batch size when I use the keras subclassing approach?</p>
",2022-12-20 10:44:52,8551737,435,https://stackoverflow.com/questions/74861849,Documentation Replicability
75136950,How to visualize tf.compat.v1 static graph in tensorboard?,"<p>For a given graph, how can we visualize the graph using tensorboard for tf.compat.v1 ?
Sharing this here after searching everywhere. Most of the documentations explains tf.keras and not for tf.compat.v1 static graphs</p>
",2023-01-16 16:19:12,10545426,369,https://stackoverflow.com/questions/75136950,Documentation Replication on Other Examples
75225610,How does tf.GradientTape record operations inside the with statement?,"<p>I don't understand how tf.GradientTape record operations like <code>y=x**2</code> inside the &quot;with&quot; statement (following operations).</p>
<pre><code>x = tf.Variable(3.0)

with tf.GradientTape() as tape:
  y = x**2
</code></pre>
<p>What Python syntax can be used to achieve this behavior?</p>
",2023-01-24 18:15:31,7973784,119,https://stackoverflow.com/questions/75225610,Documentation Replicability
75354761,Looking for source of information relating the most efficient ways to use tf.js methods,"<p>Is there any source of information relating efficiency of different tfjs methods, for example after benchmarking it seems like using casting on a tf.add operation is much slower than summing the pre existing tensors.</p>
<p>Any ideas?</p>
<p>During bench marking I see operations suche as argMax or max are very slow.</p>
",2023-02-05 18:59:58,9194598,11,https://stackoverflow.com/questions/75354761,Documentation Replicability
75401761,Change Verbosity of Keras train_on_batch()?,"<p>I am training a GAN using Keras's <code>train_on_batch()</code> command. This is very similar to Keras's <code>fit()</code>. However, in the documentation for <code>fit()</code>, there is a parameter for <code>verbose</code>, which changes how often a progress bar is printed to the console.</p>
<p>My model has many batches, and so it is printing tons of progress bars to the command line. Unfortunately, <code>train_on_batch()</code> does not have a <code>verbose</code> parameter. Is there a workaround for this? Is there a Keras global variable/environment variable that I can set? I don't want to disable my program from printing to the console, I just want to change the verbosity of specifically <code>train_on_batch()</code>.</p>
<p>For clarify, I am using Keras directly from the Keras package, I am not using tf.keras.</p>
",2023-02-09 16:41:49,12276162,448,https://stackoverflow.com/questions/75401761,Documentation Replicability
75403101,How do I distribute datasets between multiple GPUs in Tensorflow 2?,"<p>I'm trying to understand how to use multiple gpus to train a model on data too large for the GPU memory. Using <code>tf.distribute.MirroredStrategy</code> seems to copy the full data set to each GPU. What I'm hoping to do is to send a subset of the full dataset to each GPU (2 or 4 gpus) and use MirroredStrategy to reconcile parameter updates on each epoch.</p>
<p><code>MirroredStrategy.distribute_datasets_from_function()</code> looks promising.
<a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy#distribute_datasets_from_function"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy#distribute_datasets_from_function</a></p>
<p>Problem details:
A fairly complicated multimodal NN with ~200k parameters synthesizing many text, transactional, and structured inputs and with multiple regression and probabilistic outputs. I'm looking at moving development from a single GPU with 24gb memory to cloud compute with multiple 16gb cards on a single node.</p>
<p>The input and targets are currently dictionaries of numpy arrays. I'm hoping for a toy example converting those dictionaries into a distributed data set through to training with different subsets of the full data set assigned to each GPU.</p>
<p>I attempted this:</p>
<pre class=""lang-py prettyprint-override""><code>def build_model(**model_params):
    '''
    Builds a model from model_params
    '''
    return tf.keras.Model(
       inputs = [MY_INPUT_TENSORS],
       output = [MY_OUTPUT_TENSORS])

distributed_strategy = tf.distribute.MirroredStrategy()

with distributed_strategy.scope():
    train_model = build_model(**model_params)

    train_model.compile(...)


train_model.fit(X_dict, y_dict)
</code></pre>
<p>This runs on a 50% sample of the data, but returns OOM on the full sample on 2 GPUs. The full data set appears to be copied to each of the 2 16gb GPUs available. The same model runs with a 100% sample on a single 24gb GPU.</p>
",2023-02-09 18:43:40,1998707,89,https://stackoverflow.com/questions/75403101,Documentation Replication on Other Examples
75474546,Different behaviour between tf.reduce_dims + broadcasting and tf.reduce_dims + tf.tile,"<p>What could be causing that this code behaves differently in TensorFlow by exchanging both lines as marked in the code? The broadcasting would happen after creating the mask so I don't think this is caused by the tf.math.equal function. In the end the sum is close but different in both cases.</p>
<pre><code>def get_loss(mask_value):
    mask_value = tf.Variable(mask_value, dtype=tf.float32)
    def masked_seq_exact_orientation_loss(y_true, y_pred):
        # find out which timesteps in `y_true` are not the padding character
        mask = tf.reduce_all(tf.math.equal(y_true, mask_value), axis=-1)
        mask = 1.0 - tf.cast(mask, tf.float32)

        # These two lines should do the same but don't!!!!!!!! ----------
        mask = tf.tile(tf.expand_dims(mask, axis=-1), [1, 1, y_pred.shape[-1]])
        #mask = tf.expand_dims(mask, axis=-1)
        # ----------------------------------------------------------------

        # multiply loss with the mask
        loss = tf.math.abs(y_true[:,:,0:2] - y_pred) * mask

        tf.print(tf.math.reduce_sum(loss))

        # take average w.r.t. the number of unmasked entries
        return tf.math.reduce_sum(loss) / tf.math.reduce_sum(mask)
    return masked_seq_exact_orientation_loss
</code></pre>
<p>Thanks!</p>
",2023-02-16 15:36:16,11268438,13,https://stackoverflow.com/questions/75474546,Documentation Replicability
75478235,tf.image.ssim() not accepting 'return_index_map' argument,"<p>The documentation for Tensorflow's <a href=""https://www.tensorflow.org/api_docs/python/tf/image/ssim"" rel=""nofollow noreferrer"">tf.image.ssim()</a> says that if you want to return an element-wise structural similarity map, you can set &quot;return_index_map&quot; to True. It is returning an error when I define the argument as either True or False. I am running Tensorflow 2.10 on an Apple M1 Max.</p>
<p>When I run:</p>
<pre><code>    import tensorflow as tf

    a = tf.ones((20, 20, 20, 20))
    b = tf.zeros((20, 20, 20, 20))

    sim = tf.image.ssim(a, b, max_val=1, return_index_map=True)
</code></pre>
<p>I get the error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;/Users/miguel/opt/miniconda3/envs/py39_tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py&quot;, line 3433, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &quot;&lt;ipython-input-4-967be677c86c&gt;&quot;, line 1, in &lt;module&gt;
    sim = tf.image.ssim(a, b, max_val=1, return_index_map=True)
  File &quot;/Users/miguel/opt/miniconda3/envs/py39_tensorflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py&quot;, line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File &quot;/Users/miguel/opt/miniconda3/envs/py39_tensorflow/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py&quot;, line 1170, in op_dispatch_handler
    result = api_dispatcher.Dispatch(args, kwargs)
TypeError: Got an unexpected keyword argument 'return_index_map'
</code></pre>
",2023-02-16 21:44:50,20324823,1,https://stackoverflow.com/questions/75478235,Documentation Replicability
75555845,How to check whether masking works OK in Tensorlow / Keras,"<p>I want to train a transformer model that maps input vectors to an output vector. The input vector is padded with zero to make all the input vectors have the same length. To skip the padded values I use the <code>tf.keras.layers.Masking</code> layer. Here is the full model:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tf.keras.layers import Input, Dense, Masking, Flatten
from keras_nlp.layers import TransformerEncoder

values = Input(shape=(max_len,))
masked_values = Masking(mask_value=0.)(values) # Create a mask to ignore padded values
cont_emb = TransformerEncoder(num_heads=num_head,intermediate_dim=ffn_dim)(masked_values)
cont_emb_2 = Flatten()(cont_emb)
output = Dense(V)(cont_emb_2) 
</code></pre>
<p>The <code>TransformerEncoder</code>'s documentation can be found here: <a href=""https://keras.io/api/keras_nlp/layers/transformer_encoder/"" rel=""nofollow noreferrer"">https://keras.io/api/keras_nlp/layers/transformer_encoder/</a></p>
<p>This model works and generates outputs but I have no idea if the padded values are being skipped or not. Can anyone tell me if the model is OK or not? Or how can I check whether the padded values are skipped?</p>
",2023-02-24 11:02:10,12014637,582,https://stackoverflow.com/questions/75555845,Documentation Replication on Other Examples
75572543,What to look out for when passing a generator into model.fit in tensorflow?,"<p>I want to replace the x and y training data parameters in tf.keras.Model.fit with a generator. However, some subtlety seems to escape me, as the model accuracy doesn't improve with the generator when training.</p>
<p>As far as I understand the documentation, the generator is supposed to yield tuples <code>(x_vals,y_vals)</code>, such that <code>x_vals</code> is a concatenation of <code>batch_size</code>-many training samples along a new 0th dimension, and 'v_vals' is the concatenation of their corresponding labels.</p>
<p>As long as the generator fulfills this, as I understand it, we can just replace the x parameter in tf.keras.Model.fit with the generator and omit the y parameter, though to define an epoch, we also need to specify 'steps_per_epoch' in fit.</p>
<p>There however seems to be something here I misunderstood or forgot, because starting with a model and input data that trains (i.e. its accuracy improves) and replacing the training data array with a generator as discussed, results in a model that doesn't train (i.e. its accuracy instead goes up a little, then however goes back down till its equal to chance).</p>
<p>The corresponding code:</p>
<pre><code>import numpy as np
import tensorflow as tf

BATCH_SIZE = 32

#Loading training data:
def load_cifar():
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
    assert x_train.shape == (50000, 32, 32, 3)
    assert x_test.shape == (10000, 32, 32, 3)
    assert y_train.shape == (50000, 1)
    assert y_test.shape == (10000, 1)

    #Normalize the data &amp; cast to fp32:
    x_train = np.true_divide(x_train,255,dtype=np.single)
    x_test =  np.true_divide(x_test,255,dtype=np.single)
    y_train = y_train.astype(np.single)
    y_test =  y_test.astype(np.single)

    return (x_train,y_train), (x_test,y_test)


(train_x, train_y) , (validation_x, validation_y) = load_cifar()
   


# Defining the generator:
def data_generator_dummy(input_data_x:np.ndarray,
                          input_data_y:np.ndarray,
                          batch_size=BATCH_SIZE,
                          ):
    &quot;&quot;&quot;
    Given the input_data's, generate infinitely by:
     1. Drawing batch_size-many vectors from input_data_x and input_data_y
     2. Turn the drawn vectors into a mini-batch (with shape  [None]+input_data.shape)

    :param batch_size:
    :param input_data_x, input_data_y: The data on which noise shall be added
    :return: A generator for the input data.
    &quot;&quot;&quot;
    index =0
    while True:
        # We start with a zero-vector of expected size and fill the drawn samples into it:
        samples_x = np.zeros( [batch_size] + list(input_data_x.shape[1:]),dtype=np.single)
        samples_y = np.zeros( [batch_size] + list(input_data_y.shape[1:]),dtype=np.single)
        for i in range(batch_size):
            samples_x[i] = input_data_x[index%50_000]
            samples_y[i] = input_data_y[index%50_000]
            index +=1

        yield samples_x,samples_y

# Basically a linear classifier:
def make_model():
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(10,tf.nn.softmax))
    model.build([None] +list(train_x[0,:,:,:].shape))
    return model


#Training:
generator = data_generator_dummy(train_x,train_y,batch_size=BATCH_SIZE)
model = make_model()
model.summary()
optimizer_adam=tf.keras.optimizers.Adam(learning_rate=0.0005/32,beta_1=0.9,beta_2=0.999,epsilon=1e-07)
model.compile(optimizer_adam,loss=&quot;sparse_categorical_crossentropy&quot;,metrics=&quot;accuracy&quot;)
model.fit(generator, validation_data=(validation_x,validation_y),epochs=10,
          steps_per_epoch=train_x.shape[0]//BATCH_SIZE,
          )

# This one however works:
# model.fit(train_x, train_y, validation_data=(validation_x,validation_y),epochs=30,
#           steps_per_epoch=train_x.shape[0]//BATCH_SIZE,
#           shuffle=True
#           )
</code></pre>
<hr />
<p>The model also trains if one first let's the generator generate a long list of samples and then passes those into <code>fit</code> as <code>x</code>and <code>y</code>:</p>
<pre><code>#Training:
generator = data_generator_dummy(train_x,train_y,batch_size=50000)
model = make_model()
model.summary()
optimizer_adam=tf.keras.optimizers.Adam(learning_rate=0.0005/32,beta_1=0.9,beta_2=0.999,epsilon=1e-07)
model.compile(optimizer_adam,loss=&quot;sparse_categorical_crossentropy&quot;,metrics=&quot;accuracy&quot;)
while True:
    samples_x,samples_y = next(generator)
    model.fit(samples_x,samples_y, validation_data=(validation_x,validation_y),epochs=10,batch_size=BATCH_SIZE
          )
</code></pre>
",2023-02-26 14:08:48,8536211,360,https://stackoverflow.com/questions/75572543,Documentation Replication on Other Examples
75639137,TF1 to TF2 migration,"<p>Hello I am new to tensorflow and I am working on a code that I would like to migrate from tensorflow 1 to 2. I have this line of code:</p>
<pre><code>x1 = tf.compat.v1.placeholder(tf.float32, [], name=&quot;x1&quot;)
</code></pre>
<p>As mentioned in <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder</a>, I should use <code>keras.Input</code>. But even when specifying the shape, I can't have the same tensor as with compat.v1:</p>
<pre><code>x2 = tf.keras.Input(shape=[], dtype=tf.float32, name=&quot;x2&quot;)
</code></pre>
<p>To check the shape I use <code>tf.shape(x1)</code> or <code>tf.shape(x2)</code>, but the shapes are not the same. Could anyone explain to me how to have, in TF2, the same shape as in TF1 ?
Thanks and regards</p>
",2023-03-04 22:44:35,15822972,101,https://stackoverflow.com/questions/75639137,Documentation Replicability
75639356,"Explanation on ""Tensorflow AutoGraph support print and assert""","<h1>Background</h1>
<p>In <a href=""https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html"" rel=""nofollow noreferrer"">AutoGraph converts Python into TensorFlow graphs</a> it says:</p>
<blockquote>
<p>We (AutoGraph) also support constructs like break, continue, and <strong>even print and assert</strong>. When converted, this snippet’s Python assert converts to a graph that uses the appropriate tf.Assert.</p>
</blockquote>
<p>However, <a href=""https://www.tensorflow.org/guide/intro_to_graphs"" rel=""nofollow noreferrer"">Introduction to graphs and tf.function</a> says:</p>
<blockquote>
<p>To explain, the print statement is executed when Function runs the original code in order to create the graph in a process known as &quot;tracing&quot; (refer to the Tracing section of the tf.function guide. Tracing captures the TensorFlow operations into a graph, and <strong>print is not captured in the graph</strong>. That graph is then executed for all three calls without ever running the Python code again.</p>
</blockquote>
<h1>Question</h1>
<p>The first documents gives the impression that I can use <code>print</code> and TensorFlow AutoGraph can convert into Tensorflow operations. However apparently it is not the case as in the second document.</p>
<p>Please help understand if the sentence in the first document stating &quot;We/AutoGraph support even print and assert&quot; is still correct or if I misunderstand something.</p>
<p>In my understanding, AutoGraph is the one being used under <code>@tf.function</code> and <code>tf.py_function</code>.</p>
",2023-03-04 23:40:08,4281353,20088,https://stackoverflow.com/questions/75639356,Documentation Replication on Other Examples
75639435,tf.executing_eagerly() returns true even when in graph mode,"<p>Why tf.executing_eagerly() returns True after <code>tf.config.run_functions_eagerly(False)</code>?</p>
<pre><code>Python 3.9.13
TensorFlow version: 2.10.0
</code></pre>
<pre><code>@tf.function
def my_func(a):
    print(&quot;Python side effect&quot;)
    return a + a

a_fn = tf.function(my_func)
</code></pre>
<p><a href=""https://i.stack.imgur.com/7RsWLl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7RsWLl.png"" alt=""enter image description here"" /></a></p>
",2023-03-04 23:59:16,4281353,20088,https://stackoverflow.com/questions/75639435,Documentation Replicability
75640862,tf.py_function is only for Eager Mode?,"<p>Is <code>tf.py_function</code> only for Eager mode, and not for Graph mode?</p>
<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function#args"" rel=""nofollow noreferrer"">tf.py_function</a> says, it gives the impression that <code>tf.py_function</code> is to be used at Eager mode.</p>
<blockquote>
<p>Wraps a python function into a TensorFlow op <strong>that executes it eagerly</strong>.</p>
</blockquote>
<blockquote>
<p>This function allows expressing computations <strong>in a TensorFlow graph as Python functions</strong>. In particular, it wraps a Python function func in a once-differentiable TensorFlow operation that executes it with eager execution enabled.</p>
</blockquote>
<blockquote>
<p>You can also use tf.py_function to debug your models at runtime using Python tools, i.e., you can isolate portions of your code that you want to debug, wrap them in Python functions and insert pdb tracepoints or print statements as desired, and wrap those functions in tf.py_function.</p>
</blockquote>
<blockquote>
<p>Calling tf.py_function will <strong>acquire the Python Global Interpreter Lock (GIL)</strong> that allows only one thread to run at any point in time. This will preclude efficient parallelization and distribution of the execution of the program.</p>
</blockquote>
<p>I believe pdb works with Python interpreter and GIL is inside it, but there is no Python interpreter executing Python code while executing TensorFlow Graph in Graph mode. Hence I believe it is only for Eager Mode. Please confirm if this is correct.</p>
",2023-03-05 08:02:03,4281353,20088,https://stackoverflow.com/questions/75640862,Documentation Replicability
75838967,AttributeError: module 'tensorflow' has no attribute 'contrib'. tried other forums already,"<pre><code>import os
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.builders import model_builder
</code></pre>
<pre><code>    AttributeError                            Traceback (most recent call last)
    Cell In[16], line 4
          2 from object_detection.utils import label_map_util
          3 from object_detection.utils import visualization_utils as viz_utils
    ----&gt; 4 from object_detection.builders import model_builder

    File c:\Users\dell lattitude\anaconda3\envs\tsflow\lib\site-      packages\object_detection\builders\model_builder.py:22
         20 from object_detection.builders import anchor_generator_builder
         21 from object_detection.builders import box_coder_builder
    ---&gt; 22 from object_detection.builders import box_predictor_builder
         23 from object_detection.builders import hyperparams_builder
         24 from object_detection.builders import image_resizer_builder

     File c:\Users\dell lattitude\anaconda3\envs\tsflow\lib\site-     packages\object_detection\builders\box_predictor_builder.py:28
         26 from object_detection.predictors.heads import keras_box_head
         27 from object_detection.predictors.heads import keras_class_head
    ---&gt; 28 from object_detection.predictors.heads import mask_head
         29 from object_detection.protos import box_predictor_pb2
         32 def build_convolutional_box_predictor(is_training,
         33                                       num_classes,
         34                                       conv_hyperparams_fn,
       (...)
         44                                       class_prediction_bias_init=0.0,
         45                                       use_depthwise=False,):
    ...
         34   Please refer to Mask RCNN paper:
         35   https://arxiv.org/abs/1703.06870
         36   &quot;&quot;&quot;

    AttributeError: module 'tensorflow' has no attribute 'contrib'
</code></pre>
<p>I tried using tf_updatev2, that didn't work. also tried manually replacing files with    tf.compat.v1.estimator since that's supposed to work in tfv2.xxx</p>
",2023-03-25 00:15:30,18569492,1,https://stackoverflow.com/questions/75838967,Documentation Replicability
75939760,Slow performance of tf.gather due to index validation on CPU,"<p>I am using tensorflow to train <a href=""https://www.matthewtancik.com/nerf"" rel=""nofollow noreferrer"">Neural Radiancy Fields</a>. I used <code>tf.gather</code> to implement a multiresolution hashtable encoding as described in <a href=""https://nvlabs.github.io/instant-ngp/"" rel=""nofollow noreferrer"">this paper</a>. The important part is, that I am trying to retrieve values from a tensor that is optimized during trainig according to hash values that I computed out of 3D positions. I need to potentially do this for hundreds of thousands of values to render a single image so performance is critical.</p>
<p>I am using a GPU for training. The performance is not as good as I would expect it though which I suspect is due to the index validation for tf.gather being done on the CPU instead of the GPU. The GPU capacity is not fully utilized and I see significant CPU load. This is described in the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer"">here</a>. It says that the argument <code>validate_indices</code> is deprecated and that index validation is always done on the CPU.</p>
<p>My question is, if there is potentially a way to either</p>
<ul>
<li>disable the index validation for tf.gather</li>
<li>do the validation on the GPU</li>
<li>get around the use of tf.gather all together and use a method to get the values that is faster</li>
</ul>
<p>The values are updated during the training so precomputing values will not help in this case.</p>
<p>This is the code for the hash embedding that is functional but not performant due to the index validation:</p>
<pre><code># Setup
import tensorflow as tf
import numpy as np

# Hyperparameter
T = 2**20           # Size of the Hashtable
L = 16              # Number of Resolutions
F = 2               # Number of Dimentions of the Resolution
N_MIN = 2**4        # Minimum Resolution 
N_MAX = 2**18       # Maximum Resolution
VOLUME_SIZE = 10    # Bounding Box for the positions to be hashed

BATCH_SIZE = 1

# Large prime numbers used for the Hash Function
pi_i = tf.constant([1, 2654435761, 805459861], dtype=tf.int32)
# Build the Resolutions for each Layer
n_l = range(L)
b = np.exp((np.log(N_MAX)-np.log(N_MIN))/(L-1))
n_l = tf.constant([N_MIN * b ** l for l in n_l], dtype=tf.float32)

'''
These are the indices for the coordinates of the 8 vertices of the voxel in respect to a tensor with the elements:
X_Low
Y_Low
Z_Low
X_High
Y_High
Z_High
'''

vertex_indices = tf.constant([[0, 1, 2],    # X_Low, Y_Low, Z_Low
                              [3, 1, 2],    # X_High, Y_Low, Z_Low
                              [0, 4, 2],    # ...
                              [3, 4, 2], 
                              [0, 1, 5], 
                              [3, 1, 5], 
                              [0, 4, 5], 
                              [3, 4, 5]])

#@tf.function
def encode_position_hash(x, table):
    res = []
    x = x / VOLUME_SIZE

    # Get the vertices of the voxel that the postion is placed in at the multiple resolutions
    v = n_l * x[..., None]
    v = tf.concat([tf.math.floor(v), tf.math.ceil(v)], axis=2)
    v = tf.cast(v, dtype=tf.int32)
    v = tf.transpose(v, [3, 0, 1, 2])

    # SLOW #
    vertices = tf.gather(v, vertex_indices, axis = -1)
    # SLOW # 

    # calculate the hash
    v = vertices * pi_i[None, None, None, None,...]
    hash = tf.bitwise.bitwise_xor(v[..., 0], v[..., 1])
    hash = tf.bitwise.bitwise_xor(hash, v[..., 2])
    hash = tf.cast(tf.math.floormod(hash, T), dtype=tf.int32)

    # get the entries from the table
    # SLOW #
    vals = tf.gather(table, hash, axis=1, batch_dims=1)
    # SLOW #

    # Linear interpolation between the Embeddings of the voxel vertices
    x_tmp = tf.transpose((n_l * x[..., None]),[3, 0, 1, 2])[..., None, :]   # input positions 
    diff = tf.cast(vertices, dtype=tf.float32) - x_tmp                      # vectors to the vertices
    diff = tf.norm(diff, axis=-1)                                           # norm of the vectors -&gt; distances to vertices
    diff = tf.math.l2_normalize(diff, axis = -1)                            # normalize 
    res = tf.reduce_sum(vals * diff[..., None], axis = 3)                   # weighing of the embeddings
    res = tf.transpose(res, [1, 2, 3, 0])                                   # reshaping and reordering of the axes
    res = tf.reshape(res, (BATCH_SIZE, -1, L*F))

    res = tf.concat([res, x], axis = -1)                                    # Concat the original positions to the encodings

    return res
</code></pre>
<p>Here are some dummy examples to test the code:</p>
<pre><code># Test the embedding
''' A tensor for the 3D positions
    A 64 x 64 image, the rays sampled 16 times '''
positions = tf.random.uniform(shape = (BATCH_SIZE, 64, 64, 16, 3))
# postions are passed as a flat vector
positions = tf.reshape(positions, shape= (BATCH_SIZE, -1, 3))
''' A table for the embeddings. This will be optimzed during training so the values can NOT be precomputed
    16 Resolutions with the table size T '''
hash_table = tf.random.uniform(shape=(L, T, F), minval=-10**-4, maxval=10**-4)

# Encode the positions
encodings = encode_position_hash(positions, hash_table)
print(encodings)
</code></pre>
<p>I know that the tf.scatter_ functions do the index validation on the GPU however I can not figure out a way to utilize these functions to retrieve the values from the table.</p>
",2023-04-05 13:00:20,13230142,1,https://stackoverflow.com/questions/75939760,Documentation Replication on Other Examples
75993467,tensorflow unique function with 2d?,"<p><code>tf.unique</code> currently only works on 1D tensors. How can I find index of unique values in a 2D tensor.</p>
<pre><code>input = tf.constant([[0,0,1,1,1,8], [2,2,5,5,5,2], [6,6,6,8,8,9]])
#output should be  = [[0,0,1,1,1,2], [0,0,1,1,1,0], [0,0,0,1,1,2]]
</code></pre>
",2023-04-12 08:36:53,4358622,149,https://stackoverflow.com/questions/75993467,Documentation Replicability
75996642,Is there a good equivalent of pandas' `apply` for TensorFlow datasets?,"<p><strong>BACKGROUND</strong></p>
<p>The use of <a href=""https://www.tensorflow.org/guide/data"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code></a> is promoted by TensorFlow as the best practice for implementing input pipelines due to their efficient implementation of common operations such as batching, shuffling, as well as their seamless integration with the Keras API.</p>
<p>I may just be lousy at looking up the documentation on the matter, but it seems to me that the major drawback of TensorFlow datasets is that they are quite unwieldy, if not impossible to work with, when trying to implement feature engineering tasks whereby a new column is created via the application of some generic Python function. This is in contrast to pandas' very nifty <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html"" rel=""nofollow noreferrer""><code>apply()</code></a> function which can produce new columns from preexisting ones both efficiently (i.e., via vectorization) and in a pythonic manner.</p>
<p>To the best of my understanding, the closest thing to pandas' <code>apply()</code> is TensorFlow dataset's <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer""><code>map()</code></a>. However, one can't simply use it with arbitrary Python functions since they'd first need to be converted to tensors. This becomes very difficult as one has to have arcane knowledge of the miscellaneous tensor analogues of arbitrary Python functions (e.g., <code>tf.strings.length()</code> instead of Python's <code>len()</code>). Even when one finds such functions, the idiosyncracies of tensor operations makes them very un-pythonic and prone to obscure dimensionality or type errors.</p>
<p>I've read about TensorFlow's <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer""><code>py_function</code></a> as some sort of wrapper that magically converts Pythonic code into a tensor representation, but judging from the documentation, it became clear to me that this is far from the case.</p>
<p><strong>QUESTION</strong></p>
<p>Is TensorFlow's <code>tf.data</code> just not mature yet to be able to handle feature engineering in the same way that pandas <code>apply()</code> does? If not, what am I missing in my understanding?</p>
<p><strong>MINIMUM WORKING EXAMPLE</strong></p>
<p>In the code below, I compare a pandas DataFrame <code>df</code> with the equivalent TensorFlow dataset <code>ds</code>. My goal is to engineer two extra features, namely</p>
<ol>
<li>adding a suffix to the string feature <code>my_string</code>, and</li>
<li>counting the number of time a certain letter appears in any given instance of <code>my_string</code>.</li>
</ol>
<p>As you can see for yourself, the first operation works intuitively for both pandas and TensorFlow, but the second only works easily for pandas. Getting it to work with TensorFlow is either extremely complex, or just plain impossible.</p>
<pre><code>from collections import Counter
import numpy as np
import pandas as pd
import tensorflow as tf

# Create the pandas DataFrame.
df = pd.DataFrame(
    {'index': list(range(5)),
     'my_string': ['Alondra', 'Spaanbiuk', 'Ibinth', 'Liefelle', 'Yoanda'], 
     'some_other_column': np.random.rand(5),
     }).set_index('index')
print('Original pandas DataFrame:')
print(df, '\n')

# Create the TensorFlow dataset and define a function to view it 
# as a pandas DataFrame.
ds = tf.data.Dataset.from_tensors(df.to_dict(orient='list'))
def view_ds(ds):
    data = pd.concat([pd.DataFrame(k) for k in ds.take(5)], axis=0)
    # Convert byte strings to Python strings.
    object_cols = data.select_dtypes([object])
    data[object_cols.columns] = object_cols.stack().str.decode('utf-8').unstack()
    print('TensorFlow dataset:')
    print(data, '\n')
view_ds(ds)

#### Add a suffix to `my_string` as `my_string_with_suffix`.
def add_a_suffix(x):
    x['my_string_with_suffix'] = x['my_string']+'.suffix'
    return x

# Apply to the pandas DataFrame.
print('DataFrame with the suffix:')
df = df.apply(add_a_suffix, axis=1)
print(df, '\n')

# Apply to the TensorFlow dataset.
print('TensorFlow dataset with the suffix:')
ds = ds.map(lambda x: add_a_suffix(x))
view_ds(ds)

#### Count they the number of `a`'s in `my_string`:
def count_letters(x, letter='a'):
    counter = Counter(x['my_string'].lower())
    x[f'{letter}_counts'] = counter[letter]
    return x

# Apply to the pandas DataFrame.
print('DataFrame with the letter count:')
df = df.apply(count_letters, axis=1)
print(df, '\n')
    
# Apply to the TensorFlow dataset.
# HOW BUT HOW?!!
# print('TensorFlow dataset with the letter count:')
# ds = ds.apply(lambda x: count_letters(x))
# view_ds(ds)
</code></pre>
<p>The output is of the above is as follows.</p>
<pre><code>Original pandas DataFrame:
       my_string  some_other_column
index                              
0        Alondra           0.209685
1      Spaanbiuk           0.972315
2         Ibinth           0.933700
3       Liefelle           0.186369
4         Yoanda           0.667436 

TensorFlow dataset:
   my_string  some_other_column
0    Alondra           0.209685
1  Spaanbiuk           0.972315
2     Ibinth           0.933700
3   Liefelle           0.186369
4     Yoanda           0.667436 

DataFrame with the suffix:
       my_string  some_other_column my_string_with_suffix
index                                                    
0        Alondra           0.209685        Alondra.suffix
1      Spaanbiuk           0.972315      Spaanbiuk.suffix
2         Ibinth           0.933700         Ibinth.suffix
3       Liefelle           0.186369       Liefelle.suffix
4         Yoanda           0.667436         Yoanda.suffix 

TensorFlow dataset with the suffix:
TensorFlow dataset:
   my_string  some_other_column my_string_with_suffix
0    Alondra           0.209685        Alondra.suffix
1  Spaanbiuk           0.972315      Spaanbiuk.suffix
2     Ibinth           0.933700         Ibinth.suffix
3   Liefelle           0.186369       Liefelle.suffix
4     Yoanda           0.667436         Yoanda.suffix 

DataFrame with the letter count:
       my_string  some_other_column my_string_with_suffix  a_counts
index                                                              
0        Alondra           0.209685        Alondra.suffix         2
1      Spaanbiuk           0.972315      Spaanbiuk.suffix         2
2         Ibinth           0.933700         Ibinth.suffix         0
3       Liefelle           0.186369       Liefelle.suffix         0
4         Yoanda           0.667436         Yoanda.suffix         2 
</code></pre>
",2023-04-12 14:26:12,5640161,791,https://stackoverflow.com/questions/75996642,Documentation Ambiguity
76012810,Unable to extract output probability array using Tensorflow for JS,"<p>New to Javascript/Typescript + ML libs. Created a quick TS code snippet to test out the TensorFlow lib. I am stuck at a point where I am not able to extract the probability array and then choose the max from the output.</p>
<p>In the last iteration I have here, I am using data() function but it does not compile giving this error:</p>
<pre><code>Property 'data' does not exist on type 'Tensor&lt;Rank&gt; | Tensor&lt;Rank&gt;[]'.
  Property 'data' does not exist on type 'Tensor&lt;Rank&gt;[]'.ts(2339)
</code></pre>
<p>Even though input is of the type tf.Tensor and according to the docs <a href=""https://js.tensorflow.org/api/latest/#tf.Tensor.data"" rel=""nofollow noreferrer"">here</a>, it should work.</p>
<p>I am definitely missing some thing here. I am tried going through other examples, but it seems like TensorFlow has a lot to offer and I did not come across anything that would be useful in my case.</p>
<p>I feel I need help with these 3 lines here:</p>
<pre><code>const output = await net.predict(input).data();  
  const predictedPortfolio = Object.keys(portfolios)[output.indexOf(Math.max(...output))];
  return predictedPortfolio;
</code></pre>
<p>Code snippet</p>
<pre><code>import * as tf from '@tensorflow/tfjs';

interface FinancialInformation {
  age: number;
  riskTolerance: number;
  currentNetWorth: number;
  annualIncome: number;
  debt: number;
}

interface Portfolios {
  [key: string]: string[];
}

// Define the investment portfolios
const portfolios: Portfolios = {
  conservative: ['bonds', 'real estate'],
  balanced: ['stocks', 'bonds', 'real estate', 'commodities'],
  aggressive: ['stocks', 'commodities', 'crypto'],
};

export async function generateSuggestion(financialInfo: FinancialInformation): Promise&lt;string&gt; {
  // Define the neural network
  const net = tf.sequential({
    layers: [
      tf.layers.dense({ inputShape: [5], units: 10, activation: 'sigmoid' }),
      tf.layers.dense({ units: 10, activation: 'sigmoid' }),
      tf.layers.dense({ units: 3, activation: 'softmax' }),
    ],
  });

  // Train the neural network
  const trainingData = tf.tensor2d([
    [25, 2, 100000, 60000, 0],
    [30, 4, 150000, 80000, 20000],
    [40, 6, 200000, 100000, 50000],
    [50, 8, 300000, 120000, 100000],
    [60, 10, 400000, 150000, 150000],
  ]);

  const outputData = tf.tensor2d([
    [1, 0, 0],
    [0, 1, 0],
    [0, 0, 1],
    [0, 0, 1],
    [0, 0, 1],
  ]);

  const options = {
    epochs: 500,
    learningRate: 0.3,
  };

  net.compile({ optimizer: tf.train.adam(), loss: 'categoricalCrossentropy' });

  await net.fit(trainingData, outputData, options);

  // Use the neural network to generate a suggestion
  const input = tf.tensor2d([
    [financialInfo.age, financialInfo.riskTolerance, financialInfo.currentNetWorth, financialInfo.annualIncome, financialInfo.debt],
  ]) as tf.Tensor;

  const output = await net.predict(input).data();  
  const predictedPortfolio = Object.keys(portfolios)[output.indexOf(Math.max(...output))];
  return predictedPortfolio;
}
</code></pre>
",2023-04-14 07:59:28,4463330,555,https://stackoverflow.com/questions/76012810,Lack of Alternative Solutions/Documentation
76040030,Problem using Huggingface imagenet-1k dataset in Keras / Tensorflow,"<p>I'm having a problem using the imagenet-1k dataset from Huggingface with a Keras model. I'm just experimenting with simple models, but am stuck trying to get the dataset to work with the model fit function.</p>
<p>Here is how I load the dataset:</p>
<pre><code>ds = load_dataset('imagenet-1k')  # loads a DatasetDict
ds_train = ds['train']  # get a Dataset
ds_train.set_format(type='tensorflow', columns=['image'])  # convert to tf tensor
ds_val = ds['validation']  # get a Dataset
ds_val.set_format(type='tensorflow', columns=['image'])  # convert to tf tensor
</code></pre>
<p>Here is the fit invocation:</p>
<pre><code># train the autoencoder
autoencoder.fit(ds_train, ds_train,
                epochs=10,
                shuffle=True,
                validation_data=(ds_val, ds_val))
</code></pre>
<p>I get the following error:</p>
<pre><code>ValueError: Failed to find data adapter that can handle input: &lt;class 'datasets.arrow_dataset.Dataset'&gt;, &lt;class 'datasets.arrow_dataset.Dataset'&gt;
</code></pre>
<p>When I inspect one of the elements of the datasets it looks like a tf.Tensor, so I don't understand why it can't be passed directly. None of the examples or docs I can find make it clear how to do this. Huggingface <a href=""https://huggingface.co/docs/datasets/v2.11.0/en/use_with_tensorflow"" rel=""nofollow noreferrer"">examples</a> for images produce the same format that I'm getting, but apparently there is a step I'm missing before it can be used with model.fit()</p>
",2023-04-17 23:39:34,21668078,1,https://stackoverflow.com/questions/76040030,Documentation Replication on Other Examples
76153107,Difference between tf.Module and tf.keras.Model,"<p>I know both <code>tf.Module</code> and <code>tf.keras.Model</code> are used for building custom models.
But what's the difference between both of them?
Which one should be used when becuase there usage looks similar as shown in tensorflow docs?</p>
",2023-05-02 08:35:53,21760922,33,https://stackoverflow.com/questions/76153107,Documentation Ambiguity
76227668,How can I combine a py_function inside a map function?,"<p>I wanted to combine a py_function inside a map function, which took me a day, despite chatGPT's assistance.</p>
<p>Since <a href=""https://stackoverflow.com/questions/54497130/inconsistency-between-image-resizing-with-keras-pil-and-tensorflow"">resizing an image with tf.image has implementation differences in relate to openCVs</a>, I wanted to keep using the optimized tf.Dataset with the .map API, but also combine the opencv.resize API.</p>
",2023-05-11 12:29:31,13805655,21,https://stackoverflow.com/questions/76227668,Documentation Replicability
76244268,Tensorflow: Build new model from input and middle layers of another model,"<p>I'm trying to build <code>new_model</code> from another model layers for class activation mapping purposes.</p>
<pre class=""lang-py prettyprint-override""><code>def vgg_sequential():
    input_shape = IMG_SIZE + (3,)
    model = Sequential()
    model.add(tf.keras.applications.vgg16.VGG16(input_shape=input_shape, include_top=False, weights='imagenet'))
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(1))
    return model
</code></pre>
<pre class=""lang-py prettyprint-override""><code>cam_model = tf.keras.Model(inputs=seq_vgg.layers[0].input, outputs=(seq_vgg.layers[-3].output, seq_vgg.layers[-1].output))
</code></pre>
<p>And with this code i get the following error:</p>
<pre><code>ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 480, 480, 3), dtype=tf.float32, name='vgg16_input'), name='vgg16_input', description=&quot;created by layer 'vgg16_input'&quot;) at layer &quot;vgg16&quot;. The following previous layers were accessed without issue: ['block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1']
</code></pre>
<p>Already tried functional model API, providing <code>Input()</code> layer inside <code>vgg_sequential()</code> with the same error that my Input layer is disconected from the rest of my model. Beside this when using <code>tf.keras.applications.efficientnet_v2</code> that provides input layers for rescaling and resizing images i don't have any problem.</p>
<p>Any help, information, tips or links to docs that getas me to a solution will be very much appreciated.</p>
<p>Thanks in advance.</p>
",2023-05-13 18:18:46,2103321,75,https://stackoverflow.com/questions/76244268,Inadequate Examples
76380927,Tensorflow decode image,"<p>I am a beginner in tensorflow and I am training a small cnn, I am using the tf.io.decode_image function but I can't figure out if this function does preprocess.
The tensorflow documentation about it doesn't say anything.
When I open images with this function the values are between 0 and 1.
The images are single channel grayscale.
This is the code.</p>
<pre><code>def decode_img(self, imgs, channels):
        # Convert the compressed string to a 3D uint8 tensor
        images = []
        for element in imgs:

            dec_image = tf.io.decode_image(element, channels=channels, dtype=tf.float32)
            try:
                img = keras.utils.img_to_array(dec_image)
            except AttributeError:
                img = keras.preprocessing.image.img_to_array(dec_image)
            images.append(img)
        images = np.array(images)
        return images
</code></pre>
<p>I would like to have more explanations</p>
",2023-06-01 10:22:18,15460221,11,https://stackoverflow.com/questions/76380927,Requesting (Additional) Documentation/Examples
76391276,Custom gradient for broadcasting operation,"<p>I have an operation for which I want to define a custom gradient with <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer""><code>tf.custom_gradient</code></a>. The operation takes two broadcastable arguments and produces a result with the broadcasted shape. The problem is how to handle the broadcasting rules &quot;backwards&quot; in the custom gradient. Let's take the example for a multiplication operation from the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer""><code>tf.custom_gradient</code></a>:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

@tf.custom_gradient
def bar(x, y):
  def grad(upstream):
    dz_dx = y
    dz_dy = x
    return upstream * dz_dx, upstream * dz_dy
  z = x * y
  return z, grad
</code></pre>
<p>I can use this gradient alright for the non-broadcasting case:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.GradientTape() as tape:
    a = tf.ones([5])
    b = tf.ones([5])
    tape.watch([a, b])
    c = bar(a, b)
# Works fine
grad_a, grad_b = tape.gradient(c, [a, b])
</code></pre>
<p>However, when the inputs are broadcasted, the result is not correct:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.GradientTape() as tape:
    a = tf.ones([10, 1])
    b = tf.ones([5])
    tape.watch([a, b])
    c = bar(a, b)
grad_a, grad_b = tape.gradient(c, [a, b])
print(grad_a.shape, grad_b.shape)
# (10, 5) (10, 5)
</code></pre>
<p>In fact, trying to use it in graph mode fails:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.Graph().as_default():
    a = tf.ones([10, 1])
    b = tf.ones([5])
    c = bar(a, b)
    grad_a, grad_b = tf.gradients(c, [a, b])
# ValueError: Incompatible shapes between op input and calculated input gradient.
</code></pre>
<p>Is there a way to handle this &quot;unbroadcasting&quot; of the input gradients automatically?</p>
",2023-06-02 14:58:49,1782792,58906,https://stackoverflow.com/questions/76391276,Documentation Ambiguity
76396532,"Ragged tensors in dataset, tensorflow, how do I train the model","<p>I have</p>
<pre><code>def call (self, inputs):
    context, x = inputs
</code></pre>
<p>in my model, for fitting,
and my dataset contains ragged tensors, basically context and x are ragged tensor, of variable length, everything I try gives me some sort of error, for example<br> first I tried <code>[ [ context, x], ...]</code> where all the arrays were <code>np.ndarray</code>, but it said something along the lines that <code>np.ndarray</code> is an unrecognised datatype and cannot be converted to a <code>tf.Tensor</code>.<br>Then when I tried putting this in a tf.data.Dataset, it says <code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor).</code><br>
I am totally lost on how to train my model</p>
<p>I tried several different data types from list, to tf.data.Dataset, but none of them were working, and now I am totally in the dark. Consulting the documentation has not helped me figure out how does the fit function actually treat data</p>
",2023-06-03 14:34:56,13154958,1,https://stackoverflow.com/questions/76396532,Documentation Replicability
76444107,Are 'validation_steps' used if the validation_dataset is 'DirectoryIterator'?,"<p>I was trying to use the Keras API to train a given model by using its <a href=""https://keras.io/api/models/model_training_apis/"" rel=""nofollow noreferrer"">fit</a> function. In its documentation we can see the following:</p>
<blockquote>
<p>validation_steps: Only relevant if validation_data is provided and is
a tf.data dataset. Total number of steps (batches of samples) to draw
before stopping when performing validation at the end of every epoch.
If 'validation_steps' is None, validation will run until the
validation_data dataset is exhausted. In the case of an infinitely
repeated dataset, it will run into an infinite loop. If
'validation_steps' is specified and only part of the dataset will be
consumed, the evaluation will start from the beginning of the dataset
at each epoch. This ensures that the same validation samples are used
every time.</p>
</blockquote>
<p>By reading the above text I understand that if the <code>validation_data</code> is not a tf.data dataset the validation_steps is ignored. However I am not sure if in my case this principle is applied. I am using an <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"" rel=""nofollow noreferrer"">ImageDataGenerator</a> to then use its <code>flow_from_directory</code> function that returns a DirectoryIterator. In its documentation we can see the following:</p>
<blockquote>
<p>A DirectoryIterator yielding tuples of (x, y) where x is a numpy array
containing a batch of images with shape (batch_size, *target_size,
channels) and y is a numpy array of corresponding labels.</p>
</blockquote>
<p>So, by reading this I am convinced that the whole validation dataset is going to be used despite the fact that validation_steps might be set to a given number. Is there a way I can check whether it is using the whole dataset or only the given <code>validation_steps</code>? Does it simply ignore the <code>validation_steps</code> because the <code>validation_data</code> is not a tf.data and therefore there is no need to check it?</p>
<p>Thanks!</p>
<p>Code example of usage:</p>
<pre><code># model building and whatnot
# (...)
img_val = r'/content/drive/MyDrive/validation'
validation = ImageDataGenerator()
val_dataset = validation.flow_from_directory(img_val,
                                          target_size=(224, 224),
                                          batch_size=32,
                                          class_mode='categorical')

model.fit(train_dataset, validation_data=val_dataset, epochs=1000, steps_per_epoch=1875, validation_steps=375  
</code></pre>
<p>PS: I know that we can let <code>validation_steps</code> be <code>None</code> to use it fully for validating the model in each epoch. My question is especifically if the <code>validation_steps</code> parameter is ignored or not if provided while using data from a ImageDataGenerator.</p>
",2023-06-09 23:18:18,11875606,69,https://stackoverflow.com/questions/76444107,Documentation Replication on Other Examples
76447508,How to retrain a model that was saved using the tf.saved_model.save() function in Tensorflow,"<p>I am building a Neural Machine Translator for English to Konkani (a local language) language using the Transformer architecture proposed by (Vaswani et, al. 2017). I am following the tutorial code from <a href=""https://www.tensorflow.org/text/tutorials/transformer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/text/tutorials/transformer</a>. I have trained the model and used the <code>tf.saved_model.save()</code> method to save the model files locally.</p>
<p>I now want to retrain that saved model on a new dataset that I have gathered recently, but I've realised that after loading the model using the <code>tf.saved_model.load()</code> method, I am not able to train it again as the loaded model now lacks the necessary method <code>model.fit()</code> .</p>
<p>Here is a part of the model training code:</p>
<pre class=""lang-py prettyprint-override""><code>class Transformer(tf.keras.Model):
  def __init__(self, *, num_layers, d_model, num_heads, dff,
               input_vocab_size, target_vocab_size, dropout_rate=0.1):
    super().__init__()
    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=input_vocab_size,
                           dropout_rate=dropout_rate)

    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=target_vocab_size,
                           dropout_rate=dropout_rate)

    self.final_layer = tf.keras.layers.Dense(target_vocab_size)

  def call(self, inputs):
    # To use a Keras model with `.fit` you must pass all your inputs in the
    # first argument.
    context, x  = inputs

    context = self.encoder(context)  # (batch_size, context_len, d_model)

    x = self.decoder(x, context)  # (batch_size, target_len, d_model)

    # Final linear layer output.
    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)

    try:
      # Drop the keras mask, so it doesn't scale the losses/metrics.
      # b/250038731
      del logits._keras_mask
    except AttributeError:
      pass

    # Return the final output and the attention weights.
    return logits
#-----------------------------------------------------------------------

#...&lt;code to define optimizers and loss functions&gt;...

# This Class acts as an interface for the Transformer
class Translator(tf.Module):
  def __init__(self, context_tokenizers, target_tokenizers, transformer):
    self.context_tokenizers = context_tokenizers
    self.target_tokenizers = target_tokenizers
    self.transformer = transformer

  def __call__(self, sentence, max_length=MAX_TOKENS): #max_length=MAX_TOKENS
    assert isinstance(sentence, tf.Tensor)
    if len(sentence.shape) == 0:
      sentence = sentence[tf.newaxis]

    sentence = tokenize(sentence,self.context_tokenizers).to_tensor()

    encoder_input = sentence

    # As the output language is English, initialize the output with the
    # English `[START]` token.

    start_end = tokenize('',self.target_tokenizers)[0]
    start = start_end[0][tf.newaxis]
    end = start_end[-1][tf.newaxis]

    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)
    output_array = output_array.write(0, start)

    for i in tf.range(max_length):
      output = tf.transpose(output_array.stack())
      predictions = self.transformer([encoder_input, output], training=False)

      # Select the last token from the `seq_len` dimension.
      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.

      predicted_id = tf.argmax(predictions, axis=-1)

      # Concatenate the `predicted_id` to the output which is given to the
      # decoder as its input.
      output_array = output_array.write(i+1, predicted_id[0])

      if predicted_id == end:
        break

    output = tf.transpose(output_array.stack())
    # The output shape is `(1, tokens)`.

    text = self.target_tokenizers.detokenize(output)

    tokens = tf.gather(target_vocab, output)

    # `tf.function` prevents us from using the attention_weights that were
    # calculated on the last iteration of the loop.
    # So, recalculate them outside the loop.
    self.transformer([encoder_input, output[:,:-1]], training=False)
    attention_weights = self.transformer.decoder.last_attn_scores

    joined_text = tf.strings.reduce_join(text[0][1:-1], separator=' ', axis=-1)
    return joined_text, tokens, attention_weights
#-----------------------------------------------------------------------

class ExportTranslator(tf.Module):
  def __init__(self, translator):
    self.translator = translator

  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
  def __call__(self, sentence):
    (result,
     tokens,
     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)

    return result
#-----------------------------------------------------------------------

transformer = Transformer(
    num_layers=num_layers,
    d_model=d_model,
    num_heads=num_heads,
    dff=dff,
    input_vocab_size=context_vocab_size,
    target_vocab_size=target_vocab_size,
    dropout_rate=dropout_rate)

transformer.compile(
    loss=masked_loss,
    optimizer=optimizer,
    metrics=[masked_accuracy])

# training the model on the training data for some epochs
transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )

translator = Translator(context_tokenizer, target_tokenizer, transformer)

exp_translator = ExportTranslator(translator)

#saving the model
tf.saved_model.save(exp_translator, export_dir=MODEL_SAVED_FILES)

#-----------------------------------------------------------------------

#loading a saved model
reloaded = tf.saved_model.load(MODEL_SAVED_FILES)
</code></pre>
<p>Here's the error I get when I try to retrain the model using the following code:</p>
<pre class=""lang-py prettyprint-override""><code>reloaded = tf.saved_model.load(MODEL_SAVED_FILES)

#retraing the model on new dataset
reloaded.translator.transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )
</code></pre>
<p>The error:</p>
<pre class=""lang-py prettyprint-override""><code>
---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

&lt;ipython-input-41-ad1b625ff6c0&gt; in &lt;cell line: 2&gt;()
      1 #retraing the model on new dataset
----&gt; 2 reloaded.translator.transformer.fit(train_batches,
      3                 epochs=20,
      4                 validation_data=val_batches,
      5                 callbacks=[

AttributeError: '_UserObject' object has no attribute 'fit'
</code></pre>
<p>After reading the documentation I've realised that when saving the model in the above method, the <code>model.fit()</code> and other methods are not saved hence they are not callable.</p>
<p>I need help in finding a way to retrain my saved model, It is not feasible for me to train a new model on a combined dataset as It will take up lot of time and I have very limited resources. I have been looking up on the web for days but couldn't find a solution. Any help in this regards will be appreciated!</p>
",2023-06-10 18:03:00,16851318,41,https://stackoverflow.com/questions/76447508,Inadequate Examples
