QuestionId,Title,Body,QuestionAPI,CurrentAPI,CreationDate,AcceptedAnswer,UserID,User Reputation,QuestionURL,IssueType
76324368,Understanding tf.keras.layers.Dense(),"<p>I am trying to understand why there is a difference between calculating a dense layer operation directly and using the <code>keras</code> implementation.</p>
<p>Following the documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense</a>) <code>tf.keras.layers.Dense()</code> should implement the operation <code>output = activation(dot(input, kernel) + bias)</code> but <code>result</code> and <code>result1</code> below are not the same.</p>
<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(5,10)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<p>output</p>
<pre class=""lang-py prettyprint-override""><code>
[[2.87080455]
 [3.25458574]
 [3.28776264]
 [3.14319134]
 [2.04760242]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]

</code></pre>
<p>Using <code>test.get_weights()</code> I can see that the kernel and bias (<code>b</code>) are getting set to the correct values. I am using TF version 2.12.0.</p>
",tf.keras.layers.Dense,tf.keras.layers.Dense,2023-05-24 14:00:25,"<p>After some experimentation I realized that the <code>kernel</code> for the dense layer needs to be of <code>shape=(10,5)</code> as apposed to <code>(5,10)</code> as in the code from the original question above. This is implicit because <code>units=5</code> so a vector of size <code>10</code> needs to be passed (hence why <code>input_shape=(10,)</code> is commented out as a reminder). Below is the corrected code:</p>
<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias   = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            # input_shape=(10,),
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<pre class=""lang-py prettyprint-override""><code>[[2.38769]
 [3.63470697]
 [2.62423944]
 [3.31286287]
 [2.91121125]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]
</code></pre>
<p>Ultimately, I am not entirely sure what was happening under the hood and why <code>keras</code> did not raise an error. I will check with the <code>tf.keras.layers.Dense()</code> implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!</p>
",18338104,5,https://stackoverflow.com/questions/76324368,Documentation Replication on Other Examples
74088086,Seed in tensorflow initializer (tf.keras.initializers) doesn't guarantees reproducible results,"<p>looking at tensorflow documentation (see, e.g., <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal</a>) a seed should guarantee that &quot;multiple initializers will produce the same sequence when constructed with the same seed value&quot;</p>
<p>The following easy experiment says otherwise</p>
<pre><code>import tensorflow as tf
initializer = tf.keras.initializers.GlorotNormal(seed=123)
values = initializer(shape=(2, 2))
print(values)

initializer1 = tf.keras.initializers.GlorotNormal(seed=123)
values1 = initializer1(shape=(2, 2))
print(values1)
</code></pre>
<p>Giving the output</p>
<pre><code>tf.Tensor(
[[-0.58071285 -0.06369764]
 [ 0.06184607 -1.2040431 ]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[ 0.76186    -0.11021858]
 [-1.1184257  -1.430372  ]], shape=(2, 2), dtype=float32)
</code></pre>
<p>Interesting fact, if I run the python script multiple times I always get the same overall results. So the first seed somehow works, but when it is called a second time in the script it 'keeps advancing', although it should be fixed.</p>
<p>Any opinion about that? Do you think it is a bug? Do you think it is the intended behaviour (if yes could you explain me why)? It may be a problem of my TF installation? I have python 3.7.9 on Windows and Tensorflow version is 2.7.0</p>
<p>Of course, the same behaviour applies when inserting an initializer in a tf.keras.layer</p>
<pre><code>x = tf.constant(6, shape=(2,3))
dense = tf.keras.layers.Dense(units=3, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=123))
dense1 = tf.keras.layers.Dense(units=3, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=123))
print(dense(x), '\n', dense1(x))
</code></pre>
<p>giving</p>
<pre><code>tf.Tensor(
[[14.365635   3.3581433 -1.2498709]
 [14.365635   3.3581433 -1.2498709]], shape=(2, 3), dtype=float32)
 tf.Tensor(
[[10.644517  8.859441  5.136632]
 [10.644517  8.859441  5.136632]], shape=(2, 3), dtype=float32)
</code></pre>
<p>Thanks in advance for your time!</p>
",tf.keras.initializers.GlorotNormal,tf.keras.initializers.GlorotNormal,2022-10-16 14:53:17,"<p>If you go to the link you send you can read:</p>
<p><code>Note that a seeded initializer will not produce the same random values across multiple calls, but multiple initializers will produce the same sequence when constructed with the same seed value.</code></p>
<p>So yes is deterministic but not return the same value in a single build note that keras and tensorflow are keeping track of the calls you make if you want to do this in a single script you need to reset the backend for keras and is recommended use <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed"" rel=""nofollow noreferrer""><code>tf.keras.utils.set_random_seed</code></a> to set the seed, here an example how to do this</p>
<pre><code>import tensorflow as tf

seed = 123

tf.keras.utils.set_random_seed(
    seed
)
initializer = tf.keras.initializers.GlorotNormal()
values = initializer(shape=(2, 2))
print(values)
tf.keras.backend.clear_session()
tf.keras.utils.set_random_seed(
    seed
)

initializer1 = tf.keras.initializers.GlorotNormal()
values1 = initializer1(shape=(2, 2))
print(values1)
</code></pre>
<p>This will print :</p>
<pre><code>tf.Tensor(
[[-0.7219447  -1.4678022 ]
 [-0.35725543 -1.1963991 ]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[-0.7219447  -1.4678022 ]
 [-0.35725543 -1.1963991 ]], shape=(2, 2), dtype=float32)
</code></pre>
",17788510,168,https://stackoverflow.com/questions/74088086,Documentation Replication on Other Examples
74029376,Tensorflow custom reduction function with axis support,"<p>I would like to get the value with the maximum absolute value in a tensor, with respect to an axis. Note that I don't want the maximum absolute value, I want the <em>value that has the maximum absolute value</em> (so I need to keep the sign).</p>
<p>Ideally, I would like something similar to <code>reduce_max</code> or <code>reduce_min</code>:</p>
<pre class=""lang-py prettyprint-override""><code>tensor = tf.constant(
  [
    [[ 1,  5, -3],
     [ 2, -3,  1],
     [ 3, -6,  2]],

    [[-2,  3, -5],
     [-1,  4,  2],
     [ 4, -1,  0]]
   ]
)
# tensor.shape = (2, 3, 3)

tensor.reduce_maxamplitude(tensor, axis=0)
# Tensor(
#  [[-2,  5, -5],
#   [ 2,  4,  2],
#   [ 4, -6,  2]]
# )
# shape: (3, 3)

tensor.reduce_maxamplitude(tensor, axis=1)
# Tensor(
#  [[3, -6, -3],
#   [4,  4, -5]]
# )
# shape: (2, 3)

tensor.reduce_maxamplitude(tensor, axis=2)
# Tensor(
#  [[5, -3, -6],
#   [-5,  4, 4]]
# )
# shape: (2, 3)
</code></pre>
<p>but I did not find anything useful in tensorflow documentation.</p>
<p>With a flat tensor, I know that I could use <code>tf.foldl</code> or <code>tf.foldr</code>:</p>
<pre class=""lang-py prettyprint-override""><code>flat = tf.reshape(tensor, -1)
tf.foldr(lambda a, x: x if tf.abs(x) &gt; tf.abs(a) else a, flat)
# -6
</code></pre>
<p>However, I don't know how to handle an axis parameter in the case of multidimensional tensors.</p>
",-,-,2022-10-11 13:57:31,"<p>It really depends on how many dimensions your tensor has, but for a 2D tensor you could just do:</p>
<pre><code>import tensorflow as tf

tensor = tf.constant(
  [[1,  5, -3],
   [2, -3,  1],
   [3, -6,  2]])

tf.gather(tensor, tf.argmax(tf.abs(tensor), axis=1), axis=1, batch_dims=1)
</code></pre>
<pre><code>&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 5, -3, -6], dtype=int32)&gt;
</code></pre>
<p>3D example:</p>
<pre><code>tensor = tf.constant(
  [
    [[ 1,  5, -3],
     [ 2, -3,  1],
     [ 3, -6,  2]],

    [[-2,  3, -5],
     [-1,  4,  2],
     [ 4, -1,  0]]
   ]
)

# axis = 0
argmax = tf.argmax(tf.abs(tensor), axis=0)
i, j = tf.meshgrid(
    tf.range(tensor.shape[1], dtype=tf.int64), 
    tf.range(tensor.shape[2], dtype=tf.int64),
                              indexing='ij')
tf.gather_nd(tensor, tf.stack([argmax, i, j], axis=-1))
</code></pre>
<pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=int32, numpy=
array([[-2,  5, -5],
       [ 2,  4,  2],
       [ 4, -6,  2]], dtype=int32)&gt;
</code></pre>
<pre><code># axis = 1
argmax = tf.argmax(tf.abs(tensor), axis=1)
i, j = tf.meshgrid(
    tf.range(tensor.shape[0], dtype=tf.int64), 
    tf.range(tensor.shape[2], dtype=tf.int64),
                              indexing='ij')
tf.gather_nd(tensor, tf.stack([i, argmax, j], axis=-1))
</code></pre>
<pre><code>&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[ 3, -6, -3],
       [ 4,  4, -5]], dtype=int32)&gt;
</code></pre>
<pre><code># axis = 2
i, j = tf.meshgrid(
    tf.range(tensor.shape[0], dtype=tf.int64), 
    tf.range(tensor.shape[1], dtype=tf.int64),
                              indexing='ij')
tf.gather_nd(tensor, tf.stack([i, j, argmax], axis=-1))
</code></pre>
<pre><code>&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[ 5, -3, -6],
       [-5,  4,  4]], dtype=int32)&gt;
</code></pre>
<p>For a 4D tensor just extend the <code>meshgrid</code>:</p>
<pre><code># axis=-1
i, j, k = tf.meshgrid(
    tf.range(tensor.shape[0], dtype=tf.int64), 
    tf.range(tensor.shape[1], dtype=tf.int64),
    tf.range(tensor.shape[2], dtype=tf.int64),
                              indexing='ij')
</code></pre>
<p>Quick function bundling everything by @leleogere</p>
<pre><code>def reduce_maxamplitude(tensor, axis):
    argmax = tf.argmax(tf.abs(tensor), axis=axis)
    mesh = tf.meshgrid(
        *[tf.range(tensor.shape[i], dtype=tf.int64) for i in range(tensor.shape.rank) if i != axis],
        indexing='ij'
    )
    return tf.gather_nd(tensor, tf.stack([*mesh[:axis], argmax, *mesh[axis:]], axis=-1))
</code></pre>
",18159603,955,https://stackoverflow.com/questions/74029376,Lack of Alternative Solutions/Documentation
74005009,How to create output_signature for tensorflow.dataset.from_generator,"<p>I have a generator yielding data and labels <code>yield data, labels</code> where the data is
an <code>numpy.ndarray</code> with variable rows and 500 columns of type <code>dtype=float32</code> and the labels are integers of <code>numpy.int64</code>.</p>
<p>I'm trying to pass this data into TensorFlow from_generator function to create a TensorFlow dataset: <code>tf.data.Dataset.from_generator</code></p>
<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">docs</a> say that the from_generator function needs a parameter <code>output_signature</code> as an input. But I'm having trouble understanding how to build this output_signature.</p>
<p>How can I make the output_signature for the generator I described?</p>
<p>Thank you!</p>
<p>Edit:
I used <code>tf.type_spec_from_value</code> to get this:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
   datagen_row,
   output_signature=(
      tf.TensorSpec(shape=(None, 512), dtype=tf.float32, name=None),
      tf.TensorSpec(shape=(), dtype=tf.int64, name=None)
   )
)
</code></pre>
<p>But is it correct to use None when the number of rows is varying for the first data type?</p>
",tf.data.Dataset,tf.data.Dataset,2022-10-09 13:04:41,"<p>if your datagen_row() function yields input_data, label with format 500 and 1
than your output_signature should be:</p>
<pre><code>  output_signature=(
  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),
  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))
</code></pre>
<p>where the first TensorSpec is for the data format and the second one for the label format.
But it would be helpful if you post the function + maybe data examples or data shape here. Otherwise it is hard to help.</p>
",2300622,1104,https://stackoverflow.com/questions/74005009,Documentation Replicability
73165980,Tensorflow: how to feed a variable-time-step input to a RNN,"<p>I have a simple X_train and Y_train data:</p>
<pre><code>x_train = [
  array([ 6,  1,  9, 10,  7,  7,  1,  9, 10,  3, 10,  1,  4]), 
  array([ 2,  8,  8,  1,  1,  4,  2,  5,  1,  2,  7,  2,  1,  1, 4,  5, 10, 4])
]
y_train = [23, 17]
</code></pre>
<p>Arrays are numpy arrays.
I am now trying to use the <code>tf.data.Dataset</code> class to load these as tensors.
Before I have done a similar thing successfully using the following code:</p>
<pre><code>    dataset = data.Dataset.from_tensor_slices((x_train, y_train))
</code></pre>
<p>As this input is fed into a RNN, I have used the expand_dims method in the first RNN layer (the expand_dimension is passed as a function to overcome an apparent bug in tensorflow: see <a href=""https://github.com/keras-team/keras/issues/5298#issuecomment-281914537"" rel=""nofollow noreferrer"">https://github.com/keras-team/keras/issues/5298#issuecomment-281914537</a>):</p>
<pre><code>def expand_dimension(x):
    from tensorflow import expand_dims
    return expand_dims(x, axis=-1)

model = models.Sequential(
    [
        layers.Lambda(expand_dimension,
                      input_shape=[None]),
        layers.LSTM(units=64, activation='tanh'),
        layers.Dense(units=1)
    ]
)
</code></pre>
<p>This worked although because I had arrays of equal length. In the example I posted instead the 1st array has 13 numbers and the 2nd one 18.
In this case the method above doesn't work, and the recommended method seems to be using <code>tf.data.Dataset.from_generator</code>.
Reading this <a href=""https://stackoverflow.com/questions/50329855/how-to-use-the-tensorflow-dataset-pipeline-for-variable-length-inputs"">How to use the Tensorflow Dataset Pipeline for Variable Length Inputs?</a>, the accepted solution shows something like the following would work (where I am not caring here about <code>y_train</code> for simplicity):</p>
<pre><code>dataset = tf.data.Dataset.from_generator(lambda: x_train, 
                                         tf.as_dtype(x_train[0].dtype),
                                         tf.TensorShape([None, ]))
</code></pre>
<p>However, the syntax in tensorflow has changed since this answer, and now it requires to use the <code>output_signature</code> argument (see <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator</a>).</p>
<p>I've tried different ways but I'm finding hard to understand from tensorflow documentation what the <code>output_signature</code> should exactly be in my case.
Any help would be much appreciated.</p>
",tf.data.Dataset,tf.data.Dataset,2022-07-29 11:26:49,"<p>Short answer is, you can define <code>output_signature</code> as follows.</p>
<pre><code>import tensorflow as tf
import numpy as np
x_train = [
  np.array([ 6,  1,  9, 10,  7,  7,  1,  9, 10,  3, 10,  1,  4]), 
  np.array([ 2,  8,  8,  1,  1,  4,  2,  5,  1,  2,  7,  2,  1,  1, 4,  5, 10, 4])
]
y_train = [23, 17]

dataset = tf.data.Dataset.from_generator(
    lambda: x_train, 
    output_signature=tf.TensorSpec(
        [None, ], 
        dtype=tf.as_dtype(x_train[0].dtype)
    )
)
</code></pre>
<p>I'll also expand and improve on some things you're doing here to improve your pipeline.</p>
<h2>Using both inputs and labels</h2>
<pre><code>dataset = tf.data.Dataset.from_generator(
    lambda: zip(x_train, y_train), 
    output_signature=(
        tf.TensorSpec([None, ], dtype=tf.as_dtype(x_train[0].dtype)),
        tf.TensorSpec([], dtype=tf.as_dtype(y_train.dtype))
    )
)

for x in dataset:
  print(x)
</code></pre>
<p>Which would output,</p>
<pre><code>(&lt;tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 6,  1,  9, 10,  7,  7,  1,  9, 10,  3, 10,  1,  4])&gt;, &lt;tf.Tensor: shape=(), dtype=int64, numpy=23&gt;)
(&lt;tf.Tensor: shape=(18,), dtype=int64, numpy=
array([ 2,  8,  8,  1,  1,  4,  2,  5,  1,  2,  7,  2,  1,  1,  4,  5, 10,
        4])&gt;, &lt;tf.Tensor: shape=(), dtype=int64, numpy=17&gt;)
</code></pre>
<p><strong>Caveat</strong>: This can get slightly more complicated if you try to <code>tf.data.Dataset.batch()</code> items. Then you need to use <code>RaggedTensorSpec</code> instead of <code>TensorSpec</code>. Also, I haven't experimented too much with feeding in ragged tensors into a RNN. But I think those are out of scope for the question you've asked.</p>
",13454852,151,https://stackoverflow.com/questions/73165980,Documentation Ambiguity
71335830,What is the difference between tf.keras.layers.Input() and tf.keras.layers.Flatten(),"<p>I have seen multiple uses of both <code>tf.keras.layers.Flatten()</code> (ex. <a href=""https://www.tensorflow.org/tutorials/generative/autoencoder#first_example_basic_autoencoder"" rel=""nofollow noreferrer"">here</a>) and <code>tf.keras.layers.Input()</code> (ex. <a href=""https://www.tensorflow.org/tutorials/generative/autoencoder#define_a_convolutional_autoencoder"" rel=""nofollow noreferrer"">here</a>). After reading the documentation, it is not clear to me</p>
<ol>
<li>whether either of them uses the other</li>
<li>whether both can be used interchangeably when introducing to a model an input layer (let's say with dimensions <code>(64, 64)</code>)</li>
</ol>
",tf.keras.layers.Flatten,tf.keras.layers.Flatten,2022-03-03 10:46:49,"<p>I think the confusion comes from using a <code>tf.keras.Sequential</code> model, which does not need an explicit <code>Input</code> layer. Consider the following two models, which are equivalent:</p>
<pre><code>import tensorflow as tf

model1 = tf.keras.Sequential([
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(5, activation='relu'),
    ])

model1.build((1, 28, 28, 1))
</code></pre>
<pre><code>model2 = tf.keras.Sequential([
      tf.keras.layers.Input((28, 28, 1)),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(5, activation='relu'),
    ])
</code></pre>
<p>The difference is that I explicitly set the input shape of <code>model2</code> using an <code>Input</code> layer. In <code>model1</code>, the input shape will be inferred when you pass real data to it or call <code>model.build</code>.</p>
<p>Now regarding the <code>Flatten</code> layer, this layer simply converts a n-dimensional tensor (for example <code>(28, 28, 1)</code>) into a 1D tensor <code>(28 x 28 x 1)</code>. The <code>Flatten</code> layer and <code>Input</code> layer can coexist in a <code>Sequential</code> model but do not depend on each other.</p>
",9758352,427,https://stackoverflow.com/questions/71335830,Documentation Ambiguity
71149271,"How to remove single feature from tensorflow dataset, how to use apply on single feture?","<p>I created dataset from csv file with dataset = tf.data.experimental.make_csv_dataset() function but My dataset has categorical and numeric features.</p>
<pre><code>dataset=
color  price weight
red    120    1.2
blue    80     2.0
green   90     3
</code></pre>
<p>Question 1:
The question is how can I  modify  only single feature, for example weight +2, to:</p>
<pre><code>dataset=
color  price weight
red    120    3.2
blue    80     4.0
green   90     5
</code></pre>
<p>I try to do something like:</p>
<pre><code>dataset = dataset.apply(lambda x: x['weight']+2)
</code></pre>
<p>but the error is: &quot;TypeError: 'FilterDataset' object is not subscriptable&quot;</p>
<p>Example from the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply</a> doesn't show it.</p>
<p>Question 2:
How can I remove single feature ? Is there any equivalent to pandas drop column?</p>
",tf.data.Dataset,tf.data.Dataset,2022-02-16 21:06:40,"<p>You can remove features by only filtering the features that you want. This how you can modify only one feature:</p>
<pre><code>import tensorflow as tf
import pandas as pd

df = pd.DataFrame(data={'color': ['red', 'blue','green'], 'price': [120, 80, 90], 'weight': [3.2, 4.0, 5]})
df.to_csv('data.csv', index=False)

dataset = tf.data.experimental.make_csv_dataset('/content/data.csv', batch_size=1, num_epochs = 1, shuffle=False)
dataset = dataset.map(lambda x: (x['color'], x['price'], x['weight']+2))

for x in dataset:
  print(x[0], x[1], x[2])
</code></pre>
<pre><code>tf.Tensor([b'red'], shape=(1,), dtype=string) tf.Tensor([120], shape=(1,), dtype=int32) tf.Tensor([5.2], shape=(1,), dtype=float32)
tf.Tensor([b'blue'], shape=(1,), dtype=string) tf.Tensor([80], shape=(1,), dtype=int32) tf.Tensor([6.], shape=(1,), dtype=float32)
tf.Tensor([b'green'], shape=(1,), dtype=string) tf.Tensor([90], shape=(1,), dtype=int32) tf.Tensor([7.], shape=(1,), dtype=float32)
</code></pre>
",13824257,142,https://stackoverflow.com/questions/71149271,Documentation Replication on Other Examples
71129505,"Is it possible to split a tensorflow dataset into train, validation AND test datasets when using image_dataset_from_directory?","<p>I am using <code>tf.keras.utils.image_dataset_from_directory</code> to load a dataset of 4575 images. While this function allows to split the data into two subsets (with the <code>validation_split</code> parameter), I want to split it into training, testing, and validation subsets.</p>
<p>I have tried using <code>dataset.skip()</code> and <code>dataset.take()</code> to further split one of the resulting subsets, but these functions return a <code>SkipDataset</code> and a <code>TakeDataset</code> respectively (by the way, contrary to <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#take"" rel=""nofollow noreferrer"">the documentation</a>, where it is claimed that these functions return a <code>Dataset</code>). This leads to problems when fitting the model - the metrics calculated on validation sets (val_loss, val_accuracy) disappear from model history.</p>
<p>So, my question is: is there a way to split a <code>Dataset</code> into three subsets for training, validation and testing, so that all three subsets are also <code>Dataset</code> objects?</p>
<p><strong>Code used to load the data</strong></p>
<pre><code>def load_data_tf(data_path: str, img_shape=(256,256), batch_size: int=8):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.2,
        subset=&quot;training&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    val_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.3,
        subset=&quot;validation&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    return train_ds, val_ds

train_dataset, test_val_ds = load_data_tf('data_folder', img_shape = (256,256), batch_size=8)
test_dataset = test_val_ds.take(686)
val_dataset = test_val_ds.skip(686)
</code></pre>
<p><strong>Model compilation and fitting</strong></p>
<pre><code>model.compile(optimizer='sgd',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])
history = model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=1)
</code></pre>
<p><strong>When using a normal <code>Dataset</code>, <code>val_accuracy</code> and <code>val_loss</code> are present in the history of the model:</strong></p>
<p><a href=""https://i.stack.imgur.com/Qn1Yf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qn1Yf.png"" alt=""Expected behaviour: when using a Dataset, validation metrics are calculated"" /></a></p>
<p><strong>But when using a <code>SkipDataset</code>, they are not:</strong></p>
<p><a href=""https://i.stack.imgur.com/GMnBM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GMnBM.png"" alt=""Using the SkipDataset produced by test_val_ds.take() leads to validation metrics disappearing from model history"" /></a></p>
<p><a href=""https://i.stack.imgur.com/omU5U.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/omU5U.png"" alt=""val_accuracy and val_loss are not present in history keys when using a SkipDataset or a TakeDataset"" /></a></p>
",tf.data.Dataset,tf.data.Dataset,2022-02-15 15:56:25,"<p>The issue is that you are not taking and skipping samples when you do <code>test_val_ds.take(686)</code> and <code>test_val_ds.skip(686)</code>, but actually batches. Try running <code>print(val_dataset.cardinality())</code> and you will see how many batches you really have reserved for validation. I am guessing <code>val_dataset</code> is empty, because you do not have 686 batches for validation. Here is a working example:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import pathlib

dataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;validation&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

test_dataset = val_ds.take(5)
val_ds = val_ds.skip(5)

print('Batches for testing --&gt;', test_dataset.cardinality())
print('Batches for validating --&gt;', val_ds.cardinality())

model = tf.keras.Sequential([
  tf.keras.layers.Rescaling(1./255, input_shape=(180, 180, 3)),
  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(5)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=1
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=1
)
</code></pre>
<pre><code>Found 3670 files belonging to 5 classes.
Using 2936 files for training.
Found 3670 files belonging to 5 classes.
Using 734 files for validation.
Batches for testing --&gt; tf.Tensor(5, shape=(), dtype=int64)
Batches for validating --&gt; tf.Tensor(18, shape=(), dtype=int64)
92/92 [==============================] - 96s 1s/step - loss: 1.3516 - accuracy: 0.4489 - val_loss: 1.1332 - val_accuracy: 0.5645
</code></pre>
<p>In this example, with a <code>batch_size</code> of 32, you can clearly see that the validation set reserved 23 batches. Afterwards, 5 batches were given to the test set and 18 batches remained for the validation set.</p>
",11212528,45,https://stackoverflow.com/questions/71129505,Documentation Replication on Other Examples
71090570,How do I create a tf.Tensor from a pandas DataFrame containing arrays?,"<p>I have a pandas DataFrame like below.</p>
<pre><code>import pandas as pd
import numpy as np
import tensorflow as tf  # Version 2.8.0
df = pd.DataFrame({&quot;id&quot;: 
                   [&quot;i123&quot;, &quot;i456&quot;],  
                   &quot;col&quot;: [np.array([&quot;igh&quot;, &quot;ghdd&quot;, &quot;yu&quot;]),
                           np.array([&quot;uh&quot;, &quot;lkk&quot;, &quot;nj&quot;])]})
print(df)
</code></pre>
<p>Output:</p>
<pre><code>    id      col
0   i123    [igh, ghdd, yu]
1   i456    [uh, lkk, nj]
</code></pre>
<p>I would to create a <code>Tensor</code> from the values of the <code>col</code> column, in order to use them in a specific use case. I have tried converting the values like</p>
<pre><code>values = df[&quot;col&quot;].to_numpy()
values
</code></pre>
<p>Which looks like:</p>
<pre><code>array([array(['igh', 'ghdd', 'yu'], dtype='&lt;U4'),
       array(['uh', 'lkk', 'nj'], dtype='&lt;U3')], dtype=object)
</code></pre>
<p>When I try to convert this to a Tensor, by</p>
<pre><code>tf.constant(values)
</code></pre>
<p>I get an exception:</p>
<pre><code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).
</code></pre>
<p>I can see from the <a href=""https://www.tensorflow.org/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">documentation</a> that the tf.constant method should work on a very similar array
<a href=""https://i.stack.imgur.com/zscVM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zscVM.png"" alt=""TF docs"" /></a></p>
<p>The <code>values</code> variable I create have <code>.shape</code> like <code>(2,)</code> while the image below have <code>(2, 3)</code>, which might be the problem.
I can't seem to get the dtype and/or shape to match exactly, and I'm unsure how to get it to work. Any ideas?</p>
",tf.constant,tf.constant,2022-02-12 9:27:37,"<p>Try:</p>
<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import numpy as np
import tensorflow as tf  # Version 2.8.0
df = pd.DataFrame({&quot;id&quot;: 
                   [&quot;i123&quot;, &quot;i456&quot;],  
                   &quot;col&quot;: [np.array([&quot;igh&quot;, &quot;ghdd&quot;, &quot;yu&quot;]),
                           np.array([&quot;uh&quot;, &quot;lkk&quot;, &quot;nj&quot;])]})

values = df[&quot;col&quot;].to_list()
print(tf.constant(values))
</code></pre>
<pre><code>tf.Tensor(
[[b'igh' b'ghdd' b'yu']
 [b'uh' b'lkk' b'nj']], shape=(2, 3), dtype=string)
</code></pre>
<p>Or</p>
<pre><code>values = np.stack(df[&quot;col&quot;].to_numpy())
print(tf.constant(values))
</code></pre>
",11764097,943,https://stackoverflow.com/questions/71090570,Documentation Replicability
71019644,Equivalent tensorflow expression to numpy mask,"<p>I have a numpy array named PixelData of unknown shape, and I am using the following condition to filter values in the array greater than some value x using a mask:</p>
<pre><code>PixelData[PixelData&gt;=x] = PixelData[PixelData&gt;=x] - x
</code></pre>
<p>When I convert this numpy array to a tensor, I cannot perform the same masking operation. I have tried using tf.where as follows:</p>
<pre><code>PixelData = tf.where(PixelData&gt;=x, PixelData - x, PixelData)
</code></pre>
<p>In the official documentation, they always seem to define the mask dimensions in advance to equal the dimensions of the tensor being masked, but then they talk about the dimensions being broadcasted automatically, so I am a bit confused. Are these two functions equivalent? Are there any situations where they may produce different outputs?</p>
",tf.where,tf.where,2022-02-07 13:47:54,"<p>Not sure what <code>PixelData</code> looks like, but here is working example with both methods:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import tensorflow as tf

x = 2
np_pixel_data = np.array([[3, 4, 5, 1],
                       [6, 4, 2, 5]], dtype=np.float32)

np_pixel_data[np_pixel_data&gt;=x] = np_pixel_data[np_pixel_data&gt;=x] - x

tf_pixel_data = tf.constant([[3, 4, 5, 1],
                       [6, 4, 2, 5]], dtype=tf.float32)

tf_pixel_data = tf.where(tf.greater_equal(tf_pixel_data, x), tf_pixel_data - x, tf_pixel_data)

print(np_pixel_data)
print(tf_pixel_data)
</code></pre>
<pre><code>[[1. 2. 3. 1.]
 [4. 2. 0. 3.]]
tf.Tensor(
[[1. 2. 3. 1.]
 [4. 2. 0. 3.]], shape=(2, 4), dtype=float32)
</code></pre>
<p>You might have some minor rounding differences, but nothing significant.</p>
",17815854,45,https://stackoverflow.com/questions/71019644,Documentation Ambiguity
70880589,what does cardinality mean in relation to an image dataset?,"<p>After successfully creating a tensorflow image <code>Dataset</code> with:</p>
<p><code>dataset = tf.keras.utils.image_dataset_from_directory(...)</code></p>
<p>which returns</p>
<p><em>Found 21397 files belonging to 5 classes.
Using 17118 files for training.</em></p>
<p>There is the cardinality method:</p>
<p><code>dataset.cardinality()</code></p>
<p>which returns a tensor containing the single value</p>
<p><em>tf.Tensor(535, shape=(), dtype=int64)</em></p>
<p>I've read the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/cardinality"" rel=""nofollow noreferrer"">docs here</a> but I don't understand what 535 represents or why its different to the number of files?</p>
<p>I ask, because I would like to understand how cardinality plays into this equation:</p>
<p><code>steps_per_epoch = dataset.cardinality().numpy() // batch_size</code></p>
",tf.data.experimental.cardinality,tf.data.experimental.cardinality,2022-01-27 14:47:48,"<p>The cardinality, in your case, is simply the rounded number of batches:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import pathlib

dataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

print(train_ds.cardinality())
</code></pre>
<pre><code>Found 3670 files belonging to 5 classes.
Using 2936 files for training.
tf.Tensor(92, shape=(), dtype=int64)
</code></pre>
<p>The equation is: <code>2936/32 = cardinality</code>, so it depends on your batch size.</p>
",14777655,73,https://stackoverflow.com/questions/70880589,Lack of Alternative Solutions/Documentation
70747499,Using tf.map_fn when the function has multiple outputs,"<p>I can easily use tf.map_fn when the function has one output:</p>
<pre><code>import tensorflow as tf
tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]])

def my_fun(x):
    return x[0]

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<p><strong>output:</strong></p>
<pre><code>tf.Tensor([1. 4.], shape=(2,), dtype=float32)
</code></pre>
<p>But, when the function has two outputs:</p>
<pre><code>def my_fun(x):
    return [x[0],x[1]]

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<p>I get an error. Not sure what is going on. I read the information about tf.map_fn in here <a href=""https://www.tensorflow.org/api_docs/python/tf/map_fn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/map_fn</a>, but not sure how to fix this:</p>
<p>map_fn also supports functions with multi-arity inputs and outputs:</p>
<p><em>If elems is a tuple (or nested structure) of tensors, then those tensors must all have the same outer-dimension size (num_elems); and fn is used to transform each tuple (or structure) of corresponding slices from elems. E.g., if elems is a tuple (t1, t2, t3), then fn is used to transform each tuple of slices (t1[i], t2[i], t3[i]) (where 0 &lt;= i &lt; num_elems).
If fn returns a tuple (or nested structure) of tensors, then the result is formed by stacking corresponding elements from those structures.</em></p>
<p><strong>Output:</strong></p>
<pre><code>~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\util\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites)
    317     _pywrap_tensorflow.AssertSameStructure(nest1, nest2, check_types,
--&gt; 318                                            expand_composites)
    319   except (ValueError, TypeError) as e:

ValueError: The two structures don't have the same nested structure.

First structure: type=DType str=&lt;dtype: 'float32'&gt;

Second structure: type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]

More specifically: Substructure &quot;type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]&quot; is a sequence, while substructure &quot;type=DType str=&lt;dtype: 'float32'&gt;&quot; is not

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
&lt;ipython-input-36-5b11c7fef461&gt; in &lt;module&gt;
      5     return [x[0],x[1]]
      6 
----&gt; 7 print(tf.map_fn(my_fun,tensaki))

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)
    266         back_prop=back_prop,
    267         swap_memory=swap_memory,
--&gt; 268         maximum_iterations=n)
    269     results_flat = [r.stack() for r in r_a]
    270 

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)
   2712                                               list(loop_vars))
   2713       while cond(*loop_vars):
-&gt; 2714         loop_vars = body(*loop_vars)
   2715         if try_to_pack and not isinstance(loop_vars, (list, _basetuple)):
   2716           packed = True

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\control_flow_ops.py in &lt;lambda&gt;(i, lv)
   2703         cond = lambda i, lv: (  # pylint: disable=g-long-lambda
   2704             math_ops.logical_and(i &lt; maximum_iterations, orig_cond(*lv)))
-&gt; 2705         body = lambda i, lv: (i + 1, orig_body(*lv))
   2706       try_to_pack = False
   2707 

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\map_fn.py in compute(i, tas)
    256       packed_values = input_pack([elem_ta.read(i) for elem_ta in elems_ta])
    257       packed_fn_values = fn(packed_values)
--&gt; 258       nest.assert_same_structure(dtype or elems, packed_fn_values)
    259       flat_fn_values = output_flatten(packed_fn_values)
    260       tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\util\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites)
    323                   &quot;Entire first structure:\n%s\n&quot;
    324                   &quot;Entire second structure:\n%s&quot;
--&gt; 325                   % (str(e), str1, str2))
    326 
    327 

ValueError: The two structures don't have the same nested structure.

First structure: type=DType str=&lt;dtype: 'float32'&gt;

Second structure: type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]

More specifically: Substructure &quot;type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]&quot; is a sequence, while substructure &quot;type=DType str=&lt;dtype: 'float32'&gt;&quot; is not
Entire first structure:
.
Entire second structure:
[., .]```
</code></pre>
",tf.map_fn,tf.map_fn,2022-01-17 21:04:57,"<p>You should make sure you are returning a tensor. Maybe concatenate or stack the list of values:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]])

def my_fun(x):
    x = tf.stack([x[0], x[1]], axis=0)
    return x

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<pre><code>tf.Tensor(
[[1. 2.]
 [4. 5.]], shape=(2, 2), dtype=float32)
</code></pre>
<p>Of course, it all depends on the output you are expecting.</p>
",11861082,399,https://stackoverflow.com/questions/70747499,Documentation Replication on Other Examples
68984841,How can I understand the kernel of tf.keras.layers.Dense for rank >2?,"<p>How can I understand the kernel of <code>tf.keras.layers.Dense</code> for rank &gt;2?</p>
<p>The official API doc states that:</p>
<blockquote>
<p>Note: If the input to the layer has a rank greater than 2, then Dense
computes the dot product between the inputs and the kernel along the
last axis of the inputs and axis 0 of the kernel (using tf.tensordot).
For example, if input has dimensions (batch_size, d0, d1), then we
create a kernel with shape (d1, units), and the kernel operates along
axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there
are batch_size * d0 such sub-tensors). The output in this case will
have shape (batch_size, d0, units).</p>
</blockquote>
<p>My understanding is that for a rank larger than 2 (for example rank 3) only <strong>one</strong> kernel is created and thus the same kernel is applied on all slices of the second dimension, like above.
That would consequently mean that the outputs for different indices of the second dimension are <strong>not independent</strong> of each other (especially during training).</p>
<p>Is my understanding correct? And if yes, is there a simple way to use a stack of kernels instead or do I have to implement the tensor multiplication?</p>
",tf.keras.layers.Dense,tf.keras.layers.Dense,2021-08-30 13:16:38,"<p>Yes, your understanding is correct.</p>
<p>To achieve what you want, you need to define a custom keras layer. Let's suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original <code>Dense</code> layer (link: <a href=""https://github.com/tensorflow/tensorflow/blob/22ffec3a9c44133cba2182d60678d49bb372f020/tensorflow/python/keras/layers/core.py#L1077"" rel=""nofollow noreferrer"">github</a>), except that</p>
<ol>
<li>In the <code>build</code> function, the shape of <code>self.kernel</code> is (d0, i0, units) instead. You can get the value of <code>d0</code> as well as <code>i0</code> from <code>input_shape</code>.</li>
<li>In the <code>call</code> function, to do the specified tensor multiplication between <code>inputs</code> and <code>self.kernel</code>, use <code>tf.einsum</code> with this equation: <code>tf.einsum('abc,bcg-&gt;abg', inputs, self.kernel)</code></li>
</ol>
",16787662,13,https://stackoverflow.com/questions/68984841,Documentation Replicability
68431633,tf.image.stateless_random_crop VS. tf.image.random_crop. Shouldn't these be the same thing?,"<p>In tf 2.5, there are two functions for cropping an image: <code>tf.image.stateless_random_crop</code>, and <code>tf.image.random_crop</code>. The documentation states that <code>stateless_random_crop</code> is deterministic (always returns the same crop given one seed). However, <code>random_crop</code> has a seed parameter and is also deterministic, one would think. What is the actual difference between these two functions? I cannot find information about statelessness in Tensorflow anywhere.</p>
<p>The differences between <code>tf.image.stateless_random_crop</code>, and <code>tf.image.random_crop</code> are one line where stateless_random_uniform is used instead of a random_uniform:
stateless_random_crop: <a href=""https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L415-L465"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L415-L465</a>
random_crop: <a href=""https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L360-L412"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L360-L412</a></p>
<p>I always thought that <code>random_crop</code> would always return the same crop given a seed, but it looks like maybe that wasn't always true? Any enlightenment about statelessness in Tensorflow is greatly appreciated!</p>
",tf.image.stateless_random_crop,tf.image.stateless_random_crop,2021-07-18 17:39:57,"<p><code>random_crop</code> always return the same sequence of crops only when <strong>both</strong> global seed <strong>and</strong> operation seed are set.</p>
<ol>
<li>global seed is set using <code>tf.random.set_seed(global_seed)</code></li>
<li>operation seed is set by passing the seed argument into the operation, i.e., <code>tf.image.random_crop(value, size, seed=ops_seed)</code></li>
</ol>
<p>whereas what <code>stateless_random_crop</code> returns is totally determined by the seed you pass into it when the device and tensorflow version are unchanged.</p>
<p>And you are correct that the functions look redundant and duplicate but actually <code>tf.image.random_crop</code> is from the old RNGs API and it may be buggy in graph mode. The new RNGs API is <code>tf.random.Generator</code> and the stateless RNGs. For more information, see <a href=""https://www.tensorflow.org/guide/random_numbers"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/random_numbers</a></p>
<p>Using <code>tf.random.Generator</code> in combination with <code>stateless_random_crop</code>:</p>
<pre><code>class new_RNGs_random_crop:
  def __init__(self,seed,size):
    self.rand_generator=tf.random.Generator.from_seed(seed)
    self.size=size
  def random_crop(self,x):
    return tf.image.stateless_random_crop(x,self.size,
           seed=self.rand_generator.uniform_full_int([2],dtype=tf.int32))

dummy_dataset=tf.data.Dataset.from_tensor_slices(np.arange(2*3*3).reshape((2,3,3))).batch(1)
cropper=new_RNGs_random_crop(88883,(1,2,2))
dummy_dataset=dummy_dataset.map(cropper.random_crop)

for image in dummy_dataset:
  print(image)
</code></pre>
<p>Example outputs:</p>
<pre><code>tf.Tensor(
[[[3 4]
  [6 7]]], shape=(1, 2, 2), dtype=int64)
tf.Tensor(
[[[ 9 10]
  [12 13]]], shape=(1, 2, 2), dtype=int64)
</code></pre>
",11632499,185,https://stackoverflow.com/questions/68431633,Documentation Ambiguity
67197448,How to extract multiple rows from tensor at the same time?,"<p>TL;DR:
TensorFlow tensor is of shape <code>(50, 50, 6)</code>, want these indices (:, :, (0, 2, 3)). How to extract them?</p>
<p>Here is an example array I am working with:</p>
<pre><code>import numpy as np

a = np.random.randint(0,10, (50, 50, 6))
</code></pre>
<p>I want to extract the the first, third, and fourth row; in other words I need all these entries <code>(:, :, (1, 3))</code>, which works for numpy arrays:</p>
<pre><code>out = a[:,:, [0, 2, 3]]
out.shape #(50, 50, 3)

</code></pre>
<p>Working with a tensor <code>t = tf.convert_to_tensor(a)</code> and then calling the index like</p>
<pre><code>t[:,:, [0, 2, 3]]
</code></pre>
<p>throws an error:</p>
<pre><code>TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got [0, 1, 3]
</code></pre>
<p>For numpy I have found the following relevant questions, but they naturally focus on numpy arrays:</p>
<p><a href=""https://stackoverflow.com/questions/46227095/how-to-slice-a-2d-array-non-consecutively-in-python?noredirect=1&amp;lq=1"">How to slice a 2D array non-consecutively in Python</a></p>
<p><a href=""https://stackoverflow.com/questions/24398708/slicing-a-numpy-array-along-a-dynamically-specified-axis"">Slicing a numpy array along a dynamically specified axis</a></p>
<p>Looking at the TF documentation I found <code>gather_nd</code> and <code>boolean_mask</code>, which I feel are helpful, but I must freely admit that I have not understood the docs at this part. On SO I found this question <a href=""https://stackoverflow.com/questions/58052967/how-to-select-elements-of-a-tensor-along-a-specific-axis-in-tensorflow"">How to select elements of a tensor along a specific axis in TensorFlow</a>, which focuses on single elements; I am looking for complete dimensions (if that's the right wording here).</p>
<p>How can I do the numpy thing in TensorFlow?</p>
",-,-,2021-04-21 14:02:33,"<p>If you want the 0,2 and 3rd element of the last axis in the tensor, you can use tf.gather as follows: tf.gather(t,indices=[0, 2, 3],axis=-1))</p>
",12859833,310,https://stackoverflow.com/questions/67197448,Documentation Replication on Other Examples
66879748,What is the difference between tf.keras.model and tf.keras.sequential?,"<p>In some <code>tf. keras</code> tutorials, I've seen them instantiated their model class like this:</p>
<p><code>model = tf.keras.Sequential()</code></p>
<p>While in some places, they use something like this:</p>
<p><code>model = tf.keras.Model(inputs=input, outputs=output)</code></p>
<p>But seeing here in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""noreferrer"">docs</a>, they do seem the same, but I am not sure nor is it explicitly mentioned. What are the differences between the two?</p>
",tf.keras.Model,tf.keras.Model,2021-03-30 23:31:57,"<p>There are two class API to define a model in <code>tf. keras</code>. According to the doc</p>
<ul>
<li><p><a href=""https://keras.io/api/models/sequential/"" rel=""noreferrer""><code>Sequential class</code></a>: Sequential groups a linear stack of layers into a <code>tf. keras.Model</code>.</p>
</li>
<li><p><a href=""https://keras.io/api/models/model/"" rel=""noreferrer""><code>Model class</code></a>: <code>Model</code> group's layers into an object with training and inference features.</p>
</li>
</ul>
<hr />
<p>An <code>Sequential</code> model is the simplest type of model, a linear stack of layers. But there are some flaws in using the <code>sequential</code> model API, it's limited in certain points. We can't build complex networks such as multi-input or multi-output networks using this API.</p>
<p>But using <a href=""https://keras.io/api/models/model/"" rel=""noreferrer""><code>Model class</code></a>, we can instantiate a Model with the <strong>Functional API</strong> (and also with <strong>Subclassing the Model class</strong>) that allows us to create arbitrary graphs of layers. From this, we can get more flexibility and easily define models where each layer can connect not just with the previous and next layers but also share feature information with other layers in the model, for example, model-like <code>ResNet</code>, <code>EfficientNet</code>.</p>
<p>In fact, most of the SOTA model that you can get from <code>tf.keras.applications</code> is basically implemented using the <strong>Functional API</strong>. However, in subclassing API, we define our layers in <code>__init__</code> and we implement the model's forward pass in the <code>call</code> method.</p>
<p>Generally speaking, all the model definitions using Sequential API, can be achieved in Functional API or Model Subclassing API. And in Functional API or Model Subclassing API, we can create complex layers that not possible to achieve in Sequential API. If you wondering which one to choose, the answer is, it totally depends on your need. However, check out the following blog post where we have discussed the various model strategies in <code>tf. keras</code> with more examples. <a href=""https://towardsdatascience.com/model-sub-classing-and-custom-training-loop-from-scratch-in-tensorflow-2-cc1d4f10fb4e"" rel=""noreferrer"">Model Sub-Classing and Custom Training Loop from Scratch in TensorFlow 2</a></p>
",8648710,1198,https://stackoverflow.com/questions/66879748,Documentation Ambiguity
66874943,Why iterations over the same tf.data.Dataset give different data each iteration?,"<p>I'm trying to understand how <strong>tf.data.Dataset</strong> works.</p>
<p>It says on the documentation that <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take"" rel=""nofollow noreferrer"">take</a> returns a dataset with a certain amount of elements from that dataset. You can then iterate over a single sample (in this case a batch):</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow.compat.v2 as tf
import tensorflow_datasets as tfds

# Construct a tf.data.Dataset
ds = tfds.load('mnist', split='train', shuffle_files=True)

# Build your input pipeline
ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

single_batch_dataset = ds.take(1)

for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)
# ...
</code></pre>
<p>Outputs:</p>
<pre><code>tf.Tensor([2 0 6 6 8 8 6 0 3 4 8 7 5 2 5 7 8 7 1 1 1 8 6 4 0 4 3 2 4 2 1 9], shape=(32,), dtype=int64)
</code></pre>
<p>However, iterating over it again, gives different labels: (continuation of last code)</p>
<pre class=""lang-py prettyprint-override""><code>for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)

for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)

</code></pre>
<p>Outputs:</p>
<pre><code>tf.Tensor([7 3 5 6 3 1 7 9 6 1 9 3 9 8 6 7 7 1 9 7 5 2 0 7 8 1 7 8 7 0 5 0], shape=(32,), dtype=int64)
tf.Tensor([1 3 6 1 8 8 0 4 1 3 2 9 5 3 8 7 4 2 1 8 1 0 8 5 4 5 6 7 3 4 4 1], shape=(32,), dtype=int64)
</code></pre>
<p>Shouldn't the labels be the same, given that the dataset is the same?</p>
",tf.data.Dataset,tf.data.Dataset,2021-03-30 16:35:49,"<p>This is because the data files are shuffled and the dataset is shuffled with <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=ru#shuffle"" rel=""nofollow noreferrer""><code>dataset.shuffle()</code></a>.</p>
<p>With <code>dataset.shuffle()</code>, the data will be shuffled in a different way on each iteration by default.</p>
<p>One can remove <code>shuffle_files=True</code> and set the argument <code>reshuffle_each_iteration=False</code> to prevent reshuffling on different iterations.</p>
<p>The <code>.take()</code> function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them.</p>
<pre class=""lang-py prettyprint-override""><code># Construct a tf.data.Dataset
ds = tfds.load('mnist', split='train', shuffle_files=False)

# Build your input pipeline
ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

single_batch_dataset = ds.take(1)

for example in single_batch_dataset:
    image, label = example[&quot;image&quot;], example[&quot;label&quot;]
    print(label)
    
for example in single_batch_dataset:
    image, label = example[&quot;image&quot;], example[&quot;label&quot;]
    print(label)
</code></pre>
<p>Output:</p>
<pre class=""lang-py prettyprint-override""><code>tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)
tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)
</code></pre>
",2076973,1151,https://stackoverflow.com/questions/66874943,Documentation Replicability
65464181,An alternative to tf.distribute.cluster_resolver.TPUClusterResolver( tpu_name) to be used in Sagemaker?,"<ol>
<li><p>task : object_detection</p>
</li>
<li><p>environment: AWS sagemaker</p>
</li>
<li><p>instance type: 'ml.p2.xlarge' | num_instances = 1</p>
</li>
<li><p>Main file to be run: <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py"" rel=""nofollow noreferrer"">original</a></p>
</li>
<li><p>Problematic code segment from the main file:</p>
<pre><code>    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
    FLAGS.tpu_name)
    tf.config.experimental_connect_to_cluster(resolver)
    tf.tpu.experimental.initialize_tpu_system(resolver)
    strategy = tf.distribute.experimental.TPUStrategy(resolver)
    elif FLAGS.num_workers &gt; 1:
        strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    else:
        strategy = tf.compat.v2.distribute.MirroredStrategy()
</code></pre>
</li>
<li><p>Problem : Can't find the proper value to be given as <code>tpu_name</code> argument.</p>
</li>
<li><p>My research on the problem:</p>
</li>
</ol>
<p>According to the tensorflow documentation in <a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/TPUClusterResolver"" rel=""nofollow noreferrer"">tf.distribute.cluster_resolver.TPUClusterResolver</a>, it says that this resolver works only on Google Cloud platform.</p>
<blockquote>
<p>This is an implementation of cluster resolvers for the Google Cloud
TPU service.</p>
<p>TPUClusterResolver supports the following distinct environments:
Google Compute Engine Google Kubernetes Engine Google internal</p>
<p>It can be passed into tf.distribute.TPUStrategy to support TF2
training on Cloud TPUs.</p>
</blockquote>
<p>But from <a href=""https://github.com/tensorflow/tensorflow/issues/39721"" rel=""nofollow noreferrer"">this issue in github</a>, I found out that a similar code also works in Azure.</p>
<ol start=""8"">
<li>My question :</li>
</ol>
<p>Is there a way I can bypass this resolver and initialize my tpu in <strong>sagemaker</strong> ?</p>
<p>Even better, if I can find a way to insert the name or url of sagemaker gpu to the resolver and initiate it from there ?</p>
",tf.distribute.cluster_resolver.TPUClusterResolver,tf.distribute.cluster_resolver.TPUClusterResolver,2020-12-27 8:55:38,"<p>Let me clarify some confusion here. TPUs are only offered on Google Cloud and the <code>TPUClusterResolver</code> implementation queries GCP APIs to get the cluster config for the TPU node. Thus, no you can't use <code>TPUClusterResolver</code> with AWS sagemaker, but you should try it out with TPUs on GCP instead or try find some other documentation on Sagemaker's end on how they enable cluster resolving on their end (if they do).</p>
",9279666,75,https://stackoverflow.com/questions/65464181,Documentation Replicability
65436819,Keras: How to use `image_dataset_from_directory` to load test set?,"<p>I am using <code>tf.keras.preprocessing.image_dataset_from_directory</code> to load dataset as follows,</p>
<pre><code>train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir, 
                                                                    labels='inferred', 
                                                                    label_mode='categorical',
                                                                    batch_size=32,
                                                                    image_size=(224, 224))


val_dataset = tf.keras.preprocessing.image_dataset_from_directory(val_dir, 
                                                                  labels='inferred', 
                                                                  label_mode='categorical',
                                                                  batch_size=32,
                                                                  image_size=(224, 224))

</code></pre>
<p>However, when I check the document looks like this argument <code>labels</code> seem to be a must-have one,  but my test data has no labels, so how can I load test data? Is there a convenient and unified way to do this?</p>
",tf.keras.preprocessing.image_dataset_from_directory,tf.keras.utils.image_dataset_from_directory,2020-12-24 10:08:53,"<p>If your data isn't labeled, I don't think you can call it the <em>test set</em>, since you won't be able to evaluate the performance of your algorithm using it.</p>
<p>The argument you're looking for is <code>label_mode</code>, see the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer""><code>documentation</code></a>. If you set it to <code>label_model=None</code>, it will not return a target;</p>
<blockquote>
<p><strong>label_mode</strong>: <strong>'int'</strong>: means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).
<strong>'categorical'</strong> means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).
<strong>'binary'</strong> means that the labels (there can be only 2) are encoded as float32 scalars with values 0 or 1 (e.g. for binary_crossentropy).
<strong>None</strong> (no labels).</p>
</blockquote>
",9444831,1150,https://stackoverflow.com/questions/65436819,Documentation Replicability
64826405,Tensorflow: 'axis' argument in dot product,"<p>Can someone show me the way I should use the <code>axis</code> argument in <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""nofollow noreferrer""><code>tf.tensordot</code></a>?</p>
<p>I read the documentation but it was complicated and I'm still confused. I saw <a href=""https://stackoverflow.com/questions/48082900/in-tensorflow-what-is-the-argument-axis-in-the-function-tf-one-hot"">another question</a> that asks about <code>axis</code> in <code>tf.one_hot</code> and in the answers were some good insights about the matter, but that didn't help me with <code>tf.tensordot</code>. I thought you can give me some insights on this too.</p>
<p>For example, I know I can dot product a vector and a tensor like this:</p>
<pre><code>my_vector = tf.random.uniform(shape=[n])
my_tensor = tf.random.uniform(shape=[m, n])

dp = tf.tensordot(my_tensor, my_vector, 1)
</code></pre>
<p>But when I <em><strong>batch</strong></em> them and add one dimension to them to be of the shape <code>(b, n)</code> and <code>(b, m, n)</code> to obtain a <code>(b, m, 1)</code>, now I don't know how to dot product every batch.</p>
",tf.tensordot,tf.tensordot,2020-11-13 18:46:00,"<p>The operation that you want to do cannot be done (in an effective way) with <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""nofollow noreferrer""><code>tf.tensordot</code></a>. There is, however, a dedicated function for that operation, <a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/matvec"" rel=""nofollow noreferrer""><code>tf.linalg.matvec</code></a>, which will work with batches out of the box. And you can also do the same thing with <a href=""https://www.tensorflow.org/api_docs/python/tf/einsum"" rel=""nofollow noreferrer""><code>tf.einsum</code></a>, like <code>tf.einsum('bmn,bn-&gt;bm', my_tensors, my_vectors)</code>.</p>
<p>With respect to <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""nofollow noreferrer""><code>tf.tensordot</code></a>, in general it computes an &quot;all vs all&quot; product of the two given tensors, but matching and reducing some axes. When no axes are given (you have to explicitly pass <code>axes=[[], []]</code> to do this), it creates a tensor with the dimensions of both inputs concatenated. So, if you have <code>my_tensors</code> with shape <code>(b, m, n)</code> and <code>my_vectors</code> with shape <code>(b, n)</code> and you do:</p>
<pre class=""lang-py prettyprint-override""><code>res = tf.tensordot(my_tensors, my_vectors, axes=[[], []])
</code></pre>
<p>You get <code>res</code> with shape <code>(b, m, n, b, n)</code>, such that <code>res[p, q, r, s, t] == my_tensors[p, q, r] * my_vectors[s, t]</code>.</p>
<p>The <code>axes</code> argument is used to specify dimensions in the input tensors that are &quot;matched&quot;. Values along matched axes are multiplied and summed (like a dot product), so those matched dimensions are reduced from the output. <code>axes</code> can take two different forms:</p>
<ul>
<li>If it is a single integer, <code>N</code> then the last <code>N</code> dimensions of the first parameter are matched against the first <code>N</code> dimensions of <code>b</code>. In your example, that corresponds to the dimensions with <code>n</code> elements in <code>my_tensor</code> and <code>my_vector</code>.</li>
<li>If it is a list, it must contain two sublists, <code>axes_a</code> and <code>axes_b</code>, each with the same number <code>N</code> of integers. In this form, you are explicitly indicating which dimensions of the given values are matched. So, in your example, you could have passed <code>axes=[[1], [0]]</code>, which means &quot;match the dimension <code>1</code> of the first parameter (<code>my_tensor</code>) to the dimension <code>0</code> of the second parameter (<code>my_vector</code>)&quot;.</li>
</ul>
<p>If you have now <code>my_tensors</code>  with shape <code>(b, m, n)</code> and <code>my_vectors</code> with shape <code>(b, n)</code>, then you would want to match the dimension <code>2</code> of the first one to the dimension <code>1</code> of the second one, so you could pass <code>axes=[[2], [1]]</code>. However, that will give you a result <code>res</code> with shape <code>(b, m, b)</code> such that <code>res[i, :, j]</code> is the product of matrix <code>my_tensors[i]</code> and vector <code>my_vectors[j]</code>. You could take then only the results that you want (those where <code>i == j</code>), with something more or less convoluted like <code>tf.transpose(tf.linalg.diag_part(tf.transpose(res, [1, 0, 2])))</code>, but you would be doing far more computation than you need to get the same result.</p>
",7339624,3432,https://stackoverflow.com/questions/64826405,Documentation Ambiguity
64642944,Steps of tf.summary.* operations in TensorBoard are always 0,"<p>When I'm training my model with TensorFlow 2.3, I want to visualize some intermediate tensors calculated using the weight in the computation graph of my customized <code>tf.keras.layers.Layer</code>.</p>
<p>So I use <code>tf.summary.image()</code> to record these tensors and visualize them as images like this:</p>
<pre><code>class CustomizedLayer(tf.keras.layers.Layer):
    def call(self, inputs, training=None):
        # ... some code ...
        tf.summary.image(name=&quot;some_weight_map&quot;, data=some_weight_map)
        # ... some code ...
</code></pre>
<p>But in TensorBoard, no matter how many steps passed, there is only one image of step 0 shown.</p>
<p>And I tried to set the parameter <em><strong>step</strong></em> of <code>tf.summary.image()</code> to the value obtained from <code>tf.summary.experimental.get_step()</code>:</p>
<pre><code>tf.summary.image(name=&quot;weight_map&quot;, data=weight_map, step=tf.summary.experimental.get_step())
</code></pre>
<p>And update the step by calling <strong>tf.summary.experimental.set_step</strong> from a customized Callback using a tf.Variable like codes shown below:</p>
<pre><code>class SummaryCallback(tf.keras.callbacks.Callback):
def __init__(self, step_per_epoch):
    super().__init__()
    self.global_step = tf.Variable(initial_value=0, trainable=False, name=&quot;global_step&quot;)
    self.global_epoch = 0
    self.step_per_epoch = step_per_epoch
    tf.summary.experimental.set_step(self.global_step)

def on_batch_end(self, batch, logs=None):
    self.global_step = batch + self.step_per_epoch * self.global_epoch
    tf.summary.experimental.set_step(self.global_step)  
    # whether the line above is commented, calling tf.summary.experimental.get_step() in computation graph code always returns 0.
    # tf.print(self.global_step)

def on_epoch_end(self, epoch, logs=None):
    self.global_epoch += 1
</code></pre>
<p>This Callback's instance is passed in the argument <em><strong>callbacks</strong></em> in <code>model.fit()</code> function.</p>
<p>But the value <code>tf.summary.experimental.get_step()</code> returned is still 0.</p>
<p>The TensorFlow document of &quot;<code>tf.summary.experimental.set_step()</code>&quot; says:</p>
<blockquote>
<p>when using this with @tf.functions, the step value will be captured at the time the function is traced, so changes to the step outside the function will not be reflected inside the function unless using a tf.Variable step.</p>
</blockquote>
<p>Accroding to the document, I am already using a Variable to store the steps, but it's changes are still not reflected inside the function (or keras.Model).</p>
<p>Note: My code produces expected results in TensorFlow 1.x with just a simple line of <code>tf.summary.image()</code> before I migrate it to TensorFlow 2.</p>
<p>So I want to know if my approach is wrong in TensorFlow 2?</p>
<p>In TF2, how can I <strong>get training steps inside the computation graph</strong>?</p>
<p>Or there is other solution to <strong>summarize tensors (as scalar, image, etc.) inside a model in TensorFlow 2</strong>?</p>
",tf.Variable,tf.Variable,2020-11-02 9:33:43,"<p>I found this issue has been reported on Github repository of Tensorflow: <a href=""https://github.com/tensorflow/tensorflow/issues/43568"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/43568</a></p>
<p>This is caused by using <strong>tf.summary</strong> in model while <strong>tf.keras.callbacks.TensorBoard</strong> callback is also enabled, and the step will always be zero. The issue reporter gives a temporary solution.</p>
<p>To fix it, inherit the <strong>tf.keras.callbacks.TensorBoard</strong> class and overwrite the <strong>on_train_begin</strong> method and <strong>on_test_begin</strong> method like this:</p>
<pre><code>class TensorBoardFix(tf.keras.callbacks.TensorBoard):
&quot;&quot;&quot;
This fixes incorrect step values when using the TensorBoard callback with custom summary ops
&quot;&quot;&quot;

def on_train_begin(self, *args, **kwargs):
    super(TensorBoardFix, self).on_train_begin(*args, **kwargs)
    tf.summary.experimental.set_step(self._train_step)


def on_test_begin(self, *args, **kwargs):
    super(TensorBoardFix, self).on_test_begin(*args, **kwargs)
    tf.summary.experimental.set_step(self._val_step)
</code></pre>
<p>And use this fixed callback class in <strong>model.fit()</strong>:</p>
<pre><code>tensorboard_callback = TensorBoardFix(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=1)
model.fit(dataset, epochs=200, callbacks=[tensorboard_callback])
</code></pre>
<p>This solve my problem and now I can get proper step inside my model by calling <strong>tf.summary.experimental.get_step()</strong>.</p>
<p>(This issue may be fixed in later version of TensorFlow)</p>
",14562728,31,https://stackoverflow.com/questions/64642944,Documentation Replication on Other Examples
64611137,port TensorFlow 1 code to TensorFlow 2 (model learning process without sess.run),"<p>I have this piece of tf1 code, which was taken from nice book &quot;Deep Learning&quot; by S. Nikolenko.</p>
<p>It's a simple linear regression that learns <code>k</code> and <code>b</code> to 2 and 1 respectively.</p>
<pre><code>%tensorflow_version 1.x

import numpy as np,tensorflow as tf
import pandas as pd

n_samples, batch_size, num_steps = 1000, 100, 20000 #set learning constants
X_data = np.random.uniform(1, 10, (n_samples, 1)) #generate array x from 1 to 10 of shape (1000,1)
print(X_data.shape)
y_data = 2 * X_data + 1 + np.random.normal(0, 2, (n_samples, 1)) #generate right answer and add noise to it (to make it scatter)

X = tf.placeholder(tf.float32, shape=(batch_size, 1)) #defining placeholders to put into session.run
y = tf.placeholder(tf.float32, shape=(batch_size, 1))

with tf.variable_scope('linear-regression'):
  k = tf.Variable(tf.random_normal((1, 1)), name='slope') #defining 2 variables with shape (1,1)
  b = tf.Variable(tf.zeros((1,)), name='bias') # and (1,)
  print(k.shape,b.shape)

y_pred = tf.matmul(X, k) + b # all predicted y in batch, represents linear formula k*x + b
loss = tf.reduce_sum((y - y_pred) ** 2)  # mean square
optimizer = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)
display_step = 100

with tf.Session() as sess:
  sess.run(tf.initialize_variables([k,b]))
  for i in range(num_steps):
    indices = np.random.choice(n_samples, batch_size) # taking random indices
    X_batch, y_batch = X_data[indices], y_data[indices] # taking x and y from generated examples
    _, loss_val, k_val, b_val = sess.run([optimizer, loss, k, b ],
      feed_dict = { X : X_batch, y : y_batch })
    if (i+1) % display_step == 0:
      print('Epoch %d: %.8f, k=%.4f, b=%.4f' %
        (i+1, loss_val, k_val, b_val))

</code></pre>
<p>I'm striving to port it on TensorFlow 2</p>
<p>And for long time I can't wrap my head what should I use instead of <code>sess.run()</code> and <code>feed_dict</code>, which doing magic behind the scenes, official documentation go into to details with writing model class and so on, but I'm want to keep this as flat as possible.</p>
<p>Also it's suggested to calculate derivatives with <code>tf.GradientTape</code>, but I'm struggling with applying it right to my example</p>
<pre><code>%tensorflow_version 2.x

import numpy as np,tensorflow as tf
import pandas as pd

n_samples, batch_size, num_steps = 1000, 100, 200
X_data = np.random.uniform(1, 10, (n_samples, 1))
y_data = 2 * X_data + 1 + np.random.normal(0, 2, (n_samples, 1))

X = tf.Variable(tf.zeros((batch_size, 1)), dtype=tf.float32, shape=(batch_size, 1))
y = tf.Variable(tf.zeros((batch_size, 1)), dtype=tf.float32, shape=(batch_size, 1))

k = tf.Variable(tf.random.normal((1, 1)), name='slope')
b = tf.Variable(tf.zeros((1,)), name='bias')

loss = lambda: tf.reduce_sum((y - (tf.matmul(X, k) + b)) ** 2)
optimizer = tf.keras.optimizers.SGD(0.01).minimize(loss, [k, b, X, y])
display_step = 100


for i in range(num_steps):
  indices = np.random.choice(n_samples, batch_size)
  X_batch, y_batch = X_data[indices], y_data[indices]
  
</code></pre>
<p>I need SGD optimizer minimize that given loss function and learn k and b values, how can I achieve it from this point?</p>
",-,-,2020-10-30 15:19:16,"<p>After plenty of manuals I got how to do that was hiding under the hood of <code>sess.run</code> in tf1, but without an optimizer:</p>
<ol>
<li>Counting loss</li>
<li>Conunting gradients with respect to variables trained</li>
<li>Adjust grow speed of function relative to each trained var to learning rate</li>
<li>Assing new values to <code>k</code> and <code>b</code></li>
</ol>
<pre><code>X_batch, y_batch = X_data[indices], y_data[indices]
X.assign(tf.convert_to_tensor(X_batch))
y.assign(tf.convert_to_tensor(y_batch))
with tf.GradientTape(persistent=True) as tape:
  loss_val = loss()

dy_dk = tape.gradient(loss_val, k)
dy_db = tape.gradient(loss_val, b)

k.assign_sub(dy_dk * learn_rate)
b.assign_sub(dy_db * learn_rate)
if (i+1) % display_step == 0:
  print('Epoch %d: %.8f, k=%.4f, b=%.4f' %
        (i+1, loss_val, k.numpy(), b.numpy()))
</code></pre>
",6634635,41,https://stackoverflow.com/questions/64611137,Documentation Replicability
64380057,TF 2.3.0 training keras model using tf dataset with sample weights does not apply to metrics,"<p>I am passing in sample_weight as the 3rd tuple in tf.data.Dataset (using it in the context of mask, so my sample_weight are either 0, or 1. The problem is that this sample_weight doesn't seem to get applied to metrics calculation. (Ref: <a href=""https://www.tensorflow.org/guide/keras/train_and_evaluate#sample_weights"" rel=""noreferrer"">https://www.tensorflow.org/guide/keras/train_and_evaluate#sample_weights</a>)</p>
<p>Here's code snippet:</p>
<pre><code>train_ds = tf.data.Dataset.from_tensor_slices((imgs, labels, masks))
train_ds = train_ds.shuffle(1024).repeat().batch(32).prefetch(buffer_size=AUTO)

model.compile(optimizer = Adam(learning_rate=1e-4),
             loss = SparseCategoricalCrossentropy(),
             metrics = ['sparse_categorical_accuracy'])

model.fit(train_ds, steps_per_epoch = len(imgs)//32, epochs = 20)
</code></pre>
<p>The loss after training is very close to zero, but sparse_categorical_accuracy is not (about 0.89). So I highly suspect whatever sample_weight (masks) that's passed in to construct the tf.dataset, does NOT get applied when the metrics is reported during training, while loss seems to be correct. I further confirmed by running prediction on the subset that are not masked separately, and confirmed the accuracy is 1.0</p>
<p>Also, according to documentation:</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy</a></p>
<p>the metric has 3 args: y_true, y_pred, sample_weight</p>
<p>So how does one pass the sample_weight during metric computation? Is this the responsibility of model.fit(...) within the keras framework? I can't find any example googling around so far.</p>
",tf.keras.metrics.SparseCategoricalAccuracy,tf.keras.metrics.SparseCategoricalAccuracy,2020-10-15 21:40:39,"<p>Upon some debugging and doc reading, i found there's weighted_metrics argument in .compile, which i should use instead of metrics=. I confirmed this fixed my test case in the shared colab.</p>
<pre><code>model.compile(optimizer = Adam(learning_rate=1e-4),
             loss = SparseCategoricalCrossentropy(),
             weighted_metrics = [SparseCategoricalAccuracy()])
</code></pre>
",1762295,3759,https://stackoverflow.com/questions/64380057,Inadequate Examples
64326029,Load tensorflow images and create patches,"<p>I am using <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer"">image_dataset_from_directory</a> to load a very large RGB imagery dataset from disk into a <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">Dataset</a>. For example,</p>
<pre><code>dataset = tf.keras.preprocessing.image_dataset_from_directory(
    &lt;directory&gt;,
    label_mode=None,
    seed=1,
    subset='training',
    validation_split=0.1)
</code></pre>
<p>The Dataset has, say, 100000 images grouped into batches of size 32 yielding a <code>tf.data.Dataset</code> with spec <code>(batch=32, width=256, height=256, channels=3)</code></p>
<p>I would like to extract patches from the images to create a new <code>tf.data.Dataset</code> with image spatial dimensions of, say, 64x64.</p>
<p>Therefore, I would like to create a new Dataset with 400000 patches still in batches of 32 with a <code>tf.data.Dataset</code> with spec <code>(batch=32, width=64, height=64, channels=3)</code></p>
<p>I've looked at the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"" rel=""nofollow noreferrer"">window</a> method and the <a href=""https://www.tensorflow.org/api_docs/python/tf/image/extract_patches"" rel=""nofollow noreferrer"">extract_patches</a> function but it's not clear from the documentation how to use them to create a new Dataset I need to start training on the patches. The <code>window</code> seems to be geared toward 1D tensors and the <code>extract_patches</code> seems to work with arrays and not with Datasets.</p>
<p>Any suggestions on how to accomplish this?</p>
<p>UPDATE:</p>
<p>Just to clarify my needs. I am trying to avoid manually creating the patches on disk. One, that would be untenable disk wise. Two, the patch size is not fixed. The experiments will be conducted over several patch sizes. So, I do not want to manually perform the patch creation either on disk or manually load the images in memory and perform the patching. I would prefer to have tensorflow handle the patch creation as part of the pipeline workflow to minimize disk and memory usage.</p>
",tf.image.extract_patches,tf.image.extract_patches,2020-10-12 22:18:54,"<p>What you're looking for is <a href=""https://www.tensorflow.org/api_docs/python/tf/image/extract_patches"" rel=""nofollow noreferrer""><code>tf.image.extract_patches</code></a>. Here's an example:</p>
<pre><code>import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np

data = tfds.load('mnist', split='test', as_supervised=True)

get_patches = lambda x, y: (tf.reshape(
    tf.image.extract_patches(
        images=tf.expand_dims(x, 0),
        sizes=[1, 14, 14, 1],
        strides=[1, 14, 14, 1],
        rates=[1, 1, 1, 1],
        padding='VALID'), (4, 14, 14, 1)), y)

data = data.map(get_patches)

fig = plt.figure()
plt.subplots_adjust(wspace=.1, hspace=.2)
images, labels = next(iter(data))
for index, image in enumerate(images):
    ax = plt.subplot(2, 2, index + 1)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.imshow(image)
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/qn1od.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qn1od.png"" alt=""enter image description here"" /></a></p>
",14438185,23,https://stackoverflow.com/questions/64326029,Documentation Replication on Other Examples
64081367,Slicing a tensor with a tensor of indices and tf.gather,"<p>I am trying to slice a tensor with a indices tensor. For this purpose I am trying to use <code>tf.gather</code>.
However, I am having a hard time understanding the <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer"">documentation</a> and don't get it to work as I would expect it to:</p>
<p>I have two tensors. An <code>activations</code> tensor with a shape of <code>[1,240,4]</code> and an <code>ids</code> tensor with the shape <code>[1,1,120]</code>. I want to slice the second dimension of the <code>activations</code> tensor with the indices provided in the third dimension of the <code>ids</code> tensor:</p>
<pre><code>downsampled_activations = tf.gather(activations, ids, axis=1)
</code></pre>
<p>I have given it the <code>axis=1</code> option since that is the axis in the <code>activations</code> tensor I want to slice.</p>
<p>However, this does not render the expected result and only gives me the following error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0,0,1] = 1 is not in [0, 1)
</code></pre>
<p>I have tried various combinations of the <code>axis</code> and <code>batch_dims</code> options, but to no avail so far and the documentation doesn't really help me on my path. Anybody care to explain the parameters in more detail or on the example above would be very helpful!</p>
<p><strong>Edit:</strong>
The IDs are precomputed before runtime and come in through an input pipeline as such:</p>
<pre><code>features = tf.io.parse_single_example(
            serialized_example,
            features={ 'featureIDs': tf.io.FixedLenFeature([], tf.string)}
</code></pre>
<p>They are then reshaped into the previous format:</p>
<pre><code>feature_ids_raw = tf.decode_raw(features['featureIDs'], tf.int32)
feature_ids_shape = tf.stack([batch_size, (num_neighbours * 4)])
feature_ids = tf.reshape(feature_ids_raw, feature_ids_shape)
feature_ids = tf.expand_dims(feature_ids, 0)
</code></pre>
<p>Afterwards they have the previously mentioned shape (<code>batch_size = 1</code> and <code>num_neighbours = 30</code> -&gt; <code>[1,1,120]</code>) and I want to use them to slice the <code>activations</code> tensor.</p>
<p><strong>Edit2:</strong> I would like the output to be <code>[1,120,4]</code>. (So I would like to gather the entries along the second dimension of the <code>activations</code> tensor in accordance with the IDs stored in my <code>ids</code> tensor.)</p>
",tf.gather,tf.gather,2020-09-26 18:48:20,"<blockquote>
<p><code>tf.gather</code> Gather slices from <code>params</code> axis <code>axis</code> according to indices.</p>
</blockquote>
<p>Granted that the documentation is not the most expressive, and the emphasis should be placed on the <strong>slices</strong> (since you index slices from the <code>axis</code> and not elements, which is what I suppose you mistakenly took it for).</p>
<p><strong>Let's take a much smaller example:</strong></p>
<pre class=""lang-py prettyprint-override""><code>activations_small = tf.convert_to_tensor([[[1, 2, 3, 4], [11, 22, 33, 44]]])
print(activations_small.shape) # [1, 2, 4]
</code></pre>
<p>Let's picture this tensor:</p>
<pre><code>    XX 4  XX 44 XX XX
  XX  3 XX  33 X  XX
XXX 2 XX   22XX  XX
X-----X-----+X  XX
|  1  |  11 | XX
+-----+-----+X
</code></pre>
<p><code>tf.gather(activations1, [0, 0], axis=1)</code> will return</p>
<pre><code>&lt;tf.Tensor: shape=(1, 2, 4), dtype=int32, numpy=
array([[[1, 2, 3, 4],
        [1, 2, 3, 4]]], dtype=int32)&gt;
</code></pre>
<p>What <code>tf.gather</code> did was to <em>look from</em> axis 1, and picks up index 0 (ofc, two times i.e. <code>[0, 0]</code>). If you were to run <code>tf.gather(activations1, [0, 0, 0, 0, 0], axis=1).shape</code>, you'd get <code>TensorShape([1, 5, 4])</code>.</p>
<p><strong>Your Error</strong>
Now let's try to trigger the error that you're getting.</p>
<p><code>tf.gather(activations1, [0, 2], axis=1)</code></p>
<blockquote>
<p>InvalidArgumentError: indices[1] = 2 is not in [0, 2) [Op:GatherV2]</p>
</blockquote>
<p>What happened here was that when <code>tf.gather</code> looks from axis 1 perspective, there's no item (column if you will) with index = 2.</p>
<p>I guess this is what the <a href=""https://www.tensorflow.org/api_docs/python/tf/gather#args"" rel=""nofollow noreferrer"">documentation</a> is hinting at by</p>
<blockquote>
<p><code>param:&lt;indices&gt;</code> The index Tensor. Must be one of the following types: int32, int64. Must be in range [0, params.shape[axis]).</p>
</blockquote>
<p><strong>Your (potential) solution</strong></p>
<p>From the dimensions of <code>indices</code>, and that of the expected result from your question, I am not sure if the above was very obvious to you.</p>
<p><code>tf.gather(activations, indices=[0, 1, 2, 3], axis=2)</code> or anything with indices within the range of indices in <code>[0, activations.shape[2])</code> i.e. <code>[0, 4)</code> would work. Anything else would give you the error that you're getting.</p>
<p>There's a verbatim answer below in case that's your expected result.</p>
",8183516,443,https://stackoverflow.com/questions/64081367,Documentation Ambiguity
63919438,TensorFlow keras model fit() parameters steps_per_epoch and epochs behavior on train set,"<p>I'm using a tf.data dataset containing my training data consisting of (lets say) 100k images.
I'm also using a tf.data dataset containing my validation set.
Since an epoch of all 100k images takes quite long (in my case approximately one hour) before I get any feedback on performance on the validation set, I set the <code>steps_per_epoch</code> parameter in tf.keras.Model <code>fit()</code> to <code>10000</code>.
Using a batch size of 1 this results into having 10 validation scores when reaching 100k of images.
In order to complete one epoch of 100k images of my entire training dataset, I set the <code>epochs</code> parameter to <code>10</code></p>
<p>However, I'm not sure if using <code>steps_per_epoch</code> and <code>epochs</code> this way has any other consequences. Is it correct to use these parameters in order to get more frequent feedback on performance?
And also a more specific question, does it use all 100k images or does it use the same first 10k images of my training set at every 'epoch'?
I already dug into the <a href=""https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">TensorFlow docs</a> and read several different stack overflow questions, but I couldn't find anything conclusive to answer my own question. Hope you can help!</p>
<p>Tensorflow version I'm using is 2.2.0.</p>
",tf.keras.Model,tf.keras.Model,2020-09-16 11:49:04,"<blockquote>
<p>Is it correct to use these parameters in order to get more frequent
feedback on performance?</p>
</blockquote>
<p>Yes, it is correct to use these parameters. Here is the code that i used to fit the model.</p>
<pre><code>model.fit(
train_data,
steps_per_epoch = train_samples//batch_size,
epochs = epochs,
validation_data = test_data,
verbose = 1,
validation_steps = test_samples//batch_size)
</code></pre>
<blockquote>
<p>does it use all 100k images or does it use the same first 10k images of my
training set at every 'epoch'?</p>
</blockquote>
<p>It use all images in your training data.</p>
<p>For better understanding <code>Epoch</code> is the number times the learning algorithm will work through the entire training data set.</p>
<p>Where as <code>steps_per_epoch</code> is the total number of samples in your training data set divided by the batch size.</p>
<p>For example, if you have 100000 training samples and use a batch size of 100, one epoch will be equivalent to 1000 steps_per_epoch.</p>
<p><em>Note: We generally observe batch size to be the power of 2, this is because of the effective work of optimized matrix operation libraries.</em></p>
",3908025,589,https://stackoverflow.com/questions/63919438,Inadequate Examples
63851431,How to Augment the Training Set using the tf.keras.utils.Sequence API?,"<p>TensorFlow documentation have the following example that can illustrate how to create a batch generator to feed a training set in batches to a model when the training set is too large to fit in memory:</p>
<pre class=""lang-py prettyprint-override""><code>from skimage.io import imread
from skimage.transform import resize
import tensorflow as tf
import numpy as np
import math

# Here, `x_set` is list of path to the images
# and `y_set` are the associated classes.

class CIFAR10Sequence(tf.keras.utils.Sequence):

    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        return np.array([
            resize(imread(file_name), (200, 200))
               for file_name in batch_x]), np.array(batch_y)
</code></pre>
<p>My intention is to further increase the diversity of the training set by rotating each image 3x by 90. In each Epoch of the training process, the model would first be fed with the &quot;0 training set&quot; and next with the 90, 180 and 270 rotating sets, respectively.</p>
<p>How can I modify the previous piece of code to perform this operation inside the <code>CIFAR10Sequence()</code> data generator?</p>
<p>Please don't use <code>tf.keras.preprocessing.image.ImageDataGenerator()</code> so that the answer does not lose its generality for another type of similar problems that are of a different nature.</p>
<p>NB: The idea would be to create the new data &quot;in real time&quot; as the model is fed instead of creating (in advance) and storing on disk a new and augmented training set bigger than the original one to be used later (also in batches) during the training process of the model.</p>
<p>Thx in advance</p>
",-,-,2020-09-11 17:04:51,"<p>Use custom <code>Callback</code> and hook into <code>on_epoch_end</code>. After each epoch end change the angle of the data iterator object.</p>
<h3>Sample  (documented inline)</h3>
<pre><code>from skimage.io import imread
from skimage.transform import resize, rotate
import numpy as np

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras.utils import Sequence 
from keras.models import Sequential
from keras.layers import Conv2D, Activation, Flatten, Dense

# Model architecture  (dummy)
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(15, 15, 4)))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(1))
model.add(Activation('sigmoid'))
model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# Data iterator 
class CIFAR10Sequence(Sequence):
    def __init__(self, filenames, labels, batch_size):
        self.filenames, self.labels = filenames, labels
        self.batch_size = batch_size
        self.angles = [0,90,180,270]
        self.current_angle_idx = 0

    # Method to loop throught the available angles
    def change_angle(self):
      self.current_angle_idx += 1
      if self.current_angle_idx &gt;= len(self.angles):
        self.current_angle_idx = 0
  
    def __len__(self):
        return int(np.ceil(len(self.filenames) / float(self.batch_size)))

    # read, resize and rotate the image and return a batch of images
    def __getitem__(self, idx):
        angle = self.angles[self.current_angle_idx]
        print (f&quot;Rotating Angle: {angle}&quot;)

        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]
        return np.array([
            rotate(resize(imread(filename), (15, 15)), angle)
               for filename in batch_x]), np.array(batch_y)

# Custom call back to hook into on epoch end
class CustomCallback(keras.callbacks.Callback):
    def __init__(self, sequence):
      self.sequence = sequence

    # after end of each epoch change the rotation for next epoch
    def on_epoch_end(self, epoch, logs=None):
      self.sequence.change_angle()               


# Create data reader
sequence = CIFAR10Sequence([&quot;f1.PNG&quot;]*10, [0, 1]*5, 8)
# fit the model and hook in the custom call back
model.fit(sequence, epochs=10, callbacks=[CustomCallback(sequence)])
</code></pre>
<p>Output:</p>
<pre><code>Rotating Angle: 0
Epoch 1/10
Rotating Angle: 0
Rotating Angle: 0
2/2 [==============================] - 2s 755ms/step - loss: 1.0153 - accuracy: 0.5000
Epoch 2/10
Rotating Angle: 90
Rotating Angle: 90
2/2 [==============================] - 0s 190ms/step - loss: 0.6975 - accuracy: 0.5000
Epoch 3/10
Rotating Angle: 180
Rotating Angle: 180
2/2 [==============================] - 2s 772ms/step - loss: 0.6931 - accuracy: 0.5000
Epoch 4/10
Rotating Angle: 270
Rotating Angle: 270
2/2 [==============================] - 0s 197ms/step - loss: 0.6931 - accuracy: 0.5000
Epoch 5/10
Rotating Angle: 0
Rotating Angle: 0
2/2 [==============================] - 0s 189ms/step - loss: 0.6931 - accuracy: 0.5000
Epoch 6/10
Rotating Angle: 90
Rotating Angle: 90
2/2 [==============================] - 2s 757ms/step - loss: 0.6932 - accuracy: 0.5000
Epoch 7/10
Rotating Angle: 180
Rotating Angle: 180
2/2 [==============================] - 2s 757ms/step - loss: 0.6931 - accuracy: 0.5000
Epoch 8/10
Rotating Angle: 270
Rotating Angle: 270
2/2 [==============================] - 2s 761ms/step - loss: 0.6932 - accuracy: 0.5000
Epoch 9/10
Rotating Angle: 0
Rotating Angle: 0
2/2 [==============================] - 1s 744ms/step - loss: 0.6932 - accuracy: 0.5000
Epoch 10/10
Rotating Angle: 90
Rotating Angle: 90
2/2 [==============================] - 0s 192ms/step - loss: 0.6931 - accuracy: 0.5000
&lt;tensorflow.python.keras.callbacks.History at 0x7fcbdf8bcdd8&gt;
</code></pre>
<pre><code></code></pre>
",14230555,7,https://stackoverflow.com/questions/63851431,Documentation Replication on Other Examples
63715707,Does image_dataset_from_directory load all the images into memory at once?,"<p>I'm new to machine learning, and I am trying to create an image classifier, I want to load the dataset, but I want to do it in a way such that it does not take up all of my memory. Reading the tensorflow documentation, it says that iteration of a dataset happens in streaming fashion, and I am wondering if tf.keras.preprocessing.image_dataset_from_directory will load the images at once or &quot;stream&quot; it a batch at a time. If not I was thinking of making a generator to read file names one at a time and load them when the batches are ready with keras.utils.Sequence.</p>
",tf.keras.preprocessing.image_dataset_from_directory,tf.keras.utils.image_dataset_from_directory,2020-09-03 1:55:37,"<pre><code>tf.keras.preprocessing.image_dataset_from_directory(
    directory, labels='inferred', label_mode='int', class_names=None,
    color_mode='rgb', batch_size=32, image_size=(256, 256), shuffle=True, seed=None,
    validation_split=None, subset=None, interpolation='bilinear', follow_links=False
)
</code></pre>
<p>If you define batch size it will generate data <code>according to batch size</code> otherwise <code>default batch size is 32</code>. <strong>It is never possible to load the whole data in a single batch in normal computer.</strong> For more details read <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer"">documentation</a>.</p>
",10171841,669,https://stackoverflow.com/questions/63715707,Documentation Replication on Other Examples
63146831,What is the analytic interpretation for Tensorflow custom gradient?,"<p>In the official <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">tf.custom_gradient</a> documentation it shows how to define custom gradients for <code>log(1 + exp(x))</code></p>
<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient
def log1pexp(x):
  e = tf.exp(x)
  def grad(dy):
    return dy * (1 - 1 / (1 + e))
  return tf.math.log(1 + e), grad
</code></pre>
<p>When <code>y = log(1 + exp(x))</code>, analytically the derivative comes out to be <code>dy/dx = (1 - 1 / (1 + exp(x)))</code>.</p>
<p>However in the code <code>def grad</code> says its <code>dy * (1 - 1 / (1 + exp(x)))</code>.
<code>dy/dx = dy * (1 - 1 / (1 + exp(x)))</code> is not a valid equation. While <code>dx = dy * (1 - 1 / (1 + exp(x)))</code> is wrong as it should be the reciprocal.</p>
<p>What does the <code>grad</code> function equate to?</p>
",tf.custom_gradient,tf.custom_gradient,2020-07-29 5:26:15,"<p>I finally figured it out. The <code>dy</code> should be called <code>upstream_gradient</code> or <code>upstream_dy_dx</code>.</p>
<p>By chain rule we know that</p>
<p><a href=""https://i.stack.imgur.com/7g3aZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7g3aZ.png"" alt=""chain rule"" /></a></p>
<p>where <code>dx[i]/dx[i+1]</code> is the gradient of the current function.</p>
<p>So <code>dy</code> is the product of all the gradients upstream before this function.</p>
<p><a href=""https://i.stack.imgur.com/nu4Z8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nu4Z8.png"" alt=""enter image description here"" /></a></p>
<p>So, if you forget to multiply the <code>dy</code> it is effectively the same as <a href=""https://www.tensorflow.org/api_docs/python/tf/stop_gradient"" rel=""nofollow noreferrer"">tf.stop_gradient</a></p>
<p>Here is a code which demos this. Full notebook <a href=""https://github.com/Ghost---Shadow/differentiable-programming-handbook/blob/master/notebooks/custom-gradient.ipynb"" rel=""nofollow noreferrer"">here</a></p>
<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient
def foo(x):
    tf.debugging.assert_rank(x, 0)

    def grad(dy_dx_upstream):
        dy_dx = 2 * x
        dy_dx_downstream = dy_dx * dy_dx_upstream
        tf.print(f'x={x}\tupstream={dy_dx_upstream}\tcurrent={dy_dx}\t\tdownstream={dy_dx_downstream}')
        return dy_dx_downstream
    
    y = x ** 2
    tf.print(f'x={x}\ty={y}')
    
    return y, grad


x = tf.constant(2.0, dtype=tf.float32)

with tf.GradientTape(persistent=True) as tape:
    tape.watch(x)
    y = foo(foo(foo(x))) # y = x ** 8

tf.print(f'\nfinal dy/dx={tape.gradient(y, x)}')
</code></pre>
<p>Output</p>
<pre><code>x=2.0   y=4.0
x=4.0   y=16.0
x=16.0  y=256.0
x=16.0  upstream=1.0    current=32.0        downstream=32.0
x=4.0   upstream=32.0   current=8.0     downstream=256.0
x=2.0   upstream=256.0  current=4.0     downstream=1024.0

final dy/dx=1024.0
</code></pre>
",1217998,3176,https://stackoverflow.com/questions/63146831,Documentation Replication on Other Examples
63004540,How to pad 1 dimensinal vector in tensorflow? Getting InvalidArgumentError: paddings must be a matrix with 2 columns with tf.pad,"<p>I am trying to use tf.pad. Here is my attempt to pad the tensor to length 20, with values 10.</p>
<pre><code>tf.pad(tf.constant([1, 2, 3, 45]), paddings=20, constant_values=10)
</code></pre>
<p>I get this error message</p>
<pre><code>InvalidArgumentError: paddings must be a matrix with 2 columns: [2,1] [Op:PadV2]
</code></pre>
<p>I am looking at the documentation</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/pad"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/pad</a></p>
<blockquote>
<p>paddings is an integer tensor with shape [n, 2], where n is the rank of tensor. For each dimension D of input, paddings[D, 0] indicates how many values to add before the contents of tensor in that dimension, and paddings[D, 1] indicates how many values to add after the contents of tensor in that dimension</p>
</blockquote>
<p>But I am unable to figure out how to shape the pad value</p>
",tf.pad,tf.pad,2020-07-20 22:12:17,"<p>You have to specify the padding at the beginning and the padding at the end of your vector by matrix of shape (1,2) :</p>
<pre><code>tf.pad(tf.constant([1, 2, 3, 45]), [[ 0 , 20]], constant_values=10)
</code></pre>
<p>if you have three-dimensional tensor (rank = 3 e.g : (225,225,3) ) the padding matrix has to be of shape (3, 2 ) where &quot;3&quot; is the rank, and &quot;2&quot; to specify the padding at the beginning and end of each dimension.</p>
<p>For example, a padding matrix  = [ [0,2], [5,5], [2,0] ], means that we want to pad the first dimension by 0 at the beginning (=no padding) and 2 at the end .padding the second dimension by 5 at beginning and 5 at the end.</p>
",3259896,5853,https://stackoverflow.com/questions/63004540,Documentation Replicability
62962147,TensorFlow - Fashion MNIST Steps Per Epoch,"<p>I'm working with the Kera's Fashion MNIST dataset. When I fit my model, I noticed to complete one epoch it would have to go through 1500 steps.</p>
<pre><code>history = model.fit(x_train, y_train, epochs=30, validation_split=0.2)

Epoch 3/30
1500/1500 [==============================] - 3s 2ms/step - loss: 0.4494 - sparse_categorical_accuracy: 0.8438 - val_loss: 0.4691 - val_sparse_categorical_accuracy: 0.8308
Epoch 4/30
964/1500 [==================&gt;...........] - ETA: 0s - loss: 0.4294 - sparse_categorical_accuracy: 0.8504
</code></pre>
<p>I was looking at the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">docs</a> for the fit function, but couldn't understand why the default steps were set to 1500. I understand when the <code>steps_per_epoch</code> is <code>None</code> the behavior is dependent on the data type of the dataset, but how can I check if the data type is a tensor or tf.data?</p>
",tf.keras.Model,tf.keras.Model,2020-07-17 21:43:59,"<p>The number of steps per epoch is equal to <code>ceil(samples / batch_size)</code>. The default batch size in <code>model.fit</code> is 32 (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">documentation</a>). If the MNIST training data has 60000 samples, then each epoch would take 60000 / 32 = 1875 steps.</p>
<p><code>model.fit</code> also supports splitting your data into training and validation sets. You have done this with <code>validation_split=0.2</code>, so only 80% of the samples are part of the training set (20% are for validation). The new calculation would be 0.8 * 60000 / 32 = 1500. This is why you see 1500 steps per epoch.</p>
",6179818,2563,https://stackoverflow.com/questions/62962147,Documentation Replication on Other Examples
62877768,Input shape of tf.data.Dataset not accepted by model.fit(),"<p>I would like to feed with data my model by applying a <code>tf.data.Dataset</code>.</p>
<p>Having checked the documentation of TF 2.0 I found that the <code>.fit()</code> function (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit</a>) accepts:</p>
<blockquote>
<p>x - A tf.data dataset. Should return a tuple of either (inputs, targets)
or (inputs, targets, sample_weights).</p>
</blockquote>
<p>So, I wrote the following minial proof of concept code:</p>
<pre><code>from sklearn.datasets import make_blobs
import tensorflow as tf
from tensorflow.keras import Model, Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.metrics import Accuracy, AUC

X, Y = make_blobs(n_samples=500, n_features=2, cluster_std=3.0, random_state=1)

def define_model():
    model = Sequential()
    model.add(Dense(units=1, activation=&quot;sigmoid&quot;, input_shape=(2,)))
    model.compile(optimizer=&quot;adam&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[AUC(), Accuracy()])
    return model

model = define_model()

X_ds = tf.data.Dataset.from_tensor_slices(X)
Y_ds = tf.data.Dataset.from_tensor_slices(Y)
dataset = tf.data.Dataset.zip((X_ds, Y_ds))

for elem in dataset.take(1):
    print(type(elem))
    print(elem)

model.fit(x=dataset) #&lt;-- does not work
#model.fit(x=X, y=Y) &lt;-- does work without any problems....
</code></pre>
<p>As mentioned in the second comment, the code that does not apply a <code>tf.data.Dataset</code> works fine.</p>
<p>However, when applying the Dataset object I get the following error message:</p>
<pre><code>&lt;class 'tuple'&gt;
(&lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([-10.42729974,  -0.85439721])&gt;, &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;)
... other output here...
ValueError: Error when checking input: expected dense_19_input to have
shape (2,) but got array with shape (1,)
</code></pre>
<p>From my understanding of the documentation, the dataset I have constructed should be exactly the tuple object the fit method expects.</p>
<p>I do not understand this error message.</p>
<p>What am I doing wrong here?</p>
",tf.keras.Model,tf.keras.Model,2020-07-13 14:14:11,"<p>When you pass a dataset to <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""noreferrer""><code>fit</code></a>, it is expected that it will directly generate batches, not individual examples. You just need to batch your dataset before training.</p>
<pre class=""lang-py prettyprint-override""><code>dataset = dataset.batch(batch_size)
model.fit(x=dataset)
</code></pre>
",1020704,13036,https://stackoverflow.com/questions/62877768,Documentation Ambiguity
62850250,Understanding the input_shape parameter of hub.KerasLayer,"<p>When transfer learning is done, one could use a model from the tf hub. Like MobilNetV2 or Inception. These models expects the inputs, the images in a certain size. So one has to resize the images into this size before applying the models. In this <a href=""https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub"" rel=""nofollow noreferrer"">tutorial</a> the following is used:</p>
<pre><code>feature_extractor_url = &quot;https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2&quot; 

feature_extractor_layer = hub.KerasLayer(feature_extractor_url,
                                         input_shape=(224,224,3))
</code></pre>
<p>In this example the images were already resized to 224,224 before. I am wondering about the <code>input_shape=(224,224,3)</code>. In this <a href=""https://www.tensorflow.org/tutorials/images/transfer_learning"" rel=""nofollow noreferrer"">tutorial</a> the pretrained model is not loaded with the hub-KerasLayer, but instead using</p>
<pre><code>base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
</code></pre>
<p>Where IMG_SHAPE is</p>
<pre><code>IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)
</code></pre>
<p>and img_size is 160. So here the input_shape is input_shape=(160,160,3).</p>
<p>Now coming back to the:</p>
<pre><code>feature_extractor_layer = hub.KerasLayer(feature_extractor_url,
                                         input_shape=(224,224,3))
</code></pre>
<p>I was wondering what exactly the input_shape parameter  tells me or does? So I do not need to enter 224,224 here, right? I could enter another size, like 160, because my images were resized to this size? So MobilNetV2 does expect 224,224, but with this option I can specify something else? For <code>tf.keras.applications.MobileNetV2</code> I found the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2"" rel=""nofollow noreferrer"">documentation</a> where it exactly explains it:</p>
<blockquote>
<p>Optional shape tuple, to be specified if you would like to use a model
with an input image resolution that is not (224, 224, 3). It should
have exactly 3 inputs channels (224, 224, 3). You can also omit this
option if you would like to infer input_shape from an input_tensor. If
you choose to include both input_tensor and input_shape then
input_shape will be used if they match, if the shapes do not match
then we will throw an error. E.g. (160, 160, 3) would be one valid
value.</p>
</blockquote>
<p>So when I resized my images to 300,300 and I want to use MobileNetV2, can I use the following code:</p>
<pre><code> feature_extractor_url = &quot;https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2&quot; 
    
    feature_extractor_layer = hub.KerasLayer(feature_extractor_url,
                                             input_shape=(300,300,3))
</code></pre>
<p>Or do I have to resize to 224,224 and enter the 224,224 here?</p>
<p>When I check an <a href=""https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l06c03_exercise_flowers_with_transfer_learning_solution.ipynb#scrollTo=wVII2H9ZNNQf"" rel=""nofollow noreferrer"">implementation</a> for inception the images are resized to 299,299 and then the following code is used:</p>
<pre><code>IMAGE_RES = 299

feature_extractor = hub.KerasLayer(URL,
  input_shape=(IMAGE_RES, IMAGE_RES, 3),
  trainable=False)
</code></pre>
<p>Is it necessary to do this exactly to 299? Or could I also resize to another size, like 250 and give this as an input:</p>
<pre><code>   IMAGE_RES = 250

feature_extractor = hub.KerasLayer(URL,
  input_shape=(IMAGE_RES, IMAGE_RES, 3),
  trainable=False)
</code></pre>
<p>So the pretrained models do expect a certain fixed size and this input_shape parameter exists in order to make it flexible in case the user wants to use another size, right? But then why all these examples resize to exactly the size the models assume? I could also have done this to another size, right? So in all the examples it says like the models expects this and I understand it in the way that therefore we do have to resize to exactly what the model expects. But the input_shape parameter is exactly existing for this to make it flexible so that I do not have to resize to exactly what the model expects, but instead just resize to whatever I want and with the input_shape parameter I tell this to the model? As in the mentioned example with 160 image size. Or is this just possible in case I use <code>tf.keras.applications.MobileNetV2</code> loading the pretrained models, but when using <code>hub.KerasLayer</code> I cannot do it?</p>
",tf.keras.applications.mobilenet_v2.MobileNetV2,tf.keras.applications.mobilenet_v2.MobileNetV2,2020-07-11 14:13:10,"<p>This is a good observation.</p>
<p><strong>TLDR</strong>, different <code>Input Shapes</code> can be passed for <code>Models</code> of <code>tf.keras.applications</code> with the argument, <code>include_top = False</code> but that is not possible when we use <code>tf.keras.applications</code> with the argument, <code>include_top = True</code> and when we use <code>Models</code> of <code>Tensorflow Hub</code>.</p>
<p><strong>Detailed Explanation</strong>:</p>
<p>This <a href=""https://www.tensorflow.org/hub/common_signatures/images#image_input"" rel=""nofollow noreferrer"">Tensorflow Hub Documentation</a> states</p>
<pre><code>&gt; The height and width dimensions are fixed to the expected size of
&gt; input images. (Future work may remove that restriction for fully
&gt; convolutional modules.)
</code></pre>
<p>That's the reason, if we pass the <code>Image Shape</code> other than the Expected Shape, it raises an error,</p>
<pre><code> Expected these arguments to match one of the following 4 option(s):
    
    Option 1:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')
        * True
        * False
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}
    
    Option 2:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')
        * True
        * True
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}
    
    Option 3:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')
        * False
        * True
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}
    
    Option 4:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')
        * False
        * False
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}
</code></pre>
<p>Similarly, when we pass different <code>Input Shape</code> while using the <code>Pre-Trained Models</code> of <code>tf.keras.applications</code> with the argument, <strong><code>include_top = True</code></strong> (including the Dense Layers at the Top as well), it raises an error,</p>
<pre><code>ValueError: When setting `include_top=True` and loading `imagenet` 
weights, `input_shape` should be (224, 224, 3).
</code></pre>
<p>But if we set the value of argument, <strong><code>include_top = False</code></strong> while using the <code>Pre-Trained Models</code> from <code>tf.keras.applications</code>, the <code>Input_Shape</code> can be <strong>flexible</strong> i.e., for MobileNetV2, we can pass any of the shapes from the list, <code>[96, 128, 160, 192, 224]</code>) and for Models like <code>ResNet</code> or <code>VGGNet</code>, we can pass any <code>Input Shape</code>.</p>
",2165335,833,https://stackoverflow.com/questions/62850250,Documentation Ambiguity
62752605,Loss function in tf.nn.sampled_softmax_loss,"<p>I have a question regarding Tensorflow:</p>
<p>Which loss function is used in <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""nofollow noreferrer""><code>tf.nn.sampled_softmax_loss</code></a>?</p>
<p>I believe it's <em><strong>cross-entropy</strong></em>, but it is not written on the official website. Can anyone confirm my guess?</p>
",tf.nn.sampled_softmax_loss,tf.nn.sampled_softmax_loss,2020-07-06 9:01:18,"<p>Based on <a href=""https://stackoverflow.com/questions/35241251/in-tensorflow-what-is-the-difference-between-sampled-softmax-loss-and-softmax-c"">this other question</a>, it looks like it is cross entropy.</p>
<p>Besides, the main difference between <code>sampled_softmax_loss</code> and <code>softmax_cross_entropy_with_logits</code> (the standard cross_entropy loss in TF) is that the first only takes into account a subset V of your vocabulary to calculate your loss, while the second takes into account your entire vocabulary.</p>
",13874745,393,https://stackoverflow.com/questions/62752605,Documentation Replicability
62670041,batch_size in tf model.fit() vs. batch_size in tf.data.Dataset,"<p>I have a large dataset that can fit in host memory. However, when I use tf.keras to train the model, it yields GPU out-of-memory problem. Then I look into tf.data.Dataset and want to use its batch() method to batch the training dataset so that it can execute the model.fit() in GPU. According to its documentation, an example is as follows:</p>
<pre><code>train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))
test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))

BATCH_SIZE = 64
SHUFFLE_BUFFER_SIZE = 100

train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)
</code></pre>
<p>Is the BATCH_SIZE in dataset.from_tensor_slices().batch() the same as the batch_size in the tf.keras modelt.fit()?</p>
<p>How should I choose BATCH_SIZE so that GPU has sufficient data to run efficiently and yet its memory is not overflown?</p>
",-,-,2020-07-01 5:04:38,"<p>You do not need to pass the <code>batch_size</code> parameter in <code>model.fit()</code> in this case. It will automatically use the BATCH_SIZE that you use in <code>tf.data.Dataset().batch()</code>.</p>
<p>As for your other question : the batch size hyperparameter indeed needs to be carefully tuned. On the other hand, if you see OOM errors, you should decrease it until you do not get OOM (normally (but not necessarily) in this manner 32 --&gt; 16 --&gt; 8 ...). In fact you can try non-power of two batch sizes for the decrease purposes.</p>
<p>In your case I would start with a batch_size of 2 an increase it gradually (<code>3-4-5-6...</code>).</p>
<p>You do not need to provide the <code>batch_size</code> parameter if you use the <code>tf.data.Dataset().batch()</code> method.</p>
<p>In fact, even the official <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">documentation</a> states this:</p>
<blockquote>
<p>batch_size : Integer or None. Number of samples per gradient update.
If unspecified, batch_size will default to 32. Do not specify the
batch_size if your data is in the form of datasets, generators, or
keras.utils.Sequence instances (since they generate batches).</p>
</blockquote>
",6227592,1185,https://stackoverflow.com/questions/62670041,Documentation Replication on Other Examples
62249084,What is the numpy equivalent of TensorFlow Xavier initializer for CNN?,"<p>I would like to re-create the Xavier initialization in NumPy (using basic functions) in the same way that TensorFlow2 does for CNN. 
Here is how I learned to do Xavier initialization in NumPy:</p>

<pre><code># weights.shape = (2,2)
np.random.seed(0)
nodes_in = 2*2
weights = np.random.rand(2,2) * np.sqrt(1/nodes_in)

&gt;&gt;&gt;array([[0.27440675, 0.35759468],
          [0.30138169, 0.27244159]])
</code></pre>

<p>This is the way I learned Xavier initialization for the logistic regression model. It seems that for Convolution Neural Network it should be different but I don't know how.</p>

<pre><code>initializer = tf.initializers.GlorotUniform(seed=0)
tf.Variable(initializer(shape=[2,2],dtype=tf.float32))

&gt;&gt;&gt;&lt;tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=
   array([[-0.7078647 ,  0.50461936],
          [ 0.73500216,  0.6633029 ]], dtype=float32)&gt;
</code></pre>

<p>I'm confused by the TensorFlow <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform"" rel=""noreferrer"">documentation</a> when they explain the ""fan_in"" and ""fan_out"". I'm guessing this is where the problem is. Can somebody dumb it down for me, please? </p>

<p>Much appreciate it!</p>

<p><em>[UPDATE]:</em></p>

<p>When I follow the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform"" rel=""noreferrer"">tf.keras.initializers.GlorotUniform</a> documentation I still don't come to the same results:</p>

<pre><code># weights.shape = (2,2)
np.random.seed(0)
fan_in = 2*2
fan_out = 2*2
limit = np.sqrt(6/(fan_in + fan_out))
np.random.uniform(-limit,limit,size=(2,2))
&gt;&gt;&gt;array([[0.08454747, 0.37271892],
          [0.17799139, 0.07773995]])
</code></pre>
",tf.keras.initializers.GlorotUniform,tf.keras.initializers.GlorotUniform,2020-06-07 17:25:25,"<p><strong>Using Tensorflow</strong></p>

<pre><code>initializer = tf.initializers.GlorotUniform(seed=0)
tf.Variable(initializer(shape=[2,2],dtype=tf.float32))
&lt;tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=
array([[-0.7078647 ,  0.50461936],
       [ 0.73500216,  0.6633029 ]], dtype=float32)&gt;
</code></pre>

<p><strong>Same logic in Numpy</strong></p>

<pre><code>import math
np.random.seed(0)
scale = 1/max(1., (2+2)/2.)
limit = math.sqrt(3.0 * scale)
weights = np.random.uniform(-limit, limit, size=(2,2))
print(weights)
array([[0.11956818, 0.52710415],
       [0.25171784, 0.1099409 ]])
</code></pre>

<p>If you observe, the above two are not the same because of random number generators. Internally tensorflow uses the stateless random generator as below and if you observe, we got the same output. </p>

<pre><code>tf.random.stateless_uniform(shape=(2,2),seed=[0, 0], minval=-limit, maxval=limit)
&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=
array([[-0.7078647 ,  0.50461936],
       [ 0.73500216,  0.6633029 ]], dtype=float32)&gt;
</code></pre>

<p>If you need to know more about internal implementation, you can check <a href=""https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/init_ops_v2.py#L525"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/init_ops_v2.py#L525</a></p>
",5040482,115,https://stackoverflow.com/questions/62249084,Documentation Replication on Other Examples
62223016,Single Prediction Image doesn't need to be rescaled?,"<p>I followed a tutorial to make my first Convolutional Neural Network using Keras and I have a small question regarding the rescaling step.</p>

<p>So when we are importing the training set and test set, we create an instance of  the <code>tf.keras.preprocessing.image.ImageDataGenerator</code> class and use it as:</p>

<pre class=""lang-py prettyprint-override""><code>train_datagen = ImageDataGenerator(rescale=1/255)
</code></pre>

<p>Along with some other augmentation parameters. My understanding is that we use the <code>rescale</code> parameter to normalize the pixel values of the images imported.</p>

<p>But when we load up a single image to run through the CNN, we write something like (code from keras docs):</p>

<pre class=""lang-py prettyprint-override""><code>image = tf.keras.preprocessing.image.load_img(image_path)
input_arr = keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr])  # Convert single image to a batch.
predictions = model.predict(input_arr)
</code></pre>

<p>My question is, I cannot see the single input image being <code>rescaled</code> anywhere. Is it being done implicitly, or is there no need to actually perform rescaling? If the latter, then why is it so?</p>

<p>Thanks!</p>
",-,-,2020-06-05 19:40:28,"<p>The image should be normalized that it should be divided by 255, if it's done during the training. Network will not be able to interpret that.</p>

<p>Also, when we use test_datagen, we apply Rescaling by 1/255 for the predict generator. </p>

<p>Normalization, mean subtraction and std deviation needs to be done at the testing time, if that has been applied during the training stage.</p>
",11319137,476,https://stackoverflow.com/questions/62223016,Documentation Replicability
61988657,Why does tensorflow.rank always return shape with null value,"<p>Being a beginner to TensorFlow <strong>I couldn't get why does tensorflow.rank always return shape with null value?</strong></p>

<p><strong>This is what I am working on:</strong></p>

<pre><code>import tensorflow as tf
%tensorflow_version 2.x

list_2d = [[1,2,3,4],
             [5,6,7,8],
             [9,10,11,12]
]
tensor_2d = tf.Variable(list_2d)

print(tensor_2d.shape)
print(tf.rank(tensor_2d))
</code></pre>

<p><strong>and the output is</strong> </p>

<pre><code>(3, 4)
tf.Tensor(2, shape=(), dtype=int32)
</code></pre>

<p>So <strong>my question is what is this <code>shape=()</code> from <code>tf.rank</code> output</strong>?</p>

<p>I couldn't get much from here - <a href=""https://www.tensorflow.org/api_docs/python/tf/rank"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/rank</a></p>
",tf.rank,tf.rank,2020-05-24 16:06:16,"<p>It's because the output of <code>tf.rank()</code> is a tensor itself. Instead of returning the rank as an integer, the output is a tensor with a single int32 value that represents the rank of the given input tensor. The shape <code>()</code> is the shape of the output value, not the input tensor (single value tensors have shape <code>()</code>).</p>
",5176364,5151,https://stackoverflow.com/questions/61988657,Documentation Replicability
61885570,Reading a tfrecord: DecodeError: Error parsing message,"<p>I am using colab to run a <a href=""https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/handling_sparse_features.ipynb"" rel=""nofollow noreferrer"">tutorial</a> on tensorflow ranking. It uses wget to fetch the tfrecord:</p>

<pre><code>!wget -O ""/tmp/train.tfrecords"" ""http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/ELWC/train.tfrecords""
</code></pre>

<p>I am using this code to try to look at the structure of the tfrecord:</p>

<pre><code>for example in tf.compat.v1.python_io.tf_record_iterator(""/tmp/train.tfrecords""):
    print(tf.train.Example.FromString(example))
    break
</code></pre>

<p>And I am getting:</p>

<pre><code>DecodeError: Error parsing message
</code></pre>

<p>How to generally look at the structure of tfrecords instead?</p>

<p>A second question: Where to find documentation on classes like <code>tf.train.Example</code>? I just find this <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Example"" rel=""nofollow noreferrer"">empty page</a>.</p>
",tf.train.Example,tf.train.Example,2020-05-19 7:34:24,"<p>The insight of the problem is that the records are serialized using another schema: the <code>ExampleListWithContext</code> Schema, instead of the basic <code>tf.train.Example</code> schema. Updating the right deserialization solves the problem.</p>

<pre><code>filenames = ['/tmp/train.tfrecords']
raw_dataset = tf.data.TFRecordDataset(filenames)
for e in raw_dataset.take(1):
    ELWC = input_pb2.ExampleListWithContext()
    v = ELWC.FromString(e.numpy())
    print(v.context)
    for e in v.examples:
        print(e)
</code></pre>

<p>outputs:</p>

<pre><code>features {
  feature {
    key: ""query""
    value {
      bytes_list {
        value: ""why do ...""
      }
    }
  }
  feature {
    key: ""query_bert_encoder_outputs""
    value {
      float_list {
...
}}
</code></pre>
",8183621,605,https://stackoverflow.com/questions/61885570,Requesting (Additional) Documentation/Examples
61767803,Tensorflow 1.x to Tensorflow 2.1.0,"<p>I am trying to update code written in Tensorflow 1.x to code in Tensorflow 2.1.0. I have been converting codes using Tensorflow 2.1.0 documentation, and I had no problems until this code.</p>

<pre><code>loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)
</code></pre>

<p>Above code is Tensorflow 1.x version, and I think, according to Tensorflow 2.1.0 documentation, the properly updated code is </p>

<pre><code>loss = tf.nn.softmax_cross_entropy_with_logits(one_hot_labels, logits)
</code></pre>

<p>Then, when I run</p>

<pre><code>return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)
</code></pre>

<p>I get the following error.</p>

<pre><code>Loss must be scalar, given: Tensor(""softmax_cross_entropy_with_logits/Reshape_2:0"", shape=(512,), dtype=float32)**
</code></pre>

<p>So, I am guessing in Tensorflow 1.x version, the loss was passed as 'tensor' to tf.estimator.EstimatorSpec, but in Tensorflow 2.1.0, the loss has to be passed as <code>scalar</code> to <code>tf.estimator.EstimatorSpec</code>? Loss (the way it is defined here) in both Tensorflow 1.x and 2.1.0 is tensor if I remember it correctly.</p>

<p>So, does anyone know how to convert tensor to scalar (which I don't think will be sufficient nor efficient in building the CNN model) or better yet, how to solve this dilemma?</p>

<p>Or did I convert the original code the wrong way?</p>

<p>I would very much appreciate if compat.v1. is not used unless absolutely necessary (i.e. no other way to use the code in Tensorflow 2.1.0 than compat.v1.)</p>
",-,-,2020-05-13 6:30:32,"<p>You can just average the result (which is what <code>tf.losses.softmax_cross_entropy</code> did anyway through <code>tf.losses.compute_weighted_loss</code>):</p>

<pre class=""lang-py prettyprint-override""><code>loss = tf.math.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(one_hot_labels, logits))
</code></pre>
",12997689,81,https://stackoverflow.com/questions/61767803,Documentation Replication on Other Examples
61743921,can we build object detection model using Tensorflow or it is only possible with the help f tf.keras,"<p>Is there any way to build object detection model using Tensorflow without any help of tf.keras module?</p>

<p>From Tensorflow documentation I'm  not able to find any example which helps to create model without Keras.</p>
",tf.keras,tf.keras,2020-05-12 4:36:22,"<p>Keras is a high level API. But if you want to use only Tensorflow then you have to implement the architecture using low level API. You can certainly implement but you have to code it yourself to build all the convolutional layers and dense layer by yourself. </p>
",1490940,1485,https://stackoverflow.com/questions/61743921,Lack of Alternative Solutions/Documentation
61720708,How do you save a Tensorflow dataset to a file?,"<p>There are at least two more questions like this on SO but not a single one has been answered.</p>

<p>I have a dataset of the form:</p>

<pre><code>&lt;TensorSliceDataset shapes: ((512,), (512,), (512,), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;
</code></pre>

<p>and another of the form:</p>

<pre><code>&lt;BatchDataset shapes: ((None, 512), (None, 512), (None, 512), (None,)), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;
</code></pre>

<p>I have looked and looked but I can't find the code to save these datasets to files that can be loaded later. The closest I got was <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/TFRecordWriter"" rel=""noreferrer"">this page in the TensorFlow docs</a>, which suggests serializing the tensors using <code>tf.io.serialize_tensor</code> and then writing them to a file using <code>tf.data.experimental.TFRecordWriter</code>.</p>

<p>However, when I tried this using the code:</p>

<pre><code>dataset.map(tf.io.serialize_tensor)
writer = tf.data.experimental.TFRecordWriter('mydata.tfrecord')
writer.write(dataset)
</code></pre>

<p>I get an error on the first line:</p>

<blockquote>
  <p>TypeError: serialize_tensor() takes from 1 to 2 positional arguments but 4 were given</p>
</blockquote>

<p>How can I modify the above (or do something else) to accomplish my goal?</p>
",tf.data.experimental.TFRecordWriter,tf.data.experimental.TFRecordWriter,2020-05-11 1:00:29,"<p><code>TFRecordWriter</code> seems to be the most convenient option, but unfortunately it can only write datasets with a single tensor per element. Here are a couple of workarounds you can use. First, since all your tensors have the same type and similar shape, you can concatenate them all into one, and split them back later on load:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

# Write
a = tf.zeros((100, 512), tf.int32)
ds = tf.data.Dataset.from_tensor_slices((a, a, a, a[:, 0]))
print(ds)
# &lt;TensorSliceDataset shapes: ((512,), (512,), (512,), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;
def write_map_fn(x1, x2, x3, x4):
    return tf.io.serialize_tensor(tf.concat([x1, x2, x3, tf.expand_dims(x4, -1)], -1))
ds = ds.map(write_map_fn)
writer = tf.data.experimental.TFRecordWriter('mydata.tfrecord')
writer.write(ds)

# Read
def read_map_fn(x):
    xp = tf.io.parse_tensor(x, tf.int32)
    # Optionally set shape
    xp.set_shape([1537])  # Do `xp.set_shape([None, 1537])` if using batches
    # Use `x[:, :512], ...` if using batches
    return xp[:512], xp[512:1024], xp[1024:1536], xp[-1]
ds = tf.data.TFRecordDataset('mydata.tfrecord').map(read_map_fn)
print(ds)
# &lt;MapDataset shapes: ((512,), (512,), (512,), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;
</code></pre>

<p>But, more generally, you can simply have a separate file per tensor and then read them all:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

# Write
a = tf.zeros((100, 512), tf.int32)
ds = tf.data.Dataset.from_tensor_slices((a, a, a, a[:, 0]))
for i, _ in enumerate(ds.element_spec):
    ds_i = ds.map(lambda *args: args[i]).map(tf.io.serialize_tensor)
    writer = tf.data.experimental.TFRecordWriter(f'mydata.{i}.tfrecord')
    writer.write(ds_i)

# Read
NUM_PARTS = 4
parts = []
def read_map_fn(x):
    return tf.io.parse_tensor(x, tf.int32)
for i in range(NUM_PARTS):
    parts.append(tf.data.TFRecordDataset(f'mydata.{i}.tfrecord').map(read_map_fn))
ds = tf.data.Dataset.zip(tuple(parts))
print(ds)
# &lt;ZipDataset shapes: (&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;
</code></pre>

<p>It is possible to have the whole dataset in a single file with multiple separate tensors per element, namely as a file of TFRecords containing <code>tf.train.Example</code>s, but I don't know if there is a way to create those within TensorFlow, that is, without having to get the data out of the dataset into Python and then write it to the records file.</p>
",424306,1174,https://stackoverflow.com/questions/61720708,Documentation Replication on Other Examples
61305781,Using Tensorflow embedded columns raises All feature_columns must be _FeatureColumn instances error,"<p>I am new to tensorflow and I was trying to follow the official documentation where I came across 
tf.feature_column.categorical_column_with_vocabulary_list</p>

<p>The code I tested is: </p>

<pre><code>key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), default_value=0)
columns = [[tfc.embedding_column(colors, 3)], ...]
features = tf.io.parse_example(..., features=tfc.make_parse_example_spec(columns))
dense_tensor = tfc.input_layer(features, columns)
</code></pre>

<p>However , when I run this sample code I get the following error : 
 ValueError: All feature_columns must be _FeatureColumn instances. Given: [EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), dtype=tf.string, default_value=0, num_oov_buckets=0), dimension=3, combiner='mean', initializer=, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]</p>

<p>What I am doing wrong?  </p>
",tf.feature_column.categorical_column_with_vocabulary_list,tf.feature_column.categorical_column_with_vocabulary_list,2020-04-19 14:17:44,"<p><code>make_parse_example_spec</code> expects <code>FeatureColumn instances</code>. You can create the FeatureColumn instance using the below method for the category list.</p>

<pre><code>colors = feature_column.categorical_column_with_vocabulary_list(key='colors',vocabulary_lis=('R', 'G', 'B', 'Y'),num_oov_buckets=2)
my_feature_columns = [feature_column.indicator_column(colors)]
feature_column.make_parse_example_spec(my_feature_columns)
</code></pre>

<p>Output :</p>

<pre><code>{'colors': VarLenFeature(dtype=tf.string)}  
</code></pre>

<p>If you want to create a dense embedding tensor on your categorical column, you can follow the below example.  </p>

<pre><code>data = {'colors': ['X', 'R', 'G', 'B', 'Y']}

df = pd.DataFrame(data)

colors = feature_column.categorical_column_with_vocabulary_list('colors', df['colors'].unique())

colors_embedding = feature_column.embedding_column(colors, dimension=4)

dense_tensor = tf.keras.layers.DenseFeatures(colors_embedding)(data)
</code></pre>

<p>Result: </p>

<pre><code>tf.Tensor(
[[ 0.17071894  0.29407692 -0.26661882  0.07768019]
 [ 0.26196313  0.14372464 -0.41102907 -0.7207164 ]
 [-0.7888006  -0.07049363 -0.49007863  0.45744416]
 [ 0.56329435 -0.7051675   0.04742934 -0.69377   ]
 [-0.52031726  0.488502   -0.37031132 -0.44338205]], shape=(5, 4), dtype=float32)
</code></pre>
",11041539,23,https://stackoverflow.com/questions/61305781,Documentation Replication on Other Examples
60708695,"How can I make ""element wise"" comparsion inside of the tf.function?","<p>I try to make my own activation function in TensorFlow 2 and the function looks like this:</p>

<pre><code>@tf.function
def f(x):
  r = 2
  if x&gt;=0:
    return (r**2 * x + 1)**(1/r) - 1/r
  else:
    return K.exp(r*x) - 1/r
</code></pre>

<p>The problem is that it cant take as argument <code>tf.constant([2.0, 3.0])</code>because there is an issue with conditions. I have tried <code>tf.math.qreater_equal(x, 0)</code> which lead to same output also <code>tf.cond()</code>. I have had no luck with documentation examples either.
It returns error:</p>

<pre><code>InvalidArgumentError:  The second input must be a scalar, but it has shape [2]
     [[{{node cond/switch_pred/_2}}]] [Op:__inference_f_7469065]
</code></pre>

<p>Thanks!</p>
",-,-,2020-03-16 15:24:16,"<p><code>if</code> statements are converted to <code>cond</code>, but that only takes scalar arguments for the predicate (and does no broadcasting).  Try <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer""><code>where</code></a> instead: </p>

<pre><code>return tf.where(x &gt;= 0, (r**2 * x + 1)**(1/r) - 1/r, K.exp(r*x) - 1/r))
</code></pre>

<p>(Can't test this currently with TensorFlow, but that's at least how Numpy behaves...)</p>
",10962934,3,https://stackoverflow.com/questions/60708695,Documentation Ambiguity
60639731,Tensorboard for custom training loop in Tensorflow 2,"<p>I want to create a custom training loop in tensorflow 2 and use tensorboard for visualization. Here is an example I've created based on tensorflow documentation:</p>

<pre><code>import tensorflow as tf
import datetime

os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""    # which gpu to use

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))

train_dataset = train_dataset.shuffle(60000).batch(64)
test_dataset = test_dataset.batch(64)


def create_model():
    return tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28), name='Flatten_1'),
        tf.keras.layers.Dense(512, activation='relu', name='Dense_1'),
        tf.keras.layers.Dropout(0.2, name='Dropout_1'),
        tf.keras.layers.Dense(10, activation='softmax', name='Dense_2')
    ], name='Network')


# Loss and optimizer
loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adam()

# Define our metrics
train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')
test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)
test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')

@tf.function
def train_step(model, optimizer, x_train, y_train):
    with tf.GradientTape() as tape:
        predictions = model(x_train, training=True)
        loss = loss_object(y_train, predictions)
    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))

    train_loss(loss)
    train_accuracy(y_train, predictions)

@tf.function
def test_step(model, x_test, y_test):
    predictions = model(x_test)
    loss = loss_object(y_test, predictions)

    test_loss(loss)
    test_accuracy(y_test, predictions)


current_time = datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")
train_log_dir = '/NAS/Dataset/logs/gradient_tape/' + current_time + '/train'
test_log_dir = '/NAS/Dataset/logs/gradient_tape/' + current_time + '/test'
train_summary_writer = tf.summary.create_file_writer(train_log_dir)
test_summary_writer = tf.summary.create_file_writer(test_log_dir)

model = create_model()  # reset our model

EPOCHS = 5


for epoch in range(EPOCHS):
    for (x_train, y_train) in train_dataset:
        train_step(model, optimizer, x_train, y_train)
    with train_summary_writer.as_default():
        tf.summary.scalar('loss', train_loss.result(), step=epoch)
        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)

    for (x_test, y_test) in test_dataset:
        test_step(model, x_test, y_test)
    with test_summary_writer.as_default():
        tf.summary.scalar('loss', test_loss.result(), step=epoch)
        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)

    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
    print(template.format(epoch + 1,
                          train_loss.result(),
                          train_accuracy.result() * 100,
                          test_loss.result(),
                          test_accuracy.result() * 100))

    # Reset metrics every epoch
    train_loss.reset_states()
    test_loss.reset_states()
    train_accuracy.reset_states()
    test_accuracy.reset_states()
</code></pre>

<p>I am accessing tensorboard with the following command on terminal:</p>

<pre><code>tensorboard --logdir=.....
</code></pre>

<p>The code above produce summaries for losses and metrics. My question is:</p>

<ul>
<li><strong>How can i produce the graph of this process?</strong></li>
</ul>

<p>I've tried to use the recommended commands from tensorflow: <strong>tf.summary.trace_on()</strong> and <strong>tf.summary.trace_export()</strong>, but I haven't managed to plot the graph. Maybe I am using them wrong. I whould really appreciate any suggestion on how to do this.</p>
",-,-,2020-03-11 15:43:28,"<p>As answered <a href=""https://stackoverflow.com/a/61173028/2110869"">here</a>, I'm sure there's a better way, but a simple workaround is to just use the existing tensorboard callback logic:</p>

<pre><code>tb_callback = tf.keras.callbacks.TensorBoard(LOG_DIR)
tb_callback.set_model(model) # Writes the graph to tensorboard summaries using 
an internal file writer
</code></pre>
",10687511,184,https://stackoverflow.com/questions/60639731,Documentation Replication on Other Examples
60590333,Increasing each element of a tensor by the predecessor in Tensorflow 2.0,"<p>I'm new to <em>tensorflow 2.0</em>, and haven't done much except designing and training some artificial neural networks from boilerplate code. I'm trying to solve an <em>exercise for newcomers</em> into the new tensorflow. I created some code, but it doesn't work. Below is the <strong><em>problem definition</em></strong>:</p>

<hr>

<p>Assuming we have tensor <code>M</code> of rational numbers in shape of <code>(a, b, c)</code> and scalar <code>p  (0, 1)</code> (memory factor), lets create a function that will return tensor <code>N</code> in shape of <code>(a, b, c)</code>. Each element of <code>N</code> tensors moving along axis <em>c</em> should be increased by the value of predecessor multiplied by <code>p</code>.</p>

<p>Assuming we have tensor:</p>

<pre><code>T = [x1, x2, x3, x4]
</code></pre>

<p>in shape of <code>(1, 1, 4)</code>, we would like to get vector:</p>

<pre><code>[x1, x2+x1p, x3+(x2+x1p)p, x4+(x3+(x2+x1p)p)*p] 
</code></pre>

<p>Solution should be created in <em>Tensorflow 2.0</em> and should be focused on delivering the shortest execution time on CPU. Created graph should allow to efficiently calculate derivative both on tensor <code>M</code> and value <code>p</code>.</p>

<hr>

<p>This is the <strong>code I created till now</strong>:</p>

<pre><code>import tensorflow as tf

@tf.function
def vectorize_predec(t, p):
    last_elem = 0
    result = []
    for el in t:
        result.append(el + (p * last_elem))
        last_elem = el + (p * last_elem)
    return result

p = tf.Variable(0.5, dtype='double')

m = tf.constant([[0, 1, 2, 3, 4],
          [1, 3, 5, 7, 10],
          [1, 1, 1, -1, 0]])

vectorize_predec(m, p)
</code></pre>

<p>But it throws a <code>TypeError</code>.</p>

<p>I looked around documentation, I've seen functions like <code>cumsum</code> and <code>polyeval</code>, but I'm not sure they fit my needs. To my understanding, I need to write my own customer function annotated with <code>@tf.function</code>. I'm also not sure how to handle 3-dimension tensors properly according to the problem definition (adding the predecessor should happen on the last (<em>""c""</em>) axis). </p>

<p>I've seen in documentation (here: <a href=""https://www.tensorflow.org/tutorials/customization/performance"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/customization/performance</a>) that there are ways to measure size of the produced graph. Although, I'm not sure how ""graph"" allows to efficiently calculate <em>derivative</em> both on tensor <code>M</code> and value <code>p</code>. ELI5 answers appreciated, or at least some materials I can read to educate myself better.</p>

<p>Thanks a lot! </p>
",-,-,2020-03-08 17:46:06,"<p>I'll give you a couple of different methods to implement that. I think the most obvious solution is to use <a href=""https://www.tensorflow.org/api_docs/python/tf/scan"" rel=""noreferrer""><code>tf.scan</code></a>:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def apply_momentum_scan(m, p, axis=0):
    # Put axis first
    axis = tf.convert_to_tensor(axis, dtype=tf.int32)
    perm = tf.concat([[axis], tf.range(axis), tf.range(axis + 1, tf.rank(m))], axis=0)
    m_t = tf.transpose(m, perm)
    # Do computation
    res_t = tf.scan(lambda a, x: a * p + x, m_t)
    # Undo transpose
    perm_t = tf.concat([tf.range(1, axis + 1), [0], tf.range(axis + 1, tf.rank(m))], axis=0)
    return tf.transpose(res_t, perm_t)
</code></pre>

<p>However, you can also implement this as a particular matrix product, if you build a matrix of exponential factors:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def apply_momentum_matmul(m, p, axis=0):
    # Put axis first and reshape
    m = tf.convert_to_tensor(m)
    p = tf.convert_to_tensor(p)
    axis = tf.convert_to_tensor(axis, dtype=tf.int32)
    perm = tf.concat([[axis], tf.range(axis), tf.range(axis + 1, tf.rank(m))], axis=0)
    m_t = tf.transpose(m, perm)
    shape_t = tf.shape(m_t)
    m_tr = tf.reshape(m_t, [shape_t[0], -1])
    # Build factors matrix
    r = tf.range(tf.shape(m_tr)[0])
    p_tr = tf.linalg.band_part(p ** tf.dtypes.cast(tf.expand_dims(r, 1) - r, p.dtype), -1, 0)
    # Do computation
    res_tr = p_tr @ m_tr
    # Reshape back and undo transpose
    res_t = tf.reshape(res_tr, shape_t)
    perm_t = tf.concat([tf.range(1, axis + 1), [0], tf.range(axis + 1, tf.rank(m))], axis=0)
    return tf.transpose(res_t, perm_t)
</code></pre>

<p>This can also be rewritten to avoid the first transposing (which in TensorFlow is expensive) with <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""noreferrer""><code>tf.tensordot</code></a>:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def apply_momentum_tensordot(m, p, axis=0):
    # Put axis first and reshape
    m = tf.convert_to_tensor(m)
    # Build factors matrix
    r = tf.range(tf.shape(m)[axis])
    p_mat = tf.linalg.band_part(p ** tf.dtypes.cast(tf.expand_dims(r, 1) - r, p.dtype), -1, 0)
    # Do computation
    res_t = tf.linalg.tensordot(m, p_mat, axes=[[axis], [1]])
    # Transpose
    last_dim = tf.rank(res_t) - 1
    perm_t = tf.concat([tf.range(axis), [last_dim], tf.range(axis, last_dim)], axis=0)
    return tf.transpose(res_t, perm_t)
</code></pre>

<p>The three functions would be used in a similar way:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

p = tf.Variable(0.5, dtype=tf.float32)
m = tf.constant([[0, 1, 2, 3, 4],
                 [1, 3, 5, 7, 10],
                 [1, 1, 1, -1, 0]], tf.float32)
# apply_momentum is one of the functions above
print(apply_momentum(m, p, axis=0).numpy())
# [[ 0.    1.    2.    3.    4.  ]
#  [ 1.    3.5   6.    8.5  12.  ]
#  [ 1.5   2.75  4.    3.25  6.  ]]
print(apply_momentum(m, p, axis=1).numpy())
# [[ 0.      1.      2.5     4.25    6.125 ]
#  [ 1.      3.5     6.75   10.375  15.1875]
#  [ 1.      1.5     1.75   -0.125  -0.0625]]
</code></pre>

<p>Using a matrix product is more asymptotically complex, but it can be faster than scanning. Here is a small benchmark:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

# Make test data
tf.random.set_seed(0)
p = tf.constant(0.5, dtype=tf.float32)
m = tf.random.uniform([100, 30, 50], dtype=tf.float32)

# Axis 0
print(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_matmul(m, p, 0).numpy()))
# True
print(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_tensordot(m, p, 0).numpy()))
# True
%timeit apply_momentum_scan(m, p, 0)
# 11.5 ms  610 s per loop (mean  std. dev. of 7 runs, 100 loops each)
%timeit apply_momentum_matmul(m, p, 0)
# 1.36 ms  18.3 s per loop (mean  std. dev. of 7 runs, 1000 loops each)
%timeit apply_momentum_tensordot(m, p, 0)
# 1.62 ms  7.39 s per loop (mean  std. dev. of 7 runs, 1000 loops each)

# Axis 1
print(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_matmul(m, p, 1).numpy()))
# True
print(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_tensordot(m, p, 1).numpy()))
# True
%timeit apply_momentum_scan(m, p, 1)
# 4.27 ms  60.4 s per loop (mean  std. dev. of 7 runs, 100 loops each)
%timeit apply_momentum_matmul(m, p, 1)
# 1.27 ms  36.4 s per loop (mean  std. dev. of 7 runs, 1000 loops each)
%timeit apply_momentum_tensordot(m, p, 1)
# 1.2 ms  11.6 s per loop (mean  std. dev. of 7 runs, 1000 loops each)

# Axis 2
print(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_matmul(m, p, 2).numpy()))
# True
print(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_tensordot(m, p, 2).numpy()))
# True
%timeit apply_momentum_scan(m, p, 2)
# 6.29 ms  64.6 s per loop (mean  std. dev. of 7 runs, 100 loops each)
%timeit apply_momentum_matmul(m, p, 2)
# 1.41 ms  21.8 s per loop (mean  std. dev. of 7 runs, 1000 loops each)
%timeit apply_momentum_tensordot(m, p, 2)
# 1.05 ms  26 s per loop (mean  std. dev. of 7 runs, 1000 loops each)
</code></pre>

<p>So, matrix product seems to win. Let's see if this scales:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

# Make test data
tf.random.set_seed(0)
p = tf.constant(0.5, dtype=tf.float32)
m = tf.random.uniform([1000, 300, 500], dtype=tf.float32)

# Axis 0
print(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_matmul(m, p, 0).numpy()))
# True
print(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_tensordot(m, p, 0).numpy()))
# True
%timeit apply_momentum_scan(m, p, 0)
# 784 ms  6.78 ms per loop (mean  std. dev. of 7 runs, 1 loop each)
%timeit apply_momentum_matmul(m, p, 0)
# 1.13 s  76.9 ms per loop (mean  std. dev. of 7 runs, 1 loop each)
%timeit apply_momentum_tensordot(m, p, 0)
# 1.3 s  27 ms per loop (mean  std. dev. of 7 runs, 1 loop each)

# Axis 1
print(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_matmul(m, p, 1).numpy()))
# True
print(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_tensordot(m, p, 1).numpy()))
# True
%timeit apply_momentum_scan(m, p, 1)
# 852 ms  12.7 ms per loop (mean  std. dev. of 7 runs, 1 loop each)
%timeit apply_momentum_matmul(m, p, 1)
# 659 ms  10.7 ms per loop (mean  std. dev. of 7 runs, 1 loop each)
%timeit apply_momentum_tensordot(m, p, 1)
# 741 ms  19.5 ms per loop (mean  std. dev. of 7 runs, 1 loop each)

# Axis 2
print(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_matmul(m, p, 2).numpy()))
# True
print(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_tensordot(m, p, 2).numpy()))
# True
%timeit apply_momentum_scan(m, p, 2)
# 1.06 s  16.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each)
%timeit apply_momentum_matmul(m, p, 2)
# 924 ms  17 ms per loop (mean  std. dev. of 7 runs, 1 loop each)
%timeit apply_momentum_tensordot(m, p, 2)
# 483 ms  10.1 ms per loop (mean  std. dev. of 7 runs, 1 loop each)
</code></pre>

<p>Well, now it's not so clear anymore. Scanning is still not super fast, but matrix products are sometimes slower. As you can imagine if you go to even bigger tensors the complexity of matrix products will dominate the timings.</p>

<p>So, if you want the fastest solution and know your tensors are not going to get huge, use one of the matrix product implementations. If you're fine with okay speed but want to make sure you don't run out of memory (matrix solution also takes much more) and timing is predictable, you can use the scanning solution.</p>

<p>Note: Benchmarks above were carried out on CPU, results may vary significantly on GPU.</p>
",1554153,855,https://stackoverflow.com/questions/60590333,Lack of Alternative Solutions/Documentation
60453533,Tensorflow what is the tf.contrib.nccl.allsum in new version?,"<p>It seems that from tensorflow 1.13, there is no api such as tf.contrib.nccl.allsum. However, in the Nvidia official GitHub <a href=""https://github.com/tkarras/progressive_growing_of_gans"" rel=""nofollow noreferrer"">https://github.com/tkarras/progressive_growing_of_gans</a>, which uses this old API to reduce sum from different gpu devices as the following. </p>

<pre><code># Sum gradients across devices.
            if len(devices) &gt; 1:
                with tf.name_scope('SumAcrossGPUs'), tf.device(None):
                    for var_idx, grad_shape in enumerate(self._grad_shapes):
                        g = [dev_grads[dev][var_idx][0] for dev in devices]
                        if np.prod(grad_shape): # nccl does not support zero-sized tensors
                            g = tf.contrib.nccl.all_sum(g)
                        for dev, gg in zip(devices, g):
                            dev_grads[dev][var_idx] = (gg, dev_grads[dev][var_idx][1])
</code></pre>

<p>I am not sure if there is similar api which can achieve the same collective operation cross different devices. I have checked the Tensorflow official website and it seems that programmers prefer to use <code>tf.distribute.MirroredStrategy</code> which hides the raw operation of <code>NCCL</code>. Thanks a lot.</p>
",tf.distribute.MirroredStrategy,tf.distribute.MirroredStrategy,2020-02-28 14:16:17,"<p>I think the same API is <code>nccl_ops.all_sum</code>. I have demoed this API by the following code. </p>

<pre><code>import tensorflow as tf 
from tensorflow.python.ops import nccl_ops

a = []

with tf.device(""/GPU:0""):
    g = tf.constant([1,1])
    print(g)
    a.append(g)
with tf.device(""/GPU:1""):
    g = tf.constant([2,2])
    a.append(g)

b = nccl_ops.all_sum(a)
with tf.Session() as sess:
    print(sess.run(b))
</code></pre>

<p>I am not sure what tensorflow team will do in the future. But now we can use it to do the collective operations.</p>
",9881203,961,https://stackoverflow.com/questions/60453533,Documentation Replication on Other Examples
60398554,"Should we apply repeat, batch shuffle to tf.data.Dataset when passing it to fit function?","<p>I still don't after having read documentation about <code>tf.keras.Model.fit</code> and <code>tf.data.Dataset</code>, when passing <code>tf.data.Dataset</code> to fit function, should I call <code>repeat</code> and <code>batch</code> on the dataset object or should I provide the <code>batch_size</code> and <code>epochs</code> arguments to fit instead? or both? Should I apply the same treatment to the validation set?</p>

<p>And while I'm here, can I <code>shuffle</code> the dataset before the <code>fit</code>? (seems like it's an obvious yes)
If so, before, after calling <code>Dataset.batch</code> and <code>Dataset.repeat</code> (if calling them)?</p>

<p><strong>Edit:</strong> When using <code>batch_size</code> argument, and without having called <code>Dataset.batch(batch_size)</code> previously, I am getting the following error:</p>

<pre><code>ValueError: The `batch_size` argument must not be specified for the given input type.
Received input: &lt;MapDataset shapes: ((&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;), (&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;)), 
types: ((tf.float32, tf.float32, tf.float32, tf.float32), (tf.float32, tf.float32, tf.float32))&gt;, 
batch_size: 1
</code></pre>

<p>Thanks</p>
",tf.keras.Model,tf.keras.Model,2020-02-25 15:55:09,"<p>There's different ways to do what you want here, but the one I always use is: </p>

<pre><code>batch_size = 32
ds = tf.Dataset()
ds = ds.shuffle(len_ds)
train_ds = ds.take(0.8*len_ds)
train_ds = train_ds.repeat().batch(batch_size)
validation_ds = ds.skip(0.8*len_ds)
validation_ds = train_ds.repeat().batch(batch_size)
model.fit(train_ds,
          steps_per_epoch = len_train_ds // batch_size,
          validation_data = validation_ds,
          validation_steps = len_validation_ds // batch_size,
          epochs = 5)
</code></pre>

<p>This way you have access to all the variables after model fitting as well, for example if you want to visualize the validation set, you can. This is not really possible with <code>validation_split</code>. If you remove <code>.batch(batch_size)</code>, you should remove the <code>// batch_size</code>s, but I would leave them, as it clearer what is happening now.</p>

<p>You always have to provide epochs.</p>

<p>Calculating the length of your train/validation sets requires you to loop over them: </p>

<pre><code>len_train_ds = 0
for i in train_ds:
  len_train_ds += 1
</code></pre>

<p>if in <code>tf.Dataset</code> form.</p>
",7483509,1057,https://stackoverflow.com/questions/60398554,Documentation Replication on Other Examples
60215970,What's the cleanest and most efficient way to pass two stereo images to a loss function in Keras?,"<p>First off, why am I using Keras? I'm trying to stay as high level as possible, which doesn't mean I'm scared of low-level Tensorflow; I just want to see how far I can go while keeping my code as simple and readable as possible.</p>

<p>I need my Keras model (custom-built using the Keras functional API) to read the left image from a stereo pair and minimize a loss function that needs to access both the right and left images. I want to store the data in a <code>tf.data.Dataset</code>.</p>

<p>What I tried:</p>

<ol>
<li>Reading the dataset as <code>(left image, right image)</code>, i.e. as tensors with shape <code>((W, H, 3), (W, H, 3))</code>, then use function closure: define a <code>keras_loss(left_images)</code> that returns a <code>loss(y_true, y_pred)</code>, with <code>y_true</code> being a <code>tf.Tensor</code> that holds the right image. The problem with this approach is that <code>left_images</code> is a <code>tf.data.Dataset</code> and Tensorflow complains (rightly so) that I'm trying to operate on a dataset instead of a tensor. </li>
<li><p>Reading the dataset as <code>(left image, (left image, right image))</code>, which should make <code>y_true</code> a <code>tf.Tensor</code> with shape <code>((W, H, 3), (W, H, 3))</code> that holds both the right and left images. The problem with this approach is that it...does not work and raises the following error:</p>

<pre><code>ValueError: Error when checking model target: the list of Numpy arrays 
that you are passing to your model is not the size the model expected. 
Expected to see 1 array(s), for inputs ['tf_op_layer_resize/ResizeBilinear'] 
but instead got the following list of 2 arrays: [&lt;tf.Tensor 'args_1:0' 
shape=(None, 512, 256, 3) dtype=float32&gt;, &lt;tf.Tensor 'args_2:0' 
shape=(None, 512, 256, 3) dtype=float32&gt;]...
</code></pre></li>
</ol>

<p>So, is there anything I did not consider? I read the documentation and found nothing about what gets considered as <code>y_pred</code> and what as <code>y_true</code>, nor about how to convert a dataset into a tensor smartly and without loading it all in memory. </p>

<p>My model is designed as such:</p>

<pre><code> def my_model(input_shape):
     width = input_shape[0]
     height = input_shape[1]
     inputs = tf.keras.Input(shape=input_shape)
     # &lt; a few more layers &gt;
     outputs = tf.image.resize(tf.nn.sigmoid(tf.slice(disp6, [0, 0, 0, 0], [-1, -1, -1, 2])), tf.Variable([width, height]))
     model = tf.keras.Model(inputs=inputs, outputs=outputs)
     return model
</code></pre>

<p>And my dataset is built as such (in case 2, while in case 1 only the function <code>read_stereo_pair_from_line()</code> changes):</p>

<pre><code>def read_img_from_file(file_name):
    img = tf.io.read_file(file_name)
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_png(img, channels=3)
    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)
    # resize the image to the desired size.
    return tf.image.resize(img, [args.input_width, args.input_height])


def read_stereo_pair_from_line(line):
    split_line = tf.strings.split(line, ' ')
    return read_img_from_file(split_line[0]), (read_img_from_file(split_line[0]), read_img_from_file(split_line[1]))

# Dataset loading
list_ds = tf.data.TextLineDataset('test/files.txt')
images_ds = list_ds.map(lambda x: read_stereo_pair_from_line(x))
images_ds = images_ds.batch(1)
</code></pre>
",tf.data.Dataset,tf.data.Dataset,2020-02-13 20:29:51,"<p>Solved. I just needed to read the dataset as <code>(left image, [left image, right image])</code> instead of <code>(left image, (left image, right image))</code> i.e. make the second item a list and not a tuple. I can then access the images as <code>input_r = y_true[:, 1, :, :]</code> and <code>input_l = y_true[:, 0, :, :]</code></p>
",5623016,47,https://stackoverflow.com/questions/60215970,Lack of Alternative Solutions/Documentation
60047705,Repeated use of GradientTape for multiple Jacobian calculations,"<p>I am attempting to compute the Jacobian of a TensorFlow neural network's outputs with respect to its inputs. This is easily achieved with the <code>tf.GradientTape.jacobian</code> method. The trivial example provided in the TensorFlow documentation is as follows:</p>

<pre><code>with tf.GradientTape() as g:
  x  = tf.constant([1.0, 2.0])
  g.watch(x)
  y = x * x
jacobian = g.jacobian(y, x)
</code></pre>

<p>This is fine if I want only want to compute the Jacobian of a single instance of the input tensor <code>x</code>. However, I need to repeatedly evaluate this Jacobian many, many times for various instances of <code>x</code>. For a non-trivial Jacobian calculation (e.g. for a deep convolutional neural network with non-linear activation functions), this is incredibly expensive to repeatedly rerun the GradientTape calculation and evaluate the <code>jacobian</code> method. I know from the <a href=""https://www.tensorflow.org/tutorials/customization/autodiff"" rel=""nofollow noreferrer"">TensorFlow documentation</a> that the gradients (and hence the Jacobian) are computed via automatic differentiation.  I have to imagine there is some internal storage of the analytical gradient of the network (computed by automatic differentiation) which is evaluated at the given inputs. </p>

<p>My question: am I correct in assuming that TensorFlow builds and stores (at least parts of) the analytical gradients needed to compute the Jacobian? And if so, is there a way to save this analytical gradient and re-evaluate the Jacobian with new inputs without having to reconstruct it via the GradientTape method?</p>

<p>A ""persistent"" GradientTape does not seem to solve this issue: it only allows for the repeated evaluation of a single GradientTape instance with respect to multiple internal arguments of the computation.</p>
",tf.GradientTape.jacobian,tf.GradientTape.jacobian,2020-02-03 21:54:37,"<p>Maybe you find this helpful:</p>

<p>I needed to compute the jacobian of an arbitrary function many, many times. My problem was that I was using <code>GradientTape</code> inappropriately, but the code I posted might help you or give you some insight. I posted a self contained example of calculating the jacobian using both the session based <code>tf.gradient()</code> function and the modern <code>GriadientTape</code> approach. With help, I got them to run within the same order of magnitude of each other.</p>

<ul>
<li>If your question is focused on trying to reuse the intermediate calculations between calls for a speed boost, then I think Nick's answer is more applicable.</li>
<li>If your question is focused on trying to make GradientTape as fast as a static graph, then make sure you wrap it in <code>@tf.function</code> since it does just that.</li>
</ul>

<p>See my question: <a href=""https://stackoverflow.com/questions/61810094/abysmal-tf-gradienttape-performance-compared-to-tf-gradients-for-computing-jac"">Abysmal tf.GradientTape performance compared to tf.gradients() for computing jacobians</a></p>
",11737392,23,https://stackoverflow.com/questions/60047705,Documentation Replication on Other Examples
60013980,tf.nn.embedding_lookup_sparse 3D sparse tensor input,"<p>I have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse"" rel=""nofollow noreferrer""><code>tf.nn.embedding_lookup_sparse</code></a> I found it only supports 2D sparse tensors,</p>

<blockquote>
  <p>sp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary.</p>
</blockquote>

<p>My example code here</p>

<pre><code>import numpy as np
import tensorflow as tf
tf.enable_eager_execution()

# [feature number, embedding dim] 
w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer())

z = np.array(
     [
      [
        [0, 1, 2, 3],   # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum
        [2, 3]
      ],

      [
        [1, 3],
        [2]
      ],

      [
        [0, 1, 3],
        [1, 2]
      ]
     ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2],
                              [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0],
                              [2,0,1],[2,0,3],[2,1,1],[2,1,2]],
                     dense_shape=[3, 2, 4])

tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')
# the outputs
&lt;tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy=
array([[-5.8729677 , -1.3900641 ,  0.8126096 , -3.1223912 ],
       [-1.0788026 , -1.1324122 ,  0.34160078,  0.23714277],
       [-2.497394  , -2.7855003 ,  3.0201516 , -1.8009453 ]],
      dtype=float32)&gt;

print(w)
&lt;tf.Variable 'w:0' shape=(4, 4) dtype=float32, numpy=
array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)&gt;
</code></pre>

<p>But the expected output is a matrix with a dimension of <code>3x2x4</code>, not <code>3x4</code>. Does <code>tf.nn.embedding_lookup_sparse</code> support this operation?</p>
",tf.nn.embedding_lookup_sparse,tf.nn.embedding_lookup_sparse,2020-02-01 4:23:54,"<p>The most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape.</p>

<pre class=""lang-py prettyprint-override""><code># First make the z as a 2D arr and create a sparse tensor 
z = np.array([
        [0, 1, 2, 3],  # get the row 0,1,2,3 of the embedding matrix w and get the sum
        [2, 3],
        [1, 3],
        [2],
        [0, 1, 3],
        [1, 2]
      ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1],
                              [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]],
                     dense_shape=[6, 4])

res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')

res.numpy()
# the output
array([[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
       [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ],
       [ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
       [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]],

# reshape
tf.reshape(res, [-1, 2, 4])
# that is exacly what I want.
array([[[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
        [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ]],

       [[ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
        [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532]],

       [[-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
        [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]]])

# print w, and the above result is right
w.numpy()

array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)
</code></pre>

<p>So, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.</p>
",5046896,17040,https://stackoverflow.com/questions/60013980,Documentation Replicability
59998335,Constantly update tf.cond based on bool value,"<p>I am using <code>tf.cond</code> for controlling the flow of the Tensorflow graph. I went through the documentation and was able to implement <code>tf.cond</code> based branching successfully. But my concern is that while the graph is being loaded the value of the <code>bool</code> variable is checked and the branching decision is made at the initialization step itself. Any further changes in the <code>bool</code> is not tracked. Following is the MWE that better describes the problem:</p>

<pre class=""lang-py prettyprint-override""><code>def funa():
    return tf.constant(32)

def funb():
    return tf.constant(25)

foo = True
x = tf.cond(tf.convert_to_tensor(foo), lambda: funa(), lambda: funb())
for i in range(20):
    global foo
    if i &gt; 10:
        foo = False
    print(sess.run(x))    
</code></pre>

<p>This prints only <code>32</code>s. </p>

<p>I tried with <code>eager_execution</code> too with the following code:</p>

<pre class=""lang-py prettyprint-override""><code>tf.enable_eager_execution()
def funa():
    return tf.constant(32)

def funb():
    return tf.constant(21)

foo = True
x = tf.cond(tf.convert_to_tensor(foo), lambda: funa(), lambda: funb())
for i in range(20):
    if i &gt; 10:
        foo = False
    print(x)
</code></pre>

<p>Still the same result.</p>

<p>So my question is how can I write code such that one part of the graph is chosen dynamically, based on the updates to the <code>bool</code> variable (if possible)? Thanks. I am using Tensorflow v1.14.</p>
",tf.cond,tf.cond,2020-01-31 5:24:12,"<p>You can make a placeholder for <code>foo</code> and feed it's value while running the session. Modified code:</p>

<pre><code>import tensorflow as tf

def funa():
    return tf.constant(32)

def funb():
    return tf.constant(25)

foo = True
foo_p = tf.placeholder(tf.bool)

sess = tf.Session()

x = tf.cond(foo_p, lambda: funa(), lambda: funb())
for i in range(20):
    if i &gt; 10:
        foo = False
    print(sess.run(x, {foo_p:foo}))
</code></pre>
",6997665,3238,https://stackoverflow.com/questions/59998335,Documentation Replication on Other Examples
59723003,From .tfrecord to tf.data.Dataset to tf.keras.model.fit,"<p>I am attemping to use Tensorflow (v2.0)'s Datasets API to pass large amounts of data to a <code>tf.keras.model</code>.  Here is a simplified version of my dataset:</p>

<pre><code>for rec in my_dataset:
    print(repr(rec))

$ {'feature0': &lt;tf.Tensor: id=528, shape=(), dtype=float32, numpy=0.2963&gt;,
'feature1': &lt;tf.Tensor: id=618, shape=(), dtype=int64, numpy=0&gt;,
'feature2': &lt;tf.Tensor: id=620, shape=(), dtype=string, numpy=b'Inst1'&gt;,
'target': &lt;tf.Tensor: id=621, shape=(), dtype=int64, numpy=2&gt;}
{'feature0': &lt;tf.Tensor: id=528, shape=(), dtype=float32, numpy=0.4633&gt;,
'feature1': &lt;tf.Tensor: id=618, shape=(), dtype=int64, numpy=1&gt;,
'feature2': &lt;tf.Tensor: id=620, shape=(), dtype=string, numpy=b'Inst4'&gt;,
'target': &lt;tf.Tensor: id=621, shape=(), dtype=int64, numpy=0&gt;}
</code></pre>

<p>...and so on.  Each record in the <code>my_dataset</code> object is a dictionary with the features' (and target's) names as the keys and associated tensors as the values.  I created the dataset from several .tfrecord files, so I'm constrained in the sense that each tensor corresponds to a <code>tf.train.Example</code> (wrapper) object.  The dataset precisely matches the format seen in tensorflow documentation (see, for example, the last code example in <a href=""https://www.tensorflow.org/tutorials/load_data/tfrecord#reading_a_tfrecord_file"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/load_data/tfrecord#reading_a_tfrecord_file</a>).</p>

<p>I would like to use this dataset with keras.  The <code>tf.keras.model</code> objects I'm working with all seem, for their <code>fit</code> function, to take as input a tuple representing the feature vector (X) and the target (y).  I think I could figure out how to transform the tensors from my dataset into numpy arrays and pass them into the model that way, or iterate over the dataset using an iterator, but if I understand correctly that seems to defeat the whole purpose of using the Datasets API to begin with (see, for example, <a href=""https://www.tensorflow.org/guide/keras/overview#train_from_tfdata_datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/overview#train_from_tfdata_datasets</a>).</p>

<p>My question:  what is the appropriate way to transform <code>my_dataset</code> into some form that <code>tf.keras.model.fit()</code> will receive?  Or if this is the wrong question, what fundamental concepts am I missing that keep me from asking the right one?  (For example, should the .tfrecord Examples be structured differently?  Or, am I required to use an iterator instead of directly passing <code>my_dataset</code> to the model as I'd prefer?)</p>
",-,-,2020-01-13 19:30:04,"<p>Unfortunately I was only able to find a workaround instead of an outright solution.  Because <code>tf.stack</code> will only work on items of the same data type, I need to transform all data into floats during processing of the Examples (including one-hot encoding for all strings), and then use <code>tf.stack</code> on the resulting tensor:</p>

<pre><code>def proces_example(serialized_example):
    feature_description = get_feature_desc()  # dictionary describing features and dtypes
    target_name = get_target_name()  # so we don't include the target in our feature vector
    parsed_example = tf.io.parse_single_example(serialized_example, feature_description)
    tensor_list = []
    for tensor in parsed_example:
        if tensor != target_name:
            parsed_example[tensor] = tf.dtypes.cast(parsed_example[tensor], tf.float32)
            tensor_list.append(parsed_example[tensor])
    X = tf.stack(tensor_list)
    y = parsed_example[target_name]
    return X, y
</code></pre>
",3397173,506,https://stackoverflow.com/questions/59723003,Documentation Replicability
59555206,keras to tf.keras Conversion: Dense layer dimensions not defined?,"<p>So I've built a convnet using pure <code>keras</code>. It compiles and operates exactly as intended, but I need to convert it to use <code>tf.keras</code> so that I can make use of <code>tfmot</code>. Having read documentation, I attempted to convert it, only to get the following error:</p>

<p><code>The last dimension of the inputs to Dense should be defined. Found None.</code> </p>

<p>Any idea what I'm doing wrong?</p>

<p>Thanks!</p>

<p>Original <code>keras</code> model:</p>

<pre><code>input_layer = keras.layers.Input(shape=(100,))
reshape_layer = keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = keras.layers.Flatten()(conv_layer_5)
label_layer = keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = keras.layers.Dense(1, activation=""linear"")(label_layer)

model = keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>Converted <code>tf.keras</code> model:</p>

<pre><code>input_layer = tf.keras.layers.InputLayer(input_shape=(100,))
reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>EDIT 1:</p>

<p>I thought maybe I could get around the issue by saving the <code>keras</code> model after creation and loading it as a <code>tf.keras</code> model immediately before compilation / training. That throws the same error! </p>
",tf.keras,tf.keras,2020-01-01 18:51:03,"<p>There's few issues with your code. Fix them and you should be good to go,</p>

<h2>Issue 1: Use <code>Input</code> instead of <code>InputLayer</code></h2>

<p>The standard is to use <code>Input</code> layer instead of <code>InputLayer</code> (which infact uses <code>InputLayer</code> internally). You also need to change <code>input_shape</code> to <code>shape</code> if you are using <code>Input</code> layer.</p>

<pre><code>input_layer = tf.keras.layers.Input(shape=(100,))
</code></pre>

<h2>Issue 2: 2 <code>None</code> dimensions in the output</h2>

<p>When you execute the following line, you get two <code>None</code> dimensions in your output. </p>

<pre><code>reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
</code></pre>

<p>Which is why you are getting the above error. When defining the <code>Reshape</code> layer you don't define the <code>batch</code> dimension, which will be None. And that's the only dimension you can have as <code>None</code> if you want to use a <code>Dense</code> layer. Otherwise, the <code>Dense</code> layer cannot infer the shape of its weights (which is why you get the error). So change that to,</p>

<pre><code>reshape_layer = tf.keras.layers.Reshape((1, 100, 1))(input_layer)
</code></pre>

<p>The rest stays the same.</p>

<pre><code>conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
model.summary()
</code></pre>
",6639365,57,https://stackoverflow.com/questions/59555206,Documentation Replication on Other Examples
59531864,Why does TensorFlow calculate 2D convolutions when 1D convolution is called?,"<p>In the documentation of tf.nn.conv1d, it is stated that</p>

<blockquote>
  <p>Internally, this op reshapes the input tensors and invokes tf.nn.conv2d. For example, if data_format does not start with ""NC"", a tensor of shape [batch, in_width, in_channels] is reshaped to [batch, 1, in_width, in_channels], and the filter is reshaped to [1, filter_width, in_channels, out_channels]. The result is then reshaped back to [batch, out_width, out_channels] (where out_width is a function of the stride and padding as in conv2d) and returned to the caller.</p>
</blockquote>

<p>I get that the operations are equivalent, but I am a bit confused about the implications of this implementation detail. </p>

<p>Does the reshaping create some computational overhead? 
The 3D convolution has its own implementation, so why not the 1D convolution?</p>

<p>Thanks for any explanation that helps me and others to understand this implementation detail of TensorFlow!</p>
",tf.nn.conv1d,tf.nn.conv1d,2019-12-30 13:42:28,"<p>Digging through the source code, I conclude that it's likely done for convenience and minimalism of implementation - details below. </p>

<p>First, there is no ""reshaping"", only expanding, squeezing, and re-ordering dims, which bears a tiny overhead; no array elements are actually being moved in memory - only the tensor object's indexing specifiers are changed.</p>

<p>Second, all <code>conv</code> ultimately route to <a href=""https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/nn_ops.py#L942"" rel=""nofollow noreferrer""><code>tf.nn_ops.convolution_internal</code></a>, which then routes to either <code>gen_nn_ops.conv2d</code> or <code>gen_nn_ops.conv3d</code>; a <code>conv1d</code> does not exist in <code>gen_nn_ops.py</code>. Note that for some reason, you won't find that file in the Git respository - but it should be in your local install, <code>/python/ops/gen_nn_ops.py</code>.</p>

<p>Lastly, to get a real answer on why there isn't a dedicated <code>conv1d</code> implementation, you'll need to ask the cuDNN developers behind the convolution algorithms found in <code>gen_nn_ops.py</code>; it's possible that they found no performance improvements, and that <code>conv2d</code> works just as fast. From a low-level standpoint, this makes sense, as the number of matrix multiplications in sliding a kernel with <code>N x 1</code> elements along an <code>M x 1</code> input is identical to that of <code>N</code> along <code>M</code> - again, the only difference is in indexing.</p>

<p>Unfortunately devs decided to encapsulate the ultimate call, that is to <code>_pywrap_tensorflow_internal.TFE_Py_FastPathExecute</code>; the module consists of a <code>.lib</code> and a <code>.pyd</code> file - basically, compiled C (Cython) code that requires disassembly for introspection. </p>

<hr>

<p>TL;DR (1) the ""reshaping"" has a trivial overhead; (2) lack of a dedicated <code>conv1d</code> implementation is likely per sparing redundancy as <code>conv2d</code> is just as fast; (3) I'm not a cuDNN expert, so if you need to be sure, better ask over at <a href=""https://developer.nvidia.com/cudnn"" rel=""nofollow noreferrer"">cuDNN</a>, or read their <a href=""https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html"" rel=""nofollow noreferrer"">SDK Documentation</a>. Alternatively, a dev at <a href=""https://github.com/tensorflow/tensorflow/issues"" rel=""nofollow noreferrer"">TF Github</a> may help. I haven't seen cuDNN devs answer on SO for years now, so posting here may not be the best bet.</p>

<hr>

<p><strong>Dim reordering performance demo</strong>:</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
from time import time

x = np.random.randn(700, 800, 900) # 504,000,000 elements

t0 = time()
for i in range(1000):
    if i % 2 == 0:
        x = x.reshape(700, 900, 800)
    else:
        x = x.reshape(700, 800, 900)
print(time() - t0)
</code></pre>

<pre><code>0.0009968280792236328
</code></pre>
",6251391,1056,https://stackoverflow.com/questions/59531864,Documentation Replicability
59361689,Redundancies in tf.keras.backend and tensorflow libraries,"<p>I have been working in TensorFlow for about a year now, and I am transitioning from TF 1.x to TF 2.0, and I am looking for some guidance on how to use the <code>tf.keras.backend</code> library in TF 2.0. I understand that the transition to TF 2.0 is supposed to remove a lot of redundancies in modeling and building graphs, since there were many ways to create equivalent layers in earlier TensorFlow versions (and I'm insanely grateful for that change!), but I'm getting stuck on understanding when to use <code>tf.keras.backend</code>, because the operations appear redundant with other TensorFlow libraries. </p>

<p>I see that some of the functions in <code>tf.keras.backend</code> are redundant with other TensorFlow libraries. For instance, <code>tf.keras.backend.abs</code> and <code>tf.math.abs</code> are not aliases (or at least, they're not listed as aliases in the documentation), but both take the absolute value of a tensor. After examining the source code, it looks like <code>tf.keras.backend.abs</code> calls the <code>tf.math.abs</code> function, and so I really do not understand why they are not aliases. Other <code>tf.keras.backend</code> operations don't appear to be duplicated in TensorFlow libraries, but it looks like there are TensorFlow functions that can do equivalent things. For instance, <code>tf.keras.backend.cast_to_floatx</code> can be substituted with <code>tf.dtypes.cast</code> as long as you explicitly specify the dtype. I am wondering two things:</p>

<ol>
<li>when is it best to use the <code>tf.keras.backend</code> library instead of the equivalent TensorFlow functions?</li>
<li>is there a difference in these functions (and other equivalent <code>tf.keras.backend</code> functions) that I am missing?</li>
</ol>
",tf.keras.backend,tf.keras.backend,2019-12-16 17:36:52,"<p>Short answer: Prefer tensorflow's native API such as <code>tf.math.*</code> to the<code>tf.keras.backend.*</code> API wherever possible.</p>

<p>Longer answer:</p>

<ul>
<li>The <code>tf.keras.backend.*</code> API can be <em>mostly</em> viewed as a remnant of the <code>keras.backend.*</code> API. The latter is a design that serves the ""exchangeable backend"" design of the original (non-TF-specific) keras. This relates to the historical aspect of keras, which supports multiple backend libraries, among which tensorflow used to be just one of them. Back in 2015 and 2016, other backends, such as Theano and MXNet were quite popular too. But going into 2017 and 2018, tensorflow became the dominant backend of keras users. Eventually keras became a part of the tensorflow API (in 2.x and later minor versions of 1.x). In the old multi-backend world, the <code>backend.*</code> API provides a backend-independent abstraction over the myriad of supported backend. But in the tf.keras world, the value of the backend API is much more limited.</li>
<li>The various functions in <code>tf.keras.backend.*</code> can be divided into a few categories:

<ol>
<li>Thin wrappers around the equivalent or mostly-equivalent tensorflow native API. Examples: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L2363"" rel=""noreferrer"">tf.keras.backend.less</a>, <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L2431"" rel=""noreferrer"">tf.keras.backend.sin</a></li>
<li>Slightly thicker wrappers around tensorflow native APIs, with more features included. Examples: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L2589"" rel=""noreferrer"">tf.keras.backend.batch_normalization</a>, <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L4869"" rel=""noreferrer"">tf.keras.backend.conv2d</a>(<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L4869"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L4869</a>). They often perform proprocessing and implement other logics, which make your life easier than using native tensorflow API.</li>
<li>Unique functions that don't have equivalent in the native tensorflow API. Examples: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L3809"" rel=""noreferrer"">tf.keras.backend.rnn</a>, <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L342"" rel=""noreferrer"">tf.keras.backend.set_learning_phase</a></li>
</ol></li>
</ul>

<p>For category 1, use native tensorflow APIs. For categories 2 and 3, you may want to use the <code>tf.keras.backend.*</code> API, as long as you can find it in the documentation page: <a href=""https://www.tensorflow.org/api_docs/python/"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/</a>, because the documented ones have backward compatibility guarantees, so that you don't need to worry about a future version of tensorflow removing it or changing its behavior.</p>
",4982425,485,https://stackoverflow.com/questions/59361689,Documentation Replication on Other Examples
59074659,Best practice for allocating GPU and CPU resources in TensorFlow,"<p>I'm wondering what is the correct way to set devices for creating/training a model in order to optimize resource usage for speedy training in TensorFlow with the Keras API? I have 1 CPU and 2 GPUs at my disposal. I was initially using a <code>tf.device</code> context to create my model and train on GPUs only, but then I saw in the TensorFlow documentation for <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/multi_gpu_model"" rel=""nofollow noreferrer""><code>tf.keras.utils.multi_gpu_model</code></a>, they suggest explicitly instantiating the model on the CPU:</p>

<pre><code># Instantiate the base model (or ""template"" model).
# We recommend doing this with under a CPU device scope,
# so that the model's weights are hosted on CPU memory.
# Otherwise they may end up hosted on a GPU, which would
# complicate weight sharing.
with tf.device('/cpu:0'):
    model = Xception(weights=None,
                     input_shape=(height, width, 3),
                     classes=num_classes)

# Replicates the model on 8 GPUs.
# This assumes that your machine has 8 available GPUs.
parallel_model = multi_gpu_model(model, gpus=8)
parallel_model.compile(loss='categorical_crossentropy',
                       optimizer='rmsprop')
</code></pre>

<p>I did this, and now when I train I see my CPU usage go way up with all 8 cores at about 70% usage each, and my GPU memory is maxed out. Would things go faster if the model were created on one of the GPUs? Even if I have just 1 GPU, is it still better to create model on CPU and use <code>tf.device</code> context to train the model on the GPU?</p>
",tf.keras.utils.multi_gpu_model,Deprecated,2019-11-27 16:31:37,"<p>Many TensorFlow operations are accelerated using the GPU for computation. Without any annotations, TensorFlow automatically decides whether to use the GPU or CPU for an operationcopying the tensor between CPU and GPU memory, if necessary. Tensors produced by an operation are typically backed by the memory of the device on which the operation executed.</p>

<p>Tensorflow will only allocate memory and place operations on visible physical devices, as otherwise no LogicalDevice will be created on them. By default all discovered devices are marked as visible. </p>

<p>Also GPU utilization depends on the <code>batch_size</code>. The utilization may change with varying <code>batch_size</code>. </p>

<p>You can also compare your current results(time taken and utilization) with model using the <code>Example 3</code> from <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/multi_gpu_model"" rel=""nofollow noreferrer"">multi_gpu_model</a>.</p>

<p>Also if you go into the link, it states -</p>

<blockquote>
  <p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2020-04-01. Instructions for updating: Use tf.distribute.MirroredStrategy instead.</p>
</blockquote>

<p>There should be performance improvement and GPU Utilization using <code>tf.distribute.MirroredStrategy</code>. This strategy is typically used for training on one machine with multiple GPUs. The <code>tf.distribute.Strategy</code> API provides an abstraction for distributing your training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.</p>

<p>For example, a variable created under a <code>MirroredStrategy</code> is a <code>MirroredVariable</code>. If no devices are specified in the constructor argument of the strategy then it will use all the available <code>GPUs</code>. If no <code>GPUs</code> are found, it will use the available <code>CPUs</code>. Note that TensorFlow treats all <code>CPUs</code> on a machine as a single device, and uses threads internally for parallelism.</p>

<p>Would recommend to go through <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">Custom training with tf.distribute.Strategy</a> tutorial that demonstrates on how to use tf.distribute.Strategy with custom training loops. They will train a simple CNN model on the fashion MNIST dataset.</p>

<p>Hope this answers your question. Happy Learning.</p>
",3711266,4334,https://stackoverflow.com/questions/59074659,Documentation Replication on Other Examples
58748202,Difference between feature_column.embedding_column and keras.layers.Embedding in TensorFlow,"<p>I have been using <strong>keras.layers.Embedding</strong> for almost all of my projects. But, recently I wanted to fiddle around with tf.data and found <strong>feature_column.embedding_column</strong>.</p>

<p>From the documentation:</p>

<p><strong>feature_column.embedding_column</strong> - 
<code>DenseColumn</code> that converts from sparse, categorical input.
  Use this when your inputs are sparse, but you want to convert them to a dense
  representation (e.g., to feed to a DNN).</p>

<p><strong>keras.layers.Embedding</strong> - Turns positive integers (indexes) into dense vectors of fixed size.
  e.g. <code>[[4], [20]] -&gt; [[0.25, 0.1], [0.6, -0.2]]</code>
  This layer can only be used as the first layer in a model.</p>

<p>My question is, is both of the api doing similar thing on different type of input data(for ex. input - [0,1,2] for keras.layers.Embedding and its one-hot-encoded rep. [[1,0,0],[0,1,0],[0,0,1] for feature_column.embedding_column)?</p>
",tf.feature_column.embedding_column,tf.feature_column.embedding_column,2019-11-07 11:52:23,"<p>After reviewing source code for both operations here is what I found:</p>

<ul>
<li>both operations rely on <code>tensorflow.python.ops.embedding_ops</code> funcitonality;</li>
<li>keras.layers.Embedding uses <strong>dense</strong> representations and contains generic keras code for fiddling with shapes, init variables etc;</li>
<li>feature_column.embedding_column relies on <strong>sparse</strong> and contains functionality to cache results.</li>
</ul>

<p>So, your guess seems to be right: these 2 are doing similar things, rely on distinct input representations, contain some logic that doesn't change the essense of what they do.</p>
",4402524,354,https://stackoverflow.com/questions/58748202,Documentation Replication on Other Examples
58631390,What is the purpose of tf.compat?,"<p>What's the purpose of tf.compat module? It looks like just the entire Tensorflow API is replicated inside this module.
The documentation states</p>

<blockquote>
  <p>Functions for Python 2 vs. 3 compatibility.</p>
</blockquote>

<p>So why there is a ""v1"" and a ""v2"" submodule? What are the compatibility problems address by tf.compat specifically?</p>
",tf.compat,tf.compat,2019-10-30 18:08:57,"<p><a href=""https://www.tensorflow.org/api_docs/python/tf/compat"" rel=""noreferrer""><code>tf.compat</code></a> allows you to write code that works both in TensorFlow 1.x and 2.x. For example, the following piece of code:</p>

<pre><code>import tensorflow as tf

tf.compat.v1.disable_v2_behavior()
with tf.compat.v1.Session() as sess:
    x = tf.compat.v1.placeholder(tf.float32, [2])
    x2 = tf.square(x)
    print(sess.run(x2, feed_dict={x: [2, 3]}))
    # [4. 9.]
</code></pre>

<p>Runs the same on TensorFlow 1.15.0 and 2.0.0, even though session and placeholders were deprecated in 2.x. Likewise, <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v2"" rel=""noreferrer""><code>tf.compat.v2</code></a> allows you to use things introduced in 2.x from 1.x. Also, these APIs provide also backwards compatibility for the future too, so if at some point a 3.x version is released, the mechanism to write version-independent code will already be there since the first version of 2.x.</p>

<p>EDIT: The documentation for the module about Python should actually be changed. Originally, <code>tf.compat</code> only held functions for that purpose (and it was like that until 1.13, <a href=""https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/compat"" rel=""noreferrer"">see all module documentation</a>). However, it was later repurposed for TensorFlow version compatibility.</p>
",1719931,3428,https://stackoverflow.com/questions/58631390,Documentation Completeness
58550146,How to use the tf.keras.layers.BatchNormalization() in custom training loop?,"<p>I went back to tensorflow after quite a while and it seems the landscape is completely changed.</p>

<p>However, previously I used to use <code>tf.contrib....batch_normalization</code> with the following in the training loop:</p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    train_op = optimizer.minimize(cnn.loss, global_step=global_step)
</code></pre>

<p>But it seems, <code>contrib</code> is nowhere to be found and <code>tf.keras.layers.BatchNormalization</code> does not work the same way. Also, I couldn't find any training instruction in their <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""nofollow noreferrer"">documentation</a>.</p>

<p>So, any information of help is appreciated.</p>
",tf.keras.layers.BatchNormalization,tf.keras.layers.BatchNormalization,2019-10-24 22:55:53,"<p>I started using pyTorch. It solved the problem.</p>
",817824,447,https://stackoverflow.com/questions/58550146,Lack of Alternative Solutions/Documentation
58225926,Tensorflow Gradient Tape returning None,"<p>I'm using TensorFlow 1.14.0 with Python(3.6.8). I'm trying to use tensorflow_probability's lbfgs optimizer implementation(<a href=""https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer/lbfgs_minimize"" rel=""nofollow noreferrer"">documentation/example</a>).</p>

<p>If I run the example code provided in the documentation it works fine. I tried to follow the same procedure for my own code which uses the <code>tf.GradientTape()</code> approach for computing the objective function. When doing it that way, the gradients come back as <code>None</code> type.</p>

<p>I'm not seeing why one is working, but the other is not.</p>

<p>Edit: I realized that running eager execution using the gradients wouldn't work, so I adjusted the example to be able to be run with eager execution.</p>

<p>Non-working example(using GradientTape) with eager execution</p>

<pre><code>import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp

tf.enable_eager_execution()

# A high-dimensional quadratic bowl.
ndims = 3
minimum = np.ones([ndims], dtype='float64')
scales = np.arange(ndims, dtype='float64') + 1.0

# The objective function and the gradient.
def quadratic(x):
    with tf.GradientTape() as g:
        value = tf.reduce_sum(scales * (x - minimum) ** 2)
    grads = g.gradient(value, x)
    print('Gradients: ')
    print(grads)
    return value, grads

start = np.arange(ndims, 0, -1, dtype='float64')
optim_results = tfp.optimizer.lbfgs_minimize(quadratic, initial_position=start, num_correction_pairs=10,tolerance=1e-8)

print('results')
print(optim_results)
# Check that the search converged
assert(optim_results.converged)
# Check that the argmin is close to the actual value.
np.testing.assert_allclose(optim_results.position, minimum)
</code></pre>
",tf.optimizat.lbfgs_minimize,tf.optimizat.lbfgs_minimize,2019-10-03 19:44:56,"<p>You need to watch x. For the operations inside this context manager, it's required at least one of their inputs is being watched. </p>

<pre class=""lang-py prettyprint-override""><code>with tf.GradientTape() as g:
    g.watch(x)
    value = tf.reduce_sum(scales * (x - minimum) ** 2)
</code></pre>
",3667142,1133,https://stackoverflow.com/questions/58225926,Documentation Replication on Other Examples
58126494,How to Translate CSV Data into TFRecord Files,"<p>Currently I am working on a system that can take data from a CSV file and import it into a TFRecord file, However I have a few questions.</p>

<p>For starters, I need to know what type a TFRecord file can take, when using CSV types are removed.</p>

<p>Secondly, How can I convert data type:object into a type that a TFRecord can take?</p>

<p>I have two columns (will post example below) of two objects types that are strings, How can I convert that data to the correct type for TFRecords?</p>

<p>When importing Im hoping to append data from each row at a time into the TFRecord file, any advice or documentation would be great, I have been looking for some time at this problem and it seems there can only be ints,floats inputted into a TFRecord but what about a list/array of Integers?</p>

<p>Thankyou for reading!</p>

<p>Quick Note, I am using PANDAS to create a dataframe of the CSV file</p>

<p>Some Example Code Im using </p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
from ast import literal_eval
import numpy as np
import tensorflow as tf


tf.compat.v1.enable_eager_execution()


def Start():
    db = pd.read_csv(""I:\Github\ClubKeno\Keno Project\Database\..\LotteryDatabase.csv"")

    pd.DataFrame = db
    print(db['Winning_Numbers'])
    print(db.dtypes)

    training_dataset = (
        tf.data.Dataset.from_tensor_slices(
            (
                tf.cast(db['Draw_Number'].values, tf.int64),
                tf.cast(db['Winning_Numbers'].values, tf.int64),
                tf.cast(db['Extra_Numbers'].values, tf.int64),
                tf.cast(db['Kicker'].values, tf.int64)
            )
        )
    )

    for features_tensor, target_tensor in training_dataset:
        print(f'features:{features_tensor} target:{target_tensor}')
</code></pre>

<p>Error Message:</p>

<p><img src=""https://cdn.discordapp.com/attachments/279786369902051328/626967249395122213/Capture.PNG"" alt=""Error Message""></p>

<p><a href=""https://cdn.discordapp.com/attachments/502661247809093673/626946732239880194/LotteryDatabase.csv"" rel=""nofollow noreferrer"">CSV Data</a></p>

<p>Update:
Got Two Columns of dating working using the following function...</p>

<pre class=""lang-py prettyprint-override""><code>dataset = tf.data.experimental.make_csv_dataset(
        file_pattern=databasefile,
        column_names=['Draw_Number', 'Kicker'],
        column_defaults=[tf.int64, tf.int64],
    )
</code></pre>

<p>However when trying to include my two other column object types
(What data looks like in both those columns)
<code>""3,9,11,16,25,26,28,29,36,40,41,46,63,66,67,69,72,73,78,80""</code></p>

<p>I get an error, here is the function I tried for that</p>

<pre class=""lang-py prettyprint-override""><code>    dataset = tf.data.experimental.make_csv_dataset(
        file_pattern=databasefile,
        column_names=['Draw_Number', 'Winning_Numbers', 'Extra_Numbers', 'Kicker'],
        column_defaults=[tf.int64, tf.compat.as_bytes, tf.compat.as_bytes, tf.int64],
        header=True,
        batch_size=100,
        field_delim=',',
        na_value='NA'
    )
</code></pre>

<p>This Error Appears:</p>

<pre><code>TypeError: Failed to convert object of type &lt;class 'function'&gt; to Tensor. Contents: &lt;function as_bytes at 0x000000EA530908C8&gt;. Consider casting elements to a supported type.
</code></pre>

<p>Should I try to Cast those two types outside the function and try combining it later into the TFRecord file alongside the tf.data from the <code>make_csv_dataset</code> function? </p>
",-,-,2019-09-27 1:06:27,"<blockquote>
<p>For starters, I need to know what type a TFRecord file can take, when using CSV types are removed.</p>
</blockquote>
<p>TFRecord accepts following datatypes-
string, byte, float32, float 64, bool, enum, int32, int64, uint32, uint64
Talked <a href=""https://www.tensorflow.org/beta/tutorials/load_data/tf_records#data_types_for_tfexample"" rel=""nofollow noreferrer"">here</a>.</p>
<blockquote>
<p>Secondly, How can I convert data type:object into a type that a TFRecord can take?</p>
</blockquote>
<p><a href=""https://www.tensorflow.org/beta/tutorials/load_data/tf_records#creating_a_tfexample_message"" rel=""nofollow noreferrer"">Here</a> is an example from TF, it is a bit complicated to digest it at once but if you read it carefully it is easy.</p>
<blockquote>
<p>have two columns (will post example below) of two objects types that are strings, How can I convert that data to the correct type for TFRecords?</p>
</blockquote>
<p>For string type data, you require <code>tf.train.BytesList</code> which returns a bytes_list from a string.</p>
<blockquote>
<p>When importing Im hoping to append data from each row at a time into the TFRecord file, any advice or documentation would be great, I have been looking for some time at this problem and it seems there can only be ints,floats inputted into a TFRecord but what about a list/array of Integers?</p>
<p>Quick Note, I am using PANDAS to create a dataframe of the CSV file</p>
</blockquote>
<p>Instead of reading csv file using Pandas, I would recommend you to use <code>tf.data.experimental.make_csv_dataset</code> defined <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/make_csv_dataset"" rel=""nofollow noreferrer"">here</a>. This will make this conversion process very faster than Pandas and will give you less compatibility issues to work with TF classes. If you use this function, then you will not need to read the csv file row by row but all at once using <code>map()</code> which uses <code>eager execution</code>. <a href=""https://www.tensorflow.org/beta/tutorials/load_data/tf_records#tfrecord_files_using_tfdata"" rel=""nofollow noreferrer"">This</a> is a good tutorial to get started.</p>
<p>Accidentally edited wrong section of the post</p>
",9873122,175,https://stackoverflow.com/questions/58126494,Requesting (Additional) Documentation/Examples
58069572,Workaround for lack of broadcast in TFLite,"<p>I would like to run a TFLite model that requires me to produce a 3d output (the sample code is a minimum example generating the error). Is there a tensorflow equivalent to gather_nd that does not reduce the dimension by one?</p>

<p>I've tried looking through the documentation for related functions that I can think of and haven't found a good option.</p>

<pre><code>import tensorflow.compat.v1 as tf
import numpy as np

tf.disable_v2_behavior()
initial_input = tf.placeholder(dtype=tf.float32, shape=(None,5,1024))
cap_i = tf.gather_nd(initial_input, [[0,1]]) #[0,2],[0,3],[0,4],[0,5]
cap_i_broadcast = tf.broadcast_to(cap_i, [1,5,1024])
cap_iT = tf.transpose(cap_i_broadcast, perm=[0,2,1])

sess = tf.Session()
sess.run(tf.global_variables_initializer())
tf.io.write_graph(sess.graph_def, '', 'train.pbtxt')
converter = tf.lite.TFLiteConverter.from_session(sess, [initial_input], [cap_iT])
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
open('converted_model.tflite', ""wb"").write(tflite_model)
sess.close()
</code></pre>

<p>Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: GATHER_ND, TRANSPOSE. Here is a list of operators for which you will need custom implementations: BroadcastTo.</p>
",-,-,2019-09-23 20:11:46,"<p>The following code has a solution using strided slice with dimensionality reduction and then reshape to get back the correct dimension.</p>

<pre><code>import tensorflow.compat.v1 as tf
import numpy as np

tf.disable_v2_behavior()
initial_input = tf.placeholder(dtype=tf.float32, shape=(None,5,1024))
cap_i = tf.strided_slice(initial_input, [0,0,0], [0,5,1024], [1,1,1], 
shrink_axis_mask=1)
cap_i_reshaped =tf.reshape(cap_i,[1,5,1024])
cap_iT = tf.transpose(cap_i_reshaped, perm=[0,2,1])

sess = tf.Session()
sess.run(tf.global_variables_initializer())
tf.io.write_graph(sess.graph_def, '', 'train.pbtxt')
converter = tf.lite.TFLiteConverter.from_session(sess, [initial_input], 
[cap_iT])
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, 
tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
open('converted_model.tflite', ""wb"").write(tflite_model)
sess.close()
</code></pre>

<p>Previously thought slice was supported in TFLite but only strided_slice is.</p>
",12092080,33,https://stackoverflow.com/questions/58069572,Documentation Replication on Other Examples
57823210,How to combine tf.data.Dataset and tf.estimator.DNNRegressor properly,"<p>I am currently learning to use tensorflow and have troubles getting started.
I would like to use the newest API, namely estimator and dataset. But if I run the code presented below I get an Error.</p>

<p>On the tensorflow page <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor</a> I found, that ""The function should construct and return one of the following: * A tf.data.Dataset object: Outputs of Dataset object must be a tuple (features, labels) with same constraints as below.""</p>

<p>I thought my code would provide that, but there seems to be a problem and I am out of ideas.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
def input_evaluation_set():
    data = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]
    labels = []
    for d in data:
        labels.append(1)
    return tf.data.Dataset.from_tensor_slices((tf.constant(data), tf.constant(labels)))

point = tf.feature_column.numeric_column('points')
estimator = tf.estimator.DNNRegressor(feature_columns = [point],hidden_units = [100,100,100])

estimator.train(input_fn = input_evaluation_set)
</code></pre>

<p>I expect to run a training session on a deep neural network with 3 hidden layers a' 100 neurons in order to approximate the 'constant 1' function;
instead I get the Error ""ValueError: features should be a dictionary of 'Tensor's. Given type: class, 'tensorflow.python.framework.ops.Tensor'</p>
",tf.estimator.DNNRegresso,Deprecated,2019-09-06 13:42:53,"<p>You need to use .batch on your database in order to have the right format.</p>

<p>The following is working on my computer:</p>

<pre><code>import tensorflow as tf
import numpy as np

def basic_dataset(numPoints):
    data = np.linspace(0,1,numPoints)
    dataset = dict({'points': data})
    labels = []
    for d in data:
        labels.append(1)
    return tf.data.Dataset.from_tensor_slices((dataset, np.array(labels)))

def input_train_set():
    dataset = basic_dataset(11)
    return dataset.repeat(100).shuffle(1000).batch(1)

point = tf.feature_column.numeric_column('points')
estimator = tf.estimator.DNNRegressor(feature_columns = [point],hidden_units = [100,100,100], label_dimension = 1)

estimator.train(input_fn = input_train_set)
</code></pre>
",12030773,39,https://stackoverflow.com/questions/57823210,Documentation Replication on Other Examples
57813806,Apply feature columns without tf.Estimator (Tensorflow 2.0.0-rc0),"<p>In the Tensorflow tf.Estimator and tf.feature_column docs it is well documented, how to use feature columns together with an Estimator e.g. in order to one-hot encode the categorical features in the dataset being used.</p>

<p>However, I want to ""apply"" my feature columns directly to a tf.dataset which I create from a .csv file (with two columns: UserID, MovieID), without even defining a model or an Estimator. (Reason: I want to check what's happening exactly in my datapipeline, i.e. I'd like to be able to run a batch of samples through my the pipeline, and then see in the output how the features got encoded.)</p>

<p>This is what I have tried so far:</p>

<pre><code>column_names = ['UserID', 'MovieID']

user_col = tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000)
movie_col = tf.feature_column.categorical_column_with_hash_bucket(key='MovieID', hash_bucket_size=1000)
feature_columns = [tf.feature_column.indicator_column(user_col), tf.feature_column.indicator_column(movie_col)]

feature_layer = tf.keras.layers.DenseFeatures(feature_columns=feature_columns)

def process_csv(line):
  fields = tf.io.decode_csv(line, record_defaults=[tf.constant([], dtype=tf.int32)]*2, field_delim="";"")
  features = dict(zip(column_names, fields))

  return features 

ds = tf.data.TextLineDataset(csv_filepath)
ds = ds.map(process_csv, num_parallel_calls=4)
ds = ds.batch(10)
ds.map(lambda x: feature_layer(x))
</code></pre>

<p>However the last line with the map call raises the following error:</p>

<blockquote>
  <p>ValueError: Column dtype and SparseTensors dtype must be compatible.
  key: MovieID, column dtype: , tensor dtype: </p>
</blockquote>

<p>I'm not sure what this error means...
I also tried to define a tf.keras model with only the feature_layer I defined, and then run .predict() on my dataset - instead of using ds.map(lambda x: feature_layer(x)):</p>

<pre><code>model = tf.keras.Sequential([feature_layer])
model.compile()
model.predict(ds)
</code></pre>

<p>However, this results exactly in the same error as above.
Does anybody have an idea what is going wrong? Is there maybe an easier way to achieve this?</p>
",tf.feature_column,tf.feature_column,2019-09-05 22:50:19,"<p>Just found the issue:
tf.feature_column.categorical_column_with_hash_bucket() takes an optional argument dtype, which is set to tf.dtypes.string by default.
However, the datatype of my columns is numerical (tf.dtypes.int32).
This solved the issue:</p>

<pre><code>tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000, dtype=tf.dtypes.int32)
</code></pre>
",8725045,724,https://stackoverflow.com/questions/57813806,Documentation Replication on Other Examples
57449484,What is trainable parameter in tensorflow?,"<p>tf.compat.v1.layers.batch_normalization takes <code>trainable</code> as an input. The documentation says:</p>

<blockquote>
  <p>Boolean, if True also add variables to the graph collection GraphKeys.TRAINABLE_VARIABLES (see tf.Variable).</p>
</blockquote>

<p>I think only scaling factor (gamma) and offset (beta) should be added to trainable variables and I am skeptical if even moving averages will get added to GraphKeys.TRAINABLE_VARIABLES. Can somebody tell me how trainable input is influencing the behavior of batch_normalization</p>
",tf.compat.v1.layers.batch_normalization,tf.compat.v1.layers.batch_normalization,2019-08-11 11:11:50,"<p>First of all, this function is <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">deprecated</a> and should not be used.</p>

<p><code>trainable</code> arguments means that scaling factor (gamma) and offset (beta) will be trainable and it's true by default.</p>

<p>When it comes to moving averages, those <strong>are not trainable</strong>, they are only updated after each batch pass, those are not parameters (<code>tf.Variable</code> objects).</p>

<p>Please notice, you can set <code>trainable</code> to false, in such case, if <code>beta</code> and <code>gamma</code> are set to defaults (zero and one respectively), they won't affect the moving averages. You can turn them off by issuing <code>center</code> (for <code>beta</code>) or <code>scale</code> (for <code>gamma</code>).</p>
",6546694,5020,https://stackoverflow.com/questions/57449484,Documentation Replicability
57349824,"Recurrent neural network, time series prediction with newer Tensorflow 1.14","<p>How to use new tf.keras API with recurrent neural network? I have checked the documentation but there is no example of such a situation.
There is this great book Hands on machine learning from 2017. Since that year the API of tensorflow has evolved and I am trying to rewrite recurrent neural network for time series prediction with using version <code>1.14</code> code.
The code from the book is using older <code>tf.nn.dynamic_rnn</code> and <code>tf.nn.rnn_cell.BasicRNNCell</code>:</p>

<pre><code>n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1
learning_rate = 0.001

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])
cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)
rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)
stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])
stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
loss = tf.reduce_mean(tf.square(outputs - y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()
n_iterations = 500
batch_size = 50

with tf.Session() as sess:
    init.run()
        for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})
</code></pre>

<p>And this code works just fine (except that it throws warnings about deprecation left and right). I wanted to use <code>tf.keras</code> API as suggested in warning. My code is the same except:</p>

<pre><code>cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)  
rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

<p>But this yields following exception:</p>

<pre><code>InvalidArgumentError: Input to reshape is a tensor with 50 values, but the requested shape requires a multiple of 20
 [[node Reshape_1 (defined at &lt;ipython-input-9-879361be49dd&gt;:3) ]]
</code></pre>

<p>so I understand that the problematic line is</p>

<pre><code>outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
</code></pre>

<p>After checking and comparing documentation for both cells <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a> and 
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN</a> I can't find the culprit.</p>

<p><strong>What is the difference with these two cells? How to use tf.keras API with time series?</strong></p>

<p>Full old code: <a href=""https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb"" rel=""nofollow noreferrer"">https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb</a></p>

<p>Full ""my"" code:</p>

<pre><code>import numpy as np
import tensorflow as tf
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd
from utils import shuffle_batch, variable_summaries
import os


dir_path = os.getcwd()

now = datetime.utcnow().strftime(""%Y%m%d%H%M%S"")
root_logdir = ""tf_logs""
logdir = ""{}/run-{}/"".format(root_logdir, now)
print(dir_path)


t_min, t_max = -5, 5
section_start = (t_max + t_min) / 2
resolution = 0.1
n_steps = 20

def time_series(t):
    return np.sin(t)

def next_batch(batch_size, n_steps):
    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)
    Ts = t0 + np.arange(0., n_steps + 1) * resolution
    ys = time_series(Ts)
    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)


t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))

t_instance = np.linspace(start = section_start, stop = section_start + resolution * (n_steps + 1),num = n_steps + 1)

plt.figure(figsize=(11,4))
plt.subplot(121)
plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"")
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)
#plt.axis([-10, 10, -17, 13])
plt.xlabel(""Time"")
plt.ylabel(""Value"")

plt.subplot(122)
plt.title(""A training instance"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""c*"", markersize=10, label=""target"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")


# In[6]:


n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])


# In[7]:


cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)                        


rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
print(rnn_outputs.get_shape())


stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons], name='reshape1')
stacked_outputs = tf.keras.layers.Dense(n_outputs,name=""hidden2"")(stacked_rnn_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs], name='reshape2')


learning_rate = 0.001

loss = tf.reduce_mean(tf.square(outputs - y)) # MSE
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()

n_iterations = 1500
batch_size = 50
save_path =os.path.join(dir_path,""model"",""recurrent_sinus_model"")

with tf.Session() as sess:
    init.run()
    for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    saver.save(sess, save_path)


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})


plt.title(""Testing the model"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""w*"", markersize=10, label=""target"")
plt.plot(t_instance[1:], y_pred[0,:,0], ""r."", markersize=10, label=""prediction"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")

plt.show()


# In[ ]:


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t.reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})



plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"",linewidth=5,c='r')
plt.plot(t[:-1], time_series(t[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)

plt.xlabel(""Time"")
plt.ylabel(""Value"")
</code></pre>
",tf.keras,tf.keras,2019-08-04 20:00:21,"<p>So the answer is:</p>

<pre><code>rnn_outputs, rnn_states  = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)
</code></pre>

<p>instead of </p>

<pre><code>rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

<p>so the parameter <code>return_sequences=True</code> make the RNN return the time series as well, and well, this is the point.</p>
",2710943,435,https://stackoverflow.com/questions/57349824,Documentation Replication on Other Examples
57316557,"tf.keras.layers.pop() doesn't work, but tf.keras._layers.pop() does","<p>I want to pop the last layer of the model. So I use the <code>tf.keras.layers.pop()</code>, but it doesn't work.</p>

<pre><code>base_model.summary()
</code></pre>

<p><a href=""https://i.stack.imgur.com/wRz02.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/wRz02.png"" alt=""enter image description here""></a></p>

<pre><code>base_model.layers.pop()

base_model.summary()
</code></pre>

<p><a href=""https://i.stack.imgur.com/msGnY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/msGnY.png"" alt=""enter image description here""></a></p>

<p>When I use <code>tf.keras._layers.pop()</code>, it works.</p>

<pre><code>base_model.summary()
</code></pre>

<p><a href=""https://i.stack.imgur.com/CAq45.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/CAq45.png"" alt=""enter image description here""></a></p>

<pre><code>base_model._layers.pop()
base_model.summary()
</code></pre>

<p><a href=""https://i.stack.imgur.com/viCxT.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/viCxT.png"" alt=""enter image description here""></a></p>

<p>I don't find docs about this usage. Could someone help explain this?</p>
",tf.keras.layers,tf.keras.layers,2019-08-01 20:27:44,"<p>I agree this is confusing. The reason is that <code>model.layers</code> returns a shallow copy of the layers list so:</p>

<p>The tldr is dont use <code>model.layers.pop()</code> to remove the last layer. Instead we should create a new model with all but the last layer. Perhaps something like this:</p>

<pre class=""lang-py prettyprint-override""><code>new_model = tf.keras.models.Sequential(base_model.layers[:-1])
</code></pre>

<p>Checkout this <a href=""https://github.com/tensorflow/tensorflow/issues/22479"" rel=""noreferrer"">github issue</a> for more details</p>
",11255365,731,https://stackoverflow.com/questions/57316557,Documentation Replication on Other Examples
57296471,How can one use TensorFlow.js tf.data.generator for remote data sources since generators can't use callbacks,"<p>When introducing the tf.data.Dataset API, the <a href=""https://www.manning.com/books/deep-learning-with-javascript"" rel=""nofollow noreferrer"">Deep Learning with JavaScript book</a> says:</p>

<blockquote>
  <p>Large applications require technology for accessing data from a remote source, piece by piece, on demand.</p>
</blockquote>

<p>But the documentation I've read about generators says a generator can't produce values via callbacks. But how else can one access remote sources? I don't see how one can use <a href=""https://js.tensorflow.org/api/latest/#data.generator"" rel=""nofollow noreferrer"">tf.data.generator</a> in such cases. <a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/yield"" rel=""nofollow noreferrer"">MDN documentation on yield</a> states:</p>

<blockquote>
  <p>yield can only be called directly from the generator function that contains it. It can't be called from nested functions or from callbacks.</p>
</blockquote>
",-,-,2019-07-31 17:54:30,"<p>You can pass an <code>async</code> function (or a function returning a Promise) to the generator. It is then okay to use <code>await</code> inside the function (even inside a loop) to handle any asynchronous tasks.</p>

<p><strong>Code Sample</strong></p>

<pre class=""lang-js prettyprint-override""><code>const dataset = tf.data.generator(async function* () {
    const dataToDownload = await fetch(/* ... */);
    while (/* ... */) {
        const moreData = await fetch(/* ... */);
        yield otherData;
    }
});
</code></pre>

<p>This example uses <a href=""https://github.com/bitinn/node-fetch"" rel=""nofollow noreferrer""><code>node-fetch</code></a>, of course any other method of downloading data also works fine.</p>

<h3>Async Generators</h3>

<p>Regarding the MDN documentation, generators can be defined as <code>async</code>, but this changes the way they work. Instead of returning the value right away, they will return a Promise that you have to await for. So, instead of calling <code>iterator.next()</code>, you have to call <code>await iterator.next()</code> to read the value.</p>

<p><strong>Code Sample</strong></p>

<pre class=""lang-js prettyprint-override""><code>async function* foo(index) {
  while (true) {
    yield index++;
  }
}

(async () =&gt; {
  const iterator = foo(0);
  console.log((await iterator.next()).value); // 0
  console.log((await iterator.next()).value); // 1
})();
</code></pre>

<p>Luckily, Tensorflow.js is able to handle <code>async</code> functions/Promises in generators.</p>
",1230710,458,https://stackoverflow.com/questions/57296471,Documentation Ambiguity
56969703,How to use `tf.scatter_nd` with multi-dimensional tensors,"<p>I'm trying to create a new tensor (<code>output</code>) with the values of another tensor (<code>updates</code>) placed according to <code>idx</code> tensor. The shape of <code>output</code> should be <code>[batch_size, 1, 4, 4]</code> (like an image of 2x2 pixels and one channel) and <code>update</code> has shape <code>[batch_size, 3]</code>.</p>

<p>I've read Tensorflow documentation (I'm working with gpu version 1.13.1) and found <code>tf.scatter_nd</code> should work for my problem. The issue is that I cannot make it work, I think I'm having problems understanding how I have to arange <code>idx</code>. </p>

<p>Let's consider <code>batch_size = 2</code>, so what I'm doing is:</p>

<pre class=""lang-py prettyprint-override""><code>updates = tf.constant([[1, 2, 3], [4, 5, 6]])  # shape [2, 3]
output_shape = tf.constant([2, 1, 4, 4])
idx = tf.constant([[[1, 0], [1, 1], [1, 0]], [[0, 0], [0, 1], [0, 2]]])  # shape [2, 3, 2]
idx_expanded = tf.expand_dims(idx, 1)  # so I have shape [2, 1, 3, 2]
output = tf.scatter_nd(idx_expanded, updates, output_shape)
</code></pre>

<p>I expect it to work, but it doesn't, it gives me this error:</p>

<p><code>ValueError: The outer 3 dimensions of indices.shape=[2,1,3,2] must match the outer 3 dimensions of updates.shape=[2,3]: Shapes must be equal rank, but are 3 and 2 for 'ScatterNd_7' (op: 'ScatterNd') with input shapes: [2,1,3,2], [2,3], [4]</code></p>

<p>I don't understand why it's expecting <code>updates</code> to have dimension 3. I thought <code>idx</code> has to make sense with <code>output_shape</code> (that's why I used <code>expand_dims</code>) and also with <code>updates</code> (specify the two indices for the three points), but it's obvious I'm missing something here.</p>

<p>Any help would be appreciated.</p>
",tf.scatter_n,tf.scatter_n,2019-07-10 11:25:01,"<p>I've been playing around with the function and I have found my mistake. If anyone is facing this problem, this is what I did to solve it:</p>

<p>Considering <code>batch_size=2</code> and <code>3</code> points, <code>idx</code> tensor must have shape <code>[2, 3, 4]</code>, where first dimension correspond to the batch from where we are taking <code>update</code>value, second dimension must be equal to the second dimension of <code>updates</code> (number of points per batch) and the third dimension is <code>4</code> because we need <code>4</code> indices: [batch_number, channel, row, col]. Following the example in the question:</p>

<pre class=""lang-py prettyprint-override""><code>updates = tf.constant([[1., 2., 3.], [4., 5., 6.]])  # [2, 3]
idx = tf.constant([[[0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 1, 0]], [[1, 0, 1, 1], [1, 0, 0, 0], [1, 0, 1, 0]]])  # [2, 3, 4]
output = tf.scatter_nd(idx, updates, [2, 1, 4, 4])

sess = tf.Session()
print(sess.run(output))

[[[[2. 1. 0. 0.]
   [3. 0. 0. 0.]
   [0. 0. 0. 0.]
   [0. 0. 0. 0.]]]


 [[[5. 0. 0. 0.]
   [6. 4. 0. 0.]
   [0. 0. 0. 0.]
   [0. 0. 0. 0.]]]]

</code></pre>

<p>This way it's possible to place specific numbers in a new tensor.</p>
",7327257,337,https://stackoverflow.com/questions/56969703,Documentation Replication on Other Examples
56802840,What exactly tensorflow.gather() does?,"<p>I saw code for triplet loss that contains the function tf.gather(). What this function does?</p>

<p>I have gone through the tensorflow's official website for definition but still unable to get it.</p>

<pre><code>def margin_triplet_loss(y_true, y_pred, margin, batch_size):
    anchor = tf.gather(y_pred, tf.range(0, batch_size, 3))
    positive = tf.gather(y_pred, tf.range(1, batch_size, 3))
    negative = tf.gather(y_pred, tf.range(2, batch_size, 3))

    loss = K.maximum(margin
                 + K.sum(K.square(anchor-positive), axis=1)
                 - K.sum(K.square(anchor-negative), axis=1),
                 0.0)
    return K.mean(loss)
</code></pre>
",tf.gather,tf.gather,2019-06-28 7:41:59,"<p>tf.gather is a function to index an array. You gather the elements which you specify by the index argument. This is not natively posible for tensorflow tensors. </p>

<p>tf.gather(y_pred, tf.range(0, batch_size, 3)) is equivalent in numpy to y_pred[0:batch_size:3], which means that you return every third element starting from the first one. </p>
",9678047,437,https://stackoverflow.com/questions/56802840,Lack of Alternative Solutions/Documentation
56553579,How to export Estimator's best model?,"<p>I am training a simple CNN based on a Custom Estimator with TF Records.
I am trying to export the best model in terms of validation loss during the <code>train_and_evaluate</code> phase. </p>

<p>According to the documentation of the <code>tf.estimator.BestExporter</code>, I should feed a function that returns a <code>ServingInputReceiver</code> but after doing so, the <code>train_and_evaluate</code> phase crashes with a <code>NotFoundError: model/m01/eval; No such file or directory</code>.</p>

<p>Seems like if the BestExporter does not permit saving the evaluation results as it would do without the exporter. I tried with different <code>ServingInputReceiver</code> but I keep getting the same error.</p>

<p>As defined <a href=""https://www.tensorflow.org/guide/saved_model#using_savedmodel_with_estimators"" rel=""nofollow noreferrer"">here</a>:</p>

<pre><code>feature_spec = {
        'shape': tf.VarLenFeature(tf.int64),
        'image_raw': tf.FixedLenFeature((), tf.string),
        'label_raw': tf.FixedLenFeature((43), tf.int64)
    }

def serving_input_receiver_fn():
  serialized_tf_example = tf.placeholder(dtype=tf.string,
                                         shape=[120, 120, 3],
                                         name='input_example_tensor')
  receiver_tensors = {'image': serialized_tf_example}
  features = tf.parse_example(serialized_tf_example, feature_spec)
  return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)
</code></pre>

<p>and <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/BestExporter#__init__"" rel=""nofollow noreferrer"">here</a></p>

<pre><code>def serving_input_receiver_fn():
    feature_spec = {
            'image': tf.FixedLenFeature((), tf.string)
        }
    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)
</code></pre>

<p>Here are my exporter and training procedure:</p>

<pre><code>exporter = tf.estimator.BestExporter(
    name=""best_exporter"",
    serving_input_receiver_fn=serving_input_receiver_fn,
    exports_to_keep=5)

train_spec = tf.estimator.TrainSpec(
    input_fn=lambda: imgs_input_fn(train_path, True, epochs, batch_size))

eval_spec = tf.estimator.EvalSpec(
    input_fn=lambda: imgs_input_fn(eval_path, perform_shuffle=False, batch_size=1),
    exporters=exporter)

tf.estimator.train_and_evaluate(ben_classifier, train_spec, eval_spec)
</code></pre>

<p><a href=""https://gist.github.com/hichameyessou/f2710391066f6ed5786693892ac93dbe"" rel=""nofollow noreferrer"">This is a gist</a> with the output.
What's the correct way to define a <code>ServingInputReceiver</code> for the <code>BestExporter</code>?</p>
",tf.estimator.BestExporter,tf.estimator.BestExporter,2019-06-12 1:39:22,"<p>Can you try the code shown below:</p>

<pre><code>def serving_input_receiver_fn():
    """"""
    This is used to define inputs to serve the model.
    :return: ServingInputReciever
    """"""
    reciever_tensors = {
        # The size of input image is flexible.
        'image': tf.placeholder(tf.float32, [None, None, None, 1]),
    }

    # Convert give inputs to adjust to the model.
    features = {
        # Resize given images.
        'image': tf.reshape(reciever_tensors[INPUT_FEATURE], [-1, INPUT_SHAPE])
    }
    return tf.estimator.export.ServingInputReceiver(receiver_tensors=reciever_tensors,
                                                    features=features)
</code></pre>

<p>Then use <code>tf.estimator.BestExporter</code> as shown below:</p>

<pre><code>best_exporter = tf.estimator.BestExporter(
        serving_input_receiver_fn=serving_input_receiver_fn,
        exports_to_keep=1)
    exporters = [best_exporter]
    eval_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={input_name: eval_data},
        y=eval_labels,
        num_epochs=1,
        shuffle=False)
    eval_spec = tf.estimator.EvalSpec(
        input_fn=eval_input_fn,
        throttle_secs=10,
        start_delay_secs=10,
        steps=None,
        exporters=exporters)

    # Train and evaluate the model.
    tf.estimator.train_and_evaluate(classifier, train_spec=train_spec, eval_spec=eval_spec)
</code></pre>

<p>For more info, refer the link:
<a href=""https://github.com/yu-iskw/tensorflow-serving-example/blob/master/python/train/mnist_keras_estimator.py"" rel=""nofollow noreferrer"">https://github.com/yu-iskw/tensorflow-serving-example/blob/master/python/train/mnist_keras_estimator.py</a></p>
",3674176,2688,https://stackoverflow.com/questions/56553579,Documentation Ambiguity
56286350,tf.keras.metrics.SpecificityAtSensitivity num_thresholds interpretation,"<p>I'm trying to get my head around <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/metrics/SensitivityAtSpecificity"" rel=""nofollow noreferrer"">tf.keras.metrics.SensitivityAtSpecificity</a>. I'm fine with the concept of sensity and specificity in isolation, but I'm unsure how the two are related in this single metric.</p>

<p>More specifically, I'm unsure how to interpret the <code>num_thresholds</code> argument. The example in documentation has <code>num_thresholds=1</code>. Setting <code>num_thresholds</code> greater than 1 with the same input data seems to always return a metric value of 1.0.</p>

<pre class=""lang-py prettyprint-override""><code>def print_metric_value(num_thresholds):
    # other values based on docs example
    m = tf.keras.metrics.SensitivityAtSpecificity(
        0.4, num_thresholds=num_thresholds)
    m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])
    print('Result with num_thresholds = %d: %.1f' %
          (num_thresholds, m.result().numpy()))

print_metric_value(1)    # 0.5 - same as docs
print_metric_value(2)    # 1.0
print_metric_value(200)  # 1.0
</code></pre>
",tf.keras.metrics.SensitivityAtSpecificity,tf.keras.metrics.SensitivityAtSpecificity,2019-05-24 5:29:09,"<p>The <code>num_thresholds</code> refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0). </p>

<p>For example, consider the prediction vector as <code>[0, 0.5, 0.3, 0.9]</code> which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of <code>0.1</code>, we get <code>[0, 1, 1, 1]</code>; or if we apply threshold value of <code>0.6</code> we get <code>[0, 0, 0, 1]</code> (i.e. only the confidence of last prediction is higher than <code>0.6</code>).   </p>

<p>Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What <code>SensitivityAtSpecificity</code> metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given <code>0.4</code> as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to <code>SpecificityAtSensitivity</code> metric, just swap ""specificity"" and ""sensitivity"" in this paragraph.</p>

<p>You might also ask: what are the threshold values? The answer is if <code>num_thresholds=1</code> then the only threshold is 0.5. If <code>num_thresholds &gt; 1</code> then, besides 0 and 1 as thresholds, the interval (0,1) will be split into <code>num_thresholds - 1</code> equal sub-intervals and the split points are chosen as additional threshold values. For example:</p>

<pre><code>num_threshold  |  thresholds
=============================
1              | [0.5]
2              | [0, 1]
3              | [0, 0.5, 1]
4              | [0, 0.33, 0.66, 1]
5              | [0, 0.25, 0.5, 0.75, 1]
...
</code></pre>
",3098092,4098,https://stackoverflow.com/questions/56286350,Documentation Replication on Other Examples
56231695,When should tf.losses.add_loss() be used in TensorFlow?,"<p>I cannot find an answer to this question in the TensorFlow documentation. I once read that one should add losses from <code>tf.nn</code> functions but it isn't necessary for functions from <code>tf.losses</code>. Therefore:</p>

<p>When should I use <code>tf.losses.add_loss()</code>?</p>

<p>Example:</p>

<pre><code>loss = tf.reduce_mean(tf.nn.sparse_softmax_corss_entropy_with_logits
                       (labels=ground_truth, logits=predictions))

tf.losses.add_loss(loss) &lt;-- when is this required?
</code></pre>

<p>Thank yoou.</p>
",tf.losses,tf.keras.losses,2019-05-21 5:36:59,"<p>One would use this method to register the loss defined by user.</p>

<p>Namely, if you have created a tensor that defines your loss, for example as <code>my_loss = tf.mean(output)</code> you can use this method to add it to loss collection. You might want to do that if you are not tracking all your losses manually. For example if you are using a method like <code>tf.losses.get_total_loss()</code>.</p>

<p>Inside <code>tf.losses.add_loss</code> is very much straightforward:</p>

<pre><code>def add_loss(loss, loss_collection=ops.GraphKeys.LOSSES):
  if loss_collection and not context.executing_eagerly():
    ops.add_to_collection(loss_collection, loss)
</code></pre>
",7353970,10660,https://stackoverflow.com/questions/56231695,Lack of Alternative Solutions/Documentation
56047272,Explicit vs implicit type definition in TensorFlow,"<p>I'm just beginning to learn TensorFlow. Quoting from the <a href=""https://www.tensorflow.org/guide/low_level_intro#graph"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p>Let's build a simple computational graph. The most basic operation is a constant. The Python function that builds the operation takes a tensor value as input. The resulting operation takes no inputs. When run, it outputs the value that was passed to the constructor. We can create two floating point constants a and b as follows:</p>
</blockquote>

<pre><code>a = tf.constant(3.0, dtype=tf.float32)
b = tf.constant(4.0) # also tf.float32 implicitly
total = a + b
print(a)
print(b)
print(total)
</code></pre>

<p>The second constant is implicitly typed as a float32. Is that based on the explicit typing of the first constant? And does that imply that the first <code>dtype</code> is required? <a href=""https://www.tensorflow.org/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">tf.constant documentation</a> would imply that it does not:</p>

<blockquote>
  <p>If the argument dtype is not specified, then the type is inferred from the type of <code>value</code>.</p>
</blockquote>

<p>But then it would be unnecessary to explicitly type the 3.0 constant above.</p>

<p>I'm just looking for some clarification on this, since, like I said, I'm just starting out.</p>
",tf.constant,tf.constant,2019-05-08 18:51:39,"<blockquote>
  <p>But then it would be unnecessary to explicitly type the 3.0 constant
  above.</p>
</blockquote>

<p>Absolutely correct. </p>

<pre><code>a = tf.constant(3.0, dtype=tf.float32)
</code></pre>

<p>is equivalent to:</p>

<pre><code>a = tf.constant(3.0)
</code></pre>

<p>The documentation is just demonstrating the different overloads. We might choose to explicitly provide the type if we want a different numerical precision (or even just to aid human readability) but if you want the default data type TF infers, then it's entirely unnecessary.</p>
",7287543,1821,https://stackoverflow.com/questions/56047272,Documentation Replication on Other Examples
55909188,How can I apply a TensorFlow 2D Convolution (tf.nn.conv2d) to a single (non-batch) 2D image?,"<p>I would like to use the function <code>tf.nn.conv2d()</code> on a <strong>single</strong> image example, but the TensorFlow documentation seems to only mention applying this transformation to a <strong>batch</strong> of images. </p>

<p>The docs mention that the input image must be of shape <code>[batch, in_height, in_width, in_channels]</code> and the kernel must be of shape <code>[filter_height, filter_width, in_channels, out_channels]</code>. However, what is the most straightforward way to achieve 2D convolution with input shape <code>[in_height, in_width, in_channels]</code>?</p>

<p>Here is an example of the current approach, where <code>img</code> has shape (height, width, channels):</p>

<pre><code>img = tf.random_uniform((10,10,3))  # a single image
img = tf.nn.conv2d([img], kernel)[0] # creating a batch of 1, then indexing the single example
</code></pre>

<p>I am reshaping the input as follows:</p>

<p><code>[in_height, in_width, in_channels]-&gt;[1, in_height, in_width, in_channels]-&gt;[in_height, in_width, in_channels]</code> </p>

<p>This feels like an unnecessary and costly operation when I am only interested in transforming one example.</p>

<p>Is there a simple/standard way to do this that doesn't involve reshaping?</p>
",tf.nn.conv2d,tf.nn.conv2d,2019-04-29 18:47:54,"<p>AFAIK there is no way around it. It seems (<a href=""https://stackoverflow.com/questions/50779869/does-tensorflow-tf-slice-incur-allocation-and-or-memory-copy"">here</a> and <a href=""https://stackoverflow.com/questions/53398721/tensorflow-can-reshape-create-a-copy"">here</a>) that the first operation creates a copy (someone correct me if I'm wrong). You may use <a href=""https://www.tensorflow.org/api_docs/python/tf/expand_dims"" rel=""nofollow noreferrer""><code>tf.expand_dims</code></a> instead though, it's IMO more readable because of it's verbosity.</p>

<p>On the other hand, taking <code>0</code> element from the tensor should not perform a copy in this case and is almost free.</p>

<p><strong>Most importantly</strong>, except for a little inconvenience with syntax (e.g. <code>[0]</code>) those operations definitely <strong>are not costly</strong>, especially in the context of performing convolution.</p>

<p>BTW. Other ready alternative layers like the ones in <code>tf.keras</code>, require batch as first dimension as well.</p>
",9672143,422,https://stackoverflow.com/questions/55909188,Documentation Replication on Other Examples
55764694,How to use gradient_override_map in Tensorflow 2.0?,"<p>I'm trying to use <code>gradient_override_map</code> with Tensorflow 2.0. There is an <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph#gradient_override_map"" rel=""noreferrer"">example in the documentation</a>, which I will use as the example here as well.</p>

<p>In 2.0, <code>GradientTape</code> can be used to compute gradients as follows:</p>

<pre><code>import tensorflow as tf
print(tf.version.VERSION)  # 2.0.0-alpha0

x = tf.Variable(5.0)
with tf.GradientTape() as tape:
    s_1 = tf.square(x)
print(tape.gradient(s_1, x))
</code></pre>

<p>There is also the <code>tf.custom_gradient</code> decorator, which can be used to define the gradient for a <em>new</em> function (again, using the <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/custom_gradient"" rel=""noreferrer"">example from the docs</a>):</p>

<pre><code>import tensorflow as tf
print(tf.version.VERSION)  # 2.0.0-alpha

@tf.custom_gradient
def log1pexp(x):
    e = tf.exp(x)

    def grad(dy):
        return dy * (1 - 1 / (1 + e))

    return tf.math.log(1 + e), grad

x = tf.Variable(100.)

with tf.GradientTape() as tape:
    y = log1pexp(x)

print(tape.gradient(y, x))
</code></pre>

<p>However, I would like to replace the gradient for standard functions such as <code>tf.square</code>. I tried to use the following code:</p>

<pre><code>@tf.RegisterGradient(""CustomSquare"")
def _custom_square_grad(op, grad):
  return tf.constant(0)

with tf.Graph().as_default() as g:
    x = tf.Variable(5.0)
    with g.gradient_override_map({""Square"": ""CustomSquare""}):
        with tf.GradientTape() as tape:
            s_2 = tf.square(x, name=""Square"")

    with tf.compat.v1.Session() as sess:
        sess.run(tf.compat.v1.global_variables_initializer())            
        print(sess.run(tape.gradient(s_2, x)))
</code></pre>

<p>However, there are two issues: The gradient replacement does not seem to work (it is evaluated to <code>10.0</code> instead of <code>0.0</code>) and I need to resort to <code>session.run()</code> to execute the graph. Is there a way to achieve this in ""native"" TensorFlow 2.0?</p>

<p>In TensorFlow 1.12.0, the following produces the desired output:</p>

<pre><code>import tensorflow as tf
print(tf.__version__)  # 1.12.0

@tf.RegisterGradient(""CustomSquare"")
def _custom_square_grad(op, grad):
  return tf.constant(0)

x = tf.Variable(5.0)

g = tf.get_default_graph()
with g.gradient_override_map({""Square"": ""CustomSquare""}):
    s_2 = tf.square(x, name=""Square"")
grad = tf.gradients(s_2, x)

with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  print(sess.run(grad))
</code></pre>
",tf.Graph,tf.Graph,2019-04-19 16:12:29,"<p>There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the <code>tf.custom_gradient</code> decorator as follows:</p>

<pre><code>@tf.custom_gradient
def custom_square(x):
  def grad(dy):
    return tf.constant(0.0)
  return tf.square(x), grad

with tf.Graph().as_default() as g:
  x = tf.Variable(5.0)
  with tf.GradientTape() as tape:
    s_2 = custom_square(x)

  with tf.compat.v1.Session() as sess:
    sess.run(tf.compat.v1.global_variables_initializer())            
    print(sess.run(tape.gradient(s_2, x)))
</code></pre>
",7469434,2559,https://stackoverflow.com/questions/55764694,Documentation Replication on Other Examples
55711355,How to restore dangling tf.py_func within the tf.data.Dataset() with tf.saved_model API?,"<p>After doing a research for restoring the <code>tf.py_func()</code> when using saved_model API in vain, I couldn't find other information than documented in <a href=""https://www.tensorflow.org/api_docs/python/tf/py_func"" rel=""nofollow noreferrer"">tensorflow</a>:</p>

<blockquote>
  <p>The operation must run in the same address space as the Python program that calls <code>tf.py_func()</code>. If you are using distributed TensorFlow, you must run a <code>tf.train.Server</code> in the same process as the program that calls <code>tf.py_func()</code> and you must pin the created operation to a device in that server (e.g. using with <code>tf.device()</code>:)</p>
</blockquote>

<p>Two save/load snippets help to illustrate the situation. </p>

<p><strong>Save part:</strong></p>

<pre><code>def wrapper(x, y):
    with tf.name_scope('wrapper'):
        return tf.py_func(Copy, [x, y], [tf.float32, tf.float32])

def Copy(x, y):
    return x, y

x_ph = tf.placeholder(tf.float32, [None], 'x_ph')
y_ph = tf.placeholder(tf.float32, [None], 'y_ph')

with tf.name_scope('input'):
    ds = tf.data.Dataset.from_tensor_slices((x_ph, y_ph))
    ds = ds.map(wrapper)
    ds = ds.batch(1)
    it = tf.data.Iterator.from_structure(ds.output_types, ds.output_shapes)
    it_init_op = it.make_initializer(ds, name='it_init_op')

x_it, y_it = it.get_next()

# Simple operation
with tf.name_scope('add'):
    res = tf.add(x_it, y_it)

with tf.Session() as sess:
    sess.run([tf.global_variables_initializer(), it_init_op], feed_dict={y_ph: [10] * 10, x_ph: [i for i in range(10)]})
    sess.run([res])
    tf.saved_model.simple_save(sess, './dummy/test', {'x_ph': x_ph, 'y_ph': y_ph}, {'res': res})
</code></pre>

<p><strong>Load part:</strong></p>

<pre><code>graph = tf.Graph()
graph.as_default()
with tf.Session(graph=graph) as sess:
    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], './dummy/test')

    res = graph.get_tensor_by_name('add/Add:0')
    it_init_op = graph.get_operation_by_name('input/it_init_op')
    x_ph = graph.get_tensor_by_name('x_ph:0')
    y_ph = graph.get_tensor_by_name('y_ph:0')
    sess.run([it_init_op], feed_dict={x_ph: [5] * 5, y_ph: [i for i in range(5)]})

    for _ in range(5):
        sess.run([res])
</code></pre>

<p><strong>Error:</strong></p>

<blockquote>
  <p>ValueError: callback pyfunc_0 is not found</p>
</blockquote>

<p>It's well known that the function wrapped by the <code>tf.py_func()</code> isn't saved with the model. Does anybody has a solution to restore this by using the small hint given by the tf doc applying <code>tf.train.Server</code></p>
",tf.py_func,tf.py_function,2019-04-16 15:08:09,"<p>As long as no answer, I will suggest mine, which contour the pb instead of solving it. Struggling for a long time, I finally neglected it by pruning it. Then graft the new input/ouput to it with a simpler way the placeholder. Moreover, this <strong>py_func is deprecated in TF2.0</strong>.</p>
",9217178,533,https://stackoverflow.com/questions/55711355,Lack of Alternative Solutions/Documentation
55703097,Training while loop in Tensorflow,"<p>I've attempted converting a Python-side training loop to Tensorflow to (hypothetically) make the code run faster - not having to pass control over to cpu constantly. However, I can't manage using <code>tf.while_loop</code>.</p>

<p>Here's the code that works:</p>

<pre><code>import numpy as np
import tensorflow as tf

from tqdm import tqdm
from sklearn.datasets import load_iris
from sklearn.preprocessing import RobustScaler

x, y = load_iris(True)
x = RobustScaler().fit_transform(x)

shape = (10, 10)
max_epochs = 1000


graph = tf.Graph()
sess = tf.Session(graph=graph)

x = x.astype(np.float64)


# Construct graph
with graph.as_default():
    weights = tf.get_variable(
        'weights', shape, initializer=tf.constant_initializer, dtype=tf.float64
    )
    curr_epoch = tf.placeholder(dtype=tf.int64, shape=())

    with tf.name_scope('data'):
        data = tf.data.Dataset.from_tensor_slices(x)
        data = data.shuffle(buffer_size=10000)
        data = data.repeat(max_epochs)
        data = data.batch(1)
        data = data.make_one_shot_iterator().get_next()

    with tf.name_scope('update'):
        update_op = make_update_op(weights)

    init = tf.global_variables_initializer()


sess.run(init)

for i in tqdm(range(max_epochs)):
    for _ in range(x.shape[0]):
        sess.run(update_op, feed_dict={
            curr_epoch: i
        })

np_weights = sess.run(weights)
print(np_weights) # Correctly prints an array of 150's.
</code></pre>

<p>Now, if I create an update function to pass <code>tf.while_loop</code>, an error is thrown.</p>

<pre><code>def make_update_op(w):
    return w.assign(
        w + 0.001
    )

# In the code above:
update_op = tf.while_loop(lambda _: True, make_update_op, (weights,), maximum_iterations=x.shape[0])

# No inner loop:
for i in tqdm(range(max_epochs)):
    sess.run(update_op, feed_dict={
        curr_epoch: i
    })
</code></pre>

<blockquote>
  <p>Line 22, in make_update_op
      <code>return w.assign(</code>
  AttributeError: 'Tensor' object has no attribute 'assign'</p>
</blockquote>

<p>I don't quite understand what is happening even after reading the documentation. <code>weights</code> is a <code>Variable</code> after all. What could be done to correctly make the training loop?</p>
",-,-,2019-04-16 7:48:26,"<p>Turns out, all that was missing was the fact that one cannot assign to a variable inside a loop as <a href=""https://stackoverflow.com/a/55707514/7089239"">Vlad pointed out</a>. Instead, one can return the new value of a variable.</p>

<pre><code>def make_update_op(w):
    return w + 0.001

new_w = tf.while_loop(lambda _: True, make_update_op, (weights,), maximum_iterations=x.shape[0])
update_op = weights.assign(new_w)
</code></pre>

<p>To use more variables one would need to return the same amount from the function and unpack them in Python, but the principle is the same.</p>

<pre><code>def make_update_op(w, d):
    return w + 0.001, d

new_w, _ = tf.while_loop(lambda *_: True, make_update_op, (weights, data), maximum_iterations=x.shape[0])
update_op = weights.assign(new_w)
</code></pre>
",7089239,2588,https://stackoverflow.com/questions/55703097,Documentation Replication on Other Examples
55573670,Unexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits,"<p>The TensorFlow documentation for <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> explicitly declares that I should not apply softmax to the inputs of this op:</p>

<blockquote>
  <p>This op expects unscaled logits, since it performs a softmax on logits
  internally for efficiency. Do not call this op with the output of
  softmax, as it will produce incorrect results.</p>
</blockquote>

<p>However if I use cross entropy without softmax it gives me unexpected results. According to <a href=""https://cs231n.github.io/neural-networks-3/#sanitycheck"" rel=""nofollow noreferrer"">CS231n course</a> the expected loss value is around 2.3 for CIFAR-10:</p>

<blockquote>
  <p>For example, for CIFAR-10 with a Softmax classifier we would expect
  the initial loss to be 2.302, because we expect a diffuse probability
  of 0.1 for each class (since there are 10 classes), and Softmax loss
  is the negative log probability of the correct class so: -ln(0.1) =
  2.302.</p>
</blockquote>

<p>However without softmax I get much bigger values, for example 108.91984.</p>

<p>What exactly am I doing wrong with <code>sparse_softmax_cross_entropy_with_logits</code>? The TF code is shown below.</p>

<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.python import keras


(_, _), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_test = np.reshape(x_test, [-1, 32, 32, 3])

y_test = np.reshape(y_test, (10000,))
y_test = y_test.astype(np.int32)

x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3))
y = tf.placeholder(dtype=tf.int32, shape=(None,))

layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x)
layer = tf.nn.relu(layer)
layer = tf.layers.Flatten()(layer)
layer = tf.layers.Dense(units=1000)(layer)
layer = tf.nn.relu(layer)
logits = tf.layers.Dense(units=10)(layer)

# If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)

loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,
                                                      logits=logits)
loss = tf.reduce_mean(loss, name='cross_entropy')

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]})
    print(""loss: "", res)
    # Expected output is value close to 2.3
    # Real outputs are 108.91984, 72.82324, etc.

</code></pre>
",tf.nn.sparse_softmax_cross_entropy_with_logits,tf.nn.sparse_softmax_cross_entropy_with_logits,2019-04-08 12:36:53,"<p>The issue is not in the lines </p>

<pre><code># If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)
</code></pre>

<p>Images in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your <code>x_test</code> by 255 </p>

<pre><code>x_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255
</code></pre>

<p>the values will be rescaled to [0,1] and <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> will return expected values</p>
",9565342,1086,https://stackoverflow.com/questions/55573670,Documentation Replication on Other Examples
55560676,How to use tf.while_loop with eager execution?,"<p>In the documentation, the body of a tf.while_loop needs to be a python callable.</p>

<pre><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>works but</p>

<pre><code>def b(i):
    tf.add(i,1)

i = tf.constant(0)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>throws a ValueError: Attempt to convert a value (None) with an unsupported type() to a Tensor</p>

<p>In 2.0, eager execution is default, I wonder what's the problem?!</p>
",tf.while_loop,tf.while_loop,2019-04-07 15:33:15,"<p>You forgot to add return statement to your function:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def b(i):
    return tf.add(i, 1)

i = tf.constant(0)
c = lambda i: tf.less(i, 10)
tf.while_loop(c, b, [i]) # &lt;tf.Tensor: id=51, shape=(), dtype=int32, numpy=10&gt;
</code></pre>

<p>Note that in your first example function <code>b</code> does return incremented value:</p>

<pre class=""lang-py prettyprint-override""><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
print(b(1).numpy()) # 2
</code></pre>
",7779411,366,https://stackoverflow.com/questions/55560676,Documentation Replicability
55422537,Testing TF serving model fails with bytes as strings and strings as bytes confusion,"<p>I'm having a problem serving my text classification model on <code>Tensorflow 1.12</code>. I'm using <code>tf.estimator.inputs.pandas_input_fn</code> to read in my data, and <code>tf.estimator.DNNClassifier</code> to train/evaluate. I'd then like to serve my model.
(Apologies in advance, it's tough to provide a full working example here, but it's very much like the example TF provides at <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier</a>  )</p>

<p>I'm currently saving my model with ...</p>

<pre class=""lang-py prettyprint-override""><code>...
estimator.export_savedmodel(""./TEST_SERVING/"", self.serving_input_receiver_fn, strip_default_attrs=True)
...
def serving_input_receiver_fn(self):
      """"""An input receiver that expects a serialized tf.Example.""""""

      # feature spec dictionary  determines our input parameters for the model
      feature_spec = {
          'Headline': tf.VarLenFeature(dtype=tf.string),
          'Description': tf.VarLenFeature(dtype=tf.string)
      }

      # the inputs will be initially fed as strings with data serialized by
      # Google ProtoBuffers
      serialized_tf_example = tf.placeholder(
          dtype=tf.string, shape=None, name='input_example_tensor')
      receiver_tensors = {'examples': serialized_tf_example}

      # deserialize input
      features = tf.parse_example(serialized_tf_example, feature_spec)
      return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)


</code></pre>

<p>This actually fails to run with the error:</p>

<pre class=""lang-sh prettyprint-override""><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt; to Tensor. Contents: SparseTensor(indices=Tensor(""ParseExample/ParseExample:0"", shape=(?, 2), 
dtype=int64), values=Tensor(""ParseExample/ParseExample:2"", shape=(?,), dtype=string), dense_shape=Tensor(""ParseExample/ParseExample:4"", shape=(2,), dtype=int64)). Consider casting elements to a supported type.

</code></pre>

<p>I tried to save a second way doing:</p>

<pre class=""lang-py prettyprint-override""><code>def serving_input_receiver_fn(self):
  """"""Build the serving inputs.""""""
  INPUT_COLUMNS = [""Headline"",""Description""]
  inputs = {}
  for feat in INPUT_COLUMNS:
    inputs[feat] = tf.placeholder(shape=[None], dtype=tf.string, name=feat)
  return tf.estimator.export.ServingInputReceiver(inputs, inputs)
</code></pre>

<p>This actually works, until I try testing it with the <code>saved_model_cli</code>.
Some output for <code>saved_model_cli show --all --dir TEST_SERVING/1553879255/</code>:</p>

<pre class=""lang-sh prettyprint-override""><code>MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['predict']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['Description'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Description:0
    inputs['Headline'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Headline:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['class_ids'] tensor_info:
        dtype: DT_INT64
        shape: (-1, 1)
        name: dnn/head/predictions/ExpandDims:0
    outputs['classes'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: dnn/head/predictions/str_classes:0
    outputs['logits'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/logits/BiasAdd:0
    outputs['probabilities'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/head/predictions/probabilities:0
  Method name is: tensorflow/serving/predict

</code></pre>

<p>But now I can't seem to test it.</p>

<pre class=""lang-sh prettyprint-override""><code>&gt;&gt;&gt; saved_model_cli run --dir TEST_SERVING/1553879255/ --tag_set serve --signature_def predict --input_examples 'inputs=[{""Description"":[""What is going on""],""Headline"":[""Help me""]}]'
Traceback (most recent call last):
 ...
  File ""/Users/Josh/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 489, in _create_example_string
    feature_list)
TypeError: 'What is going on' has type str, but expected one of: bytes

</code></pre>

<p>Ok, lets turn it into a bytes object by changing to <code>b[""What is going on""]</code> and <code>b[""Help me""]</code>...</p>

<pre class=""lang-sh prettyprint-override""><code>ValueError: Type &lt;class 'bytes'&gt; for value b'What is going on' is not supported for tf.train.Feature.
</code></pre>

<p>Any ideas/thoughts??
Thanks!</p>
",tf.estimator.DNNClassifier,tf.compat.v1.estimator.DNNClassifier,2019-03-29 17:18:28,"<p>Ok, so eventually I found the answer, quoted in <a href=""https://stackoverflow.com/questions/51482730/tensorflow-how-to-export-estimator-using-tensorhub-module"">TensorFlow: how to export estimator using TensorHub module?</a> </p>

<p>The problem was with serialization stuff I don't really understand. The solution allows to pass raw strings to <code>tf.estimator.export.build_raw_serving_input_receiver_fn</code> instead.</p>

<p>My saving funciton now looks like this:</p>

<pre class=""lang-py prettyprint-override""><code>  def save_serving_model(self,estimator):
      feature_placeholder = {'Headline': tf.placeholder('string', [1], name='headline_placeholder'),
      'Description': tf.placeholder('string', [1], name='description_placeholder')}
      serving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholder)

      estimator.export_savedmodel(""TEST_SERVING/"", serving_input_fn)
</code></pre>

<p>where using the <code>saved_model_cli</code> works. I.e.:</p>

<pre class=""lang-sh prettyprint-override""><code>saved_model_cli run --dir /path/to/model/ --tag_set serve --signature_def predict --input_exprs=""Headline=['Finally, it works'];Description=['Yay, it works']"" 

</code></pre>

<pre class=""lang-sh prettyprint-override""><code>Result for output key class_ids:
[[2]]
Result for output key classes:
[[b'2']]
Result for output key logits:
[[-0.56755465  0.31625098  0.39260274]]
Result for output key probabilities:
[[0.16577701 0.40119565 0.4330274 ]]
</code></pre>
",5088987,276,https://stackoverflow.com/questions/55422537,Documentation Replication on Other Examples
55363728,How to feed .h5 files in tf.data pipeline in tensorflow model,"<p>I'm trying to optimize the input pipeline for .h5 data with tf.data. But I encountered a <code>TypeError: expected str, bytes or os.PathLike object, not Tensor</code>. I did a research but can't find anything about converting a tensor of string to string.</p>

<p>This simplified code is executable and return the same error:</p>

<pre><code>batch_size = 1000
conv_size = 3
nb_conv = 32
learning_rate = 0.0001

# define parser function
def parse_function(fname):
    with h5py.File(fname, 'r') as f: #Error comes from here
        X = f['X'].reshape(batch_size, patch_size, patch_size, 1)
        y = f['y'].reshape(batch_size, patch_size, patch_size, 1)
        return X, y

# create a list of files path
flist = []
for dirpath, _, fnames in os.walk('./proc/'):
    for fname in fnames:
        if fname.startswith('{}_{}'.format(patch_size, batch_size)) and fname.endswith('h5'):
            flist.append(fname)

# prefetch data
dataset = tf.data.Dataset.from_tensor_slices((flist))
dataset = dataset.shuffle(len(flist))
dataset = dataset.map(parse_function, num_parallel_calls=4)
dataset = dataset.batch(1)
dataset = dataset.prefetch(3)

# simplest model that I think of
X_ph = tf.placeholder(tf.float32, shape=None)
y_ph = tf.placeholder(tf.float32, shape=None)
W = tf.get_variable('w', shape=[conv_size, conv_size, 1, 1], initializer=tf.contrib.layers.xavier_initializer())
loss = tf.reduce_mean(tf.losses.mean_squared_error(tf.nn.softmax(labels=y_ph, predictions=tf.matmul(X_ph, W))))
train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)

# start session
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(train_op, feed_dict={X_ph: dataset[0], y_ph: dataset[1]}))
</code></pre>

<p>Apparently the <code>fname</code> is a tensor of string but the positional argument waits for only a string. I can't find any documentation on this. And the answer of <a href=""https://stackoverflow.com/questions/45246764/how-to-convert-a-string-tensor-to-a-python-string-in-tensorflow"">another post</a> doesn't solve this problem. In my case, I work only with h5 where one h5 store one batch.</p>

<hr>

<p><strong>Update Solution:</strong>
Thanks to the comment of @kvish, the part of loading .h5 file is solved.
The code is upgraded with a simple conv layer, the placeholders have been taken. <strong>Each .h5 is one batch.</strong> I want to prefetch in parallele multiple batches(h5py doesn't support multithread reading so I write batches into multiple files). One can <strong>copy-paste-and-launch</strong>:</p>

<pre><code>import h5py
import threading
import numpy as np
import tensorflow as tf

# generate some img data
for i in range(5):
    with h5py.File('./test_{}.h5'.format(i), 'w') as f:
        f.create_dataset('X', shape=(1000, 100, 100), dtype='float32', data=np.random.rand(10**7).reshape(1000, 100, 100))
        f.create_dataset('y', shape=(1000, 100, 100), dtype='float32', data=np.random.rand(10**7).reshape(1000, 100, 100))
        print(threading.get_ident())

# params
num_cores = 3
shuffle_size = 1
batch_size = 1

# read .h5 file
def parse_file(f):
    print(f.decode('utf-8'))
    with h5py.File(f.decode(""utf-8""), 'r') as fi:
        X = fi['X'][:].reshape(1000, 100, 100, 1)
        y = fi['y'][:].reshape(1000, 100, 100, 1)
        print(threading.get_ident())  # to see the thread id
        return X, y

# py_func wrapper
def parse_file_tf(filename):
    return tf.py_func(parse_file, [filename], [tf.float32, tf.float32])

# tf.data input pipeline
files = tf.data.Dataset.list_files('./test_*.h5')
dataset = files.map(parse_file_tf, num_parallel_calls=num_core)
dataset = dataset.batch(batch_size).shuffle(shuffle_size).prefetch(3)
it = dataset.make_initializable_iterator()
iter_init_op = it.initializer
X_it, y_it = it.get_next()

# simplest model that I can think of 
with tf.name_scope(""Conv1""):
    W = tf.get_variable(""W"", shape=[3, 3, 1, 1],
                         initializer=tf.contrib.layers.xavier_initializer())
    b = tf.get_variable(""b"", shape=[1], initializer=tf.contrib.layers.xavier_initializer())
    layer1 = tf.nn.conv2d(X_it, W, strides=[1, 1, 1, 1], padding='SAME') + b
    out = tf.nn.relu(layer1)

loss = tf.reduce_mean(tf.losses.mean_squared_error(labels=y_it, predictions=out))
train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)

# session
sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run(iter_init_op)
sess.run([train_op])
sess.close()
</code></pre>

<hr>

<p>Somehow there will be another cudnn issue which isn't related to this post.</p>

<p>tensorflow-cpu v1.12: work fine</p>

<p>tensorflow-gpu v1.12: <strong>runtime</strong> issue happens</p>

<blockquote>
  <p>Traceback (most recent call last):   File
  ""/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py"",
  line 1334, in _do_call
      return fn(*args)   File ""/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py"",
  line 1319, in _run_fn
      options, feed_dict, fetch_list, target_list, run_metadata)   File ""/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py"",
  line 1407, in _call_tf_sessionrun
      run_metadata) tensorflow.python.framework.errors_impl.NotFoundError: No algorithm
  worked!    [[{{node Conv1/Conv2D}} = Conv2D[T=DT_FLOAT,
  data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""SAME"",
  strides=[1, 1, 1, 1], use_cudnn_on_gpu=true,
  _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients/Conv1/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer,
  W/read)]]      [[{{node
  mean_squared_error/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_2/_37}}
  = _Recvclient_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"",
  send_device=""/job:localhost/replica:0/task:0/device:GPU:0"",
  send_device_incarnation=1, tensor_name=""edge_63_me...t/Switch_2"",
  tensor_type=DT_INT32,
  _device=""/job:localhost/replica:0/task:0/device:CPU:0""]]
  tensorflow-cpu v1.12: works fine!</p>
</blockquote>
",-,-,2019-03-26 18:10:29,"<p>Here is an example of how you can wrap the function with the help of <a href=""https://www.tensorflow.org/api_docs/python/tf/py_func"" rel=""nofollow noreferrer"">py_func</a>. Do note that this is deprecated in TF V2. You can follow the documentation for further details.</p>

<pre><code>def parse_function_wrapper(filename):
   # Assuming your data and labels are float32
   # Your input is parse_function, who arg is filename, and you get X and y as output
   # whose datatypes are indicated by the tuple argument  
   features, labels = tf.py_func(
       parse_function, [filename], (tf.float32, tf.float32)) 
   return features, labels

# Create dataset of filenames.
dataset = tf.data.Dataset.from_tensor_slices(flist)
dataset = dataset.shuffle(len(flist))
dataset = dataset.map(parse_function_wrapper)
</code></pre>
",9217178,533,https://stackoverflow.com/questions/55363728,Lack of Alternative Solutions/Documentation
55176818,How to support masking in custom tf.keras.layers.Layer,"<p>I'm implementing a custom <code>tf.keras.layers.Layer</code> that needs to support masking.</p>

<p>Consider the following scenario</p>

<pre class=""lang-py prettyprint-override""><code>embedded = tf.keras.layer.Embedding(input_dim=vocab_size + 1, 
                                    output_dim=n_dims, 
                                    mask_zero=True)
x = MyCustomKerasLayers(embedded)
</code></pre>

<p>Now per the documentation</p>

<blockquote>
  <p><code>mask_zero</code>: Whether or not the input value 0 is a special ""padding"" value that should be masked out. This is useful when using recurrent layers which may take variable length input. <strong>If this is True then all subsequent layers in the model need to support masking or an exception will be raised</strong>. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).</p>
</blockquote>

<p>I wonder, what does that mean? Looking through <a href=""https://www.tensorflow.org/tutorials/eager/custom_layers"" rel=""noreferrer"">TensorFlow's custom layers guide</a> and the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer"" rel=""noreferrer"">tf.keras.layer.Layer</a> documentation it is not clear what should be done to support masking</p>

<ol>
<li><p>How do I support masking?</p></li>
<li><p>How do I access the mask from the past layer? </p></li>
<li><p>Assuming input of <code>(batch, time, channels)</code> or `(batch, time) would the masks look different? What will be their shapes?</p></li>
<li><p>How do I pass it on to the next layer? </p></li>
</ol>
",tf.keras.layers.Layer,tf.keras.layers.Layer,2019-03-15 6:31:12,"<ol>
<li><p>To support masking one should implement the <code>compute_mask</code> method inside the custom layer</p></li>
<li><p>To access the mask, simply add as the second positional argument in the <code>call</code> method the argument <code>mask</code>, and it will be accessible (ex. <code>call(self, inputs, mask=None)</code>)</p></li>
<li><p>This cannot be guessed, it is the layer's before responsible to calculate the mask </p></li>
<li><p>Once you implemented the <code>compute_mask</code> passing the mask to the next layer happens automatically - excluding the case of model subclassing, which in this case it is up to you to calculate masks and pass them on.</p></li>
</ol>

<p>Example:</p>

<pre class=""lang-py prettyprint-override""><code>class MyCustomKerasLayers(tf.keras.layers.Layer):
    def __init__(self, .......):
        ...

    def compute_mask(self, inputs, mask=None):
        # Just pass the received mask from previous layer, to the next layer or 
        # manipulate it if this layer changes the shape of the input
        return mask

    def call(self, input, mask=None):
        # using 'mask' you can access the mask passed from the previous layer
</code></pre>

<p>Notice that this example just passes on the mask, if the layer will output a shape different than the one received, you should change the mask accordingly in <code>compute_mask</code> to pass on the correct one</p>

<h3>EDIT</h3>

<p>Now explanation is also included in the <a href=""https://www.tensorflow.org/beta/guide/keras/masking_and_padding"" rel=""nofollow noreferrer""><code>tf.keras</code> masking and padding documentation</a>.</p>
",5368083,12085,https://stackoverflow.com/questions/55176818,Lack of Alternative Solutions/Documentation
55109696,TensorFlow - Difference between tf.keras.layers.Layer vs tf.keras.Model,"<p>Reading through the <a href=""https://www.tensorflow.org/tutorials/eager/custom_layers"" rel=""noreferrer"">documentation of implementing custom layers</a> with <code>tf.keras</code>, they specify two options to inherit from, <code>tf.keras.Layer</code> and <code>tf.keras.Model</code>.</p>

<p>Under the context of <em>creating custom layers</em>, I'm asking myself what is the difference between these two? Technically what is different?</p>

<p>If I were to implement the transformer encoder for example, which one would be more suitable? (assuming the transformer is a only a ""layer"" in my full model)</p>
",tf.keras,tf.keras,2019-03-11 20:14:39,"<p>In the documentation:</p>

<blockquote>
  <p>The Model class has the same API as Layer, with the following
  differences: - It exposes built-in training, evaluation, and
  prediction loops (model.fit(), model.evaluate(), model.predict()). -
  It exposes the list of its inner layers, via the model.layers
  property. - It exposes saving and serialization APIs.</p>
  
  <p>Effectively, the ""Layer"" class corresponds to what we refer to in the
  literature as a ""layer"" (as in ""convolution layer"" or ""recurrent
  layer"") or as a ""block"" (as in ""ResNet block"" or ""Inception block"").</p>
  
  <p>Meanwhile, the ""Model"" class corresponds to what is referred to in the
  literature as a ""model"" (as in ""deep learning model"") or as a
  ""network"" (as in ""deep neural network"").</p>
</blockquote>

<p>So if you want to be able to call <code>.fit()</code>, <code>.evaluate()</code>, or <code>.predict()</code> on those blocks or you want to be able to save and load those blocks separately or something you should use the Model class. The Layer class is leaner so you won't bloat the layers with unnecessary functionality...but I would guess that that generally wouldn't be a big problem.  </p>
",5368083,12085,https://stackoverflow.com/questions/55109696,Documentation Replication on Other Examples
55094952,Understanding Tensorflow control dependencies,"<p>I am trying to gain a stronger grasp of TensorFlow. I came across the concept of control dependencies. I understand that the order of ops as specified by us is not really relevant to Tensorflow during execution. In order to optimise the speed of execution TensorFlow decides its own order of calculating nodes. 
But we can customise order of execution by using tf.control_dependencies.
I am not able to understand the use cases of the function. Can anyone direct me to some resource(other than the documentation) or explain the working of this function?
An example:</p>

<pre><code>tf.reset_default_graph()
x = tf.Variable(5)
y=tf.Variable(3)
assign = tf.assign(x,x+y)
z = x+assign
with tf.Session() as sess:
   sess.run(tf.global_variables_initializer())
   with tf.control_dependencies([assign]):
        z_out = sess.run(z)

print(z_out)
</code></pre>

<p>The output of the code is 8. So I infer that since z=x+y,the assign node has not been evaluated(right?). But doesn't this mean that the result of tensorflow may be erroneous? This means we need to create new nodes during every operation to force TensorFlow to calculate all the nodes leading up to the result. But in say training a neural network with 10000 steps if each step creates a new set of 1000 weights/parameters won't the space complexity explode?</p>
",-,-,2019-03-11 3:42:04,"<p>In the snippet you have posted, <a href=""https://www.tensorflow.org/api_docs/python/tf/control_dependencies"" rel=""noreferrer""><code>tf.control_dependencies</code></a> is not having any effect. The function creates a context where <strong>new operations</strong> are created with a control dependency to the given operations, but in your code there are no new operations within the context, just evaluation of previously existing operations.</p>

<p>In most cases, control flow in TensorFlow is ""obvious"", in the sense that there is only one way to make a computation correctly. However, when stateful objects (i.e. variables) are involved, there are situations that may be ambiguous. Consider the following example:</p>

<pre><code>import tensorflow as tf

v1 = tf.Variable(0)
v2 = tf.Variable(0)
upd1 = tf.assign(v1, v2 + 1)
upd2 = tf.assign(v2, v1 + 1)
init = tf.global_variables_initializer()
</code></pre>

<p><code>v1</code> and <code>v2</code> are both variables initialized to <code>0</code> and then updated. However, each use the value of the other variable in the update. In a regular Python program things would run sequentially, so <code>upd1</code> would run first (so <code>v1</code> would be <code>1</code>) and <code>upd2</code> after (so <code>v2</code> would be <code>2</code>, because <code>v1</code> was <code>1</code>). But TensorFlow does not record the order in which operations are created, only their dependencies. So it may also happen that <code>upd2</code> runs before <code>upd1</code> (so <code>v1</code> would be <code>2</code> and <code>v2</code> would be <code>1</code>) or that both update values (<code>v2 + 1</code> and <code>v1 + 1</code>) are computed before the assignments (so both <code>v1</code> and <code>v2</code> would be <code>1</code> in the end). Indeed, if I run it several times:</p>

<pre><code>for i in range(10):
    with tf.Session() as sess:
        sess.run(init)
        sess.run([upd1, upd2])
        print(*sess.run([v1, v2]))
</code></pre>

<p>I do not always get the same result (personally I get <code>1 1</code> and <code>2 1</code>, although technically <code>1 2</code> would also be possible). If for example you wanted to compute the new value for <code>v2</code> after <code>v1</code> has been updated, you could just do the following:</p>

<pre><code>import tensorflow as tf

v1 = tf.Variable(0)
v2 = tf.Variable(0)
upd1 = tf.assign(v1, v2 + 1)
upd2 = tf.assign(v2, upd1 + 1)
init = tf.global_variables_initializer()
</code></pre>

<p>Here the new value <code>v2</code> is computed using <code>upd1</code>, which is guaranteed to be the value of the variable after the update. So here <code>upd2</code> would have an implicit dependency to the assignment, and so things would work as expected.</p>

<p>But what if you wanted to always compute the new values for <code>v1</code> and <code>v2</code> using the non-updated variable values (that is, consistently end up with both <code>v1</code> and <code>v2</code> being <code>1</code>)? In that case you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/control_dependencies"" rel=""noreferrer""><code>tf.control_dependencies</code></a>:</p>

<pre><code>import tensorflow as tf

v1 = tf.Variable(0)
v2 = tf.Variable(0)
new_v1 = v2 + 1
new_v2 = v1 + 1
with tf.control_dependencies([new_v1, new_v2]):
    upd1 = tf.assign(v1, new_v1)
    upd2 = tf.assign(v2, new_v2)
init = tf.global_variables_initializer()
</code></pre>

<p>Here, the assignment operations cannot happen until the new values for <code>v1</code> and <code>v2</code> have been computed, so their final values will always be <code>1</code> in both cases.</p>
",10726895,115,https://stackoverflow.com/questions/55094952,Inadequate Examples
55005915,How to resize image to put into tf.train.Example,"<p>I have an image (JPEG or PNG) as a byte buffer (read from the internet), and this is the way I was putting it in a <code>tf.train.Example</code> before:</p>

<pre><code>record = tf.train.Example(features=tf.train.Features(feature={
    'image/encoded': dataset_util.bytes_feature(image_bytes)
    # there are more features but they're not relevant
}))
</code></pre>

<p>However, for my usecase, the images are too big, so I'd like to resize them either before I put them in the <code>tf.train.Example</code> or just after (whichever is easiest).</p>

<p>Here's what I'm trying:</p>

<pre><code># predeclared
# - image_bytes
# - image_format
# - height
# - width

# resize image
if image_format == b'jpeg':
    image = tf.image.decode_jpeg(image_bytes, None, tf.float32)
elif image_format == b'png':
    image = tf.image.decode_png(image_bytes, None, tf.float32)

image = tf.image.resize_images(image, (int(height), int(width)))

image = tf.image.convert_image_dtype(image, tf.uint8)
record = tf.train.Example(features=tf.train.Features(feature={
    'image/encoded': dataset_util.bytes_feature(tf.image.encode_jpeg(image))
    # there are more features but they're not relevant
}))
</code></pre>

<p>I suspect this is valid right up until I actually try to put it in the <code>tf.train.Example</code>, at which point it tells me <code>TypeError: &lt;tf.Tensor 'EncodeJpeg:0' shape=() dtype=string&gt; has type Tensor, but expected one of: bytes</code>. I've tried figuring out how to get the <code>Tensor</code> into a <code>BytesList</code> or something like it, but I haven't been able to find any documentation for this. I suspect there may be a better way to approach the entire process however.</p>

<p>How can I do this the right way?</p>
",tf.train.Example,tf.train.Example,2019-03-05 15:11:05,"<p>You can resize prior to encoding. </p>

<pre><code>def int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
</code></pre>

<p>Convert from string and resize </p>

<pre><code>image = numpy.fromstring(byte_arr).reshape((height, width, channels))
image_raw = image.tostring()
</code></pre>

<p>Then serialize as tfrecords file</p>

<pre><code>writer = tf.python_io.TFRecordWriter(tfr_name)
example = tf.train.Example(features=tf.train.Features(feature{'height':int64_feature(height),
                                                              'width': int64_feature(width),
                                                              'channels': int64_feature(channels),
                                                              'image_raw': bytes_feature(image_raw),

writer.write(example.SerializeToString())
writer.close()
</code></pre>
",1129436,3136,https://stackoverflow.com/questions/55005915,Lack of Alternative Solutions/Documentation
54686895,Tensorflow dilation behave differently than morphological dilation,"<p>As the following piece of code shows, the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dilation2d"" rel=""noreferrer"">tensorflow <code>tf.nn.dilation2D</code> function</a> doesn't behave as a <a href=""https://homepages.inf.ed.ac.uk/rbf/HIPR2/dilate.htm"" rel=""noreferrer"">conventional dilation operator</a>. </p>

<pre><code>import tensorflow as tf
tf.InteractiveSession()
A = [[0, 0, 0, 0, 0, 0, 0],
     [0, 0, 0, 0, 1, 0, 0],
     [0, 0, 0, 1, 1, 1, 0],
     [0, 0, 0, 0, 1, 0, 0],
     [0, 0, 0, 0, 0, 0, 0],
     [0, 0, 0, 0, 0, 0, 0]]
kernel = tf.ones((3,3,1))
input4D = tf.cast(tf.expand_dims(tf.expand_dims(A, -1), 0), tf.float32)
output4D = tf.nn.dilation2d(input4D, filter=kernel, strides=(1,1,1,1), rates=(1,1,1,1), padding=""SAME"")
print(tf.cast(output4D[0,:,:,0], tf.int32).eval())
</code></pre>

<p>Returns the following tensor:</p>

<pre><code>array([[1, 1, 1, 2, 2, 2, 1],
       [1, 1, 2, 2, 2, 2, 2],
       [1, 1, 2, 2, 2, 2, 2],
       [1, 1, 2, 2, 2, 2, 2],
       [1, 1, 1, 2, 2, 2, 1],
       [1, 1, 1, 1, 1, 1, 1]], dtype=int32)
</code></pre>

<p>I don't understand neither <strong>why</strong> it behaves like that, neither <strong>how</strong> I should use <code>tf.nn.dilation2d</code> to retrieve the expected output:</p>

<pre><code>array([[0, 0, 0, 1, 1, 1, 0],
       [0, 0, 1, 1, 1, 1, 1],
       [0, 0, 1, 1, 1, 1, 1],
       [0, 0, 1, 1, 1, 1, 1],
       [0, 0, 0, 1, 1, 1, 0],
       [0, 0, 0, 0, 0, 0, 0]], dtype=int32)
</code></pre>

<p>Can someone enlighten the succinct documentation of tensorflow and give an explanation of what the the <code>tf.nn.dilation2D</code> function does ?</p>
",tf.nn.dilation2D,tf.nn.dilation2D,2019-02-14 9:19:44,"<p>As mentioned in the documentation page linked,</p>

<blockquote>
  <p>Computes the grayscale dilation of 4-D input and 3-D filter tensors.</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>In detail, the grayscale morphological 2-D dilation is the max-sum correlation [...]</p>
</blockquote>

<p>What this means is that the kernel's values are added to the image's values at each position, then the maximum value is taken as the output value.</p>

<p>Compare this to correlation, replacing the multiplication with an addition, and the integral (or sum) with the maximum:</p>

<p>&nbsp; &nbsp; &nbsp; convolution: <em>g</em>(<em>t</em>) =  <em>f</em>() <em>h</em>(-<em>t</em>) d</p>

<p>&nbsp; &nbsp; &nbsp; dilation: <em>g</em>(<em>t</em>) = max<sub></sub> { <em>f</em>() + <em>h</em>(-<em>t</em>) }</p>

<p>Or in the discrete world:</p>

<p>&nbsp; &nbsp; &nbsp; convolution: <em>g</em>[<em>n</em>] = <sub><em>k</em></sub> <em>f</em>[<em>k</em>] <em>h</em>[<em>k</em>-<em>n</em>]</p>

<p>&nbsp; &nbsp; &nbsp; dilation: <em>g</em>[<em>n</em>] = max<sub><em>k</em></sub> { <em>f</em>[<em>k</em>] + <em>h</em>[<em>k</em>-<em>n</em>] }</p>

<hr>

<p>The dilation with a binary structuring element (kernel, what the question refers to as a conventional dilation) uses a structuring element (kernel) that contains only 1s and 0s. These indicate included and excluded. That is, the 1s determine the domain of the structuring element.</p>

<p>To recreate the same behavior with a grey-value dilation, set the included pixels to 0 and the excluded pixels to minus infinity.</p>

<p>For example, the 3x3 square structuring element used in the question should be a 3x3 matrix of zeros.</p>
",1782553,1477,https://stackoverflow.com/questions/54686895,Documentation Ambiguity
54047604,How to assign custom gradient to TensorFlow op with multiple inputs,"<p>I'm trying to use TensorFlow's <code>@tf.custom_gradient</code> functionality to assign a custom gradient to a function with multiple inputs.  I can put together a working setup for only one input, but not for two or more.</p>

<p>I've based my code on <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">TensorFlow's custom_gradient documentation</a>, which works just fine for one input, as in this example:</p>

<pre><code>import tensorflow as tf
import os

# Suppress Tensorflow startup info
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

# Custom gradient decorator on a function,
# as described in documentation
@tf.custom_gradient
def my_identity(x):

    # The custom gradient
    def grad(dy):
        return dy

    # Return the result AND the gradient
    return tf.identity(x), grad

# Make a variable, run it through the custom op
x = tf.get_variable('x', initializer=1.)
y = my_identity(x)

# Calculate loss, make an optimizer, train the variable
loss = tf.abs(y)
opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)
train = opt.minimize(loss)

# Start a TensorFlow session, initialize variables, train
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(train)
</code></pre>

<p>This example runs silently, then closes.  No issues, no errors.  The variable optimizes as expected.  However, in my application, I need to do such a calculation with multiple inputs, so something of this form:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad
</code></pre>

<p>Running this in place of the example (and adding another variable input to the call of <code>my_identify</code>) results in the following error output.  Best as I can tell, the last parts of the error are from the dynamic generation of the op -- the information format matches the C++ formatting required in the op establishment (though that's about all I know about it).</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 27, in &lt;module&gt;
    train = opt.minimize(loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 400, in minimize
    grad_loss=grad_loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 519, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 630, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 821, in _GradientsHelper
    _VerifyGeneratedGradients(in_grads, op)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 323, in _VerifyGeneratedGradients
    ""inputs %d"" % (len(grads), op.node_def, len(op.inputs)))
ValueError: Num gradients 2 generated for op name: ""IdentityN""
op: ""IdentityN""
input: ""Identity""
input: ""x/read""
input: ""y/read""
attr {
  key: ""T""
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_gradient_op_type""
  value {
    s: ""CustomGradient-9""
  }
}
 do not match num inputs 3
</code></pre>

<p>Based on other custom gradient options, I surmised that the issue was a lack of supplied gradient for the second input argument.  So, I changed my function to this:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad, grad
</code></pre>

<p>This results in the following more familiar error:</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 22, in &lt;module&gt;
    y = my_identity(x, z)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 111, in decorated
    return _graph_mode_decorator(f, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 132, in _graph_mode_decorator
    result, grad_fn = f(*args)
ValueError: too many values to unpack (expected 2)
</code></pre>

<p>The <code>@custom_gradient</code> decorator is only identifying the last returned element as a gradient.  So, I tried putting the two gradients into a tuple as <code>(grad, grad)</code> such that there would only be ""two"" outputs for the function.  TensorFlow rejected this too, this time because it can't call a tuple like it would a Tensor -- entirely reasonable, in hindsight.</p>

<p>I've fussed around with the example some more, but to no avail.  No matter what I try, I can't get the custom-defined gradient to deal with multiple inputs.  I'm hoping that somebody with more knowledge than I regarding custom ops and gradients will have a better idea on this -- thanks in advance for the help!</p>
",tf.custom_gradient,tf.custom_gradient,2019-01-04 23:45:09,"<p>If we use multiple variables as input, the number of gradients return from ""grad"" function should be equals to number of input variables, though we maybe don't care about some of them. </p>

<p>For example:</p>

<pre><code>@tf.custom_gradient
def my_multiple(x,z):

def grad(dy):
    # return two gradients, one for 'x' and one for 'z'
    return (dy*z, dy*x)

return tf.identity(x*z), grad
</code></pre>

<p>Note that the second output of ""my_multiple"" is a function, not a gradient tensor. </p>
",10554082,119,https://stackoverflow.com/questions/54047604,Documentation Replication on Other Examples
53919290,tensorflow sparse categorical cross entropy with logits,"<p>I am a novice programmer trying to follow <a href=""https://www.tensorflow.org/tutorials/sequences/text_generation"" rel=""nofollow noreferrer"">this</a> guide.
However, I ran across an issue. The guide says to define the loss function as:</p>

<pre><code>def loss(labels, logits):
    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)
</code></pre>

<p>This gives me the following error:</p>

<blockquote>
  <p>sparse_categorical_crossentropy() got an unexpected keyword argument
  'from_logits'</p>
</blockquote>

<p>which I take to mean that <code>from_logits</code> is an argument not specified in the function, which is supported by the documentation, which that <code>tf.keras.losses.sparse_categorical_crossentropy()</code> has only two possible inputs. </p>

<p>Is there a way to specify that logits are being used or is that even necesarry?</p>
",-,-,2018-12-25 4:10:02,"<p>The <code>from_logits</code> parameter is introduced in Tensorflow 1.13.</p>

<p>You can compare 1.12 and 1.13 with these urls:</p>

<pre><code>https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/keras/losses.py
https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/losses.py
</code></pre>

<p>1.13 is not released at the time of writing. This is why the tutorial starts with the line</p>

<pre><code>!pip install -q tf-nightly
</code></pre>
",9185745,175,https://stackoverflow.com/questions/53919290,Documentation Replication on Other Examples
53649402,Disable TensorBoard logging on tf.Estimator methods,"<p>Is there a way disable the automatic TensorBoard logging when using the <code>tf.estimator.Estimator</code> class?</p>

<pre><code># Classifier
classifier = tf.estimator.Estimator(
    model_fn=lambda features, labels, mode, params: model(features, labels, mode, params, word_embeddings),
    params=params,
    model_dir=str(MODEL_DIR),
    tensorboard=Fasle)  # &lt;---- Something like that?

for _ in range(params['epochs']):
    classifier.train(input_fn=lambda: input_fn(generator, example_generator._data['train'] ,batch_size=params['batch_size']))
    classifier.evaluate(input_fn=lambda: input_fn(generator, example_generator._data['validation'], batch_size=params['batch_size']))
</code></pre>

<p>I read through the <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig"" rel=""nofollow noreferrer""><code>tf.estimator.RunConfig</code></a> and couldn't find a solution.</p>
",-,-,2018-12-06 10:33:07,"<p>Instantiating RunConfig for Estimator with <code>save_summary_steps=None</code> should fix this</p>
",5368083,12085,https://stackoverflow.com/questions/53649402,Lack of Alternative Solutions/Documentation
53578484,tf.gather with indices of higher dimention than input data?,"<p>Reading <a href=""https://github.com/WangYueFt/dgcnn"" rel=""nofollow noreferrer"">Dynamic Graph CNN for Learning on Point Clouds</a> code, I came across this snippet:</p>

<pre><code>  idx_ = tf.range(batch_size) * num_points
  idx_ = tf.reshape(idx_, [batch_size, 1, 1]) 

  point_cloud_flat = tf.reshape(point_cloud, [-1, num_dims])
  point_cloud_neighbors = tf.gather(point_cloud_flat, nn_idx+idx_)  &lt;--- what happens here?
  point_cloud_central = tf.expand_dims(point_cloud_central, axis=-2)
</code></pre>

<p>debugging the line I made sure that the dims are</p>

<pre><code>point_cloud_flat:(32768,3) nn_idx:(32,1024,20), idx_:(32,1,1) 
// indices are (32,1024,20) after broadcasting
</code></pre>

<p>Reading the <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer"">tf.gather doc</a> I couldn't understand what the function does with dimensions higher that the input dimensions</p>
",tf.gather,tf.gather,2018-12-02 8:04:32,"<p>An equivalent function in numpy is <code>np.take</code>, a simple example:</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np

params = np.array([4, 3, 5, 7, 6, 8])

# Scalar indices; (output is rank(params) - 1), i.e. 0 here.
indices = 0
print(params[indices])

# Vector indices; (output is rank(params)), i.e. 1 here.
indices = [0, 1, 4]
print(params[indices])  # [4 3 6]

# Vector indices; (output is rank(params)), i.e. 1 here.
indices = [2, 3, 4]
print(params[indices])  # [5 7 6]

# Higher rank indices; (output is rank(params) + rank(indices) - 1), i.e. 2 here
indices = np.array([[0, 1, 4], [2, 3, 4]])
print(params[indices])  # equivalent to np.take(params, indices, axis=0)
# [[4 3 6]
# [5 7 6]]
</code></pre>

<p>In your case, the rank of <code>indices</code> is higher than <code>params</code>, so output is rank(<code>params</code>) + rank(<code>indices</code>) - 1 (i.e. 2 + 3 - 1 = 4, i.e. (32, 1024, 20, 3)). The <code>- 1</code> is because the <code>tf.gather(axis=0)</code> and <code>axis</code> must be rank 0 (so a scalar) at this moment. So the <code>indices</code> takes the elements of the first dimension (<code>axis=0</code>) in a ""fancy"" indexing way.</p>

<p><strong>EDITED</strong>:</p>

<p>In brief, in your case, (if I didn't misunderstand the code)</p>

<ul>
<li><code>point_cloud</code> is (32, 1024, 3), 32 batches 1024 points which have 3
coordinates. </li>
<li><code>nn_idx</code> is (32, 1024, 20), indices of 20 neighbors of
32 batches 1024 points. The indices are for indexing in <code>point_cloud</code>. </li>
<li><code>nn_idx+idx_</code> (32, 1024, 20), indices of 20 neighbors of
32 batches 1024 points. The indices are for indexing in <code>point_cloud_flat</code>.</li>
<li><code>point_cloud_neighbors</code> finally is (32, 1024,
20, 3), the same as <code>nn_idx+idx_</code> except that <code>point_cloud_neighbors</code> are their 3 coordinates while <code>nn_idx+idx_</code> are just their indices.</li>
</ul>
",7034613,2349,https://stackoverflow.com/questions/53578484,Documentation Replicability
53569622,Difference between tf.train.Checkpoint and tf.train.Saver,"<p>I found there are different ways to save/restore models and variables in <code>Tensorflow</code>. These ways including:</p>

<ul>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save"" rel=""nofollow noreferrer"">tf.saved_model.simple_save</a></li>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"" rel=""nofollow noreferrer"">tf.train.Checkpoint</a></li>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/train/Saver"" rel=""nofollow noreferrer"">tf.train.Saver</a></li>
</ul>

<p>In tensorflow's documentations, I found some differences between them:</p>

<ol>
<li><code>tf.saved_model</code> is a thin wrapper around <code>tf.train.Saver</code></li>
<li><code>tf.train.Checkpoint</code> support eager execution but <code>tf.train.Saver</code> <strong>not</strong>.</li>
<li><code>tf.train.Checkpoint</code> not creating <code>.meta</code> file but still can load graph structure (here is a big question! how it can do that?)</li>
</ol>

<p>How <code>tf.train.Checkpoint</code> can load graph without <code>.meta</code> file? or more generally What is the difference between <code>tf.train.Saver</code> and <code>tf.train.Checkpoint</code>?</p>
",-,-,2018-12-01 9:56:07,"<p>According to Tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"" rel=""nofollow noreferrer"">docs</a>:</p>

<blockquote>
  <p><code>Checkpoint.save</code> and <code>Checkpoint.restore</code> write and read object-based
  checkpoints, in contrast to <code>tf.train.Saver</code> which writes and reads
  variable.name based checkpoints. Object-based checkpointing saves a
  graph of dependencies between Python objects (Layers, Optimizers,
  Variables, etc.) with named edges, and this graph is used to match
  variables when restoring a checkpoint. It can be more robust to
  changes in the Python program, and helps to support restore-on-create
  for variables when executing eagerly. <strong>Prefer <code>tf.train.Checkpoint</code> over
  <code>tf.train.Saver</code> for new code</strong>.</p>
</blockquote>
",1462770,16282,https://stackoverflow.com/questions/53569622,Documentation Ambiguity
53568337,Print accuracy when training tf.estimator.DNNClassifier,"<p>I am new to tensorflow, using <a href=""https://www.tensorflow.org/guide/custom_estimators"" rel=""nofollow noreferrer"">official tutorial</a> tf.estimator.DNNClassifier and custom estimator to build simple NN to solve classification problem.</p>

<p>While training :</p>

<pre><code>dnn_model = tf.estimator.DNNClassifier(hidden_units=[10,10,10],
                                       feature_columns = my_features_column,
                                       n_classes=5,
                                       optimizer = tf.train.AdamOptimizer()
                                      )

dnn_model.train(input_fn=train_input_func)
</code></pre>

<p>It will report loss at specific time as following:</p>

<pre><code>INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmphwkvj5le/model.ckpt-150
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 150 into /tmp/tmphwkvj5le/model.ckpt.
INFO:tensorflow:loss = 133.04277, step = 150
INFO:tensorflow:global_step/sec: 115.114
INFO:tensorflow:loss = 128.15938, step = 250 (0.872 sec)
INFO:tensorflow:global_step/sec: 134.317
INFO:tensorflow:loss = 123.093094, step = 350 (0.743 sec)
INFO:tensorflow:global_step/sec: 133.573
INFO:tensorflow:loss = 117.80729, step = 450 (0.748 sec)
INFO:tensorflow:global_step/sec: 135.081
INFO:tensorflow:loss = 114.07168, step = 550 (0.741 sec)
INFO:tensorflow:Saving checkpoints for 650 into /tmp/tmphwkvj5le/model.ckpt.
INFO:tensorflow:Loss for final step: 118.19583.
</code></pre>

<p>I want to print classification accuracy every batch or epoch, likes the log Info in keras:</p>

<pre><code>Epoch 1/20
5000/5000 [==============================] - 1s 157us/step - loss: 1.4885 - acc: 0.3276 - val_loss: 1.4397 - val_acc: 0.3620
Epoch 2/20
5000/5000 [==============================] - 0s 66us/step - loss: 1.3792 - acc: 0.3922 - val_loss: 1.4001 - val_acc: 0.3768
.
.
</code></pre>

<p>How can I find the tutorial on this problem ? All I find were talking about more lower API (tensor, session, etc.).</p>
",-,-,2018-12-01 6:26:11,"<p>You want to use the 'hooks' option in the estimator train.</p>

<p>The particular hook you want to use is this one: <a href=""https://www.tensorflow.org/api_docs/python/tf/train/LoggingTensorHook"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/LoggingTensorHook</a></p>

<p>A similar problem was solved here:
<a href=""https://stackoverflow.com/a/45716062/10498246"">https://stackoverflow.com/a/45716062/10498246</a>
where they used the Logging Tensor Hook on a different training function.</p>
",10083164,55,https://stackoverflow.com/questions/53568337,Documentation Replicability
53307954,TensorFlow Custom Estimator predict throwing value error,"<p>Note: this question has an accompanying, documented <a href=""https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub"" rel=""nofollow noreferrer"">Colab</a> notebook.</p>
<p>TensorFlow's documentation can, at times, leave a lot to be desired. Some of the older docs for lower level apis seem to have been expunged, and most newer documents point towards using higher level apis such as TensorFlow's subset of <code>keras</code> or <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator"" rel=""nofollow noreferrer""><code>estimators</code></a>. This would not be so problematic if the higher level apis did not so often rely closely on their lower levels. Case in point, <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator"" rel=""nofollow noreferrer""><code>estimators</code></a> (especially the <code>input_fn</code> when using TensorFlow Records).</p>
<p>Over the following Stack Overflow posts:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel"">Tensorflow v1.10: store images as byte strings or per channel?</a></li>
<li><a href=""https://stackoverflow.com/questions/52064866/tensorflow-1-10-tfrecorddataset-recovering-tfrecords"">Tensorflow 1.10 TFRecordDataset - recovering TFRecords</a></li>
<li><a href=""https://stackoverflow.com/questions/52874647/tensorflow-v1-10-why-is-an-input-serving-receiver-function-needed-when-checkpoi"">Tensorflow v1.10+ why is an input serving receiver function needed when checkpoints are made without it?</a></li>
<li><a href=""https://stackoverflow.com/questions/52641737/tensorflow-1-10-custom-estimator-early-stopping-with-train-and-evaluate"">TensorFlow 1.10+ custom estimator early stopping with train_and_evaluate</a></li>
<li><a href=""https://stackoverflow.com/questions/53226898/tensorflow-custom-estimator-stuck-when-calling-evaluate-after-training"">TensorFlow custom estimator stuck when calling evaluate after training</a></li>
</ul>
<p>and with the gracious assistance of the TensorFlow / StackOverflow community, we have moved closer to doing what the TensorFlow <a href=""https://www.tensorflow.org/guide/custom_estimators"" rel=""nofollow noreferrer"">&quot;Creating Custom Estimators&quot; guide</a> has not, demonstrating how to make an estimator one might actually use in practice (rather than toy example) e.g. one which:</p>
<ul>
<li>has a validation set for early stopping if performance worsen,</li>
<li>reads from TF Records because many datasets are larger than the TensorFlow recommend 1Gb for in memory, and</li>
<li>that saves its best version whilst training</li>
</ul>
<p>While I still have many questions regarding this (from the best way to encode data into a TF Record, to what exactly the <code>serving_input_fn</code> expects), there is one question that stands out more prominently than the rest:</p>
<p>How to predict with the custom estimator we just made?</p>
<p>Under the documentation for <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict"" rel=""nofollow noreferrer"">predict</a>, it states:</p>
<blockquote>
<p><code>input_fn</code>: A function that constructs the features. Prediction continues until <code>input_fn</code> raises an end-of-input exception (<code>tf.errors.OutOfRangeError</code> or <code>StopIteration</code>). See Premade Estimators for more information. The function should construct and return one of the following:</p>
<ul>
<li>A tf.data.Dataset object: Outputs of Dataset object must have same constraints as below.</li>
<li>features: A tf.Tensor or a dictionary of string feature name to Tensor. features are consumed by model_fn. They should satisfy the expectation of model_fn from inputs.</li>
<li>A tuple, in which case the first item is extracted as features.</li>
</ul>
</blockquote>
<p>(perhaps) Most likely, if one is using <code>estimator.predict</code>, they are using data in memory such as a dense tensor (because a held out test set would likely go through <code>evaluate</code>).</p>
<p>So I, in the accompanying <a href=""https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub"" rel=""nofollow noreferrer"">Colab</a>, create a single dense example, wrap it up in a <code>tf.data.Dataset</code>, and call <code>predict</code> to get a <code>ValueError</code>.</p>
<p>I would greatly appreciate it if someone could explain to me how I can:</p>
<ol>
<li>load my saved estimator</li>
<li>given a dense, in memory example, predict the output with the estimator</li>
</ol>
",-,-,2018-11-14 20:02:54,"<pre><code>to_predict = random_onehot((1, SEQUENCE_LENGTH, SEQUENCE_CHANNELS))\
        .astype(tf_type_string(I_DTYPE))
pred_features = {'input_tensors': to_predict}

pred_ds = tf.data.Dataset.from_tensor_slices(pred_features)
predicted = est.predict(lambda: pred_ds, yield_single_examples=True)

next(predicted)
</code></pre>

<blockquote>
  <p>ValueError: Tensor(""IteratorV2:0"", shape=(), dtype=resource) must be from the same graph as Tensor(""TensorSliceDataset:0"", shape=(), dtype=variant).</p>
</blockquote>

<p>When you use the <code>tf.data.Dataset</code> module, it actually defines an input graph which is independant from the model graph. What happens here is that you first created a small graph by calling <code>tf.data.Dataset.from_tensor_slices()</code>, then the estimator API created a second graph by calling <code>dataset.make_one_shot_iterator()</code> automatically. These 2 graphs can't communicate so it throws an error.</p>

<p>To circumvent this, you should never create a dataset outside of estimator.train/evaluate/predict. This is why everything data related is wrapped inside input functions.</p>

<pre><code>def predict_input_fn(data, batch_size=1):
  dataset = tf.data.Dataset.from_tensor_slices(data)
  return dataset.batch(batch_size).prefetch(None)

predicted = est.predict(lambda: predict_input_fn(pred_features), yield_single_examples=True)
next(predicted)
</code></pre>

<p>Now, the graph is not created outside of the predict call.</p>

<p>I also added <code>dataset.batch()</code> because the rest of your code expect batched data and it was throwing a shape error. Prefetch just speed things up.</p>
",5623899,4978,https://stackoverflow.com/questions/53307954,Requesting (Additional) Documentation/Examples
53206900,Sound way of managing multiple sessions and graphs,"<p>I'd like to manage multiple Keras models in multiple sessions. My application is constructed such that models can be live at the same time, in addition to creating, saving and loading them.</p>

<p><strong>What is the proper way of managing this situation?</strong></p>

<p>Currently one model is represented by an instance of a wrapper class. This is used in the training, saving, loading and prediction. One <code>tf.Graph</code> and <code>tf.Session</code> is created per instance, and they are used in every function requiring the actual model.</p>

<pre><code>class NN:
    def __init__(self):
        self.graph = tf.Graph()
        self.session = tf.Session(graph=self.graph)

    def predict(self, x):
        with self.graph.as_default():
            with self.session.as_default():
                return self.model.predict(x)
</code></pre>

<p>Similar functions using the <code>with</code> statements are created for compiling the network, fitting, saving (weights to .h5 and model to JSON) and loading. So whenever the model is needed, the graph and session are brought to context.</p>

<p>This resulted in a strange error (<a href=""https://stackoverflow.com/questions/53002518/poor-exit-code-when-managing-multiple-sessions"">Q</a> for further context), and I was left wondering, what is the standard way of dealing with this. I tried to release all possible resources before creating or loading a model, but it hasn't helped. This function is just a compilation of all possible routines scraped off the internet, and is purely guesswork.</p>

<pre><code>def _new_session(self):
    if self.session is not None:
        self.session.close()
    k.clear_session()
    gc.collect()
    self.graph = tf.Graph()
    self.session = tf.Session(graph=self.graph)
</code></pre>

<p>I've not found good documentation of a similar situation. So I'd very much appreciate any real insight into this.</p>

<hr>

<p>I might need to delete the old question, as it's quite all over the place. At the time of asking I had no idea what was going on. But it's there for now.</p>

<hr>

<p>Some specific questions have arisen.</p>

<ul>
<li>Loading and making predictions on a model works, compiling and fitting doesn't, although just compiling does. Do the two contexts differ in any way? Is the loaded model exactly the same?</li>
<li>At which points should a new context be created when manipulating the models? (e.g. at load, compilation, fitting, probably not with every prediction)</li>
<li>Which actions are necessary to take when releasing the resources of previous contexts? Either when a network is disposed of or when creating a new context.</li>
<li>Why exactly is the context switch needed for multiple models?</li>
<li>What are the roles of graph vs. session, given that different things are executed on the graph and session?</li>
</ul>

<h3>Updates</h3>

<ul>
<li>Compiling, fitting and saving one network works without any context trickery. Doing the same for another model in the same context works too (or at least does not produce an error).</li>
<li>In addition to above, <strong>loading the saved model and predicting works too</strong>, right after the training and for both models! Now I'm not sure whether the prediction is made correctly, but again, no error. This only begs the question I posed above even more: <em>why are the different contexts needed?</em></li>
</ul>

<hr>

<p>The underlying issue with the error has been finally (and somewhat embarassingly) <a href=""https://stackoverflow.com/questions/53002518/poor-exit-code-when-managing-multiple-sessions"">resolved</a> by updating all packages.</p>
",-,-,2018-11-08 11:31:55,"<p>EDIT: Actually, seeing again how <code>K.get_session()</code> works, it should return the current default session, so I'm not sure <code>set_session</code> is doing anything meaningful there. I'll leave the answer just in case you want to try but probably this won't help.</p>

<hr>

<p>Maybe you can get it to work with something like this:</p>

<pre><code>from contextlib import contextmanager

class NN:
    def __init__(self):
        self.graph = tf.Graph()
        self.session = tf.Session(graph=self.graph)

    def predict(self, x):
        with self._context():
            return self.model.predict(x)

    @contextmanager
    def _context(self):
        prev_sess = K.get_session()
        K.set_session(self.session)
        with self.graph.as_default(), self.session.as_default():
            yield
        K.set_session(prev_sess)
</code></pre>

<p>Note that the Keras session object is a global variable, so I suppose this should work as long as you don't try to use these contexts from multiple threads.</p>
",7089239,2588,https://stackoverflow.com/questions/53206900,Lack of Alternative Solutions/Documentation
53079436,tensorflow Tf.cond giving unexpected output,"<p>I seem to be having a misunderstanding on how <code>tf.cond</code> works. In the tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/cond"" rel=""nofollow noreferrer"">documentation</a>, it gives the following example:</p>

<pre><code>z = tf.multiply(a, b)
result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))
</code></pre>

<p>The result of the example, if <code>x&lt;y</code> is <code>True</code> is <code>tf.add(x,z)</code> else <code>tf.square(y)</code></p>

<p>Following this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation.</p>

<p>in my example, <code>deterministic_action = 4</code>, <code>random_action = 11</code>, <code>chose_random=False</code>. The <code>stochastic_action</code> should be <code>4</code>, instead it is <code>1</code>.
Where did the value 1 come from?</p>

<pre><code>#!/usr/bin/env python3

import tensorflow as tf
import numpy as np

with tf.Graph().as_default():
    with tf.device('/cpu:0'):
        stochastic_ph = tf.placeholder(tf.bool, (), name=""stochastic"")
        eps = tf.get_variable(""eps"", (), initializer=tf.constant_initializer(0))
        with tf.variable_scope('test_cond') as sc:
            deterministic_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=0) # 4
            random_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=1) # 11
            chose_random = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32) &lt; eps # False because eps = 0
            stochastic_action = tf.cond(chose_random, lambda: random_action, lambda: deterministic_action) # S_action should be 4 but it is 1
            #output_action = tf.cond(stochastic_ph, lambda: stochastic_action, lambda: deterministic_action)


    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init, feed_dict={stochastic_ph: True})
    print (""s_ph = "", stochastic_ph)
    d_action = sess.run(deterministic_action)
    print (""det_action= "", d_action)
    r_action = sess.run(random_action)
    print (""rand_action= "", r_action)
    e = sess.run(eps)
    c_action = sess.run(chose_random)
    print (""chose_rand= "", c_action)
    s_action = sess.run(stochastic_action)
    print (""s_action= "", s_action)
    #output = sess.run(output_action)
</code></pre>

<p>here is the output:</p>

<pre><code>python random_vec.py
2018-10-31 09:46:15.028376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
</code></pre>
",tf.cond,tf.cond,2018-10-31 8:46:24,"<p>This is because you are evaluating again in a new sess.run. 
Since you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1.
Here is the result of your code, when I extract the value of deterministic_action as well in the last step.</p>

<p>Modification:</p>

<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
r_action = sess.run(random_action)
print (""rand_action= "", r_action)
e = sess.run(eps)
c_action = sess.run(chose_random)
print (""chose_rand= "", c_action)
s_action, d_action = sess.run([stochastic_action, deterministic_action])
print (""s_action= "", s_action)
print (""det_action= "", d_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
det_action=  1
</code></pre>

<p>Now all you need to do is run everything in one sess.run</p>

<pre><code>d_action, r_action, e,  c_action, s_action = sess.run([deterministic_action, random_action, eps, chose_random, stochastic_action])
print (""det_action= "", d_action)
print (""rand_action= "", r_action)
print (""chose_rand= "", c_action)
print (""s_action= "", s_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  4
</code></pre>

<p>Update:</p>

<p>I was not clear on why the random_uniform generates different values when seed is set. This is because the code is running with the same session object that it initialized the variables with.
Modifying the code with a new session object, this is what happens:</p>

<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
sess.close()
sess = tf.Session()
sess.run(init, feed_dict={stochastic_ph: True})
s_action = sess.run(stochastic_action)
print (""s_action= "", s_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
s_action=  4
</code></pre>
",1059860,2080,https://stackoverflow.com/questions/53079436,Documentation Replication on Other Examples
53032922,TensorFlow while loop with condition dependent on body,"<p>I want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don't know how to accomplish this with <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop()</code></a>.</p>

<p>My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by</p>

<pre><code>import numpy as np
import tensorflow as tf
IMAGE_SHAPE = [960, 720]
CROP_SHAPE = [320, 240]
max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE)
crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index)
img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])
</code></pre>

<p>and the condition is</p>

<pre><code>cond = tf.count_nonzero(img_crop &gt; 0) &gt; 0.5 * tf.size(img_crop)
</code></pre>

<p>Going over the documentation and examples of <code>tf.while_loop(cond, body, loop_vars, ...)</code>, what I understand is that both <code>cond</code> and <code>body</code> should take the same arguments given in <code>loop_vars</code>.
I don't see how I can have <code>cond</code> depend on <code>img_crop</code> which would be calculated inside <code>body</code>, and isn't provided in <code>loop_vars</code>.</p>

<p>I could equivalently compute <code>cond</code> using <code>crop_begin_index</code> without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem.</p>

<p>Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use <code>tf.while_loop()</code>?</p>
",tf.while_loop,tf.while_loop,2018-10-28 15:05:05,"<p>The arguments that are passed on to the <code>condition</code> function are the arguments returned from your <code>body</code> function. So you just have to return that value that you want to base your condition on in the <code>body</code> function, then carry out the condition on that value in your <code>cond</code> function. Something like, </p>

<pre><code>def body(image_shape, crop_shape, img_crop):
    max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE)
    crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index)
    img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])
    return (image_shape, crop_shape, img_crop)

def cond(image_shape, crop_shape, img_crop):
    return tf.count_nonzero(img_crop &gt; 0) &gt; 0.5 * tf.size(img_crop)

image_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))
</code></pre>

<p>Don't have access to an interpreter right now, so there might be some syntax problems there, but something like that. </p>

<p>Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions.</p>

<p>Also note, you'll need to specify some initial value for <code>img_crop</code> in the loop vars.</p>

<p>Moreover, by default, <code>tf.while_loop</code> expects the shapes of all the <code>loop_vars</code> to remain the same across all loop runs. You can modify this through the <code>shape_invariants</code> argument. </p>
",2260153,2642,https://stackoverflow.com/questions/53032922,Documentation Replication on Other Examples
52976606,Global step not incrementing with batch norm and custom estimator,"<p>I have a customer estimator that has several layers that look like the following in the model function:</p>

<pre><code>natural_layer = tf.layers.dense(inputs = natural_layer, 
                                units = units, 
                                activation = None,
                                use_bias = False,
                                kernel_regularizer = params['regularizer'],
                                name = 'pre_batch_norm_layer_' + str(i + 1))

natural_layer = tf.layers.batch_normalization(natural_layer,
                                              axis = 1,
                                              center = True,
                                              scale = True,
                                              training = (mode == tf.estimator.ModeKeys.TRAIN),
                                              name = 'batch_norm_layer_' + str(i + 1))

natural_layer = params['natural_layer_activation'](natural_layer, name = 'activation_layer_' + str(i + 1))
</code></pre>

<p>Because I'm using batch norm, the training op is set up like this:</p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    optimizer = tf.contrib.opt.MultitaskOptimizerWrapper(params['optimization_algorithm'](params['training_rate']))
    train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())
</code></pre>

<p>Where the optimizer is usually tf.train.AdamOptimizer.</p>

<p>However, when I go to train the estimator the global step never increments (so training will run forever), and I get this:</p>

<p>WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.</p>

<p>I am passing tf.train.get_global_step() to minimize, so I'm not sure why it never gets updated. My hunch is that it has something to do with the batch normalization because when I remove that or replace it with dropout, everything works fine (even when keeping the update ops lines that are required for batch normalization per the documentation).</p>

<p>Anyone know what is going on? Happy to post more code if helpful. </p>
",tf.train.get_global_step,tf.train.get_global_step,2018-10-24 19:29:33,"<p>I couldn't figure out why the global step was not incrementing automatically, but manually incrementing the global step as follows by adding it to the train_op with tf.group is a nice work around. </p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
        optimizer = tf.contrib.opt.MultitaskOptimizerWrapper(params['optimization_algorithm'](params['training_rate']))
        train_op = optimizer.minimize(loss)

        global_step = tf.train.get_global_step()
        update_global_step = tf.assign(global_step, global_step + 1, name = 'update_global_step')

        return tf.estimator.EstimatorSpec(mode, loss = loss, train_op = tf.group(train_op, update_global_step))
</code></pre>
",9226290,111,https://stackoverflow.com/questions/52976606,Documentation Replication on Other Examples
52969867,make tensorflow dataset from huge number of images(*.jpg) and labels(*.mat),"<p>I have a huge number of images with their labels (.mat) file (cannot use <code>tf.data.Dataset.from_tensor_slices()</code>) and I want to use <code>tf.data</code> API to make a tensorflow dataset out of it.</p>

<p>As I read in the documentation, I can use <code>tf.data.TextLineDataset</code> for large number of data(I have to have a txt file with the address of all the images and send the path of the txt file as <code>tf.data.TextLineDataset</code> argument).
Then, I can use <code>map</code> method to read txt file (<code>tf.read_file</code>) decode jpg image (<code>tf.image.decode_jpeg</code>) and do some basic transformation on the image.</p>

<p>However, I cannot use <code>scipy.io.loadmat</code> in any part of <code>map</code> method because I have no string indicating the path to the mat file. All I have is <code>tf.Tensor</code>.</p>

<p>I don't think that reading all images and making a TFRecord out of it is that much efficient in this case because then I am basically doing every thing two times. Once, reading the whole images and making TFRecord, and once again, reading TFRecord to make tensorflow dataset.</p>

<p>Any idea how I can resolve this issue?</p>

<p>This is my code:</p>

<pre><code>dataset = tf.data.TextLineDataset(txt_file).map(read_img_and_mat)
</code></pre>

<p>and then:</p>

<pre><code>def read_img_and_mat(path):
    image_string = tf.read_file(path)
    image_decoded = tf.image.decode_jpeg(image_string, channels=3)
    label = ... # get label from mat file
    return image_decoded, label
</code></pre>
",tf.data.TextLineDataset,tf.data.TextLineDataset,2018-10-24 13:08:06,"<p>I found a way to do it using <code>tf.data.from_generator</code>
The trick I found was to make two separate Dataset (one for mat file and one for the jpg file) and then to combine them using <code>tf.data.Dataset.zip</code></p>

<p>Here is how it works:</p>

<pre><code>mat_dataset = tf.data.Dataset.from_generator(read_mat_file, tf.int64)

def read_mat_file():
    while True:
        with open('mat_addresses.txt', 'r') as input_:
            for line in input_:
                # open file and extract info from it as np.array
                yield tuple(label)  # why tuple? https://github.com/tensorflow/tensorflow/issues/13101
</code></pre>

<p>in order to get the next batch one just have to do:</p>

<pre><code>iter = mat_dataset.make_one_shot_iterator()
sess.run(iter.get_next())
</code></pre>

<p>however, one can make <code>img_dataset</code> and combine it with <code>mat_dataset</code> like this:</p>

<pre><code>img_dataset = tf.data.TextLineDataset('img_addresses.txt').map(read_img)

def read_img(path):
    image_string = tf.read_file(path)
    image_decoded = tf.image.decode_jpeg(image_string, channels=3)
    return image_decoded

dataset = tf.data.Dataset.zip((mat_dataset, img_dataset))
</code></pre>

<p>and now, getting next next batch like mentioned.</p>

<p>PS. I have no idea about how efficient the code works in comparison to <code>feed_dict</code></p>
",10354279,148,https://stackoverflow.com/questions/52969867,Documentation Replication on Other Examples
52711895,How to run define Tensorflow graph were all variables are in float16 instead instead of float32,"<p>By default, the variables Tensorflow is in float32. To save memory, I'm trying to run in float16. In my graph, every place where I could define the datatype as float16, I did. However, I get an error when I run the code </p>

<p>Here's my code below. </p>

<pre><code>import math
import numpy as np
import tensorflow as tf

vocabulary_size = 10
batch_size = 64 
embedding_size = 100 
num_inputs =4
num_sampled = 128 

graph = tf.Graph()

with graph.as_default(): #took out "" , tf.device('/cpu:0')""


    train_dataset = tf.placeholder(tf.int32, shape=[batch_size, num_inputs ])
    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])

    embeddings = tf.get_variable( 'embeddings', dtype=tf.float16,
        initializer= tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0, dtype=tf.float16) )

    softmax_weights = tf.get_variable( 'softmax_weights', dtype=tf.float16,
        initializer= tf.truncated_normal([vocabulary_size, embedding_size],
                             stddev=1.0 / math.sqrt(embedding_size), dtype=tf.float16 ) )

    softmax_biases = tf.get_variable('softmax_biases', dtype=tf.float16,
        initializer= tf.zeros([vocabulary_size], dtype=tf.float16),  trainable=False )

    embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is

    embed_reshaped = tf.reshape( embed, [batch_size*num_inputs, embedding_size] )

    segments= np.arange(batch_size).repeat(num_inputs)

    averaged_embeds = tf.segment_mean(embed_reshaped, segments, name=None)

    sam_sof_los = tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,
                                   labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)

    loss = tf.reduce_mean( sam_sof_los )

    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss) 

    saver = tf.train.Saver()
</code></pre>

<p>And this is this is the error message</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    509                 as_ref=input_arg.is_ref,
--&gt; 510                 preferred_dtype=default_dtype)
    511           except TypeError as err:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)
   1143     if ret is None:
-&gt; 1144       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1145 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)
    980         ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
--&gt; 981         (dtype.name, t.dtype.name, str(t)))
    982   return t

ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor(""sampled_softmax_loss/Log:0"", shape=(64, 1), dtype=float32)'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-2-12d508b9e5d7&gt; in &lt;module&gt;()
     46 
     47     sam_sof_los = tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,
---&gt; 48                                    labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)
     49 
     50     loss = tf.reduce_mean( sam_sof_los )

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in sampled_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name, seed)
   1347       partition_strategy=partition_strategy,
   1348       name=name,
-&gt; 1349       seed=seed)
   1350   labels = array_ops.stop_gradient(labels, name=""labels_stop_gradient"")
   1351   sampled_losses = nn_ops.softmax_cross_entropy_with_logits_v2(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed)
   1126     if subtract_log_q:
   1127       # Subtract log of Q(l), prior probability that l appears in sampled.
-&gt; 1128       true_logits -= math_ops.log(true_expected_count)
   1129       sampled_logits -= math_ops.log(sampled_expected_count)
   1130 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
    860     with ops.name_scope(None, op_name, [x, y]) as name:
    861       if isinstance(x, ops.Tensor) and isinstance(y, ops.Tensor):
--&gt; 862         return func(x, y, name=name)
    863       elif not isinstance(y, sparse_tensor.SparseTensor):
    864         try:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py in sub(x, y, name)
   8316   if _ctx is None or not _ctx._eager_context.is_eager:
   8317     _, _, _op = _op_def_lib._apply_op_helper(
-&gt; 8318         ""Sub"", x=x, y=y, name=name)
   8319     _result = _op.outputs[:]
   8320     _inputs_flat = _op.inputs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    544                   ""%s type %s of argument '%s'."" %
    545                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
--&gt; 546                    inferred_from[input_arg.type_attr]))
    547 
    548           types = [values.dtype]

TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type float16 of argument 'x'.
</code></pre>

<p>The error comes from line <code>tf.nn.sampled_softmax_loss</code>.</p>

<p>At first I thought perhaps tf.segment_mean may cast the output as a float32, so I tried casting averaged_embeds to float16 but I still get the same error. </p>

<p>From the documentation, there doesn't seem to be a way to define any data types in sampled_softmax_loss</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss</a></p>
",tf.nn.sampled_softmax_loss,tf.nn.sampled_softmax_loss,2018-10-09 0:53:37,"<p>As far as I can tell, you can only do it using a hack.</p>

<p>The issue comes from the call to:</p>

<pre><code>  if sampled_values is None:
      sampled_values = candidate_sampling_ops.log_uniform_candidate_sampler(
          true_classes=labels,
          num_true=num_true,
          num_sampled=num_sampled,
          unique=True,
          range_max=num_classes,
          seed=seed)
</code></pre>

<p>which outputs an object of this type:</p>

<pre><code>LogUniformCandidateSampler(
    sampled_candidates=&lt;tf.Tensor 'LogUniformCandidateSampler:0' shape=(128,) dtype=int64&gt;,
    true_expected_count=&lt;tf.Tensor 'LogUniformCandidateSampler:1' shape=(64, 1) dtype=float32&gt;,
    sampled_expected_count=&lt;tf.Tensor 'LogUniformCandidateSampler:2' shape=(128,) dtype=float32&gt;
)
</code></pre>

<p>The hack would be to generate yourself the <code>LogUniformCandidateSampler</code>, to cast its result as <code>tf.float16</code> and pass it to <code>tf.nn.sampled_softmax_loss</code>.</p>

<pre><code># Redefine it as the tensorflow one is not exposed.
LogUniformCandidateSampler = namedtuple(""namedtuple"", [""sampled_candidates"", ""true_expected_count"", ""sampled_expected_count""]) 
sampled_values = tf.nn.log_uniform_candidate_sampler(
      true_classes=tf.cast(train_labels, tf.int64), num_sampled=num_sampled,
      num_true=1,
      unique=True,
      range_max=vocabulary_size,
      seed=None)

sampled_value_16 = LogUniformCandidateSampler(
    sampled_values.sampled_candidates,
    tf.cast(sampled_values.true_expected_count, tf.float16),
    tf.cast(sampled_values.sampled_expected_count, tf.float16))

sam_sof_los = tf.nn.sampled_softmax_loss(
    weights=softmax_weights,
    biases=softmax_biases,
    inputs=averaged_embeds,
    labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size, 
    sampled_values=sampled_value_16)
</code></pre>

<p>But this is really a hack and it might have unexpected consequences (an expected one would be that the <code>tf.cast</code> operation is not differentiable).</p>
",3259896,5853,https://stackoverflow.com/questions/52711895,Lack of Alternative Solutions/Documentation
52572275,tensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)?,"<p>I've read the <a href=""https://www.tensorflow.org/api_docs/python/tf/manip/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_nd documentation</a> and run the example code for 1D and 3D tensors... and now I'm trying to do it for a 2D tensor.  I want to 'interleave' the columns of two tensors.  For 1D tensors, one can do this via</p>

<pre><code>'''
We want to interleave elements of 1D tensors arr1 and arr2, where
arr1 = [10, 11, 12]
arr2 = [1, 2, 3, 4, 5, 6]
such that
desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12]
'''

import tensorflow as tf

with tf.Session() as sess:

    updates1 = tf.constant([1,2,3,4,5,6])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)

    updates2 = tf.constant([10,11,12])
    indices2 = tf.constant([[2], [5], [8]])
    scatter2 = tf.scatter_nd(indices2, updates2, shape)

    result = scatter1 + scatter2

    print(sess.run(result))
</code></pre>

<p>(aside: is there a <em>better</em> way to do this?  I'm all ears.)</p>

<p>This gives the output</p>

<p><code>[ 1  2 10  3  4 11  5  6 12]</code></p>

<p>Yay! that worked!</p>

<p>Now lets' try to extend this to 2D.</p>

<pre><code>    '''
    We want to interleave the *columns* (not rows; rows would be easy!) of

    arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]
    arr2 = [[10 11 12], [10 11 12], [10 11 12]]
    such that
    desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]]
    '''

    updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([3, 9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)
</code></pre>

<p>This gives the error
<code>ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1
dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but
are 6 and 3. Shapes are [6] and [3]. for 'ScatterNd_2' (op: 'ScatterNd') with
input shapes: [6,1], [3,6], [2].</code></p>

<p>Seems like my <code>indices</code> is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean
I need to <em>explicitly</em> specify every single pair of indices for every element in <code>updates1</code>?
Or is there some kind of 'wildcard' specification I can use for the rows? (Note <code>indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]])</code> gives syntax errors, as it probably should.)</p>

<p>Would it be easier to just do a transpose, interleave the rows, then transpose back?
Because I tried that...</p>

<pre><code>scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))
print(sess.run(tf.transpose(scatter1)))
</code></pre>

<p>...and got a <em>much</em> longer error message, that I don't feel like posting unless someone requests it. </p>

<p>PS- I searched to make sure this isn't a duplicate -- I find it hard to imagine that someone else hasn't asked this before -- but turned up nothing. </p>
",tf.scatter_nd,tf.scatter_nd,2018-09-29 20:24:35,"<p>This is pure slicing but I didn't know that syntax like <code>arr1[0:,:][:,:2]</code> actually works. It seems it does but not sure if it is better.</p>

<p>This may be the <em>wildcard</em> slicing mechanism you are looking for.</p>

<pre><code>arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]])
arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]])

with tf.Session() as sess :
    sess.run( tf.global_variables_initializer() )
    print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1],
                              arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2],
                              arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))
</code></pre>

<p>Output is</p>

<pre><code>[[ 1  2 10  3  4 11  5  6 12]
 [ 1  2 10  3  4 11  5  7 12]
 [ 1  2 10  3  4 11  5  8 12]]
</code></pre>

<p>So, for example,</p>

<p><code>arr1[0:,:]</code> returns</p>

<pre><code>[[1 2 3 4 5 6]
 [1 2 3 4 5 7]
 [1 2 3 4 5 8]]
</code></pre>

<p>and <code>arr1[0:,:][:,:2]</code> returns the first two columns</p>

<pre><code>[[1 2]
 [1 2]
 [1 2]]
</code></pre>

<p>axis is 1.</p>
",4259243,1472,https://stackoverflow.com/questions/52572275,Documentation Replication on Other Examples
51859776,lambda layer function definition without tf.keras.backend (Python Keras Package),"<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda"" rel=""nofollow noreferrer"">tf.keras.layers.Lambda</a> documentation explains how a function can be defined in a lambda layer. That document provides the following function as an example,</p>

<pre><code>def antirectifier(x):

    x -= K.mean(x, axis=1, keepdims=True)
    x = K.l2_normalize(x, axis=1)

    pos = K.relu(x)
    neg = K.relu(-x)

    return K.concatenate([pos, neg], axis=1)

model.add(Lambda(antirectifier))
</code></pre>

<p>But according to that, <code>tf.keras.backend</code> must be used to conduct operations on the input Tensor object.</p>

<p>Is there any way we can use default python packages and user-defined function to define the steps of a lambda function.</p>

<p>If it's possible, please be kind enough to provide some examples.</p>
",tf.keras.layers.Lambda,tf.keras.layers.Lambda,2018-08-15 13:34:42,"<p>If you're not using <code>import tensorflow</code> and its functions, there is absolutely no problem. </p>

<p>The code is perfect and that's it. </p>

<p>Just <code>import keras.backend as K</code></p>

<p>Example <code>rounded = K.round(x)</code></p>

<hr>

<p>This is Keras independent documentation: <a href=""https://keras.io/layers/core/#lambda"" rel=""nofollow noreferrer"">https://keras.io/layers/core/#lambda</a></p>
",261433,432,https://stackoverflow.com/questions/51859776,Inadequate Examples
51858970,"tf.gradients() sums over ys, does it?","<p><a href=""https://www.tensorflow.org/versions/r1.6/api_docs/python/tf/gradients"" rel=""noreferrer"">https://www.tensorflow.org/versions/r1.6/api_docs/python/tf/gradients</a></p>

<p>In the documentation for tf.gradients(ys, xs) it states that </p>

<blockquote>
  <p>Constructs symbolic derivatives of sum of ys w.r.t. x in xs</p>
</blockquote>

<p>I am confused about the summing part, I have read elsewhere that this sums the derivatives dy/dx across the batch for every x in the batch. However, whenever I use this I fail to see this happening. Take the following simple example:</p>

<pre><code>x_dims = 3
batch_size = 4

x = tf.placeholder(tf.float32, (None, x_dims))

y = 2*(x**2)

grads = tf.gradients(y,x)

sess = tf.Session()

x_val = np.random.randint(0, 10, (batch_size, x_dims))
y_val, grads_val = sess.run([y, grads], {x:x_val})

print('x = \n', x_val)
print('y = \n', y_val)
print('dy/dx = \n', grads_val[0])
</code></pre>

<p>This gives the following output:</p>

<pre><code>x = 
 [[5 3 7]
 [2 2 5]
 [7 5 0]
 [3 7 6]]
y = 
 [[50. 18. 98.]
 [ 8.  8. 50.]
 [98. 50.  0.]
 [18. 98. 72.]]
dy/dx = 
 [[20. 12. 28.]
 [ 8.  8. 20.]
 [28. 20.  0.]
 [12. 28. 24.]]
</code></pre>

<p>This is the output I would expect, simply the derivative dy/dx for every element in the batch. I don't see any summing happening. I have seen in other examples that this operation is followed by dividing by the batch size to account for tf.gradients() summing the gradients over the batch (see here: <a href=""https://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html"" rel=""noreferrer"">https://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html</a>). Why is this necessary?</p>

<p>I am using Tensorflow 1.6 and Python 3.</p>
",tf.gradients,tf.gradients,2018-08-15 12:45:16,"<p>If y and x have the same shape then the sum over the dy/dx is the sum over exactly one value. However, if you have more than one y for each x, then the gradients are summed.</p>

<pre><code>import numpy as np
import tensorflow as tf

x_dims = 3
batch_size = 4

x = tf.placeholder(tf.float32, (None, x_dims))
y = 2*(x**2)
z = tf.stack([y, y]) # There are twice as many z's as x's

dy_dx = tf.gradients(y,x)
dz_dx = tf.gradients(z,x)

sess = tf.Session()

x_val = np.random.randint(0, 10, (batch_size, x_dims))
y_val, z_val, dy_dx_val, dz_dx_val = sess.run([y, z, dy_dx, dz_dx], {x:x_val})

print('x.shape =', x_val.shape)
print('x = \n', x_val)
print('y.shape = ', y_val.shape)
print('y = \n', y_val)
print('z.shape = ', z_val.shape)
print('z = \n', z_val)
print('dy/dx = \n', dy_dx_val[0])
print('dz/dx = \n', dz_dx_val[0])
</code></pre>

<p>Produces the following output:</p>

<pre><code>x.shape = (4, 3)
x = 
 [[1 4 8]
 [0 2 8]
 [2 8 1]
 [4 5 2]]

y.shape =  (4, 3)
y = 
 [[  2.  32. 128.]
 [  0.   8. 128.]
 [  8. 128.   2.]
 [ 32.  50.   8.]]

z.shape =  (2, 4, 3)
z = 
 [[[  2.  32. 128.]
  [  0.   8. 128.]
  [  8. 128.   2.]
  [ 32.  50.   8.]]

 [[  2.  32. 128.]
  [  0.   8. 128.]
  [  8. 128.   2.]
  [ 32.  50.   8.]]]

dy/dx = 
 [[ 4. 16. 32.]
 [ 0.  8. 32.]
 [ 8. 32.  4.]
 [16. 20.  8.]]
dz/dx = 
 [[ 8. 32. 64.]
 [ 0. 16. 64.]
 [16. 64.  8.]
 [32. 40. 16.]]
</code></pre>

<p>In particular, notice that the values of dz/dx are twice those of dy/dz since they are summed over the inputs to the stack.</p>
",8820311,109,https://stackoverflow.com/questions/51858970,Documentation Ambiguity
51824310,Difference between Keras and tensorflow implementation of LSTM with dropout,"<p>I was reviewing the documentation for the LSTM cell in tensorflow and Keras. In particular, I want to apply dropout as well. Here is what I have in Keras and would like to apply the same LSTM cell in tensorflow:</p>

<pre><code>cell = LSTM(num_units_2, return_sequences=True, dropout=dropout, recurrent_dropout=dropout)(net)
</code></pre>

<p>Therefore, I know that I need to use <code>tf.nn.rnn_cell.LSTMCell</code> in tensorflow with <code>num_units = num_units_2</code>. Second, I need a <code>DropoutWrapper</code> as:</p>

<pre><code>cell = tf.nn.rnn_cell.DropoutWrapper(cell)
</code></pre>

<p>Now, I want to apply <code>dropout</code> and <code>recurrent_dropout</code> similar to the Keras code. Therefore, I found that tensorflow's implementation of dropout will apply a different dropout mask at every time step unless <code>variational_recurrent</code> is set to True (Yet I'm not sure how variational_recurrent works in details). </p>

<p>Additionally, I'm not sure if the LSTM in Keras apply different Mask at each time step as well. </p>

<p>Second, I was confused about the difference between the <code>output_keep_prob</code> and the <code>state_keep_prob</code> as both mention: </p>

<p><em>output_keep_prob</em>: unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added...</p>

<p>Any help is much appreciated!!</p>
",-,-,2018-08-13 14:08:09,"<h2>What variational dropout does</h2>

<p>As far as I know, the main novelty of variational dropout is using the same dropout mask for all unrolled steps (as you said).</p>

<h2>Difference between <code>output_keep_prob</code> and the <code>state_keep_prob</code></h2>

<p><code>output_keep_prob</code> is the dropout rate applied to the output (h) of the LSTM cell where <code>state_keep_prob</code> is the dropout rate applied to the cell (c) of the LSTM state.</p>

<h2>Dropout choice in Keras</h2>

<p>Looking at the <code>_generate_dropout_mask</code> method in the <a href=""https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L2220-L2232"" rel=""nofollow noreferrer"">LSTM source code</a> and <a href=""https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1855-L1868"" rel=""nofollow noreferrer"">its use for the LSTMCell</a> of Keras, I think Keras LSTM uses variational recurrent dropout only for the recurrent connections (i.e. <code>self._recurrent_dropout_mask</code>) . But I'm not 100% confident about this.</p>
",7886651,2282,https://stackoverflow.com/questions/51824310,Documentation Replication on Other Examples
51706848,How does tf.reshape() work internally ?,"<p>I'm trying to understand how tf.reshape works. Let's have an example:</p>

<pre><code>embeddings = tf.placeholder(tf.float32, shape=[N0,N1])
M_2D = tf.placeholder(tf.float32, shape=[N0,None])
M_3D = tf.reshape(M_2D, [-1,N0,1])
weighted_embeddings = tf.multiply(embeddings, M_3D)
</code></pre>

<p>Here I have a 2D tensor M_2D whose columns represent coefficients for the N0 embeddings of dimension N1. I want to create a 3D tensor where each column of M_2D is placed in the first dimension of M_3D, and columns are keep in the same order. My final goal is to create a 3D tensor of 2D embeddings, each weighted by the columns of M_2D. </p>

<p>How can I be sure that reshape actually place each column in the new dimension of M_3D. Is it possible that it places the rows instead ? Is there somewhere in tensorflow documentation a clear explanation on the internal working process of tf.reshape, particularly when -1 is provided ?    </p>
",tf.reshape,tf.reshape,2018-08-06 11:43:20,"<p>Tensor before and after <code>tf.reshape</code> have the <strong>same flatten order</strong>.</p>

<p>In tensorflow runtime, a Tensor is consists of raw data(byte array), shape, and dtype, <code>tf.reshape</code> only change shape, with raw data and dtype not changed. <code>-1</code> or <code>None</code> in <code>tf.reshape</code> means that this value can be calculated.</p>

<p>For example,</p>

<pre><code># a tensor with 6 elements, with shape [3,2]
a = tf.constant([[1,2], [3,4], [5,6]]) 
# reshape tensor to [2, 3, 1], 2 is calculated by 6/3/1
b = tf.reshape(a, [-1, 3, 1])
</code></pre>

<p>In this example, <code>a</code> and <code>b</code> have the same flatten order, namely <code>[1,2,3,4,5,6]</code>, <code>a</code> has the shape <code>[3,2]</code>, its value is <code>[[1,2], [3,4], [5,6]]</code>, <code>b</code> has the shape <code>[2,3,1]</code>, its value is <code>[[[1],[2],[3]],[[4],[5],[6]]]</code>.</p>
",6084245,1551,https://stackoverflow.com/questions/51706848,Documentation Completeness
51691199,How does tf.create_partitioned_variables work?,"<p>I am trying to figure out how to use <a href=""https://www.tensorflow.org/api_docs/python/tf/create_partitioned_variables"" rel=""nofollow noreferrer"">tf.create_partitioned_variables</a>
I am reading the documentation but I am having a hard time understanding.</p>

<p>Could anyone explain how it works and give some examples of its usage? </p>

<p>From what I understand I can use it to get a list of slices from a variable.
I just dont understand how I get the slices</p>

<p>ex:
how would i get a list of <code>[[1.],[3.]]</code> from <code>tf.Variable(np.array([[1.0],[3.0]]), dtype=tf.float32)</code></p>

<p>or list of </p>

<pre><code>[[[1 0] [3 0]], [[0 5] [0 7]]]
</code></pre>

<p>from</p>

<pre><code>[[[1 0]
  [3 0]]

 [[0 5]
  [0 7]]]
</code></pre>
",tf.create_partitioned_variables,tf.compat.v1.create_partitioned_variables,2018-08-05 3:39:55,"<p>The first 3 arguments are required. The first is the shape of the input tensor. The second is the split specification. The API currently supports splits along one dimension only. The split specification has the same number of dimensions as the shape, with one split being >= 1 and the others being 1. The last argument is the tensor itself, or a callable that returns it.</p>

<p>First example:</p>

<pre><code>tf.create_partitioned_variables(v.shape, [2, 1], v)
</code></pre>

<p>Second example:</p>

<pre><code>[tf.squeeze(v) 
    for v in tf.create_partitioned_variables(
        v.shape, [2, 1, 1], v)]
</code></pre>
",774972,5999,https://stackoverflow.com/questions/51691199,Inadequate Examples
51612489,tensorflow tf.edit_distance explanation required?,"<p>How does tensorflow <code>tf.edit_distance</code> function works?
How it compares string stored in two different sparse matrix equivalent of 2d or 3d dense matrix. </p>

<p>Example given on tensorflow web page <a href=""https://www.tensorflow.org/api_docs/python/tf/edit_distance"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/edit_distance</a> is not so obvious. Please provide explanation using some other examples. </p>

<p>Also this example is not clear.</p>

<pre><code>#'hypothesis' is a tensor of shape [2, 1] with variable-length values:
#(0,0) = [""a""] and (1,0) = [""b""]

hypothesis = tf.SparseTensor([[0, 0, 0],[1, 0, 0]],[""a"", ""b""],(2, 1, 1))

#'truth' is a tensor of shape `[2, 2]` with variable-length values:
#(0,0) = [], (0,1) = [""a""], (1,0) = [""b"", ""c""],(1,1) = [""a""]

truth = tf.SparseTensor([[0, 1, 0],[1, 0, 0],[1, 0, 1],[1, 1, 0]],[""a"", ""b"", 
""c"", ""a""],(2, 2, 2))

normalize = True

#'output' is a tensor of shape [2, 2] with edit distances normalized by 
#'truth' lengths.

output ==&gt; [[inf, 1.0],[0.5, 1.0]],

(0,0): no truth, (0,1): no hypothesis, (1,0): addition, (1,1): no hypothesis
</code></pre>

<p>How output is of dimension [2,2]?</p>

<p>What normalization is doing here?</p>
",tf.edit_distance,tf.edit_distance,2018-07-31 11:37:21,"<p>hypothesis in dense form looks like this</p>

<pre><code>[[['a']],
 [['b']]] # (2, 1, 1)
</code></pre>

<p>truth is this</p>

<pre><code>[[[],['a']],
 [['b', 'c'], ['a']]] # (2, 2, 2)
</code></pre>

<p>We are trying to find the <a href=""https://en.wikipedia.org/wiki/Levenshtein_distance"" rel=""nofollow noreferrer"">Levenshtein distance</a> between hypothesis and truth value.
So, here is what is happening:</p>

<p>at (0,0,0) - how far is ['a'] in hypothesis from [] - no truth in that position so can't calculate distance</p>

<p>at (0,0,1) - since there is nothing in that position at hypothesis we return 1. Unlike the case above, the distance is 1 because in theory the hypothesis can be made same as truth by inserting one character (See Levenshtein distance calculations)</p>

<p>at (1,0,0) - how far is ['b'] in hyp from ['b', 'c'] in truth. This is again 1, since we can insert a character to make hyp same as truth. But, we selected to normalize the output distance. So we divide by length of truth segment, which is 2. So you get 0.5</p>

<p>at (1,0,1) - how far is [] in hyp from ['a'], since there is nothing in that position at hyp, we return 1</p>

<p>Output is (2,2) because rank of hyp and truth is 3. The function returns tensor with rank (rank-1) </p>

<p>It helps by imagining what we are trying to do here. You have 2 sequences in hypothesis and 2 sequences in the truth. So your output score will be such that you get scores for each position in each sequence.</p>

<p>Here is an example where we try to match 4 hypotheses to a truth value. I think you have to do this for each truth sequence for the use case that you describe in your comment - let me know if you find something more efficient :-)</p>

<pre><code>import tensorflow as tf

hypothesis = tf.SparseTensor(
            [[0, 0, 0],
             [1, 0, 0],
             [2, 0, 0],
             [3, 0, 0]],
             [""a"", ""b"", ""c"", ""d""],
            (4, 1, 1))

truth = tf.SparseTensor([[0, 0, 0], [0, 0, 1], [0, 1, 0]], [""b"", ""c"", ""a""], (1,2,2))
num_hyp = 4
truth = tf.sparse_concat(0, [truth] * num_hyp)

d = tf.edit_distance(hypothesis, truth)

with tf.Session() as sess:
    print(sess.run(d))
</code></pre>

<p>Output:</p>

<pre><code>[[1.  1. ]
 [0.5 1. ]
 [0.5 1. ]
 [1.  1. ]]
</code></pre>
",7930290,397,https://stackoverflow.com/questions/51612489,Lack of Alternative Solutions/Documentation
51586693,"Tensor has shape [?, 0] -- how to reshape to [?,]","<p>When <code>src</code> has shape <code>[?]</code>, <code>tf.gather(src, tf.where(src != 0))</code> returns a tensor with shape <code>[?, 0]</code>. I'm not sure how a dimension can have size 0, and I'm especially unsure how to change the tensor back. I didn't find anything in the documentation to explain this, either.</p>

<p>I tried to <code>tf.transpose(tensor)[0]</code>, but the first dimension of the transposed tensor has size 0 and cannot be accessed! What's wrong?</p>
",tf.gather,tf.gather,2018-07-30 3:41:10,"<p>I think you should use <a href=""https://www.tensorflow.org/api_docs/python/tf/not_equal"" rel=""nofollow noreferrer""><code>tf.not_equal</code></a> to perform elementwise comparison on the tensor.</p>

<pre><code>src = tf.constant([0, 1, 1, 0], dtype=tf.int8)
tf.gather(src, tf.where(tf.not_equal(src, 0))).eval(session=tf.Session())

array([[1],
       [1]], dtype=int8)
</code></pre>

<p>You can also shorten this a bit and use <a href=""https://www.tensorflow.org/api_docs/python/tf/boolean_mask"" rel=""nofollow noreferrer""><code>tf.boolean_mask</code></a> instead of <code>tf.where</code> and <code>tf.gather</code>:</p>

<pre><code>tf.boolean_mask(src, tf.not_equal(src, 0)).eval(session=tf.Session())
array([1, 1], dtype=int8)
</code></pre>

<p>Note the difference in the shape of the outputs.</p>
",6772171,1574,https://stackoverflow.com/questions/51586693,Documentation Replication on Other Examples
51069173,What exactly qualifies as a 'Tensor' in TensorFlow?,"<p>I am new to TensorFlow and just went through the eager execution tutorial and came across the tf.decode_csv function. Not knowing about it, I read the documentation.  <a href=""https://www.tensorflow.org/api_docs/python/tf/decode_csv"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/decode_csv</a></p>

<p>I don't really understand it. </p>

<p>The documentation says 'records: A Tensor of type string.' 
<strong>So, my question is: What qualifies as a 'Tensor'?</strong> </p>

<p>I tried the following code:</p>

<pre><code>dec_res = tf.decode_csv('0.1,0.2,0.3', [[0.0], [0.0], [0.0]])
print(dec_res, type(dec_res))



l = [[1,2,3],[4,5,6],[7,8,9]]
r = tf.reshape(l, [9,-1])
print(l, type(l))
print(r, type(r))
</code></pre>

<p>So the list <code>dec_res</code> contains tf.tensor objects. That seems reasonable to me. But is an ordinary string also a 'Tensor' according to the documentation?</p>

<p>Then I tried something else with the <code>tf.reshape</code> function. In the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/reshape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/reshape</a> it says that 'tensor: A Tensor.' So, <code>l</code> is supposed to be a tensor. But it is not of type <code>tf.tensor</code> but simply a python <code>list</code>. This is confusing.</p>

<p>Then the documentation says </p>

<blockquote>
  <p>Returns:</p>
  
  <p>A Tensor. Has the same type as tensor.</p>
</blockquote>

<p>But the type of <code>l</code> is <code>list</code> where the type of <code>r</code> is <code>tensorflow.python.framework.ops.Tensor</code>. So the types are not the same. </p>

<p>Then I thought that TensorFlow is very generous with things being a tensor. So I tried:</p>

<pre><code>class car(object):
def __init__(self, color):
    self.color = color


red_car = car('red')
#test_reshape = tf.reshape(red_car, [1, -1])
print(red_car.color) # to check, that red_car exists.
</code></pre>

<p>Now, the line in comments results in an error. </p>

<p>So, can anyone help me to find out, what qualifies as a 'Tensor'?</p>

<p>P.S.: I tried to read the source code of <code>tf.reshape</code> as given in the documentation </p>

<blockquote>
  <p>Defined in tensorflow/python/ops/gen_array_ops.py.</p>
</blockquote>

<p>But this file does not exist in the Github repo. Does anyone know how to read it?</p>
",tf.decode_csv,tf.io.decode_csv,2018-06-27 18:20:58,"<p><a href=""https://www.tensorflow.org/programmers_guide/tensors"" rel=""nofollow noreferrer"">https://www.tensorflow.org/programmers_guide/tensors</a></p>

<blockquote>
  <p>TensorFlow, as the name indicates, is a framework to define and run
  computations involving tensors. A tensor is a generalization of
  vectors and matrices to potentially higher dimensions. Internally,
  TensorFlow represents tensors as n-dimensional arrays of base
  datatypes.</p>
</blockquote>

<p>What you are observing commes from the fact that tensorflow operations (like reshape) can be built from various python types using the function tf.convert_to_tensor:</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor</a></p>

<blockquote>
  <p>All standard Python op constructors apply this function to each of
  their Tensor-valued inputs, which allows those ops to accept numpy
  arrays, Python lists, and scalars in addition to Tensor objects</p>
</blockquote>
",6810233,153,https://stackoverflow.com/questions/51069173,Requesting (Additional) Documentation/Examples
50820781,quesion about the axis of tf.stack(),"<p>I read the doc of <code>tf.stack()</code> on <a href=""https://www.tensorflow.org/api_docs/python/tf/stack"" rel=""nofollow noreferrer"">tensorflow stack </a>. There is an example on the page:</p>

<pre><code>&gt;&gt;&gt; x = tf.constant([1, 4])
&gt;&gt;&gt; y = tf.constant([2, 5])
&gt;&gt;&gt; z = tf.constant([3, 6])
&gt;&gt;&gt; sess=tf.Session()
&gt;&gt;&gt; sess.run(tf.stack([x, y, z]))
array([[1, 4],
       [2, 5],
       [3, 6]], dtype=int32)
&gt;&gt;&gt; sess.run(tf.stack([x, y, z], axis=1))
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)
</code></pre>

<p>what I don't understand is the second example where <code>axis=1</code>.</p>

<p>From the result it seems it converts the three inputs rows to columns first </p>

<p>and then put them toghter along the <code>axis=1</code>, but </p>

<p>I think the result should be </p>

<pre><code>array([[1,4, 2, 5, 3, 6 ]] dtype=int32 )
</code></pre>

<p>can anyone help explain this?</p>

<p>Thanks!</p>
",tf.stack,tf.stack,2018-06-12 15:27:38,"<p><code>tf.stack</code> always adds a new dimension, and always concatenates the given tensor along that new dimension. In your case, you have three tensors with shape <code>[2]</code>. Setting <code>axis=0</code> is the same as adding a new first dimension, so each tensor would now have shape <code>[1, 2]</code>, and concatenating across that dimension, so the final shape would be <code>[3, 2]</code>. That is, each tensor would be a ""row"" of the final tensor. With <code>axis=1</code> the shapes of each individual tensor would be extended to <code>[2, 1]</code>, and the result would have shape <code>[2, 3]</code>. So each given tensor would be a ""column"" of the resulting tensor.</p>

<p>In other words, <code>tf.stack</code> is functionally equivalent to this:</p>

<pre><code>def tf.stack(tensors, axis=0):
    return tf.concatenate([tf.expand_dims(t, axis=axis) for t in tensors], axis=axis)
</code></pre>

<p>But the result that you expect would be obtained with something like this:</p>

<pre><code>tf.concatenate([tf.expand_dims(t, axis=0) for t in tensors], axis=1)
</code></pre>

<p>Note that the added dimension and the concatenation dimension are different in this case.</p>
",1347796,609,https://stackoverflow.com/questions/50820781,Inadequate Examples
50606178,TensorFlow tf.data.Dataset and bucketing,"<p>For an LSTM network, I've seen great improvements with bucketing.</p>

<p>I've come across the <a href=""https://www.tensorflow.org/api_guides/python/contrib.training#Bucketing"" rel=""noreferrer"">bucketing section in the TensorFlow docs</a> which (tf.contrib).</p>

<p>Though in my network, I am using the <code>tf.data.Dataset</code> API, specifically I'm working with TFRecords, so my input pipeline looks something like this</p>

<pre><code>dataset = tf.data.TFRecordDataset(TFRECORDS_PATH)
dataset = dataset.map(_parse_function)
dataset = dataset.map(_scale_function)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.padded_batch(batch_size, padded_shapes={.....})
</code></pre>

<p>How can I incorporate the bucketing method into a the <code>tf.data.Dataset</code> pipeline?</p>

<p>If it matters, in every record in the TFRecords file I have the sequence length saved as an integer.</p>
",-,-,2018-05-30 13:37:22,"<p>Various <code>bucketing</code> use cases using <code>Dataset API</code> are explained well <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/kernel_tests/bucketing_test.py"" rel=""nofollow noreferrer"">here</a>.</p>

<p><strong><code>bucket_by_sequence_length()</code> example:</strong></p>

<pre><code>def elements_gen():
   text = [[1, 2, 3], [3, 4, 5, 6, 7], [1, 2], [8, 9, 0, 2]]
   label = [1, 2, 1, 2]
   for x, y in zip(text, label):
       yield (x, y)

def element_length_fn(x, y):
   return tf.shape(x)[0]

dataset = tf.data.Dataset.from_generator(generator=elements_gen,
                                     output_shapes=([None],[]),
                                     output_types=(tf.int32, tf.int32))

dataset =   dataset.apply(tf.contrib.data.bucket_by_sequence_length(element_length_func=element_length_fn,
                                                              bucket_batch_sizes=[2, 2, 2],
                                                              bucket_boundaries=[0, 8]))

batch = dataset.make_one_shot_iterator().get_next()

with tf.Session() as sess:

   for _ in range(2):
      print('Get_next:')
      print(sess.run(batch))
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>Get_next:
(array([[1, 2, 3, 0, 0],
   [3, 4, 5, 6, 7]], dtype=int32), array([1, 2], dtype=int32))
Get_next:
(array([[1, 2, 0, 0],
   [8, 9, 0, 2]], dtype=int32), array([1, 2], dtype=int32))
</code></pre>
",5368083,12085,https://stackoverflow.com/questions/50606178,Documentation Replicability
50514454,End of Sequence Error when using tf.estimator and tf.data,"<p>I am using <code>tf.estimator.train_and_evaluate</code> and <code>tf.data.Dataset</code> to feed data to the estimator:</p>

<p>Input Data function:</p>

<pre><code>    def data_fn(data_dict, batch_size, mode, num_epochs=10):
        dataset = {}
        if mode == tf.estimator.ModeKeys.TRAIN:
            dataset = tf.data.Dataset.from_tensor_slices(data_dict['train_data'].astype(np.float32))
            dataset = dataset.cache()
            dataset = dataset.shuffle(buffer_size= batch_size * 10).repeat(num_epochs).batch(batch_size)
        else:
            dataset = tf.data.Dataset.from_tensor_slices(data_dict['valid_data'].astype(np.float32))
            dataset = dataset.cache()
            dataset = dataset.batch(batch_size)

        iterator = dataset.make_one_shot_iterator()
        next_element = iterator.get_next()

    return next_element
</code></pre>

<p>Train Function:</p>

<pre><code>def train_model(data):
    tf.logging.set_verbosity(tf.logging.INFO)
    config = tf.ConfigProto(allow_soft_placement=True,
                            log_device_placement=False)
    config.gpu_options.allow_growth = True
    run_config = tf.contrib.learn.RunConfig(
        save_checkpoints_steps=10,
        keep_checkpoint_max=10,
        session_config=config
    )

    train_input = lambda: data_fn(data, 100, tf.estimator.ModeKeys.TRAIN, num_epochs=1)
    eval_input = lambda: data_fn(data, 1000, tf.estimator.ModeKeys.EVAL)
    estimator = tf.estimator.Estimator(model_fn=model_fn, params=hps, config=run_config)
    train_spec = tf.estimator.TrainSpec(train_input, max_steps=100)
    eval_spec = tf.estimator.EvalSpec(eval_input,
                                      steps=None,
                                      throttle_secs = 30)

    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</code></pre>

<p>The training goes fine, but when it comes to evaluation I get this error:</p>

<pre><code>OutOfRangeError (see above for traceback): End of sequence 
</code></pre>

<p>If I don't use <code>Dataset.batch</code> on evaluation dataset (by omitting the line <code>dataset[name] = dataset[name].batch(batch_size)</code> in <code>data_fn</code>) I get the same error but after a much longer time.</p>

<p>I can only avoid this error if I don't batch the data and use <code>steps=1</code> for evaluation, but does that perform the evaluation on the whole dataset?</p>

<p>I don't understand what causes this error as the documentation suggests I should be able to evaluate on batches too.</p>

<p>Note: I get the same error when using <code>tf.estimator.evaluate</code> on data batches.</p>
",tf.data.Dataset,tf.data.Dataset,2018-05-24 16:50:01,"<p>I posted this question as a github issue and here is the response from the Tensorflow team:</p>
<p><a href=""https://github.com/tensorflow/tensorflow/issues/19541"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/19541</a></p>
<p>Copying from &quot;xiejw&quot; for completeness:</p>
<blockquote>
<p>If I understand correctly, this issue is &quot;once give estimator an input_fn with dataset inside, the evaluate process will error out with OutOfRangeError.&quot;</p>
<p>Estimator can handle this correctly actually. However, a known common root cause for this is metrics defined in model_fn have bug. We need to rule that part out first.</p>
<p>@mrezak if possible, can you show the code about the model_fn? Or if you have a minimal reproducible script, that will be extremely helpful. -- Thanks in advance.</p>
<p>A common problem for this is: metric in tensorflow should return two Ops: update_op and value_op. Estimator calls the update_op for each batch of the data in input source and, once it is exhausted, it call the value_op to get the metric values. The value_op here should have dependency back to variables reading only.</p>
<p>Many model_fn puts the dependency of value_op with the input pipeline, so, estimator.evaluate will thereby trigger the input pipeline one more time, which errors out with OutOfRangeError</p>
</blockquote>
<p>The problem was indeed how I defined the <code>eval_metric</code> in <code>model_fn</code>. In my actual code my total loss to be optimized was composed of multiple losses (reconstruction + L2 + KL) and in the evaluation part I wanted to get the reconstruction loss (on the validation data), which depended on the input data pipeline. My actual reconstruction cost was more complex than MSE (none of the other tf.metric functions as well) which was not straightforward to be implemented using tf.metric basic functions.</p>
<p>This is &quot;xiejw&quot;'s suggestion which fixed the issue:</p>
<pre><code>my_total_loss =  ... # the loss you care. Pay attention to how you reduce the loss. 
eval_metric_ops = {'total_loss: tf.metrics.mean(my_total_loss)}
</code></pre>
",8636859,273,https://stackoverflow.com/questions/50514454,Documentation Replication on Other Examples
50383462,how to randomly initialize weights in tensorflow?,"<p>in tensorflow, I learned from the tutorial that one would initialize the variables with something like
<code>
sess.run(tf.global_variables_initializer())
</code></p>

<p>however I found that every time I run this with the same input dataset, the loss value starts with the same value.</p>

<p>I presume this is due to the fact that the initialization is always setting up the variables with the same values. (probably zero)</p>

<p>I wish to randomize the values of weights. I've tried searching for this but  tensorflow docs doesn't give a clear answer if the initialization is done with zero values by default or random values.</p>

<p>How can I specify the initializaing to setup random values?</p>

<hr>

<p><strong>update</strong></p>

<p>my network is first a bunch of CNNs and pooling layers like below:
```
conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[3,3], padding=""same"", activation=tf.nn.relu, name=""conv_chad_1"")</p>

<pre><code>    pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2)

    conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3,3], padding=""same"", activation=tf.nn.relu, name=""conv_chad_2"")

    pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2, name=""pool_chad_2"")
</code></pre>

<p>```</p>

<p>AFAIK, the weights are defined inside these predefined layers. How do I specify these layers to initialize their weight variables randomly??</p>
",-,-,2018-05-17 4:42:33,"<p>You should provide more information. For example, how do you initialize your variables in your graph? For initializing your weights in a neural network, you must initialize them randomly (biases are ok to be initialized all as zero). Thus you must use a code like the following for defining them with proper initialization:</p>

<pre><code># initialize weights randomly from a Gaussian distribution
# step 1: create the initializer for weights
weight_initer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)
# step 2: create the weight variable with proper initialization
W = tf.get_variable(name=""Weight"", dtype=tf.float32, shape=[784, 200], initializer=weight_initer)

# initialize biases as zero
# step 1: create the initializer for biases
bias_initer =tf.constant(0., shape=[200], dtype=tf.float32)
# step 2: create the bias variable with proper initialization
b = tf.get_variable(name=""Bias"", dtype=tf.float32, initializer=bias_initer)
</code></pre>
",3044831,807,https://stackoverflow.com/questions/50383462,Documentation Replication on Other Examples
50246535,Tensorflow estimator input function: defining each feature or not?,"<p>With <code>x</code> is a 120 x 4 feature matrix of Iris data (4 features) and <code>y</code> is a label, I can make an input function for <code>tf.estimator</code> like below </p>

<pre><code>def input_function(x, y):
    dict_x = {
        ""sepal_length"" : x[:,0],
        ""sepal_width"" :  x[:,1],
        ""petal_length"" : x[:,2],
        ""petal_width"" :  x[:,3]
    }

    dataset = tf.data.Dataset.from_tensor_slices((
        dict_x, y
    ))

    return dataset
</code></pre>

<p>then define the feature column like below:</p>

<pre><code>feature_columns = [
    tf.feature_column.numeric_column(key=""sepal_length""),
    tf.feature_column.numeric_column(key=""sepal_width""),
    tf.feature_column.numeric_column(key=""petal_length""),
    tf.feature_column.numeric_column(key=""petal_width"")
]
</code></pre>

<p>But, I found in the internet (I forget the source, still searching) that I also can define the input function like below. The difference with previous method is all four features now defined with only one key, <code>""x""</code>.</p>

<pre><code>def input_function(x, y):
    dict_x = {
        ""x"" : x,
    }

    dataset = tf.data.Dataset.from_tensor_slices((
        dict_x, y
    ))

    return dataset
</code></pre>

<p>then define the feature column like below:</p>

<pre><code>feature_columns = [
    tf.feature_column.numeric_column(key=""x"",shape=4),
]
</code></pre>

<p>I've run both method and both give almost same result. <strong>My question</strong>: I can't find any documentation that explain the difference between both method, because at a glance <code>dict_x</code> have different shape. Are they still treated equally at input layer on neural networks?</p>

<p>I'm new using <code>tf.estimator</code>, Thank You</p>

<p>My estimator code if needed:</p>

<pre><code>classifier = tf.estimator.DNNClassifier(
    feature_columns=feature_columns,
    hidden_units=[10],
    n_classes=3,
    optimizer=tf.train.GradientDescentOptimizer(0.001),
    activation_fn=tf.nn.relu
)

# Train the model
classifier.train(
    input_fn=lambda:input_function(xtrain, ytrain, True)
)
</code></pre>
",-,-,2018-05-09 6:07:16,"<p>In case of <code>numeric_column</code> with same <code>dtype</code>'s the only difference is shape of the resultant input:</p>

<p>Option 1 creates input of shape: <code>[120,4,1]</code>: 120 samples, each represented by 4 vectors of 1 number.</p>

<p>Whereas option 2 creates input of shape: <code>[120,1,4]</code>: 120 samples, each represented by a single vector consisting of 4 numbers.</p>

<p>In the end, it does not really matter because both get flattened to <code>[120,4]</code> before being fed to the network.</p>

<hr>

<p>First I created the features.</p>

<pre><code>features1 = {
    'sepal_length' : np.random.rand(120),
    'sepal_width': np.random.rand(120),
    'petal_length': np.random.rand(120),
    'petal_width': np.random.rand(120)
}

features2 = {
    'everything' : np.random.rand(120, 4)
}
</code></pre>

<p>
Then I prepared the feature columns -- same as you did.</p>

<pre><code>feature_columns1 = [
    tf.feature_column.numeric_column(key=""sepal_length""),
    tf.feature_column.numeric_column(key=""sepal_width""),
    tf.feature_column.numeric_column(key=""petal_length""),
    tf.feature_column.numeric_column(key=""petal_width"")
]

feature_columns2 = [
    tf.feature_column.numeric_column(key=""everything"", shape=4),
]
</code></pre>

<p>
Now, to see what exactly is done with them when they're fed to the network we can use the <code>feature_column.input_layer()</code>.</p>

<pre><code>inputs1 = tf.feature_column.input_layer(features1, feature_columns1)
inputs2 = tf.feature_column.input_layer(features2, feature_columns2)
</code></pre>

<p>
And as we can see, both ways produced the same shape.</p>

<pre><code>with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    res1 = sess.run(inputs1)
    res2 = sess.run(inputs2)
</code></pre>

 

<pre><code>print(res1.shape)
print(res2.shape)
(120, 4)
(120, 4)
</code></pre>
",2147347,3145,https://stackoverflow.com/questions/50246535,Lack of Alternative Solutions/Documentation
50243230,Unable to understand tf.nn.raw_rnn,"<p>In the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn"" rel=""nofollow noreferrer"">official documentation</a> of <code>tf.nn.raw_rnn</code> we have emit structure as the third output of <code>loop_fn</code> when the <code>loop_fn</code> is run for the first time.</p>

<p>Later on the emit_structure is used to copy <code>tf.zeros_like(emit_structure)</code> to the minibatch entries that are finished by <code>emit = tf.where(finished, tf.zeros_like(emit_structure), emit)</code>.</p>

<p>my lack of understanding or lousy documentation on google's part is: emit structure is <code>None</code> so <code>tf.where(finished, tf.zeros_like(emit_structure), emit)</code> is going to throw a ValueError as <code>tf.zeros_like(None)</code> does so. Can somebody please fill in what I am missing here?</p>
",tf.nn.raw_nn,tf.compat.v1.nn.raw_rnn,2018-05-08 22:45:02,"<p>Yep, the doc is rather confusing in this place. If you look at the internals of <code>tf.nn.raw_rnn</code>, the key term there is <strong>""in pseudo-code""</strong>, so the example in the doc isn't accurate.</p>

<p>The exact source code looks like this (may differ depending on your tensorflow version):</p>



<pre class=""lang-py prettyprint-override""><code>if emit_structure is not None:
  flat_emit_structure = nest.flatten(emit_structure)
  flat_emit_size = [emit.shape if emit.shape.is_fully_defined() else
                    array_ops.shape(emit) for emit in flat_emit_structure]
  flat_emit_dtypes = [emit.dtype for emit in flat_emit_structure]
else:
  emit_structure = cell.output_size
  flat_emit_size = nest.flatten(emit_structure)
  flat_emit_dtypes = [flat_state[0].dtype] * len(flat_emit_size)
</code></pre>

<p>So it handles the case when <code>emit_structure is None</code> and simply takes the value <code>cell.output_size</code>. That's why nothing really breaks.</p>
",6546694,5020,https://stackoverflow.com/questions/50243230,Documentation Replication on Other Examples
49987839,How to handle None in tf.clip_by_global_norm?,"<p>I have read in answers to <a href=""https://stackoverflow.com/questions/36498127/how-to-apply-gradient-clipping-in-tensorflow"">this question here</a> that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws </p>

<p>ValueError: None values not supported.</p>

<pre><code>tf.reset_default_graph()
z = tf.get_variable(name = 'z', shape = [1])
b = tf.get_variable('b', [1])
c = b*b - 2*b + 1
optimizer = tf.train.AdamOptimizer(0.1)
gradients, variables = zip(*optimizer.compute_gradients(c))
gradients = tf.clip_by_global_norm(gradients, 2.5)
train_op = optimizer.apply_gradients(zip(gradients, variables))
</code></pre>

<p>Can somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually</p>

<p>The official documentation seems to agree with @danijar's comments. see <a href=""https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/clip_by_global_norm"" rel=""nofollow noreferrer"">here</a></p>

<blockquote>
  <p>Any of the entries of t_list that are of type None are ignored.</p>
</blockquote>
",tf.clip_by_global_norm,tf.clip_by_global_norm,2018-04-23 18:38:06,"<p>There's a small problem in your code: you're assigning the return value of <code>tf.clip_by_global_norm</code> to a single variable, when this function returns a pair of values.</p>

<p>The documentation says:</p>

<blockquote>
  <p>Returns:</p>
  
  <p>list_clipped: A list of Tensors of the same type as list_t.</p>
  
  <p>global_norm: A 0-D (scalar) Tensor representing the global norm.</p>
</blockquote>

<p>Hence, the problem arises when you try to apply the gradients to the variables, in the next line.</p>

<p>You can easily fix your code ignoring the global_norm returned value.</p>

<pre><code>gradients, _ = tf.clip_by_global_norm(gradients, 2.5)
</code></pre>
",6546694,5020,https://stackoverflow.com/questions/49987839,Documentation Replicability
49899526,Tensorflow input pipeline where multiple rows correspond to a single observation?,"<p>So I've just started using Tensorflow, and I'm struggling to properly understand input pipelines. </p>

<p>The problem I'm working on is sequence classification.
I'm trying to read in a CSV file with shape (100000, 4). First 3 columns are features, 4th column is the label. BUT - the data represents sequences of length 10 i.e. rows 1-10 are sequence 1, rows 11-20 are sequence 2 etc. This also means each label is repeated 10 times.</p>

<p>So at some point in this input pipeline, I'll need to reshape my feature tensor like tf.reshape(features, [batch_size_, rows_per_ob, input_dim]). 
And only take every 10th row of my label tensor like label[::rows_per_ob]</p>

<p>Another thing I should point out is that my actual dataset is in the billions of rows so I have to think about performance.</p>

<p>I've put together the below code from documentation and other posts on here, but I don't think I fully understand this because I'm seeing the following error:</p>

<blockquote>
  <p>INFO:tensorflow:Error reported to Coordinator: , Attempting to use uninitialized value input_producer_2/limit_epochs/epochs</p>
</blockquote>

<p>There seems to be an out of range error.</p>

<p>I also can't figure out what to do with these batches once I get them working. Initially, I thought I would reshape them then just feed them into ""feed_dict"", but then I read that this is really bad, and I should be using a tf.data.Dataset object. But I'm not sure how to feed these batches into a Dataset. I'm also not entirely sure when would be the optimal time in this process to reshape my data?</p>

<p>And a final point of confusion - when you use an Iterator with a Dataset object, I see that we use the get_next() method. Does this mean that each element in the Dataset represent a full batch of data? And does this then mean that if we want to change the batch size, we need rebuild the entire Dataset object?</p>

<p>I'm really struggling to fit all the pieces together. If anyone has any pointers for me, it would be very much appreciated! Thanks!</p>

<pre><code># import
import tensorflow as tf

# constants
filename = ""tensorflow_test_data.csv""
num_rows = 100000
rows_per_ob = 10
batch_size_ = 5
num_epochs_ = 2
num_batches = int(num_rows * num_epochs_ / batch_size_ / rows_per_ob)

# read csv line
def read_from_csv(filename_queue):
    reader = tf.TextLineReader(skip_header_lines=1)
    _, value = reader.read(filename_queue)
    record_defaults = [[0.0], [0.0], [0.0], [0.0]]
    a, b, c, d = tf.decode_csv(value, record_defaults=record_defaults)
    features = tf.stack([a, b, c])
    return features, d

def input_pipeline(filename=filename, batch_size=batch_size_, num_epochs=num_epochs_):
    filename_queue = tf.train.string_input_producer([filename],
                                                    num_epochs=num_epochs,
                                                    shuffle=False)
    x, y = read_from_csv(filename_queue)
    x_batch, y_batch = tf.train.batch([x, y],
                                      batch_size = batch_size * rows_per_ob,
                                      num_threads=1,
                                      capacity=10000)
    return x_batch, y_batch

###
x, y = input_pipeline(filename, batch_size=batch_size_,
                      num_epochs = num_epochs_)

# I imagine using lists is wrong here - this was more just for me to
# see the output
x_list = []
y_list = []
with tf.Session() as sess:
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    for _ in range(num_batches):
        x_batch, y_batch = sess.run([x, y])
        x_list.append(x_batch)
        y_list.append(y_batch)
    coord.request_stop()
    coord.join(threads)
</code></pre>
",-,-,2018-04-18 12:17:41,"<p>You can express the entire pipeline using <code>tf.data.Dataset</code> objects, which might make things slightly easier:</p>

<pre><code>dataset = tf.data.TextLineDataset(filename)

# Skip the header line.
dataset = dataset.skip(1)

# Combine 10 lines into a single observation.   
dataset = dataset.batch(rows_per_ob)

def parse_observation(line_batch):
  record_defaults = [[0.0], [0.0], [0.0], [0.0]]
  a, b, c, d = tf.decode_csv(value, record_defaults=record_defaults)
  features = tf.stack([a, b, c])
  label = d[-1]  # Take the label from the last row.
  return features, label

# Parse each observation into a `row_per_ob X 2` matrix of features and a
# scalar label.
dataset = dataset.map(parse_observation)

# Batch multiple observations.
dataset = dataset.batch(batch_size)

# Optionally add a prefetch for performance.
dataset = dataset.prefetch(1)
</code></pre>

<p>To use the values from the dataset, you can make a <code>tf.data.Iterator</code> to get the next element as a pair of <code>tf.Tensor</code> objects, then use these as the input to your model.</p>

<pre><code>iterator = dataset.make_one_shot_iterator()

features_batch, label_batch = iterator.get_next()

# Use the `features_batch` and `label_batch` tensors as the inputs to
# the model, rather than fetching them and feeding them via the `Session`
# interface.
train_op = build_model(features_batch, label_batch)
</code></pre>
",5323535,143,https://stackoverflow.com/questions/49899526,Documentation Replication on Other Examples
49701918,tf.layers.batch_normalization parameters,"<p>I am not sure if it is only me who thinks that tensorflow documentation is a bit weak.</p>

<p>I was planing to use the tf.nn.batch_normalization function to implement batch normalization but later recognized the  tf.layers.batch_normalization function which seemingly should be the one to use for its simplicity. But the documentation is really poor if I may say it.</p>

<p>I am trying to understand how to <em>correctly</em> use it but with the information provided on the Web page is it really not easy. I am hoping that maybe some other people have experience and help me (and possibly many others) to understand it.. </p>

<p>Let me share the interface first:</p>

<pre><code>tf.layers.batch_normalization(
    inputs,
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer=tf.zeros_initializer(),
    gamma_initializer=tf.ones_initializer(),
    moving_mean_initializer=tf.zeros_initializer(),
    moving_variance_initializer=tf.ones_initializer(),
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    training=False,
    trainable=True,
    name=None,
    reuse=None,
    renorm=False,
    renorm_clipping=None,
    renorm_momentum=0.99,
    fused=None,
    virtual_batch_size=None,
    adjustment=None
)
</code></pre>

<p>Q1) beta values are initialized to zero and gamma values are initialized to 1. But it does not say why. When batch normalization used, I understand that the ordinary bias parameter of the neural network becomes obsolete and beta parameter in the batch normalization step kind of does the same thing. From that angle, setting beta to zero is understandable. But why are gamma values initialized to 1? Is that really the most efficient way?</p>

<p>Q2) I see a momentum parameter there as well. The documentation just says "" Momentum for the moving average."". I assume that this parameter is used when calculating the ""mean"" value for a certain mini batch in the corresponding hidden layer. With other words, the mean value used in batch normalization is NOT the mean of current mini batch, it is rather primarily the mean of the last 100 mini batches (since momentum = 0.99). But it is very unclear how this parameter affects the execution in testing, or if I am just validating my model on the dev set by calculating cost and accuracy. My <em>assumption</em> is that anytime I deal with test and dev sets, I set the parameter ""training"" to False so that momentum parameter becomes obsolete for that particular execution and the ""mean"" and ""variance"" values that were calculated during the training are used now instead of calculating new mean and variance values. It is how it should be if I am mistaken but I do not see anything in the documentation if it is the case. Could anyone confirm that my understanding correct? If not, I would really appreciate further explanation on this.</p>

<p>Q3) I am having difficulties to give a meaning to the trainable parameter. I assume beta and gamma params are meant here. Why would they not be trainable?</p>

<p>Q4) The ""reuse"" parameter. What is it really?</p>

<p>Q5) adjustment parameter. Another mistery..</p>

<p>Q5) A kind of summary question.. Here is my overall assumption that needs confirmation and feedback.. Important params here are:
- inputs
- axis
- momentum
- center
- scale
- training
And I assume that as long as the training=True when training, we are safe. And as long as training=False when validating dev set or test set or even when using the model in real life, we are safe too.</p>

<p>Any feedback will really be appreciated.</p>

<p>ADDENDUM:</p>

<p>Confusion continues. Help!</p>

<p>I am trying to use this function instead of implementing a batch normalizer manually. I have the following forward propagation function that loops through layers of the NN.</p>

<pre><code>def forward_propagation_with_relu(X, num_units_in_layers, parameters, 
                                  normalize_batch, training, mb_size=7):

    L = len(num_units_in_layers)

    A_temp = tf.transpose(X)

    for i in range (1, L):
        W = parameters.get(""W""+str(i))
        b = parameters.get(""b""+str(i))
        Z_temp = tf.add(tf.matmul(W, A_temp), b)

        if normalize_batch:
            if (i &lt; (L-1)):  
                with tf.variable_scope(""batch_norm_scope"", reuse=tf.AUTO_REUSE):
                    Z_temp = tf.layers.batch_normalization(Z_temp, axis=-1, 
                                                           training=training)

        A_temp = tf.nn.relu(Z_temp)

    return Z_temp   #This is the linear output of last layer
</code></pre>

<p>The tf.layers.batch_normalization(..) function wants to have static dimensions but I do not have it in my case.</p>

<p>Since I apply mini batches rather than training the entire train set each time before I run the optimizer, 1 dimension of the X appears to be unknown.</p>

<p>If I write:</p>

<pre><code>print(X.shape)
</code></pre>

<p>I get:</p>

<pre><code>(?, 5)
</code></pre>

<p>And when this is the case, when I run the whole program I get the following error below.</p>

<p>I saw in some other threads that some people say that they could solve the problem by using tf.reshape function. I try it.. Forward prop goes fine but later on it crashes in the Adam Optimizer..</p>

<p>Here is what I get when I run the code above (without using tf.reshape):</p>

<p>How do I solve this???</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-191-990fb7d7f7f6&gt; in &lt;module&gt;()
     24 parameters = nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs,
     25                       normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers,
---&gt; 26                       lambd, print_progress)
     27 
     28 print(parameters)

&lt;ipython-input-190-59594e979129&gt; in nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs, normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers, lambd, print_progress)
     34         # Forward propagation: Build the forward propagation in the tensorflow graph
     35         ZL = forward_propagation_with_relu(X_mini_batch, num_units_in_layers, 
---&gt; 36                                            parameters, normalize_batch, training)
     37 
     38     with tf.name_scope(""calc_cost""):

&lt;ipython-input-187-8012e2fb6236&gt; in forward_propagation_with_relu(X, num_units_in_layers, parameters, normalize_batch, training, mb_size)
     15                 with tf.variable_scope(""batch_norm_scope"", reuse=tf.AUTO_REUSE):
     16                     Z_temp = tf.layers.batch_normalization(Z_temp, axis=-1, 
---&gt; 17                                                            training=training)
     18 
     19         A_temp = tf.nn.relu(Z_temp)

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py in batch_normalization(inputs, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, training, trainable, name, reuse, renorm, renorm_clipping, renorm_momentum, fused, virtual_batch_size, adjustment)
    775       _reuse=reuse,
    776       _scope=name)
--&gt; 777   return layer.apply(inputs, training=training)
    778 
    779 

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)
    805       Output tensor(s).
    806     """"""
--&gt; 807     return self.__call__(inputs, *args, **kwargs)
    808 
    809   def _add_inbound_node(self,

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    676           self._defer_regularizers = True
    677           with ops.init_scope():
--&gt; 678             self.build(input_shapes)
    679           # Create any regularizers added by `build`.
    680           self._maybe_create_variable_regularizers()

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py in build(self, input_shape)
    251       if axis_to_dim[x] is None:
    252         raise ValueError('Input has undefined `axis` dimension. Input shape: ',
--&gt; 253                          input_shape)
    254     self.input_spec = base.InputSpec(ndim=ndims, axes=axis_to_dim)
    255 

ValueError: ('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(6), Dimension(None)]))
</code></pre>

<p>This is so hopeless.. </p>

<p>ADDENDUM(2)</p>

<p>I am adding more information:</p>

<p>The following simply means that there are 5 units in input layer, 6 units in each hidden layer, and 2 units in output layer.</p>

<pre><code>num_units_in_layers = [5,6,6,2] 
</code></pre>

<p>Here is the updated version of forward prop function with tf.reshape</p>

<pre><code>def forward_propagation_with_relu(X, num_units_in_layers, parameters, 
                                  normalize_batch, training, mb_size=7):

    L = len(num_units_in_layers)
    print(""X.shape before reshape: "", X.shape)             # ADDED LINE 1
    X = tf.reshape(X, [mb_size, num_units_in_layers[0]])   # ADDED LINE 2
    print(""X.shape after reshape: "", X.shape)              # ADDED LINE 3
    A_temp = tf.transpose(X)

    for i in range (1, L):
        W = parameters.get(""W""+str(i))
        b = parameters.get(""b""+str(i))
        Z_temp = tf.add(tf.matmul(W, A_temp), b)

        if normalize_batch:
            if (i &lt; (L-1)):  
                with tf.variable_scope(""batch_norm_scope"", reuse=tf.AUTO_REUSE):
                    Z_temp = tf.layers.batch_normalization(Z_temp, axis=-1, 
                                                           training=training)

        A_temp = tf.nn.relu(Z_temp)

    return Z_temp   #This is the linear output of last layer
</code></pre>

<p>When I do this, I can run the forward prop function. But it seems to be crashing in later execution. Here is the error that I get. (Note that I print out the shape of input X before and after reshaping in the forward prop function).</p>

<pre><code>X.shape before reshape:  (?, 5)
X.shape after reshape:  (7, 5)

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1349     try:
-&gt; 1350       return fn(*args)
   1351     except errors.OpError as e:

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1328                                    feed_dict, fetch_list, target_list,
-&gt; 1329                                    status, run_metadata)
   1330 

~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    515             compat.as_text(c_api.TF_Message(self.status.status)),
--&gt; 516             c_api.TF_GetCode(self.status.status))
    517     # Delete the underlying status object from memory otherwise it stays alive

InvalidArgumentError: Incompatible shapes: [7] vs. [2]
     [[Node: forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub = Sub[T=DT_FLOAT, _class=[""loc:@batch_norm_scope/batch_normalization/moving_mean""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](forward_prop/batch_norm_scope/batch_normalization/cond_2/Switch_1:1, forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:1)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-222-990fb7d7f7f6&gt; in &lt;module&gt;()
     24 parameters = nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs,
     25                       normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers,
---&gt; 26                       lambd, print_progress)
     27 
     28 print(parameters)

&lt;ipython-input-221-59594e979129&gt; in nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs, normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers, lambd, print_progress)
     88                                                                         cost_mini_batch,
     89                                                                         accuracy_mini_batch],
---&gt; 90                                                                         feed_dict={training: True})
     91                       nr_of_minibatches += 1
     92                       sum_minibatch_costs += minibatch_cost

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    893     try:
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 895                          run_metadata_ptr)
    896       if run_metadata:
    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1126     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1127       results = self._do_run(handle, final_targets, final_fetches,
-&gt; 1128                              feed_dict_tensor, options, run_metadata)
   1129     else:
   1130       results = []

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1342     if handle is None:
   1343       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-&gt; 1344                            options, run_metadata)
   1345     else:
   1346       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1361         except KeyError:
   1362           pass
-&gt; 1363       raise type(e)(node_def, op, message)
   1364 
   1365   def _extend_graph(self):

InvalidArgumentError: Incompatible shapes: [7] vs. [2]
     [[Node: forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub = Sub[T=DT_FLOAT, _class=[""loc:@batch_norm_scope/batch_normalization/moving_mean""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](forward_prop/batch_norm_scope/batch_normalization/cond_2/Switch_1:1, forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:1)]]

Caused by op 'forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub', defined at:
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py"", line 16, in &lt;module&gt;
    app.launch_new_instance()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 478, in start
    self.io_loop.start()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2850, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""&lt;ipython-input-222-990fb7d7f7f6&gt;"", line 26, in &lt;module&gt;
    lambd, print_progress)
  File ""&lt;ipython-input-221-59594e979129&gt;"", line 36, in nn_model
    parameters, normalize_batch, training)
  File ""&lt;ipython-input-218-62e4c6126c2c&gt;"", line 19, in forward_propagation_with_relu
    training=training)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 777, in batch_normalization
    return layer.apply(inputs, training=training)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 807, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 697, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 602, in call
    lambda: self.moving_mean)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/utils.py"", line 211, in smart_cond
    return control_flow_ops.cond(pred, true_fn=fn1, false_fn=fn2, name=name)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1985, in cond
    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1839, in BuildCondBranch
    original_result = fn()
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 601, in &lt;lambda&gt;
    lambda: _do_update(self.moving_mean, new_mean),
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 597, in _do_update
    var, value, self.momentum, zero_debias=False)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py"", line 87, in assign_moving_average
    update_delta = (variable - value) * decay
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 778, in _run_op
    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 934, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4819, in _sub
    ""Sub"", x=x, y=y, name=name)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3267, in create_op
    op_def=op_def)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Incompatible shapes: [7] vs. [2]
     [[Node: forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub = Sub[T=DT_FLOAT, _class=[""loc:@batch_norm_scope/batch_normalization/moving_mean""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](forward_prop/batch_norm_scope/batch_normalization/cond_2/Switch_1:1, forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:1)]]
</code></pre>

<p>Regarding the question why the shape of X is not static.. I don't know...
HEre is how I setup the dataset.</p>

<pre><code>with tf.name_scope(""next_train_batch""):
    filenames = tf.placeholder(tf.string, shape=[None])
    dataset = tf.data.Dataset.from_tensor_slices(filenames)
    dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(minibatch_size)
    iterator = dataset.make_initializable_iterator()
    X_mini_batch, Y_mini_batch = iterator.get_next()
</code></pre>

<p>I have 2 csv files that include the train data.</p>

<pre><code>train_path1 = ""train1.csv""
train_path2 = ""train2.csv""
train_input_paths = [train_path1, train_path2]
</code></pre>

<p>And I use the initializable iterator as following:</p>

<pre><code>sess.run(iterator.initializer, 
         feed_dict={filenames: train_input_paths})
</code></pre>

<p>During the training, I keep getting mini batches from the train set. Everything works fine when I disable batch normalization. If I enable batch norm, it requires static shape of the input X (mini batch). I reshape it but this time it crashes later in the execution as seen above. </p>

<p>ADDENDUM(3)</p>

<p>I guess I figured out where it crashes. It probably crashes when I run the optimizer after calculating the cost.</p>

<p>First the sequence of commands:
First forward prop, then compute cost, then run optimizer. First 2 seems to be working but not the optimizer.</p>

<p>HEre is how I define the optimizer:</p>

<pre><code>with tf.name_scope(""train""):
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):        
        # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.
        optimizer =  tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_mini_batch)
</code></pre>

<p>I have the update_ops there to be able to update the moving averages. If I interpret it right, it is just crashing when it tries to update moving averages. I might be misinterpreting the error msg as well.. </p>

<p>ADDENDUM(4)</p>

<p>I tried to normalize based on the known dimension and it worked! But that's not the dimension I would like to normalize, which is now confusing. Let me elaborate:</p>

<p>nr of units in input layer: 5
nr of units in layer 1 (first hidden layer): 6
so weight1 is (6, 5) matrix
Assume that mini batch size is 7.
Shape of A[0] (or X_mini_batch) in my case is: (7, 5), where 7 is the # training samples in mini batch, and 5 is the # units in input layer.</p>

<p>When calculating Z[1]...
Z[1] = weight1 * A[0].transpose
... then shape of Z[1] is (6, 7) matrix, where each column gives 6 features for each train sample.</p>

<p>The question is then which column do we want to normalize in Z[1]? What makes sense to me is that you normalize each feature from all given train samples. This means that I need to normalize each row bcz I have different feature values for different train examples in each row. And since Z[1] has the shape (6, 7), if I set axis=0, it should refer to normalization in each row. And 7 is the unknown number in my case so it doesn't hurt. Based on this logic, it works! But I am totally puzzled if axis=0 really refers to each row here... Let me show another example about this axis issue, which has bothered me for a long time now..</p>

<p>The <em>irrelevant from this topic</em> code example:</p>

<pre><code>cc = tf.constant([[1.,2.,3.], 
                  [4.,5.,6.]])

with tf.Session() as sess:
    print(sess.run(tf.reduce_mean(cc, axis=0)))
    print(sess.run(tf.reduce_mean(cc, axis=1)))  
</code></pre>

<p>This gives the following output:</p>

<pre><code>[2.5 3.5 4.5]
[2. 5.]
</code></pre>

<p>When I set axis to 0, it is giving the average of each column. And if axis=1, it is giving the average of each row.</p>

<p>(Note that cc.shape gives (2,3))</p>

<p>Now the million dollar question: In a 2 dimensional matrix, is axis 0 or 1 when I want to address each row?</p>

<p>ADDENDUM(5)
I guess I get it now correctly. Let me summarize my axis understanding here. Hopefully I am getting it right now...</p>

<p>Here is the Z[1] matrix representation with the shape (6,7):</p>

<p>t_ex :   train example
f:       feature</p>

<pre><code>t_ex1   t_ex2   t_ex3   t_ex4   t_ex5   t_ex6   t_ex7
  f1      f1      f1      f1      f1      f1      f1
  f2      f2      f2      f2      f2      f2      f2
  f3      f3      f3      f3      f3      f3      f3
  f4      f4      f4      f4      f4      f4      f4
  f5      f5      f5      f5      f5      f5      f5
  f6      f6      f6      f6      f6      f6      f6
</code></pre>

<p>In this mini batch above, there are 7 train examples and each train ex has 6 features (since there are 6 units in layer 1). When we say ""tf.layers.batch_normalization(..,axis=0)"", we mean that the normalization has to be done per row for each feature to eliminate the high variance between - say - f1 values in the first row.</p>

<p>With other words, we do NOT normalize f1,f2,f3,f4,f5,f6 with each other. We normalize f1:s with each other, and f2:s with each other, and so on..</p>
",tf.nn.batch_normalization,tf.nn.batch_normalization,2018-04-06 22:44:37,"<p>Q1) Initializing gamma as 1, beta as 0 means directly using the normalized inputs. Since there is no prior information about what the variance of a layer output should be, it is fair enough to assume standard Gaussian.</p>

<p>Q2) During training phase (<code>training=True</code>), the batch is normalized with their own mean and var, assuming that training data are randomly sampled. During test (<code>training=False</code>), since the test data could be arbitrarily sampled, we cannot use their mean and var. Thus, we use, as you said, the moving averaging estimations from the last ""100"" training iterations.</p>

<p>Q3) Yes, trainable refers to <code>beta</code> and <code>gamma</code>. There are cases to set <code>trainable=False</code>, e.g. if a novel method is used to update the parameters, or if the batch_norm layer is pre-trained and needs to be frozen. </p>

<p>Q4) You may have noticed <code>reuse</code> parameters in other <code>tf.layers</code> functions as well. In general, if you wanna call a layer more than once (e.g. training and validation) and you do not wanna TensorFlow to think that you are creating a new layer, you set <code>reuse=True</code>. I prefer <code>with tf.variable_scope(..., reuse=tf.AUTO_REUSE):</code> to achieve the same purpose.</p>

<p>Q5) I am not sure about this one. I guess it is for users who want to design new tricks to adjust the scale and bias.</p>

<p>Q6) Yes, you are right.</p>
",9328846,2063,https://stackoverflow.com/questions/49701918,Lack of Alternative Solutions/Documentation
49686860,Side effect in tf.while_loop,"<p>I am currently having a hard time trying to understand how tensorflow works, and I feel like the python interface is somehow obscure.</p>

<p>I recently tried to run a simple print statement inside a tf.while_loop, and there are many things that remains unclear to me:</p>

<pre><code>import tensorflow as tf

nb_iter = tf.constant(value=10)
#This solution does not work at all
#nb_iter = tf.get_variable('nb_iter', shape=(1), dtype=tf.int32, trainable=False)
i = tf.get_variable('i', shape=(), trainable=False,
                     initializer=tf.zeros_initializer(), dtype=nb_iter.dtype)

loop_condition = lambda i: tf.less(i, nb_iter)
def loop_body(i):
    tf.Print(i, [i], message='Another iteration')
    return [tf.add(i, 1)]

i = tf.while_loop(loop_condition, loop_body, [i])

initializer_op = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(initializer_op)
    res = sess.run(i)
    print('res is now {}'.format(res))
</code></pre>

<p>Notice that if I initialize nb_iter with</p>

<pre><code>nb_iter = tf.get_variable('nb_iter', shape=(1), dtype=tf.int32, trainable=False)
</code></pre>

<p>I got the following error:</p>

<blockquote>
  <p>ValueError: Shape must be rank 0 but is rank 1 for 'while/LoopCond'
  (op: 'LoopCond') with input shapes: [1].</p>
</blockquote>

<p>It get even worse when I try to use the 'i' index for indexing a tensor (example not shown here), I then get the following error</p>

<blockquote>
  <p>alueError: Operation 'while/strided_slice' has been marked as not
  fetchable.</p>
</blockquote>

<p>Can someone point me to a documentation that explains how tf.while_loop works when used with tf.Variables, and if it possible to use side_effects (like print) inside the loop, as well as indexing tensor with the loop variable ?</p>

<p>Thank you in advance for your help</p>
",tf.while_loop,tf.while_loop,2018-04-06 6:39:39,"<p>There were actually many things wrong with my first example:</p>

<p>tf.Print is not executed if the operator has no side effect (ie i = tf.Print())</p>

<p>If the boolean, is a scalar, it is then a rank-0 tensor, not a rank-1 tensor. ...</p>

<p>Here is the code that works:</p>

<pre><code>import tensorflow as tf

#nb_iter = tf.constant(value=10)
#This solution does not work at all
nb_iter = tf.get_variable('nb_iter', shape=(), dtype=tf.int32, trainable=False,
                          initializer=tf.zeros_initializer())
nb_iter = tf.add(nb_iter,10)
i = tf.get_variable('i', shape=(), trainable=False,
                     initializer=tf.zeros_initializer(), dtype=nb_iter.dtype)
v = tf.get_variable('v', shape=(10), trainable=False,
                     initializer=tf.random_uniform_initializer, dtype=tf.float32)

loop_condition = lambda i: tf.less(i, nb_iter)
def loop_body(i):
    i = tf.Print(i, [v[i]], message='Another vector element: ')
    return [tf.add(i, 1)]

i = tf.while_loop(loop_condition, loop_body, [i])

initializer_op = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(initializer_op)
    res = sess.run(i)
    print('res is now {}'.format(res))
</code></pre>

<p>output:</p>

<pre><code>Another vector element: [0.203766704]
Another vector element: [0.692927241]
Another vector element: [0.732221603]
Another vector element: [0.0556482077]
Another vector element: [0.422092319]
Another vector element: [0.597698212]
Another vector element: [0.92387116]
Another vector element: [0.590101123]
Another vector element: [0.741415381]
Another vector element: [0.514917374]
res is now 10
</code></pre>
",2697831,485,https://stackoverflow.com/questions/49686860,Requesting (Additional) Documentation/Examples
49564318,Issue with fine-tuning inceptionv3 in slim tensorflow and tf record batches,"<p>I am trying to fine-tune inceptionv3 model using slim tensorflow library. 
I am unable to understand certain things while writing the code for it. I tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the check point. Here are the steps I followed 
 1. I created a tf.record for my training data which is fine, now I am reading the data using the below code. </p>

<pre><code>import tensorflow as tf
import tensorflow.contrib.slim.nets as nets
import tensorflow.contrib.slim as slim
import matplotlib.pyplot as plt
import numpy as np

# get the data and labels here

data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'

# Training setting
num_epochs = 100
initial_learning_rate = 0.0002
learning_rate_decay_factor = 0.7
num_epochs_before_decay = 5
num_classes = 5980

# load the checkpoint
model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'

# log directory
log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'

with tf.Session() as sess:
    feature = {'train/image': tf.FixedLenFeature([], tf.string),
               'train/label': tf.FixedLenFeature([], tf.int64)}

    # Create a list of filenames and pass it to a queue
    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)

    # Define a reader and read the next record
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)

    # Decode the record read by the reader
    features = tf.parse_single_example(serialized_example, features=feature)

    # Convert the image data from string back to the numbers
    image = tf.decode_raw(features['train/image'], tf.float32)

    # Cast label data into int32
    label = tf.cast(features['train/label'], tf.int32)

    # Reshape image data into the original shape
    image = tf.reshape(image, [128, 128, 3])

    # Creates batches by randomly shuffling tensors
    images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,
                                            min_after_dequeue=64)
</code></pre>

<p>Now I am finetuning the model using slim and this is the code. </p>

<pre><code>  init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
    sess.run(init_op)

    # Create a coordinator and run all QueueRunner objects
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    # load model

    # load the inception model from the slim library - we are using inception v3
    #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))

    img, lbl = sess.run([images, labels])
    one_hot_labels = slim.one_hot_encoding(lbl, num_classes)

    with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):
        logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,
                                                          dropout_keep_prob=.6)

    # Restore convolutional layers:

    variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])
    init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)

    # loss function
    loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)
    total_loss = tf.losses.get_total_loss()

    # train operation
    train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))

    print('Im here')
    # Start training.
    slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)
</code></pre>

<p>Now I have few questions about the code, which I am quite unable to figure out. Once, the code reaches <strong>slim.learning.train</strong> I don't see anything printing however, it's training, I can see in the log. Now, 
1. How do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.<br>
2. How do I make sure that in the code <strong>tf.train.shuffle_batch</strong> I am not repeating my images and I am training over the whole dataset? 
3. How can I print the loss values while it's training?</p>
",-,-,2018-03-29 20:14:52,"<p>Here are answers to your questions.</p>

<ol>
<li><p>You cannot give epochs directly to <code>slim.learning.train</code>. Instead, you give the number of batches as the argument. It is called <code>number_of_steps</code>. It is used to set an operation called <code>should_stop_op</code> on <a href=""https://github.com/tensorflow/tensorflow/blob/7a0def60d45c1841a4e79a0ddf6aa9d50bf551ac/tensorflow/contrib/slim/python/slim/learning.py#L709"" rel=""nofollow noreferrer"">line 709</a>. I assume you know how to convert number of epochs to batches.</p></li>
<li><p>I don't think the <code>shuffle_batch</code> function will repeat images because internally it uses the <a href=""https://www.tensorflow.org/api_docs/python/tf/RandomShuffleQueue"" rel=""nofollow noreferrer"">RandomShuffleQueue</a>. According to <a href=""https://stackoverflow.com/a/43190902/1586200"">this answer</a>, the <code>RandomShuffleQueue</code> enqueues elements using a background thread as:</p>

<ul>
<li>While <code>size(queue) &lt; capacity</code>:

<ul>
<li>Add an element to the queue</li>
</ul></li>
</ul></li>
</ol>

<p>It dequeues elements as:</p>

<ul>
<li>While the <code>number of elements dequeued &lt; batch_size</code>:

<ul>
<li>Wait until the <code>size(queue) &gt;= min_after_dequeue + 1</code> elements.</li>
<li>Select an element from the queue uniformly at random, remove it from the queue, and add it the output batch.</li>
</ul></li>
</ul>

<p>So in my opinion, there is very little chance that the elements would be repeated, because in the <code>dequeuing</code> operation, the chosen element is removed from the queue. So it is sampling without replacement.</p>

<p><strong>Will a new queue be created for every epoch?</strong></p>

<p>The tensors being inputted to <code>tf.train.shuffle_batch</code> are <code>image</code> and <code>label</code> which ultimately come from the <code>filename_queue</code>. If that queue is producing TFRecord filenames indefinitely, then I don't think a new queue will be created by <code>shuffle_batch</code>. You can also create a toy code like <a href=""https://stackoverflow.com/a/45207025/1586200"">this</a> to understand how <code>shuffle_batch</code> works.</p>

<p>Coming to the next point, how to train over the whole dataset? In your code, the following line gets the list of TFRecord filenames.</p>

<pre><code>filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)
</code></pre>

<p>If <code>filename_queue</code> covers all TFRecords that you have, then you are surely training over the entire dataset. Now, how to shuffle the entire dataset is another question. As mentioned <a href=""https://github.com/tensorflow/tensorflow/issues/14857"" rel=""nofollow noreferrer"">here</a> by @mrry, there is no support (yet, AFAIK) to shuffle out-of-memory datasets. So the best way is to prepare many shards of your dataset such that each shard contains about 1024 examples. Shuffle the list of TFRecord filenames as:</p>

<pre><code>filename_queue = tf.train.string_input_producer([data_path], shuffle=True, capacity=1000)
</code></pre>

<p>Note that I removed the <code>num_epochs = 1</code> argument and set <code>shuffle=True</code>. This way it will produce the <em>shuffled</em> list of TFRecord filenames indefinitely. Now on each file, if you use <code>tf.train.shuffle_batch</code>, you will get a near-to-uniform shuffling. Basically, as the number of examples in each shard tend to 1, your shuffling will get more and more uniform. I like to not set <code>num_epochs</code> and instead terminate the training using the <code>number_of_steps</code> argument mentioned earlier.</p>

<ol start=""3"">
<li>To print the loss values, you could probably just edit the <a href=""https://github.com/tensorflow/tensorflow/blob/024aecf414941e11eb643e29ceed3e1c47a115ad/tensorflow/contrib/slim/python/slim/learning.py#L768"" rel=""nofollow noreferrer""><code>training.py</code></a> and introduce <code>logging.info('total loss = %f', total_loss)</code>. I don't know if there is any simpler way. Another way without changing the code is to view summaries in Tensorboard.</li>
</ol>

<p>There are very helpful articles on how to view summaries in Tensorboard, including the link at the end of this answer. Generally, you need to do the following things.</p>

<ol>
<li>Create <code>summary</code> object.</li>
<li>Write variables of interest into <code>summary</code>.</li>
<li>Merge all individual summaries.</li>
<li>Create a <code>summary</code> op.</li>
<li>Create a summary file writer.</li>
<li>Write the summaries throughout the training at a desired frequency.</li>
</ol>

<p>Now steps 5 and 6 are already done automatically for you if you use <code>slim.learning.train</code>.</p>

<p>For first 4 steps, you could check the file <a href=""https://github.com/tensorflow/models/blob/46377f8842e512805a3b9cbbfab026e39a82d346/research/slim/train_image_classifier.py#L472"" rel=""nofollow noreferrer""><code>train_image_classifier.py</code></a>. Line 472 shows you how to create a <code>summaries</code> object. Lines 490, 512 and 536 write the relevant variables into <code>summaries</code>. Line 549 merges all summaries and the line 553 creates an op. You can pass this op to <code>slim.learning.train</code> and you can also specify how frequently you want to write summaries. In my opinion, do not write anything apart from loss, total_loss, accuracy and learning rate into the summaries, unless you want to do specific debugging. If you write histograms, then the tensorboard file could take tens of hours to load for networks like ResNet-50 (my tensorboard file once was 28 GB, which took 12 hours to load the progress of 6 days!). By the way, you could actually use <code>train_image_classifier.py</code> file to finetune and you will skip most of the steps above. However, I prefer this as you get to learn a lot of things.</p>

<p>See the <a href=""https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"" rel=""nofollow noreferrer"">launching tensorboard</a> section on how to view the progress in a browser.</p>

<p><strong>Additional remarks:</strong></p>

<ul>
<li><p>Instead of minimizing <code>total_loss + loss</code>, you could do the following:</p>

<pre><code>loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)
tf.losses.add_loss(loss)
total_loss = tf.losses.get_total_loss()
train_op = slim.learning.create_train_op(total_loss, optimizer=tf.train.AdamOptimizer(learning_rate=1e-4))
</code></pre></li>
<li><p>I found <a href=""https://kwotsin.github.io/tech/2017/02/11/transfer-learning.html"" rel=""nofollow noreferrer"">this</a> post to be very useful when I was learning Tensorflow.</p></li>
</ul>
",7776604,962,https://stackoverflow.com/questions/49564318,Documentation Replication on Other Examples
49418325,"Use ""tf.contrib.factorization.KMeansClustering""","<p>Referring to this Link, <a href=""https://github.com/tensorflow/tensorflow/issues/17002"" rel=""nofollow noreferrer"">(the Link)</a>
I try to practice using tf.contrib.factorization.KMeansClustering for clustering. The simple codes as follow works okay:</p>

<pre><code>import numpy as np
import tensorflow as tf

# ---- Create Data Sample -----
k = 5
n = 100
variables = 5
points = np.random.uniform(0, 1000, [n, variables])

# ---- Clustering -----
input_fn=lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)
kmeans=tf.contrib.factorization.KMeansClustering(num_clusters=6)
kmeans.train(input_fn=input_fn)
centers = kmeans.cluster_centers()

# ---- Print out -----
cluster_indices = list(kmeans.predict_cluster_index(input_fn))
for i, point in enumerate(points):
  cluster_index = cluster_indices[i]
  print ('point:', point, 'is in cluster', cluster_index, 'centered at', centers[cluster_index])
</code></pre>

<p>My question is why would this ""input_fn"" code does the trick?
If I change the code to this, it will run into an infinite loop. Why??</p>

<pre><code>input_fn=lambda:tf.convert_to_tensor(points, dtype=tf.float32)
</code></pre>

<p>From the document <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeansClustering"" rel=""nofollow noreferrer"">(here)</a>, it seems that train() is expecting argument of input_fn, which is simply a A 'tf.data.Dataset' object , like Tensor(X). So, why do I have to do all these tricky things regarding lambda: tf.train.limit_epochs()?</p>

<p>Can anyone who is familiar with the fundamental of tensorflow estimators help to explain? Many Thanks!</p>
",-,-,2018-03-21 23:47:33,"<blockquote>
  <p>My question is why would this ""input_fn"" code does the trick? If I change the code to this, it will run into an infinite loop. Why??</p>
</blockquote>

<p>The documentation states that <code>input_fn</code> is called repeatedly until it returns a <code>tf.errors.OutOfRangeError</code>. Adorning your tensor with <code>tf.train.limit_epochs</code> ensures that the error is eventually raised, which signals to KMeans that it should stop training.</p>
",7270211,159,https://stackoverflow.com/questions/49418325,Inadequate Examples
49370940,One hot encoding characters,"<p>Is there a possibilty to one-hot encode characters of a text in Tensorflow or Keras?</p>

<ul>
<li><code>tf.one_hot</code> seem to take only integers.</li>
<li><code>tf.keras.preprocessing.text.one_hot</code> seems to one-hot encode sentences
to words, but not to characters.</li>
</ul>

<p>Beside that, <code>tf.keras.preprocessing.text.one_hot</code> works really strange, since the response does not really seem one-hot encoded, since the following code:</p>

<pre><code>text = ""ab bba bbd""
res = tf.keras.preprocessing.text.one_hot(text=text,n=3)
print(res)
</code></pre>

<p>Lead to this result:</p>

<pre><code>[1,2,2]
</code></pre>

<p>Every time I run this program, the output is a different 3d vector, sometimes it is <code>[1,1,1]</code> or <code>[2,1,1]</code>. The documentation says, that unicity is not guaranteed, but this seems really senseless to me.</p>
",tf.keras.preprocessing.text.one_hot,tf.keras.preprocessing.text.one_hot,2018-03-19 19:30:14,"<p>I found a nice answer based on pure python, unfortunately I do not find the source anymore. It first converts every char to an int, and then replaces the int with an one-hot array. It has unicity over the whole program, even over all programms if the alphabet is the same length and the same order.</p>

<pre><code>    # Is the alphabet of all possible chars you want to convert
    alphabet = ""abcdefghijklmnopqrstuvwxyz0123456789""

    def convert_to_onehot(data):
        #Creates a dict, that maps to every char of alphabet an unique int based on position
        char_to_int = dict((c,i) for i,c in enumerate(alphabet))
        encoded_data = []
        #Replaces every char in data with the mapped int
        encoded_data.append([char_to_int[char] for char in data])
        print(encoded_data) # Prints the int encoded array

        #This part now replaces the int by an one-hot array with size alphabet
        one_hot = []
        for value in encoded_data:
            #At first, the whole array is initialized with 0
            letter = [0 for _ in range(len(alphabet))]
            #Only at the number of the int, 1 is written
            letter[value] = 1
            one_hot.append(letter)
        return one_hot

   print(convert_to_onehot(""hello world""))
</code></pre>
",3921232,607,https://stackoverflow.com/questions/49370940,Documentation Ambiguity
48914952,num_buckets as a parameter in a tensorflow feature column,"<p>Currently Tensorflow documentation define a categorical vocabulary column this way:</p>

<pre><code>vocabulary_feature_column =
tf.feature_column.categorical_column_with_vocabulary_list(
    key=""feature_name_from_input_fn"",
    vocabulary_list=[""kitchenware"", ""electronics"", ""sports""]) 
</code></pre>

<p>However this suppose that we input manually the vocabulary list.
In case of large dataset with many columns and many unique values I would like to automate the process this way:</p>

<pre><code>for k in categorical_feature_names:
    vocabulary_feature_column =
        tf.feature_column.categorical_column_with_vocabulary_list(
        key=""feature_name_from_input_fn"",
        vocabulary_list=list_of_unique_values_in_the_column) 
</code></pre>

<p>To do so I need to retrieve the parameter <code>list_of_unique_values_in_the_column</code>.
Is there anyway to do that with Tensorflow? </p>

<p>I know there is tf.unique that could return unique values in a tensor but I don't get how I could feed the column to it so it returns the right vocabulary list.</p>
",tf.unique,tf.unique,2018-02-21 20:31:51,"<p>If <code>list_of_unique_values_in_the_column</code> is known, you can save them in one file and read by <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file"" rel=""nofollow noreferrer""> tf.feature_column.categorical_column_with_vocabulary_file</a>. If unknown, you can use <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/categorical_column_with_hash_bucket"" rel=""nofollow noreferrer""> tf.feature_column.categorical_column_with_hash_bucket </a> with a large enough size.</p>
",2175173,2187,https://stackoverflow.com/questions/48914952,Documentation Replication on Other Examples
48697799,Tensorflow feature column for variable list of values,"<p>From the TensorFlow docs it's clear how to use <code>tf.feature_column.categorical_column_with_vocabulary_list</code> to create a feature column which takes as input some string and outputs a one-hot vector. For example</p>

<pre><code>vocabulary_feature_column =
    tf.feature_column.categorical_column_with_vocabulary_list(
        key=""vocab_feature"",
        vocabulary_list=[""kitchenware"", ""electronics"", ""sports""])
</code></pre>

<p>Let's say <code>""kitchenware""</code> maps to <code>[1,0,0]</code> and <code>""electronics""</code> maps to <code>[0,1,0]</code>. My question is related to having a <strong>list of strings</strong> as a feature. For example, if the feature value was <code>[""kitchenware"",""electronics""]</code> then the desired output would be <code>[1,1,0]</code>. The input list length is not fixed but the output dimension is.</p>

<p>The use case is a straight bag-of-words type model (obviously with a much larger vocabulary list!).</p>

<p>What is the correct way to implement this?</p>
",tf.feature_column.categorical_column_with_vocabulary_list,tf.feature_column.categorical_column_with_vocabulary_list,2018-02-09 2:18:42,"<p>you should use tf.feature_column.indicator_column
see <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column</a></p>
",7978198,807,https://stackoverflow.com/questions/48697799,Documentation Replication on Other Examples
48471926,In Tensorflow's Dataset API how do you map one element into multiple elements?,"<p>In the tensorflow <code>Dataset</code> pipeline I'd like to define a custom map function which takes a single input element (data sample) and returns multiple elements (data samples).</p>

<p>The code below is my attempt, along with the desired results. </p>

<p>I could not follow the documentation on <code>tf.data.Dataset().flat_map()</code> well enough to understand if it was applicable here or not.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

input = [10, 20, 30]

def my_map_func(i):
  return [[i, i+1, i+2]]       # Fyi [[i], [i+1], [i+2]] throws an exception

ds = tf.data.Dataset.from_tensor_slices(input)
ds = ds.map(map_func=lambda input: tf.py_func(
  func=my_map_func, inp=[input], Tout=[tf.int64]
))
element = ds.make_one_shot_iterator().get_next()

with tf.Session() as sess:
  for _ in range(9):
    print(sess.run(element))
</code></pre>

<p>Results:</p>

<pre><code>(array([10, 11, 12]),)
(array([20, 21, 22]),)
(array([30, 31, 32]),)
</code></pre>

<p>Desired results:</p>

<pre><code>(10)
(11)
(12)
(20)
(21)
(22)
(30)
(31)
(32)
</code></pre>
",tf.data.Dataset,tf.data.Dataset,2018-01-27 2:08:26,"<p>Two more steps were required to achieve this. First, the map function needs to return a numpy array, not a list.</p>

<p>Then you can use <code>flat_map</code> combined with <code>Dataset().from_tensor_slices()</code> to flatten them. The code below now produces the desired result:</p>

<p>Tested in Tensorflow 1.5 (copy/paste runnable example)</p>

<pre><code>import tensorflow as tf
import numpy as np

input = [10, 20, 30]

def my_map_func(i):
  return np.array([i, i + 1, i + 2])

ds = tf.data.Dataset.from_tensor_slices(input)
ds = ds.map(map_func=lambda input: tf.py_func(
  func=my_map_func, inp=[input], Tout=[tf.int64]
))
ds = ds.flat_map(lambda x: tf.data.Dataset().from_tensor_slices(x))

element = ds.make_one_shot_iterator().get_next()

with tf.Session() as sess:
  for _ in range(9):
    print(sess.run(element))
</code></pre>

<hr>

<p>Here is a method of doing this if you have multiple variables to return, in this example I input a string (such as a filename) and output multiples of both strings and integers. In this case I repeat the string for each of the integers of [10, 20, 30]. </p>

<p>Copy/paste runnable example:</p>

<pre><code>import tensorflow as tf
import numpy as np

input = [b'testA', b'testB', b'testC']

def my_map_func(input):
  return np.array([input, input, input]), np.array([10, 20, 30])

ds = tf.data.Dataset.from_tensor_slices(input)
ds = ds.map(map_func=lambda input: tf.py_func(
    func=my_map_func, inp=[input], Tout=[tf.string, tf.int64]))
ds = ds.flat_map(lambda mystr, myint: tf.data.Dataset().zip((
  tf.data.Dataset().from_tensor_slices(mystr),
  tf.data.Dataset().from_tensor_slices(myint))
))

element = ds.make_one_shot_iterator().get_next()

with tf.Session() as sess:
  for _ in range(9):
    print(sess.run(element))
</code></pre>
",4790871,31007,https://stackoverflow.com/questions/48471926,Documentation Replicability