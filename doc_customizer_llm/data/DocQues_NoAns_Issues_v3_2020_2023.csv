QuestionId,Title,Body,QuestionsAPI,CurrentAPI,CreationDate,UserId,UserReputation,QuestionURL,IssueType
76447508,How to retrain a model that was saved using the tf.saved_model.save() function in Tensorflow,"<p>I am building a Neural Machine Translator for English to Konkani (a local language) language using the Transformer architecture proposed by (Vaswani et, al. 2017). I am following the tutorial code from <a href=""https://www.tensorflow.org/text/tutorials/transformer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/text/tutorials/transformer</a>. I have trained the model and used the <code>tf.saved_model.save()</code> method to save the model files locally.</p>
<p>I now want to retrain that saved model on a new dataset that I have gathered recently, but I've realised that after loading the model using the <code>tf.saved_model.load()</code> method, I am not able to train it again as the loaded model now lacks the necessary method <code>model.fit()</code> .</p>
<p>Here is a part of the model training code:</p>
<pre class=""lang-py prettyprint-override""><code>class Transformer(tf.keras.Model):
  def __init__(self, *, num_layers, d_model, num_heads, dff,
               input_vocab_size, target_vocab_size, dropout_rate=0.1):
    super().__init__()
    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=input_vocab_size,
                           dropout_rate=dropout_rate)

    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=target_vocab_size,
                           dropout_rate=dropout_rate)

    self.final_layer = tf.keras.layers.Dense(target_vocab_size)

  def call(self, inputs):
    # To use a Keras model with `.fit` you must pass all your inputs in the
    # first argument.
    context, x  = inputs

    context = self.encoder(context)  # (batch_size, context_len, d_model)

    x = self.decoder(x, context)  # (batch_size, target_len, d_model)

    # Final linear layer output.
    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)

    try:
      # Drop the keras mask, so it doesn't scale the losses/metrics.
      # b/250038731
      del logits._keras_mask
    except AttributeError:
      pass

    # Return the final output and the attention weights.
    return logits
#-----------------------------------------------------------------------

#...&lt;code to define optimizers and loss functions&gt;...

# This Class acts as an interface for the Transformer
class Translator(tf.Module):
  def __init__(self, context_tokenizers, target_tokenizers, transformer):
    self.context_tokenizers = context_tokenizers
    self.target_tokenizers = target_tokenizers
    self.transformer = transformer

  def __call__(self, sentence, max_length=MAX_TOKENS): #max_length=MAX_TOKENS
    assert isinstance(sentence, tf.Tensor)
    if len(sentence.shape) == 0:
      sentence = sentence[tf.newaxis]

    sentence = tokenize(sentence,self.context_tokenizers).to_tensor()

    encoder_input = sentence

    # As the output language is English, initialize the output with the
    # English `[START]` token.

    start_end = tokenize('',self.target_tokenizers)[0]
    start = start_end[0][tf.newaxis]
    end = start_end[-1][tf.newaxis]

    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)
    output_array = output_array.write(0, start)

    for i in tf.range(max_length):
      output = tf.transpose(output_array.stack())
      predictions = self.transformer([encoder_input, output], training=False)

      # Select the last token from the `seq_len` dimension.
      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.

      predicted_id = tf.argmax(predictions, axis=-1)

      # Concatenate the `predicted_id` to the output which is given to the
      # decoder as its input.
      output_array = output_array.write(i+1, predicted_id[0])

      if predicted_id == end:
        break

    output = tf.transpose(output_array.stack())
    # The output shape is `(1, tokens)`.

    text = self.target_tokenizers.detokenize(output)

    tokens = tf.gather(target_vocab, output)

    # `tf.function` prevents us from using the attention_weights that were
    # calculated on the last iteration of the loop.
    # So, recalculate them outside the loop.
    self.transformer([encoder_input, output[:,:-1]], training=False)
    attention_weights = self.transformer.decoder.last_attn_scores

    joined_text = tf.strings.reduce_join(text[0][1:-1], separator=' ', axis=-1)
    return joined_text, tokens, attention_weights
#-----------------------------------------------------------------------

class ExportTranslator(tf.Module):
  def __init__(self, translator):
    self.translator = translator

  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
  def __call__(self, sentence):
    (result,
     tokens,
     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)

    return result
#-----------------------------------------------------------------------

transformer = Transformer(
    num_layers=num_layers,
    d_model=d_model,
    num_heads=num_heads,
    dff=dff,
    input_vocab_size=context_vocab_size,
    target_vocab_size=target_vocab_size,
    dropout_rate=dropout_rate)

transformer.compile(
    loss=masked_loss,
    optimizer=optimizer,
    metrics=[masked_accuracy])

# training the model on the training data for some epochs
transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )

translator = Translator(context_tokenizer, target_tokenizer, transformer)

exp_translator = ExportTranslator(translator)

#saving the model
tf.saved_model.save(exp_translator, export_dir=MODEL_SAVED_FILES)

#-----------------------------------------------------------------------

#loading a saved model
reloaded = tf.saved_model.load(MODEL_SAVED_FILES)
</code></pre>
<p>Here's the error I get when I try to retrain the model using the following code:</p>
<pre class=""lang-py prettyprint-override""><code>reloaded = tf.saved_model.load(MODEL_SAVED_FILES)

#retraing the model on new dataset
reloaded.translator.transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )
</code></pre>
<p>The error:</p>
<pre class=""lang-py prettyprint-override""><code>
---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

&lt;ipython-input-41-ad1b625ff6c0&gt; in &lt;cell line: 2&gt;()
      1 #retraing the model on new dataset
----&gt; 2 reloaded.translator.transformer.fit(train_batches,
      3                 epochs=20,
      4                 validation_data=val_batches,
      5                 callbacks=[

AttributeError: '_UserObject' object has no attribute 'fit'
</code></pre>
<p>After reading the documentation I've realised that when saving the model in the above method, the <code>model.fit()</code> and other methods are not saved hence they are not callable.</p>
<p>I need help in finding a way to retrain my saved model, It is not feasible for me to train a new model on a combined dataset as It will take up lot of time and I have very limited resources. I have been looking up on the web for days but couldn't find a solution. Any help in this regards will be appreciated!</p>
",tf.saved_model.load,tf.saved_model.load,2023-04-17 23:39:34,16851318,41,https://stackoverflow.com/questions/76447508,Inadequate Examples
76396532,"Ragged tensors in dataset, tensorflow, how do I train the model","<p>I have</p>
<pre><code>def call (self, inputs):
    context, x = inputs
</code></pre>
<p>in my model, for fitting,
and my dataset contains ragged tensors, basically context and x are ragged tensor, of variable length, everything I try gives me some sort of error, for example<br> first I tried <code>[ [ context, x], ...]</code> where all the arrays were <code>np.ndarray</code>, but it said something along the lines that <code>np.ndarray</code> is an unrecognised datatype and cannot be converted to a <code>tf.Tensor</code>.<br>Then when I tried putting this in a tf.data.Dataset, it says <code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor).</code><br>
I am totally lost on how to train my model</p>
<p>I tried several different data types from list, to tf.data.Dataset, but none of them were working, and now I am totally in the dark. Consulting the documentation has not helped me figure out how does the fit function actually treat data</p>
",tf.data.Dataset,tf.data.Dataset,2023-04-12 14:26:12,13154958,1,https://stackoverflow.com/questions/76396532,Documentation Replicability
76391276,Custom gradient for broadcasting operation,"<p>I have an operation for which I want to define a custom gradient with <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer""><code>tf.custom_gradient</code></a>. The operation takes two broadcastable arguments and produces a result with the broadcasted shape. The problem is how to handle the broadcasting rules &quot;backwards&quot; in the custom gradient. Let's take the example for a multiplication operation from the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer""><code>tf.custom_gradient</code></a>:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

@tf.custom_gradient
def bar(x, y):
  def grad(upstream):
    dz_dx = y
    dz_dy = x
    return upstream * dz_dx, upstream * dz_dy
  z = x * y
  return z, grad
</code></pre>
<p>I can use this gradient alright for the non-broadcasting case:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.GradientTape() as tape:
    a = tf.ones([5])
    b = tf.ones([5])
    tape.watch([a, b])
    c = bar(a, b)
# Works fine
grad_a, grad_b = tape.gradient(c, [a, b])
</code></pre>
<p>However, when the inputs are broadcasted, the result is not correct:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.GradientTape() as tape:
    a = tf.ones([10, 1])
    b = tf.ones([5])
    tape.watch([a, b])
    c = bar(a, b)
grad_a, grad_b = tape.gradient(c, [a, b])
print(grad_a.shape, grad_b.shape)
# (10, 5) (10, 5)
</code></pre>
<p>In fact, trying to use it in graph mode fails:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.Graph().as_default():
    a = tf.ones([10, 1])
    b = tf.ones([5])
    c = bar(a, b)
    grad_a, grad_b = tf.gradients(c, [a, b])
# ValueError: Incompatible shapes between op input and calculated input gradient.
</code></pre>
<p>Is there a way to handle this &quot;unbroadcasting&quot; of the input gradients automatically?</p>
",tf.custom_gradient,tf.custom_gradient,2023-04-05 13:00:20,1782792,58906,https://stackoverflow.com/questions/76391276,Documentation Ambiguity
76380927,Tensorflow decode image,"<p>I am a beginner in tensorflow and I am training a small cnn, I am using the tf.io.decode_image function but I can't figure out if this function does preprocess.
The tensorflow documentation about it doesn't say anything.
When I open images with this function the values are between 0 and 1.
The images are single channel grayscale.
This is the code.</p>
<pre><code>def decode_img(self, imgs, channels):
        # Convert the compressed string to a 3D uint8 tensor
        images = []
        for element in imgs:

            dec_image = tf.io.decode_image(element, channels=channels, dtype=tf.float32)
            try:
                img = keras.utils.img_to_array(dec_image)
            except AttributeError:
                img = keras.preprocessing.image.img_to_array(dec_image)
            images.append(img)
        images = np.array(images)
        return images
</code></pre>
<p>I would like to have more explanations</p>
",tf.io.decode_image,tf.io.decode_image,2023-03-05 8:02:03,15460221,11,https://stackoverflow.com/questions/76380927,Requesting (Additional) Documentation/Examples
76244268,Tensorflow: Build new model from input and middle layers of another model,"<p>I'm trying to build <code>new_model</code> from another model layers for class activation mapping purposes.</p>
<pre class=""lang-py prettyprint-override""><code>def vgg_sequential():
    input_shape = IMG_SIZE + (3,)
    model = Sequential()
    model.add(tf.keras.applications.vgg16.VGG16(input_shape=input_shape, include_top=False, weights='imagenet'))
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(1))
    return model
</code></pre>
<pre class=""lang-py prettyprint-override""><code>cam_model = tf.keras.Model(inputs=seq_vgg.layers[0].input, outputs=(seq_vgg.layers[-3].output, seq_vgg.layers[-1].output))
</code></pre>
<p>And with this code i get the following error:</p>
<pre><code>ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 480, 480, 3), dtype=tf.float32, name='vgg16_input'), name='vgg16_input', description=&quot;created by layer 'vgg16_input'&quot;) at layer &quot;vgg16&quot;. The following previous layers were accessed without issue: ['block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1']
</code></pre>
<p>Already tried functional model API, providing <code>Input()</code> layer inside <code>vgg_sequential()</code> with the same error that my Input layer is disconected from the rest of my model. Beside this when using <code>tf.keras.applications.efficientnet_v2</code> that provides input layers for rescaling and resizing images i don't have any problem.</p>
<p>Any help, information, tips or links to docs that getas me to a solution will be very much appreciated.</p>
<p>Thanks in advance.</p>
",tf.keras.applications.efficientnet_v2,tf.keras.applications.efficientnet_v2,2023-03-04 23:59:16,2103321,75,https://stackoverflow.com/questions/76244268,Inadequate Examples
76153107,Difference between tf.Module and tf.keras.Model,"<p>I know both <code>tf.Module</code> and <code>tf.keras.Model</code> are used for building custom models.
But what's the difference between both of them?
Which one should be used when becuase there usage looks similar as shown in tensorflow docs?</p>
",tf.Module,tf.Module,2023-02-16 21:44:50,21760922,33,https://stackoverflow.com/questions/76153107,Documentation Ambiguity
76040030,Problem using Huggingface imagenet-1k dataset in Keras / Tensorflow,"<p>I'm having a problem using the imagenet-1k dataset from Huggingface with a Keras model. I'm just experimenting with simple models, but am stuck trying to get the dataset to work with the model fit function.</p>
<p>Here is how I load the dataset:</p>
<pre><code>ds = load_dataset('imagenet-1k')  # loads a DatasetDict
ds_train = ds['train']  # get a Dataset
ds_train.set_format(type='tensorflow', columns=['image'])  # convert to tf tensor
ds_val = ds['validation']  # get a Dataset
ds_val.set_format(type='tensorflow', columns=['image'])  # convert to tf tensor
</code></pre>
<p>Here is the fit invocation:</p>
<pre><code># train the autoencoder
autoencoder.fit(ds_train, ds_train,
                epochs=10,
                shuffle=True,
                validation_data=(ds_val, ds_val))
</code></pre>
<p>I get the following error:</p>
<pre><code>ValueError: Failed to find data adapter that can handle input: &lt;class 'datasets.arrow_dataset.Dataset'&gt;, &lt;class 'datasets.arrow_dataset.Dataset'&gt;
</code></pre>
<p>When I inspect one of the elements of the datasets it looks like a tf.Tensor, so I don't understand why it can't be passed directly. None of the examples or docs I can find make it clear how to do this. Huggingface <a href=""https://huggingface.co/docs/datasets/v2.11.0/en/use_with_tensorflow"" rel=""nofollow noreferrer"">examples</a> for images produce the same format that I'm getting, but apparently there is a step I'm missing before it can be used with model.fit()</p>
",tf.Tensor,tf.Tensor,2023-01-16 16:19:12,21668078,1,https://stackoverflow.com/questions/76040030,Documentation Replication on Other Examples
76012810,Unable to extract output probability array using Tensorflow for JS,"<p>New to Javascript/Typescript + ML libs. Created a quick TS code snippet to test out the TensorFlow lib. I am stuck at a point where I am not able to extract the probability array and then choose the max from the output.</p>
<p>In the last iteration I have here, I am using data() function but it does not compile giving this error:</p>
<pre><code>Property 'data' does not exist on type 'Tensor&lt;Rank&gt; | Tensor&lt;Rank&gt;[]'.
  Property 'data' does not exist on type 'Tensor&lt;Rank&gt;[]'.ts(2339)
</code></pre>
<p>Even though input is of the type tf.Tensor and according to the docs <a href=""https://js.tensorflow.org/api/latest/#tf.Tensor.data"" rel=""nofollow noreferrer"">here</a>, it should work.</p>
<p>I am definitely missing some thing here. I am tried going through other examples, but it seems like TensorFlow has a lot to offer and I did not come across anything that would be useful in my case.</p>
<p>I feel I need help with these 3 lines here:</p>
<pre><code>const output = await net.predict(input).data();  
  const predictedPortfolio = Object.keys(portfolios)[output.indexOf(Math.max(...output))];
  return predictedPortfolio;
</code></pre>
<p>Code snippet</p>
<pre><code>import * as tf from '@tensorflow/tfjs';

interface FinancialInformation {
  age: number;
  riskTolerance: number;
  currentNetWorth: number;
  annualIncome: number;
  debt: number;
}

interface Portfolios {
  [key: string]: string[];
}

// Define the investment portfolios
const portfolios: Portfolios = {
  conservative: ['bonds', 'real estate'],
  balanced: ['stocks', 'bonds', 'real estate', 'commodities'],
  aggressive: ['stocks', 'commodities', 'crypto'],
};

export async function generateSuggestion(financialInfo: FinancialInformation): Promise&lt;string&gt; {
  // Define the neural network
  const net = tf.sequential({
    layers: [
      tf.layers.dense({ inputShape: [5], units: 10, activation: 'sigmoid' }),
      tf.layers.dense({ units: 10, activation: 'sigmoid' }),
      tf.layers.dense({ units: 3, activation: 'softmax' }),
    ],
  });

  // Train the neural network
  const trainingData = tf.tensor2d([
    [25, 2, 100000, 60000, 0],
    [30, 4, 150000, 80000, 20000],
    [40, 6, 200000, 100000, 50000],
    [50, 8, 300000, 120000, 100000],
    [60, 10, 400000, 150000, 150000],
  ]);

  const outputData = tf.tensor2d([
    [1, 0, 0],
    [0, 1, 0],
    [0, 0, 1],
    [0, 0, 1],
    [0, 0, 1],
  ]);

  const options = {
    epochs: 500,
    learningRate: 0.3,
  };

  net.compile({ optimizer: tf.train.adam(), loss: 'categoricalCrossentropy' });

  await net.fit(trainingData, outputData, options);

  // Use the neural network to generate a suggestion
  const input = tf.tensor2d([
    [financialInfo.age, financialInfo.riskTolerance, financialInfo.currentNetWorth, financialInfo.annualIncome, financialInfo.debt],
  ]) as tf.Tensor;

  const output = await net.predict(input).data();  
  const predictedPortfolio = Object.keys(portfolios)[output.indexOf(Math.max(...output))];
  return predictedPortfolio;
}
</code></pre>
",tf.Tensor,tf.Tensor,2022-11-16 6:37:02,4463330,555,https://stackoverflow.com/questions/76012810,Lack of Alternative Solutions/Documentation
75996642,Is there a good equivalent of pandas' `apply` for TensorFlow datasets?,"<p><strong>BACKGROUND</strong></p>
<p>The use of <a href=""https://www.tensorflow.org/guide/data"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code></a> is promoted by TensorFlow as the best practice for implementing input pipelines due to their efficient implementation of common operations such as batching, shuffling, as well as their seamless integration with the Keras API.</p>
<p>I may just be lousy at looking up the documentation on the matter, but it seems to me that the major drawback of TensorFlow datasets is that they are quite unwieldy, if not impossible to work with, when trying to implement feature engineering tasks whereby a new column is created via the application of some generic Python function. This is in contrast to pandas' very nifty <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html"" rel=""nofollow noreferrer""><code>apply()</code></a> function which can produce new columns from preexisting ones both efficiently (i.e., via vectorization) and in a pythonic manner.</p>
<p>To the best of my understanding, the closest thing to pandas' <code>apply()</code> is TensorFlow dataset's <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer""><code>map()</code></a>. However, one can't simply use it with arbitrary Python functions since they'd first need to be converted to tensors. This becomes very difficult as one has to have arcane knowledge of the miscellaneous tensor analogues of arbitrary Python functions (e.g., <code>tf.strings.length()</code> instead of Python's <code>len()</code>). Even when one finds such functions, the idiosyncracies of tensor operations makes them very un-pythonic and prone to obscure dimensionality or type errors.</p>
<p>I've read about TensorFlow's <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer""><code>py_function</code></a> as some sort of wrapper that magically converts Pythonic code into a tensor representation, but judging from the documentation, it became clear to me that this is far from the case.</p>
<p><strong>QUESTION</strong></p>
<p>Is TensorFlow's <code>tf.data</code> just not mature yet to be able to handle feature engineering in the same way that pandas <code>apply()</code> does? If not, what am I missing in my understanding?</p>
<p><strong>MINIMUM WORKING EXAMPLE</strong></p>
<p>In the code below, I compare a pandas DataFrame <code>df</code> with the equivalent TensorFlow dataset <code>ds</code>. My goal is to engineer two extra features, namely</p>
<ol>
<li>adding a suffix to the string feature <code>my_string</code>, and</li>
<li>counting the number of time a certain letter appears in any given instance of <code>my_string</code>.</li>
</ol>
<p>As you can see for yourself, the first operation works intuitively for both pandas and TensorFlow, but the second only works easily for pandas. Getting it to work with TensorFlow is either extremely complex, or just plain impossible.</p>
<pre><code>from collections import Counter
import numpy as np
import pandas as pd
import tensorflow as tf

# Create the pandas DataFrame.
df = pd.DataFrame(
    {'index': list(range(5)),
     'my_string': ['Alondra', 'Spaanbiuk', 'Ibinth', 'Liefelle', 'Yoanda'], 
     'some_other_column': np.random.rand(5),
     }).set_index('index')
print('Original pandas DataFrame:')
print(df, '\n')

# Create the TensorFlow dataset and define a function to view it 
# as a pandas DataFrame.
ds = tf.data.Dataset.from_tensors(df.to_dict(orient='list'))
def view_ds(ds):
    data = pd.concat([pd.DataFrame(k) for k in ds.take(5)], axis=0)
    # Convert byte strings to Python strings.
    object_cols = data.select_dtypes([object])
    data[object_cols.columns] = object_cols.stack().str.decode('utf-8').unstack()
    print('TensorFlow dataset:')
    print(data, '\n')
view_ds(ds)

#### Add a suffix to `my_string` as `my_string_with_suffix`.
def add_a_suffix(x):
    x['my_string_with_suffix'] = x['my_string']+'.suffix'
    return x

# Apply to the pandas DataFrame.
print('DataFrame with the suffix:')
df = df.apply(add_a_suffix, axis=1)
print(df, '\n')

# Apply to the TensorFlow dataset.
print('TensorFlow dataset with the suffix:')
ds = ds.map(lambda x: add_a_suffix(x))
view_ds(ds)

#### Count they the number of `a`'s in `my_string`:
def count_letters(x, letter='a'):
    counter = Counter(x['my_string'].lower())
    x[f'{letter}_counts'] = counter[letter]
    return x

# Apply to the pandas DataFrame.
print('DataFrame with the letter count:')
df = df.apply(count_letters, axis=1)
print(df, '\n')
    
# Apply to the TensorFlow dataset.
# HOW BUT HOW?!!
# print('TensorFlow dataset with the letter count:')
# ds = ds.apply(lambda x: count_letters(x))
# view_ds(ds)
</code></pre>
<p>The output is of the above is as follows.</p>
<pre><code>Original pandas DataFrame:
       my_string  some_other_column
index                              
0        Alondra           0.209685
1      Spaanbiuk           0.972315
2         Ibinth           0.933700
3       Liefelle           0.186369
4         Yoanda           0.667436 

TensorFlow dataset:
   my_string  some_other_column
0    Alondra           0.209685
1  Spaanbiuk           0.972315
2     Ibinth           0.933700
3   Liefelle           0.186369
4     Yoanda           0.667436 

DataFrame with the suffix:
       my_string  some_other_column my_string_with_suffix
index                                                    
0        Alondra           0.209685        Alondra.suffix
1      Spaanbiuk           0.972315      Spaanbiuk.suffix
2         Ibinth           0.933700         Ibinth.suffix
3       Liefelle           0.186369       Liefelle.suffix
4         Yoanda           0.667436         Yoanda.suffix 

TensorFlow dataset with the suffix:
TensorFlow dataset:
   my_string  some_other_column my_string_with_suffix
0    Alondra           0.209685        Alondra.suffix
1  Spaanbiuk           0.972315      Spaanbiuk.suffix
2     Ibinth           0.933700         Ibinth.suffix
3   Liefelle           0.186369       Liefelle.suffix
4     Yoanda           0.667436         Yoanda.suffix 

DataFrame with the letter count:
       my_string  some_other_column my_string_with_suffix  a_counts
index                                                              
0        Alondra           0.209685        Alondra.suffix         2
1      Spaanbiuk           0.972315      Spaanbiuk.suffix         2
2         Ibinth           0.933700         Ibinth.suffix         0
3       Liefelle           0.186369       Liefelle.suffix         0
4         Yoanda           0.667436         Yoanda.suffix         2 
</code></pre>
",tf.py_function,tf.py_function,2022-11-14 15:44:35,5640161,791,https://stackoverflow.com/questions/75996642,Documentation Ambiguity
75939760,Slow performance of tf.gather due to index validation on CPU,"<p>I am using tensorflow to train <a href=""https://www.matthewtancik.com/nerf"" rel=""nofollow noreferrer"">Neural Radiancy Fields</a>. I used <code>tf.gather</code> to implement a multiresolution hashtable encoding as described in <a href=""https://nvlabs.github.io/instant-ngp/"" rel=""nofollow noreferrer"">this paper</a>. The important part is, that I am trying to retrieve values from a tensor that is optimized during trainig according to hash values that I computed out of 3D positions. I need to potentially do this for hundreds of thousands of values to render a single image so performance is critical.</p>
<p>I am using a GPU for training. The performance is not as good as I would expect it though which I suspect is due to the index validation for tf.gather being done on the CPU instead of the GPU. The GPU capacity is not fully utilized and I see significant CPU load. This is described in the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer"">here</a>. It says that the argument <code>validate_indices</code> is deprecated and that index validation is always done on the CPU.</p>
<p>My question is, if there is potentially a way to either</p>
<ul>
<li>disable the index validation for tf.gather</li>
<li>do the validation on the GPU</li>
<li>get around the use of tf.gather all together and use a method to get the values that is faster</li>
</ul>
<p>The values are updated during the training so precomputing values will not help in this case.</p>
<p>This is the code for the hash embedding that is functional but not performant due to the index validation:</p>
<pre><code># Setup
import tensorflow as tf
import numpy as np

# Hyperparameter
T = 2**20           # Size of the Hashtable
L = 16              # Number of Resolutions
F = 2               # Number of Dimentions of the Resolution
N_MIN = 2**4        # Minimum Resolution 
N_MAX = 2**18       # Maximum Resolution
VOLUME_SIZE = 10    # Bounding Box for the positions to be hashed

BATCH_SIZE = 1

# Large prime numbers used for the Hash Function
pi_i = tf.constant([1, 2654435761, 805459861], dtype=tf.int32)
# Build the Resolutions for each Layer
n_l = range(L)
b = np.exp((np.log(N_MAX)-np.log(N_MIN))/(L-1))
n_l = tf.constant([N_MIN * b ** l for l in n_l], dtype=tf.float32)

'''
These are the indices for the coordinates of the 8 vertices of the voxel in respect to a tensor with the elements:
X_Low
Y_Low
Z_Low
X_High
Y_High
Z_High
'''

vertex_indices = tf.constant([[0, 1, 2],    # X_Low, Y_Low, Z_Low
                              [3, 1, 2],    # X_High, Y_Low, Z_Low
                              [0, 4, 2],    # ...
                              [3, 4, 2], 
                              [0, 1, 5], 
                              [3, 1, 5], 
                              [0, 4, 5], 
                              [3, 4, 5]])

#@tf.function
def encode_position_hash(x, table):
    res = []
    x = x / VOLUME_SIZE

    # Get the vertices of the voxel that the postion is placed in at the multiple resolutions
    v = n_l * x[..., None]
    v = tf.concat([tf.math.floor(v), tf.math.ceil(v)], axis=2)
    v = tf.cast(v, dtype=tf.int32)
    v = tf.transpose(v, [3, 0, 1, 2])

    # SLOW #
    vertices = tf.gather(v, vertex_indices, axis = -1)
    # SLOW # 

    # calculate the hash
    v = vertices * pi_i[None, None, None, None,...]
    hash = tf.bitwise.bitwise_xor(v[..., 0], v[..., 1])
    hash = tf.bitwise.bitwise_xor(hash, v[..., 2])
    hash = tf.cast(tf.math.floormod(hash, T), dtype=tf.int32)

    # get the entries from the table
    # SLOW #
    vals = tf.gather(table, hash, axis=1, batch_dims=1)
    # SLOW #

    # Linear interpolation between the Embeddings of the voxel vertices
    x_tmp = tf.transpose((n_l * x[..., None]),[3, 0, 1, 2])[..., None, :]   # input positions 
    diff = tf.cast(vertices, dtype=tf.float32) - x_tmp                      # vectors to the vertices
    diff = tf.norm(diff, axis=-1)                                           # norm of the vectors -&gt; distances to vertices
    diff = tf.math.l2_normalize(diff, axis = -1)                            # normalize 
    res = tf.reduce_sum(vals * diff[..., None], axis = 3)                   # weighing of the embeddings
    res = tf.transpose(res, [1, 2, 3, 0])                                   # reshaping and reordering of the axes
    res = tf.reshape(res, (BATCH_SIZE, -1, L*F))

    res = tf.concat([res, x], axis = -1)                                    # Concat the original positions to the encodings

    return res
</code></pre>
<p>Here are some dummy examples to test the code:</p>
<pre><code># Test the embedding
''' A tensor for the 3D positions
    A 64 x 64 image, the rays sampled 16 times '''
positions = tf.random.uniform(shape = (BATCH_SIZE, 64, 64, 16, 3))
# postions are passed as a flat vector
positions = tf.reshape(positions, shape= (BATCH_SIZE, -1, 3))
''' A table for the embeddings. This will be optimzed during training so the values can NOT be precomputed
    16 Resolutions with the table size T '''
hash_table = tf.random.uniform(shape=(L, T, F), minval=-10**-4, maxval=10**-4)

# Encode the positions
encodings = encode_position_hash(positions, hash_table)
print(encodings)
</code></pre>
<p>I know that the tf.scatter_ functions do the index validation on the GPU however I can not figure out a way to utilize these functions to retrieve the values from the table.</p>
",tf.gather,tf.gather,2022-08-21 18:58:29,13230142,1,https://stackoverflow.com/questions/75939760,Documentation Replication on Other Examples
75640862,tf.py_function is only for Eager Mode?,"<p>Is <code>tf.py_function</code> only for Eager mode, and not for Graph mode?</p>
<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function#args"" rel=""nofollow noreferrer"">tf.py_function</a> says, it gives the impression that <code>tf.py_function</code> is to be used at Eager mode.</p>
<blockquote>
<p>Wraps a python function into a TensorFlow op <strong>that executes it eagerly</strong>.</p>
</blockquote>
<blockquote>
<p>This function allows expressing computations <strong>in a TensorFlow graph as Python functions</strong>. In particular, it wraps a Python function func in a once-differentiable TensorFlow operation that executes it with eager execution enabled.</p>
</blockquote>
<blockquote>
<p>You can also use tf.py_function to debug your models at runtime using Python tools, i.e., you can isolate portions of your code that you want to debug, wrap them in Python functions and insert pdb tracepoints or print statements as desired, and wrap those functions in tf.py_function.</p>
</blockquote>
<blockquote>
<p>Calling tf.py_function will <strong>acquire the Python Global Interpreter Lock (GIL)</strong> that allows only one thread to run at any point in time. This will preclude efficient parallelization and distribution of the execution of the program.</p>
</blockquote>
<p>I believe pdb works with Python interpreter and GIL is inside it, but there is no Python interpreter executing Python code while executing TensorFlow Graph in Graph mode. Hence I believe it is only for Eager Mode. Please confirm if this is correct.</p>
",tf.py_function,tf.py_function,2022-06-27 12:56:46,4281353,20088,https://stackoverflow.com/questions/75640862,Documentation Replicability
75639137,TF1 to TF2 migration,"<p>Hello I am new to tensorflow and I am working on a code that I would like to migrate from tensorflow 1 to 2. I have this line of code:</p>
<pre><code>x1 = tf.compat.v1.placeholder(tf.float32, [], name=&quot;x1&quot;)
</code></pre>
<p>As mentioned in <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder</a>, I should use <code>keras.Input</code>. But even when specifying the shape, I can't have the same tensor as with compat.v1:</p>
<pre><code>x2 = tf.keras.Input(shape=[], dtype=tf.float32, name=&quot;x2&quot;)
</code></pre>
<p>To check the shape I use <code>tf.shape(x1)</code> or <code>tf.shape(x2)</code>, but the shapes are not the same. Could anyone explain to me how to have, in TF2, the same shape as in TF1 ?
Thanks and regards</p>
",tf.compat.v1.placeholder,tf.compat.v1.placeholder,2022-05-21 11:25:40,15822972,101,https://stackoverflow.com/questions/75639137,Documentation Replicability
75572543,What to look out for when passing a generator into model.fit in tensorflow?,"<p>I want to replace the x and y training data parameters in tf.keras.Model.fit with a generator. However, some subtlety seems to escape me, as the model accuracy doesn't improve with the generator when training.</p>
<p>As far as I understand the documentation, the generator is supposed to yield tuples <code>(x_vals,y_vals)</code>, such that <code>x_vals</code> is a concatenation of <code>batch_size</code>-many training samples along a new 0th dimension, and 'v_vals' is the concatenation of their corresponding labels.</p>
<p>As long as the generator fulfills this, as I understand it, we can just replace the x parameter in tf.keras.Model.fit with the generator and omit the y parameter, though to define an epoch, we also need to specify 'steps_per_epoch' in fit.</p>
<p>There however seems to be something here I misunderstood or forgot, because starting with a model and input data that trains (i.e. its accuracy improves) and replacing the training data array with a generator as discussed, results in a model that doesn't train (i.e. its accuracy instead goes up a little, then however goes back down till its equal to chance).</p>
<p>The corresponding code:</p>
<pre><code>import numpy as np
import tensorflow as tf

BATCH_SIZE = 32

#Loading training data:
def load_cifar():
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
    assert x_train.shape == (50000, 32, 32, 3)
    assert x_test.shape == (10000, 32, 32, 3)
    assert y_train.shape == (50000, 1)
    assert y_test.shape == (10000, 1)

    #Normalize the data &amp; cast to fp32:
    x_train = np.true_divide(x_train,255,dtype=np.single)
    x_test =  np.true_divide(x_test,255,dtype=np.single)
    y_train = y_train.astype(np.single)
    y_test =  y_test.astype(np.single)

    return (x_train,y_train), (x_test,y_test)


(train_x, train_y) , (validation_x, validation_y) = load_cifar()
   


# Defining the generator:
def data_generator_dummy(input_data_x:np.ndarray,
                          input_data_y:np.ndarray,
                          batch_size=BATCH_SIZE,
                          ):
    &quot;&quot;&quot;
    Given the input_data's, generate infinitely by:
     1. Drawing batch_size-many vectors from input_data_x and input_data_y
     2. Turn the drawn vectors into a mini-batch (with shape  [None]+input_data.shape)

    :param batch_size:
    :param input_data_x, input_data_y: The data on which noise shall be added
    :return: A generator for the input data.
    &quot;&quot;&quot;
    index =0
    while True:
        # We start with a zero-vector of expected size and fill the drawn samples into it:
        samples_x = np.zeros( [batch_size] + list(input_data_x.shape[1:]),dtype=np.single)
        samples_y = np.zeros( [batch_size] + list(input_data_y.shape[1:]),dtype=np.single)
        for i in range(batch_size):
            samples_x[i] = input_data_x[index%50_000]
            samples_y[i] = input_data_y[index%50_000]
            index +=1

        yield samples_x,samples_y

# Basically a linear classifier:
def make_model():
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(10,tf.nn.softmax))
    model.build([None] +list(train_x[0,:,:,:].shape))
    return model


#Training:
generator = data_generator_dummy(train_x,train_y,batch_size=BATCH_SIZE)
model = make_model()
model.summary()
optimizer_adam=tf.keras.optimizers.Adam(learning_rate=0.0005/32,beta_1=0.9,beta_2=0.999,epsilon=1e-07)
model.compile(optimizer_adam,loss=&quot;sparse_categorical_crossentropy&quot;,metrics=&quot;accuracy&quot;)
model.fit(generator, validation_data=(validation_x,validation_y),epochs=10,
          steps_per_epoch=train_x.shape[0]//BATCH_SIZE,
          )

# This one however works:
# model.fit(train_x, train_y, validation_data=(validation_x,validation_y),epochs=30,
#           steps_per_epoch=train_x.shape[0]//BATCH_SIZE,
#           shuffle=True
#           )
</code></pre>
<hr />
<p>The model also trains if one first let's the generator generate a long list of samples and then passes those into <code>fit</code> as <code>x</code>and <code>y</code>:</p>
<pre><code>#Training:
generator = data_generator_dummy(train_x,train_y,batch_size=50000)
model = make_model()
model.summary()
optimizer_adam=tf.keras.optimizers.Adam(learning_rate=0.0005/32,beta_1=0.9,beta_2=0.999,epsilon=1e-07)
model.compile(optimizer_adam,loss=&quot;sparse_categorical_crossentropy&quot;,metrics=&quot;accuracy&quot;)
while True:
    samples_x,samples_y = next(generator)
    model.fit(samples_x,samples_y, validation_data=(validation_x,validation_y),epochs=10,batch_size=BATCH_SIZE
          )
</code></pre>
",tf.keras.Model,tf.keras.Model,2022-04-01 18:22:14,8536211,360,https://stackoverflow.com/questions/75572543,Documentation Replication on Other Examples
75478235,tf.image.ssim() not accepting 'return_index_map' argument,"<p>The documentation for Tensorflow's <a href=""https://www.tensorflow.org/api_docs/python/tf/image/ssim"" rel=""nofollow noreferrer"">tf.image.ssim()</a> says that if you want to return an element-wise structural similarity map, you can set &quot;return_index_map&quot; to True. It is returning an error when I define the argument as either True or False. I am running Tensorflow 2.10 on an Apple M1 Max.</p>
<p>When I run:</p>
<pre><code>    import tensorflow as tf

    a = tf.ones((20, 20, 20, 20))
    b = tf.zeros((20, 20, 20, 20))

    sim = tf.image.ssim(a, b, max_val=1, return_index_map=True)
</code></pre>
<p>I get the error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;/Users/miguel/opt/miniconda3/envs/py39_tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py&quot;, line 3433, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &quot;&lt;ipython-input-4-967be677c86c&gt;&quot;, line 1, in &lt;module&gt;
    sim = tf.image.ssim(a, b, max_val=1, return_index_map=True)
  File &quot;/Users/miguel/opt/miniconda3/envs/py39_tensorflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py&quot;, line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File &quot;/Users/miguel/opt/miniconda3/envs/py39_tensorflow/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py&quot;, line 1170, in op_dispatch_handler
    result = api_dispatcher.Dispatch(args, kwargs)
TypeError: Got an unexpected keyword argument 'return_index_map'
</code></pre>
",tf.image.ssim,tf.image.ssim,2022-02-28 8:05:44,20324823,1,https://stackoverflow.com/questions/75478235,Documentation Replicability
74434308,Setting only global level seed gives same output in consecutive iterations of loop in Tensorflow,"<p>I am testing out the <code>tf.random.set_seed</code> according to the rules given at - <a href=""https://www.tensorflow.org/api_docs/python/tf/random/set_seed"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/random/set_seed</a></p>
<p>In particular I am testing the second rule - where we set only global level seed and no operation level seed.</p>
<p>According to the documentation (the link is mentioned above), the second rule is:</p>
<blockquote>
<p>If the global seed is set, but the operation seed is not: The system deterministically picks an operation seed in conjunction with the global seed so that it gets a unique random sequence.</p>
</blockquote>
<p>To explain the second rule, the documentation uses the following snippet:</p>
<pre><code>tf.random.set_seed(1234)
print(tf.random.uniform([1]))  # generates 'A1'
print(tf.random.uniform([1]))  # generates 'A2'
</code></pre>
<p>and states that</p>
<blockquote>
<p>The reason we get 'A2' instead 'A1' on the second call of tf.random.uniform above is because the second call uses a different operation seed.</p>
</blockquote>
<p>Now, I tested this rule on a 1D tensor of shape (3,) to check if the output of shuffling the tensor does not give the same sequence within consecutive iterations of the loop as follows:</p>
<pre><code>import tensorflow as tf


&quot;&quot;&quot;
Only global level seed
&quot;&quot;&quot;

tf.random.set_seed(1234)
   
constant_tensor = tf.constant([1,2,3])

for i in range(1, 15):
    shuffled_tensor = tf.random.shuffle(constant_tensor)
    print(shuffled_tensor)
</code></pre>
<p>I got the following output:</p>
<pre><code>tf.Tensor([3 1 2], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([1 3 2], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([1 2 3], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
</code></pre>
<p>From the output you can see that the sequence on line number 7 and 8 match.
Also the sequence on line number 13 and 14 match.</p>
<p>According to the documentation, tensorflow should not output the same sequence in a consecutive iteration.</p>
<p>Then why am I getting this kind of output? Have I misunderstood the concept?</p>
<p>To test this further, I also tested to following snippet which I used to generate 14 1-D tensors and check if any tensor is repeated within consecutive runs as follows:</p>
<pre><code>import tensorflow as tf
tf.random.set_seed(1234)
for i in range(1, 15):
    print(tf.random.uniform(shape=[1], minval=1, maxval=15, dtype=tf.int32))
</code></pre>
<p>And I got the following output:</p>
<pre><code>tf.Tensor([12], shape=(1,), dtype=int32)
tf.Tensor([8], shape=(1,), dtype=int32)
tf.Tensor([1], shape=(1,), dtype=int32)
tf.Tensor([2], shape=(1,), dtype=int32)
tf.Tensor([4], shape=(1,), dtype=int32)
tf.Tensor([3], shape=(1,), dtype=int32)
tf.Tensor([2], shape=(1,), dtype=int32)
tf.Tensor([7], shape=(1,), dtype=int32)
tf.Tensor([13], shape=(1,), dtype=int32)
tf.Tensor([11], shape=(1,), dtype=int32)
tf.Tensor([8], shape=(1,), dtype=int32)
tf.Tensor([3], shape=(1,), dtype=int32)
tf.Tensor([1], shape=(1,), dtype=int32)
tf.Tensor([4], shape=(1,), dtype=int32)
</code></pre>
<p>You can see that no two consecutive tensors are repeated. Why didn't I see this behaviour for my first snippet?</p>
",tf.random.set_seed,tf.random.set_seed,2021-06-28 11:48:57,7422352,5021,https://stackoverflow.com/questions/74434308,Documentation Ambiguity
74060508,How to Save a Tensorflow Dataset,"<p>As the title says I'm trying to save a <code>TensorSliceDataset</code> object to file. Viewing tensorflow's <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">website</a> it seems that the <code>tf.data.Dataset</code> class has a save function but it is not implemented for <code>TensorSliceDataset</code> objects. Pickling also did not work for me.</p>
<p>Example code</p>
<pre><code>import tensorflow as tf
t = tf.range(10)
ds = tf.data.Dataset.from_tensor_slices(t)
ds.save()
</code></pre>
<p>returns error: <code>AttributeError: 'TensorSliceDataset' object has no attribute 'save'</code></p>
",tf.data.Dataset,tf.data.Dataset,2021-05-13 17:54:55,7875444,298,https://stackoverflow.com/questions/74060508,Documentation Replicability
73794766,what is the meaning of axis=-1 in tf.keras.layers.Normalization?,"<p>I'm trying to learn deep learning using keras and tensorflow and I came across a code explaining linear regression at <a href=""https://www.tensorflow.org/tutorials/keras/regression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/keras/regression</a> wherein they have created a normalization layer using normalizer = tf.keras.layers.Normalization(axis=-1). Someone please explain the meaning of axis =-1 . I tried looking at the API documentation but I couldnt understand the explanation from there?I know that axis=0 represent rows and axis=1 columns, right?
Thanks in advance</p>
",tf.keras.layers.Normalization,tf.keras.layers.Normalization,2021-04-22 10:07:35,19986715,1,https://stackoverflow.com/questions/73794766,Documentation Completeness
73461248,Is there an alternative to tf.keras.utils.image_dataset_from_directory if images are not organized in class-folders?,"<p>I want to train an image classification network.</p>
<p>I have all images in one folder and a .json file with labels and a lot of meta data.
I wrote a couple of functions to extract the images which correspond to the classes I want to train for, shuffle them and randomly split them into a train- and a val-list.
So currently I have something like this:</p>
<pre><code>list_imagepath_train = [' C:\Users\someuser\Pictures\randomimagename1.jpg', ' C:\Users\someuser\Pictures\randomimagename2.jpg', ' C:\Users\someuser\Pictures\randomimagename5.jpg', ' C:\Users\someuser\Pictures\randomimagename8.jpg', ' C:\Users\someuser\Pictures\randomimagename9.jpg', ' C:\Users\someuser\Pictures\randomimagename10.jpg', ' C:\Users\someuser\Pictures\randomimagename12.jpg']

list_corresponding_classlabels_train = ['5', '5', '2', '3', '2', '2', '5']
    
list_imagepath_val = [' C:\Users\someuser\Pictures\randomimagename3.jpg', ' C:\Users\someuser\Pictures\randomimagename4.jpg', ' C:\Users\someuser\Pictures\randomimagename6.jpg', ' C:\Users\someuser\Pictures\randomimagename7.jpg']
    
list_corresponding_classlabels_val = ['2', '3', '5', '2']
</code></pre>
<p>And now I want to convert those lists to a train- and a val-dataset to use in Tensorflow.
The thing is that I can't use <code>tf.keras.utils.image_dataset_from_directory</code> because alle images, independent of their label, are in the same folder and it seems a bit pointless to me to move them around every time I start a new training. <code>tf.keras.preprocessing.image.ImageDataGenerator</code> is deprecated (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator</a>) and now I am not sure which function to use to convert the lists into the needed dataset.
This is all very new to me, so any input or hint is very welcome!</p>
",tf.keras.preprocessing.image.ImageDataGenerator,tf.keras.preprocessing.image.ImageDataGenerator,2021-03-04 2:31:04,19399312,142,https://stackoverflow.com/questions/73461248,Documentation Replicability
73179836,tensorflow.py_function fails to temporarily switch to eager execution while in graph mode,"<p>I'm not sure if this is a Tensorflow bug or my misunderstanding about what this function is supposed to do, but I can't get <code>tf.py_function</code> to return an <code>EagerTensor</code> <em>while in graph mode</em>. Consequently, calling <code>.numpy()</code> on the output of this function fails.</p>
<p>The issue can be reproduced using the exact example given in the official documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/py_function</a>):</p>
<pre><code>import tensorflow as tf

tf.compat.v1.disable_eager_execution()

def log_huber(x, m):
  if tf.abs(x) &lt;= m:
    return x**2
  else:
    return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))

x = tf.constant(1.0)
m = tf.constant(2.0)

with tf.GradientTape() as t:
  t.watch([x, m])
  y = tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32)

dy_dx = t.gradient(y, x)
assert dy_dx.numpy() == 2.0

</code></pre>
<p>This generates the following error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;&lt;input&gt;&quot;, line 17, in &lt;module&gt;
  File &quot;C:\Users\...\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\framework\ops.py&quot;, line 446, in __getattr__
    self.__getattribute__(name)
AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>
<h3>About version</h3>
<p>I am running Python 3.8 and Tensorflow v2.9.1.</p>
<p>Any help would be greatly appreciated!</p>
",tf.py_function,tf.py_function,2021-02-05 12:04:21,10453038,86,https://stackoverflow.com/questions/73179836,Documentation Replicability
72850120,"Keras - Specifying from_logits=False when using tf.keras.layers.Dense(1,activation='sigmoid')(x)","<p>I am working on a binary classification problem, using transfer learning and image inputs and have a question regarding the</p>
<p>I have been working through using the correct activation layers (e.g. Softmax or Sigmoid - sigmoid for binary softmax for multiclass) and noticed when I specify 'sigmoid' as part of the <code>Dense()</code> output layer, I no longer need to specify <code>from_logits=True</code> during <code>model.compile()</code>.</p>
<p>This means when I am obtaining predictions, I don't use the <code>tf.nn.sigmoid()</code> function and instead simply check if the value is greater than 0.5, then 1, else 0. Is this correct? Here is my code:</p>
<pre><code>i = keras.Input(shape=(150, 150, 3))
                scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)
                mt = scale_layer(i)
                mt = base_model(model_top, training=False)
                mt = keras.layers.GlobalAveragePooling2D()(mt)
                mt = keras.layers.Dropout(dropout)(mt)  # Regularize with dropout
                o = keras.layers.Dense(1,activation='sigmoid')(mt)
                model = keras.Model(i, o)

....

model.compile(optimizer=keras.optimizers.Adam(lr),loss=keras.losses.BinaryCrossentropy(from_logits=False)
                )
</code></pre>
<p>And then when I obtain predictions, I have the following:</p>
<pre><code>                pred = model.predict(test)
                pred = tf.where(pred &lt; 0.5, 0, 1)
                pred = pred.numpy()
</code></pre>
<p>My intuition is that as I am specifying the sigmoid activation function during the Dense layer build, I no longer work with 'logits' and therefore do not need to apply the sigmoid function later on. In the documentation, I've seen both examples used but it's quite sparse on information when working with <code>model.predict()</code>, would appreciate any guidance.</p>
",tf.nn.sigmoid,tf.nn.sigmoid,2021-02-04 3:12:10,6419012,35,https://stackoverflow.com/questions/72850120,Documentation Replicability
72749893,Optimizer.apply_gradients creating variables in tf.function,"<p>I have created a neural style transfer with Eager Execution, but it does not work when I  try to turn it into a tf.function.
The error message says:</p>
<pre><code>ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
</code></pre>
<p>However, no variable is being created inside the function. Here is a simplified version of the code, which is just a neural style transfer with one image (the goal is to make the generated image look exactly like the content image):</p>
<pre><code>import tensorflow as tf
import numpy as np
from PIL import Image

#Get and process the images
image = np.array(Image.open(&quot;frame7766.jpg&quot;)).reshape(1, 720, 1280, 3)/255
content_image = tf.convert_to_tensor(image, dtype = tf.float32)
# variable is defined outside of tf.function
generated_image = tf.Variable(np.random.rand(1, 720, 1280, 3)/2 + content_image/2, dtype = tf.float32)

def clip_0_1(image): # keeps image values between 0 and 1
    return tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)

@ tf.function
def train_step(generated_image, content_image): #turn generated image into tf variable
    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)
    with tf.GradientTape() as tape:
        cost = tf.reduce_sum(tf.square(generated_image - content_image))
    grad = tape.gradient(cost, generated_image) 
    optimizer.apply_gradients([(grad, generated_image)]) # More information below
    generated_image.assign(clip_0_1(generated_image))
    return generated_image

generated_image = train_step(generated_image, content_image)
</code></pre>
<p>The error message points to the line</p>
<pre><code>optimizer.apply_gradients([(grad, generated_image)]) 
</code></pre>
<p>I have tried to change the input of <code> optimizer.apply_gradients</code> to <code>zip([grad], [generated_image])</code>, and every combination of lists and tuples I can think of, but the error still remains. I have also looked through <a href=""https://www.tensorflow.org/guide/function#creating_tfvariables"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/function#creating_tfvariables</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer</a>, but neither of them shows examples where the variable is not explicitly defined.
The only conclusion that I can come to is that one of my commands (most likely <code>optimizer.apply_gradients</code>) creates a variable because of an issue in my earlier code. Is that correct?</p>
",tf.keras.optimizers.Optimizer,tf.keras.optimizers.Optimizer,2021-02-03 1:28:57,17819542,13,https://stackoverflow.com/questions/72749893,Documentation Replication on Other Examples
72720129,Understanding tf.keras.metrics.Precision and Recall for multiclass classification,"<p>I am building a model for a multiclass classification problem. So I want to evaluate the model performance using the Recall and Precision.
I have 4 classes in the dataset and it is provided in <code>one hot</code> representation.</p>
<p>I was reading the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision"" rel=""nofollow noreferrer"">Precision</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall"" rel=""nofollow noreferrer"">Recall</a> <code>tf.keras</code> documentation, and have some questions:</p>
<ol>
<li>When it calculating the Precision and Recall for the multi-class classification, how can we take the average of all of the labels, meaning the global precision &amp; Recall? is it calculated with <code>macro</code> or <code>micro</code> since it is not specified in the documentation as in the <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html"" rel=""nofollow noreferrer"">Sikit learn</a>.</li>
<li>If I want to calculate the precision &amp; Recall for each label separately, can I use the argument <code>class_id</code> for each label to do  <code>one_vs_rest</code> or <code>binary</code> classification. Like what I have done in the code below?</li>
<li>can I use the argument <code>top_k</code> with the value <code>top_k=2</code> would be helpful here or it is not suitable for my classification of 4 classes only?</li>
<li>While I am measuring the performance of each class, What could be the difference, when I set the <code>top_k=1</code> and not setting <code>top_k</code>overall?</li>
</ol>
<pre><code>model.compile(
      optimizer='sgd',
      loss=tf.keras.losses.CategoricalCrossentropy(),
      metrics=[tf.keras.metrics.CategoricalAccuracy(),
               ##class 0
               tf.keras.metrics.Precision(class_id=0,top_k=2), 
               tf.keras.metrics.Recall(class_id=0,top_k=2),
              ##class 1
               tf.keras.metrics.Precision(class_id=1,top_k=2), 
               tf.keras.metrics.Recall(class_id=1,top_k=2),
              ##class 2
               tf.keras.metrics.Precision(class_id=2,top_k=2), 
               tf.keras.metrics.Recall(class_id=2,top_k=2),
              ##class 3
               tf.keras.metrics.Precision(class_id=3,top_k=2), 
               tf.keras.metrics.Recall(class_id=3,top_k=2),
])
</code></pre>
<p>Any clarification of this function will be appreciated.
Thanks in advance</p>
",tf.keras.metrics.Precision,tf.keras.metrics.Precision,2021-01-29 11:27:07,17534198,325,https://stackoverflow.com/questions/72720129,Documentation Replicability
72707453,How to save a tensorflow dataset to multiple shards without using enumerate,"<p>I have a tensorflow dataset with some elements in it, and I want to save it with <code>tf.data.Dataset.save</code> such that each element gets its own shard. Thus if the dataset contains 2,000 elements, it would be saved to 2,000 shards.</p>
<p>The documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#save"" rel=""nofollow noreferrer"">here</a> specifies how to create 1 shard only, but not how to make a shard for each element.</p>
<p>Below, I am able to do it with enumerate, but is there another way to do it without also saving the index from <code>enumerate</code>?</p>
<pre><code>tuple_data = np.array([3, 4])
data = tf.data.Dataset.from_tensor_slices(tuple_data)
data = data.enumerate()
print(list(data.as_numpy_iterator()))
# [(0, 3), (1, 4)]

data.save(path='~/Desktop/1', shard_func=lambda i, x: i)
</code></pre>
",tf.data.Dataset,tf.data.Dataset,2021-01-23 19:54:08,9909857,341,https://stackoverflow.com/questions/72707453,Documentation Replicability
72329108,Is there a simple way to know which Tensorflow ops have a registered GPU kernel?,"<p>I have been trying to optimize some Tensorflow code that was pretty memory inefficient (use of large dense tensors containing very sparse information), and would thus limit batch size and scalability, by trying to make use of SparseTensors.
After some struggle I finally come up with a decent solution with satisfactory speedup on CPU and very low memory usage, and when the time comes to use a GPU I realize that the previous memory inefficient is orders of magnitude faster...</p>
<p>Using tensorboard profiling I've discovered that two of the operations I have used in my &quot;&quot;optimized&quot;&quot; version only run on CPU (namely UniqueV2 and sparse_dense_matmul), but I could not see any hint of that in the documentation.</p>
<p>The only related piece of <a href=""https://www.tensorflow.org/guide/gpu#overview"" rel=""nofollow noreferrer"">documentation</a> states:</p>
<blockquote>
<p>If a TensorFlow operation has no corresponding GPU implementation,
then the operation falls back to the CPU device. For example, since
tf.cast only has a CPU kernel, on a system with devices CPU:0 and
GPU:0, the CPU:0 device is selected to run tf.cast, even if requested
to run on the GPU:0 device.</p>
</blockquote>
<p>In turn there is nothing in the tf.cast documentation hinting that the op has no GPU kernel.</p>
<p>Thus, is there a simple way to know whether a TF ops has a registered GPU kernel, without having to use a GPU to find it out?</p>
<p>The <a href=""https://www.tensorflow.org/guide/create_op#gpu_support"" rel=""nofollow noreferrer"">custom ops</a> guide suggest that this could be seen by looking at the ops C files, but this seems a rather cumbersome way to do it...</p>
<p>I'm using TF v2.8</p>
<p>Thanks!</p>
",tf.cast,tf.cast,2021-01-16 21:00:36,19167343,11,https://stackoverflow.com/questions/72329108,Inadequate Examples
71933464,How to make true_fn of tf.cond skip a for loop in tensorflow v1.0/python?,"<p>I want to use <code>tf.cond</code> to mimic the python <code>if-else</code> logic in the <code>_preprocessing_fn</code> of <code>transform.py</code>.</p>
<p>Specifically, if the condition of <code>tf.cond</code> is true, I want to skip the current iteration of the for loop.</p>
<p>This seems problematic because <code>true_fn</code> and <code>false_fn</code> parameters of <code>tf.cond</code> are expected to return Tensors according to the documentation.</p>
<p>However, in my case, I want <code>true_fn</code> (aka <code>skip_feature_fn</code>)to simply &quot;continue&quot; to the next for loop iteration. Also, I want <code>false_fn</code> to take in two inputs (<code>feature</code> and <code>sp</code>) and simply feed them to some other API (e.g. <code>tft.vocabulary</code>).
I don't expect either of <code>true_fn</code> or <code>false_fn</code> to return anything.</p>
<p>Could someone help me accomplish my goal?</p>
<p>Here is the code snippet I'm working with:</p>
<pre><code>def _preprocessing_fn(inputs, category_features=features.STRING_FEATURES):
  outputs = transform_lib.preprocessing_helper_fn(
      inputs, used_features=category_features)

  for feature in category_features:
    if feature:
      sp = outputs[feature]
      tf.cond(
          tf.equal(sp.dense_shape[1], 0), skip_feature_fn, lambda: process_feature_further(
              feature,
              sp,
          ))

  return outputs
</code></pre>
<p>Thank you.</p>
",tf.cond,tf.cond,2021-01-06 12:45:56,4982651,117,https://stackoverflow.com/questions/71933464,Documentation Replication on Other Examples
71893462,How to retrieve file paths from a tf.data.Dataset created with from_tensor_slices() and shuffled after every epoch,"<p>First of all, I would like to say that this is my first question in stackOverflow, so I hope that the question as a whole respects the rules. I realize that the question is a bit long, but I would like to provide as much background and detail as possible .</p>
<p>I am currently developing a real-time image binary classification system based on Tensorflow 2.8.0 and I am quite new at it. Here are some of the peculiarities of the data that I have for the mentioned project:</p>
<ul>
<li>Too big to fit in memory: I have more than 200 GB of data. Keep in mind that I have labeled only a small portion of it, but <strong>I want to write code that could manage the whole dataset in the future</strong>.</li>
<li>Some files are not directly compatible with Tensorflow: I have .FITS and .FIT files that cannot be opened directly with Tensorflow. Due to this issue, I use a library called Astropy to open these files.</li>
<li>The classes are very unbalanced.</li>
</ul>
<p>After reading the official documentation and tutorials, I thought that, in order to load, preprocess and feed data to my CNN, the best option was to build an input pipeline using the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">`</a> class due to the ease of opening FITS files. My general procedure follows this idea:</p>
<ol>
<li>Get a list of file paths and split it into train, val and test partitions if desired.</li>
<li>Create a tf.data.Dataset with the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices"" rel=""nofollow noreferrer"">from_tensor_slices()</a> method</li>
<li>Shuffle the data (before the heavier reading and image processing operations)</li>
<li>Read and process every path with <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">map()</a></li>
<li>Batch and prefetch</li>
</ol>
<p>Here are some code fragments in case they help to understand my goal:</p>
<pre><code>(...)

import config as cfg    # Custom .py file
import tensorflow as tf

# x_train, x_val and x_test are previously split file paths lists
train_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in x_train])
val_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in x_val])
test_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in x_test])

train_ds = configure_tf_ds(train_ds)
val_ds = configure_tf_ds(val_ds)
test_ds = configure_tf_ds(test_ds)

def configure_tf_ds(self, tf_ds, buf_size):
    # reshuffle_each_iteration=True ensures that data is shuffled each time it is iterated
    tf_ds = tf_ds.shuffle(buffer_size=cfg.SHUFFLE_BUF_SIZE, seed=cfg.seed, reshuffle_each_iteration=True)
    
    tf_ds = tf_ds.map(lambda x: tf.py_function(self.process_path, [x], [self.img_dtpye, self.label_dtype]))

    tf_ds = tf_ds.batch(self.batch_size) 

    tf_ds = tf_ds.prefetch(buffer_size=tf.data.AUTOTUNE)

    return tf_ds

def process_path(self, file_path):
    # Labels are extracted from the file path, not relevant for my problem
    label = get_label(file_path)
    path = bytes.decode(file_path.numpy()).lower()
    img = None
    # Open and process images depending on their file paths' extension: FITS, FIT, JPG
    if &quot;fit&quot; in path:
        img = tf.py_function(func=self.decode_fits, inp=[file_path], Tout=self.img_dtpye)  
    else:
        img = tf.py_function(func=self.decode_img, inp=[file_path], Tout=self.img_dtpye)  

    return img, label

model.fit(train_ds, epochs=50, validation_data=val_ds)

# Then, I would like to obtain predictions, plot results, and so on but knowing which file paths I am working with

(...)

</code></pre>
<p>Following the previous idea, I have successfully created and tested different types of pipelines for different types of partitions of my dataset: unlabeled (remember that only a portion of the data is labeled), labeled and weighted labeled (I wanted to see if my models improve by specifying class weights when training).</p>
<p>However, in order to monitor results and make proper adjustments to my model, I would like to retrieve the usual predictions, real labels and images next to the file paths <strong>preserving the ability to shuffle the data after every epoch</strong>.
I have managed to solve my question if I do not shuffle data with .shuffle(reshuffle_each_iteration=True), but models' performance is supposed to increase if data is shuffled after each epoch, according to several sources.</p>
<p>I have read different posts in stackOverflow related to my question. I will list those posts next to the problems that I have found for my particular use case:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/67072660/tensorflow-how-to-retain-file-names-in-tf-data-dataset-from-generator"">Solution 1:</a> My dataset cannot be fed to the model as X, y because it is a tf.data.Dataset</li>
<li><a href=""https://stackoverflow.com/questions/51162500/how-can-i-access-the-filenames-gathered-by-tf-data-dataset-list-files"">Solution 2:</a> I want to obtain the image and the label too.</li>
<li><a href=""https://stackoverflow.com/questions/54752287/get-input-filenames-from-tensorflow-dataset-iterators"">Solution 3:</a> This works, but it would not respect the expected tf.data.Dataset format in the future .fit() call <a href=""https://keras.io/api/models/model_training_apis/#fit-method"" rel=""nofollow noreferrer"">as stated here</a>:</li>
</ul>
<blockquote>
<p>A tf.data dataset. Should return a tuple of either (inputs, targets)
or (inputs, targets, sample_weights)</p>
</blockquote>
<p>I have also tried to keep a separate tf.data.Dataset with only the file paths but if I call the shuffle method with the reshuffle_each_iteration=True option in both tf.data.Dataset instances, the order of their elements does not match even if I set the same seed.</p>
<p>In short, is it possible to achieve what I want? If so, how should I proceed?</p>
<p>Thank you very much in advance.</p>
",tf.data.Dataset,tf.data.Dataset,2021-01-05 19:08:24,18816743,21,https://stackoverflow.com/questions/71893462,Documentation Replication on Other Examples
71619495,Image normalization by tf.image.convert_image_dtype function,"<p>According to documentation <code>tf.image.convert_image_dtype</code> &quot;Images that are represented using floating point values are expected to have values in the range [0,1).&quot;</p>
<p>But in the keras tutorial(<a href=""https://keras.io/examples/vision/cutmix/"" rel=""nofollow noreferrer"">https://keras.io/examples/vision/cutmix/</a>) i have seen the following preprocessing function:</p>
<pre><code>def preprocess_image(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0
    return image, label
</code></pre>
<p>My question is: why did they divide by 255, when <code>tf.image.convert_image_dtype</code> already did that job?</p>
",tf.image.convert_image_dtype,tf.image.convert_image_dtype,2020-12-28 17:31:25,5094589,915,https://stackoverflow.com/questions/71619495,Documentation Ambiguity
71588962,Solving a set of linear systems in tensorflow,"<p>I'm having a problem understanding the working mechanism of tensorflow's function: tf.linalg.solve.
I want to solve a set of linear systems (AX = Y), where the linear coefficients (A) were shared but there are multiple batches of Y, which are different.
Using numpy, I can simply do it via:</p>
<pre><code>np.random.seed(0)
mtx = np.random.uniform(size= (1,4,4))
vec = np.random.uniform(size= (100,4,1))
solution = np.linalg.solve(mtx,vec)
print(abs(np.matmul(mtx,solution) - vec).max())
# 5.551115123125783e-16
</code></pre>
<p>which gives me a quite consistent solution.
But when I switch to tensorflow, it gives me the results:</p>
<pre><code>mtx = tf.random.uniform(shape = (1,4,4))
vec = tf.random.uniform(shape = (100,4,1))
solution = tf.linalg.solve(mtx,vec)
print(tf.math.reduce_max(abs(tf.matmul(mtx,solution) - vec))) 
# tf.Tensor(1.3136615, shape=(), dtype=float32)
</code></pre>
<p>According to the document, I assume the solution should be solved according to the corresponding vec. But it does not seem to give me the expected results in tensorflow. Since I'm a new user, I could have messed up something.
It would be appreciated if any information could be offered.</p>
",tf.linalg.solve,tf.linalg.solve,2020-12-24 11:09:18,12416654,63,https://stackoverflow.com/questions/71588962,Documentation Ambiguity
71294464,@tf_gradient peculiar implementation in StyleGan,"<p>I've been reading the source code for the StyleGAN implementation, and I cannot understand the peculiar use of the <code>@tf_gradient</code> decorator. Let us take the concrete example of their implementation of <code>Leaky_Relu</code>. The way I would do it is as follows :</p>
<pre><code>def myLRelu(x,alpha=0.2):
    alpha = tf.constant(alpha, dtype=x.dtype, name='alpha')
    @tf.custom_gradient
    def func(x):
        y = tf.maximum(x, x * alpha)
        def grad(dy):
            dx = tf.where(y &gt;= 0, dy, dy * alpha)
            return dx
        return y, grad
    return func(x)
</code></pre>
<p>Which follows the tf documentation for the use of tf.custom_gradient. But in the styleGan paper, they implement it as follows (I removed the &quot;variable_scope&quot; in my implementation as I'm not sure what it does):</p>
<pre><code>def leaky_relu(x, alpha=0.2):
    with tf.variable_scope('LeakyReLU'):
        alpha = tf.constant(alpha, dtype=x.dtype, name='alpha')
        @tf.custom_gradient
        def func(x):
            y = tf.maximum(x, x * alpha)
            @tf.custom_gradient
            def grad(dy):
                dx = tf.where(y &gt;= 0, dy, dy * alpha)
                return dx, lambda ddx: tf.where(y &gt;= 0, ddx, ddx * alpha)
            return y, grad
        return func(x)
</code></pre>
<p>There are two <code>@tf.custom_gradient</code> decorators used, and I don't understand why since there clearly aren't any second order derivatives being computed (as they are identically 0 anyway for LRelu). Is this a trick to somehow speed up computations ? If so, how does it work ?</p>
<p>EDIT : To clarify why I think this is somehow a &quot;trick&quot; to make computations of gradients faster, the authors make the following comment in the code :</p>
<pre><code># High-level ops for manipulating 4D activation tensors.
# The gradients of these are meant to be as efficient as possible.
</code></pre>
<p>And for completeness, here is the <a href=""https://github.com/NVlabs/stylegan/"" rel=""nofollow noreferrer"">repo</a> from which I took the code from</p>
",tf.custom_gradient,tf.custom_gradient,2020-12-22 12:08:57,3842374,153,https://stackoverflow.com/questions/71294464,Documentation Replication on Other Examples
71130645,Correct axes to use dot product to evaluate the final output of a listwise learning to rank model,"<p>I'm not being able to find the correct configuration to pass to a tf.keras.layers.Dot to make a pairwise dot product when the entries each have lists of values, like from a listwise learning to rank model. For instance, suppose:</p>
<pre><code>repeated_query_vector = [
  [[1, 2], [1, 2]],
  [[3, 4], [3, 4]]
]

document_vectors = [
  [[5, 6], [7, 8]],
  [[9, 10], [11, 12]],
]
</code></pre>
<p>Calling tf.keras.layers.Dot(axes=??)([repeated_query_vector, document_vectors]) I want the output to be like:</p>
<pre><code>[
  [1*5 + 2*6, 1*7 + 2*8]
  [3*9 + 4*10, 3*11 + 4*12]
]
</code></pre>
<p>All examples I found in the documentation have one dimension less than my use case. What would be the correct value of axes for this call?</p>
",tf.keras.layers,tf.keras.layers,2020-12-08 14:55:46,13262684,35,https://stackoverflow.com/questions/71130645,Inadequate Examples
70363340,Question about tensorflow.tile with a tensor of 5 dimensions,"<p>I'm trying to understand the following thing from an implementation of a paper I'm currently reading:</p>
<p>In <code>tensorflow</code>, if I have a tensor <code>x</code> of shape <code>(4,64,5,5)</code></p>
<ul>
<li><p>Then I create a new dimension by doing</p>
<pre><code>x = x[:,:,tf.newaxis]
</code></pre>
<p>ending with a new tensor of <code>shape</code> <code>(4,64,1,5,5)</code></p>
</li>
<li><p>Then I do</p>
<pre><code>x = tf.tile(x, (1, 1, 5, 1, 1))
</code></pre>
</li>
</ul>
<p>ending up with something of shape <code>(4,64,5,5,5)</code></p>
<p>Reading the documentation for <code>tf.tile</code>, I still don't understand what is it exactly doing in this case. Am I replicating the new dimension for 5 times? And if yes, what is exactly placed in the new dimension by tensorflow? What am I exactly replicating?</p>
",tf.tile,tf.tile,2020-11-10 21:06:32,14824108,596,https://stackoverflow.com/questions/70363340,Documentation Ambiguity
70328363,Extra dimension to MaxPool1D layer from Conv1D layer,"<p>I'm very new to Tensorflow (this is my first project using it), and I don't really understand how input shapes work. I am trying to train a CNN-LSTM on a set of financial time series data.</p>
<p>For my use case, I have a <code>tf.keras.data.DataLoader</code> object which is meant to serve batches of training data to the model.</p>
<p>One training instance corresponds to the price history over the last 30 days, and hence should have shape <code>(30,)</code>.</p>
<p>running the following code:</p>
<pre><code>for x, y in train_ds:
    print(x, y)
    print(x.shape)
    break
</code></pre>
<p>I get that <code>x.shape</code> is <code>(4, 30)</code>, where the <code>Dataset</code> object I have defined serves training instances in batches of 4.</p>
<p>Here is my code:</p>
<pre><code># driver code for experiments
import keras
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from keras import layers

WIDTH = 30
BATCH_SIZE = 4

# load datasets (prepended with 'n' for 'normalized' )

nXtrain = np.load('cad_90s_nXtrain.npy')
nytrain = np.load('cad_90s_nytrain.npy')
nXval = np.load('cad_90s_nXval.npy')
nyval = np.load('cad_90s_nyval.npy')
nXtest = np.load('cad_90s_nXtest.npy')
nytest = np.load('cad_90s_nytest.npy')

# instantiate tensorflow Datasets
train_ds = tf.data.Dataset.from_tensor_slices((nXtrain, nytrain)).batch(BATCH_SIZE)
val_ds = tf.data.Dataset.from_tensor_slices((nXval, nyval)).batch(BATCH_SIZE)
test_ds = tf.data.Dataset.from_tensor_slices((nXtest, nytest)).batch(BATCH_SIZE)


input_shape = (BATCH_SIZE, WIDTH, 1 )

testnet = tf.keras.Sequential([
    layers.InputLayer(input_shape=input_shape),
    layers.Conv1D(filters=32,
                  kernel_size=3,
                  activation='tanh',
                  padding='same',
                  strides=1),
    layers.MaxPool1D(pool_size=2,
                     padding='same'),
    layers.ReLU(),
    layers.LSTM(units=64, dropout=0.2, activation='tanh'),
    layers.Dense(units=1)
])

testnet.build()
testnet.summary()
</code></pre>
<p>with accompanying error message:</p>
<pre><code>ValueError: Input 0 of layer &quot;max_pooling1d&quot; is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 4, 30, 32)

</code></pre>
<p>I don't understand what's going on--why is there an extra dimension coming out of the <code>Conv1D</code> layer? I mean, should the output of 1-D convolution not simply be
<code>(BATCH_SIZE, WIDTH, 32)</code> (padding was set to <code>'same'</code>)?</p>
<p>I apologize if this is addressed in the documentation, but I have been looking everywhere for an answer and I can't seem to fix this problem. I would really appreciate some help here.</p>
<p>Thanks!</p>
",- , -,2020-11-10 12:44:46,8163401,289,https://stackoverflow.com/questions/70328363,Lack of Alternative Solutions/Documentation
69792031,Explanation of tf.keras.layers.CategoryEncoding output_mode='multi_hot' behavior,"<h1>Question</h1>
<p>Please help understand the definition of <strong>multi hot encoding</strong> of tf.keras.layers.CategoryEncoding and the behavior of <code>output_mode='multi_hot'</code>.</p>
<h1>Background</h1>
<p>According to <a href=""https://stats.stackexchange.com/a/467672"">What exactly is multi-hot encoding and how is it different from one-hot?</a>:</p>
<blockquote>
<p>If you would use multi-hot-encoding you would first label-encode your classes, thus having only a single number which represents the presence of a class (e.g. 1 for 'dog') and then convert the numerical labels to binary vectors of size log2(5)=3.<br />
Examples:</p>
<pre><code>'cat'  = [0,0,0]  
'dog'  = [0,0,1]  
'fish' = [0,1,0]  
'bird' = [0,1,1]  
'ant'  = [1,0,0]   
</code></pre>
</blockquote>
<h1>Behaviour of <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding"" rel=""nofollow noreferrer"">tf.keras.layers.CategoryEncoding</a></h1>
<p>The document says <code>num_tokens</code> is the total number of tokens the layer should support.</p>
<blockquote>
<h3>args</h3>
<h4>num_tokens</h4>
<p>The total number of tokens the layer should support. All inputs to the layer must integers in the range 0 &lt;= value &lt; num_tokens, or an error will be thrown.</p>
<h4>output_mode</h4>
<ul>
<li>&quot;one_hot&quot;: Encodes each individual element in the input into an array of num_tokens size, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output.</li>
<li>&quot;multi_hot&quot;: Encodes each sample in the input into <strong>a single array of num_tokens size, containing a 1 for each vocabulary term present in the sample</strong>. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens).</li>
</ul>
</blockquote>
<p>According to the definitions of multi hot encoding above, I expected <code>tf.keras.layers.CategoryEncoding(num_tokens=5, output_mode=&quot;multi_hot&quot;)</code> encodes 5 tokens into an array of size 3.</p>
<p>However, the document says &quot;multi_hot&quot; encodes each sample into <strong>a single array of num_tokens size</strong>, containing a 1 for each vocabulary term present in the sample, and behaves as such.</p>
<pre><code>dataset = tf.data.Dataset.from_tensor_slices(tf.constant(['cat', 'dog', 'fish', 'bird']))

lookup = tf.keras.layers.StringLookup(max_tokens=5, oov_token='[UNK]')
lookup.adapt(dataset)
lookup.get_vocabulary()
---
['[UNK]', 'fish', 'dog', 'cat', 'bird']

mhe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=&quot;multi_hot&quot;)
print(f&quot;cat: {mhe(lookup(tf.constant('cat'))).numpy()}&quot;)
print(f&quot;dog: {mhe(lookup(tf.constant('dog'))).numpy()}&quot;)
---
cat: [0. 0. 0. 1. 0.]
dog: [0. 0. 1. 0. 0.]
</code></pre>
<p>Which has no difference from One Hot Encoding.</p>
<pre><code>ohe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=&quot;one_hot&quot;)
print(f&quot;cat: {ohe(lookup(tf.constant('cat'))).numpy()}&quot;)
print(f&quot;dog: {ohe(lookup(tf.constant('dog'))).numpy()}&quot;)
---
cat: [0. 0. 0. 1. 0.]
dog: [0. 0. 1. 0. 0.]
</code></pre>
<p>For multi value inputs, multi_hot only handles the first value.</p>
<pre><code>print(ohe(lookup(tf.constant(['cat', 'dog']))).numpy())
---
[[0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0.]]

print(mhe(lookup(tf.constant(['cat', 'dog']))).numpy())
---
[0. 0. 1. 1. 0.]
</code></pre>
<p>To handle multiple inputs, need to be 2D array.</p>
<pre><code>print(mhe(lookup(tf.constant([['cat'], ['dog']]))).numpy())
---
[[0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0.]]
</code></pre>
<p>Apparently the definition of <strong>multi hot encoding</strong> of <code>tf.keras.layers.CategoryEncoding</code> is not the same with the one in <a href=""https://stats.stackexchange.com/a/467672"">What exactly is multi-hot encoding and how is it different from one-hot?</a>.</p>
<h1>Related</h1>
<ul>
<li><a href=""https://github.com/tensorflow/tensorflow/issues/52892"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/52892</a></li>
</ul>
",tf.keras.layers.CategoryEncoding,tf.keras.layers.CategoryEncoding,2020-10-14 15:04:24,4281353,20088,https://stackoverflow.com/questions/69792031,Lack of Alternative Solutions/Documentation
69672777,Compute Hessian of lossfunction in Tensorflow,"<p>I would like to compute the hessian of a loss function of a neural network in Tensorflow with respect to all the parameters (or trainable variables). By modifying the example code from the Tensorflow documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/GradientTape</a>) I managed to compute the hessian w.r.t the weight matrix for the first layer (if I'm not mistaken):</p>
<pre><code>with tf.GradientTape(persistent=True) as tape:
    loss = tf.reduce_mean(model(x,training=True)**2)
    g = tape.gradient(loss,model.trainable_variables[0]) 
    h=tape.jacobian(g,model.trainable_variables[0])
</code></pre>
<p>If I try to compute it w.r.t model.trainable_variables instead the tape.jacobian complains that 'list object has no attribute shape'. I instead tried to flatten the model.trainable_variables and compute it w.r.t the flattened vector:</p>
<pre><code>with tf.GradientTape(persistent=True) as tape:
    loss = tf.reduce_mean(model(x,training=True)**2)
    source = tf.concat([tf.reshape(x,[-1]) for x in model.trainable_variables],axis=0)
    g = tape.gradient(loss,source) 
    h=tape.jacobian(g,source)
   
</code></pre>
<p>The problem now is that g is empty (NoneType) for some reason. I noticed that source is tf.Tensor-type but model.trainable_variables[0] was of type tf.ResourceVariable so I tried changing this by declaring source as</p>
<pre><code>source = resource_variable_ops.ResourceVariable(tf.concat([tf.reshape(x,[-1]) for x in model.trainable_variables],axis=0))
</code></pre>
<p>This didn't change anything though, so I'm guessing that this is not the issue. I also thought that the problem might be that the source-variable is not watched, but it seems that it is set to trainable and even if i do tape.watch(source), g is still empty.</p>
<p>Does anybody know how I can solve this?</p>
",tf.GradientTape,tf.GradientTape,2020-10-10 19:57:29,9163968,211,https://stackoverflow.com/questions/69672777,Documentation Replication on Other Examples
69587392,How to apply map() when working with a batched Dataset?,"<p>I am creating a timeseries Dataset using <code>tf.keras.utils.timeseries_dataset_from_array</code>.
According to the docs, it returns a <code>tf.data.Dataset</code> instance.
I also pass the batch size argument when calling the <code>timeseries_dataset_from_array</code> function, so my dataset is a BatchDataset.
I am using map on this batched Dataset (<code>ds</code>), passing <code>my_fun</code>.
Data in the code below is a pandas dataframe containing continuous timesteps.</p>
<p>What does the <code>my_fun</code> function expect as input parameters - aka what does it apply on each iteration? Whole batches of shape (samples, sequence_length, features) or a single element of shape (None, sequence_length, features)?</p>
<p>I am confused because when I print the single argument that I define in my <code>my_fun</code> function, it yields a shape of (None, None, features), but I cannot inspect it further...</p>
<p>My code is inspired from the TF tutorial (see split_window function)
<a href=""https://www.tensorflow.org/tutorials/structured_data/time_series"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/structured_data/time_series</a></p>
<pre class=""lang-py prettyprint-override""><code>def split_window(self, features):
   inputs = features[:, self.input_slice, :]
   labels = features[:, self.labels_slice, :]
   if self.label_columns is not None:
     labels = tf.stack(
         [labels[:, :, self.column_indices[name]] for name in 
          self.label_columns],
             axis=-1)

   # Slicing doesn't preserve static shape information, so set the shapes
   # manually. This way the `tf.data.Datasets` are easier to inspect.
   inputs.set_shape([None, self.input_width, None])
   labels.set_shape([None, self.label_width, None])

   return inputs, labels

data = np.array(data, dtype=np.float32)
ds = timeseries_dataset_from_array(
        data=data,
        targets=None,
        sequence_length=24,
        sequence_stride=1,
        shuffle=True,
        batch_size=32)
 
ds = ds.map(split_window)
</code></pre>
",tf.data.Dataset,tf.data.Dataset,2020-10-02 13:54:02,17161135,121,https://stackoverflow.com/questions/69587392,Documentation Replication on Other Examples
69458522,What does tf.squeeze does to the audio and how can I load an mp3?,"<p>I'm using TensorFlow and I would like to be able to load audio and generate a spectrogram from it. I have little knowledge of how audio internally works.
Currently, this is the code I'm using:</p>
<pre><code>import pathlib
import tensorflow as tf
import tensorflow_io as tfio
import matplotlib.pyplot as plt

from IPython.display import Audio

data_dir = pathlib.Path('recordings')
sample_file = data_dir/'testA.mp3'
audio = tfio.audio.AudioIOTensor(str(sample_file))

# remove last dimension
audio_slice = audio[100:]
audio_tensor = tf.squeeze(audio_slice, axis=[-1])
#audio_tensor = audio.to_tensor()
tensor = tf.cast(audio_tensor, tf.float32) / 32768.0

print(&quot;Audio Tensor: &quot; + str(tensor))

plt.figure()
plt.plot(tensor.numpy())
plt.show()

# Convert to spectrogram
spectrogram = tfio.audio.spectrogram(tensor, nfft=512, window=512, stride=256)
    
plt.figure()
plt.imshow(tf.math.log(spectrogram).numpy())
plt.show()
</code></pre>
<p>I have been reading the documentation and in order to create a tensor I need to either use the tf.squeeze method or audio.to_tensor(). I have no clue what the tf.squeeze method does, but when I use it I get the error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 2 [Op:Squeeze]
</code></pre>
<p>If I instead use the method audio.to_tensor(), I'm unable to display the created spectrogram on the plt and instead I get the following error:</p>
<pre><code>TypeError: Invalid shape (28224, 1, 257) for image data
</code></pre>
",tf.squeeze,tf.squeeze,2020-09-27 22:05:48,4999534,121,https://stackoverflow.com/questions/69458522,Documentation Replication on Other Examples
68878231,tf.gradients() vs tf.gradientTape.gradient() in graph mode,"<p>I had a question regarding the behavior of tf.gradients() as opposed tf.gradientTape.gradient() in graph mode.</p>
<p>Given a differentiable function y = f(x), where x and y are each single tensorflow tensors, is there any difference between the behavior of tf.gradient(y, x) vs tape.gradient(y, x) where tape is an instance of tf.gradientTape (assuming the use of graph mode) ?</p>
<p>Not sure why tensorflow has two different gradient methods which can be used with graph mode - maybe there are some subtle differences in the implementations? Ive looked at the documentation for gradientTape and tf.gradients but its not clear whether there is any difference between the behavior of these methods for a single (x, y) pair, or whether its just that tf.gradients() can be used in this case for a speedup when using graph mode.</p>
<p>Thank you so much for your help!</p>
",tf.gradients,tf.gradients,2020-09-18 15:52:50,16569549,51,https://stackoverflow.com/questions/68878231,Documentation Replication on Other Examples
68354367,Getting an error when using tf.keras.metrics.Mean in functional Keras API,"<p>I'm trying to add a Mean metric to a Keras functional model (Tensorflow 2.5), and am getting the following error:</p>
<pre><code>ValueError: Expected a symbolic Tensor for the metric value, received: tf.Tensor(0.0, shape=(), dtype=float32)
</code></pre>
<p>Here is the code:</p>
<pre><code>x = [1, 2, 3, 4, 5, 6, 7, 8]
y = [5 + i * 3 for i in x]
a = Input(shape=(1,))
output = Dense(1)(a)
model = Model(inputs=a,outputs=output)
model.add_metric(tf.keras.metrics.Mean()(output))
model.compile(loss='mse')
model.fit(x=x, y=y, epochs=100)
</code></pre>
<p>If I remove the following line (from which the exception is thrown):</p>
<pre><code>model.add_metric(tf.keras.metrics.Mean()(output))
</code></pre>
<p>the code works as expected.
<br><br>I Tried disabling eager execution, but I get the following error instead:</p>
<pre><code>ValueError: Using the result of calling a `Metric` object when calling `add_metric` on a Functional Model is not supported. Please pass the Tensor to monitor directly.
</code></pre>
<p>The above usage was pretty much copied from the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Mean"" rel=""nofollow noreferrer"">tf.keras.metrics.Mean</a> documentation (see <em>Usage with compile() API</em>)</p>
",tf.keras.metrics.Mean,tf.keras.metrics.Mean,2020-09-03 18:59:47,6133787,361,https://stackoverflow.com/questions/68354367,Lack of Alternative Solutions/Documentation
67947583,"Defining a callable ""loss"" function","<p>I am trying to optimize a loss function (defined using evidence lower bound) with <code>tf.train.AdamOptimizer.minimize()</code> on Tensorflow version <code>1.15.2</code> with eager execution enabled. I tried the following:</p>
<pre><code>learning_rate = 0.01
optim = tf.train.AdamOptimizer(learning_rate=learning_rate)
train_op = optim.minimize(loss)
</code></pre>
<p>and got the following : <code>RuntimeError: &quot;loss&quot; passed to Optimizer.compute_gradients should be a function when eager execution is enabled.</code></p>
<p>This works fine if I disable eager execution but since I need to save a tensorflow variable as a <code>numpy</code> array so I need eager execution enabled. The documentation mentions that when eager execution is enabled, the loss must be a <strong>callable</strong>. So the loss function should be defined in a way that it takes no inputs but gives out loss. I am not exactly sure how do I achieve such a thing.</p>
<p>I tried <code>train_op = optim.minimize(lambda: loss)</code> but got <code>ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [] and loss &lt;function &lt;lambda&gt; at 0x7f3c67a93b00&gt;</code></p>
",tf.train.AdamOptimizer.minimize,tf.compat.v1.train.AdamOptimizer.minimize,2020-08-19 8:27:13,6639856,332,https://stackoverflow.com/questions/67947583,Documentation Replication on Other Examples
67759756,"How do I use ""text_dataset_from_directory"" to do binary text classification from tf.dataset object?","<p>Sorry, I am still relatively new to text classification and Tensorflow, so this may look like a very dumb question.</p>
<p>I have the song lyrics of two different singers. What I am trying to achieve is to build a binary text classification model to predict whether a song fits to the style of singer A or singer B more.
I have the training data (the lyrics text files) of both classes in sub-directories. The directory structure is similar to,</p>
<pre><code>Classification/
...Singer_A/
......A_song_1.txt
......A_song_2.txt
...Singer_B/
......B_song_1.txt
......B_song_2.txt
</code></pre>
<p>And from what I read on the Tensorflow documentation, I could easily construct a dataset by using the
<code>text_dataset_from_directory</code> method. So something like,</p>
<pre><code>dataset = text_dataset_from_directory(
    'Classification', labels='inferred', label_mode='int',
    batch_size=32
)
</code></pre>
<p>However, I don't know how I could go on from there. I would suppose that the created <code>tf.data.Dataset</code> object would still need Tokenization in the texts component, and the tokenized text would then need padding and embedding before feeding it into a logistic model. But I don't know how to further process it in the <code>tf.data.Dataset</code> object.</p>
<p>I saw <a href=""https://www.tensorflow.org/text/guide/word_embeddings"" rel=""nofollow noreferrer"">Tensorflow's Text Embedding Tutorial</a>, but don't really see how it could be changed to become a binary model.</p>
",tf.data.Dataset,tf.data.Dataset,2020-08-03 11:24:26,10230473,86,https://stackoverflow.com/questions/67759756,Documentation Replicability
67563475,How to convert a tensorflow model and load as tfds,"<p>I need help converting my dataset from how I usually make it using
<code>tf.keras.preprocessing.image_dataset_from_directory</code>
To be used to replace this in an example</p>
<pre><code>dataset, info = tfds.load(name='mnist', split=split, with_info=True,

as_supervised=True, try_gcs=True)
</code></pre>
<p>How can I do so? I am unable to find related documentation so if you can link that it would be amazing.
Thanks</p>
<p>This is how the dataset is used in the example</p>
<pre><code>  split = 'train' if is_training else 'test'
  dataset, info = tfds.load(name='mnist', split=split, with_info=True,
                            as_supervised=True, try_gcs=True)


  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255.0

    return image, label

  dataset = dataset.map(scale)
</code></pre>
",tf.keras.preprocessing.image_dataset_from_directory,tf.keras.preprocessing.image_dataset_from_directory,2020-07-21 12:48:02,15760012,3,https://stackoverflow.com/questions/67563475,Documentation Ambiguity
67523944,"Tensorflow2 - Use ""tf.data.experimental.make_csv_dataset"" with ""tf.keras.preprocessing.timeseries_dataset_from_array""","<p>I am trying to get TensorFlow to read +100 CSV files that <em><strong>don't</strong></em> fit in memory (+1GB size each). The files contain time series data (EEG signals), with the labels in the first column. From the TensorFlow documentation it seems like I should be able to use the <em>tf.data</em> API to load my data off-disk.</p>
<p>For the sake of simplicity and reproducibility, let's consider the following &quot;<em>sample_data.csv</em>&quot; dataset:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Label</th>
<th>Feature 1</th>
<th>Feature 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Apple</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>Banana</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>Coconut</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>Durian</td>
<td>7</td>
<td>8</td>
</tr>
</tbody>
</table>
</div>
<p>I've tried using <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset"" rel=""nofollow noreferrer"">tf.data.experimental.make_csv_dataset</a> to load the CSV files into <em>tf.data.Dataset</em> objects, and then <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array"" rel=""nofollow noreferrer"">tf.keras.preprocessing.timeseries_dataset_from_array</a> to process the data into sliding windows with overlap. For the dataset above, I would do:</p>
<pre><code>import tensorflow as tf

input_data = tf.data.experimental.make_csv_dataset(
    'sample_data.csv',
    batch_size=1,
    column_names=['Label', 'Feature 1', 'Feature 2']
    label_name='Label',
    num_epochs=1,
    shuffle=False
)
</code></pre>
<p>Which we can check works correctly by looking at the output from <code>list(input_data.as_numpy_iterator())</code>. We can then feed <code>input_data</code> to the next function:</p>
<pre><code>my_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(
    input_data,
    targets=None,
    sequence_length=3,
    sequence_stride=2,
    sampling_rate=1,  
    batch_size=1,
    shuffle=False
)
</code></pre>
<p>Which unfortunately <strong>throws this error</strong>:</p>
<blockquote>
<p>TypeError: dataset length is unknown.</p>
</blockquote>
<p>I also tried using <code>my_dataset = input_data.window(3, shift=2)</code> (see the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"" rel=""nofollow noreferrer"">tf.data.Dataset.window</a> documentation) and it didn't throw an error, but
it seems to be returning an <strong>empty dataset</strong>? See &quot;<em>_VariantDataset shapes: (None,)</em>&quot; in the output:</p>
<pre><code>list(input_data.window(3, shift=2))

[344]:
[(OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;),
 (OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;),
 (OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;)]
</code></pre>
<p>If I load the &quot;<em>sample_data.csv</em>&quot; in memory using pandas and then feed the <em>timeseries_dataset_from_array</em> function a numpy array instead, it works correctly.</p>
<p>Any ideas on how to solve this? <strong>What's the best method to input overlapping windows from off-memory time-series data into TensorFlow</strong>?</p>
<p>Thank you!</p>
",tf.data,tf.data,2020-07-09 15:58:29,6395699,13,https://stackoverflow.com/questions/67523944,Documentation Replication on Other Examples
67344068,TensorFlow 2 - does NumPy numerical values and arrays cause new graphs for TF Function?,"<p>Does &quot;<strong>numerical Python values</strong>&quot; stated in the <a href=""https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/"" rel=""nofollow noreferrer"">Hands on ML 2</a> include NumPy int, float, and array? Do we need to explicitly create a TF Tensor or a TF DataSet from a NumPy construct as the argument of a TF Function?</p>
<p><a href=""https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/"" rel=""nofollow noreferrer"">Hands on ML 2</a> Chapter 12 Auto Graph and Tracing:</p>
<blockquote>
<p>By default, a TF Function generates a new graph for every unique set
of intput shapes and data types and caches it for subsequent calls.
... However <em><strong>this is only true for tensor arguments</strong></em>: if you pass
numerical Python values to a TF Function, a new graph will be
generated for every distinct value. ...</p>
<p>if you pass <strong>numerical Python values</strong> to a TF function, a new graph will
be generated for every distinct values. If you call a TF function many
times with different numerical Python values, then many graphs will be
generated, slowing down your program and using up a lot of RAM (you
must delete the TF Function to release it).</p>
<p>Python values should be reserved for arguments that will have few
unique values, such as hyper parameters like the number of neurons per
layer. This allows TensorFlow to better optimize each variant fo yor
model.</p>
</blockquote>
<p>The 3rd rule stated in the TensorFlow document <a href=""https://www.tensorflow.org/guide/function#rules_of_tracing"" rel=""nofollow noreferrer"">Rules of tracing</a> corresponds with Python int, float, boolean, str , etc that will cause a new graph part. But not sure if the 5th rule (all other Python types) applies to NumPy constructs.</p>
<blockquote>
<p>A Function determines whether to reuse a traced ConcreteFunction by computing a cache key from an input's args and kwargs.  A cache key is a key that identifies a ConcreteFunction based on the
input args and kwargs of the Function call, according to the following
rules (which may change):</p>
<ol>
<li><p>The key generated for a tf.Tensor is its shape and dtype.</p>
</li>
<li><p>The key generated for a tf.Variable is a unique variable id.</p>
</li>
<li><p>The key generated for a Python primitive (like int, float, str) is its value.</p>
</li>
<li><p>The key generated for nested dicts, lists, tuples, namedtuples, and attrs is the flattened tuple of leaf-keys (see nest.flatten). (As a
result of this flattening, calling a concrete function with a
different nesting structure than the one used during tracing will
result in a TypeError).</p>
</li>
<li><p>For all other Python types the key is unique to the object. This way a
function or method is traced independently for each instance it is
called with.</p>
</li>
</ol>
</blockquote>
<p>I suppose the fact <a href=""https://www.tensorflow.org/api_docs/python/tf/numpy_function"" rel=""nofollow noreferrer"">tf.numpy_function</a> exists suggests that the TF Function tracing will generate a new graph, but need a definite confirmation.</p>
",tf.numpy_function,tf.numpy_function,2020-07-06 12:02:32,4281353,20088,https://stackoverflow.com/questions/67344068,Documentation Replication on Other Examples
67211152,Tensorlow - please decipher what the tf.where document says,"<p>Please decipher what the <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer"">tf.where</a> documentation says about what it does when both x and y are provided.</p>
<p>I suppose it tries to say it will produce a result by:</p>
<ol>
<li>Broadcast y to the result shape.</li>
<li>Broadcast x to the result shape.</li>
<li>Update y with x elements where the condition is true.</li>
</ol>
<p>Is this correct?</p>
<blockquote>
<p>If x and y are provided (both have non-None values):
tf.where will choose an output shape from the shapes of condition, x, and y that all three shapes are broadcastable to.</p>
<p><strong>Returns</strong>
If x and y are provided: A Tensor with the same type as x and y, and shape that is broadcast from condition, x, and y. Otherwise, a Tensor with shape (num_true, dim_size(condition)).</p>
</blockquote>
",tf.where,tf.where,2020-06-23 8:20:52,4281353,20088,https://stackoverflow.com/questions/67211152,Documentation Replicability
67066760,Configuring labels in TensorFlow BinaryCrossentropy loss function,"<p>I want to compute cross-entropy loss using <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy"" rel=""nofollow noreferrer"">tf.keras.losses.BinaryCrossentropy</a>. The documentation has the following example, and specifies that true labels and predicted labels should have the shape <code>[batch_size]</code>:</p>
<pre><code>y_true = [[0., 1.], [0., 0.]]
y_pred = [[0.6, 0.4], [0.4, 0.6]]

bce = tf.keras.losses.BinaryCrossentropy()
bce(y_true, y_pred).numpy()
</code></pre>
<p>From the example, it is inferred that each sample's label should be formatted as [probability of belonging to Class 0, probability of belonging to Class 1]. Is it correct? If it is, why <code>y_true[1]</code> probabilities do not add up to 1?</p>
",tf.keras.losses.BinaryCrossentropy,tf.keras.losses.BinaryCrossentropy,2020-06-18 12:29:22,5425172,4449,https://stackoverflow.com/questions/67066760,Documentation Ambiguity
66916390,Error when adapting batch size in tf.keras.utils.Sequence,"<p>I study using tf.keras.utils.Sequence on Tensorflow 2.4.1. I used the example code in Sequence in API document (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence</a>) and finetuned by adding <code>on_epoch_end</code> function to adaptively change the <code>batch_size</code> value on every epoch.</p>
<pre><code>from skimage.io import imread
from skimage.transform import resize
import numpy as np
import random
import math

# Here, `x_set` is list of path to the images
# and `y_set` are the associated classes.

class CIFAR10Sequence(tensorflow.keras.utils.Sequence):

    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def on_epoch_end(self):
        print(self.batch_size)
        self.batch_size = int(random.randint(10, 100))

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        return np.array([
            resize(imread(file_name), (200, 200))
               for file_name in batch_x]), np.array(batch_y)
</code></pre>
<p>However, in practice, the number of steps per epoch, which expected to change depending on the number of batches, remains unchanged. In fact, Tensorflow returns a WARNING, informing that they run out of data, and stop the training immediately. This problem happens when the initialize <code>batch_size</code> is smaller than the current <code>self.batch_size</code>.</p>
<pre><code>WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches
</code></pre>
<p>Here is my guess, Tensorflow did adapt the batch size after every epoch, but somehow the model was still keeping the initial value. This problem never happened in Keras version 1. So far, I have no clue on solving this problem.
Edit 1: The number of training data is much larger than the number of batches.</p>
",tf.keras.utils.Sequence,tf.keras.utils.Sequence,2020-06-15 19:05:37,5169676,69,https://stackoverflow.com/questions/66916390,Documentation Replicability
66546321,Proper way to input a scalar into a Tensorflow 2 model,"<p>In my Tensorflow 2 model, I want my batch size to be parametric, such that I can build tensors which have appropriate batch size dynamically. I have the following code:</p>
<pre><code>batch_size_param = 128

tf_batch_size = tf.keras.Input(shape=(), name=&quot;tf_batch_size&quot;, dtype=tf.int32)
batch_indices = tf.range(0, tf_batch_size, 1)

md = tf.keras.Model(inputs={&quot;tf_batch_size&quot;: tf_batch_size}, outputs=[batch_indices])
res = md(inputs={&quot;tf_batch_size&quot;: batch_size_param})
</code></pre>
<p>The code throws an error in <code>tf.range</code>:</p>
<pre><code>ValueError: Shape must be rank 0 but is rank 1
 for 'limit' for '{{node Range}} = Range[Tidx=DT_INT32](Range/start, tf_batch_size, Range/delta)' with input shapes: [], [?], []
</code></pre>
<p>I think the problem is with the fact that <code>tf.keras.Input</code> automatically tries to expand the input array at the first dimension, since it expects the partial shape of the input without the batch size and will attach the batch size according to the shape of the input array, which in my case a scalar. I can just feed the scalar value as a constant integer into <code>tf.range</code> but this time, I won't be able to change it after the model graph has been compiled.</p>
<p>Interestingly, I failed to find a proper way to input only a scalar into a TF-2 model even though I checked the documentation, too. So, what would be the best way to handle such a case?</p>
",tf.keras.Input,tf.keras.Input,2020-06-08 14:39:09,1538049,3591,https://stackoverflow.com/questions/66546321,Documentation Replication on Other Examples
66049816,Custom layer in sequential model tensorflow,"<p>I'm trying to create a custom layer for my model, which can be used the classic Dense layer of Keras. Here my custom layer:</p>
<pre><code>class MyDenseLayer(tf.keras.layers.Layer):
    def __init__(self, num_outputs):
        super(MyDenseLayer, self).__init__()
        self.num_outputs = num_outputs
    def build(self, input_shape):
        self.kernel = self.add_weight(&quot;kernel&quot;, 
                                      shape=[int(input_shape[-1]),
                                      self.num_outputs])
    def call(self, input):
        return tf.matmul(input, self.kernel)
</code></pre>
<p>It does not do anything 'custom' for now.</p>
<p>But when I add it to my model</p>
<pre><code>def build_model():
    model = keras.Sequential([
        MyDenseLayer(10)(normed_x_train),
        layers.Activation(tf.nn.relu),
        layers.Dense(1, activation=tf.nn.relu)
        ])
    return model
</code></pre>
<p>I get this:</p>
<pre><code>The added layer must be an instance of class Layer. Found: tf.Tensor(
[....])
</code></pre>
<p>Because probably I'm creating directly the object of class Custom Layer. But I do not find in the tf documentation how to add other properties to make it work as a normal layer, i.e. as something like <code>layers.Dense(100, activation=tf.nn.relu)</code></p>
<p>Is there a way to make it work like that ?</p>
",tf.keras.layers.Layer,tf.keras.layers.Layer,2020-05-18 21:11:02,12338521,181,https://stackoverflow.com/questions/66049816,Lack of Alternative Solutions/Documentation
66038861,Why are both branches in tf.cond being executed? And why does tf.while_loop finish the loop even though the condition still true?,"<p>I am using keras for a while now, but usually I don't have to use customized layers or perform some more complex flow control, so I'm struggling trying to understand somethings.</p>
<p>I am modeling a neural network with a customized layer on the top. This customized layer calls another function (<code>search_sigma</code>)  and inside this function I execute <code>tf.while_loop</code> and inside of <code>tf.while_loop</code> I execute <code>tf.cond</code>.</p>
<p>I cannot understand why the conditions are not working.</p>
<ul>
<li><code>tf.while_loop</code> stops even though the condition (<code>l1</code>) still true</li>
<li><code>tf.cond executes</code> both <code>f1</code> and <code>f2</code> (callables <code>true_fn</code> and <code>false_fn</code>)</li>
</ul>
<p>Could someone help me understand what I am missing?</p>
<p>I already tried to change both tf.cond and tf.while_loop conditions for true tensors, just to see what would happen. The behavior (exactly same errors) remained the same.</p>
<p>I also tried to write this code without implementing a class (using just functions). Nothing changed.</p>
<p>I tried to find solutions looking at tensorflow documentation, other stack overflow doubts and websites talking about tf.while_loop and tf.cond.</p>
<p>I left some <code>print()</code>s in the body of the code to try to track what was happening.</p>
<pre><code>class find_sigma:
    
    def __init__ (self, t_inputs,  inputs,  expected_perp=10. ):       
        self.sigma, self.cluster = t_inputs
        self.inputs = inputs
        self.expected_perp = expected_perp
        self.min_sigma=tf.constant([0.01],tf.float32)
        self.max_sigma=tf.constant([50.],tf.float32)
 

    def search_sigma(self):

        
        def cond(s,sigma_not_found): return sigma_not_found


        def body(s,sigma_not_found):   

            print('loop')
            pi = K.exp( - K.sum( (K.expand_dims(self.inputs, axis=1) - self.cluster)**2, axis=2  )/(2*s**2) )        
            pi = pi / K.sum(pi)
            MACHINE_EPSILON = np.finfo(np.double).eps
            pi = K.maximum(pi, MACHINE_EPSILON)
            H = - K.sum ( pi*(K.log(pi)/K.log(2.)) , axis=0 )
            perp = 2**H

            print('0')

            l1 = tf.logical_and (tf.less(perp , self.expected_perp), tf.less(0.01, self.max_sigma-s))
            l2 = tf.logical_and (tf.less(  self.expected_perp , perp) , tf.less(0.01, s-self.min_sigma) )
    
            def f1():
                print('f1')
                self.min_sigma = s 
                s2 = (s+self.max_sigma)/2 
                return  [s2, tf.constant([True])]
                

            def f2(l2): 
                tf.cond( l2, true_fn=f3 , false_fn = f4)

            def f3(): 
                print('f3')
                self.max_sigma = s 
                s2 = (s+self.min_sigma)/2
                return [s2, tf.constant([True])]

            def f4(): 
                print('f4')
                return [s, tf.constant([False])]
            
            output = tf.cond( l1, f1 ,  f4 ) #colocar f2 no lugar de f4

            s, sigma_not_found = output
            
            print('sigma_not_found = ',sigma_not_found)
            return [s,sigma_not_found]

        print('01')

        sigma_not_found = tf.constant([True])

        new_sigma,sigma_not_found=sigma_not_found = tf.while_loop(
            cond , body, loop_vars=[self.sigma,sigma_not_found]
        )

        print('saiu')
        
        print(new_sigma)

        return new_sigma
</code></pre>
<p>The piece of code that calls the above code is:</p>
<pre><code>self.sigma = tf.map_fn(fn=lambda t: find_sigma(t,  inputs).search_sigma() , elems=(self.sigma,self.clusters), dtype=tf.float32)
</code></pre>
<p>'inputs' is a <code>(None, 10)</code> size tensor</p>
<p>'self.sigma' is a <code>(10,)</code> size tensor</p>
<p>'self.clusters' is a <code>(N, 10)</code> size tensor</p>
",tf.while_loop,tf.while_loop,2020-05-15 22:22:30,15141021,1,https://stackoverflow.com/questions/66038861,Inadequate Examples
66030439,TensorFlow profiler using tf.profiler.experimental.client.trace gives empty trace data,"<p>I'm unable to collect trace data using <code>tf.profiler.experimental.client.trace</code> Please can someone help? I'm following the (CPU/GPU) example usage here <a href=""https://www.tensorflow.org/api_docs/python/tf/profiler/experimental/client/trace"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/profiler/experimental/client/trace</a> which looks simple enough.</p>
<p>I have a very simple model, and I'm able to collect trace data from it using <code>tf.profiler.experimental.start</code> and <code>tf.profiler.experimental.stop</code>.</p>
<p>But <code>tf.profiler.experimental.client.trace</code> gives me empty trace data.</p>
<p>My code is as follows:</p>
<pre><code>import tensorflow as tf
import numpy as np
                                                                                                    
def mnist_dataset(batch_size):
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()                                              
    x_train = x_train / np.float32(255)
    y_train = y_train.astype(np.int64)
    train_dataset = tf.data.Dataset.from_tensor_slices(
        (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)
    return train_dataset

batch_size = 64
dataset = mnist_dataset(batch_size)

model = tf.keras.Sequential([
    tf.keras.Input(shape=(28, 28)),
    tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
    metrics=['accuracy'])
                                                                                           
#tf.profiler.experimental.start('./logs/tb_log')                                                                        
tf.profiler.experimental.server.start(6009)

model.fit(dataset, epochs=10, steps_per_epoch=70)

tf.profiler.experimental.client.trace('grpc://localhost:6009', './logs/tbc_log', 20000)
#tf.profiler.experimental.stop()         
</code></pre>
<p>The code runs through the epochs, and then outputs</p>
<pre><code>2021-02-02 17:49:44.943933: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288184943887718 [2021-02-02T17:49:44.943887718+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 2
2021-02-02 17:49:44.944037: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:49:44.944197: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:49:44.944316: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:49:44.944340: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:49:44.946274: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:49:44.947547: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:49:44.946338176+00:00) for the scheduled start (2021-02-02T17:49:44.943887718+00:00) and will start immediately.
2021-02-02 17:49:44.947582: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:49:44.947660: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 2 GPUs
2021-02-02 17:49:44.949656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.11.0
2021-02-02 17:50:08.435260: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-02-02 17:50:08.435591: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-02-02 17:50:08.635192: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. 
2021-02-02 17:50:08.648616: I tensorflow/core/profiler/rpc/profiler_service_impl.cc:67] Collecting XSpace to repository: ./logs/tbc_log/plugins/profile/2021_02_02_17_49_44/localhost_6009.xplane.pb
2021-02-02 17:50:08.650309: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-02-02 17:50:08.650676: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
No trace event is collected. Automatically retrying.

2021-02-02 17:50:08.651046: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288208651017638 [2021-02-02T17:50:08.651017638+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 1
2021-02-02 17:50:08.651123: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:50:08.651274: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:50:08.651391: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:50:08.651420: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:50:08.652492: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:50:08.652570: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:50:08.652539729+00:00) for the scheduled start (2021-02-02T17:50:08.651017638+00:00) and will start immediately.
2021-02-02 17:50:08.652591: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:50:31.280828: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-02-02 17:50:31.281134: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-02-02 17:50:31.510697: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. 
2021-02-02 17:50:31.515475: I tensorflow/core/profiler/rpc/profiler_service_impl.cc:67] Collecting XSpace to repository: ./logs/tbc_log/plugins/profile/2021_02_02_17_49_44/localhost_6009.xplane.pb
2021-02-02 17:50:31.518037: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-02-02 17:50:31.518440: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
No trace event is collected. Automatically retrying.

2021-02-02 17:50:31.518819: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288231518793164 [2021-02-02T17:50:31.518793164+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 0
2021-02-02 17:50:31.518889: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:50:31.519021: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:50:31.519124: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:50:31.519147: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:50:31.520067: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:50:31.520136: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:50:31.520095781+00:00) for the scheduled start (2021-02-02T17:50:31.518793164+00:00) and will start immediately.
2021-02-02 17:50:31.520152: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:50:44.891412: W tensorflow/core/profiler/rpc/client/profiler_client.cc:152] Deadline exceeded: Deadline Exceeded
2021-02-02 17:50:44.891501: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
2021-02-02 17:50:44.891526: W tensorflow/core/profiler/rpc/client/capture_profile.cc:145] localhost:6009 returned Deadline exceeded: Deadline Exceeded
No trace event is collected after 3 attempt(s). Perhaps, you want to try again (with more attempts?).
Tip: increase number of attempts with --num_tracing_attempts.
2021-02-02 17:50:44.891848: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
Traceback (most recent call last):
  File &quot;keras_singleworker_2.py&quot;, line 37, in &lt;module&gt;
2021-02-02 17:50:44.893228: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
    tf.profiler.experimental.client.trace('grpc://localhost:6009', './logs/tbc_log', 20000)
  File &quot;/fserver/jonathanb/miniconda3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/profiler/profiler_client.py&quot;, line 131, in trace
    _pywrap_profiler.trace(
tensorflow.python.framework.errors_impl.UnavailableError: No trace event was collected because there were no responses from clients or the responses did not have trace data.
</code></pre>
<p>I've tried locating tf.profiler.experimental.server.start and tf.profiler.experimental.client.trace in other locations in the code, but with no success.</p>
",tf.profiler.experimental.client.trace,tf.profiler.experimental.client.trace,2020-05-14 12:29:41,15131641,71,https://stackoverflow.com/questions/66030439,Documentation Ambiguity
66019998,"How to get a processed dataset, if the processing steps are not tensor operations?","<p>I have an instance of <code>tf.data.Dataset()</code>, of images, basically, acquired this way:</p>
<pre><code>import tensorflow as tf

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_directory,
    image_size = (image_height, image_width),
    batch_size = batch_size
)
</code></pre>
<p>So, this dataset has <code>(data, label)</code> where the data is a tensor of shape <code>(batch_size, image_height, image_width, channels)</code> [I don't really need the labels it assigns]. So far so good. The problem is, I need to process this dataset, applying certain operations to the images, and, this dataset is too big to load everything in memory (that's why <code>batch_size</code> is there). According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">tensorflow documentation</a>, <code>tf.data.Dataset.map()</code> is the function I need (or so I assume....).</p>
<pre><code>def image_processing(data):
    print(data.shape)
    
    # Do some operations.
    # Do some copies [because np.arrays help me more...].
    copy = np.array(data, copy=True)

    # Change some pixels, like, zero out a square in this image
    # It sad that TensorFlow can't do this assignment if it were a tf.Tensor:
    copy[10:80,10:80] = np.array([0,0,0])

    # Do more things, and when done return.
    return something


processed_dataset = dataset.map(lambda image, label: (image_processing(image), label))
</code></pre>
<p>First of all, the shape returned by the print: <code>(None, 200, 200, 3)</code> instead of <code>(32, 200, 200, 3)</code>, or, instead of <code>(200, 200, 3)</code> [which is what I'd expect from reading the documentation] [let's assume batch of 32, and images 200x200], and this is messing my code, because, I need to do assigments, like, take the ith image, and change a couple pixels: <code>data[i][12:15,40:50] = np.array([1,2,3])</code> and things like that.</p>
<p>Basically, that's the error message: <code>TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'</code>.</p>
<hr />
<p><strong>In summary, my question:</strong> How can I get a <code>processed_dataset</code>, where the processing steps will not be whole tensor operations, but instead, will be changing individual values in the data (say, individual pixels), for certain images (say, the ith image, jth image, etc)?</p>
<hr />
<p>If you must know, I am running this in Ubuntu. Tensorflow version is:</p>
<pre><code>&gt;&gt;&gt; tf.__version__
'2.4.0'
</code></pre>
",tf.data.Dataset,tf.data.Dataset,2020-05-12 21:30:01,15049194,33,https://stackoverflow.com/questions/66019998,Documentation Replication on Other Examples
65953591,Which format should have time series input for LSTM-Model in Tensorflow?,"<p>I have a problem with the input for the fit-function of an LSTM-Model in TensorFlow. I have an input with the following shape:<br />
(5, 128, 78, 80)<br />
The fields are: (number of samples, timesteps, feature1, feature2)</p>
<p>The output has the shape: (5, 128, 78, 2)</p>
<p>This is my model:</p>
<pre><code>from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation

batch_size=5

time_model = tf.keras.Sequential()
time_model.add(tf.keras.layers.LSTM(512,return_sequences=True,input_shape=(128,2)))
time_model.add(Activation('sigmoid'))
time_model.add(Dense(2,name=&quot;dense&quot;))
time_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')


time_model.fit(x=time_input,y=time_output, epochs=10, batch_size=batch_size)
</code></pre>
<p>I get the following error:<br />
<code>ValueError: Input 0 of layer sequential_38 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (5, 128, 78, 80)</code></p>
<p>So I think, I have to change the shape of my data, but I don't know how. I tried already different values for input and  input_shape-attribute.<br />
I read in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM</a> that the input has to be a tensor with shape <code>[batch, timesteps, feature]</code>. So I put the two features in a nested array, and gave <code>[batch, timesteps, array of the features]</code> to the fit-function. But it told me that the data could not be converted to a tensor. Also explicit converting with <code>tf.convert_to_tensor</code> did not work.</p>
<p>I would be really glad, if someone could explain me, how I can pass input data with two features to an LSTM-model.</p>
",tf.keras.layers.LSTM,tf.keras.layers.LSTM,2020-05-10 19:34:30,11535546,36,https://stackoverflow.com/questions/65953591,Documentation Ambiguity
65863738,Changing order of Input Image in 3D convolutions,"<p>According to the official documentation of tf.keras.layers.Conv3D</p>
<blockquote>
<p>5+D tensor with shape: batch_shape + (channels, conv_dim1, conv_dim2,
conv_dim3) if data_format='channels_first' or 5+D tensor with shape:
batch_shape + (conv_dim1, conv_dim2, conv_dim3, channels) if
data_format='channels_last'</p>
</blockquote>
<p>. Now the whole idea around channels and batch shape makes sense, but will changing the general order of (conv_dim1, conv_dim2,conv_dim2) as (x,y,z) to say (z,x,y) affect the performance.</p>
<p>Does Conv3D worry about order of x-y-z dimension ?</p>
<p>I was training a U-net segmentation model and upon changing the order of axis I saw difference in performance. (x,y,z) order converges faster as compared to (y,x,z).</p>
<p>I just wanted to make sure what's the correct way..</p>
",tf.keras.layers.Conv3D,tf.keras.layers.Conv3D,2020-05-10 14:19:03,5066344,79,https://stackoverflow.com/questions/65863738,Documentation Ambiguity
65835387,ValueError: too many values to unpack (expected 2) when using tf.keras.preprocessing.image_dataset_from_directory,"<p>I want to create a dataset-variable as well as a labels-variable using the function tf.keras.preprocessing.image_dataset_from_directory (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory</a>).
The documentation states:</p>
<blockquote>
<p>Returns:
A tf.data.Dataset object.
If label_mode is None, it yields
float32 tensors of shape (batch_size, image_size[0], image_size[1],
num_channels), encoding images (see below for rules regarding
num_channels).
Otherwise, it yields a tuple (images, labels), where
images has shape (batch_size, image_size[0], image_size[1],
num_channels), and labels follows the format described below.</p>
</blockquote>
<p>My code is the following:</p>
<pre><code>train_ds, labels = tf.keras.preprocessing.image_dataset_from_directory(
  directory = data_dir,
  labels='inferred',
  label_mode = &quot;int&quot;,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
</code></pre>
<p>I expect to get a tuple as return values, but instead I get the error message:</p>
<pre><code>Found 2160 files belonging to 2160 classes.
Using 1728 files for training.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-168-ed9d42ed2ab9&gt; in &lt;module&gt;
      7   seed=123,
      8   image_size=(img_height, img_width),
----&gt; 9   batch_size=batch_size)

ValueError: too many values to unpack (expected 2)
</code></pre>
<p>When I save the output in one variable (just train_ds) and I inspect the variable, I get the following output:</p>
<pre><code>&lt;BatchDataset shapes: ((None, 120, 30, 3), (None,)), types: (tf.float32, tf.int32)&gt;
</code></pre>
<p>How can I access the two tuples inside seperatly?</p>
",tf.data.Dataset,tf.data.Dataset,2020-05-09 6:40:20,12336925,156,https://stackoverflow.com/questions/65835387,Documentation Ambiguity
65794527,"Example of output_signature , output_types & output_shapes for complex object called by tf.data.Dataset.from_generator","<p>I've a generator function that yields the following tuple: <code>yield (transformed_input_array, set_y)</code></p>
<p><em>transformed_input_array</em> is a list of ndarrays with the following shape: <em>(1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140)</em>  and the following types: <em>tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64</em>
<em>set_y</em> is a ndarray of shape <em>1024</em> and type of <em>int64</em></p>
<p>I've wrapped my generator with tf.data.Dataset.from_generator function, here is the code:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
    generator,
    # output_signature=(
    #     tf.TensorSpec(shape=(), dtype=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64)),
    #     tf.TensorSpec(shape=1024, dtype=tf.int64))
    output_types=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64, tf.int64),
    output_shapes=((1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140), 1024)
)
</code></pre>
<p>But when I run the training, I get the following error:</p>
<blockquote>
<p>ValueError: Data is expected to be in format <code>x</code>, <code>(x,)</code>, <code>(x, y)</code>,
or <code>(x, y, sample_weight)</code>, found: (&lt;tf.Tensor 'IteratorGetNext:0'
shape=(1024, 104) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:1'
shape=(1024, 142) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:2'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'It eratorGetNext:3'
shape=(1024, 1) dtype=int16&gt;, &lt;tf.Tensor 'IteratorGetNext:4'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:5'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:6'
shape=(1024, 140) dtype=float64&gt;, &lt;tf.Tensor 'ExpandDims:0'
shape=(1024, 1) dtype=int64&gt;)</p>
</blockquote>
<p>If I try to run with output_signature param (commented out code), I get the following error:</p>
<blockquote>
<p>TypeError: Cannot convert value (tf.float64, tf.float64, tf.int8,
tf.int16, tf.int8, tf.int8, tf.float64) to a TensorFlow DType.</p>
</blockquote>
<p><strong>Can someone provide an example, of how I should treat complex type (list of ndarrays)?</strong> Couldn't find any example in TF documentation..</p>
",tf.data.Dataset,tf.data.Dataset,2020-05-06 6:35:12,336558,700,https://stackoverflow.com/questions/65794527,Inadequate Examples
65779087,How to use tf.gradients within a model and still use a custom training loop?,"<p>I would like to make a TensorFlow model where the outputs respect a mathematical condition, namely that output 0 is a scalar function and all subsequent outputs are its partial derivatives w.r.t. the input. This is because my observations are the scalar function and its partials, and not using the partials for training would be a waste of information.</p>
<p>For now, using simply tf.gradients works if I don't build a custom training loop, i.e. when I don't utilize eager execution. The model is built like this, and training works as expected:</p>
<pre><code>import tensorflow as tf


from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras import callbacks

# Creating a model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Dense,
    Dropout,
    Flatten,
    Concatenate,
    Input,
    Lambda,
)

# Custom activation function
from tensorflow.keras.layers import Activation
from tensorflow.keras import backend as K

import numpy
import matplotlib.pyplot as plt

import tensorboard

layer_width = 200
dense_layer_number = 3

def lambda_gradient(args):
    layer = args[0]
    inputs = args[1]
    return tf.gradients(layer, inputs)[0]

# Input is a 2 dimensional vector
inputs = tf.keras.Input(shape=(2,), name=&quot;coordinate_input&quot;)

# Build `dense_layer_number` times a dense layers of width `layer_width`
stream = inputs
for i in range(dense_layer_number):
    stream = Dense(
        layer_width, activation=&quot;relu&quot;, name=f&quot;dense_layer_{i}&quot;
    )(stream)

# Build one dense layer that reduces the 200 nodes to a scalar output
scalar = Dense(1, name=&quot;network_to_scalar&quot;, activation=custom_activation)(stream)

# Take the gradient of the scalar w.r.t. the model input
gradient = Lambda(lambda_gradient, name=&quot;gradient_layer&quot;)([scalar, inputs])

# Combine them to form the model output
concat = Concatenate(name=&quot;concat_scalar_gradient&quot;)([scalar, gradient])

# Wrap everything in a model
model = tf.keras.Model(inputs=inputs, outputs=concat)

loss = &quot;MSE&quot;
optimizer = &quot;Adam&quot;

# And compile
model.compile(loss=loss, optimizer=optimizer)
</code></pre>
<p>However, them problem now comes when I want to do online training (i.e. with an incremental dataset). In this case, I wouldn't compile my model at the very end. Instead, I write a loop as such (before calling model.compile):</p>
<pre><code># ... continue from previous minus model.compile

loss_fn = tf.keras.losses.MeanSquaredError()
optimizer = tf.keras.optimizers.Adam()

# Iterate over the batches of a dataset and train.
for i_batch in range(number_of_batches):

    with tf.GradientTape() as tape:
        # Predict w.r.t. the inputs X
        prediction_Y = model(batches_X[i_batch])
        
        # Compare batch prediction to batch observation
        loss_value = loss_fn(batches_Y[i_batch], prediction_Y)

    gradients = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(gradients, model.trainable_weights))
</code></pre>
<p>This however gives the following exception at <code>prediction_Y = model(batches_X[i_batch])</code>:</p>
<pre><code>RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
</code></pre>
<p>As most examples, tutorials and documentation solely deal with using gradients to do training, and not within the model, I can't find any good resources how to deal with this. I tried to find how to use gradient tape, but I can't figure out how to use it in the model design phase. Any pointers would be appreciated!</p>
<p>Versions used:</p>
<pre><code>$ python --version                                         
Python 3.8.5
$ python -c &quot;import tensorflow as tf;print(tf.__version__);print(tf.keras.__version__)&quot;
2.2.0
2.3.0-tf
</code></pre>
",tf.GradientTape,tf.GradientTape,2020-05-02 18:55:19,6848887,163,https://stackoverflow.com/questions/65779087,Inadequate Examples
65481591,Keras Generator to tf.data.Dataset,"<p>I am working with the Mask RCNN keras implementation but the data generator hard locks on my systems when using <code>use_multiprocessing=True</code>. The data generator runs fine in single thread. I am trying to convert the data generator to a <code>tf.data.Dataset</code> as recommended by tensorflow. I have no idea how to do this and have been unable to find any documentation on this.</p>
<p>Mask RCNN data generator:</p>
<pre><code>class DataGenerator(KU.Sequence):
    &quot;&quot;&quot;An iterable that returns images and corresponding target class ids,
        bounding box deltas, and masks. It inherits from keras.utils.Sequence to avoid data redundancy
        when multiprocessing=True.

        dataset: The Dataset object to pick data from
        config: The model config object
        shuffle: If True, shuffles the samples before every epoch
        augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.
            For example, passing imgaug.augmenters.Fliplr(0.5) flips images
            right/left 50% of the time.
        random_rois: If &gt; 0 then generate proposals to be used to train the
                     network classifier and mask heads. Useful if training
                     the Mask RCNN part without the RPN.
        detection_targets: If True, generate detection targets (class IDs, bbox
            deltas, and masks). Typically for debugging or visualizations because
            in trainig detection targets are generated by DetectionTargetLayer.

        Returns a Python iterable. Upon calling __getitem__() on it, the
        iterable returns two lists, inputs and outputs. The contents
        of the lists differ depending on the received arguments:
        inputs list:
        - images: [batch, H, W, C]
        - image_meta: [batch, (meta data)] Image details. See compose_image_meta()
        - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)
        - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.
        - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs
        - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]
        - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width
                    are those of the image unless use_mini_mask is True, in which
                    case they are defined in MINI_MASK_SHAPE.

        outputs list: Usually empty in regular training. But if detection_targets
            is True then the outputs list contains target class_ids, bbox deltas,
            and masks.
        &quot;&quot;&quot;

    def __init__(self, dataset, config, shuffle=True, augmentation=None,
                 random_rois=0, detection_targets=False):

        self.image_ids = np.copy(dataset.image_ids)
        self.dataset = dataset
        self.config = config

        # Anchors
        # [anchor_count, (y1, x1, y2, x2)]
        self.backbone_shapes = compute_backbone_shapes(config, config.IMAGE_SHAPE)
        self.anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,
                                                      config.RPN_ANCHOR_RATIOS,
                                                      self.backbone_shapes,
                                                      config.BACKBONE_STRIDES,
                                                      config.RPN_ANCHOR_STRIDE)

        self.shuffle = shuffle
        self.augmentation = augmentation
        self.random_rois = random_rois
        self.batch_size = self.config.BATCH_SIZE
        self.detection_targets = detection_targets

    def __len__(self):
        return int(np.ceil(len(self.image_ids) / float(self.batch_size)))

    def __getitem__(self, idx):
        b = 0
        image_index = -1
        while b &lt; self.batch_size:
            
            # Increment index to pick next image. Shuffle if at the start of an epoch.
            image_index = (image_index + 1) % len(self.image_ids)

            if self.shuffle and image_index == 0:
                np.random.shuffle(self.image_ids)

            # Get GT bounding boxes and masks for image.
            image_id = self.image_ids[image_index]
            image, image_meta, gt_class_ids, gt_boxes, gt_masks = \
                load_image_gt(self.dataset, self.config, image_id,
                              augmentation=self.augmentation)

            # Skip images that have no instances. This can happen in cases
            # where we train on a subset of classes and the image doesn't
            # have any of the classes we care about.
            if not np.any(gt_class_ids &gt; 0):
                continue

            # RPN Targets
            rpn_match, rpn_bbox = build_rpn_targets(image.shape, self.anchors,
                                                    gt_class_ids, gt_boxes, self.config)

            # Mask R-CNN Targets
            if self.random_rois:
                rpn_rois = generate_random_rois(
                    image.shape, self.random_rois, gt_class_ids, gt_boxes)
                if self.detection_targets:
                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask = \
                        build_detection_targets(
                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, self.config)

            # Init batch arrays
            if b == 0:
                batch_image_meta = np.zeros((self.batch_size,) + image_meta.shape, dtype=image_meta.dtype)
                batch_rpn_match = np.zeros([self.batch_size, self.anchors.shape[0], 1], dtype=rpn_match.dtype)
                batch_rpn_bbox = np.zeros([self.batch_size, self.config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4], dtype=rpn_bbox.dtype)
                batch_images = np.zeros((self.batch_size,) + image.shape, dtype=np.float32)
                batch_gt_class_ids = np.zeros((self.batch_size, self.config.MAX_GT_INSTANCES), dtype=np.int32)
                batch_gt_boxes = np.zeros((self.batch_size, self.config.MAX_GT_INSTANCES, 4), dtype=np.int32)
                batch_gt_masks = np.zeros((self.batch_size, gt_masks.shape[0], gt_masks.shape[1],self.config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)
                if self.random_rois:
                    batch_rpn_rois = np.zeros((self.batch_size, rpn_rois.shape[0], 4), dtype=rpn_rois.dtype)
                    if self.detection_targets:
                        batch_rois = np.zeros((self.batch_size,) + rois.shape, dtype=rois.dtype)
                        batch_mrcnn_class_ids = np.zeros((self.batch_size,) + mrcnn_class_ids.shape, dtype=mrcnn_class_ids.dtype)
                        batch_mrcnn_bbox = np.zeros((self.batch_size,) + mrcnn_bbox.shape, dtype=mrcnn_bbox.dtype)
                        batch_mrcnn_mask = np.zeros((self.batch_size,) + mrcnn_mask.shape, dtype=mrcnn_mask.dtype)

            # If more instances than fits in the array, sub-sample from them.
            if gt_boxes.shape[0] &gt; self.config.MAX_GT_INSTANCES:
                ids = np.random.choice(
                    np.arange(gt_boxes.shape[0]), self.config.MAX_GT_INSTANCES, replace=False)
                gt_class_ids = gt_class_ids[ids]
                gt_boxes = gt_boxes[ids]
                gt_masks = gt_masks[:, :, ids]

            # Add to batch
            batch_image_meta[b] = image_meta
            batch_rpn_match[b] = rpn_match[:, np.newaxis]
            batch_rpn_bbox[b] = rpn_bbox
            batch_images[b] = mold_image(image.astype(np.float32), self.config)
            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids
            batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes
            batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks
            if self.random_rois:
                batch_rpn_rois[b] = rpn_rois
                if self.detection_targets:
                    batch_rois[b] = rois
                    batch_mrcnn_class_ids[b] = mrcnn_class_ids
                    batch_mrcnn_bbox[b] = mrcnn_bbox
                    batch_mrcnn_mask[b] = mrcnn_mask
            b += 1

        inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,
                  batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]
        outputs = []

        if self.random_rois:
            inputs.extend([batch_rpn_rois])
            if self.detection_targets:
                inputs.extend([batch_rois])
                # Keras requires that output and targets have the same number of dimensions
                batch_mrcnn_class_ids = np.expand_dims(
                    batch_mrcnn_class_ids, -1)
                outputs.extend(
                    [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])

        return inputs, outputs
</code></pre>
<p>I have tried to use the <code>tf.data.Dataset.from_generator()</code> however it requires the <code>output_types=</code> argument and the Mask RCNN outputs a number of lists, I can not figure out how to define <code>output_types=</code>.</p>
<p>I am using <code>python3.7</code>, <code>keras==2.2.5</code>, <code>tensorflow==2.2.0</code></p>
",tf.data.Dataset,tf.data.Dataset,2020-04-17 13:59:50,2600161,505,https://stackoverflow.com/questions/65481591,Documentation Replication on Other Examples
65437493,convert string to float array in csv using tf.data,"<p>I have a csv like this :</p>
<pre><code>kw_text,kw_text_weight
amazon google,0.5 0.5
google facebook microsoft,0.5 0.3 0.2
</code></pre>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>kw_text</th>
<th>kw_text_weight</th>
</tr>
</thead>
<tbody>
<tr>
<td>amazon google</td>
<td>0.5 0.5</td>
</tr>
<tr>
<td>google facebook microsoft</td>
<td>0.5 0.3 0.2</td>
</tr>
</tbody>
</table>
</div>
<p>I want to convert column <code>text_weight</code> to <code>tf.data</code> . But I find nothing about it in tensorflow document website .</p>
",tf.data,tf.data,2020-04-16 7:49:16,6862189,1245,https://stackoverflow.com/questions/65437493,Lack of Alternative Solutions/Documentation
65277703,image normalization and TPU,"<p>I'm trying to incorporate image normalization in my keras model to run on Google's cloud TPU. Therefore I inserted a line into my code:</p>
<pre><code>with strategy.scope():
     input_shape=(128,128,3)
     image_0 = Input(shape=input_shape)
     **image_1 = tf.image.per_image_standardization(image_0)**
     ...
</code></pre>
<p>There was nor error thrown, but according the documentation of google tf.image.per_image_standardization
is not a supported function. Does anybody know if it works anyhow, or does anybody have an idea how to check if it works?</p>
",tf.image.per_image_standardization,tf.image.per_image_standardization,2020-04-04 16:31:14,14818604,1,https://stackoverflow.com/questions/65277703,Documentation Replicability