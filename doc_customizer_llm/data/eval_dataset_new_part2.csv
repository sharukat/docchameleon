QuestionId,QuestionAPI,IssueType,Title,Question,GroundTruth,GT_Code,yt_queries,so_queries,yt_urls,yt_transcripts,so_urls,contexts
56047272,tf.constant,example required,Explicit vs implicit type definition in TensorFlow,"<p>I'm just beginning to learn TensorFlow. Quoting from the <a href=""https://www.tensorflow.org/guide/low_level_intro#graph"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p>Let's build a simple computational graph. The most basic operation is a constant. The Python function that builds the operation takes a tensor value as input. The resulting operation takes no inputs. When run, it outputs the value that was passed to the constructor. We can create two floating point constants a and b as follows:</p>
</blockquote>

<pre><code>a = tf.constant(3.0, dtype=tf.float32)
b = tf.constant(4.0) # also tf.float32 implicitly
total = a + b
print(a)
print(b)
print(total)
</code></pre>

<p>The second constant is implicitly typed as a float32. Is that based on the explicit typing of the first constant? And does that imply that the first <code>dtype</code> is required? <a href=""https://www.tensorflow.org/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">tf.constant documentation</a> would imply that it does not:</p>

<blockquote>
  <p>If the argument dtype is not specified, then the type is inferred from the type of <code>value</code>.</p>
</blockquote>

<p>But then it would be unnecessary to explicitly type the 3.0 constant above.</p>

<p>I'm just looking for some clarification on this, since, like I said, I'm just starting out.</p>
","<blockquote>
  <p>But then it would be unnecessary to explicitly type the 3.0 constant
  above.</p>
</blockquote>

<p>Absolutely correct. </p>

<pre><code>a = tf.constant(3.0, dtype=tf.float32)
</code></pre>

<p>is equivalent to:</p>

<pre><code>a = tf.constant(3.0)
</code></pre>

<p>The documentation is just demonstrating the different overloads. We might choose to explicitly provide the type if we want a different numerical precision (or even just to aid human readability) but if you want the default data type TF infers, then it's entirely unnecessary.</p>
",,"['TensorFlow tf.constant dtype inference', 'TensorFlow tf.constant documentation', 'TensorFlow constant type inference example', 'TensorFlow dtype specification necessity', 'TensorFlow beginner tutorial on constants and dtype']","['Is it necessary to explicitly specify the dtype for tf.constant in TensorFlow?', 'Does the dtype of one tf.constant affect the dtype of another tf.constant in the same computational graph?', 'What is the default dtype for tf.constant if dtype is not specified?', 'Why would one explicitly specify the dtype for tf.constant if it can be inferred from the value?']","{'https://www.youtube.com/watch?v=Jn5sQjYi1FU', 'https://www.youtube.com/watch?v=tPYj3fFJGjk'}","['""""""[Document(page_content=""Hello, everybody, and welcome to an absolutely\\nmassive TensorFlow slash machine learning slash artificial intelligence course. Now,\\nplease stick with me for this short introduction, as I am going to give you a lot of important\\ninformation regarding the course content, the resources for the course, and what you\\ncan expect after going through this. Now, first, I will tell you who this course is\\naimed for. So this course is aimed for people that are beginners in machine learning and\\nartificial intelligence, or maybe have a little bit of understanding but are trying to get\\nbetter, but do have a basic fundamental knowledge of programming and Python. So this is not\\na course you\'re going to take if you haven\'t done any programming before, or if you don\'t\\nknow any Python syntax in general, it\'s gonna be highly advised that you understand the\\nbasic syntax behind Python, as I\'m not going to be explaining that throughout this course.\\nNow, in terms of your instructor for this course, that is going to be me, my name is\\nTim, some of you may know me, as tech with Tim, from my YouTube channel, right teach\\nall kinds of different programming topics. And I\'ve actually been working with Free Code\\nCamp and posted some of my series on their channel as well. Now let\'s get into the course\\nbreak down and talk about exactly what you\'re going to learn and what you can expect from\\nthis course. So as this course is geared towards beginners, and people just getting started\\nin the machine learning and AI world, we\'re gonna start by breaking down exactly what\\nmachine learning and artificial intelligence is. So talking about what the differences\\nare, between them, the different types of machine learning, reinforcement learning,\\nfor example, versus neural networks versus simple machine learning, we\'re gonna go through\\nall those different differences. And then we\'re going to get into a general introduction\\nof TensorFlow. Now, for those of you that don\'t know, TensorFlow is a module developed\\nand maintained by Google, which can be used within Python to do a ton of different scientific\\ncomputing, machine learning and artificial intelligence applications. We\'re gonna be\\nworking with that through the entire tutorial series. And after we do that general introduction\\nto TensorFlow, we\'re going to get into our core learning algorithms. Now, these are the\\nlearning algorithms that you need to know before we can get further into machine learning,\\nthey build a really strong foundation, they\'re pretty easy to understand and implement. And\\nthey\'re extremely powerful. After we do that, we\'re going to get into neural networks discuss\\nall the different things that go into how neural networks work, how we can use them,\\nand then do a bunch of different examples. And then we\'re going to get into some more\\ncomplex aspects of machine learning and artificial intelligence and get to convolution neural\\nnetworks, which can do things like image recognition and detection. And then we\'re going to get\\ninto recurrent neural networks, which are going to do things like natural language processing,\\nchatbots, text processing, all those different kinds of things, and finally ended off with\\nreinforcement learning. Now, in terms of resources for this course, there are a ton, and what\\nwe\'re going to be doing to make this really easy for you, and for me, is doing everything\\nthrough Google Collaboratory. Now, if you haven\'t heard of Google Collaboratory, essentially,\\nit\'s a collaborative coding environment that runs an iPython Notebook in the cloud, on\\na Google machine where you can do all of your machine learning for free. So you don\'t need\\nto install any packages, you don\'t need to use Pip, you don\'t need to get your environment\\nset up, all you need to do is open a new Google Collaboratory window, and you can start writing\\ncode. And that\'s what we\'re gonna be doing in this series. If you look in the description\\nright now, you will see links to all of the notebooks that I use throughout this guide.\\nSo if there\'s anything that you want to cleared up, if you want the code for yourself, if\\nyou want just text based descriptions of the things that I\'m saying, you can click those\\nlinks and gain access to them. So with that being said, I\'m very excited to get started,\\nI hope you guys are as well. And let\'s go ahead and get into the content. So in this first section, I\'m going to spend\\na few minutes discussing the difference between artificial intelligence, neural networks and\\nmachine learning. And the reason we need to go into this is because we\'re going to be\\ncovering all of these topics throughout this course. So it\'s vital that you guys understand\\nwhat these actually mean. And you can kind of differentiate between them. So that\'s what\\nwe\'re going to focus on now. Now, quick disclaimer here, just so everyone\'s aware, I\'m using\\nsomething called Windows Inc. This just default comes with Windows, I have a drawing tablet\\ndown here. And this is what I\'m going to be using for some of the explanatory parts, but\\nthere\'s no real coding, just to kind of illustrate some concepts and topics to you. Now I have\\nvery horrible handwriting, I\'m not artistic whatsoever, programming is more definitely\\nmore of my thing than, you know, drawing and doing diagrams and stuff. But I\'m going to\\ntry my best. And this is just the way that I find I can convey information the best to\\nyou guys. So anyways, let\'s get started and discuss the first topic here, which is artificial\\nintelligence. Now, artificial intelligence is a huge hype nowadays. And it\'s funny because\\na lot of people actually don\'t know what this means. Or they tried to tell people that what\\nthey\'ve created is not artificial intelligence, when in reality, it actually is. Now the kind\\nof formal definition of AI and I\'m just gonna read it off of my slide here to make sure\\nthat I\'m not messing this up, is the effort to automate intellectual tasks normally performed\\nby humans. Now, that\'s a fairly big definition, right? What is considered an intellectual\\ntask and, you know, really, that doesn\'t help us too much. So what I\'m going to do is bring\\nus back to when AI was first created to kind of explain to you how AI has evolved and what\\nit really started out being so back in 1950 There was kind of a question being asked by\\nscientists and researchers, can computers think, can we get them to figure things out?\\nCan we get away from hard coding? And you know, having like, Can we get a computer to\\nthink can it do its own thing? So that was kind of the question that was asked. And that\'s\\nwhen the term artificial intelligence was kind of coined and created. Now back then\\nAI was simply a predefined set of rules. So if you\'re thinking about an AI for maybe like\\ntic tac toe, or an AI for chess, all they would have had back then, is predefined rules\\nthat humans had come up with and typed into the computer in code. And the computer would\\nsimply execute those set of rules and follow those instructions. So there was no deep learning\\nmachine learning crazy algorithms happening, it was simply if you wanted the computer to\\ndo something, you would have to tell it beforehand, say you\'re in this position. And this happens,\\ndo this. And that\'s what AI was. And very good AI was simply just a very good set of\\nrules were a ton of different rules that humans had implemented into some program, you could\\nhave AI programs that are stretching, you know, half a million lines of code, just with\\ntons and tons and tons of different rules that have been created for that AI. So just\\nbe aware that AI does not necessarily mean anything crazy, complex or super complicated.\\nBut essentially, if you\'re trying to simulate some intellectual task, like playing a game\\nthat a human would do with a computer, that is considered AI, so even a very basic artificial\\nintelligence for Tic Tac Toe game where it plays against you, that is still considered\\nAI. And if we think of something like Pac Man, right, where we have, you know, our little\\nghost, and this will be my rough sketch of a ghost, we have our Pac Man guy who will\\njust be this. Well, when we consider this ghost AI, what it does is it attempts to find\\nand kind of simulate how we get to Pac Man, right. And the way this works is just using\\na very basic pathfinding algorithm. This has nothing to do with deep learning, or machine\\nlearning or anything crazy. But this is still considered artificial intelligence, the computer\\nis figuring out how it can kind of play and do something by following an algorithm. So\\nwe don\'t necessarily need to have anything Crazy, Stupid complex to be considered AI,\\nit simply needs to just be simulating some intellectual human behavior. That\'s kind of\\nthe definition of artificial intelligence. Now, obviously, today, AI has evolved into\\na much more complex field where we now have machine learning and deep learning and all\\nthese other techniques, which is what we\'re going to talk about now. So what I want to\\nstart by doing is just drawing a circle here. And I want to label this circle and say, A,\\nI like that. So this is going to define AI, because everything I\'m about to put inside\\nof here is considered artificial intelligence. So now, let\'s get into machine learning. So\\nwhat I\'m going to do is draw another circle inside of here. And we\'re going to label this\\ncircle, ml for machine learning. Now notice I put this inside of the artificial intelligence\\ncircle. This is because machine learning is a part of artificial intelligence. Now, what\\nis machine learning? Well, what we talked about previously, was kind of the idea that\\nAI used to just be a predefined set of rules, right? Where what would happen is, we would\\nfeed some data, we would go through the rules by and then analyze the data with the rules.\\nAnd then we\'d spit out some output, which would be you know, what we\'re going to do.\\nSo in the classic example of chess, say, we\'re in check, what we pass that board information\\nto the computer, it looks at it sets of rules, it determines we\'re in check, and then it\\nmoves us somewhere else. Now, what is machine learning in contrast to that? Well, machine\\nlearning is kind of the first field that actually figuring out the rules for us. So rather than\\nus hard coding the rules into the computer, what machine learning attempts to do is take\\nthe data and take what the output should be, and figure out the rules for us. So you\'ll often hear that, you know, machine learning requires\\na lot of data. And you need a ton of examples and, you know, input data to really train\\na good model. Well, the reason for that is because the way that machine learning works\\nis it generates the rules for us. We give it some input data, we give it what the output\\ndata should be. And then it looks at that information and figures out what rules can\\nwe generate, so that when we look at new data, we can have the best possible output for that.\\nNow, that\'s also why a lot of the times, machine learning models do not have 100% accuracy,\\nwhich means that they may not necessarily get the correct answer every single time.\\nAnd our goal when we create machine learning models is to raise our accuracy as high as\\npossible, which means it\'s going to make the fewest mistakes possible. Because just like\\na human, you know, our machine learning models, which are trying to simulate, you know, human\\nbehavior can make mistakes. But to summarize that, essentially machine learning the difference\\nbetween that and kind of, you know, algorithms and basic artificial intelligence is the fact\\nthat rather get that rather than us the programmer giving it the rules. It figures out the rules\\nfor us. And we might not necessarily know explicitly what the rules are when we look\\nat machine learning and create machine learning models. But we know that we\'re giving some\\ninput data, we\'re giving the expected output data, and then it looks at all of that information\\ndoes some algorithms, which we\'ll talk about later on that and figures out the rules for\\nus. So that later when we give it some input data, and we don\'t know the output data, it\\ncan use those rules that it\'s figured out from our examples and all that training data\\nthat we gave it to generate some output. Okay, so that\'s machine learning. Now we\'ve covered\\nAI and machine learning. And now it\'s time to cover neural networks or deep learning.\\nNow, this circle gets to go right inside of the machine learning right here, I\'m just\\ngonna label this one and n, which stands for neural networks. Now, neural networks get\\na big hype, they\'re usually what the first, you know, when you get into machine learning,\\nyou want to learn neural networks are kind of like neural networks are cool, they\'re\\ncapable of a lot. But let\'s discuss what these really are. So the easiest way to define a\\nneural network is it as a form of machine learning that uses a layered representation\\nof data. Now, we\'re not going to really understand this completely right now. But as we get further\\nin, that should start to make more sense as a definition. But what I need to kind of illustrate\\nto you is that in the previous example, where we just talked about machine learning, essentially\\nwhat we had is we had some input bubbles, which I\'m going to define this these, we had\\nsome set of rules that is going to be in between here, and then we had some output. And what\\nwould happen is we feed this input to this set of rules, something happens in here, and\\nthen we get some output. And then that is what you know, our program does, that\'s what\\nwe get from the model, we pretty much just have two layers, we have kind of the input\\nlayer, the output layer, and the rules are kind of just what connects those two layers\\ntogether. Now in neural networks, and what we call deep learning, we have more than two\\nlayers. Now, I\'m just trying to erase all this quickly. So I can show you that. So let\'s\\nsay and all journalists want another color, because why not? If we\'re talking about neural\\nnetworks, what we might have, and this will vary, and I\'ll talk about this in a second\\nis the fact that we have an input layer, which will be our first layer of data, we could\\nhave some layers in between this layer, that are all connected together. And then we could\\nhave some output layer. So essentially, what happens is, our data is going to be transformed\\nthrough different layers, and different things are going to happen, there\'s gonna be different\\nconnections between these layers. And then eventually, we will reach an output. Now it\'s\\nvery difficult to explain neural networks without going completely in depth. So we\'ll\\ncover a few more notes that I have here. Essentially, in neural networks, we just have multiple\\nlayers, that\'s kind of the way to think of them. And as we see machine learning, you\\nguys should start to understand this more. But just understand that we\'re dealing with\\nmultiple layers. And a lot of people actually call this a multi stage information extraction\\nprocess. Now, I did not come up with that term. I think that\'s from a book or something.\\nBut essentially, what ends up happening is we have our data at this first layer, which\\nis that input information, which we\'re going to be passing to the model that we\'re going\\nto do something with, It then goes to another layer, where it will be transformed, it will\\nchange into something else, using a predefined kind of set of rules and weights that we\'ll\\ntalk about later, then it will pass through all of these different layers were different\\nkind of features of the data, which again, we\'ll discuss in a second will be extracted\\nwill be figured out will be found until eventually, we reach an output layer where we can kind\\nof combine everything we\'ve discovered about the data into some kind of output that\'s meaningful\\nto our program. So that\'s kind of the best that I can do to explain neural networks without\\ngoing on to a deeper level, I understand that a lot of you probably don\'t understand what\\nthey are right now. And that\'s totally fine. But just know that there are layered representation\\nof data, we have multiple layers of information. Whereas in standard machine learning, we only\\nhave you know, one or two layers, and then artificial intelligence in general, we don\'t\\nnecessarily have to have like a predefined set of layers. Okay, so that is pretty much it for neural networks, there\'s\\none last thing I will say about them is that they\'re actually not modeled after the brain.\\nSo a lot of people seem to think that neural networks are modeled after the brain and the\\nfact that you have neurons firing in your brain. And that can relate to neural networks.\\nNow, there is a biological inspiration for the name neural networks in the way that they\\nwork from, you know, human biology, but is not necessarily modeled about the way that\\nour brain works. And in fact, we actually don\'t really know how a lot of the things\\nin our brain operate and work. So it would be impossible for us to say that neural networks\\nare modeled after the brain, because we actually don\'t know how information is kind of happens\\nand occurs and transfers through our brain. Or at least we don\'t know enough to be able\\nto say this is exactly what it is a neural network. So anyways, that was kind of the\\nlast point there. Okay, so now we need to talk about data. Now data is the most important\\npart of machine learning and artificial intelligence, neural networks as well. And it\'s very important\\nthat we understand how important data is and what the different kinds of parts of it are,\\nbecause they\'re going to be referenced a lot in any of the resources that we\'re using.\\nNow what I want to do is just create an example here, I\'m going to make a data set that is\\nabout students final grades in like a school system. So essentially, we\'re gonna make this\\na very easy example. We\'re all we\'re gonna have for this data set is we\'re going to have\\ninformation about students. So we\'re gonna have their midterm one grade, their midterm\\nto grade, and then we\'re gonna have their final grade. So I\'m just gonna say mid term,\\none. And again, excuse my handwriting here, it\'s not the easiest thing to write with this\\ndrawing tablet. And then I\'ll just do final. So this is going to be our data set. And we\'ll\\nactually see some similar data sets to this as we go through and do some examples later\\non. So for student one, which we\'ll just put some students here, we\'re going to have their\\nmidterm one grade, maybe that\'s a 70, their midterm to grade, maybe that was an 80. And\\nthen let\'s say their final was like their final term grade, not just the mark on the\\nfinal exam, let\'s give them a 77. Now for midterm one can give someone a 60, maybe we\\ngive them a 90, and then we determine that the final grade on their exam was, let\'s say,\\nan 84. And then we can do something with maybe a lower grade here, so 4050, and then maybe\\nthey got a 38, or something in the final grade. Now, obviously, we could have some other information\\nhere that we\'re admitting like maybe there was some exams, some assignments, whatever\\nsome other things they did that contributed to their grade. But the problem that I want\\nto consider here is the fact that given our midterm, one grade and our midterm to grade\\nand our final grade, how can I use this information to predict any one of these three columns.\\nSo if I were given a student\'s midterm, one grade, and I were given a student\'s final\\ngrade, how could I predict their midterm to grade. So this is where we\'re going to talk\\nabout features and labels. Now, whatever information we have that is the input information, which\\nis the information we will always have that we need to give to the model to get some output\\nis what we call our features. So in the example where we\'re trying to predict midterm two,\\nand let\'s just do this and highlight this in red, so we understand what we would have\\nas our features, our input information are going to be midterm one. And finally, because\\nthis is the information we\'re going to use to predict something it is the input, it is\\nwhat we need to give the model. And if we\'re training a model to look at midterm one and\\nfinal grade, whenever we want to make a new prediction, we need to have that information\\nto do so. Now, what\'s highlighted in red, so this midterm two here is what we would\\ncall the label or the output. Now, the label is simply what we are trying to look for or\\npredict. So when we talk about features versus labels, features is our input information,\\nthe information that we have that we need to use to make a prediction. And our label\\nis that output information that is just representing you know what we\'re looking for. So when we\\nfeed our features to a model, he will give to us a label. And that is kind of the point\\nthat we need to understand. So that was the basic here. And now I\'m just going to talk\\na little bit more about data, because we will get into this more as we continue going, and\\nabout the importance of it. So the reason why data is so important is this is kind of the\\nkey thing that we use to create models. So whenever we\'re doing AI and machine learning,\\nwe need data, pretty much unless you\'re doing a very specific type of machine learning and\\nartificial intelligence, which we\'ll talk about later. Now for most of these models,\\nwe need tons of different data, we need tons of different examples. And that\'s because\\nwe know how machine learning works now, which is essentially, we\'re trying to come up with\\nrules for a data set, we have some input information, we have some output information or some features\\nand some labels, we can give that to a model and tell it to start training. And what it\\nwill do is come up with rules such that we can just give some features to the model in\\nthe future. And then it should be able to give us a pretty good estimate of what the\\noutput should be. So when we\'re training, we have a set of training data. And that is\\ndata where we have all of the features and all of the labels. So we have all of this\\ninformation, then when we\'re going to test the model or use the model later on, we would\\nnot have this midterm two information, we wouldn\'t pass this in the model, we would\\njust pass our features, which is midterm one and final and then we would get the output\\nof midterm two. So I hope that makes sense. That just means data is extremely important.\\nIf we\'re feeding incorrect data or data that we shouldn\'t be using to the model that could\\ndefinitely result in a lot of mistakes. And if we have incorrect output information or\\nincorrect input information that is going to cause a lot of mistakes as well, because\\nthat is essentially what the model is using to learn and to kind of develop and figure\\nout what it\'s going to do with new input information. So anyways, that is enough of data. Now let\'s\\ntalk about the different types of machine learning. Okay, so now that we\'ve discussed\\nthe difference between artificial intelligence, machine learning and neural networks, we have\\na kind of decent idea about what data is in the difference between features and labels.\\nIt\'s time to talk about the different types of machine learning specifically, which are\\nunsupervised learning, supervised learning and reinforcement learning. Now, these are\\njust the different types of learning the different types of figuring things out. Now, different\\nkinds of algorithms fit into these different categories from within artificial intelligence\\nwithin machine learning and within neural networks. So the first one we\'re going to\\ntalk about is supervised learning, which is kind of what we\'ve already discussed. So I\'ll\\njust write supervised up here. Again, excuse the handwriting. So supervised Learning. Now\\nwhat is this? Well, supervised learning is kind of everything we\'ve already\\nlearned, which is we have some features. So we\'ll write our features like this, right,\\nwe have some features. And those features correspond to some label or potentially labels,\\nsometimes we might predict more than one information. So when we have this information, we have\\nthe features, and we have the labels, what we do is we pass this information to some\\nmachine learning model, it figures out the rules for us. And then later on, all we need\\nis the features. And it will give us some labels using those rules. But essentially,\\nwhat supervised learning is, is when we have both of this information, the reason that\'s\\ncalled supervised is because what ends up happening when we train our machine learning\\nmodel is we pass the input information, it makes some arbitrary prediction using the\\nrules it already knows. And then it compares that prediction that it made to what the actual\\nprediction is, which is this label. So we supervise the model and we say, okay, so you\\npredicted that the color was red, but really, the color of whatever we passed in should\\nhave been blue. So we need to tweak you just a little bit so that you get a little bit\\nbetter, and you move in the correct direction. And that\'s kind of the way that this works.\\nFor example, say we\'re predicting, you know, student\'s final grade, well, if we predict\\nthat the final grade is 76, but the actual greatest 77, we were pretty close, but we\'re\\nnot quite there. So we supervise the model and we say, Hey, we\'re gonna tweak you just\\na little bit, move you in the correct direction. And hopefully we get you to 77. And that is\\nkind of the way to explain this, right, you have the features. So you have the labels,\\nwhen you pass the features, the model has some rules, and it\'s already built, it makes\\na prediction. And then it compares that prediction to the label, and then re tweaks the model\\nand continues doing this with 1000s upon 1000s upon 1000s of pieces of data until eventually\\nit gets so good that we can stop training. And that is what supervised learning is, it\'s\\nthe most common type of learning, it\'s definitely the most applicable in a lot of instances.\\nAnd most machine learning algorithms that are actually used use a form of supervised\\nmachine learning. A lot of people seem to think that this is, you know, a less complicated,\\nless advanced way of doing things. That is definitely not true. All of the different\\nmethods, I\'m going to tell you have different advantages and disadvantages. And this has\\na massive advantage when you have a ton of information and you have the output of that\\ninformation as well. But sometimes we don\'t have the luxury of doing that. And that\'s\\nwhere we talk about unsupervised learning. So hopefully that made sense for supervised\\nlearning, tried my best to explain that. And now let\'s go into or sorry, for supervised\\nlearning. Now let\'s go into unsupervised learning. So if we know the definition of supervised\\nlearning, we should hopefully be able to come up with a definition of unsupervised learning,\\nwhich is when we only have features. So given a bunch of features like this, and absolutely\\nno labels, no output for these features. What we want to do is have the model come up with\\nthose labels for us. Now, this is kind of weird. You\'re kind of like Wait, how does\\nthat work? Why would we even want to do that? Well, let\'s take this for an example. We have\\nsome axis some axes of data, okay. And we have like a two dimensional data point. So\\nI\'m just gonna call this, let\'s say x, and let\'s say y, okay, and I\'m gonna just put\\na bunch of dots on the screen that kind of represents like maybe a scatterplot of some\\nof our different data. And I\'m just going to put some dots specifically closer to other\\nones, just so you guys kind of get the point of\\nwhat we\'re trying to do here. So let\'s do that. Okay, so let\'s say I have this data\\nset, this here is what we\'re working with. And we have these features, the features in\\nthis instance, are going to be x and y, right? So X, and Y are my features. Now we don\'t\\nhave any output specifically for these data points, what we actually want to do is we\\nwant to create some kind of model that can cluster these data points, which means figure\\nout kind of, you know, unique groups of data and say, okay, so you during group one, you\'re\\nin group two, you\'re in group three, and you\'re in group four, we may not necessarily know\\nhow many groups we have, although sometimes we do. But what we want to do is just group\\nthem and kind of say, okay, we want to figure out which ones are similar. And we want to\\ncombine those together. So hopefully, what we could do with an unsupervised machine learning\\nmodel is pass all of these features, and then have the model create kind of these groupings.\\nSo like maybe this is a group, maybe this is a group, maybe this is a group if we were\\nhaving four groupings, and maybe if we had two groupings, we might get groupings that\\nlook something like this, right. And then when we pass a new data point in, that could\\nwe could figure out what group that was a part of by determining, you know, which one\\nis closer to. Now this is kind of a rough example. It\'s hard to again, explain all of\\nthese without going very in depth into the specific algorithms. But unsupervised machine\\nlearning or just learning in general is when you don\'t have some output information. You\\nactually want the model to figure out the output for you. And you don\'t really care\\nhow it gets there. You just want it to get there. And again, a good example is clustering\\ndata points, and we\'ll talk about some specific Applications of when we might even want to\\nuse that later on, just understand you have the features, you don\'t have the labels, and\\nyou get the unsupervised model to kind of figure it out for you. Okay, so now our last type, which is very different\\nthan the two types I just explained, is called reinforcement learning. Now personally reinforcement\\nlearning, and I don\'t even know if I want to spell this because I feel like I\'m going\\nto mess it up. Reinforcement Learning is the coolest type of machine learning in my opinion.\\nAnd this is when you actually don\'t have any data, you have what you call an agent, and\\nenvironment and a reward. I\'m going to explain this very briefly with a very, very, very\\nsimple example, because it\'s hard to get too far. So let\'s say we have a very basic game,\\nyou know, maybe we made this game ourselves. And essentially, the objective of the game\\nis to get to the fluc. Okay, that\'s all it is, we have some ground, you can move left\\nto right, and we want to get to this flag. Well, we want to train some artificial intelligence,\\nsome machine learning model that can figure out how to do this. So what we do is we call\\nthis our agent, we call this entire thing. So this whole thing here, the environment.\\nSo I guess I could write that here. So and by our meant, think I spelt that correctly.\\nAnd then we have something called a reward. And a reward is essentially what the agent\\ngets when it does something correctly. So let\'s say the agent takes one step over this\\nway. So let\'s say he\'s a new position is here, I just want to keep drawing him. So I\'m just\\ngonna use a dot. Well, he got closer to the flag. So what I\'m actually going to do is\\ngive him a plus two reward. So let\'s say he moves again, closer to the flag, maybe I give\\nhim now plus one, this time, he got even closer. And as he gets closer, I\'ll give him more\\nand more reward. Now what happens if he moves backwards? So let\'s erase this. And let\'s\\nsay that at some point in time, rather than moving closer to the for the flag, he moves\\nbackwards, well, he might get a negative reward. Now, essentially, what the objective of this\\nagent is to do is to maximize its reward. So if you give it a negative reward for moving\\nbackwards, it\'s going to remember that it\'s going to say, Okay, at this position here,\\nwhere I was standing, when I moved backwards, I got a negative reward. So if I get to this\\nposition, again, I don\'t want to go backwards anymore, I want to go forwards, because that\\nshould give me a positive reward. And the whole point of this is we have this agent\\nthat starts off with absolutely no idea, no kind of, you know, knowledge of the environment.\\nAnd what it does is it starts exploring, and it\'s a mixture of randomly exploring and exploring\\nusing kind of some of the things that\'s figured out so far, to try to maximize its reward.\\nSo eventually, when the agent gets to the flag, it will have the most the highest possible\\nreward that it can have. And the next time that we plug this agent into the environment,\\nit will know how to get to the flag immediately, because it\'s kind of figured that out, it\'s\\ndetermined that in all these different positions, if I move here, this is the best place to\\nmove. So if I get in this position, move there. Now this is again, hard to explain without\\nmore detailed examples, and going more mathematically and all that, but essentially, just understand\\nwe have the agent, which is kind of what the thing is that\'s moving around in our environment,\\nwe have this environment wizard, which is just what the agent can move around in. And\\nthen we have a reward. And the reward is what we need to figure out as the programmer a\\nway to reward the agent correctly so that it gets to the objective in the best possible\\nway. But the agent simply maximizes that reward. So it just figures out where I need to go\\nto maximize that reward, it starts at the beginning, kind of randomly exploring the\\nenvironment, because it doesn\'t know any of the rewards it gets at any of the positions.\\nAnd then as it explores some more different areas, it kind of figures out the rules and\\nthe way that the environment works. And then we\'ll determine how to reach the objective,\\nwhich is whatever it is that is this a very simple example, you could train a reinforcement\\nmodel to do this. And you know, like half a second, right. But there is way more advanced\\nexamples. And there\'s been examples of reinforcement learning, like of AI is pretty much figuring\\nout how to play games together how to it\'s it\'s actually pretty cool some of the stuff\\nthat reinforcement learning is doing. And it\'s a really awesome kind of advancement\\nin the field because it means we don\'t need all this data anymore. We can just get this\\nto kind of figure out how to do things for us and explore the environment and learn on\\nits own. Now this can take a really long time, this can take a very short amount of time\\nreally depends on the environment. But a real application of this is training AI\'s to play\\ngames, as you might be able to tell by kind of what I was explaining here. And yeah, so\\nthat is kind of the fundamental differences between supervised, unsupervised and reinforcement\\nlearning, we\'re going to cover all three of these topics throughout this course. And it\'s\\nreally interesting to see some of the applications we can actually do with this. So with that\\nbeing said, I\'m going to kind of end what I\'m going to call module one, which is just\\na general overview of the different topics, some definitions and getting a fundamental\\nknowledge. And in the next one, what we\'re gonna be talking about is what TensorFlow\\nis, we\'re going to get into code In a little bit, and we\'re going to discuss some different\\naspects of TensorFlow and things we need to know to be able to move forward and do some\\nmore advanced things. So now in module two of this course, what\\nwe\'re going to be doing is getting a general introduction to TensorFlow, understanding\\nwhat a tensor is understanding shapes and data representation, and then how TensorFlow\\nactually works on a bit of a lower level, this is very important, because you can definitely\\ngo through and learn how to do machine learning without kind of gaining this information and\\nknowledge. But it makes it a lot more difficult to tweak your models and really understand\\nwhat\'s going on, if you don\'t, you know, have that fundamental lower level knowledge of\\nhow TensorFlow actually works and operates. So that\'s exactly what we\'re gonna cover here.\\nNow, for those of you that don\'t know what TensorFlow is, essentially, this is an open\\nsource Machine Learning Library. It\'s one of the largest ones in the world, it\'s one\\nof the most well known and it\'s maintained and supported by Google. Now, TensorFlow,\\nessentially allows us to do and create machine learning models and neural networks, and all\\nof that without having to have a very complex math background. Now, as we get further in,\\nand we start discussing more in detail how neural networks work, and machine learning\\nalgorithms actually function, you\'ll realize there\'s a lot of math that goes into this.\\nNow, it starts off being very kind of fundamental, like basic calculus and basic linear algebra.\\nAnd then it gets much more advanced into things like gradient descent, and some more regression\\ntechniques and classification. And essentially, you know, a lot of us don\'t know that we don\'t\\nreally need to know that, so long as we have a basic understanding of it, then we can use\\nthe tools that TensorFlow provides for us to create models. And that\'s exactly what\\nTensorFlow does. Now, what I\'m in right now is what I call Google Collaboratory. I\'m going\\nto talk about this more in depth in a second. But what I\'ve done for this whole course,\\nis I\'ve transcribed very detailed everything that I\'m going to be covering through each\\nmodule. So this is kind of the transcription of module one, which is the introduction to\\nTensorFlow, you can see it\'s not crazy long. But I wanted to do this so that any of you\\ncan follow along with kind of the text base and kind of my lecture notes, I almost want\\nto call them as I go through the different content. So in the description, there will\\nbe links to all of these different notebooks. This is in something called Google Collaboratory,\\nwhich again, we\'re going to discuss in a second, but you can see here that I have a bunch of\\ntext, and then it gets down to some different coding aspects. And what I\'m going to be doing\\nto make sure that I stay on track is simply following along through this, I might deviate\\nslightly, I might go into some other examples. This will be kind of everything I\'m going\\nto be covering through each module. So again, to follow along, click the link in the description.\\nAlright, so what can we do with TensorFlow? Well, these are some of the different things\\nI\'ve listed them here. So I don\'t forget, we can do image classification, data clustering,\\nregression, reinforcement learning, natural language processing, and pretty much anything\\nthat you can imagine with machine learning. Essentially, what TensorFlow does, is gives\\nus a library of tools that allow us to omit having to do these very complicated math operations.\\nIt just does them for us. Now, there is a bit that we need to know about them, but nothing\\ntoo complex. Now let\'s talk about how TensorFlow actually works. So TensorFlow has two main\\ncomponents that we need to understand, to figure out how operations and math are actually\\nperformed. Now we have something called graphs and sessions. Now, the way that tensor flow\\nworks, is it creates a graph of partial computations. Now, I know this is gonna sound a little bit\\ncomplicated, some of you guys just try to kind of forget about the complex vocabulary\\nand follow along. But essentially, what we do when we write code in TensorFlow is we\\ncreate a graph. So if I were to create some variable, that variable gets added to the\\ngraph, and maybe that variable is the sum or the summation of two other variables. What\\nthe graph will define now is say, you know, we have variable one, which is equal to the\\nsum of variable two and variable three. But what we need to understand is that it doesn\'t\\nactually evaluate that it simply states that that is the computation that we\'ve defined.\\nSo it\'s almost like writing down an equation without actually performing any math, we kind\\nof just, you know, have that equation there. We know that this is the value, but we haven\'t\\nevaluated it. So we don\'t know that the value is like 7%, we just know that it\'s the sum\\nof, you know, vector one and vector two, or it\'s the sum of this or it\'s the cross product,\\nor the dot product, we just defined all of the different partial computations, because\\nwe haven\'t evaluated those computation yet. And that is what is stored in the graph. And\\nthe reason that\'s called a graph is because different computations can be related to each\\nother. For example, if I want to figure out the value of vector one, but vector one is\\nequal to the value of vector three plus vector four, I need to determine the value of vector\\nthree and vector four, because before I can do that computation, so they\'re kind of linked\\ntogether and I hope that makes a little bit of sense. Now what is a session? Well session\\nis essentially a way to execute part or the entire graph. So when we start In a session,\\nwhat we do is we start executing different aspects of the graph. So we start at the lowest\\nlevel of the graph where nothing is dependent on anything else, we have maybe constant values,\\nor something like that. And then we move our way through the graph, and start doing all\\nof the different partial computations that we\'ve defined. Now, I hope that this isn\'t\\ntoo confusing. I know this is kind of a lot of lingo you guys should will understand this\\nas we go through. And again, you can read through some of these components here that\\nI have in Collaboratory, if I\'m kind of skipping through anything you don\'t truly understand.\\nBut that is the way that graphs and sessions work, we won\'t go too in depth with them,\\nwe do need to understand that that is the way TensorFlow works. And there\'s some times\\nwhere we can\'t use a specific value in our code yet, because we haven\'t evaluated the\\ngraph, we haven\'t created a session and gotten the values yet, which we might need to do\\nbefore we can actually, you know, use some specific value. So that\'s just something to\\nconsider. Alright, so now we\'re actually going to get into coding\\nimporting, installing TensorFlow. Now, this is where I\'m going to introduce you to Google\\nCollaboratory and explain how you guys can follow along without having to install anything\\non your computer. And it doesn\'t matter if you have like a really crappy computer, or\\neven if you\'re on like an iPhone, per se, you can actually do this, which is amazing.\\nSo all you need to do is Google Google Collaboratory, and create a new notebook. Now what Google\\nCollaboratory is, is essentially a free Jupyter Notebook in the cloud for you. The way this\\nworks is you can open up this notebook, you can see this is called I, py and B, I yeah,\\nwhat is that I py and B, which I think just stands for IPython notebook. And what you\\ncan do in here is actually write code and write text as well. So this in here is what\\nit\'s called, you know, Google Collaboratory notebook. And essentially, why it\'s called\\na notebook is because not only can you put code but you can also put notes, which is\\nwhat I\'ve done here with these specific titles. So you can actually use markdown inside of\\nthis. So if I open up one of these, you can see that I\'ve used markdown text, to actually\\nkind of create these sections. And yeah, that is kind of how Collaboratory works. But what\\nyou can do in Collaboratory is forget about having to install all of these modules. They\'re\\nalready installed for you. So what you\'re actually going to do when you open a Collaboratory\\nwindow is Google is going to automatically connect you to one of their servers or one\\nof their machines that has all of this stuff done and set up for you. And you can start\\nwriting code and executing it off their machine and seeing the result. So for example, if\\nI want you to print hello, like this, and I\'ll zoom in a little bit, so you guys can\\nread this, all I do is like create a new code block, which I can do by clicking code. Like\\nthat I can delete one like that as well. And I hit run. Now notice, give it a second, it\\ndoes take longer than typically on your own machine, and we get Hello popping up here.\\nSo the great thing about Collaboratory is the fact that we can have multiple code blocks,\\nand we can run them in whatever sequence we want. So to create another code block, you\\ncan just you know, do another code block from up here or but just by looking down here,\\nyou get code and you get text. And I can run this in whatever order I want. So I can do\\nlike print. Yes, for example, I can run Yes, and we\'ll see the output of Yes, and then\\nI can print hello one more time. And notice that it\'s showing me the number on this left\\nhand side here on which these kind of code blocks were run. Now all these code blocks\\ncan kind of access each other. So for example, I do define funk, and we\'ll just take some\\nparameter H and all we\'ll do is just print H, well, if I create another code block down\\nhere, so let\'s go code. I can call funk with say, Hello, make sure I run this block first.\\nSo we define the function. Now we\'ll run funk and notice we get the output Hello. So we\\ncan access all of the variables, all the functions, anything we\'ve defined in other code blocks\\nfrom code blocks that are below it, or code blocks that are executed after it. Now another\\nthing that\'s great about Collaboratory is the fact that we can import pretty much any\\nmodule we can imagine. And we don\'t need to install it. So I\'m not actually going to be\\ngoing through how to install TensorFlow completely. There is a little bit on how to install TensorFlow\\non your local machine inside of this notebook, which I\'ll refer you to. But essentially,\\nif you know how to use Pip, it\'s pretty straightforward. You can pip install TensorFlow or pip install\\nTensorFlow GPU if you have a compatible GPU, which you can check from the link that\'s in\\nthis notebook. Now, if I want to import something, what I can do is literally just write the\\nimport. So I can say import NumPy, like this. And usually NumPy is a module that you need\\nto install. But we don\'t need to do that here. It\'s already installed on the machine. So\\nagain, we hook up to those Google servers, we can use their hardware to perform machine\\nlearning. And this is awesome. This is amazing. And it gives you performance benefits when\\nyou\'re running on like a lower kind of crappier machine, right. So we can have a look at the\\nRAM and the disk space of our computer, we can see we have 12 gigs of RAM. We\'re dealing\\nwith 107 gigabytes of data on our disk space. And we can obviously, you know, look at that\\nif we want, we can connect connect to our local runtime, which I believe connects to\\nyour local machine, but I\'m not going to go through all that. I just want to show you\\nguys some basic components of Have Collaboratory. Now, some other things that are important\\nto understand is this runtime tab, which you might see me use. So restart runtime essentially\\nclears all of your output, and just restarts whatever\'s happened. Because the great thing\\nwith Collaboratory is since I can run specific code blocks, I don\'t need to execute the entire\\nthing of code every time I want to run something, if I\'ve just made a minor change in one code\\nblock, I can just run that code. Sorry, I can just run that code block. I don\'t need\\nto run everything before it or even everything after it right. But sometimes you want to\\nrestart everything and just rerun everything. So to do that, you click Restart runtime,\\nthat\'s just going to clear everything you have. And then restart and run all will restart\\nthe runtime as well as run every single block of code you have in sequential order in which\\nit shows up in the thing. So I recommend you guys open up one of these windows, you can\\nobviously follow along with this notebook if you want. But if you want to type it out\\non your own and kind of mess with it, open up a notebook, save it, it\'s very easy. And\\nthese are again, extremely similar to Jupyter Notebooks or Jupyter notebooks. They\'re pretty\\nmuch the same. Okay, so that is kind of the Google Collaboratory aspect how to use that.\\nLet\'s get into importing TensorFlow. Now, this is going to be kind of specific to Google\\nCollaboratory. So you can see here, these are kind of the steps we need to follow to\\nimport TensorFlow. So since we\'re working in Google Collaboratory, they have multiple\\nversions of TensorFlow, they have the original version of TensorFlow, which is 1.0, and the\\n2.0 version. Now to define the fact that we want to use TensorFlow 2.0. Just because we\'re in this notebook, we need to\\nwrite this line of code at the very beginning of all of our notebooks. So percent, TensorFlow\\nunderscore version two point x. Now this is simply just saying, we need to use TensorFlow\\ntwo point x. So whatever version that is, and this is only required in a notebook, if\\nyou\'re doing this on your local machine in a text editor, you\'re not going to need to\\nwrite this. Now once we do that, we typically import TensorFlow as an alias name of TF.\\nNow to do that, we simply import the TensorFlow module and then we write as TF. If you\'re\\non your local machine, again, you\'re going to need to install TensorFlow first, to make\\nsure that you\'re able to do this, but since we\'re in Collaboratory, we don\'t need to do\\nthat. Now, since we\'ve defined the fact we\'re using version two point x, when we print the\\nTensorFlow version, we can see here that it says version two, which is exactly what we\'re\\nlooking for. And then this is TensorFlow. 2.1. Point Oh. So make sure that you print\\nyour version you\'re using version 2.0. Because there is a lot of what I\'m using in this series\\nthat is kind of if you\'re in TensorFlow 1.0. It\'s not going to work. So it\'s new in TensorFlow\\n2.0. Or it\'s been refactored and the names have been changed. Okay, so now that we\'ve\\ndone that, we\'ve imported TensorFlow, we\'ve got this here. And I\'m actually going to go\\nto my fresh notebook and just do this. So we\'ll just copy these lines over just so we\\nhave some fresh code, and I don\'t have all this text that we have to deal with. So let\'s\\ndo this TensorFlow, let\'s import TensorFlow as TF. And then we can print the TF dot version\\nand have a look at that. So version. Okay, so let\'s run our code. Here. We can see TensorFlow\\nis already loaded. Oh, it says 1.0. So if you get this error, it\'s actually good. I\\nran into this where TensorFlow is already been loaded, all you need to do is just restart\\nyour runtime. So I\'m going to restart and run all just click Yes. And now we should\\nsee that we get that version 2.0. Once this starts running, give it a second, TensorFlow\\n2.0 selected, we\'re going to import that module. And there we go, we get version 2.0. Okay,\\nso now it\'s time to talk about tensors. Now, what is a tensor? Now tensor just immediately\\nseems kind of like a complicated name. You\'re like, Alright, tensor like this is confusing.\\nBut what is well, obviously, this is going to be a primary aspect of TensorFlow, considering\\nthe name similarities. And essentially, all it is, is a vector generalized to higher dimensions.\\nNow, what is a vector? Well, if you\'ve ever done any linear algebra, or even some basic\\nkind of vector calculus, you should hopefully know what that is. But essentially, it is\\nkind of a data point is kind of the way that I like describe it. And the reason we call\\nit a vector is because it doesn\'t necessarily have a certain coordinate. So like, if you\'re\\ntalking about a two dimensional data point, you have, you know, maybe an x and a y value,\\nor like an x one value and an x two value. Now a vector can have any amount of dimensions\\nin it, it could have one dimension, which simply means it just one number could have\\ntwo dimensions, which means we\'re having two numbers, so like an x and a y value. If we\'re\\nthinking about a two dimensional graph, we\'d have three dimensions if we\'re thinking about\\na three dimensional graph, so that would be three data points, we get a four dimensions,\\nif we\'re talking about sometimes some image data and some video data, five dimensions,\\nand we can keep going going going with vectors. So essentially, what a tensor is, and I\'ll\\njust read this formal definition to make sure I haven\'t butchered anything that\'s from the\\nactual TensorFlow website. A tensor is a generalization of vectors and matrices to potentially higher\\ndimensions. Internally, TensorFlow represented tensors as n dimensional arrays of base datatypes.\\nNow we\'ll understand what that means in a second. But hopefully, that makes sense. Now,\\nsince tensors are so important to TensorFlow, they\'re kind of the main object that we\'re\\ngoing to be working with manipulating and viewing. And it\'s the main object that\'s passed\\naround through our program. Now, what we can see here is each tensor represents a partially\\ndefined computation that will eventually produce a value. So just like we talked about in the\\ngraphs and sessions, what we\'re going to do is when we create our program, we\'re going\\nto be creating a bunch of tensors. And TensorFlow is going to be creating them as well. And\\nthose are going to store partially defined computations in the graph. Later, when we\\nactually build the graph and have the session running, we will run different parts of the\\ngraph, which means we\'ll execute different tensors and be able to get different results\\nfrom our tensors. Now each tensor has what we call a data type and a shape. And that\'s\\nwhat we\'re going to get into now. So a data type is simply what kind of information is\\nstored in the tensor. Now, it\'s very rare that we see any data types different than\\nnumbers, although there is the data type of strings and a few others as well. But I haven\'t\\nincluded all of them here, because they\'re not that important. But some examples we can\\nsee are float, 32, and 32, string and others. Now, the shape is simply the representation\\nof the tensor in terms of what dimension it is. And we\'ll get to some examples, because\\nI don\'t want to explain the shape until we can see some examples to really dial in. But\\nhere is some examples of how we would create different tensors. So what you can do is you\\ncan simply do TF dot variable, and then you can do the value and the datatype that your\\ntensor is. So in this case, we\'ve created a string tensor, which stores one string,\\nand it is TF dot strings, we define the data type Second, we have a number tensor, which\\nstores some integer value. And then that is of type TF, int 16. And we have a floating\\npoint tensor, which stores a simple floating point. Now these tensors have a shape of,\\nI believe it\'s going to be one, which simply means they are a scalar. Now a scalar value.\\nAnd you might hear me say this a lot simply means just one value. That\'s all it means.\\nWhen we talk about like vector values, that typically means more than one value. And we\\ntalked about matrices, we\'re having different it just it goes up. But scalar simply means\\none number. So yeah, that is what we get for the different datatypes and creating tensors,\\nwe\'re not really going to do this very much in our program. But just for some examples\\nhere, that\'s how we do it. So we\'ve imported them. So I can actually run these. And I mean,\\nwe\'re not going to really get any output by running this code, because well, there\'s nothing\\nto see. But now we\'re going to talk about the rank slash degree of tensors. So another\\nword for rank is degree. So these are interchangeably. And again, this simply means the the, the\\nnumber of dimensions involved in the tensor. So when we create a tensor of rank zero, which\\nis what we\'ve done up here, we call that a scalar. Now, the reason this has rank zero\\nis because it\'s simply one thing, we don\'t have any dimension to this, there\'s like zero\\ndimensionality, if that was even a word, it just one value. Whereas here, we have an array.\\nNow when we have an array or a list, we immediately have at least rank one. Now the reason for\\nthat is because this array can store more than one value in one dimension, right? So\\nI can do something like test, I can do okay, I could do, Tim, which is my name. And we\\ncan run this, and we\'re not going to get any output obviously here. But this is what we\\nwould call a rank one tensor. Because it is simply one list one array, which means one\\ndimension, and again, you know, that\'s also like vector. Now, this, what we\'re looking\\nat here is a rank two tensor. The reason this is a rank two tensor is because we have a\\nlist inside of a list or in this case, multiple lists inside of a list. So the way that you\\ncan actually determine the rank of a tensor is the deepest level of nested lists, at least\\nin Python with our representation. That\'s what that is. So here, we can see we have\\na list inside of a list, and then another list inside of this upper list. So this would\\ngive us rank two. And this is what we typically call a matrices. And this again, is going\\nto be of TF dot strings. So that\'s the datatype for this tensor variable. So all of these\\nwe\'ve created are tensors. They have a data type, and they have some rank and some shape.\\nAnd we\'re going to talk about the shape and the second. So to determine the rank of a\\ntensor, we can simply use the method TF dot rank. So notice, when I run this, we get the\\nshape, which is blank of rank two tensor, that\'s fine. And then we get NumPy two, which\\nsimply means that this is of rank two. Now, if I go for that rank one tensor and I print\\nthis out. So let\'s have a look at it, we get NumPy one here, which is telling us that this\\nis simply of rank one. Now if I want to use one of these ones up here and see what it\\nis, so let\'s try it. We can do numbers, so TF dot rank number, so we\'ll print that here,\\nand we get NumPy zero because that\'s rank zero, right? So We\'ll go back to what we had,\\nwhich was rank two tensor. But again, those are kind of the examples we want to look at.\\nOkay, so shapes of a tensor. So this is a little bit different now, what a shape simply\\ntells us is how many items we have in each dimension. So in this case, when we\'re looking\\nat rank two, tensor dot shape, so we have dot shape here, that\'s an attribute of all\\nof our tensors, we get to two. Now let\'s look up here, what we have is Whoa, look at this\\ntwo, and two, so we have two elements in the first dimension, right, and then two elements\\nin the second dimension. That\'s pretty much what this is telling us. Now let\'s look at\\nthe rank of or the shape of rank one tensor, we get three. So because we only have a rank\\none, notice we only get one number, whereas when we had rank two, we got two numbers.\\nAnd it told us how many elements were in each of these lists, right? So if I go and I add\\nanother one here, like that, and we have a look now at the shape, oops, I gotta run this\\nfirst. So that\'s something Oh, can\'t convert non square to tensor. Sorry, so I need to\\nhave a uniform amount of elements in each one here, I can\'t just do what I did there.\\nSo we\'ll add a third element here. Now what we can do is run this shouldn\'t get any issues,\\nlet\'s have a look at the shape. And notice we get now two, three. So we have two lists.\\nAnd each of those lists have three elements inside of them. So that\'s how the shape works.\\nNow, I could go ahead and add another list in here if I wanted to. And I could say like,\\nokay, okay. Okay, so let\'s run this, hopefully, no errors\\nlooks like we\'re good. Now let\'s look at the shape again. And now we get a shape of three,\\nthree, because we have three interior lists. And in each of those lists, we have three\\nelements. And that is pretty much how that works. Now, again, we could go even further\\nhere, we could put another list inside of here, that would give us a rank three tensor.\\nAnd we\'d have to do that inside of all of these lists. And then what that would give\\nus now would be three numbers representing how many elements we have in each of those\\ndifferent dimensions. Okay, so changing shape. Alright, so this is what we need to do a lot\\nof times when we\'re dealing with tensors in TensorFlow. So essentially, there is many\\ndifferent shapes that can represent the same number of elements. So up here, we have three\\nelements in a rank one tensor. And then here, we have nine elements in a rank two tensor.\\nNow, there\'s ways that we can reshape this data so that we have the same amount of elements\\nbut in a different shape. For example, I could flatten this, right, take all of these elements,\\nand throw them into a rank one tensor. That simply is a length of nine elements. So how\\ndo we do that? Well, let me just run this code for us here and have a look at this.\\nSo what we\'ve done is we\'ve created tensor one, that is TF dot ones, what this stands for is we\'re going to create\\na tensor that simply is populated completely with ones of this shape. So shape 123, which\\nmeans you know, that\'s the shape we\'re going to get. So let\'s print this out and look at\\ntensor one, just so I can better illustrate this. So tensor one, look at the shape that\\nwe have 123, right, so we have one interior list, which we\'re looking at here. And then\\nwe have two lists inside of that list. And then each of those lists, we have three elements.\\nSo that\'s the shape we just defined. Now, we have six elements inside of here. So there\\nmust be a way that we can reshape this data to have six elements, but in a different shape.\\nIn fact, what we can do is reshape this into a 231 shape, we\'re going to have two lists,\\nright? We\'re going to have three inside of those. And then inside of each of those, we\'re\\ngoing to have one element. So let\'s have a look at that one. So let\'s have a look at\\ntensor two, actually, what am I doing, we print all we can print all of them here. So\\nlet\'s just print them and have a look at them. So when we look at tensor one, we saw this\\nwas a shape. And now we look at this tensor two. And we can see that we have two lists,\\nright? inside of each of those lists, we have three lists. And inside of each of those lists,\\nwe have one element. Now finally, our tensor three is a shape of three, negative one, what\\nis negative one, when we put negative one here, what this does is infer what this number\\nactually needs to be. So if we define an initial shape of three, what this does is say, okay,\\nwe\'re going to have three lists. That\'s our first level. And then we need to figure out\\nbased on how many elements we have in this reshape, which is the method we\'re using,\\nwhich I didn\'t even talk about, which will go into a second, what this next dimension\\nshould be. Now, obviously, this is going to need to be three. So three, three, right?\\nBecause we\'re gonna have three lists inside of each of those lists we need to have are\\nactually is that correct? Let\'s see if that\'s even the shape three to my bat. So this actually\\nneeds to change to three, two, I don\'t know why I wrote three, three there. But you get\\nthe point. Right, so what this does, we have three lists, we have six elements. This number\\nobviously needs to be two because well, three times two is going to give us six and that\\nis essentially how you can determine how many elements are actually in a tensor by just\\nlooking at its shape. Now this is the reshape method where all we need to do is called TF\\ndot reshape, give the tensor and give the shape we want to change it to so long as that\'s\\na valid shape. And when we multiply all the numbers in here, it\'s equal to the number\\nof elements in this tensor that will reshape it for us and give us that new shaped data.\\nThis is very useful. We\'ll use this actually a lot as we go through TensorFlow. So make\\nsure you\'re kind of familiar with how that works. Alright, so now we\'re moving on to\\ntypes of tensors. So there is a bunch of different types of tensors that\\nwe can use. So far, the only one we\'ve looked at is variable. So we\'ve created TF dot variables,\\nand kind of just hard coded our own tensors, we\'re not really going to do that very much.\\nBut just for that example. So we have these different types, we have constant placeholder\\nsparsetensor variable, there\'s actually a few other ones as well. Now, we\'re not going\\nto really talk about these two that much, although constant and variable are important\\nto understand the difference between so we can read this, with the exception of variable,\\nall of these tensors are immutable, meaning their value may not change during execution.\\nSo essentially, all of these, when we create a tensor mean, we have some constant value,\\nwhich means that whatever we\'ve defined here, it\'s not going to change, whereas the variable\\ntensor could change. So that\'s just something to keep in mind when we use variable. That\'s\\nbecause we think we might need to change the value of that tensor later on. Whereas if\\nwe\'re using a constant value tensor, we cannot change it. So that\'s just something to keep\\nin mind, we can obviously copy it, but we can\'t change. Okay, so evaluating tensors,\\nwe\'re almost at the end of this section, I know. And then we\'ll get into some more kind\\nof deeper code. So there will be some times for this guide, we need to evaluate a tense,\\nof course, so what we need to do to evaluate a tensor is create a session. Now, this isn\'t\\nreally like, we\'re not going to do this that much. But I just figured I\'d mention it to\\nmake sure that you guys are aware of what I\'m doing. If I start kind of typing this\\nlater on. Essentially, sometimes we have some tensor object, and throughout our code, we\\nactually need to evaluate it to be able to do something else. So to do that, all we need\\nto do is literally just use this kind of default template, a block of code, where we say with\\nTF dot session, as some kind of session doesn\'t really matter what we put here, then we can\\njust do whatever the tensor name is dot eval, and calling that will actually have TensorFlow,\\njust figure out what it needs to do to find the value of this tensor, it will evaluate\\nit, and then it will allow us to actually use that value. So I put this in here, you\\nguys can obviously read through this, if you want to understand some more in depth on how\\nthat works. And the source for this is straight from the TensorFlow website, a lot of this\\nis straight up copied from there. And I\'ve just kind of added my own spin to it and made\\nit a little bit easier to understand. Okay, so we\'ve done all that. So let\'s just go in\\nhere and do a few examples of reshaping just to make sure that everyone\'s kind of on the\\nsame page. And then we\'ll move on to actually talking about some simple learning algorithms.\\nSo I want to create a tensor that we can kind of mess with and reshape, so what I\'m going\\nto do is just say t equals and we\'ll say TF dot ones. Now, what TF dot ones does is just\\ncreate, again, all the values to be ones that we\'re going to have and whatever shape now\\nwe can also do zeros and zeros is just going to give us a bunch of zeros. And let\'s create\\nsome like crazy shape and just visualize this, let\'s see like a five by five by five. So\\nobviously, if we want to figure out how many elements are going to be in here, we need\\nto multiply this value. So I believe this is going to be 625, because that should be\\nfive to the power of four, so five times five times five times five. And let\'s actually\\nprint T and have a look at that and see what this is. So we run this now. And you can see\\nthis is the output we\'re getting. So obviously, this is a pretty crazy looking tensor. but\\nyou get the point, right, and it tells us the shape is 55555. Now watch what happens\\nwhen I reshape this tensor. So if I want to take all of these elements and flatten them\\nout, what I could do is simply say, we\'ll say t equals TF dot reshape, like that. And\\nwe\'ll reshape the tensor t to just the shape 625. Now, if we do this, and we run here,\\noops, I got to print T. At the bottom, after we\'ve done that, if I could spell the print\\nstatement correctly, you can see that now we just get this massive list that just has\\n625 zeros. And again, if we wanted to reshape this to something like 125, and maybe we weren\'t\\nthat good at math, and couldn\'t figure out that this last value should be five, we could\\nput a negative one, this would mean that TensorFlow would infer now what the shape needs to be.\\nAnd now when we look at it, we can see that we\'re we\'re going to get is well just simply\\nfive kind of sets of these. I don\'t know matrices, whatever you want to call them, and our shape\\nis 125. Five. So that is essentially how that works. So that\'s how we reshape. That\'s how\\nwe kind of deal with tensors. Create variables, how that works in terms of sessions and graphs.\\nAnd hopefully with that, that gives you enough of an understanding of tensors of shapes of\\nranks a value so that when we move into the next part of the tutorial, we\'re actually\\nwriting code and I promise we\'re going to be writing some more advanced code, you\'ll\\nunderstand how that works. So with that being said, let\'s get into the next section. So welcome to Module Three of this course.\\nNow what we\'re going to be doing in this module is learning the core machine learning algorithms\\nthat come with TensorFlow. Now, these algorithms are not specific to TensorFlow, but they are\\nused within there. And we\'ll use some tools from TensorFlow to kind of implement them.\\nBut essentially, these are the building blocks. Before moving on to things like neural networks\\nand more advanced machine learning techniques, you really need to understand how these work\\nbecause they\'re kind of used in a lot of different techniques and combined together, and one\\nof them but to show you is actually very powerful if you use it in the right way, a lot of what\\nmachine learning actually is and a lot of machine learning algorithms and implementations\\nand businesses and applications and stuff like that, actually just use pretty basic\\nmodels. Because these models are capable of actually doing, you know, very powerful things.\\nWhen you\'re not dealing with anything that\'s crazy complicated, you just need some basic\\nmachine learning some basic classification, you can use these kind of fundamental core\\nlearning algorithms. Now, the first one we\'re going to go through is linear regression.\\nBut we will cover classification and clustering in hidden Markov models. And those are kind\\nof going to give us a good spread of the different core algorithms. Now there is a ton ton like\\n1000s of different machine learning algorithms. These are kind of the main categories that\\nyou\'ll cover. But within these categories, there is more specific algorithms that you\\ncan get into, I just feel like I need to mention that because I know a lot of you will have\\nmaybe seen some different ways of doing things in this course might show you, you know, a\\ndifferent perspective on that. So let me just quickly talk about how I\'m going to go through\\nthis, it\'s very similar to before I have this notebook, as I\'ve kind of talked about, there\\nis a link in the description, I would recommend that you guys hit that and follow along with\\nwhat I\'m doing and read through the notebook. But I will just be going through the notebook.\\nAnd then occasionally, what I will actually do, oops, I need to open this up here is go\\nto this kind of untitled tab I have here and write some code in here, because most of what\\nI\'m going to do is just copy code over into here, so we can see it all in kind of one\\nblock. And then we\'ll be good to go. And the last note before we really get into it, and\\nI\'m sorry, I\'m talking a lot. But it is important to make you guys aware of this, you\'re going\\nto see that we use a lot of complicated syntax throughout this kind of series and the rest\\nof the course in general, I just want to make it extremely clear that you should not have\\nto memorize or even feel obligated to memorize any of the syntax that you see everything\\nthat you see here, I personally don\'t even have memorized, there\'s a lot of what\'s in\\nhere that I can\'t just come up with the top of my head, when we\'re dealing with kind of\\nlibrary and module so big that like TensorFlow, it\'s hard to memorize all those different\\ncomponents. So just make sure you understand what\'s happening. But you don\'t need to memorize\\nit, if you\'re ever going to need to use any of these tools, you\'re going to look them\\nup, you\'re going to see what it is you\'re like, Okay, I\'ve used this before, you\'re\\ngoing to understand it. And then you can go ahead and you know, copy that code in and\\nuse it in whatever way you need to, you don\'t need to memorize anything that we do here.\\nAlright, so let\'s go ahead and get started with linear regression. So what is linear\\nregression? What\'s one of those basic forms of machine learning, and essentially, what\\nwe try to do is have a linear correspondence between data points. So I\'m just going to\\nscroll down here to a good example. So what I\'ve done is use matplotlib, just to plot\\na little graph here. So we can see this one right here. And essentially, this is kind\\nof our data set, this will we\'ll call our data set, what we want to do is use linear\\nregression to come up with a model that can give us some good predictions for our data\\npoints. So in this instance, maybe what we want to do is given some x value for a data\\npoint, we want to predict the y value. Now in this case, we can see there\'s kind of some\\ncorrespondence linearly for these data points. Now, what that means is we can draw something\\ncalled a line of best fit through these data points that can kind of accurately classify\\nthem, if that makes any sense. So I\'m going to scroll down here and look at what our line\\nof best fit for this data set actually is, we can see this blue line, it pretty much\\nI mean, is the perfect line of best fit for this data set. And using this line, we can\\nactually predict future values in our data set. So essentially, linear regression is\\nused when you have data points that correlate in kind of a linear fashion. Now, this is\\na very basic example, because we\'re doing this in two dimensions with x and y. But oftentimes,\\nwhat you\'ll have is you\'ll have data points that have you know, eight or nine kind of\\ninput values. So that gives us you know, a nine dimensional kind of data set. And what\\nwe\'ll do is predict one of the different values. So in the instance, where we were talking\\nabout students before, maybe we have a student\'s What does it midterm grade and their second\\nmidterm grade, and then we want to predict their final grade, what we can do is use linear\\nregression to do that, where our kind of input values are going to be the two midterm grades\\nand the output value is going to be that final grade that we\'re looking to predict. So if\\nwe were to plot that, we would plot that on a three dimensional graph, and we would draw\\na three dimensional line that would represent the line of best fit for that data set. Now,\\nfor any of you that don\'t know what line of best fit stands for, it says line or this\\nis just the definition I got from this website here. line of best fit refers to a line through\\na scatterplot of data points that best expresses the relationship between those points. So\\nexactly what I\'ve kind of been trying to explain when we have data that correlates linearly\\nand I always butcher that word. What we can do is draw a line through it. And then we\\ncan use that line to predict new data points. Because if that line is good, it\'s a good\\nline of best fit for the data set, then hopefully, we would assume that we can just, you know,\\npick some point, find where it would be on that line. And that\'ll be kind of our predicted\\nvalue. So I\'m going to go into an example now where I start drawing and going into a\\nlittle bit of math. So we understand how this works on a deeper level. But that should give\\nyou a surface level understanding. So actually, I\'ll leave this up because I was messing with\\nthis beforehand. This is kind of a data set that I\'ve drawn on here. So we have our x\\nand we have our y, and we have our line of best fit. Now what I want to do is I want to use this line of\\nbest fit to predict a new data point. So all these red data points are ones that we\'ve\\ntrained our model with the information that we gave to the model so that it could create\\nthis line of best fit, because essentially, all linear regression really does is look\\nat all of these data points and create a line of best fit for them. That\'s all it does.\\nIt\'s pretty, I don\'t know the word for it\'s pretty easy to actually do this, this algorithm\\nis not that complicated is not that advanced. And that\'s why we start with it here because\\nit just makes sense to explain. So I hope that a lot of you know in two dimensions,\\na line can be defined as follows. So with the equation y equals mx plus b, now B stands\\nfor the y intercept, which means somewhere on this line, so essentially where the line\\nstarts. So in this instance, our b value is going to be right here. So this is going to\\nbe B because that is the y intercept. So we can say that that\'s like maybe you know, we\\ngo on, we\'ll do this, we\'ll say this is like 123, we might say B is something like 0.4,\\nright? So I can just pencil that in 0.4. And then what is m x and y? Well, X and Y stands\\nfor the coordinates of this data point. So this would have, you know, some x y value.\\nIn this case, we might call it you know, something like, what do you want to say to 2.7 that\\nmight be the value of this data point. So that\'s our x and y. And then our M stands\\nfor the slope, which is probably the most important part. Now slope simply defines the\\nsteepness of this line of best fit that we\'ve done here. Now the way we calculate slope\\nis using rise over run, no rise over run essentially just means how much we went up versus how\\nmuch we went across. So if you want to calculate the slope of a line, what you can actually\\ndo is just draw a triangle. So right angled triangle anywhere on the line, so just pick\\ntwo data points. And what you can do is calculate this distance and this distance, and then\\nyou can simply divide the distance up by the distance across, and that gives you the slope.\\nNow, I\'m not going to go too far into slope, because I feel like you guys probably understand\\nwhat that is. But let\'s just pick some values for this line. And I want to actually show\\nyou some real examples of math and how we\'re going to do this. So let\'s say that our linear\\nregression algorithm, you know, comes up with this line, I\'m not going to discuss really\\nhow it does that, although it just pretty much looks at all these data points, and finds\\nthe line that you know, goes, it splits these data points evenly. So essentially, you want\\nto be as close to every data point as possible. And you want to have as many data points,\\nyou want to have the same amount of data points on the left side and the right side of the\\nline. So in this example, we have you know, a data point on the left a data point on the\\nleft, we have one two that are pretty much on the line. And then we have two that are\\non the right. So this is a pretty good line of best fit, because all of the points are\\nvery close to the line, and they split them evenly. So that\'s kind of how you come up\\nwith a line of best fit. So let\'s say that the equation for this line is something like\\ny equals, let\'s just give it 1.5 and x plus, and let\'s say that value is just 0.5 to make\\nit easy. So this is going to be the equation of our line. Now notice that X and Y don\'t\\nhave a value, that\'s because we need to give the value to come up with one of the other\\nones. So what we can do is we can say if we have either the y value, or we have the x\\nvalue of some point, and we want to figure out, you know where it is on the line, what\\nwe can do is just feed one in do a calculation, and that will actually give us the other value.\\nSo in this instance, let\'s say that, you know, I\'m trying to predict something and I\'m given\\nthe the fact that x equals two, I know that x equals two, and I want to figure out what\\ny would be if x equals two, well, I can use this line to do so. So what I would do is\\nI\'m going to say y equals 1.5 times two plus 0.5. Now all of you quick math majors out\\nthere, give me the value of 3.5. Which means that if x was at two, then I would have my\\ndata point as a prediction here on this line. And I would say okay, so you\'re telling me\\naccess to my prediction is that y is going to be equal to 3.5. Because given the line\\nof best fit for this data set, that\'s where this point will lie on that line. So I hope\\nthat makes sense. You can actually do this the reverse way as well. So if I\'m just given\\nsome y value, say I know that you know my y value is at like 2.7 or something. I could\\nplug that in just rearrange the numbers in this equation and then solve for x. Now obviously,\\nthis is a very basic example, because we\'re just doing all of this in two dimensions,\\nbut you can do this in higher dimensions as well. So actually, most times, what\'s gonna\\nend up happening is you\'re gonna have, you know, like eight or nine input variables,\\nand then you\'re gonna have one output variable that you\'re predicting. Now, so long as our\\ndata points are correlated linearly, in three dimensions, we can still do this. So I\'m going\\nto attempt to show you this actually, in three dimensions, just to hopefully clear some things\\nup because it is important to kind of get a grasp and perspective of the different dimensions.\\nSo let\'s say we have a bunch of data points that are kind of like this. And I\'m trying\\nmy best to kind of draw them in some linear fashion using like all the dimensions here.\\nBut it is hard because drawing in three dimensions on a two dimensional screen is not easy. Okay.\\nSo let\'s say this is kind of like what our data points look like. Now, I would say that\\nthese correlate linearly, like pretty pretty well, they kind of go up in one fashion. And we\\ndon\'t know the scale of this. So this is probably fun. So the line of best fit for this data\\nset, and I\'ll just put my kind of thickness up might be something like this right? Now\\nnotice that this line is in three dimensions, right? This is going to cross our I guess\\nthis is our x, y, and Zed axes. So we have a three dimensional line. Now, the equation\\nfor this line a little bit more complicated, I\'m not going to talk about exactly what it\\nis. But essentially, what we do is we make this line and then we say, Okay, what value\\ndo I want to predict? Do I want to predict y x y Zed. Now, so long as I have two values,\\nso two values, I can always predict the other one. So if I have, you know, the x y of a\\ndata point, that will give me the Zed. And if I have the Zed y, that will give me the\\nx. So so long as you have you know, all of the data points, except one, you can always\\nfind what that point is, based on the fact that, you know, we have this line, and we\'re\\nusing that to predict. So I think I\'m going to leave it at that for the explanation. I\\nhope that makes sense. Again, just understand that we use linear regression when our data\\npoints are correlated linearly. Now, some good examples of linear regression were, you\\nknow, that kind of student predicting the grade kind of thing, you would assume that\\nif someone has, you know, a low grade, then they would finish with a lower grade, and\\nyou would assume if they have a higher grade, they would finish with a higher grade. Now,\\nyou could also do something like predicting, you know, future life expectancy. Now, this\\nis kind of a darker example. But essentially, what you could think of here is, if someone\\nis older, they\'re expected to live, you know, like, not as long. Or you could look at health\\nconditions, if someone is in critical illness condition, and they have a critical illness,\\nthen chances are their life expectancy is lower. So that\'s an example of something that\\nis correlated linearly, essentially, something goes up and something goes down or something\\ngoes up, the other thing goes up. That\'s kind of what you need to think of when you think\\nof a linear correlation. Now the magnitude of that correlation, so you know, how much\\ndoes one go up versus how much one goes down, is exactly what our algorithm figures out\\nfor us, we just need to know to pick linear regression when we think things are going\\nto be correlated in that sense. Okay, so that is enough of the explanation of linear regression.\\nNow, we\'re going to get into actually coding and creating a model. But we first need to\\ntalk about the data set that we\'re going to use in the example we\'re going to kind of\\nillustrate linear regression with. Okay, so I\'m here and I\'m back in the notebook. Now,\\nthese are the inputs, we need to start with to actually start programming and getting\\nsome stuff done. Now, the first thing we need to do is actually install SK learn. Now, even\\nif you\'re in a notebook, you actually need to do this because for some reason, it doesn\'t\\ncome by default with the notebook. So to do this, we just did an exclamation point, pip\\ninstall hyphen, Q, sk learn. Now if you\'re going to be working on your own machine. Again,\\nyou can use PIP to install this. And I\'m assuming that you know to use PIP if you\'re going to\\nbe going along in that direction. Now, as before, since we\'re in the notebook, we need\\nto define we\'re going to use TensorFlow version two point x. So to do that, we\'re going to\\njust, you know, do that up here with the percent sign. And then we have all these imports,\\nwhich we\'re going to be using throughout here. So from future import, absolutely important\\ndivision, print function, Unicode literals. And then obviously, the big ones. So NumPy,\\npandas matplotlib. When we\'re using ipython, we\'re gonna be using TensorFlow. And Yep,\\nso I\'m actually just gonna explain what some of these modules are. Because I feel like\\nsome of you may actually not know. NumPy is essentially a very optimized version of arrays\\nin Python. So what this allows us to do is lots of kind of multi dimensional calculations.\\nSo essentially, if you have a multi dimensional array, which we\'ve talked about before, right\\nwhen we had, you know, those crazy shapes, like 5555 NumPy, allows us to represent data\\nin that form, and then very quickly manipulate and perform operations on it. So we can do\\nthings like cross product dot product, matrix addition, matrix subtraction, element wise,\\naddition, subtraction, you know, vector operations, that\'s what this does. For us. It\'s pretty\\ncomplex, but we\'re going to be using it a fair amount. pandas. Now what pandas does\\nis it\'s kind of a data analytics tool. I almost want to say, I don\'t know the formal definition\\nof what pandas is, but it allows us to very easily manipulate data so you know, loading\\ndata sets, view data sets, cut off specific columns, or cut out rows from our data set,\\nvisualize the data sets. That\'s what pandas does for us. Now, matplotlib is actually a\\nvisualization have kind of graphs and charts. So we\'ll use that a little bit lower when\\nI actually graph some different aspects of our data set, the ipython display. This is\\njust specific for this notebook. It\'s just to clear the output. There\'s nothing crazy\\nwith that. And then obviously, we know what TensorFlow is this crazy import for TensorFlow\\nhere. So compact v2 feature column as FC we\'ll talk about later. But we need something called\\na feature column when we create a linear regression algorithm or model in TensorFlow, so we\'re\\ngoing to use that. Okay. So now that we\'ve gone through all that, we need to start talking\\nabout the data set that we\'re going to use for linear regression. And for this example,\\nbecause what we\'re going to do is, you know, actually create this model and start using\\nit to predict values. So the data set that we\'re going to use, actually, I need\\nto read this because I forget exactly what the name of it is, is the Titanic data set,\\nthat\'s what it is. So essentially, what this does is aimed to predict who\'s going to survive,\\nor the likelihood that someone will survive being on the Titanic given a bunch of information.\\nSo what we need to do is a load in this data set. Now I know this seems like a bunch of\\ngibberish, but this is how we need to load it. So we\'re going to use pandas, so PD dot\\nread CSV from this URL. So what this is going to do is take this CSV file, which stands\\nfor comma separated values, and we can actually look at this if we want, I think, so I said\\nit said Ctrl, click, let\'s see if this pops up. So let\'s actually download this. And let\'s\\nopen this up ourselves and have a look at what it is in Excel. So I\'m going to bring\\nthis up here, you can see that link. And this is what our data set is. So we have our columns,\\nwhich just stand for, you know, what is it the different attributes in our data set of\\nthe different features and labels of our data set, we have survived. So this is what we\'re\\nactually going to be aiming to predict. So we\'re going to call this our label right where\\nour output information. So here, a zero stands for the fact that someone did not survive,\\nand one stands for the fact that someone did survive. Now just thinking about it on your\\nown for a second, and looking at some of the categories we have up here, can you think\\nabout why linear regression would be a good algorithm for something like this? Well, for\\nexample, if someone is a female, we can kind of assume that they\'re going to have a higher\\nchance of surviving on the Titanic, just because of you know, the kind of the way that our\\nculture works, you know, saving woman and children first, right. And if we look through\\nthis data set, we\'ll see that when we see females, it\'s pretty rare that they don\'t\\nsurvive, although as I go through, there is quite a few that didn\'t survive. But if we\\nlook at it, compared to males, you know, there\'s definitely a strong correlation that being\\na female results in a stronger survival rate. Now, if we look at age, right, can we think\\nof how age might affect this? Well, I would assume if someone\'s way younger, they probably\\nhave a higher chance of surviving, because they would be you know, prioritized in terms\\nof lifeboats or whatever it was, I don\'t know much about the Titanic. So I can\'t talk about\\nthat specifically. But I\'m just trying to go through the categories and explain to you\\nwhy we pick this algorithm. Now, number of siblings that one might not be as you know,\\ninfluential, in my opinion, parche. I don\'t actually remember what parche stands for,\\nI think it is like what part, I don\'t know exactly what this column stands for. So unfortunately,\\nI can\'t tell you guys that one. But we\'ll talk about some more the second fare, again,\\nnot exactly sure what fare stands for, I\'m going to look on the TensorFlow website after\\nthis and get back to you guys. And we have a class. So class is what class they were\\non the boat, right? So first class, second class, third class. So you might think someone\\nthat\'s in a higher class might have a higher chance of surviving, we have deck. So this\\nis what deck they were on when it crashed. So unknown is pretty common. And then we have\\nall these other decks, you know, if someone got hit, if someone was standing on the deck\\nthat had the initial impact, we might assume that they would have a lower chance of survival\\nbark to is where they were going, and then are they alone? Yes or no. And this one, you\\nknow, this is interesting, we\'re going to see does this make an effect, if someone has\\na loan is that a higher chance of survival? Is that a lower chance of survival? So this\\nis kind of interesting. And this is what I want you guys to think about is that when\\nwe have information and data like this, we don\'t necessarily know what correlations there\\nmight be. But we can kind of assume there\'s some linear thing that we\'re looking for some\\nkind of pattern, right. Whereas if something is true, then you know, maybe it\'s more likely\\nsomeone will survive. Whereas like, if they\'re not alone, maybe it\'s less likely. And maybe\\nthere\'s no correlation whatsoever. But that\'s where we\'re gonna find out as we do this model.\\nSo let me look actually, on the TensorFlow website and see if I can remember what parche\\nand I guess what fair was. So let\'s go up to the top here. Again, a lot of this stuff\\nis just straight up, copied from the TensorFlow website. I\'ve just added my own stuff to it.\\nYou can see like, I just copied all this. We\'re just bringing it in there. Let\'s see\\nwhat it says about the different columns if it gives us any exact explanations. Okay,\\nso I couldn\'t find what parts were fair stance where for some reason, it\'s on the TensorFlow\\nwebsite, either I couldn\'t really find any information about it. Because no, you know,\\nleave a comment down below. But it\'s not that important. We just want to use this data to\\ndo a test. So what I\'ve done here, we\'ve I\'ve loaded in my data set, and notice that I\'ve\\nloaded a training data set in a testing data set. Now we\'ll talk about this more later.\\nThis is important, I have two different data sets, one to train the model with, and one\\nto test the model with no kind of the basic reason we would do this Because when we test\\nour model for accuracy to see how well it\'s doing, it doesn\'t make sense to test it on\\ndata it\'s already seen, it needs to see fresh data so we can make sure there\'s no bias and\\nthat it hasn\'t simply just memorize the data, you know, that we had. Now, what I\'m doing\\nhere at the bottom with this y train, and this y eval is I\'m essentially popping a column\\noff of this data set. So if I print out the data set here, and I\'m actually I\'m going\\nto show you a cool trick with pandas that we can use to look at this. So I can say df\\ntrain.so, by looking at this by just looking at the head, and we\'ll print this out, I might\\nneed to import some stuff above. We\'ll see if this works or not yet, so I need to just\\ndo these imports. So let\'s install. And let\'s do these imports away for the serrana. Okay,\\nso I\'ve just selected TensorFlow 2.0. We\'re just importing this now should be done in\\none second. And now what we\'ll do is we\'ll print out the data frame here. So essentially,\\nwhat this does is load this into a panda\'s data frame. This is a specific type of object.\\nNow, we\'re not going to go into this specifically. But a data frame allows us to view a lot of\\ndifferent aspects about the data and kind of store it in a nice form, as opposed to\\njust loading it in and storing it in like a list or a NumPy array, which we might do\\nif we didn\'t know how to use pandas, this is a really nice way to do it read CSV loaded\\ninto a data frame object, which actually means we can reference specific columns and specific\\nrows in the data frame. So let\'s run this and just have a look at it. Yep, I got need\\nto print df train dot head. So let\'s do that. And there we go. So this is what our data\\nframe head looks like. Now head, what that does is show us the first five entries in\\nour data set, as well as show us a lot of the different columns that are in it. Now\\nsince we have more than you know, we have a few different columns, it\'s not showing\\nus all of them, it\'s just giving us the dot dot dot. But we can see this is what the data\\nframe looks like. And this is kind of the representation internally. So we have entries\\nzero survived zero survived. One, we have male, female, all that. Now notice that this\\nhas the survived column, okay? Because what I\'m going to do is I\'m going to print the\\ndata frame head again. So df train, dot head, after we run these two lines. Now what this\\nline does is takes this entire survived column, so all these zeros and ones, and removes it\\nfrom this data frame, so the head data frame, and stores it in the variable y train. The\\nreason we need to do that is because we need to separate the data, we\'re going to be classifying\\nfrom the data that is kind of our input information or our initial data set. Right. So since we\'re\\nlooking for the survived information, we\'re gonna put that in its own, you know, kind\\nof variable store here. Now we\'ll do the same thing for the evaluation data set, which is\\ndf evaluation or testing data. And notice that here, this was trained as CSV, and this\\none was eval dot CSV. Now these have the exact same form, they look the look completely identical.\\nIt\'s just that, you know, some entries, we\'ve just kind of arbitrarily split them. So we\'re\\ngonna have a lot of entries in this training set. And we\'ll have a few in the testing set\\nthat we\'ll just used to do an evaluation on the model later on. So we pop them off by\\ndoing this pop removes and returns this column. So if I print out y train, which are actually\\nlet\'s look at this one, first, just to show you how it\'s been removed, we can see that\\nwe have the survived column here, we popped, and now the survived column is removed from\\nthat data set. So it\'s just important to understand. Now we can print out some other stuff too.\\nSo we can look at the Y train, see what that is just to make sure we really understand\\nthis data. So let\'s look at y train. And you can see that we have 626 or 627 entries, and\\njust you know, zeros or ones representing whether someone survived or whether they did\\nnot. Now the corresponding indexes in this kind of list or data frame correspond to the\\nindexes in the testing and training data frame. What I mean by that is, you know, entry zero\\nin this specific data frame, corresponds to entry zero in our y train variable. So if\\nsomeone survived, you know, at entry zero, it would say one here, right, or in this case,\\nentry zero did not survive. Now, I hope that\'s clear. I hope I\'m not confusing you with that.\\nBut I just want to show one more example to make sure. So we\'ll say df train zero, I\'m\\ngoing to print that and then we\'re going to print y train at index zero, oops, if I didn\'t\\nmess up my brackets, and we\'ll have a look at it. Okay, so I\'ve just looked up the documentation,\\nbecause I totally forgot that I couldn\'t do that. If I want to find one specific row in\\nmy data frame, what I can do is print dot look. So I do my data frame, and then dot\\nlook, and then whatever index i want. So in this case, I\'m locating row zero, which is\\nthis. And then on the Y train, I\'m doing the same thing. I\'m locating row zero. Now what\\nI had before, right, if I did df train, and I put square brackets inside here, what I\\ncan actually do is reference a specific column. So if I wanted to look at, you know, say the\\ncolumn for age, right, so we have a column for age, what I can do is do df train age.\\nAnd then I can print this out like this, and it gives me all of the different age values.\\nSo that\'s kind of how we use a data frame. We\'ll see that as we go further on. Now. Let\'s\\ngo back to the other example I had, because I just erased it, where I wanted to show you\\nthe rows zero in the data frame. That\'s training. And then in the y train, you know, output,\\nwhatever that is. So the survival. So you can see here that this is what we get from\\nprinting df train dot loke, zero. So row zero, this is all the information. And then here,\\nthis corresponds to the fact that they did not survive at row zero because it\'s simply\\njust the output is value zero. I know this is weird is saying like name zero D type object\\nzero, don\'t worry about that. It\'s just because it\'s trying to print it with some information.\\nBut essentially, this just means this person who was male 22, and had one sibling did not\\nsurvive. Okay, so let\'s get out of this. Now we can close\\nthis, and let\'s go to Oh, we\'ve pretty much already done what I\'ve just had down here,\\nwe can look at the data frame head, this is a little bit of a nicer output, when we just\\nhave df train dot head, we can see that we get kind of a nice outputted little graph,\\nwe\'ve already looked at this information. So we know kind of some of the attributes\\nof the data set. Now we want to describe the data set, sometimes what describe does is\\njust give us some overall information. So let\'s have a look at it here, we can see that\\nwe have 627 entries, the mean of age is 29, the standard deviation is you know, 12, point,\\nwhatever. And then we get the same information about all of these other different attributes.\\nSo for example, it gives us you know, the mean fair, the minimum fair, and just some\\nstatistics. Because understand this great, if you don\'t doesn\'t really matter, the important\\nthing to look at typically is just how many entries we have, sometimes we need that information.\\nAnd sometimes the mean can be helpful as well, because you can kind of get an average of\\nlike what the average value is in the data set. So if there\'s any bias later on, you\\ncan figure that out. But it\'s not crazy important. Okay, so let\'s have a look at the shape. So\\njust like NumPy arrays, and tensors have a shape attribute. So do data frames. So we\\nwant to look at the shape, you know, we can just print a df train dot shape, we get 627\\nby nine, which essentially means we have 627 rows, and nine columns or nine attributes.\\nSo yeah, this is what it says here, you know, 627 entries, nine features, we can interchange\\nattributes and features. And we can look at the head information for y. So we can see\\nthat here, which we\'ve already looked at before. And that gives us the name, which was survived.\\nOkay, so now what we can actually do is make some kind of graphs about this data. Now I\'ve\\njust stolen this code, you know, straight up from the TensorFlow website, I wouldn\'t\\nexpect you guys to do any of this, you know, like output any of these values, what we\'re\\ngoing to do is create a few histograms and some plots just to look at kind of some correlations\\nin the data so that when we start creating this model, we have some intuition on what\\nwe might expect. So let\'s look at age. So this gives us a histogram of the age. So we\\ncan see that there\'s about 25, people that are kind of between zero and five, there is,\\nyou know, maybe like five people that are in between five and 10. And then the most\\namount of people are kind of in between their 20s, and 30s. So in the mid 20s, this is good\\ninformation to know, because that\'s going to introduce a little bit of bias into kind\\nof our linear correlation graph, right. So just understanding you know that we have like\\na large subset, there\'s some outliers here, like there\'s one person that\'s ad right over\\nhere, a few people that are 70, slim, important things to kind of understand before we move\\non to the algorithm. So let\'s look at the sex values now. So this is how many female\\nand how many male, we can see that there\'s much, many more males on there as females,\\nwe can have a look at the class. So we can see if they\'re in first, second or third class,\\nmost people are in third, then followed by first and then second. And then lastly, we\\ncan look at what is this that we\'re doing Oh, the percentage survival by sex. So we\\ncan see how likely a specific person or specific sex is to survive just by plotting this. So\\nwe can see that males have about a 20% survival rate, whereas females are all the way up to\\nabout 78%. So that\'s important to understand, that kind of confirms that what we were looking\\nat before in the data set when we were exploring it, and you don\'t need to do this every time\\nthat you\'re looking at a data set, but it is good to kind of get some intuition about\\nit. So this is what we\'ve learned. So far, majority passengers are in their 20s, or 30s,\\nthe majority passengers are male, they\'re in third class. And females have a much higher\\nchance of survival kind of already knew that. Alright, so training and testing data sets.\\nNow, we already kind of went through this, so I\'ll skim through it quickly. Something\\nthat we did above is load in two different data sets. The first data set was that training\\ndata set, which had the shape of 627 by nine, what I\'m actually going to do is create a\\ncode block here, and just have a look at what was this df eval dot shape to show you how\\nmany entries we have in here. So here in our testing data set, you can see we have significantly\\nless at 264 entries, or rows, whatever you want to call them. So that\'s how many things\\nwe have to actually test our model. So what we do is we use that training data to create\\nthe model and then the testing data to evaluate it and make sure that it\'s working properly.\\nSo these things are important. Whenever we\'re doing machine learning models, we typically\\nhave testing and training data. And yeah, that is pretty much it. Now I\'m just gonna\\ntake one second to copy over a lot of this code into the kind of other notebook I have\\njust so we can see all of it at once. And then we\'ll be back and we\'ll get into actually\\nmaking the model. Okay, so I\'ve copied in some code here. I\\nknow this seems A lot of kind of gibberish right now, but I\'m gonna break down line by\\nline what all this is doing and why we have this here. But we first need to discuss something\\ncalled the feature columns. And the difference between categorical and numeric data. So get\\ncategorical data is actually fairly common. Now when we\'re looking at our data set, and\\nactually I can open I don\'t have it open in Excel anymore. But let\'s open this from my\\ndownloads. So let\'s downloads where is this train? Okay, awesome. So we have this Excel\\ndata sheet here. And we can see what a categorical data or categorical data is, is something\\nthat\'s not numeric. So for example, unknown see, first third, city and why right, so anything\\nthat has different categories, there\'s going to be like a specific set of different categories,\\nthere could be so for example, for age, kind of the set of values we could have for age\\nwas is numeric, so that\'s different. But for categorical, we can have male or female, and\\nI suppose we could have other but in this data set, we just have mail and we just have\\nfemale. For class, we\'re gonna have first, second third for deck, we can have unknown\\nCA, I\'m sure through all the letters of the alphabet, but that is still considered categorical.\\nNow, what do we do with categorical data? Well, we always need to transform this data\\ninto numbers somehow. So what we actually end up doing is we encode this data using\\ninteger values. So for the example of male and female, what we might say, and this is\\nwhat we\'re gonna do in a second is that female is represented by zero and male is represented\\nby one, we do this because although it\'s interesting to know what the actual class is, the model\\ndoesn\'t care, right female and male, it doesn\'t make a difference to it, it just needs to\\nknow that those values are different or different, or those values are the same. So rather than\\nusing strings and trying to find some way to pass that in and do math with that, we\\nneed to turn those into integers, we turn those into zeros and ones right now for class,\\nright, so first, second, third, you know, you guys can probably assume that we\'re going\\nto encode this with we\'re gonna encode it with 012. Now, again, this doesn\'t necessarily\\nneed to be an order. So a third could be represented by one and first can be represented by two,\\nright? It doesn\'t need to be an order, it doesn\'t matter. So long as every third has\\nthe same number, every first has the same number, and every second has the same number.\\nAnd then same thing with deck. Same thing with embark and same thing with a loan. Now,\\nwe could have an instance where you know, we\'ve encoded every single one of these values\\nwith a different value. So in the, you know, rare occasion where there\'s one category,\\nthat\'s categorical, and every single value in that category is different than we will\\nhave, you know, 627, in this instance, different encoding labels that are going to be numbers,\\nthat\'s fine, we can do that. And actually, we don\'t really need to do that, because you\'re\\ngoing to see how TensorFlow can handle that for us. So those categorical data, numeric\\ncolumns are pretty straightforward. They\'re anything that just have integer or float values\\nalready. So in this case, age and fair. And yeah, so that\'s what we\'ve done. We\'ve just\\ndefined our categorical columns here, and our numeric columns here. This is important,\\nbecause we\'re going to loop through them, which we\'re doing here to create something\\ncalled feature columns. feature columns are nothing special, they\'re just what we need\\nto feed to our linear estimator or linear model to actually make predictions. So kind\\nof our steps here that we\'ve gone through so far, is import, load the data set, explore\\nthe data set, make sure we understand it, create our categorical columns and our numeric\\ncolumns. So I\'ve just hard coded these in right, like sex parch class deck alone, all\\nthese ones. And then same thing with numeric columns. And then for a linear estimator,\\nwe need to create these as feature columns using some kind of advanced syntax, which\\nwe\'re going to look at here. So we create a blank list, which is our feature columns,\\nwhich will just store our different feature columns, we loop through each feature name\\nin the categorical columns. And what we do is we define a vocabulary, which is equal\\nto the data frame at that feature name. So first, we would start with sex, then we go\\nand siblings, then we go parched, then we go class. And we get all of the different\\nunique values. So that\'s actually what this does dot unique gets a list of all unique\\nvalues from the feature code. And I can print this out, she\'ll put this in a different line,\\nwe\'ll just take this value and have a look at actually what this is, right. So if I run,\\nI just will have to run all these in order. And then we\'ll create a new code block while\\nwe wait for that to happen. Let\'s see if we can get this installing fast enough. Run, run, run. Okay, now we go to df train, and we can see\\nthis is what this looks like. So these are all the different unique values that we had\\nin that specific feature name. Now that feature name was what? categorical columns. Oh, what\\nI do feature name of sorry, that\'s gonna be the unique one. Let\'s just put rather than\\nfeature name, let\'s put sex right and let\'s have a look at what this is. So we can see\\nthat the two unique values are male and female. Now I actually want to do what is it embark\\ntown and I want to see what this one is. So how many different values we Um, so we\'ll\\ncopy that in and we can see we have Southampton cannot pronounce that and then the other cities\\nand unknown, and that is kind of how we get the unique value. So that\'s what that method\\nis doing. There. Let\'s actually delete this code block because we don\'t need anymore. Alright, so that\'s what we do. And then when we do down here\\nis we say feature columns dot append. So just add to this list, the TensorFlow feature column\\ndot categorical column with vocabulary list. Now, I know this is a mouthful, but this is\\nkind of something again, you\'re just going to look up when you need to use it, right.\\nSo understand that you need to make feature columns for linear regression, you don\'t really\\nneed to completely understand how, but you just need to know that that\'s something you\\nneed to do. And then you can look up the syntax and understand. So this is what this does,\\nthis is actually going to create for us a column, it\'s going to be in the form of a\\nlike NumPy array, kind of that has the feature name, so whatever one we\'ve looped through,\\nand then all of the different vocabulary associated with it. Now we need this because we just\\nneed to create this column, so that we can create our model using those different columns,\\nif that makes any sense. So our linear model needs to have you know, all of the different\\ncolumns we\'re going to use, it needs to know all of the different entries that could be\\nin that column, and needs to know whether this is a categorical column or a numeric\\ncolumn. In previous examples, what we might have done is actually changed the data set\\nmanually, so encode it manually, TensorFlow just can do this for us now in touch for 2.0.\\nSo we\'ll just use that too. Okay, so that\'s what we did with these feature columns. Now,\\nfor the numeric columns a little bit different, it\'s actually easier, all we need to do is\\ngive the feature name and whatever the data type is, and create a column with that. So\\nnotice, we don\'t we can omit this unique value because we know when it\'s numeric, but you\\nknow, there could be an infinite amount of values. And then I\'ve just printed out the\\nfeature columns, you can see what this looks like. So vocabulary lists, categorical column,\\ngives us the number of siblings, and then the vocabulary list is these are all the different\\nencoding values that is created. then same thing, you know, we go down here parch, these\\nare different encodings. So they\'re not necessarily an order is like what I was talking about\\nbefore. Let\'s go to a numeric one. What do we have here? Um, yeah, so for numeric comm,\\njust as the key, that\'s the shape we\'re expecting, and this is the data type. So that is pretty\\nmuch it. We\'re actually loading these in. So now it\'s almost time to create the model.\\nSo what we\'re going to do to create the model now is talk about first the training process\\nand training some kind of, you know, machine learning model. Okay, so the training process,\\nnow, the training process of our model is actually fairly simple, at least for linear\\nmodel. Now, the way that we train the model is we feed it information, right? So we feed\\nit that those data points from our data set. But how do we do that? Right? Like, how do\\nwe feed that to the model? Do we just give it all at once? Well, in our case, we only\\nhave 627 rows, which isn\'t really that much data, like we can fit that in RAM in our computer,\\nright? But what if we\'re training a crazy machine learning model, and we have, you know,\\n25 terabytes of data that we need to pass it, we can\'t load that into RAM, at least\\nI don\'t know, any ram that\'s that large. So we need to find a way that we can kind of\\nload it in what\'s called batches. So the way that we actually load this model is we load\\nit in batches. Now we don\'t need to understand really kind of how this process works and\\nhow batching kind of occurs, what we do is give 32 entries at once to the model. Now\\nthe reason we don\'t just feed one at a time is because that\'s a lot slower, we can load\\nyou know, a small batch size of 32, that can increase our speed dramatically. And that\'s\\nkind of a lower level understanding. So I\'m not going to go too far into that. Now that\\nwe understand, we kind of load it in batches, right? So we don\'t load it entirely all at\\nonce we just load a specific set of kind of elements as we go. What we have is called\\nepochs. Now, what are epochs? Well, epochs are essentially how many times the model is\\ngoing to see the same data. So what might be the case, right, and then when we pass\\nthe data to our model, the first time, it\'s pretty bad, like it looks at the model creates\\na line of best fit, but it\'s not great, it\'s not working perfectly. So we need to use something\\ncalled an epoch, which means we\'re just going to feed the model feed the data again, but\\nin a different order. So we do this multiple times, so that the model will look at the\\ndata, look at the data in a different way, and then kind of a different form and see\\nthe same data a few different times it pick up on patterns, because the first time it\\nsees a new data point is probably not going to have a good idea how to make a prediction\\nfor that. So we can feed it more and more and more than you know, we can get a better\\nprediction. Now this is where we talk about something called overfitting, though, sometimes\\nwe can see the data too much of the past too much data to our model to the point where\\nit just straight up memorizes those data points. And it\'s it\'s really good at classifying for\\nthose data points, but we pass it some new data points, like our testing data, for example.\\nIt\'s horrible at kind of, you know, classifying those. So what we do to kind of prevent this\\nfrom happening is we just make sure that we start with like a lower amount of epochs and\\nthen we can work our way up and kind of incrementally change that if we need to, you know, go higher,\\nright? We need more epochs. So yeah, so that\'s kind of it for epochs. Now, I will say that\\nthis training process kind of applies to all the different What is it machine learning\\nmodels that we\'re going to look at? We have epochs, we have batches we have a batch size,\\nand now we have something called an input function. Now, this is pretty complicated.\\nThis is the code for the input function. Don\'t like that we need to do this, but it\'s necessary.\\nSo essentially what an input function is, is the way that we define how our data is\\ngoing to be broke into epochs and into batches to feed to our model. Now, these, you probably\\naren\'t ever going to really need to code like from scratch by yourself. But this is one\\nI\'ve just stolen from the tangible website pretty much like everything else that\'s in\\nthe series. And what this does, is it takes our data and encodes it in a TF data data\\nset object. Now this is because our model needs this specific object to be able to work,\\nit needs to see a data set object to be able to use that data to create the model. So what\\nwe need to do is take this panda\'s data frame, we need to turn it into that object. And the\\nway we do that is with the input function. So we can see that what this is doing here.\\nSo this is make input function, we actually have a function defined inside of another\\nfunction. I know this is kind of complicated for some of you guys, but and what I\'m actually\\ngonna do Sorry, I\'m gonna just copy this into the other page, because I think it\'s easier\\nto explain without all the text around. So let\'s create a new code block. let\'s paste\\nthis in. And let\'s have a look at what this does. So actually, let me just tap down. Okay,\\nso make input function. We have our parameters data data frame, which is our panda\'s data\\nframe, our labeled data frame, which stands for those labels. So that y train, or that\\neval, y eval, right? We have number of epochs, which is how many epochs we\'re going to do\\nwe set the default 10 shuffle, which means are we going to shuffle our data and mix it\\nup? Before we pass it to the model in batch size, which is how many elements are we going\\nto give to that to the model? Well, it\'s training at once. Now, what this does is we\\nhave an input function defined inside of this function. And we say data set equals tensor\\nframe dot data dot data set from tensor slices, dict data frame labelled data. Now what this\\ndoes, and we can read the comment, I mean, create a TF data data set object with the\\ndata and its label. Now I can\'t explain to you like how this works on a lower level.\\nBut essentially, we pass a dictionary representation of our data frame, which is whatever we passed\\nin here. And then we pass the label data frame, which is going to be you know, all those y\\nvalues. And we create this object. And that\'s what this line of code does. So TF data data\\nset from tensor slices, which is just what you\'re going to use, I mean, we can read this\\ndocumentation, create a data set whose elements are slices of the given tensors. The given\\ntensors are sliced along the first dimension, this operation preserves the structure of\\nthe input tensors, removing the first dimension of each tensor and using it as the data set\\ndimension. So I mean, you guys can look at that, like read through the documentation,\\nif you want. But essentially, what it does is create the desert object for this. Now,\\nif shuffle, DS equals DS dot shuffle 1000, what this does is just shuffle the data set,\\nyou don\'t really need to understand more than that. And then what we do is we see data set\\nequals data set dot batch, the batch size, which is going to be 32. And then repeat for\\nthe number of epochs. So what this is going to do is essentially take our data set and\\nsplit it into a number of I don\'t want to what do I want to call it, like blocks that\\nare going to be passed to our model. So we can do this by knowing the batch size, it\\nobviously knows how many elements because that\'s the data set object itself, and then\\nrepeat number of epochs. So this can figure out you know, how many one how many blocks\\nDo I need to split it into, to feed it to my model, never returned out a set simply\\nfrom this function here, we\'ll return that data set object, and then on the outside return,\\nwe actually return this function. So what this out exterior function does, and I\'m really\\njust trying to break this down. So you guys understand is make an input function, it literally\\nmakes a function and returns the function object to wherever we call it from. So that\'s\\nhow that works. Now we have a train input function and an eval input function. And what\\nwe need to do to create these images use this function that we\'ve defined above. So we say\\nmake input function, df train, y train, so our data frame for training and our data frame\\nfor the labels of that. So we can see the comment, you know, here we will call the input\\nfunction, right. And then eval train. So it\'s going to be the same thing except for the\\nevaluation. We don\'t need to shuffle the data because we\'re not training it, we only need\\none epoch, because again, we\'re just training it. And we\'ll pass the evaluation data set\\nand the evaluation value from why. Okay, so that\'s it for making the input function. Now,\\nI know this is complicated, but that\'s the way we have to do it. And unfortunately, if\\nyou don\'t understand after that, there\'s not much more I can do, you\'d might just have\\nto read through some of the documentation. Alright, creating the model. We\'re finally\\nhere. I know this has been a while, but I need to get through everything. So linear\\nestimates, we\'re gonna copy this and I\'m just gonna put it in here. And we\'ll talk about\\nwhat this does. So linear underscore, st equals TF dot estimator dot linear classifier, and\\nwe\'re giving it the feature columns that we created up here. So this work was not for\\nnothing. We have this feature column, which defines you know, what is in every single\\nway. What should we expect for our input data, we pass that to a linear classifier object\\nfrom the estimator module from TensorFlow. And then that creates the model for us. Now,\\nthis, again, is syntax. So you don\'t need to memorize, you just need to understand how\\nit works, what we\'re doing is creating an estimator, all of these kind of core learning\\nalgorithms use what\'s called estimators, which are just basic implementations of algorithms\\nin TensorFlow. And again, pass the feature columns. That\'s how that works. Alright, so now let\'s go to training the model. Okay,\\nso I\'m just going to copy this again, I know you guys think I\'m just copying the code back\\nand forth. But I\'m not going to memorize the syntax, I just want to explain to you how\\nall this works. And again, you guys will have all this code, you can mess with it, play\\nwith it, and learn on your own that way. So to train is really easy. All we need to do,\\nI say, linear ESP dot train, and then just give that input function. So that input function\\nthat we created up here, right, which was returned from make input function, like this\\ntrain input function here is actually equal to a function, it\'s equal to a function object\\nitself. If I were to call train underscore input function like this, this would actually\\ncall this function. That\'s how this works in Python, it\'s a little bit of a complicated\\nsyntax, but it\'s how it works, we pass that function here. And then this will use the\\nfunction to grab all of the input that we need and train the model. Now, the result\\nis going to be rather than trained, we\'re going to evaluate right and notice that we\\ndidn\'t store this one in a variable, but we\'re storing the result in a variable, so that\\nwe can look at it. Now clear output is just from what we import above just gonna clear\\nthe console output, because there will be some output while we\'re training, that we\\ncan print the accuracy of this model. So let\'s actually run this and see how this works.\\nThis will take a second. So I\'ll be back once this is done. Okay, so we\'re back, we\'ve got\\na 73.8% accuracy. So essentially, what we\'ve done right is we\'ve trained the model, you\\nmight have seen a bunch of output while you were doing this on your screen. And then we\\nprinted out the accuracy. after evaluating the model. This accuracy isn\'t very good,\\nbut for our first shot this Okay, and we\'re gonna talk about how to improve this in a\\nsecond. Okay, so we\'ve evaluated the data set, we stored that in result, I want to actually\\nlook at what result is because obviously, you can see we\'ve referenced the accuracy\\npart, like, you know, as if this was a Python dictionary. So let\'s run this one more time.\\nI\'m just going to take a second again. So okay, so we printed out results here. And\\nwe can see that we have actually a bunch of different values, we have accuracy, accuracy,\\nbaseline, AUC, and all these different kind of statistical values. Now, these aren\'t really\\ngoing to mean much to you guys. But I just want to show you that we do have those statistics.\\nAnd to access any specific one, this is really just a dictionary object. So we can just reference\\nthe key that we want, which is what we did with accuracy. Now notice, our accuracy actually\\nchanged here, we went to 76. And the reason for this is, like I said, you know, our data\\nis getting shuffled, it\'s getting put in in a different order. And based on the order\\nin which we see data, our model will, you know, make different predictions and be trained\\ndifferently. So if we had, you know, another epoch, right, if I change epochs to say, 11,\\nor 15, our accuracy will change. Now it might go up, it might go down, that\'s something\\nwe have to play with, as you know, our machine learning developer, right, that\'s what your\\ngoal is, is to get the most accurate model. Okay, so now it\'s time to actually use the\\nmodel to make predictions. So up until this point, we\'ve just been doing a lot of work\\nto understand how to create the model, you know what the model is how we make an input\\nfunction, training, testing data, I know a lot, a lot, a lot of stuff. Now to actually\\nuse this model and like make accurate predictions with it is somewhat difficult, but I\'m going\\nto show you how. So essentially, TensorFlow models are built to make predictions on a\\nlot of things at what they\'re not great at making predictions on like one piece of data,\\nyou just want like one passenger to make a prediction for, they\'re much better at working\\nin like large batches of data, that you can definitely do it with one, but I\'m going to\\nshow you how we can make a prediction for every single point that\'s in that evaluation\\ndata set. So right now we looked at the accuracy. And the way we determine the accuracy was\\nby essentially comparing the results that the predictions gave from our model versus\\nwhat the actual results were, for every single one of those passengers. And that\'s how we\\ncame up with an accuracy of 76%. Now, if we want to actually check and get predictions\\nfrom the model and see what those actual predictions are, what we can do is use a method called\\ndot predict. So what I\'m going to do is I\'m going to say, I guess results like this, equals\\nand in this case, we\'re going to do the model name, which is linear ESD dot predict. And\\nthen inside here, what we\'re going to pass is that input function we use for the evaluation.\\nSo just like you know, we need to pass an input function to actually train the model,\\nwe also need to pass an input function to make a prediction. Now this input function\\ncould be a little bit different. We can modify this a bit if we wanted to. But to keep things\\nsimple, we use the same one for now. So what I\'m going to do is just use this eval input\\nfunctions, the one we\'ve already created where we did, you know, one epoch we don\'t need\\nto shuffle because it\'s just the evaluation set. So inside here rindu eval input funk.\\nNow what we need to do though, is convert this to a list, just because we\'re going to\\nloop through it. And I\'m actually going to print out this value. So we can see what it\\nis, before we get to the next step. So let\'s run this and have a look at what we get. Okay,\\nso we get logistics array, we can see all these different values. So we have, you know,\\nthis array with this value, we have probabilities, this value. And this is kind of what we\'re\\ngetting. We\'re getting logistic, all classes, like there\'s all this random stuff. What you\\nhopefully should notice, and I know I\'m just like whizzing through is that we have a dictionary\\nthat represents the predictions. And I\'ll see if I can find the end of the dictionary\\nhere. For every single, what is it prediction. So since we passed, you know, 267 input data\\nfrom this, you know, eval input function, what was returned to us is a list of all of\\nthese different dictionaries that represent each prediction. So what we need to do is\\nlook at each dictionary so that we can determine what the actual prediction was, is what I\'m\\ngoing to do is actually just present do result wandering to result zero, because this is\\na list. So that should mean we can index it. So we actually look at one prediction. Okay,\\nso this is the dictionary of one prediction. So I know this seems like a lot. But this\\nis what we have. This is our prediction. So logistics, we get some array, we have logistic\\nin here in this dictionary, and then we have probabilities. So what I actually want is\\nprobability. Now since what we ended up having was a prediction of two classes, right, either\\nzero or one, we\'re predicting either someone survived, or they didn\'t survive, or what\\ntheir percentage should be, we can see that the percentage of survival here is actually\\n96%. And the percentage that it thinks that it won\'t survive is, you know, 3.3%. So if\\nwe want to access this, what we need to do is click do result at some index, so whatever,\\nyou know, one we want. So we\'re gonna say result. And then here, we\'re going to put\\nprobabilities, so I\'m just going to print that like that. And then we can see the probabilities.\\nSo let\'s run this. And now we see our probabilities are 96, and 33. Now, if we want the probability\\nof survival, so I think I actually might have messed this up, I\'m pretty sure the survival\\nprobability is actually the last one. Whereas like the non survival is the first one because\\nzero means you didn\'t survive, and one means you did survive. So that\'s my bad, I messed\\nthat up. So I actually want their chance of survival, or index one. So if I index one,\\nyou see, we get 3.3%. But if I wanted their chance of not surviving, I would index zero.\\nAnd that makes sense, because zero is, you know, what we\'re looking at like zero represents,\\nthey didn\'t survive, whereas one represents they did survive. So that\'s kind of how we\\ndo that. So that\'s how we get. Now if we wanted to loop through all of these, we could we\\ncould loop through every dictionary, we could print every single probability of each person,\\nwe could also look at that person stats, and then look at their probability. So let\'s see,\\nthe probability of surviving is in this case, you know, 3%, or whatever it was 3.3%. But\\nlet\'s look at the person that we were actually predicting them and see if that makes sense.\\nSo if I go eval are what was it df eval dot Loke. Zero, we print that and then we print\\nthe result, what we can see is that for the person who was male, and 35, that had no siblings,\\ntheir fare was this, they\'re in third class, we don\'t know what deck they were on. And\\nthey were alone, they have a 3.3% chance of survival. Now, if we change this, we could\\ngo like to two, let\'s have a look at this second person and see what their chances survival\\nis, okay, so they have a higher percent chance a 38% chance, they\'re female, they\'re a little\\nbit older. So that might be a reason why their survival rates a bit lower. I mean, we can\\nkeep doing this and look through and see what it is, right? If we want to get the actual\\nvalue, like if this person survived, or if they didn\'t survive. And what I can do is\\nI can print df eval, actually, it\'s not going to be eval, it\'s going to be y underscore eval. Yep. And that\'s going to be dot Loke. Three.\\nNow, this will give us if they survived or not. So actually, in this case, that person\\ndid survive, but we\'re only predicting a 32%. So you can see that that\'s, you know, represented\\nin the fact that we only have about a 76% accuracy. Because this model is not perfect.\\nAnd in this instance, it was pretty bad. It\'s saying they have a 32% chance of surviving,\\nbut they actually get survived. So maybe that should be higher, right? So we could change\\nthis number, and go for four. I\'m just messing around and showing you guys you know how we\\nuse this. So in this one, you know, same thing, this person survived, although, what is it\\nthey only were given a 14% chance of survival. So anyways, that is how that works. This is\\nhow we actually make predictions and look at the predictions, you understand that now\\nwhat\'s happening is I\'ve converted this to a list just because it\'s actually a generator\\nobject, which means it\'s meant to just be looped through rather than just look at it\\nwith a list but that\'s fine. We\'ll use a list and then we can just print out you know, result\\nthat whatever index probabilities and then one to represent their chance of survival.\\nOkay, so that has been it for linear regression. Now, let\'s get into classification. And now\\nwe are on to classification. So essentially classification Is differentiating between,\\nyou know, data points and separating them into classes. So rather than predicting a\\nnumeric value, which we did with regression earlier, so linear regression, and you know,\\nthe percentage survival chance, which is a numeric value, we actually want to predict\\nclasses. So what we\'re going to end up doing is predicting the probability that a specific\\ndata point or a specific entry, or whatever we\'re going to call it is within all of the\\ndifferent classes it could be. So for example, here, we\'re gonna use flowers. So it\'s called\\nthe iris, I think it\'s the iris flower data set, or something like that. And we\'re gonna\\nuse some different properties of flowers to predict what species of flower it is. So that\'s\\na difference between classification and regression. Now, I\'m not going to talk about the specific\\nalgorithm we\'re going to use here for classification, because there\'s just so many different ones\\nyou can use. But yeah, I mean, if you really care about how they work on a lower mathematical\\nlevel, I\'m not going to be explaining that because it doesn\'t make sense to explain it\\nfor one algorithm when there\'s like hundreds, and they all work a little bit differently.\\nSo you guys can kind of look that up. And I\'ll tell you some resources and where you\\ncan find that. I\'m also going to go faster through this example, just because I\'ve already\\ncovered kind of a lot of the fundamental stuff in linear regression. So hopefully, we should\\nget this one done a little bit quicker, and move on to the next kind of aspects in this\\nseries. Alright, so first steps, load TensorFlow, import TensorFlow, we\'ve done that already.\\ndata set, we need to talk about this. So the data set we\'re using is that Iris flowers\\ndata set, like I talked about, and this specific data set separates flowers into three different\\nspecies. So we have these different species. This is the information we have. So sepal,\\nlength, width, petal length, petal width, we\'re going to use that information, obviously,\\nto make the predictions. So given this information, you know, in our final model, can it tell\\nus which one of these flowers it\'s most likely to be? Okay. So what we\'re going to do now\\nis define the CSV call names and the species. So the column names are just going to define,\\nwhat we\'re going to have in our data set is like the headers for the columns. species,\\nobviously, it\'s just the species and we\'ll throw them there. Alright, so now we\'re going\\nto load in our data sets. So this is going to be different every time you\'re kind of\\nworking with models depending on where you\'re getting your data from. And our example, we\'re\\ngoing to get it from Kara\'s, which has kind of been a sub module of TensorFlow has a lot\\nof useful data sets and tools that we\'ll be using throughout the series. But Cara\'s that\\nutils dot get file, again, don\'t really focus on this, just understand what this is going\\nto do is save this file onto our computer as Iris training dot CSV, grab it from this\\nlink. And then what we\'re gonna do down here is load the train and test and again, notice\\nthis training, and this is testing into two separate data frames. So here, we\'re going\\nto use the names of the columns as the CSV column names, we\'re going to use the path\\nas whatever we loaded here, header equals zero, which just means row zero is the header.\\nAlright, so now, we will move down and we\'ll have a look at our data set. So like we\'ve\\ndone before, oh, I\'ve got to run this code first. csv column nips, okay, so we\'ve just,\\nwe\'re just running things in the wrong order here, apparently. Okay, so let\'s look at the\\nhead. So we can see this is kind of what our data frame looks like. And notice that our\\nspecies here are actually defined numerically. So rather than before, when we had to do that\\nthing, where, you know, we made those feature columns, and we converted the categorical\\ndata into numeric data with those kind of weird tensor flow tools. This is actually\\nalready encoded for us. No zero stands for setosa. And then wanting to obviously stand\\nfor these ones, respectively. And that\'s how that works. Now, these I believe, are in centimeters,\\nthe sepal length, petal length, petal width, that\'s not super important. But sometimes\\nyou do want to know that information. Okay, so now we\'re going to pop up those columns\\nfor the species like we did before, and separate that into train y, test y, and then have a\\nlook at the head again. So let\'s do that. And run this. Notice that is gone. Again,\\nwe\'ve talked about how that works. And then these if we want to have a look at them. And\\nactually, let\'s do this, we\'re just having a new block, let\'s say train, underscore,\\ny dot, what is it? dot head? If I could spell head correctly, okay, so we run head, and\\nwe can see, this is what it looks like nothing special. That\'s what we\'re getting. Alright,\\nso let\'s delete that. Let\'s look at the shape\\nof our training data. I mean, we can probably guess what it is already. But we\'re gonna\\nhave shape for because we have four features. And then how many entries do we have? Well,\\nI\'m sure this will tell us. So 120 entries in shape for awesome. That\'s our shape. Okay,\\ninput function. So we\'re moving fast here already, we\'re getting into a lot of the coding.\\nSo what I\'m actually going to do is, again, copy this over into a separate document. And\\nI\'ll be back in a second with all that. Okay, so input function time, we already know what\\nthe input function does, because we used it previously. Now, this input function is a\\nlittle bit different than before, just because we\'re kind of changing things slightly. So\\nhere, we don\'t actually have any. What do you call it? We don\'t have any epochs and\\nour batch size is different. So what we\'ve done here is rather than actually, you know,\\ndefining like make input function, we just have input function like this. And what we\'re\\ngoing to do is a little bit different one passes input function. I\'ll kind of show you\\na little bit more complex. But you can see that we\'ve cleaned this up a little bit. So,\\nexactly, we\'re doing what we do before, we\'re converting this data, which is our features,\\nwhich we\'re passing in here into a data set. And then we\'re passing those labels as well.\\nAnd then if we\'re training, so if training is true, what we\'re going to do is say data\\nset is equal to the data set dot shuffled. So we\'re going to shuffle the information,\\nand then repeat that. And that is all we really need to do, we can do data set dot batch at\\nthe batch size 256, return that, and we\'re good to go. So this is our input function.\\nAgain, these are kind of complicated, you kind of have to just get experience seeing\\na bunch of different ones to understand how to actually make one on your own. From now\\non, don\'t worry about it too much, you can pretty much just copy the input functions\\nyou\'ve created before and modify them very slightly if you\'re going to be doing your\\nown models. But by the end of this, you should have a good idea of how these input functions\\nwork, we will have seen like four or five different ones. And then you know, we can\\nkind of mess with them and tweak them as we go on. But don\'t focus on it too much. Okay,\\nso input function, this is our input function, I\'m not really going to go into much more\\ndetail with that. And now our feature columns. So this is, again, pretty straightforward.\\nFor the feature columns, all we need to do for this is since they\'re all numeric feature\\ncolumns is rather than having to for loops, where we were separating the numeric and categorical\\nfeature columns before, we can just loop through all of the keys in our training data set.\\nAnd then we can append to my feature columns blank list, the feature column dot numeric\\ncolumn, in the key is equal to whatever key we\'ve looped through here. Let me show you\\nwhat this means in case anyone\'s confused. Again, you can see when I print my feature\\ncolumns, we get key equals sepal length, we get our shape, and we get all of that other\\nnice information. So let\'s copy this into the other one, have a look at our output after\\nthis. Okay, so my feature columns for key and train keys. So notice trainers here, train\\nkeys, what that does is actually give us all the columns. So this was a really quick and\\neasy way to kind of loop through all the different columns, although I could have looped through\\nCSV column names and just removed the species column to do that, but again, we don\'t really\\nneed to. So for key and trade keys, my featured columns dot append TF, feature column, numeric\\ncolumn key equals key, this was just gonna create those feature columns,\\nwe don\'t need to do that vocabulary thing. And that dot unique because again, these are\\nall already encoded for us. Okay, awesome. So that was the next step. So let\'s go back\\nhere, building the model. Okay. So this is where we need to talk a bit more in depth\\nof what we\'re actually going to build. So the model for this is a classification model.\\nNow there is like hundreds of different classification models we can use that are pre made in TensorFlow.\\nAnd so far, what we\'ve done with that linear classifier is that\'s a pre made model that\\nwe kind of just feed a little bit of information to, and it just works for us. Now here, we\\nhave two kind of main choices that we can use for this kind of classification tasks\\nthat are pre built in TensorFlow, we have a dnn classifier, which stands for a deep\\nneural network, which we\'ve talked about very vaguely, very briefly, and we have a linear\\nclassifier. Now, a linear classifier works very similarly to linear regression, except\\nit does classification. Rather than regressions, we get actually numeric value, or we get sorry,\\nyou know, the labels like probability of being a specific label, rather than a numeric value.\\nBut in this instance, we\'re actually going to go with deep neural network. Now, that\'s\\nsimply because tensor flow on their website like this is all of this is kind of building\\noff of the TensorFlow website, because all the code is very similar. And I\'ve just added\\nmy own spin and explained things very in depth, they recommend using that deep neural network\\nfor this is a better kind of choice. But typically, when you\'re creating machine learning apps,\\nyou\'ll mess around with different models and kind of tweak them. And you\'ll notice that\\nit\'s not that difficult to change models, because most of the work comes from loading\\nand kind of pre processing our data. Okay, so what we need to do is build a deep neural\\nnetwork with two hidden later, two hidden layers with 30 nodes and 10 hidden nodes each.\\nNow I\'m going to draw out the architecture of this neural network in just one second,\\nbut I want to show you what we\'ve done here. So we said classifier equals TF dot estimator.\\nSo this estimator module just stores a bunch of pre made models from TensorFlow. So in\\nthis case, dnn classifier is one of those, what we need to do is pass our feature columns,\\njust like we did to our linear classifier. And now we need to define the hidden units.\\nNow hidden units is essentially us a building the architecture of the neural network. So\\nlike you saw before, we had an input layer, we had some like middle layers, called our\\nhidden layers in a neural network. And then we had our output layer, I\'m going to explain\\nneural networks in the next module. So this will all kind of click and make sense for\\nnow we\'ve arbitrarily decided 30 nodes in the first hidden layer 10 in the second, and\\nthe number of classes is going to be three. Now that\'s something that we need to decide\\nwe know there\'s three classes for the flowers. So that\'s what we\'ve defined. Okay, so let\'s\\ncopy this and go back to the other page here. And that is now our model. And now it is time\\nto talk about how we can actually train the model which is coming down here. Okay, so\\nI\'m going to copy this. I\'m going to paste it over here. And let\'s just dig through this\\nbecause this is a bit more of a complicated piece of code than we usually use to work\\nwith. I\'m also going to remove these comments just to clean things up in here. So we\'ve\\ndefined the classifier which is it deep neural network classifier, we have our feature columns,\\nhidden units classes. Now to train the classifier, so we have this input function here, this\\ninput function is different than the one we created previously, remember when when we\\nhad previously was like make input whatever function I will continue typing in inside\\nof define another function, it actually returned that function from this function. I know complicated.\\nIf you\'re not a Python kind of Pro, I don\'t expect that to make perfect sense. But here,\\nwe just have a function, right, we do not returning a function from another function,\\nit just one function. So when we want to use this, to train our model, what we do is create\\nsomething called a lambda. Now, a lambda is an anonymous function that can be defined\\nin one line, when you write lambda, what that means is, essentially, this is a function.\\nSo this is a function. And whatever\'s after the colon is what this function does. Now,\\nthis is a one line function. So like if I create a lambda here, right? And I say lambda,\\nprint, hi, and I said, x equals lambda. And I called x like that. This works. This is\\na valid line of syntax. Actually, I want to make sure that I\'m not just like messing with\\nyou when I say that, and that this is actually correct. Okay, so sorry, I just accidentally\\ntrained the model. So I just commented that out. You can see we\'re printing Hi, right\\nat the bottom of the screen. I know, it\'s kind of small, but it does say hi, that\'s\\nhow this works. Okay, so this is a cool thing. If you haven\'t seen this in Python before,\\nthat\'s what a lambda does, allows you to define a function in one line. Now, the thing that\'s\\ngreat about this is that we can say like, you know, x equals lambda, and here put another\\nfunction, which is exactly what we\'ve done with this print function. And that means when\\nwe call x, it will, you know, execute this function, which will just execute the other\\nfunction. So it\'s kind of like a chain where you call x, x is a function. And inside that\\nfunction, it does another function, right? It just like calling a function from inside\\na function. So what is lambda doing here? Well, since we\\nneed the actual function object, what we do is we define a function that returns to us\\na function. So this actually just like it calls this function, when you put this here,\\nnow, there\'s no I can\'t, it\'s very difficult to explain this, if you don\'t really understand\\nthe concept of lambdas. And you don\'t understand the input functions. But just know we\'re doing\\nthis because of the fact that we didn\'t embed another function and return the function object.\\nIf we had done that, if we had done that, you know, input function that we created before\\nwhere we had the interior function, then we wouldn\'t need to do this, because what would\\nhappen is we would return the input function, right like that, which\\nmeans when we passed it into here, it could just call that directly, it didn\'t need to\\nhave a lambda. Whereas here, though, since we need to just put a lambda, we need to define\\nwhat this is. And then and then this works. That\'s just this, there\'s no other way to\\nreally explain this. So yeah, what we do is we create this input function. So we pass\\nwe have train, we have train, why we have training equals true, and then we do steps\\nequals 5000. So this is similar to an epoch, except this is just defining a set amount\\nof steps we\'re going to go through. So rather than saying, like, we\'ll go through the data\\nset 10 times, we\'re just gonna say we\'ll go through the data set until we\'ve hit 5000\\nnumbers like 5000, things that have been looked at. So that\'s what this does with that train.\\nLet\'s run this and just look at the training output. From our model, it gives us some like,\\nthings here, we can kind of see how this is working. Notice that if I can stop here for\\na second, it tells us the current step, it tells us the loss, the lowest, the lower this\\nnumber, the better. And then it tells us global steps per second. So how many steps we\'re\\ncompleting per second. Now at the end here, we get final step, loss of 39, which is pretty\\nhigh, which means this is pretty bad. But that\'s fine. This is kind of just our first\\ntest at training a neural network. So this is just giving us output, while it\'s training\\nto kind of see what\'s happening. Now, in our case, we don\'t really care because this is\\na very small model, when you\'re training models that are massive and take terabytes of data,\\nyou kind of care about the progress of them. So that\'s when you would use kind of that\\noutput, right? And you would actually look at that. Okay, so now that we\'ve trained the\\nmodel, let\'s actually do an evaluation on the model. So we\'re just going to say classifier\\ndot evaluate. And what we\'re going to do is a very similar thing to what we\'ve done here\\nis just past this input function, right, like here with a lambda once again, and reason\\nwe add the lambda when we don\'t have this like, double function going on, like a nested\\nfunction, we need the lambda. And then in here, what we do is rather than passing train\\nand train why we\'re gonna pass test, I believe, and I think it\'s, I just call it test why.\\nOkay, and then for training, obviously, this is false. So we can just set that false like\\nthat. I\'m just gonna look at the other screen to make sure I didn\'t mess this up. Because\\nagain, I don\'t remember the syntax. Yeah, so class classifier, dot evaluate TEST TEST\\nwhy looks good to me. We\'ll take this print statement just so we get a nice output for\\nour accuracy. Okay, so let\'s look at this. Again. We\'re gonna have to wait for this to\\ntrain. But I will show you a way that we don\'t need to wait for this to train Every time\\nand one second, and I\'ll be right back. Okay, so what I\'m actually going to do, and I\'m just kind of paused like\\nthe execution of this code is throw this in the next block under. Because the nice thing\\nabout Google Collaboratory is that I can run this block of code, right, I can train all\\nthis stuff, which is what I\'ll run now while we\'re talking just so it happens. And then\\nI can have another code block kind of below it, which I have here. And it doesn\'t matter,\\nI don\'t need to rerun that block every time I change something here. So if I change something\\nin any lower blocks, I don\'t need to change the upper block, which means I don\'t need\\nto wait for this to train every time I want to do an evaluation on it. Anyways, so we\'ve\\ndone this, we can test we got test y, I just need to change this instead of eval result.\\nActually, I need to say eval underscore result equals classifier dot evaluate, so that we\\ncan actually store this somewhere and get the answer. And that will print this and notice\\nthis happens much, much faster, we get a test accuracy of 80%. So if I were to retrain the model, chances are this\\naccuracy would change, again, because of the order in which we\'re seeing different flowers.\\nBut this is pretty decent, considering we don\'t have that much test data. And we don\'t\\nreally know what we\'re doing right? We\'re kind of just messing around and experimented\\nfor right now. So to get 80% is pretty good. Okay, so actually, what am I doing? We need\\nto go back now and do prediction. So how am I going to predict this for specific flowers.\\nSo let\'s go back to our core learning algorithms. And let\'s go to predictions. Now, I\'ve written\\na script already, just to save a bit of time that allows us to do a prediction on any given\\nflower. So what I\'m going to do is create a new block down here, code block and copy\\nthis function. And now we\'re going to digest this and kind of go through this on our own\\nto make sure this makes sense. But what this little script does is allow the user to type\\nin some numbers, so the sepal, length, width, and I guess, petal length and width, and then\\nit will spit out to you what the predicted class of that flower is. So we couldn\'t do\\na prediction on every single one of our data points, like we did previously. And we already\\nknow how to do that. I showed you that with linear regression. But here, I just wanted\\nto do it on one entry. So what do we do? So I start by creating a\\ninput function, it\'s very basic, we have batch size 256, all we do is we give some features,\\nand we create a data set from those features. That\'s a dict. And then dot batch and the\\nbatch size. So what this is doing is notice we don\'t give any y value, right? We don\'t\\ngive any labels. reason we do we don\'t do that is because when we\'re making a prediction,\\nwe don\'t know the label, right? Like we actually want that the model to give us the answer.\\nSo here, I wrote down the features, I create a predictive dictionary, just cuz I\'m going\\nto add things to it. And then I just prompted here with a print statement, please type numeric\\nvalues as property. So for feature and feature, valid equals true, well, valid Val equals\\ninput feature colon. So this just means what we\'re going to do is for each feature, we\'re\\ngoing to wait to get some valid response. Once we get some valid response, what we\'re\\ngoing to do is add that to our dictionary. So we\'re gonna say predict feature. So whatever\\nthat feature was, so sepal, length, sepal, width, petal length, or pept. petal width\\nis equal to a list that has in this instance, whatever that value was. Now, the reason we\\nneed to do this is because again, the predict method from TensorFlow works on predicting\\nfor multiple things, not just one value. So even if we only have one value, we want to\\npredict for it, we need to put it inside of a list because it\'s expecting the fact that\\nwe will probably have more than one value in which we would have multiple values in\\nthe list, right, each representing a different row or a new flower to make a prediction for,\\nokay, now we say predictions equals classifier dot predict. And then in this case, we have\\ninput function, lambda input function predict, which is this input function up here. And\\nthen we say for prediction dictionaries, because remember, every prediction comes back as a\\ndictionary in predictions, we\'ll say the class ID is equal to whatever the class IDs of the\\nprediction dictionary at zero. And these are simply what? I don\'t know exactly how to explain\\nthis. We\'ll look at in a second, I\'ll go through that. And then we have the probability is\\nequal to the prediction dictionary probabilities of class ID. Okay? Then we\'re going to say\\nprint prediction is we\'re going to do this weird format thing. I just stole this from\\nTensorFlow. And it\'s going to be the species at the class ID and then 100 times probability,\\nwhich will give us actual integer value. We\'re gonna digest this but let\'s run this right\\nnow and have a look. So please type numeric values as prompted. sepal length, let\'s type\\nlike 2.4 sub the width 2.6 petal width, let\'s just say that\'s like 6.5. And yeah, petal\\nwidth like 6.3. Okay, so then it calls this and it says prediction is virginica. I guess\\nthat\'s the the class we\'re going with. And it says that\'s an 83 or 86.3% chance that\\nthat is the prediction. So yeah, that is how that works. So that\'s what this does. I wanted\\nto give a little script I wrote most of this, I mean, I stole some of this from TensorFlow,\\nbut just to show you how you actually predict on one value, so let\'s look at these prediction\\ndictionary because I just want to show you what one of them actually is. So I\'m going\\nto say print pred underscore dict, and then this will allow me to actually walk through\\nwhat class IDs our probabilities are and how I\'ve kind of done this. So let\'s run this\\nup the length scales just go like 1.4 2.3. I don\'t know what these values are going to\\nend up being. And we get prediction is same one with 77.1%, which makes sense because\\nthese values are similar kind of in difference to what I did before. Okay, so this is the\\ndictionary. So let\'s look for what we were looking for. So probabilities, notice we get\\nthree probabilities, one for each of the different classes. So we can actually say what you know\\nthe percentages for every single one of the predictions, then what we have is class IDs.\\nNow, class IDs, what this does is tell us what class ID it predicts is actually the\\nflower right? So here, it says two, which means that this probability is 77%. That\'s\\nat index two in this array, right? So that\'s why this value is two. So it\'s saying that\\nthat class is two, it thinks it\'s class two, like that\'s whatever was encoded in our system\\nis two. And that\'s how that works. So that\'s how I know which one to print out is because\\nthis tells me it\'s class two. And I know for making this list all the way back up here\\nif I could get rid of this output. Whereas when I say species, that number two is virginica,\\nor I guess that\'s how you say. So that is what the classification is. That\'s what the\\nprediction is. So that\'s how I do that. And that\'s how that works. Okay, so I think that\\nis pretty much it for actually classification. So it\'s pretty basic, I\'m\\ngoing to go and see if there\'s anything else that I did for classification in here. Okay,\\nso here, I just put some examples. So here\'s some example input expected classes. So you\\nguys could try to do these if you want. So for example, on this one, sepal, length sepal\\nwidth. So for 5.1 3.3 1.7 and 0.5, the output should be setosa. For 5.9 3.0 4.2 1.5, it\\nshould be this one. And then obviously, this for this, just so you guys can mess with them\\nif you want. But that\'s pretty much it for classification, and now on to clustering.\\nOkay, so now we\'re moving on to clustering. Now, clustering is the first unsupervised\\nlearning algorithm that we\'re going to see in this series. And it\'s very powerful. Now,\\nclustering only works for a very specific set of problems. And you use clustering when\\nyou have a bunch of input information or features, but you don\'t have any labels or open information. Essentially, what clustering does, is finds\\nclusters of like data points, and tells you the location of those clusters. So you give\\na bunch of training data, you can pick how many clusters you want find. So maybe we\'re\\ngoing to be classifying digits, right, handwritten digits, using k means clustering. In that\\ninstance, we would have 10 different clusters for the digits zero through nine, and you\\npass all this information. And the algorithm actually finds those clusters in the data\\nset for you, we\'re gonna walk through an example it\'ll make sense. But I just want to quickly\\nexplain the basic algorithm behind k means is essentially the set of steps because I\'m\\ngoing to walk you through them and with a visual example. So we\'re going to start by\\nrandomly picking k points to place a K centroids. Now a centroid stands for where our current\\ncluster is kind of defined. And we\'ll see in a second, the next step is we\'re going\\nto assign all of the data points to the centroids by distance. So actually, now that I\'m talking\\nabout this, I think it just makes more sense to get right into the example because if I\\nkeep talking about this, you guys are probably just getting be confused, although I might\\ncome back to this just to reference those points. Okay, so let\'s create a little graph like this in\\ntwo dimensions for our basic example. And let\'s make some data points here. So I\'m just\\ngonna make them all red. And you\'re gonna notice that I\'m gonna make this kind of easier\\nfor ourselves by putting them in like their own unique little groups, right? So actually,\\nwe\'ll add one up here, then we can add some down here, and down here. Now the algorithm\\nstarts for K means clustering. And you\'ll understand how this works as we continue by\\nrandomly picking k centroids. I\'m going to denote a centroid by a little filled in triangle\\nlike this. And essentially what these are, is where these different clusters currently\\nexist. So we start by randomly picking K, which is what we\'ve defined. So let me in\\nthis instance, we\'re going to say k equals 3k, centroid, wherever. So maybe we put one,\\nyou know, somewhere like here, you know what I might not bother filling these in, because\\nwe\'re going to take a while, maybe we put one here. Maybe we end up putting one over\\nhere. Now, I\'ve kind of put them close to where the clusters are. But these are going\\nto be completely random. Now what happens next is each group, or each data point, is\\nassigned to a cluster by distance. So essentially, what we do is for every single data point\\nthat we have, we find what\'s known as the Euclidean distance, or it actually could be\\na different distance you\'d use like Manhattan distance if you guys know what that is. To\\nall of the centroids. So let\'s say we\'re looking at this data point here, what we do is find\\nthe distance to all of these different centroids. And we assign this data point to the closest\\ncentroid. So the closest one by distance, now in this instance is looking like it\'s\\ngoing to be a bit of a tie between this centroid and this centroid, but I\'m going to give it\\nto the one on the left. So what we do is we\'re going to say this is now part of this central.\\nSo I\'m calling this like, let\'s just say this is centered one, this is century two, and\\nthis is centroid three, than this now is going to be a part of centroid one because it\'s\\nclosest to centroid one. And we can go through and we do this for every single data point.\\nSo obviously, we know all of these are going to be our ones, right. And we know these are\\ngoing to be our two, so two to two. And then these are obviously going to be our three. Now, I\'m actually just going to add a few\\nother data points, because I want to make this a little bit more sophisticated, almost,\\nif that makes any sense. So add those data points here, we\'ve an add one here. And that\\nwill give these labels. So these ones are close. So I\'m going to say this one to one,\\nI\'m going to say this one\'s two, I know it\'s not closest to it. But just because I want\\nto do that for now. We\'ll say two for that. And we\'ll say three here. Okay, so now that\\nwe\'ve done that we\'ve labeled all these points, what we do is we now move these centroids\\nthat we\'ve defined into the middle of all of their data points. So what I do is I essentially\\nfind it\'s called center of mass, the center of mass between all of the data points that\\nare labeled the same. So in this case, these will be all the ones that are labeled the\\nsame. And I take this centroid, which I\'m going to have to erase, get rid of it here,\\nand I put it right in the middle. So let\'s go back to blue. And let\'s say the middle\\nof these data points ends up being somewhere around here. So we put it in here, and this\\nis what we call center mass. And this again, would be centroid two. So let\'s just erase\\nthis. And there we go. Now we do the same thing with the other centroid. So let\'s remove\\nthese ones, these ones. So for three, I\'m saying it\'s probably going to be somewhere\\nin here. And then for one, our center mass is probably going to be located somewhere\\nabout here. Now what I do is I repeat the process that I just did, and I reassign all\\nthe points now to the closest center. So all these points are labeled one, two, all that,\\nyou know, we can kind of remove their labels, and this is just going to be great me trying\\nto erase the labels, I shouldn\'t have wrote them on top. But essentially, what we do is\\nwe\'re just going to be like reassigning them. So I\'m going to say okay, so this is two,\\nand we just do the same thing as before, find the closest distance. So we\'ll say you know,\\nthese can stay in the same cluster, maybe this one actually here gets changed to one\\nnow, because it\'s closest to centroid one. And we just reassign all these points. And\\nmaybe you know this one. Now, if it was to before, let\'s say like this one\'s one, and\\nwe just reassign them. Now we repeat this process of finding the closest, or assigning\\nall the points that are closest centroid, moving the centroid into the center of mass.\\nAnd we keep doing this until eventually we reach a point where none of these points are\\nchanging which centroid they\'re part of. So eventually, we reach a point where I\'m just\\ngonna erase this and draw like a new graph, because it\'ll be a little bit cleaner. But\\nwhat we have is, you know, like a bunch of data points. So we have some over here, some\\nover here, maybe we\'ll just put some here. And maybe we\'ll do like a k equals, for example,\\nfor this one, and we have all these centroids. And I\'ll just draw these centroids with blue,\\nagain, that are directly in the middle of all of their data points. They\'re like as\\nin the middle as they can get, none of our data points have moved. And we call this now\\nour cluster. So now we have these clusters, we have these centroids, right, we know where\\nthey are. And what we do is when we have a new data point that we want to make a prediction\\nfor or figure out what cluster, it\'s a part of, what we do is we will plot that data points.\\nSo let\'s say it\'s this new data point here, we find the distance to all of the clusters\\nthat exist, and then we assign it to the closest one. So obviously, it would be assigned to\\nthat one. And we can do this for any data point, right. So even if I put a data point\\nall the way over here, well, it\'s closest cluster is this so it gets assigned to this\\ncluster. And my output will be whatever this label of this cluster is. And that\'s essentially\\nhow this works. So you\'re just clustering data points, figuring out which ones are similar.\\nAnd there\'s a pretty basic algorithm, I mean, you draw your little triangle, you find distance\\nfrom every point in the triangle, or to all of the triangles actually. And then what you\\ndo is just simply assign those values to that centroid, you move that centroid to the center\\nof mass, and you repeat this process constantly, until eventually you get to a point where\\nnone of your data points you\'re moving. That means you found the best clusters that you\\ncan, essentially. Now the only thing with this is you do need to know how many clusters\\nyou want for K means clustering, because k is a variable that you need to define, although\\nthere is some algorithms that can actually determine the best amount of clusters for\\na specific data set. But that\'s a little bit beyond what we\'re going to be focused on focusing\\non right now. So that is pretty much clustering. There\'s not really much more to talk about\\nit, especially because we can\'t really code anything for it now. So we\'re going to move\\non to hidden Markov models. Now hidden Markov models are way different than what we\'ve seen\\nso far. We\'ve been using kind of algorithms that rely on data. So like k means clustering,\\nwe gave a lot of data and we don\'t clustered all those data points found those centroids.\\nUse those centroids to find where new data points should be. Same thing with linear regression\\nand classification. Whereas hidden Markov models, we actually deal with probability\\ndistributions. Now, example we\'re going to go into here and kind of I have to do a lot\\nof examples for this, because it\'s a very abstract concept is a basic weather model.\\nSo what we actually want to do is predict the weather on any given day, given the probability\\nof different events occurring. So let\'s say we know, you know, maybe in like a simulated\\nenvironment or something like that this might be an application, that we have some specific things about our\\nenvironment, like we know, if it\'s sunny, there\'s an 80% chance that the next day, it\'s\\ngoing to be sunny again, and a 20% chance that it\'s going to rain. Maybe we know some\\ninformation about sunny days and about cold days. And we also know some information about\\nthe average temperature on those days. Using this information, we can create a hidden Markov\\nmodel that will allow us to make a prediction for the weather in future days, given kind\\nof that probability that we\'ve discovered. Now, you might be like, Well, how do we know\\nthis? Like, how do I know this probability, a lot of the times you actually do know the\\nprobability of certain events occurring, or certain things happening, which makes these\\nmodels really good. But there\'s some times where what you actually do is you have a huge\\ndata set, and you calculate the probability of things occurring based on that data set.\\nSo we\'re not going to do that part, because that\'s just kind of going a little bit too\\nfar. And the whole point of this is just to introduce us to some different models. But\\nin this example, what we will do is use some predefined probability distributions. So let\\nme just read out the exact definition of a hidden Markov model and start going more in\\ndepth. So the hidden Markov model is a finite set of states, each of which is associated\\nwith a generally multi dimensional probability distribution. Transitions among the states\\nare governed by a set of probabilities called transition probabilities. So in a hidden Markov\\nmodel, we have a bunch of states. Now in the example I was talking about with this weather\\nmodel, the states we would have is hot day, and cold day. Now, these are what we call\\nhidden because never do we actually access or look at these states, while we interact\\nwith the model, in fact, when we look at is something called observations. Now, at each\\nstate, we have an observation, I\'ll give you an example of an observation. If it is hot\\noutside team has an 80% chance of being happy. If it is cold outside, Tim has a 20% chance\\nof being happy. That is an observation. So at that state, we can observe the probability\\nof something happening during that state is x, right? Or is y or whatever it is. So we\\ndon\'t actually care about the States. In particular, we care about the observations we get from\\nthat state. Now in our example, what we\'re actually going to do is we\'re going to look\\nat the weather as an observation for the state. So for example, on a sunny day, the weather\\nhas, you know, the probability of being between five and 15 degrees Celsius with an average\\ntemperature of 11 degrees. That\'s like that\'s a probability we can use. And I know this\\nis slightly abstract, but I just want to talk about the data we\'re going to work with here,\\nI\'m going to draw out a little example go through it, and we actually get into the code.\\nSo let\'s start by discussing the type of data we\'re going to use. So typically, in previous\\nones, right, we use like hundreds, if not, like 1000s of entries, or rows or data points\\nfor our models to train for this. We don\'t need any of that. In fact, all we need is\\njust constant values for probability and our What is it transition distributions and observation\\ndistributions. Now, what I\'m going to do is go in here and talk about states observations\\nand transitions. So we have a certain amount of states. Now we will define how many states\\nwe have, we don\'t really care what that state is. So we could have states for example, like\\nwarm cooled, high, low, red, green, blue, you can have as many states as we want, we\\ncould have one state to be honest, although that would be kind of strange to have that.\\nAnd these are called hidden because we don\'t directly observe. Now observations. So each\\nstate has a particular outcome or observation associated with it based on a probability\\ndistribution. So it could be the fact that during a hot day, it is 100% true that Tim\\nis happy. Although in a hot day, we could observe that 80% of the time, Tim is happy,\\nand 20% of the time, he is sad, right? Those are observations we make about each state,\\nand each state will have their different observations and different probabilities of those observations\\noccurring. So if we were just going to have like an outcome for the state, that means\\nit\'s always the same, there\'s no probability that something happens. And in that case,\\nthat\'s just called an outcome because the probability of the event occurring will be\\n100%. Okay, then we have transitions. So each state will have a probability to find the\\nlikelihood of transitioning to a different state. So for example, if we have a hot day,\\nthere\'ll be a percentage chance that the next day will be a cold day and if we have a cold\\nday, there\'ll be a percentage chance of the next day is either a hot day or a cold day.\\nSo we\'re going to go through like the exact what we have for our specific model below.\\nJust understand there\'s a probability that we could transition into a different state.\\nAnd from each state, we can transition into every other state or a defined set of states\\ngiven a certain probability. So I know it\'s a mouthful, I know it\'s a lot. But let\'s go\\ninto a basic drawing example. Because I just want to illustrate like graphically a little\\nbit kind of how this works. In case these are ideas are a little bit too abstract for\\nany of you. Okay, I\'m just pulling out the drawing tablet, just one second here, and\\nlet\'s do this basic weather model. So what I\'m going to do is just simply draw two\\nstates, actually, let\'s do it with some colors, because why not? So we\'re gonna use yellow.\\nAnd this is going to be our hot day, okay, this is going to be our Sun. And then I\'m\\njust going to make a cloud, we\'ll just do like a gray cloud, this will be my cloud.\\nAnd we\'ll just say it\'s gonna be raining over here. Okay, so these are my two states. Now,\\nin each state, there\'s a probability of transitioning to the other state. So for example, in a hot\\nday, we have a, let\'s say, 20% chance of transitioning to a cold day, and we have a 80% chance of\\ntransitioning to another hot day, like the next day, right? Now, in a cold day, we have,\\nlet\'s say, a 30% chance of transitioning to a hot day. And we have in this case, what\\nis that going to be a 70% chance of transitioning to another cold day. Now, on each of these\\ndays, we have a list of observations. So these are what we call states, right? So this could\\nbe s one. And this could be s two, it doesn\'t really matter. Like if we named them or anything,\\nwe just we have two states. That\'s what we know. We know the transition probability.\\nThat\'s what we\'ve just defined. Now we want the observation probability or distribution\\nfor that. So essentially, on a hot day, our observation is going to be that the temperature\\ncould be between 15 and 25 degrees Celsius with an average temperature of let\'s say,\\n20. So we could say observation, right, say, observation. And we\'ll say that the mean,\\nso the average temperature is going to be 20. And then the distribution for that will\\nbe like the minimum value is going to be 15. And the max is going to be 25. So this is\\nwhat we call actually like a standard deviation, I\'m not really going to explain exactly what\\nstandard deviation is, although you can kind of think of it as something like this. So\\nessentially, there\'s a mean, which is the middle point, the most common event that could\\noccur, and at different levels of standard deviation, which is going into statistics,\\nwhich I don\'t really want to mention that much, because I\'m definitely not an expert,\\nwe have a probability of hitting different temperatures as we move to the left and right\\nof this value. So on this curve, somewhere, we have 15. And on this curve to the right,\\nsomewhere, we have 25. Now we\'re just defining the fact that this is where we\'re going to\\nkind of end our curve. So we\'re going to say that, like the probability is in between these\\nnumbers is gonna be in between 15 and 25, with an average of 20. And then our model\\nwill kind of figure out some things to do with that. That\'s as far as I really want\\nto go in standard deviation. And I\'m sure that\'s like a really horrible explanation.\\nBut that\'s kind of the best I\'m going to give you as for right now. Okay, so that\'s our\\nobservation here, our observation over here is going to be similar. So we\'re going to\\nsay mean, on a cold day temperature is going to be five degrees, we\'ll say the minimum\\ntemperature, maybe it\'s going to be something like negative five, and the max could be something\\nlike 15, or like, yeah, I guess a 15. So we\'ll have some distribution. That\'s just what we\\nwant to understand, right. And this is kind of a strange distribution, because we\'re dealing\\nwith what is it standard deviation, although we can just deal with like straight percentage\\nobservations. So for example, it was a 20% chance that Tim is happy, or there\'s an 80%\\nchance that he is, like, those are probabilities that we can have as our observation probabilities\\nin the model. Okay, so there\'s a lot of lingo. There\'s a lot going on, we\'re gonna get into\\nlike a concrete example now. So hopefully, this should make more sense. But again, just\\nunderstand states transitions observations, we don\'t actually ever look at the states,\\nwe just have to know how many we have in the transition probability and observation probability\\nin each of them. Okay. So what I want to say now, though, is what do we even do with this\\nmodel? So once I make this right, once I make this hidden Markov model, what\'s the point\\nof it? Well, the point of it is to predict future events based on past events. So we\\nknow that probability distribution, and I want to predict the weather for the next week.\\nWell, I can use that model to do that. Because I can say, Well, if the current day today\\nis warm, then what is the likelihood that the next day tomorrow is going to be cold,\\nright? And that\'s what we\'re kind of doing with this model. We\'re making predictions\\nfor the future based on probability of past events occurring. Okay. So important stuff.\\nSo let\'s just run this already loaded. Import TensorFlow. And notice that here I\'ve imported\\nTensorFlow probability is TF P. This is because this is a separate module from TensorFlow\\nthat deals with probability. Now we also need TensorFlow to before this hidden Markov model,\\nwe\'re going to use the TensorFlow process. Build the module, not a huge deal. Okay, so whether model. So this is just going\\nto define what our model actually is. So the different parts of it. So this is taken directly\\nfrom the documentation of TensorFlow, you guys can see, you know, where I have all this\\ninformation from, like I\'ve sourced all of it. But essentially, what the model we\'re\\ngoing to try to create is that cold days are encoded by zero and hot days encoded by one,\\nthe first day in our sequence has an 80% chance of being cold. So whatever day we\'re starting\\nout has an 80% chance of being cold, which would mean 20% chance of being one, a cold\\nday has a 30% chance of being followed by hot day, and a hot day is a 20% chance of\\nbeing followed by a cold day, which would mean you know, 70% cold, the cold and 80%,\\nhot hot. On each day, the temperature is normally distributed with mean and standard deviation,\\nzero and five on a cold day and mean and standard deviation 15 and 10. On a hot day. Now, what\\nthat means standard deviation is essentially, I mean, we can read this thing here is that\\non a hot day, the average temperature is 15. That\'s mean, and ranges from five to 25. Because\\nthe standard deviation is 10 of that, which just means 10 on each side, kind of the min\\nmax value. Again, I\'m not in statistics, so please don\'t quote me on any definitions of\\nstandard deviation. I just tried to explain it enough so that you guys can understand\\nwhat we\'re doing. Okay, so what we\'re going to do to model this, and I\'m just\\nkind of going through this fairly quickly, because it\'s pretty easy to really do this\\nis I\'m going to load the TensorFlow probability distributions kind of module and just save\\nthat as TF D. And I\'m just going to do that. So I don\'t need to write TF p dot distributions\\ndot all of this, I can just kind of shortcut it. You\'ll notice I\'m referencing TFT here,\\nwhich just stands for TFP distributions, and TFP is TensorFlow probability. Okay, so my\\ninitial distribution is TensorFlow probability distributions, categorical. And this is probability\\nof 80%. And point percent. Now this refers to point two. So let\'s look at point two,\\nthe first day in our sequence has an 80% chance of being cold. So we\'re saying that, that\'s\\nessentially what this is, the initial distribution of being cold is 80%. And then 20%, after\\ncategorical, it\'s just a way that we can do this distribution. Okay. So transition distribution,\\nwas it TensorFlow probability categorical, the probability is 70%, and 30%, and 20% 80%.\\nNow notice that since we have two states, we\'ve defined two probabilities. Notice since\\nwe have two states, we have defined two probabilities, the probability of landing on each of these\\nstates at the very beginning of our sequence, this is the transition probability referred\\nto points three and four above. So this is what we have here, so called this 30%, chance,\\n20% chance for a hot day. And that\'s what we\'ve defined. So we say this is going to\\nbe cold, then state one, we have 70% chance of being cold there, again, we have 30% chance\\nof going hot day, and then you know, reverse here. Okay, so observation distribution. Now, this one\\nis a little bit different, but essentially, we do TFD dot normal. Now, I don\'t know, I\'m\\nnot gonna explain exactly what all this is. But when you\'re doing standard deviation,\\nyou\'re going to do it like this, where you\'re going to say loke, which stands for your average\\nor your mean, right. So that was their average temperature is going to be zero on a hot day.\\n15. On a cold day, the standard deviation on the cold day is five, which means we range\\nfrom five, or negative five to five degrees. And on a hot day, it\'s 10. So that is going\\nto be we go range from five to 25 degrees, and our average temperature is 15. Now the\\nreason we\'ve added dot here is because these just need to be float values. So rather than\\ninserting integers here, and having potentially type errors later on, we just have flipped.\\nOkay, so the loake argument represents the mean, and the scales, the standard deviation,\\nyeah, exactly what we just defined there. Alright, so let\'s run this, I think we actually\\nalready did. And now we can create our model. So to create the models pretty easy. I mean,\\nall we do is say model equals TensorFlow distribution dot hidden Markov model, give it the initial\\ndistribution, which is equal to initial distribution, transition, distribution, observation, distribution\\nand steps. Now, what is steps will steps is how many days we want to predict for. So the\\nnumber of steps is how many times we\'re going to step through this probability cycle, and\\nrun the model essentially. Now remember, what we want to do is we want to predict the average\\ntemperature on each day, right? Like that\'s what the goal of our example is, is to predict\\nthe average temperature. So given this information, using these observations and using these transitions,\\nwhat we\'ll do is predict that so I\'m going to run this model. What is the issue here?\\ntensor is on hashtag tensor is. Okay, give me one sec. Have a look here, though, I haven\'t\\nhad this issue before. Okay. So after a painful amount of searching on Stack Overflow, and\\nGoogle and actually just reading through more documentation on TensorFlow, I have determined\\nthe issue. So remember, the error was we\'re getting on actually this line here. I think\\nI can see what the output is on this. Okay. Well, this is a different error, but it was\\nthere was an error at this line. Essentially, what was happening is we have a mismatch between\\nthe two versions here. So the most recent version of TensorFlow is not compatible with\\nthe older version of TensorFlow probability, at least in the sense that the things that\\nwe\'re trying to do with it. So I just needed to make sure that I installed the most recent\\nversion of TensorFlow probability. So what you need to do if this is in your notebook,\\nand this should actually work fine for you guys, because this will be updated by the\\ntime you get there. But in case you run into the issue, I\'ll you know, deal with it. But\\nessentially, we\'re going to do select version two point x of TensorFlow, you\'re going to\\nrun this install commands, you\'re gonna install TensorFlow probability, just run this command,\\nthen after you run this command, you\'re going to read need to restart your runtimes, go\\nto runtime and then restart runtime. And then you can just continue on with the script,\\nselect TensorFlow two point x, again, do your imports. And then you know, we\'ll test if\\nit\'s actually going to work for us here, run our distributions, create the model without\\nany issues, this time notice no red text, and then run this final line, which will give\\nyou the output. Now, this is what I wanted to talk about here that we didn\'t quite get\\nto because we were having some bugs. But this is how we can actually kind of run our model\\nand see the output. So what you can do is do model dot mean. So you say mean equals\\nmodel dot mean. And what this is going to do is essentially just calculate, the probability\\nis going to essentially take that from the model. Now, when we have model dot mean, this\\nis what we call, you know, a partially defined tensor. So remember, our tensors were like\\npartially defined computations. Well, that\'s what model dot mean, actually is. That\'s what\\nthis method is. So if we want to get the value of that we actually need to do is create a\\nnew session in TensorFlow, run this part of the graph, which we\'re going to get by doing\\nmean got NumPy. And then we can print that out. So I know this might seem a little bit\\nconfusing, but essentially, to run a session in the new version of TensorFlow, so two point\\nx, or 2.1, or whatever it is, you\'re going to type with tF compat, v1 dot session, as\\nsash. And then I mean, this is really matter what you have here, but whatever you want,\\nand then what I\'m doing is just printing mean NumPy. So to actually get the value from this\\nhere, this variable i called NumPy. And then what it does is print out this array, that\\ngives me the expected temperatures on each day. So we have, you know, three, six, essentially\\n7.5 8.25. And you can see these are the temperatures based on the fact that we start with an initial\\nprobability of starting on a cold day. So we kind of get that here, right, we\'re starting\\nat three degrees. That\'s what it\'s determined we\'re going to start at. And then we have\\nall of these other temperatures as predicting for the next days. Now notice if we recreate\\nthis model, so just rerun the distributions, rerun them and go model dot mean, again, this\\nstays the same, right? Well, because our probabilities are the same, this model is going to do the\\ncalculation the exact same, there\'s not really any training that goes into this. So we get,\\nyou know, very similar, if not the exact same values, I can\'t remember if these are identical.\\nBut that\'s what it looks like to me, I mean, we can run this again, see, we get the same\\none. And we\'ll create the model one more time. And let me just check these values here to\\nmake sure I\'m not lying to you guys. Yes, they\'re the exact same. Okay, so let\'s start\\nmessing with a few probabilities and see what we can do to this temperature and see what\\nchanges we can cause. So if I do 0.5, here, and I do 0.5, for the categorical probability,\\nremember, this refers to points three and four above. So that\'s a cold day has a 30%\\nchance of being followed by a hot day, and then a hot day is 20% chance of being followed\\nby a cold day. So what I\'ve just done now is change the probability to be 50%. So that\\na cold day now has a 50% chance of being followed by a hot day and a 50% chance of being followed\\nby cold day. And let\'s recreate this model. let\'s rerun this, and let\'s see if we get\\na difference. But we do notice this, the temperature now has been is going a little bit higher. Now notice that we get the same starting temperature,\\nbecause that\'s just the average based on this probability that we have here. But if we wanted\\nto potentially start, you know, hotter, we could reverse these numbers, we go 0.2 0.8.\\nlet\'s rerun all of this. And now look at this, what our temperatures are, we start at 12.\\nAnd then we actually drop our temperature down to 10. So that\'s how this hidden Markov\\nmodel works. And this is nice, because you can just tweak the probabilities, this happens\\npretty well instantly. And we can have a look at our output very nicely. So obviously, this\\nis representing the temperature on our like the first day, this would be the second day,\\nthird day, fourth day, fifth, six, seven. And obviously like the more days you go on,\\nthe least accurate This is probably going to be because it\'s just runs off probability.\\nAnd if you\'re going to try to predict, you know, a year in advance, and you\'re using\\nthe weather that you have from, I guess the previous year, you\'re probably not going to\\nget a very accurate prediction. But anyways, these are hidden Markov models. They\'re not\\nlike extremely useful. There\'s some situations where you might want to use something like\\nthis. So that\'s why we\'re implementing them in this course, and showing you how they work.\\nIt\'s also another feature of TensorFlow that a lot of people don\'t talk about receive.\\nAnd, you know, personally, I hadn\'t really heard of hidden Markov models until I started\\ndeveloping this course. So one of these that has been eight for this module. Now, I hope\\nthat this kind of gave you guys a little bit of an idea of how we can actually implement\\nsome of these machine learning algorithms, a little bit of idea of how to work with data,\\nhow we can feed that to a model, the importance between testing and training data. And then\\nobviously, linear regression is when we focused a lot on so I hope you guys are very comfortable\\nwith that algorithm. Then what was the last, the second one we did, I kind of go up to\\nremember exactly the sequence we had here. So classification that was important as well.\\nSo I hope you guys really understood that clustering. We didn\'t go too far into that.\\nBut again, this is an interesting algorithm. And if you need to do some kind of clustering,\\nyou now know of one algorithm to do that, called k means clustering, and you understand\\nhow that works. And now you know, hidden Markov models. So in the next module, we\'re going\\nto start covering neural networks, we now have the knowledge, we need to really dive\\nin there and start doing some cool stuff. And then in the future modules, we\'re going\\nto do deep computer vision, I believe we\'re gonna do chatbots with recurrent neural networks,\\nand then some form of reinforcement learning at the end. So with that being said, let\'s\\ngo to the next module. love everybody, and welcome to module four. Now, in this module\\nof this course, we\'re gonna be talking about neural networks, discussing how neural networks\\nwork, a little bit of the math behind them talking about gradient descent, and back propagation,\\nand how information actually flows to the neural network. And then getting into an example\\nwhere we use a neural network to classify articles of clothing. So I know that was a\\nlot, but that\'s what we\'re gonna be covering here. Now, neural networks are complex, there\'s\\nkind of a lot of components that go into them. And I\'m going to apologize right now, because\\nit\'s very difficult to explain it all at once, what I\'m going to be trying to do is kind\\nof piece things together and explain them in blocks. And then at the end, you know,\\nkind of combine everything together. Now, I will say, in case any of you didn\'t watch\\nthe beginning of this course, I do have very horrible handwriting. But this is the easiest\\nway to explain things to you guys. So bear with me, you know, I\'m sure you\'ll be able\\nto understand what I\'m saying. But it might just be painful to read some of it. Alright,\\nso let\'s get into right away and start discussing what neural networks are and how they work.\\nWell, the whole point of a neural network is to provide, you know, classification or\\npredictions for us. So we have some input information, we feed it to the neural network,\\nand then we want it to give us some output. So if we think of the neural network as this\\nblack box, we have all this input, right, we give all this data to the neural network,\\nmaybe we\'re talking about an image, maybe we\'re talking about just some random data\\npoints, maybe we\'re talking about a data set, then we get some meaningful output. This is\\nwhat we\'re looking at. So if we\'re just looking at a neural network from kind of the outside,\\nwe think of it as this magical black box, we give some input, it gives us some output.\\nAnd I mean, we could call this black box, just some function, right? Where it\'s a function\\nof the input, maps it to some output. And that\'s exactly what a neural network does,\\nit takes input and maps that input to some output, just like any other function, right,\\njust like if you had a straight line like this, this is a function, you know, this is\\nyour line, you know, whatever it is, you get to say y equals like 4x, maybe that\'s your\\nline, you give some input x, and it gives you some value y, this is a mapping of your\\ninput to your output. Alright, so now that we have that down, what is a neural network\\nmade up of? Well, a neural network is made up of layers. And remember, we talked about\\nthe layered representation of data when we talk about neural networks. So I\'m going to\\ndraw a very basic neural network, we\'re going to start with the input layer. The input layer\\nis always the first layer in our neural network. And it is what is going to accept our raw\\ndata. Now what I mean by raw data is whatever data we like want to give to network, whatever\\nwe want to classify whatever our input information is, that\'s what this layer is going to receive\\nin the neural network. So we can say, you know, these arrows represent our input, and\\nthey come to our first input layer. So this means for example, if you had an image\\nand this image, and I\'ll just draw like one like this, let\'s say this is our image, and\\nit has all these different pixels, right? All these different pixels in the image, and\\nyou want to make a classification on this image. Well, maybe it has a width and a height\\nand a classic width and height example is 28 by 28. If you had 28 by 28 pixels, and\\nyou want to make a classification on this image, how many input neurons you think you\\nwould need in your neural network to do this? Well, this is kind of, you know, a tough question,\\nif you don\'t know a lot about neural networks. If you\'re predicting for the image, if you\'re\\ngoing to be looking at the entire image to make a prediction, you\'re going to need every\\nsingle one of those pixels, which is 28 times 28 pixels, which I believe is something like\\n784. I could be wrong on that number, but I believe that\'s what it is. So you would\\nneed 784 input input neurons, that\'s totally fine. That might seem like a big number. But\\nwe deal with massive numbers when it comes to computers. So this really isn\'t that many.\\nBut that\'s an example of you know how you would use a neural network input layer to\\nrepresent an image, you would have 784 input neurons, and you would pass one pixel to every\\nsingle one of those neurons. Now, if we\'re doing an example, where maybe we just have\\none piece of input information, maybe it\'s literally just one number, well, then all\\nwe need is one input neuron. If we have an example where we have four pieces of information,\\nwe would need four input neurons. Right now this can get a little bit more complicated,\\nbut that\'s the basis that I want you to understand is that you know the pieces of input, you\'re\\ngoing to have for Regardless of what they are, you need one input neuron for each piece\\nof that information, unless you\'re going to be reshaping or putting that information at\\ndifferent forms. Okay, so let\'s just actually skip ahead and go to now our output layer.\\nSo this is going to be our output. Now what is our output layer? Well, our output layer\\nis going to have as many neurons and again, the neurons are just representing like a node\\nin the layer as output pieces that we want. Now let\'s say we\'re doing a classification\\nfor images, right. And maybe there\'s two classes that we could represent. Well, there\'s a few\\ndifferent ways we could design our output layer, what we could do is say, okay, we\'re\\ngoing to use one output neuron, this output neuron is going to give us some value, we\\nwant this value to be between zero, and one. And we\'ll say that\'s inclusive. Now, what\\nwe can do now if we\'re predicting two classes, say, okay, so if my open neuron is going to\\ngive me some value, if that value is closer to zero, then that\'s going to be close to\\nzero. If this value is closer to one, it\'s going to be class one, right? And that would\\nmean, we have our training data, right? And we talked about training and testing data,\\nwe give our input, and our output would need to be the value zero, or one because it\'s\\neither the correct class which is zero, right? Or the correct class, which is one. So like\\nour, what am I saying our labels for our training data set would be zero and one, and then this\\nvalue on our output neuron would be guaranteed to be between zero and one, based on something\\nthat I\'m going to talk about a little bit later. That\'s one way to approach it, right,\\nwe have a single value, we look at that value. And based on what that value is, we can determine,\\nyou know what class we predicted not work sometimes. But in other instances, when we\'re\\ndoing classification, what makes more sense is to have as many output neurons as classes\\nyou\'re looking to predict for. So let\'s say we\'re gonna have, you know, like five classes\\nthat were predicting for maybe these three pieces of input information are enough to\\nmake that prediction, well, we would actually have five output neurons, and each of these\\nneurons would have a value between zero and one. And the combination, so the sum of every\\nsingle one of these values would be equal to one. Now, can you think of what this means\\nif every single one of these neurons has a value between zero and one, and their sum\\nis one? What does this look like to you? Well, to me, this looks like a probability distribution.\\nAnd essentially, what\'s going to happen is we\'re gonna make predictions for how strongly\\nwe think each our input information is each class. So if we think that it\'s like class one, maybe we\'ll just\\nlabel these like this, then what we would do is say, Okay, this is going to be 0.9,\\nrepresenting 90%. Maybe this is like 0.001, maybe this is 0.05 0.003, right, you get the\\npoint, it\'s going to add up to one, and this is a probability distribution for our output\\nlayer. So that\'s a way to do it as well. And then obviously, if we\'re doing some kind of\\nregression task, we can just have one neuron and that will just predict some value. And\\nwe\'ll define you know what we want that value to be. Okay. So that\'s my example, for my\\noutput. Now, let\'s erase this. And let\'s actually just go back to one output neuron, because\\nthat\'s what I want to use for this example. Now, we have something in between these layers,\\nbecause obviously, you know, we can\'t just go from input to output with nothing else.\\nWhat we have here is called a hidden layer. Now in neural networks, we can have many different\\nhidden layers, we can add, you know, hidden layers that are connecting to other hidden\\nlayers, and like we could have hundreds 1000s if we wanted to, for this basic example, we\'ll\\nuse one. And I\'ll write this as hidden. So now we have our three layers. Now why is this\\ncalled hidden? reason this is called hidden is because we don\'t observe it. When we\'re\\nusing the neural network, we pass information to the input layer, we get information from\\nthe output layer, we don\'t know what happens in this hidden layer, or in these hidden layers.\\nNow, how are these layers connected to each other? How do we get from this input layer\\nto the hidden layer to the output layer and get some meaningful hope? Well, every single\\nlayer is connected to another layer with something called weights. Now we can have different\\nkind of architectures of connections, which means I could have something like this one\\nconnects to this, this connects to this, this connects to this. And that could be like my\\nconnection kind of architecture, right? We could have another one where this one goes\\nhere. And you know, maybe this one goes here. And actually, after I\'ve drawn this line,\\nnow we get what we\'re gonna be talking about a lot, which is called a densely connected\\nneural network. Now, a densely connected neural network, or a densely connected layer, essentially\\nmeans that it\'s connected to every node from the previous layer. So in this case, you can\\nsee, every single node in the input layer is connected to every single node in the output\\nlayer, or in the hidden layer, my back. And these connections are what we call weights.\\nNow, these weights are actually what the neural network is going to change and optimize to\\ndetermine the mapping from our input to our output. Because again, remember, that\'s what\\nwe\'re trying to do. We have some kind of function, we get some input, it gives us some output.\\nHow do we get that input an output? Well, by modifying these weights, I was a little\\nbit more complex, but this is the starting. So these are the lines that I\'ve drawn are\\nreally just numbers. And every single one of these lines is some numeric value. Typically,\\nthese numeric values are between zero and one, but they can be large they can be negative\\nreally depends on what kind of network you\'re doing and how you\'ve designed it. Now, let\'s\\njust write some random numbers, we\'d have like 0.1, this could be like 0.7, you get\\nthe point, right, we just have numbers for every single one of these lines. And these\\nare what we call the trainable parameters that our neural network will actually tweak\\nand change as we train to get the best possible result. So we have these connections. Now\\nour hidden layers connected to our output layer as well. This is again another densely\\nconnected layer. Because every layer, or every neuron neuron from the previous layer is connected\\nto every neuron from the next layer, if you would like to determine how many connections\\nyou have, what you can do is say there\'s three neurons here, there\'s two neurons here, three\\ntimes two equals six connections. That\'s how that works from layers. And then obviously,\\nyou can just multiply all the neurons together as you go through and determine what that\'s\\ngoing to be. Okay, so that is how we connect these layers, we have these weights, so let\'s\\njust write a W on here. So we remember that those are weights. Now, we also have something\\ncalled biases. So let\'s add a bias here, I\'m going to label this beat. Now biases are a\\nlittle bit different than these nodes, we have regular, there\'s only one bias, and a\\nbias exists in the previous layer to the layer that it affects. So in this case, what we\\nactually have is a bias that connects to each neuron in the next layer from this, right,\\nso it\'s still densely connected. But it\'s just a little bit different. Now notice that\\nthis bias doesn\'t have an arrow beside it, because this doesn\'t take any input information.\\nThis is another trainable parameter for the network. And this bias is just some constant\\nnumeric value, that we\'re going to connect to the hidden layer, so we can do a few things\\nwith it. Now these weights always have a value of one, we\'re going to talk about why they\\nhave a value of one in a second. But just know that whenever a bias is connected to\\nanother layer, or to another neuron, its weight is typically one. Okay, so we have that connected,\\nwe have our bias. And that actually means we have a bias here as well. And this bias\\nconnects to this, notice that our biases do not connect with each other. The reason for\\nthis, again, is they\'re just some constant value. And they\'re just something we\'re kind\\nof adding into the network is another trainable parameter that we can use. Now let\'s talk\\nabout how we actually pass information through the network and why we even use these weights\\nand biases of what they do. So let\'s say we have, I can\'t really think of a good examples,\\nwe\'re just gonna do some arbitrary stuff. Let\'s say we have like a data points, right?\\nx, y, z. And all these data points have some map value, right? There\'s some value that\\nwe\'re looking for for them, or there\'s some class we\'re trying to put them in, maybe we\'re\\nclustering them between, like, red dots and blue dots. So let\'s do that. Let\'s say an\\nXYZ is either a part of the red class, or the blue class, let\'s just do that. So what\\nwe want this opener on to give us is red or blue. So what I\'m going to do is say, since\\nyou just one class, will get this output neuron in between the\\nrange is your own one will say, Okay, if it\'s closer to zero, that\'s red, if it\'s closer\\nto one that\'s blue. And that\'s what we\'ll do for this network. And for this example,\\nnow, our input neurons are going to obviously be x, y, and Zed. So let\'s pick some data point. And let\'s say we have you know,\\nthe value to two. That\'s our data point. And we want to predict whether it\'s red or blue.\\nHow do we pass it through? Well, what we need to do is determine how we can, you know, find\\nthe value of this hidden layer note, we already know the value of this input node. But now\\nwe need to go to the next layer using these connections and find what the value of these\\nnodes are. Well, the way we determine these values is I\'m going to say and I\'ve just said\\nn one, just to represent like this is a node like this is node one, maybe this one should\\nbe node two, is equal to what we call a weighted sum of all of the previous nodes that are\\nconnected to it, if that makes any sense to you guys. So a weighted sum is something like\\nthis, I\'m just gonna write the equation, I\'ll explain it, I\'m gonna say n one is equal to\\nthe sum of not say n equals zero, let\'s say I equals zero to n. In this case, we\'re going\\nto say w i times x i plus b. Now I know this equation looks really mathy and complicated,\\nit\'s really not what this symbol and this equation here means is taking the weighted\\nsum of all the neurons that are connected to this neuron. So in this case, we have neuron\\nx neuron y and neuron Zed connected to N one. So when we take the weighted sum, or we calculate\\nthis, what this is really equal to is the weight at neuron x. So we say w x times the\\nvalue at neuron x, which in this case, is just equal to two right? plus whatever the\\nweight is at neuron y. So in this case, this is w y And then times two, and then you get\\nthe point where we have w Zed, and I\'m trying on the edge of my drawing tablet to write\\nthis, times two. Now, obviously, these weights have some numeric value. Now, when we start\\nour neural network, these weights are just completely random. They don\'t make any sense.\\nThey\'re just some random values that we can use. As the neural network gets better, these\\nweights are updated and changed to make more sense in our network. So right now, we\'ll\\njust leave them as w XWYW. Said, but no, these are some numeric values. So this returns to\\na some value, right, some value, let\'s just call this value v. And that\'s what this is\\nequal to. So V, then what we do is we add the bias. Now remember, the bias was connected\\nwith a weight of one, which means if we take the weighted sum of the bias, right, all we\'re\\ndoing is adding whatever that biases value was. So if this bias value was 100, then what\\nwe do is we add 100. Now I\'ve just written the plus B to explicitly state the fact that\\nwe\'re adding the bias, although it could really be considered as a part of the summation equation.\\nBecause it\'s another connection to the neural net, let\'s just talk about what this symbol\\nmeans for anyone that\'s confused about that. Essentially, this stands for some AI stands\\nfor an index, an N stands for what index we\'ll go up to now, m means how many neurons we\\nhad in the previous layer. And then what we\'re doing here, saying wi xi, so we\'re gonna say\\nweight 0x, zero plus weight 1x, one plus weight 2x. Two is almost like a for loop, we\'re just\\nadding them all together. And then we add the beep. And I hope that makes enough sense.\\nSo that we understand that. So that is our weighted sum, enter bias. So essentially,\\nwhat we do is we go through and calculate these values. So this gets some value, maybe\\nthis values like 0.3, maybe this value seven, whatever it is, and we do the same thing now\\nat our output neuron. So we take the weighted sum of this value times its weight, and then\\nwe take the weighted sum, so this value times its weight, plus the bias, this is given some\\nvalue here, and then we can look at that value and determine what the output of our neural\\nnetwork is. So that is pretty much how that works in terms of the weighted sums, the weights\\nand the biases. Now let\'s talk about the kind of the training process and another thing\\ncalled an activation function. So I\'ve lied to you a little bit, because I\'ve said, I\'m\\njust going to start erasing some stuff. So we have a little bit more room on here. So\\nI\'ve lied to you. And I\'ve said that this is completely how this works. What we\'re missing\\none key feature that I want to talk about, which is called an activation function. Now\\nremember how we want this value to be in between zero and one right at our output layer? Well,\\nright now, we can\'t really guarantee that that\'s going to happen. I mean, especially\\nif we\'re starting with random weights and random biases in our neural network, we\'re\\npassing this information through, we could get to this point here, we could have like\\n700 as our value. That\'s kind of crazy to me, right? We have this huge value, how do\\nwe look at 700 and determine whether this is red or whether this is blue? Well, we can\\nuse something called an activation function. Now I\'m gonna go back to my slides here, whatever\\nwe want to call this, this notebook, just to talk about what an activation function\\nis. And you guys can see you can follow along, I have all the equations kind of written out\\nhere as well. So let\'s go to activation function, which is right here. Okay. So these are some\\nexamples of an activation function. And I just want you to look at what they do. So\\nthis first one is called a rectified linear unit. Now notice that essentially, what this\\nactivation function does is take any values that are less than zero and just make them zero. So any x values that are you know, in\\nthe negative, it just makes their y zero. And then any values that are positive, it\'s\\njust equal to whatever their positive value is. So if it\'s 10, is 10. This allows us to\\njust pretty much eliminate any negative numbers, right? That\'s kind of what rectified linear\\nunit dots. Now 10 H or hyperbolic tangent? What does this do? It\'s actually squishes,\\nour values between negative one and one. So it takes whatever values we have. And the\\nmore positive they are, the closer to one they are, the more negative they are the closer\\nto negative one they are. So can we see why this might be useful, right for a neural network.\\nAnd then last one is sigmoid, what this does is squish our values between zero and one.\\nA lot of people call it like the squishy fire function, because all it does is take any\\nextremely negative numbers and put them closer to zero and any extremely positive numbers\\nand put them close to one any values in between, you\'re going to get some number that\'s kind\\nof in between that based on the equation one over one plus e to the negative Zed, and this\\nis a data set, I guess is equal to that. Okay, so that\'s how that works. So those are some\\nactivation functions. Now, I hope that\'s not too much math for you. But let\'s talk about\\nhow we use them. Right. So essentially, what we do is at each of our neurons, we\'re going\\nto have an activation function that is applied to the output of that neuron. So we take this\\nthis weighted sum plus the bias, and then we apply an activation function to it before\\nwe send that value to the next neuron. So in this case, n one isn\'t actually just equal\\nto this, what n one is equal to is n one is equal to F, which stands for activation function\\nof this equation, right? So say I equals zero w i x i plus b. And that\'s what n ones value\\nis equal to when it comes to this output neuron. So each of these have an activation function\\non them, and two has the same activation function as an one. And we can define what activation\\nfunction we want to apply at each neuron. Now, at our output neuron, the activation\\nfunction is very important, because we need to determine what we want our value to look\\nlike, do we want it between negative one and one? Do we want it between zero and one? Or\\ndo we want it to be some massively large number? Do we want it between zero and positive infinity?\\nWhat do we want, right? So what we do is we pick some activation function for our output\\nneuron. And based on what I said, where we want our values between zero and one, I\'m\\ngoing to be picking the sigmoid function. So sigmoid recall squishes, our values between\\nzero and one. So what we\'ll do here is we\'ll take n one, right, so n one, times whatever\\nthe weight is there. So weight zero, plus n two times weight one plus a bias and apply\\nsigmoid and then this will give us some value between zero and one, then we can look at\\nthat value. And we can determine what the output of this network is. So that\'s great.\\nAnd that makes sense why we would use that on the output neuron, right? So we can squish\\nour value in between some kind of value. So we can actually look at it and determine you\\nknow what to do with it, rather than just having these crazy, and I want to see if I\\ncan make this eraser any bigger. That\'s much better. Okay. So there we go. Let\'s just erase\\nsome of this. And now let\'s talk about why we use the activation function on like an\\nintermediate layer like this. Well, the whole point of an activation function is to introduce\\ncomplexity into our neural network. So essentially, we, you know, we just have these basic weights\\nand these biases. And this is kind of just, you know, like a complex function. At this\\npoint, we have a bunch of weights, we have a bunch of biases. And those are the only\\nthings that we\'re training and the only things that we\'re changing to make our network better\\nknow what an activation function can do, is, for example, take a bunch of points that are\\non the same like plane, right, so let\'s just say these are in some point, if we can apply\\nan activation function of these, where we introduce a higher dimensionality. So an activation\\nfunction like sigmoid that is like a higher dimension function, we can hopefully spread\\nthese points out and move them up or down off the plane in hopes of extracting kind\\nof some different features. Now, it\'s hard to explain this until we get into the training\\nprocess of the neural network. But I\'m hoping this is maybe giving you a little bit of idea,\\nif we can introduce a complex activation function into this kind of process, then it allows\\nus to make some more complex predictions, we can pick up on some different patterns.\\nIf I can see that, you know, when sigmoid or rectified linear unit is applied to this\\noutput, it moves my point opera moves it down or moves it in, like whatever direction and\\nn dimensional space, then I can determine specific patterns I couldn\'t determine in\\nthe previous dimension. That\'s just like if we\'re looking at something in two dimensions.\\nIf I can move that into three dimensions, I immediately see more detail. There\'s more\\nthings that I can look at, right? And I will try to do a good example of why we might use\\nit like this. So let\'s say we have a square right? Like this, right? And I asked you,\\nI\'m like, tell me some information about this square? Well, what you can tell me immediately\\nis you can tell me the width, you can tell me the height. And I guess you could tell\\nme the cover, right? You could tell me has one face, you\\ncould tell me that\'s four vertexes in Tell me a fair amount about the square, you could\\ntell me its area. Now what happens as soon as I extend this square, and I make it into\\na cube? Well, now you can immediately tell me a lot more information, you can tell me\\nyou know the height, or I guess the depth, width, height, depth? Yeah, whatever you want\\nto call it there. You can tell me how many faces it has, you can tell me what color each\\nof the faces are, you can tell me how many vertexes you can tell me if this cube or the\\nsquare this rectangle is uniform or not. And you can pick up on a lot more information.\\nSo that\'s kind of I mean, this is a very oversimplification of what this actually does. But this is kind\\nof the the concept, right is that if we are in two dimensions, if we can somehow move\\nour data points into a higher dimension by applying some function to them, then what\\nwe can do is get more information and extract more information about the data points, which\\nwill lead to better predictions. Okay. So now that we\'ve talked about all this, as I\'m\\ntalking about how neural networks train, and I think you guys are ready for this, this\\nis a little bit more complicated. But again, it\'s not that crazy. Alright, so we talked\\nabout these weights and biases. And these weights and biases are what our network will\\ncome up with and determine to, you know, like, make the network better. So essentially, what\\nwe\'re going to do now is talk about something called a loss function. So as our network\\nstarts, right, the way that we train it just like we\'ve trained other networks, or other\\nmachine learning models is we give it some information, we give it what the expected\\noutput is, and then we just see what the expected output or what the output was from the network\\ncompared to the expected output and modify it like that. So essentially, what we start\\nwith is we say okay, two to two, we say this class is red, which I forget what I labeled\\nthat what as but let\'s just say you Like that was a zero. Okay, so this class is zero. So\\nI want this network to give me a zero for the point two to two. Now this network starts\\nwith completely random weights and completely random biases. So chances are when we get to this output here, we\'re not\\ngoing to get zero, maybe we get some value after applying the sigmoid function that\'s\\nlike 0.7. Well, this is pretty far away from red. But how far away is it? Well, this is\\nwhere we use something called loss function. Now, what a loss function does is calculate\\nhow far away our output was from our expected output. So if our expected output is zero,\\nand our output was your point seven, the loss function is going to give us some value that\\nrepresents like how bad or how good this network was. Now, it tells us this network was really\\nbad, it gives us like a really high loss, then that tells us that we need to tweak the\\nweights and biases more and move the network in a different direction. We\'re starting to\\nget into gradient descent. But let\'s understand the loss function first. So it\'s going to\\nsay if it was really bad, let\'s move it more, let\'s change the weights more drastically,\\nlet\'s change the biases more drastically. Whereas if it was really good, it\'ll be like\\nokay, so that one was actually decent, you only need to tweak a little bit, and you only\\nneed to move this, this and this. So that\'s good. And that\'s the point of this last month,\\nit just calculate some value, the higher the value, the worse our network was. A few examples\\nof loss function. Let\'s go down here cuz I think I had a few optimizer loss back here.\\nmean squared error mean absolute error and hinge loss. Now mean absolute error. You know\\nwhat, let\'s actually just look one up here. So mean, absolute error, and have a look at\\nwhat this is. So images, let\'s pick something, this is mean absolute error. This is the equation\\nfor mean absolute error. Okay, so the summation of the absolute value of y i minus lambda\\nof x i over n. Now, this is kind of complicated, I\'m not going to go into it too much I was\\nexpecting, I was hoping I was gonna get like a better example for mean squared error. Okay,\\nso these are the three loss functions here. So mean squared error mean absolute error\\nhinge loss, obviously, there\'s a ton more that we could use, I\'m not going to talk about\\nwhich how each of these work specifically, I mean, you can look them up pretty easily.\\nAnd also, so you know, these are also referenced as cost function. So cost or loss, you might\\nhear these change these terms kind of interchange, cost and loss essentially mean the same thing.\\nYou want your network to cost the least you want your network to have the least amount\\nof loss. Okay, so now that we have talked about the loss function, we need to talk about\\nhow we actually update these weights and biases. Now, let\'s, let\'s go back to here, because\\nI think I had some notes on it. This is what we call gradient descent. So essentially,\\nthe parameters for our network our weights and biases, and by changing these weights\\nand biases, we will you know, either make the network better or make the network worse,\\nthe loss function will determine if the network is getting better if it\'s getting worse. And\\nthen we can determine how we\'re going to move the network to change that. So this is now\\ngradient descent where the math gets a little bit more complicated. So this is an example\\nof what your neural network function might look like. Now, as you have higher dimensional\\nmath, you have, you know, a lot more dimensions, a lot more space to explore when it comes\\nto creating different parameters and creating different biases and activation functions\\nand all of that. So as we apply our activation functions, we\'re kind of spreading our network\\ninto higher dimensions, which just makes things much more complicated. Now, essentially, what\\nwe\'re trying to do with the neural network is optimize this loss function. This loss\\nfunction is telling us how good it is or how bad it is. So if we can get this loss function\\nas low as possible, then that means we should technically have the best neural network.\\nSo this is our kind of loss functions, like mapping or whatever, what we\'re looking for\\nis something called a global minimum, we\'re looking for the minimum point where we get\\nthe least possible loss from our neural network. So if we start where these red circles are,\\nright, I\'ve just stole this image off Google Images, what we\'re trying to do is move downwards\\ninto this globe, global minimum. And this is the process of called gradient descent.\\nSo we calculate this loss and we use an algorithm called gradient descent, which tells us what\\ndirection we need to move our function to determine our to get to this global minimum.\\nSo it essentially looks where we are, it says this was the loss and it says, Okay, I\'m going\\nto calculate what\'s called a gradient, which is literally just a steepness or a direction.\\nAnd we\'re going to move in that direction. And then the algorithm called brought backpropagation\\nwill go backwards through the network and update the weights and biases so that we move\\nin that direction. I think this is as far as I really want to go because I know this\\nis getting more complicated already, then some of you guys probably can handle on that\\nI can probably explain, but that\'s kind of the basic principle. We\'ll go back to the\\ndrawing board and we\'ll do a very quick recap before we get into some of the other stuff,\\nneural networks, input, output, hidden layers connected with weights, there\'s biases that\\nconnect to each layer. These biases can be thought of as Y intercepts, they\'ll simply\\nmove completely up or move completely down that entire, you know, activation function,\\nright, we\'re shifting things left or right, because this will allow us to get a better\\nprediction and have another parameter that we can train and add a little bit of complexity\\nto our neural network model. Now, the way that information is passed through these layers\\nis we take the weighted sum out of neurons of all of the connected neurons to it, we\\nthen add this bias neuron, and we apply some activation function that\'s going to put this\\nyou know, these values in between two set values. So for example, when we talk about\\nsigmoid that\'s going to squish our values between zero and one, when we talk about hyperbolic\\ntangent, that\'s going to squish our values between negative one and one. And when we\\ntalk about rectified linear unit, that\'s gonna squish our values between zero and positive\\ninfinity. So we apply those activation functions, and then we continue the process. So n, one\\ngets its value, and two gets its value. And then finally, we make our way to our output\\nlayer, we might have passed through some other hidden layers before that. And then we do\\nthe same thing. We take the weighted sum, we add the bias, we apply an activation function,\\nwe look at the output, and we determine whether we know we are a class Why are we are classes\\nthat are whether this is the value we\'re looking for. And, and that\'s how it works. Now we\'re\\nat the training process, right? So we\'re doing this now, that\'s kind of how this worked when\\nwe were making a prediction. So when we\'re training, essentially, what happens is we\\njust make predictions, we compare those predictions to whatever these expected values should be\\nusing this loss function, then we calculate what\'s called a gradient, a gradient is the\\ndirection we need to move to minimize this last function. And this is where the Advanced\\nMath happens and why I\'m kind of skimming over this aspect. And then we use an algorithm\\ncalled back propagation where we step backwards through the network, and update the weights\\nand biases according to the gradient that we calculated. Now, that is pretty much how\\nthis works. So you know, the more info we have, likely, unless\\nwe\'re overfitting, but, you know, if we have a lot of data, if we can keep feeding the\\nnetwork, it starts off being really horrible, having no idea what\'s going on. And then as\\nmore and more information comes in, it updates these weights and biases gets better and better\\nsees more examples. And after, you know, certain amount of epochs or certain amount of pieces\\nof information, our network is making better and better predictions and having a lower\\nand lower loss. And the way we will calculate how well our network is doing is by passing\\nit, you know, our validation data set where it can say, okay, so we got an 85% accuracy\\non this data set, we\'re doing okay, you know, let\'s tweak this, let\'s tweak that, let\'s\\ndo this. So the loss function, the lower this is, the better also known as the cost function.\\nAnd that is kind of neural networks. In a nutshell. Now, I know this wasn\'t really in\\na nutshell, because it was 30 minutes long. But that is, you know, as much of an explanation\\nas I can really give you without going too far into the mathematics behind everything.\\nAnd again, remember the activation function is to move us up in dimensionality, the bias\\nis another layer of complexity and a trainable parameter for our network allows us to shift\\nthis kind of activation function left, right up, down. And yeah, that is how that works.\\nOkay, so now we have an optimizer. This is kind of the last thing on how neural networks\\nwork optimizer is literally just the algorithm that does the gradient descent and back propagation\\nfor us. So I mean, you guys can read through some of them here, we\'ll be using probably\\nthe atom optimizer for most of our examples, although there\'s you know, lots of different\\nones that we can pick from now the this optimization technique, again, it\'s just a different algorithm.\\nThere\'s some of them are faster, some of them are slower, some of them work a little bit\\ndifferently. And we\'re not really going to get into picking optimizers in this course,\\nbecause that\'s more of an advanced machine learning technique. Alright, so enough explaining\\nenough math enough drawings, enough talking now it is time to create our first official\\nneural network. Now, these are the imports we\'re going to need. So import TensorFlow\\nas TF TF from TensorFlow import Kerris again. So this does actually come with TensorFlow,\\nI forget if I said you need to install that before, my apologies and then import NumPy\\nas NP import matplotlib.pi plot as PLT. Alright, so I\'m going to do actually similar\\nthing to what I did before, I\'m kind of just gonna copy some of this code into another\\nnotebook, just to make sure that we can look at everything\\nat the end, and then kind of step through the code step by step rather than all the\\ntext going to happen here. Alright, so the data set, and the problem we are going to\\nconsider for our first neural network is the fashion amnesty data set. Now the fashion\\neminence data set contains 60,000 images for training and 10,000 images for validating\\nand testing 70,000 images, and it is essentially pixel data of clothing articles. So what we\'re\\ngoing to do to load in this data set from Kara\'s the section built into Kara as its\\nmentors Like a beginner, like testing training data set, we\'re gonna say fashion underscore\\ngymnast equals Kara\'s dot data sets dot fashion feminist. Now this will get the data set object.\\nAnd then we can load that object by doing fashion m this dot load data. Now by doing\\nthis by having the topples, train images, train labels, test images, test labels equals\\nthis, this will automatically split our data into the sets that we need. So we need the\\ntraining. And we need the testing. And again, we\'ve talked about all that. So I\'m going\\nto kind of skim through that. And now we have it in all of these kind of topples here. Alright,\\nso let\'s have a look at this data set to see what we were working with. Okay, so let\'s\\nrun some of this code. Let\'s get this import going. If it doesn\'t take forever, okay, let\'s\\nget the data set. Yeah, this will take a second to download for you guys, if you don\'t already\\nhave a cached. And then we\'ll go train images dot shape. And let\'s look at what one of the\\nimages looks like. or sorry, what our data set looks like. So we have 60,000 images that\\nare 28 by 28. Now, what that means is we have 28 pixels, or 28 rows of 28 pixels, right?\\nSo that\'s kind of what our, you know, information is. So we\'re going to have in total 784 pixels,\\nwhich I\'ve denoted here. So let\'s have a look at one pixel. So to reference one pixel, this\\nis what I what I\'m doing this comes in as a Actually, I\'m not sure what type of data\\nframe this is, but let\'s have a look at it. So let\'s say type of train underscore images,\\nbecause I want to see that. So that\'s an NumPy array. So to reference the different indexes\\nin this is similar to pandas, we\'re just going to do zero comma 23, comma 23, which stands\\nfor you know, image zero, 23, and then 23. And this gives us one pixel. So row 23, column\\n23, which will be that. Okay, so let\'s run this. And let\'s see, this value is 194. Okay,\\nso that\'s kind of interesting. That\'s what one pixel looks like. So let\'s look at what\\nmultiple pixels look like. So we\'ll print, train underscore images. And okay, so we get\\nall these zeros. let\'s print train images, zero colon, that should work for us. And we\'re\\ngetting all these zeros. Okay, so that\'s the border of the picture. That\'s okay, I can\'t\\nshow you what I wanted to show you anyways, one pixel, and I wanted to have you guys guess\\nit is simply just represented by a number between zero and 255. Now what this stands\\nfor is the grayscale value of this pixel. So we\'re dealing with grayscale images, although\\nwe can deal with, you know, 3d 45 D images as well, or not five D images, but we can\\ndeal with images that have like RGB values for so for example, we could have a number\\nbetween zero to 55, another number between zero and 255, and another number between zero\\nand 255 for every single pixel, right? whereas this one is just one simple static value.\\nOkay, so it sounds like your pixel values between zero and 205, zero being black and\\n255 being white. So essentially, you know, it\'s 255, that means that this is white. If\\nit\'s zero, that means that it is black. Alright, so let\'s have a look at the first 10 training\\nlabels. So that was our training images. Now, what are the training labels? Okay, so we\\nhave an array and we get values from zero to nine. Now, this is because we have 10 different\\nclasses that we could have for our data set. So there\'s 10 different articles of clothing\\nthat are represented, I don\'t know what all of them are, although they are right here.\\nSo t shirt, trouser, pullover, dress coat, sandal shirt, sneaker bag, ankle boots. Okay,\\nso let\'s run this class names, just so that we have that saved. And now what I\'m going\\nto do is just use matplotlib to show you what one of the images looks like. So in this case,\\nthis is a shirt. I know this is printing out kind of weird, but I\'m just showing the image.\\nI know it\'s like different colors. But that\'s because if we don\'t define that we\'re drawing\\nit grayscale, it\'s going to do this. But anyways, that is what we get for the shirt. So let\'s\\ngo to another image. And let\'s have a look at what this one is. I actually don\'t know\\nwhat that is. So we\'ll skip that. Maybe that\'s a What is it? t shirt or top? This I guess\\nis gonna be like a dress. Yeah, so we do have dress there. Let\'s go for Have a look at this. Again, some of these are like hard to even\\nmake out when I\'m looking at the myself. And then I guess this will be like a hoodie or\\nsomething. I\'m trying to get one to sandal to show you guys a few different ones. There\\nwe go. So that is a sandal or a sneaker. Okay, so that is kind of how we do that and how\\nwe look at the different images. So if you wanted to draw it out, all you do is just\\nmake a figure, you just show the image, do the color bar, which is just giving you this,\\nthen you\'re gonna say I don\'t want to grid and then you can just show the image, right?\\nBecause if you don\'t have this line here, and you show with the grid, oh, it\'s actually\\nnot showing the grid. That\'s interesting. Although I thought it was going to show me\\nthose pixel grid, so I guess you don\'t need that line. Alright, so data pre processing.\\nAlright, so this is an important step in neural networks. And a lot of times when we have\\nour data, we have it in these like random forms or we\'re missing data. There\'s information\\nwe don\'t know or that we haven\'t seen and typically what we need to do is pre processing.\\nNow what I\'m going to do here is squish all my values between zero and one. Typically, it\'s a good idea to get all of your input values\\nin a neural network in between, like that range in between, I would say negative one,\\nand one is what you\'re trying to do, you\'re trying to make your numbers as small as possible\\nto feed to the neural network. The reason for this is your neural network starts out\\nwith random weights and biases that are in between the range zero and one, unless you\\nchange that value. So if you have massive input information and tiny weights, then you\'re\\nkind of having a bit of a mismatch. And you\'re going to make it much more difficult for your\\nnetwork to actually classify your information. Because it\'s going to have to work harder\\nto update those weights and biases to reduce how large those values are going to be, if\\nthat makes any sense. So it usually is a good idea to pre process these and make them in\\nbetween the value of zero and one. Now, since we know that we\'re just going to have pixel\\nvalues that are in the range of 255, we can just divide by 255. And that will automatically\\nscale it down for us. Although it is extremely important that we do this to not only the\\ntraining images, but the testing images as well. If you just pre process, your training\\nimages, and then you pass in, you know, new data that\'s not pre processed, that\'s going\\nto be huge issue, you need to make sure that your data comes in the same form. And that\\nmeans when we\'re using the model to to make predictions, whatever, you know, I guess it\\npixel data we have, we need to pre process in the same way that we pre processed our\\nother data. Okay, so let\'s pre process that. So train images, and test images. And I\'m\\njust going to actually steal some of the stuff here and throw it in my other one before we\\nget too far. So let\'s get this data set. And let\'s throw it in here, just so we can come\\nback and reference all of this together. Let\'s go class names. We don\'t actually need the\\nfigures, a few things I can skip, we do need this pre processing step like that. If I could\\ngo over here, and then what else do we need, we\'re going to need this model. Okay, so let\'s\\nactually just copy the model into this and just make it a little bit cleaner. I\'m gonna\\nhave a look at it. So new codeblock model. Okay, so model, creating our model. Now creating\\nour model is actually really easy. I\'m hoping what you guys have realized so far is that\\ndata is usually the hardest part of machine learning and neural networks, getting your\\ndata in the right form the right shape, and you know, pre processed correctly. Building\\nthe model is usually pretty easy, because we have tools like TensorFlow, and Caris that\\ncan do it for us. So we\'re gonna say model equals Kara\'s dot sequential. Now, sequential\\nsimply stands for the most basic form of neural network, which we\'ve talked about so far,\\nwhich is just information going from the left side to the right side, passing through the\\nlayers, sequentially, right called sequential, we have not talked about recurrent or convolutional\\nneural networks yet. Now what we\'re going to do here is go Kara\'s dot layers dot flat.\\nSo sorry, inside here, we\'re going to define the layers that we want in our neural network.\\nThis first layer is our input layer. And what flatten does is allows us to take in a shape\\nof 28 by 28, which we\'ve defined here, and flatten all of the pixels into 784 pixels.\\nSo we take this 28 by 28, kind of matrix like structure, and just flatten it out. interiors\\nwill do that for us, we don\'t actually need to take our you know, matrix data in transform\\nbefore passing. So we\'ve done that. Next we have Kara\'s dot layers dot dense 128. activation\\nequals rectified linear unit. So this is our first hidden layer, layer two, right? That\'s\\nwhat I\'ve denoted here. And this is a dense layer. Now dense again means that all of the\\nWhat is it, the neurons in the previous layer are connected to every neuron in this layer.\\nSo we have 828 neurons here, how do we pick that number? We don\'t know, we kind of just\\ncame up with it. Usually, it\'s a good idea that you\'re going to do this as like a little\\nbit smaller than what your input layer is, although sometimes it\'s going to be bigger,\\nyou know, sometimes it\'s going to be half the size really depends on the problem, I\\ncan\'t really give you a straight answer for that. And then our activation function we\'ll\\ndefine as rectified linear unit. Now we could pick a bunch of different activation functions,\\nthere\'s time, we could pick sigma, and we could pick tan h, which is hyperbolic tangent,\\ndoesn\'t really matter. And then we\'re going to define our last layer, which is our output\\nlayer, which is a dense layer of 10 output neurons with the activation of softmax. Okay,\\nso can we think of why we would have picked 10? Here, right, I\'ll give you guys a second\\nto think about it. based on the fact that our output layer, you know, is supposed to\\nhave as many neurons as classes, we\'re going to predict four. So that is exactly what we\\nhave 10. If we look, we have 10 classes here. So we\'re going to have 10 output neurons in\\nour output layer. And again, we\'re going to have this probability distribution. And the\\nway we do that is using the activation function softmax. So soft, Max will make sure that\\nall of the values of our neurons add up to one and that there are between zero and one.\\nSo that is our, our model. We\'ve created the model now. So let\'s actually run this See, you\'re gonna\\nget any errors here, it\'s just going to run. And then we\'ll run the model. And then we\'ll\\ngo on to the next step, which is actually going to be training and testing the model.\\nOkay, so let\'s create the model now shouldn\'t get any issues, and we\'re good. And now let\'s\\nmove on to the next step. I\'m forgetting what it is, though, which is train the model. Oh,\\nsorry, compiling the model. Okay, so to compiling the model. So we\'ve built now what we call\\nthe architecture of our neural network, right, we\'ve defined the amount of neurons in each\\nlayer, we\'ve defined the activation function, and we define the type of layer and the type\\nof connections. The next thing we need to pick is the optimizer the loss and the metrics\\nwe\'re going to be looking at. So the optimizer we\'re going to use is atom. This is, again,\\njust the algorithm that performs the gradient descent, you don\'t really need to look at\\nthese too much, you can read up on some different activation functions, or sorry, optimizers,\\nif you want to kind of see the difference between them, but it\'s not crazy, we\'re going\\nto pick a loss. So in this case, sparse categorical cross entropy, again, not going to go into\\ndepth about that you guys can look that up if you want to see how it works, and then\\nmetrics. So what we\'re looking for the output that we want to see from the network, which\\nis accuracy. Now from, you know, kind of right now, with our current knowledge, we\'re just\\ngoing to stick with this as what we\'re going to compile our neural networks with, we can\\npick different values if we want. And these are what we call, what is it hyper parameter\\ntuning. So the parameters that are inside here, so like the weights, and the biases\\nare things that we can\'t manually change. But these are things that we can change, right,\\nthe optimizer, the loss, the metrics, the activation function, we can change that. So\\nthese are called hyper parameters. Same thing with the number of neurons in each layer.\\nSo hyper parameter tuning is a process of changing all of these values, and looking\\nat how models perform with different hyper parameters change. So I\'m not really going\\nto talk about that too much. But that is something to note, because you\'ll probably hear that,\\nyou know, this hyper parameter kind of idea. Okay, so we\'ve compiled the model now using\\nthis, which just means we picked all the different things that we need to use for it. And now\\non to training the model. So I\'m just gonna copy this in. Again, remember, this, these\\nparts are pretty syntactically heavy, but fairly easy to actually do. So we\'re going\\nto fit the model. So fit just means we\'re fitting it to the training data, it\'s another\\nword for training, essentially. So we\'re going to pass it the training images, the training\\nlabels, and notice how much easier it has to pass this. Now, we don\'t need to do this\\ninput function, we don\'t need to do all of that, because Kerris can handle it for us.\\nAnd we define our epochs as 10 epochs is another hyper parameter that you could tune and change\\nif you wanted to. Alright, so that will actually fit our model. So what I\'m going to do is\\nput this in another code block, so I don\'t need to keep retraining this. So we\'ll go\\nlike that. And let\'s actually look at this training process. So we run the model, this\\nshould compile and now let\'s fit it and let\'s see what we actually end up getting. Alright,\\nso epoch one, and we can see that we\'re getting a loss, and we\'re getting accuracy printing\\nout on the side here. Now this was going to take a second like this is going to take a\\nfew minutes, as opposed to our other models that we made or not a few minutes. But you\\nknow, a few seconds, when you have 60,000 images, and you have a network that\'s comprised\\nof 784 neurons, 128 neurons, and then 10 neurons, you have a lot of weights and biases and a\\nlot of math that needs to go on. So this will take a few seconds to run. Now, if you\'re\\non a much faster computer, you\'ll probably be faster than this. But this is why I like\\nGoogle Collaboratory. Because you know, this isn\'t using any of my computer\'s resources\\nto train. It\'s using this. And we can see, like the RAM and the disk. How do I look at\\nthis in this network? Oh, is it in? Let me look at this now. Okay, I don\'t know why it\'s\\nnot letting me click this. But usually you can have a look at it. And now we\'ve trained\\nand we\'ve fit the model. So we can see that we had an accuracy of 91%. But the thing is,\\nthis is the accuracy, or testing or our training data. So now if we want to find what the true\\naccuracy is, what we need to do is actually test it on our testing data. So I\'m going\\nto steal this line of code here. This is how we test our model. Pretty straightforward.\\nI\'ll just close this. Let\'s go to new code block. So we have test last test accuracy\\nis model dot evaluate test images, test labels, verbose equals one. Now what is verbose? I\\nwas hoping it was gonna give me the things so I could just read it to you guys. But verbose\\nessentially, is just are we looking at output or not? So like, how much information are\\nwe seeing as this model evaluates? It\'s like how much is printing out to the console? That\'s\\nwhat that means. And yes, this will just split up kind of the metrics that are returned to\\nthis into test loss and test accuracy. So we can have a look at. Now, you will notice\\nwhen I run this, that the accuracy will likely be lower on this than it was on our model.\\nSo actually, the accuracy we had from this was about 91. And now we\'re only getting at\\n8.5. So this is an example of something we call overfitting. Our model seemed like it\\nwas doing really well on the testing. data or sorry, the training data. But that\'s because\\nit was seeing that data so often right with 10 epochs, it started to just kind of memorize\\nthat data and get good at seeing that data. Whereas now when we pass it new data that\\nit\'s never seen before, it\'s only 88.5% accurate, which means we overfit our model. And it\'s\\nnot as good at generalizing for other data sets, which is usually the goal, right? When\\nwe create a model, we want the highest accuracy possible, but we want the highest accuracy\\npossible on new data. So we need to make sure our model generalizes properly. Now in this\\ninstance, you know, like, it\'s, it\'s hard to figure out how do we do that, because we\\ndon\'t know that much about neural networks. But this is the idea of overfitting and of\\nhyper parameter tuning, right? So if we can start changing some of this architecture,\\nand we can change, maybe the optimizer the loss function, maybe we go epochs eight, let\'s\\nsee if this does any better, right, so let\'s now fit the model with eight epochs. We\'ll\\nhave a look at what this accuracy is. And then we\'ll test it and see if we get a higher\\naccuracy on the testing data set. And this is kind of the idea of that hyper parameter\\ntuning, right? We just look at each epoch or not each epoch, we look at each parameter,\\nwe tweak them a little bit, and usually will, like write some code that automates this for\\nus. But that\'s the idea is we want to get the most generalize accuracy that we can.\\nSo I\'ll wait for this to train, we\'re actually almost done. So I won\'t even bother cutting\\nthe video. And then we\'ll run it this evaluation. And we\'ll see now if we got a better accuracy.\\nNow I\'m getting a little bit scared because the accuracy is getting very high here. And\\nsometimes you know that you want the accuracy to be high on your training data. But when\\nit gets to a point where it\'s very high, you\'re in a situation where it\'s likely that you\'ve\\noverfit. So let\'s look at this now. And let\'s see what we get. So 88.4. So we actually dropped\\ndown a little bit. And it seemed like those epochs didn\'t make a big difference. So maybe\\nif I train it on one epoch, let\'s have an idea and see what this does, you know, make\\nyour prediction, you think we\'re gonna be better? Do you think we\'re gonna be worse,\\nit\'s only seen the training data one time, let\'s run this. And let\'s see 89.34. so in\\nthis situation, less epochs was actually better. So that\'s something to consider, you know,\\na lot of people I see just go like 100 epochs and just think their model is going to be\\ngreat, that\'s actually not good to do. A lot of the times you\'re going to have a worse\\nmodel, because what\'s going to end up happening is it\'s going to be seeing the same information\\nso much tweaking, so specifically to that information that it\'s seen that when you show\\nit new data, it can\'t actually, you know, classify and generalize on that. Alright, so let\'s go back. And let\'s see what else we\'re doing\\nnow, with this. Okay, so now that we\'ve done that, we need to make predictions. So to make\\npredictions is actually pretty easy. So I\'m actually just going to copy this line in,\\nwe\'ll go into a new code block down here. So all you have to do is say model dot predict,\\nand then you\'re going to give it an array of images that you want to predict on. So\\nin this case, if we look at test images shape, so actually, let\'s make a new code block.\\nAnd let\'s go here. So let\'s say test underscore images, dot shape. All right, give me a second.\\nSo we have 10,000 by 28, by 28. So this is an array of 10,000 entries of images. Now,\\nif I just wanted to predict on one image, what I could do is say test images, zero and\\nthen put that inside of an array. The reason I need to do that is because the data that\\nthis model is used to seeing is an array of images to make a prediction on that\'s what\\nthis predict method means. And it\'s much better at making predictions on many things at once\\nthan just one specific item. So if you are predicting one item only, you do need to put\\nit in an array, because it\'s used to seeing that form. So we could do this. Um, I mean,\\nI\'m just going to leave it so we\'re just going to predict on every single one of the test\\nimages, because then we can have a look at a cool function I\'ve kind of made. So let\'s\\nactually do this predictions equals model dot predict test images. I mean, let\'s print\\npredictions. And look at actually what it is. Where is my autocomplete? There it is.\\nOkay. So let\'s have a look. Is this some object? Whoa. Okay, so this is arrays of arrays, that\\nlooks like we have some, like really tiny numbers on them. So what this is, is essentially\\nevery single, you know, prediction, or so every single image has a list that represents\\nthe prediction for it, just like we\'ve done with kind of the linear models and stuff like\\nthat. So if I want to see the prediction for test image zero, I would say prediction zero,\\nright? let\'s print this out. And this is the array that we\'re getting these this is the\\nprobability distribution that was calculated on our output layer for you know, these, what\\ndoes it for that image. So if we want to figure out what class we actually think that this\\nis predicting for, we can use a cool function from NumPy called arg Max, which essentially\\nis just going to take the index, this is going to return to us the index of the maximum value\\nin this list. So let\'s say that it was I\'m looking for the least negative, which I believe\\nis this, so this should be nine. This should return to us nine because this is the index\\nhave the highest value in this list, unless I\'m just wrong when I\'m looking at the negatives\\nhere. So nine, that\'s what we got. Okay, so now if we want to see what the actual classes,\\nwell, we have our class names up here. So we know class nine is actually ankle boot.\\nSo let\'s see if this is actually an ankle boot. So I\'m just going to do class underscore\\nnames. I think that\'s what I called it, like this. So that should print out what it thinks\\nit is. Yeah, class underscore names. But now, let\'s actually show the image of this prediction.\\nSo to do that, I\'m just going to steal some code from here because I don\'t remember all\\nthe syntax off the top of my head. So this, so let\'s steal this figure. Let\'s show this\\nand let\'s see if it actually looks like an ankle boots. So to do that, we\'re gonna say,\\ntest underscore images, zero because obviously, image zero corresponds to prediction zero,\\nand that will show this and see what we get. Okay, so ankle boot, and we\'ll be looking\\nat the image is actually an ankle boot. And we can do this for any of the images that\\nwe want to read. So if I do prediction one, prediction one, now let\'s have a look pullover,\\nthat kind of looks like a pullover to me. I mean, I don\'t know if it actually is, but\\nthat\'s what it looks like. You need to to take a look here. Okay, trouser, yep, looks\\nlike trousers to me. And we can see that that is how we get to predictions for our model,\\nwe use model dot predict. Alright, so let\'s move down here now to the next thing that\\nwe did. Alright, so we\'ve already done that. So verifying predictions, okay. So this is\\nactually a cool kind of script that I wrote, I\'ll zoom out a little bit, so we can read\\nit. What this does, is let us use our model to actually make, and I\'m stealing some of\\nthis from TensorFlow to make predictions on any entry that we want. So what it\'s going\\nto do is ask us to type in some number, we\'re going to type in that number, it\'s going to\\nfind that image in the test data set, it\'s going to make a prediction on that from the\\nmodel, and then show us what it actually is versus what it was predicted being. Now I\\njust need to actually run. Actually, let\'s just steal this code and bring it in the other\\none, cuz I\'ve already trained the model there. So we don\'t have to wait again. So let\'s go\\n11. For 11, let\'s go to a new code block, and run that. So let\'s run this script, have\\na look down here. So pick a number, we\'ll pick some number, let\'s go 45. And then what\\nit\'s going to do is say expected sneaker, guess sneaker and actually show us the image there. So we can see this\\nis what you know, our pixel kind of data looks like. And this is what the expected was. And\\nthis is what the guess was from the neural network. Now we can do the same thing. If\\nwe run it again, pick a number 34. Let\'s see here, expected bank, guess back. So that\'s\\nkind of showing you how we can actually use this model. So anyways, that that has been\\nit for this kind of module on neural networks. Now I did this in about an hour, I\'m hoping\\nI explained a good amount that you guys understand now how neural networks work. In the next\\nmodule, we\'re going to move on to convolution neural networks, which again, should help\\nyou know, kind of get your understanding of neural networks up as well as learn how we\\ncan do deep computer vision, object recognition and detection using convolutional neural networks.\\nSo with that being said, let\'s get into the next module. Hello, everyone, and welcome\\nto the next module in this TensorFlow course. So what we\'re gonna be doing here is talking\\nabout deep computer vision, which is very exciting, very cool. This has been used for\\nall kinds of things you ever seen the self driving cars, for example, Tesla, they you\\nactually use a TensorFlow deep learning model is obviously very complicated more than I\\ncan really explain here to do a lot of their computer vision for self driving, we\'ve used\\ncomputer vision in the medicine field, computer vision is actually used in sports a lot. For\\nthings like goal line technology, and even detecting images and players on the field\\ndoing analysis. There\'s lots of cool things we\'re doing with it nowadays. And for our\\npurposes, what we\'re gonna be doing is using this for to perform classification, although\\nit can be used for object detection and recognition, as well as facial detection and recognition\\nas well. So all kinds of applications, in my opinion, one of the cooler things in deep\\nlearning that we\'re doing right now, and let\'s go ahead and talk about we\'re actually gonna\\nbe focusing on here. So we\'re gonna start by discussing what a convolutional neural\\nnetwork is, which is essentially the way that we do deep learning, we\'re going to learn\\nabout image data. So what\'s the difference between image data and other regular data,\\nwe\'re gonna talk about convolutional layers and pooling layers and how stacks of those\\nwork together as what we call a convolutional base for our convolutional neural network.\\nWe\'re going to talk about cnn architectures and get into actually using pre trained models\\nthat have been developed by companies such as Google and TensorFlow themselves to perform\\nclassification tasks for us. So that is pretty much the breakdown of what we\'re about to\\nlearn there\'s quite a bit in this module is probably the more difficult one or the most\\ndifficult one we\'ve been doing so far. So if you do get lost at any point, and you don\'t\\nunderstand some of it, don\'t feel bad. This stuff is very difficult. And I would obviously\\nrecommend reading through some of the descriptions I have here in this notebook, which again,\\nyou can find from the link in the description or looking up some things that maybe I don\'t\\ngo into Enough, enough. depth about in your own time as I can\'t really spend, you know,\\n1011 hours explaining a convolutional neural network. So let\'s now talk about image data,\\nwhich is the first thing we need to understand. So in our previous examples, what we did with\\nwhen we had a neural network is we had two dimensional data, right, we had a width and\\na height when we\'re trying to classify some kind of images using a dense neural network.\\nAnd well, that\'s what we use two dimensions, well, with an image, we actually have three\\ndimensions. And what makes up those dimensions, well, we have a height and we have a width,\\nand then we have something called color channels. Now, it\'s very important to understand this,\\nbecause we\'re going to see this a lot as we get into convolution networks that the same\\nimage is really represented by three specific layers, right, we have the first layer, which\\ntells us all of the red values of the pixels, the second layer, which tells us all the green\\nvalues, and the third layer, which tells us all the blue values. So in this case, those\\nare the color channels. And we\'re going to be talking about channels in depth quite a\\nbit in this series. So just understand that although you think of an image as a two dimensional\\nkind of thing, in our computer, it\'s really represented by three dimensions, where these\\nchannels are telling us the color of each pixel. Because remember, in red, green, blue,\\nyou have three values for each pixel, which means that you\'re going to need three layers\\nto represent that pixel. Right. So this is what we can kind of think of it as a stack\\nof layers. And in this case, a stack of pixels, right, or stack of colors really telling us\\nthe value for each pixel. So if we were to draw this to the screen, we would get the\\nblue, green and red values of each pixel, determine the color of it, and then draw the\\ntwo dimensional image right based on the width and the height. Okay, so now we\'re gonna talk about a convolutional\\nneural network and the difference between that in a dense neural network. So in our\\nprevious examples, when we use the dense neural network to do some kind of image classification,\\nlike that fashion, M, this data set, what it essentially did was look at the entire\\nimage at once and determined based on finding features in specific areas of the image, what\\nthat image was, right? Maybe it found an edge here, a line here, maybe it found a shape,\\nmaybe it found a horizontal diagonal line. The important thing to understand, though,\\nis that when it found these patterns and learn to the patterns that made up specific shapes,\\nit learns them in specific areas, it knew that if we\'re in between, for example, looking\\nat this cat image, we\'re gonna classify this as a cat. If an eye exists on, you know, the\\nleft side of the screen where the eyes are here, then that\'s a cat. It doesn\'t necessarily\\nknow that if we flipped this cat, we did a horizontal flip of this cat. And the eyes\\nwere over here that that is a pattern that makes up a cat. So the idea is that the dense\\nnetwork looks at things globally, it looks at the entire image and learns patterns in\\nspecific areas. That\'s why we need things to be centered, we need things to be very\\nsimilar when we use a dense neural network to actually perform image classification.\\nBecause it cannot learn local patterns, and apply those to different areas of the image.\\nSo for example, some patterns we might look for, when we\'re looking at an image like a\\ncat here would be something like this, right, we would hope that maybe we could find a few\\nears, we could find the eyes, the nose. And you know, the pause here, and those features\\nwould tell us that this makes up a cat. Now with a dense neural network, it would find\\nthese features it would learn them learn these patterns, we would only learn them in this\\nspecific area where they\'re boxed off, which means if I horizontally flipped this image,\\nright, and I go like that, then it\'s not going to know that that\'s a catch, because it learned\\nthat pattern a specific area, it\'ll need to relearn that pattern in the other area. Now,\\nconvolutional neural network, on the other hand, learns local patterns. So rather than\\nlearning that the ear exists in, you know, this specific location, it just learns that\\nthis is what an ear looks like. And it can find that anywhere in the image. And we\'ll\\ntalk about how we do that as we get to the explanation. But the whole point is that our\\nconvolutional neural network will scan through our entire image, it will pick up features\\nand find features in the image. And then based on the features that exist in that image will\\npass that actually to a dense neural network or a dense classifier, it will look at the\\npresence of these features and determine, you know, the combination of these presences\\nof features that make up specific classes or makeup specific objects. So that\'s kind\\nof the point. I hope that makes sense. The main thing to remember is that dense neural\\nnetworks work on a global scale, meaning they learned global patterns, which are specific\\nand are found in specific areas. Whereas convolutional neural networks or convolutional layers will\\nfind patterns that exist anywhere in the image because they know what the pattern looks like.\\nNot that it just exists in a specific area. Alright, so how they work right? So let\'s\\nsee, when a neural network regular neural network looks at this a dog image, this is\\na good example, I should have been using this before, it will find that there\'s two eyes\\nthat exist here, right? It will say okay, so I found that these eyes make up a dog.\\nThis is its training image, for example, and it\'s like okay, so this pattern makes up the\\ndog the iris is in this location. Now what happens when we do this and we flip the image\\nto the The other side, well, our neural network starts looking for these eyes right on the\\nleft side of the image where it found them previously, and where it was trained on, it\\nobviously doesn\'t find them there. And so it says that our image isn\'t a dog, although\\nit clearly is a dog, it\'s just a dog that\'s oriented differently. In fact, it\'s just flipped horizontally, right? We\'re actually I guess,\\nI would say, vertically flipped vertically. So since it doesn\'t find the eyes in this\\nlocation, and it can only look at patterns that is learned in specific locations, it\\nknows that this or it\'s gonna say this isn\'t a dog, even though it is, whereas our convolutional\\nlayer will find the eyes regardless of where they are in the image, and still tell us that\\nthis is a dog, because even though the dogs moved over, it knows what an eye looks like.\\nSo we can find the eye anywhere in the image. So that\'s kind of the point of the convolutional\\nneural network and the convolutional layer. And what the convolutional layer does is look\\nat our image and essentially feed back to us what we call an output feature map that\\ntells us about the presence of specific features, or what we\'re going to call filters in our\\nimage. So that is kind of the way that works. Now, essentially, the thing we have to remember\\nis that our dense neural networks output just a bunch of numeric values. Whereas what our\\nconvolutional layers are actually going to be doing is outputting. What we call feature\\nmap, I\'m going to scroll down here to show you this example, we\'re actually going to\\ndo is run what we call a filter over our image, we\'re going to sample the image at all these\\ndifferent areas. And then we\'re going to create what we call an output feature map that quantifies\\nthe presence of the filters pattern at different locations. And we\'ll run many, many, many\\ndifferent filters over our image at a time. So that we have all these different feature\\nmaps telling us about the presence of all these different features. So one convolutional\\nlayer will start by doing that with very small, simple filters, such as straight lines like\\nthis. And then other convolution layers on top of that, right, because it\'s going to\\nreturn a map that looks something like this out of the layer. We\'ll take this map in now\\nthe one that was created from the previous layer and say, Okay, what this map is representing\\nto me, for example, the presence of these diagonal lines, let me try to look for curbs,\\nright or let me try to look for edges. So it will look at the presence of the features\\nfrom the previous convolutional layer, and then say, Okay, well, if I have all these\\nlines combined together, that makes up an edge, and it will look for that, right. And\\nthat\'s kind of the way that a convolutional neural network works and why we stack these\\ndifferent layers. Now, we also use something called pooling, and there\'s a few other things\\nthat we\'re going to get into. But that is the basics. I\'m going to go into a drawing\\nexample and show you exactly how that works. But hopefully, this makes a little bit of\\nsense that the convolution layer returns a feature map that quantifies the presence of\\na filter at a specific location. And this filter, the advantage of it is that we slide\\nit across the entire image. So if this filter or This feature is present anywhere in the\\nimage, we will know about it rather than in our dense network where it had to learn that\\npattern in a specific global location. Okay, so let\'s get on the drawing tablet and do\\na few examples. Alright, so I\'m here on my drawing tablet, and we\'re going to explain\\nexactly how a convolutional layer works and how the network kind of works together. So\\nthis is an image I\'ve drawn on the left side of our screen here. I know this is very basic,\\nyou know, this is just an x, right? This is what our images, we\'re just going to assume\\nthis is grayscale, we\'re going to avoid doing anything with color channels this second,\\njust because they\'re not that important. But just understand that what I\'m about to show\\nyou does apply to cover channels, as well and to multiple kind of layers and depth.\\nAnd then if we can understand it on a simple level, we should understand it more thoroughly.\\nSo what we want essentially is our convolutional layer, to give us some output, it\'s meaningful\\nabout this image. So we\'re gonna assume this is the first convolutional layer. And what\\nit needs to do essentially is returned to us some feature map that tells us about the\\npresence of specific what we call filters in this image. So each convolutional layer\\nhas a few properties to it. The first one is going to be the input signs. So what can\\nwe expect? Well, what is that that was as the as the input size? How many filters are\\nwe going to have? So filters like this, and what\'s the sample size of our filters? That\'s\\nwhat we need to know, for each of our convolutional neural networks. So essentially, what is a\\nfilter will filter is just some pattern of pixels. And we saw them before we\'ll do a\\npretty basic one here, as the filter we\'re going to look for, which looks something like\\nthis. This will be the first filter we\'re going to look for just to illustrate how this\\nworks. But the idea is that at each convolutional layer, we look for many different filters.\\nAnd in fact, the number we\'re typically looking for, is actually about times 32 filters. Sometimes\\nwe have 64 filters as well and sometimes even 128. So we can do as many filters so we want\\nas few filters as we want, but the filters are what is going to be trained. So this filter\\nis actually what is going to be found by the neural network. It\'s what\'s going to change\\nit You know, this is essentially what we\'re looking\\nfor this is what\'s created in the program. And that\'s kind of like the trainable parameter\\nof a convolutional neural network is the filter. So the amount of filters and what they are\\nwill change as the program goes on. As we\'re learning more and figuring out what features\\nthat make up, you know, a specific image. So I\'m going to get rid of this stuff right\\nnow, just so we can draw and do a basic example. But I want to show you how we look for a filter\\nin the image. So we have filters, right, they\'ll come up with them looking to start completely\\nrandom, but they\'ll change as we go on. So let\'s say the filter we\'re looking for is\\nthat one I drew before, I\'m just gonna redraw it at the top here a little bit smaller. And\\nwe\'ll just say it\'s a diagonal line, right. But another filter we could look for might\\nbe something like, you know, a straight line, just like that all across, we could have a\\nhorizontal line. And in fact, we\'ll have 32 of them. And when we\'re doing just, you know,\\nthree by three grids of filters, well, there\'s not that many combinations, we\'re going to\\ndo at least grayscale wise. So what we\'ll do is we\'ll define the sample size, which\\nis how big our filter is, is going to be three by three, which we know right now, which means\\nthat what we\'re going to do is we\'re going to look at three by three spots in our image,\\nand look at the pixels. And try to find how closely these filters match with the pixels\\nwe\'re looking at on each sample. So what this is going to do, this convolution layer is\\ngoing to output us what we call a feature map, which can be a little bit smaller than\\nthe original image. And you\'ll see why in a second. But that tells us about the presence\\nof specific features in areas of image. So since we\'re looking for two filters, here,\\nactually, we\'ll do two filters, which means that we\'re actually going to have a depth\\ntwo feature map being returned to us right, because for two filters, that means we need\\ntwo maps, quantifying the presence of both of those filters. So for this green box that\\nwe\'re looking at the left side here, we\'ll look for this first filter here. And what\\ndo we get? Well, the way we actually do this, the way we look at this filter, is we take\\nthe cross product, or actually the cross product, the dot product, sorry, between this little\\ngreen box and this filter, right? Because they\'re both pixels, they\'re both actually\\nnumeric values down at the bottom. So what we do is we take that dot product, which essentially\\nmeans we\'re element wise, adding, or what is it element wise, multiplying all these\\npixels by each other. So if this pixel values is zero, right, because it\'s white, or it\\ncould be the other way around, we could say White is one black is zero, it doesn\'t really\\nmatter, right? If this is a zero, and this is a one, these are obviously very different.\\nAnd when we do the dot product of those two, so we multiply them together, then in our\\noutput feature, we would have zero, right, that\'s kind of the way it works. So we do\\nthis dot product of this entire thing. If you don\'t know what the dot product is, I\'m\\nnot really going to go into that. But we do the dot product. And that gives us some value\\nessentially telling us how similar these two blocks are. So how similar this sample is\\nthat we\'re taking the image and the filter that we\'re looking for, they\'re very similar,\\nwe\'re going to likely put a one or something telling us you know, they\'re very close together,\\nthey\'re not similar at all, we\'re going to put a zero. So in this case, for our first\\nfilter, we\'re probably going to have a value because this middle pixel is the same of something\\nlike zero point like one, two, right? But the all the other values are different. So\\nit\'s not going to be very similar whatsoever. So then, what we\'re going to do now is we\'ll look at\\nthe actually second filter, which is this horizontal line. And in fact, we\'re going\\nto get a very similar output response here, probably something like, you know, 0.12, that\'s\\ngoing to go in the top left. And again, these are both maps representing each filter, right?\\nSo now we\'ll move our green box over one like this, to just shift that over one. And now\\nwe\'ll start looking at the next section. And in fact, I\'m gonna see if I can erase this,\\njust to make it a little bit cleaner here. Get rid of the green, there we go. Okay, so\\nwe\'ll move this box over like this. And now start looking at this one, it will do the\\nexact same thing we did again before. So we\'re gonna say, all right, how similar are these?\\nWell, they\'re not similar at all. So we\'re gonna get zero for that first filter, how\\nsome of the other ones? Oh, actually, they\'re like, a little bit similar. There\'s a lot\\nof white that\'s kind of in the same space, like, you know, stuff like that. So we\'ll\\nsay maybe this is like 0.7, right? I\'m just randomly picking these numbers, they are going\\nto be much different than what I\'m putting in here. But I\'m just trying to get you to\\nunderstand what\'s kind of happening, right, and this is completely random, the way I\'m\\nmaking the numbers, just make sure you understand that because this is not exactly what it would\\nlook like. Okay, so then we\'re gonna move the box over one more time, let\'s just erase\\nthis to keep this clean. This will be the last time we do this for the purpose of this\\nexample. And now what we\'re going to have is Wow, we have a perfect match for the first\\nfilter. So we put one, the other ones like add, it\'s kind of similar, there\'s a few things\\nthat are different. So maybe this gets like 0.4 or something, right? whatever they are,\\nwe end up getting some value. So we\'ll fill in all these values. Let\'s just put some arbitrary\\nvalues here for now, just so we can do something with the examples 0.70 0.1 to 0.4 to 0.3 0.9\\nto point one, again, completely random 0.4 0.6 Alright, so this is now what We\'ve gotten\\nour response map from looking at two filters on our original image of five by five. Now\\nnotice that the size of these is three by three. And obviously the reason for that is\\nbecause in a five by five image, when we\'re taking three by three samples, well, we can\\nonly take nine, three by three samples, because when we go down a row, right, we\'re going\\nto move down one, and we\'re going to do the same thing we did before of this, these three\\nby three samples. And if we add the amount of times we can do that, well, we just get\\nthree by three, which is now. So this now is kind of telling us the presence of features\\nin this original image map. Now, the thing is, though, we\'re going to do this 64 times\\nright, for 64 filters, or 32 filters of the amount of filters that we have. So we\'re going\\nto have a lot of layers like a ton of different layers, which means that we\'re going to be\\nconstantly expanding as we go through the convolutional layers, the depth of this, this\\nkind of output feature map. And that means that there\'s a lot of computations that need\\nto be done. And essentially, that means that this can be very slow. So now we need to talk\\nabout an operation called pooling. So I\'ll backtrack a little bit, but we will talk about\\npooling in a second, what\'s going to happen right is when we have all these layers that\\nare generated, so this is called the output feature map right? From this original image,\\nwhat we\'re gonna do is the next convolution layer, and the network is now going to do\\nthe process we just talked about, except on this output feature map, which means that\\nsince this one was picking up things like lines and edges, right, the next convolutional\\nlayer, will pick up combinations of lines and edges and maybe find what a curve is,\\nright, we\'ll slowly work our way up from very, very small amount of pixels, to finding more\\nand more, almost, I want to say abstract, different features that exist in the image.\\nAnd this is what really allows us to do some amazing things with a convolutional neural\\nnetwork. When we have a ton of different layers stacking up on each other, we can pick out\\nall the small little edges, which are pretty easy to find. And with all these combinations\\nof layers working together, we can even find things like say eyes, right, or feet, or heads\\nor face, right, we can find very complicated structures, because we slowly work our way\\nup starting by solving very easy problem, which are like finding lines, and then finding\\ncombinations of lines, combination of edges, shapes, and very abstract things. That\'s how\\nthis convolutional network works. So we\'ve done that now it\'s now time to talk about\\npooling. And we\'ll also talk about Pat, actually, we\'ll go padding first, before we go pooling,\\nI just, it doesn\'t really matter what order we talk about this in. But I just think padding\\nmakes sense based on the way we\'re going right now. So sometimes, we want to make sure that\\nthe output feature map from our original image here is the same dimensions are same size\\nas this red. So this is five by five, obviously, and this is three by three. So if we want\\nthis to be five by five as an output, what we need to do is add something called padding\\nto our original image. So padding is essentially just adding an extra row and column on each\\nside of our image here, so that when we and we just fill in all these pixels, and like\\nkind of the padded pixels here, I just blank random pixels, they don\'t mean anything. Essentially,\\nwhy we do that is so that when we do our three by three sample size here like this, we can\\ntake a three by three sample where every single pixel is in the center of that sample, because\\nright now, this pixels not in the center, this pixel can never be in the center, this\\npixel can never be in the center, only, you know, a few pixels get to be in the center.\\nAnd what this allows us to do is generate an output map that is the same size as our\\noriginal input, and allows us to look at features that are maybe right on the edges of images\\nthat we might not have been able to see. See before. Now this isn\'t super important when\\nyou go to like very large images, but it just something to consider you can add padding,\\nor we may do this as we get through our examples. And there\'s also something called stride which\\nI want to talk about as well. So what a stride is is essentially how much\\nwe move the sample box every time that we\'re about to move it right. So before like so\\nlet\'s say we\'re doing an example of padding here, right, we our first sample we would\\ntake here and again, these pixels are just added we added them in to make this work better\\nfor us, you would assume that the next time we move the box, you\'re gonna move it one\\npixel over, that\'s called a stride of one, we can do that. But we also can employ a stride\\nof two, which means we\'ll move over by two, obviously, the larger your stride, the smaller\\nyour output feature map is going to be. So you might want to add more padding, well,\\nyou don\'t want to add too much padding, but it\'s just something to consider and we will\\nuse a stride in different instances. Okay, so that\'s great. That hopefully makes sense.\\nLet\'s erase this. Now we don\'t need this anymore. We talked about padding, we talked about the\\nstride. Now we\'re gonna talk about a pooling operation, which is very important. So kind\\nof the idea is that we\'re gonna have a ton of layers, right for all these filters, and\\nwe\'re just gonna have a lot of numbers, a lot of computations, and there must be some\\nway to make these a little bit simpler, a little bit easier to use. Well, yes, that\'s\\ntrue. And there is a way to do that. And that\'s called pooling. So there\'s three different\\ntypes of pooling. Well, there\'s more but the basic ones are min, max, and average. And\\nessentially, a pooling operation is just taking specific values from a sample of the output\\nfeature map. So once we generate this output feature map, what we do to reduce its dimensionality\\nand just make it a little bit easier to work with, is when we sample, typically two by\\ntwo areas of this output feature map, and just take either the min max or average value\\nof all the values inside of here and map these, we\'re gonna go back this way to a new feature\\nmap that\'s twice the one times the size essentially, or not, what am I saying two times smaller\\nthan this original map. And it\'s kind of hard with three, like three by three to really\\nshow you this. But essentially, what\'s gonna end up happening is we\'re gonna have something\\nlike this. So we\'re gonna take the sample here, we\'re gonna say, Okay, what are we doing\\nmin max, or average pooling, we\'re doing min pooling, we\'re gonna take the smallest value,\\nwhich means we\'ll take zero, we\'re doing max pooling, we\'ll take the maximum value, which\\nmeans we\'ll take 0.3, if we\'re doing average, we\'re probably gonna get an average value\\nof close to what 0.2, maybe. So let\'s say 0.2, we\'ll go there. That\'s how we do that\\nwith pooling again, just to make this feature map smaller. So we\'ll do that for both of\\nthe filters. But let\'s just say this is your point to let\'s say, this here that I\'m blocking\\noff, is, I don\'t know, what is this gonna be 0.6. It\'s hard to do this average with\\nfour numbers, let\'s say this one down here, is going to be zero point. I don\'t know, let\'s just do two one or something.\\nAnd then this last one, here, we Okay, we got some bigger values, maybe this will be\\nlike 0.4. Okay, so that\'s one, the one down here we\'ll have some values of its own, we\'ll\\njust do squiggles to represent that it has something, we\'ve effectively done a max pooling\\noperation on this, we\'ve reduced the size of it by about half. And that is kind of how\\nthat works. Now typically, what we do is we use a two by two pooling, or like sample size\\nlike that with a stride of two, which actually means that we would straw it like this. But\\nsince we\'re not going to do padding on this layer, right now, we\'ll just do a stride of\\none. And this is how we pool it. Now, the different kinds of pooling are used for different\\nkinds of things, the reason we would use a max pooling operation is to pretty much tell\\nus about the maximum presence of a feature in that kind of local area, we really only\\ncare if the feature exists, where if it doesn\'t exist, and average pooling is not very often\\nused, although in this case, we did use an average pooling. But you know, it just different\\nkinds of pooling average tells you about the average presence of the feature in that area.\\nMax tells you about is that feature present in that area at all, and min tells you does\\nit not exist. If it doesn\'t exist, right, we\'re just gonna have a zero if there\'s even\\none zero in that area. So that\'s the point of pooling and support of convolutional layers.\\nI think I\'m done with the whiteboarding. For now we\'re actually going to start getting\\ninto a little bit of code, and talking about creating our own convolutional networks, which\\nhopefully, will make this a lot more clear. So let\'s go ahead and get into that. Alright,\\nso now it is time to create our first convolutional neural network. Now we\'re gonna be using Kerris\\nto do this. And we\'re also gonna be using the CIA FDR image data set that contains 60,000\\nimages of 10 different classes of everyday objects. Now, these images are 32 by 32, which\\nessentially means they are blurs, and they are colorful. Now, I just want to emphasize\\nas we get into this, that the reason I\'m not typing all of these lines out, and I just\\nhave them in here already, is because this is likely what you guys will be using or doing\\nwhen you actually make your own models. Chances are that you are not going to sit unless you\'re\\na pro at TensorFlow, and I am not even there yet either with my knowledge of it, and have\\nall of the lines memorized and not have to go reference the syntax. So the point is here,\\nso long as you can understand why this works, and what these lines are doing, you\'re gonna\\nbe fine. You don\'t need to memorize them, and I have not memorized them and I don\'t\\nI look up the documentation, I copy and paste what I need, I alter them, I write a little\\nbit of my own code. But that\'s kind of what you\'re going to end up doing. So that\'s what\\nI\'m doing here. So this is the image data set. We have truck, core ship, airplane, you\\nknow, just an everyday regular objects, there is 60,000 images, as we said, and 6000 images\\nof each class. So we don\'t have too many images of just one specific class. So we\'ll start\\nby importing our modules. So TensorFlow, we\'re gonna import TensorFlow caros. We\'re gonna\\nuse the data set built into Kerris for this. So that\'s the CI FDR image data set, would\\nyou actually look at just by clicking at this, it\'ll bring you and give me information about\\nthe data set, although we don\'t need that right now, because I already know the information\\nabout it. And now we\'re just going to load our images in. So again, this stuff, the way\\nthis works is you\'re gonna say data sets.ci, fA r 10 dot load data. Now this load data\\nhas like a very strange TensorFlow object that\'s like a data set object. So this is\\ndifferent from what we\'ve used before where some of our objects have actually been, like\\na NumPy arrays where we can look at them better, this is not going to be in that. So just something\\nto keep in mind here. We\'re going to normalize this data into train images and test images,\\nbut it\'s dividing both of them by 255. Now again, we\'re doing that because we want to\\nmake sure that our values are between zero and one because that\'s a lot better to work\\nwith in our neural networks rather than large integer values, just causes, you know, some\\nthings to mess up sometimes, no class names, we\'re just going to find a list here. So we\\nhave all the class names, so that zero represents airplane one automobiles so far until truck,\\nwe run that block of code here, we\'ll download this data set, although I don\'t think it takes\\nthat long to do that. So okay, so wait, I guess yeah, I guess that\'s good. I think we\'re\\nokay there. And now, let\'s just have a look at actually some of the images here by running\\nthis script. So we can see this is a truck can change the image index to be two, we can\\nsee this is another truck, let\'s go to say six, we get a bird. And you can see these\\nare really blurry, but that\'s fine. For this example, we\'re just trying to get something\\nthat works. Alright, guys, that\'s a horse, you know, you get the point. Alright, so now\\ncnn architecture. So essentially, we\'ve already talked about how a convolution neural network\\nworks. We haven\'t talked about the architecture and how we actually make one, essentially,\\nwhat we do is we stack a bunch of convolutional layers, and Max pooling, min pooling, or average\\npooling layers together in something like this, right. So after each convolutional layer,\\nwe have a max pooling layer, some kind of pooling layer, typically, to reduce the dimensionality,\\nalthough you don\'t need that, you could just go straight into three convolutional layers.\\nAnd on our first layer, what we do is we define the amount of filters just like here, we define\\nthe sample size. So how big are those filters and activation function, which essentially\\nmeans after we apply that, what is it that cross not crossed by dot product operation\\nthat we talked about, will apply rectified linear unit to that and then put that in the\\noutput feature map? Again, we\'ve talked with activation functions before, so I won\'t go\\ntoo far into depth with them. And then we define the input shape, which essentially\\nmeans what can we expect in this first layer? Well, 32 by 32, by three, these ones, we don\'t\\nneed to do that, because they\'re going to figure out what that is based on the input\\nfrom the previous layer. Alright, so these are just a breakdown of the layers. The convolution\\nor the max pooling layers here, two by two essentially means that we\'re going to do is\\nwe\'re going to have a two by two sample size with actually a stride of two. Again, the\\nwhole point of this is to actually divide or, you know, shrink it by a factor of two,\\nhow large each of these layers are. Alright, so now let\'s have a summary. It\'s already\\nprinted out here, we can see that we have, Wait, is this correct? mobilenet v2, I don\'t\\nthink that\'s correct. That\'s because I haven\'t run this one. My apologies on that, guys,\\nthis is from something later in the tutorial, we can see that we have comm two D as our\\nfirst layer, this is the output shape of that layer, notice that it is not 32 by 32, by\\n32. It is 30 by 30 by 32. Because when we do that sampling, without padding, right,\\nthat\'s what we\'re gonna get, we\'re gonna get to pixels less, because the amount of samples\\nwe can take. All right, next, we have the max pooling to dealer. So this now this is\\nthe output shape is 15 by 15, by 32, which means we\'ve shrunk this shape by a factor\\nof two, we do a convolution on this, which means that now we get 1313. And we\'re doing\\n64. Because we\'re going to take 64 filters, this time. And the max pooling again, we go\\nsix by six by 64, because we\'re going to divide this again by a factor of two, notice that\\nit just rounded, right, and then come to do so another layer here, we get four by four\\nby 64. Again, because of the way we take those values. So this is what we have defined so\\nfar. But this is not the end of our convolutional neural network. In fact, this doesn\'t really\\nmean much to us, right? This just tells us about the presence of specific features as\\nwe\'ve gone through this convolution base, which is what this is called the stack of\\nconvolution and Max pooling layers. So what we actually need to do is now pass this information\\ninto some kind of dense layer classifier, which is actually going to take this pixel\\ndata that we\'ve kind of calculated and found, so the almost extraction of features that\\nexist in the image, and tell us which combination of these features map to either you know,\\nwhat one of these 10 classes are. So that\'s kind of the point you do this convolution\\nbase, which extracts all of the features out of your image. And then you use the dense\\nnetwork to say, Okay, well, if these combination of features exist, then that means this image\\nis this, otherwise, it\'s this and that, and so on. So that\'s what we\'re doing here. Alright,\\nso let\'s say adding the dense layer. So to add the dense layer is pretty easy model dot\\nadd is just how we add them, right. So we\'re going to flatten all of those pixels was,\\nwhich essentially means take the four by four by 64. And just put those all into a straight\\nline like we\'ve done before, so just one dimensional, then we\'re going to have a 64 neuron dense\\nlayer that connects all of those things to it with an activation function of rectified\\nlinear unit, then our output layer of a dense layer with 10 neurons, obviously 10 because\\nthat\'s the amount of classes we have for this problem. So let\'s run this here. We\'ll add\\nthose layers. Let\'s look at a summary and see Oh, things have changed now. Should we\\ngo from four by four by 64 2024. Notice that that is precisely the calculation of four\\ntimes four times 64. That\'s how we get that number here, then we have a dense layer and\\nanother dense layer. And this is our output layer. Finally, this is what we\'re getting\\nis we\'re going to get 10 neurons out. So essentially just a list of values. And that\'s how we can\\ndetermine which class is predicted. So this up to here is the convolutional base. This\\nis what we call the classifier, and they work together to essentially extract the features,\\nand then look at the features and predict the actual object or whatever it is the class.\\nAlright, so that\'s how that works. Now it\'s time to train again, we\'ll go through this\\nquickly. Um, I believe I\'ve already trained this, this takes a long time to train. So\\nI\'m actually going to reduce the epochs here to just be four, I\'d recommend you guys train\\nthis on higher. So like 10, if you\'re going to do but it does take a while. So for our\\npurposes, and for my time, will leave a little bit shorter right now. But you should be getting\\nabout a 70% accuracy. And you can see I\'ve trained this previously, if you train it on\\n10 epochs, but I\'m just gonna train up to four, we get our 67 68%. And that should be\\nfine. So we\'ll be back once this is training, and we\'ll talk about how some of this works.\\nOkay, so the model is finally finished training, we did about four epochs, you can see we got\\nan accuracy about 67% on the evaluation data, to quickly go over this stuff. optimizers,\\nAdam talked about that before loss function is sparse, categorical cross entropy. That\\none I mean, you can read this, if you want computes the cross entropy loss between the\\nlabels and predictions. And I\'m not gonna go into that, but these kinds of things are\\nthings that you can look up if you really understand why they work. For most problems,\\nyou can just if you want to figure out what you know, loss function optimizer to use,\\njust use the basics, like use atom use a categorical cross entropy, using a classification task,\\nyou want to do something like this, there\'s just you can go up and look kind of all of\\nthe different loss functions. And it\'ll tell you when to use which one and you can kind\\nof mess with them and tweak them if you want. Now, history equals model dot fit this just\\nso we can access some of the statistics from this model dot fit. Obviously, it\'s just training\\nthe data to this test images, test labels, and train images and train labels where this\\nis the validation data suite. So evaluating the model, we want to evaluate the model,\\nwe can evaluate it now on the test images and test labels, we\'re obviously going to\\nget the same thing because the valuation is test images and test labels. So we should\\nget the same accuracy as 60 735, which we do right here. Alright, so there we go, we\\nget about 70% of you guys trained this on 10 epochs, you should get close to 70, I\'m\\na little bit lower, just because I didn\'t want to go that high. And that is now the\\nmodel. I mean, we could use this if we want, we could use predict, we could pass in some\\nimage. And we could see the prediction for it. I\'m not going to do that just because\\nwe\'ve already talked about that enough. And I want to get into some of the cooler stuff\\nwhen we\'re working with smaller data sets. So the basic idea here is this is actually\\na pretty small data set, right, we use about 60,000 images. And if you think about the\\namount of different patterns, we need to pick up to classify, you know, things like horses\\nversus trucks, that\'s a pretty difficult task to do. Which means that we need a lot of data.\\nAnd in fact, some of the best convolutional neural networks that are out there are trained\\non millions of pieces of you know, sample information or data. So obviously, we don\'t\\nhave that kind of data. So how can we work with, you know, a few images, maybe like a\\nfew 1000 images, and still get a decent model? Well, the thing is, you can\'t unless we use\\nsome of the techniques, and I\'m about to show you. So working with small data sets. So just\\nlike I mentioned, it\'s difficult to create a very good convolution neural network from\\nscratch, if you\'re using a small amount of data. That is why we can actually employ these\\ntechniques, the first one data augmentation, but also using pre trained models to kind\\nof accomplish what we need to do. And that\'s we\'re going to be talking about now on the\\nsecond part of the tutorial, we\'re going to create another convolutional neural network.\\nSo just to clarify, this is created, we\'ve made the model up here already, this is all\\nwe need to do to do it. This is the architecture and this was just to get you familiar with\\nthe idea. So data augmentation. So this is basically the idea. If you have one image,\\nwe can turn that image into several different images, and train and pass all those images\\nto our, our model. So essentially, if we can rotate the image, if we can flip it, if we\\ncan stretch it, compress it, you know, shift it, zoom it, whatever it is, and pass that\\nto our model, it should be better at generalizing. Because we\'ll see the same image, but modified\\nand augmented multiple times, which means that we can turn a data set, say of 10,000\\nimages into 40,000 images by doing four augmentations on every single image. Now, obviously, you\\nstill want a lot of unique images. But this technique can help a lot and is used quite\\na bit because that allows our kind of modeled to be able to pick up images that maybe are\\noriented differently or zoomed in a bit or stretch something different, right? Just better\\nat generalizing, which is the whole point. So I\'m not going to go through this in to\\ndepth, too much depth, but this is essentially a script that does data augmentation for you.\\nWe\'re gonna use this ima image data generator from the Kara\'s pre processing dot image module,\\nwe\'re going to create an image data generator object. And essentially what this allows us\\nto do is specify some parameters on how we want to modify our image. In this case, we\\nhave the route range, some shifts, shear, zoom, horizontal flip and the mode. Now I\'m\\nnot going to go into how this works, you can look at the documentation if you\'d like. But\\nessentially, this will just allow us to augment our images. Now what I\'m going to do is pick\\none arbitrary image from the test image data set, just our test image, I guess, group of\\nphotos, whatever you want to call it, I\'m going to convert that to an image array, which\\nessentially takes it from the weird data set object that it kind of is and turns it into\\na NumPy array, then we\'re going to reshape this. So it\'s in the form one comma, which\\nessentially means one, and then this will figure out what the rest of the shape should\\nbe, oh, sorry, one, and then plus the image shape, which is whatever this shape is. So\\nwe\'ll reshape that. And then what we\'re gonna do is we\'re gonna say, for batch in data flow\\nGen dot flow, talk about how that works in a second. Essentially, this is just going\\nto augment the image for us and actually save it onto our drive. So in this instance, what\'s\\ngoing to happen is this data Gen dot flow is going to take the image which we\'ve created\\nhere, right, and we formatted it correctly, by doing these two steps, which you need to\\ndo beforehand, it\'s going to save this image as test dot jpg, and this will be the prefix,\\nwhich means it\'ll be some information after, and it will do this as many times until we\\nbreak. So essentially, given an image, it will do test one, test two, test three, test\\nfour, test five, with random augmentations. Using this, until eventually, we decided to\\nbreak out of this. Now what I\'m doing is just showing the image by doing this, and batch\\nzero is just showing us the you know, that first image in there. And that\'s kind of how\\nthis works. So you can mess with the script and figure out a way to use it. But I would\\nrecommend if you want to do data augmentation, just look into image data generator, this\\nis something that I just want to show you. So you\'re aware of, and I\'ll just run it so\\nyou can see exactly how this works. So essentially, given an image of a truck, what it will do\\nis augmented in these different ways. You can see kind of the shifts, the translations,\\nthe rotations, all of that. And we\'ll do actually a different image here to see what one looks\\nlike, let\'s just do image size 22, we get something different. So in this case, I believe\\nthis is maybe like a deer rabbit or a dog or something, I don\'t really know exactly\\nwhat it is because it\'s so blurry. But you can see that\'s kind of the shifts we\'re getting.\\nAnd it makes sense because you want to have images in different areas so that we have\\na better generalization. Alright, so let\'s close that. Okay, so now we\'re gonna talk\\nabout using it or sorry, what is it pre trained models? Okay. So we talked about data augmentation,\\nthat\'s a great technique if you want to increase the size of your data set. But what if even\\nafter that we still don\'t have enough images in our data set? Well, what we can do is use\\nsomething called a pre trained model. Now companies like Google, and you know, TensorFlow,\\nwhich is owned by Google, make their own amazing convolutional neural networks that are completely\\nopen source that we can use. So what we\'re going to do is actually use part of a convolutional\\nneural network that they\'ve trained already on, I believe, 1.4 million images. And we\'re\\njust gonna use part of that model, as kind of the base of our models that we have a really\\ngood starting point. And all we need to do is what\'s called fine tune the last few layers\\nof that network, so that they work a little bit better for our purposes. So what we\'re\\ngoing to do essentially is say, all right, we have this model that Google\'s trained,\\nthey\'ve trained it on 1.4 million images, it\'s capable of classifying, let\'s say, 1000\\ndifferent classes, which is actually the example we\'ll look at later. So obviously, the beginning\\nof that model, is what\'s picking up on the smaller edges. And you know, kind of the very\\ngeneral things that appear in all of our images. So if we can use the base of that model, so\\nkind of the beginning of it, that does a really good job picking up on edges, and general\\nthings that will apply to any images, then what we can do is just change the top layers\\nof that model a tiny bit, or add our own layers to it to classify for the problem that we\\nwant. And that should be a very effective way to use this pre trained model. We\'re saying\\nwe\'re going to use the beginning part that\'s really good at kind of the generalization\\nstep, then we\'ll pass it into our own layers that will do whatever we need to do specifically\\nfor our problem. That\'s what\'s like the fine tuning step. And then we should have a model\\nthat works pretty well. In fact, that\'s what we\'re going to do in this example, now. So\\nthat\'s kind of the point of what I\'m talking about here is using part of a model that already\\nexists that\'s very good at generalizing, and it\'s been trained on so many different images.\\nAnd then we\'ll pass our own training data in, we won\'t modify the beginning aspect of\\nour neural network, because it already works really well. We\'ll just modify the last few\\nlayers that are really good at classifying, for example, just cats and dogs, which is\\nexactly the example we\'re actually going to do here. So I hope that makes sense. As we\\nget through this should be cleared up a little bit. But using a pre trained model is now\\nthe section we\'re getting into. So this is based on this documentation. As always, I\'m\\nreferencing everything. So you guys can see that if you\'d like we do our imports like\\nthis, we\'re going to load a data set. This actually takes a second to load the data set,\\nI believe, oh, maybe not. And essentially, the problem we\'re doing is trying to classify\\ndogs versus cats with a fair degree of accuracy. In fact, we\'d like to get above 90%. So this\\nis the data set we\'re loading in from TensorFlow data sets as TF DS This is kind of a weird\\nway to load it in again, stuff like this, you just have to reference the documentation,\\nI can explain it to you. But it\'s not really going to help when the next example is going\\nto be a different way of loading the data, right? So so long as you know how to get the\\ndata in the correct form, you can get it into some kind of NumPy array, you can split it\\ninto training, testing and validation data, you should be okay. And if you\'re using a\\nTensorFlow data set, it should tell you in the documentation, how to load it in properly.\\nSo loaded in here, we\'re training 80% train, I will go 10% for once, raw validation, and\\n10% for the testing data. So we\'ve loaded that. And now what we\'re doing here is just\\nwe\'ll look at a few images. So this actually creates a function, I know, this is a weird\\nthing, this is pretty unique to this example, that allows us to call this function with\\nsome integer, essentially, and get what the actual string representation of that is to\\nthe label for it. And what I\'m doing here is just taking two images from our raw training\\ndata set, and just displaying them. And you can see that\'s what we\'re getting here, dog\\nand dog. If I go ahead and take five, we\'ll see, these are what our images look like.\\nRight, so here\'s an example of a dog, we have a cat, right, and so on so forth, you kind\\nof get that you get the point there. Now, notice, though, that these images are different\\ndimensions. In fact, none of these images other than these two actually are the same\\ndimension at all. Oh, actually, I don\'t think these ones are either. So obviously, there\'s\\na step that we need to do, which is we need to scale all these images to be the same size.\\nSo to do that, what we\'re going to do is write a little function like this, that essentially\\nwill return an image that is reshaped. So I guess, that these reshaped to the image\\nsize, which I\'m going to set out 160 by 160. Now we can make this bigger if we want. But\\nthe problem is, sometimes if you make an image that is bigger than like, you want to make\\nyour image bigger than most of your data set examples. And that means you\'re going to be\\nreally stretching a lot of the examples out and you\'re losing a lot of detail. So it\'s\\nmuch better to make the image size smaller rather than bigger. You might say, well, if\\nyou make it smaller, you\'re gonna lose detail too. But it\'s just, it\'s better to compress\\nit smaller than it is to go really big, even just when it comes to the amount of training\\ntime and how complex networks going to be. So that\'s something to consider. You can mess\\naround with those when you\'re making your own networks. But again, smaller is typically\\nbetter, in my opinion, you don\'t wanna go too small, but something that\'s like, you\\nknow, half the size, what an average image would be. Alright, so we\'re gonna go format\\nexample, we\'re gonna just take an image and a label. And what this will do is return to\\nus just the reshaped image and labels. In this case, we\'re going to cast which means\\nconvert every single pixel in our image to be a float 32 value because it could be integers,\\nwe\'re then going to divide that by 127.5, which taken is exactly half of 255, and then\\nsubtract one, then we\'re going to resize this image to be the image size. So sorry, the\\nimage will be resized to the image size, so 160 by 160. And we\'ll return new image and\\nthe label. So now we can apply this function to all of our images using map if you don\'t\\nknow what map is, essentially, it takes every single example in, in this case going to be\\nraw train, and applies the function to it, which will mean that it will convert rod train\\ninto images that are all resized to 160 by 160. And we\'ll do the same thing for validation\\nand test. So run that no issue there. And now let\'s have a look at our images and see\\nwhat we get. And there we are. Now I\'ve just messed up the color because I didn\'t add a\\nseam up thing, which I think I needed. Where was the sea map. Anyways, you know what, that\'s\\nfine. For now. This is what our images look like this is the resize now we get all images\\n160 by 160. And we are good to go. Alright, so now let\'s have a look at the shape of an\\noriginal image versus our new image. So I mean, this was just to prove that essentially,\\nour original shapes were like 262 409 by some random values, and they\'re all reshaping that\\n161 60 by three, three, obviously is the color channel of the images. Alright, so picking\\na pre trained model. So this is the next step is probably one of the hardest steps is picking\\na model that you would actually like to use the base up. Now we\'re going to use one called\\nmobile net v two, which is actually from Google. It\'s built into TensorFlow itself. That\'s\\nwhy I\'ve picked it. And all we\'re going to do is set this.\\nSo essentially, we\'re going to say the base model in our code is equal to tf Kara\'s the\\napplications mobile net v2, which is just telling us the architecture of the model that\\nwe want, we\'ll have a look at it down below here. In just a second, we\'ll define the input\\nshape, which is important because this can take any input shape that we want. So we\'ll\\nchange it to 161 60 by three, which we\'ve defined up here, include top, very important\\nmeans do we include the classifier that comes with this network already or not? Now in our\\ncase, we\'re going to be retraining parts of this network so that it works specifically\\nfor dogs and cats, and not for 1000 different classes, which is what this model was actually\\naimed to do is train a 1.4 million images for 1000 different classes of everyday objects.\\nSo we\'re going to not include the top which means don\'t include the classifier for these\\n1000 classes. And we\'re going to load the weights from what\'s called image net, which\\nis just a specific save of the weights. So this is the architecture and this is kind\\nof the data Now that we\'re filling in for that architecture, so the weights, and we\'ll\\nload that in which we have here. So base model. Now let\'s look at it. So let\'s have a summary.\\nYou can see this is a pretty crazy model. I mean, we would never be expected to create\\nsomething like this by herself. This is, you know, teams of data scientists, PhD students,\\nengineers, would I write the experts in the field that have created a network like this.\\nSo that\'s why we\'re going to use it because it works. So effectively for the generalization\\nat the beginning, which is what we want. And then we can take those features that this\\ntakes out, so in five by five by 1280, which is what I want us to focus on the output of\\nthis actual network here. So really, you can see this last layer, we\'re going to take this\\nand using this information, pass that to some more convolutional layers, and actually our\\nown classifier, I believe, and use that to predict versus dogs versus cats. So at this\\npoint, the base model will simply open a shape 32 by five by five by 1280. That\'s the tensor\\nthat we\'re going to get out of this. That\'s the shape, you can watch how this kind of\\nworks as you go through it. And yes, alright, so we can just have a look at this here, this,\\nwhat I wanted to do essentially was just look at what the actual shape was going to be.\\nSo 32, five by five by 1280, just because this gives us none until it knows what the\\ninput is. And now it\'s I\'m talking about freezing the base. So essentially, the point is, we\\nwant to use this as the base of our network, which means we don\'t want to change it. If\\nwe just put this network in right now is the base to our neural network. Well, what\'s going\\nto happen is, it\'s going to start retraining all these weights and biases. And in fact,\\nit\'s going to train 2.25 7 million more weights and biases, when in fact, we don\'t want to\\nchange these because these have already been defined, they\'ve been set. And we know that\\nthey will work well for the problem already. Right? They worked well for classifying 1000\\nclasses. Why are we going to touch this now. And if we were going to touch this, what\'s\\nthe point of even using this base, right, we don\'t want to train this, we want to leave\\nit the same. So to do that, we\'re just gonna freeze it. Now freezing is a pretty, I mean,\\nit just essentially means turning the trainable attribute of a layer off or of the model off.\\nSo what we do is we just say base model dot trainable equals false, which essentially\\nmeans that we are no longer going to be training, any aspect of that I want to say model, although\\nwe\'ll just call it the base layer for now, the base model. So now if we look at the summary,\\nwe can see when we scroll down to the bottom, if we get there any day soon, that now the\\ntrainable parameters is zero instead of 2.25 7 million, which it was before. And now it\'s\\ntime to add our own classifier on top of this. So essentially, we\'ve got a pretty good network,\\nright five by five by 12, at our last output. And what we want to do now is take that, and\\nwe want to use it to classify either cat or either Doc, right, so what we\'re going to\\ndo is add a global average layer, which essentially is going to take the entire average of every\\nsingle so of 12 180 different layers that are five by five, input that into a one D\\ntensor, which is kind of flattening that for us. So we do that global average pooling.\\nAnd then we\'re just going to add the prediction layer, which essentially is going to just\\nbe one dense node. And since we\'re only classifying two different classes, right, dogs and cats,\\nwe only need one, then we\'re going to add all these models together. So the base model,\\nand I guess, layers, the global average layer that we define there, and then the prediction\\nlayer, to create our final model. So let\'s do this global average layer, prediction layer\\nmodel. Give that a second to kind of run there. Now when we look at the summary, we can see\\nwe have mobile net v2, which is actually a model, but that is our base layer. And that\'s\\nfine, because the output shape is that then global average pooling, which again, just\\ntakes this flattens it out does the average for us. And then finally, our dense layer,\\nwhich is going to simply have one neuron, which is going to be our output. Now notice\\nthat we have 2.25 and 9 million parameters in total. And only 1200 81 of them are trainable.\\nThat\'s because we have 1200 80 connections from this layer to this layer, which means\\n1200 80 weights and one bias. So that is what we\'re doing. This is what we have created.\\nNow this base, the majority of the network has been done for us. And we just add our\\nown little classifier on top of this. And now we\'re going to feed some training samples\\nand data to this. Remember, we\'re not training this base layer whatsoever. So the only thing\\nthat needs to be learned is the weights and biases on these two layers here. Once we have\\nthat we should have a decent model ready to go. So let\'s actually train this now. I\'m\\ngoing to compile this here. I\'m picking a learning rate. It\'s very slow. What essentially\\nwhat the learning rate means is how much am I allowed to modify the weights and biases\\nof this network, which is what I\'ve done, just made that very low, because we don\'t\\nwant to make any major changes if we don\'t have to, because we\'re already using a base\\nmodel that exists, right. So we\'ll set the learning rate, I\'m not going to talk about\\nwhat this does specifically, you can look that up if you\'d like to. And then the loss\\nfunction will use binary cross entropy just because we\'re using two classes. If you\'re\\nusing more than more than two classes, you just have cross entropy or some other type\\nof cross entropy. And then what we\'re going to do is actually evaluate the model right\\nnow before we even train it. So I\'ve compiled it, I\'ve just set what we\'ll end up using.\\nBut I want to evaluate the model currently, without training it whatsoever on our validation\\ndata validation batches and see what it actually looks like what it actually you know what\\nwe\'re getting right now, with the current base model being the way it is, and not having\\nchanged the weights and biases, the completely random from the global average pooling in\\nthe dense layer. So let\'s evaluate. And let\'s see what we get as an accuracy. Okay, so we\\ncan actually see that with the random weights and biases. For those last layer that we added,\\nwe\'re getting an accuracy of 56%, which pretty much means that it\'s guessing, right? It\'s,\\nyou know, 50% is late to classes. So if we got anything lower than 50, like 50, should\\nhave been our guests, which is what we\'re getting. So now what we\'re going to do, and\\nI actually, I\'ve trained this already, I think so I might not have to do it, again, is a\\ntrain this model on all of our images to all of our images, and cats and cats and dogs.\\nSo we\'ve loaded in four, which will allow us now to modify these weights and biases\\nof this layer. So hopefully, it can determine what features need to be present for a dog\\nto be a dog and for cat to be a cat, right. And then it can make a pretty good prediction.\\nIn fact, I\'m not going to train this in front of us right now, because this actually takes\\nclose to an hour to train just because there is a lot of images that it needs to look at,\\nand a lot of calculations that need to happen. But when you do end up training this, you\\nend up getting an accuracy of a close to 92 or 93%, which is pretty good considering the\\nfact that all we did was use that original layer, like base layer that classified up\\nto 1000 different images, so very general, and applied that just to cats and dogs by\\nadding our dense layer classifier on top. So you can see this was kind of the accuracy\\nI had from training this previously, I don\'t want to train again, because it takes so long.\\nBut I did want to show that you can save a model and load a model by doing this syntax.\\nSo essentially, on your model object, you can call model dot save, save it as whatever\\nname you\'d like dot each phi, which is just a format for saving models. And Kara\'s is\\nspecific to Kara\'s not TensorFlow. And then you can load the model by doing this. So this\\nis useful because after you train this for an hour, obviously, you don\'t want to retrain\\nthis if you don\'t have to, to actually use it to make predictions. So you can just load\\nthe model. Now, I\'m not going to go into using them all specifically, you guys can look up\\nthe documentation to do that. We\'re at the point now where I\'ve showed you so much syntax\\non predicting and how we actually use the models. But the basic idea would be to do\\nmodel dot predict, right, and then you can see that it\'s even giving me the input here.\\nSo model dot predict, give it some x batch size verbose, right, because it will predict\\non multiple things. And that will spit back to you a class which then you can figure out,\\nOkay, this is a cat or this is a dog, you\'re going to pass this obviously the same input\\ninformation we had before, which is 160 by 160, by three, and that will make the prediction\\nfor you. So that\'s kind of the thing there, I was getting an error just because I hadn\'t\\nsaved this previously. But that\'s how you save and load models, which I think is important\\nwhen you\'re doing very large models. So when you fit this, feel free to change the box\\nto be something slower if you\'d like, again, right? This takes a long time to actually\\nend up running. But you can see that the accuracy increases pretty well exponential exponentially,\\nfrom when we didn\'t even have that classifier on it. Now the last thing I want to talk about\\nis object detection, I\'m just going to load up a page, we\'re not going to do any examples,\\nI\'m just gonna give you a brief introduction, because we\'re kind of running out of time\\nfor this module, because you can use TensorFlow to do object detection and recognition, which\\nis kind of cool. So let\'s get into that now. Okay, so right now I\'m on a GitHub page that\'s\\nbuilt by TensorFlow here, I\'m going to leave that link in the notebook where it says object\\ndetection, so you guys can look at that. But essentially, there is an API for TensorFlow\\nthat does object detection for you. And in fact, it works very well and even gives you\\nconfidence scores. So you can see this is what you\'ll actually end up getting if you\\nend up using this API. Now, unfortunately, we don\'t have time to go through this because\\nthis will take a good amount of time to talk about the setup and how to actually use this\\nproject properly. But if you go through this documentation, you should be able to figure\\nit out. And now you guys are familiar with TensorFlow, and you understand some of the\\nconcepts here. This runs a very different model than what we\'ve discussed before. Unfortunately,\\nwe don\'t have time to get into it. But just something I wanted to make clear is that you\\ncan do something like this with TensorFlow. And I will leave that resource so that if\\nyou\'d like to check this out, you can use it. There\'s also a great module in Python\\ncalled facial recognition. It\'s not a part of TensorFlow. But it does use some kind of\\nconvolutional neural network to do facial detection and recognition, which is pretty\\ncool as well. So I\'ll put that link in here. But for that, for now, that\'s going to be\\nour what is a compositional neural network kind of module. So I hope this has cleared\\nsome things up on how deep vision works and how convolutional neural networks work. I\\nknow I haven\'t gone into crazy examples, what I\'ve shown you some different techniques,\\nthat hopefully you\'ll go look up kind of on your own and really dive into because now\\nyou have that base kind of domain knowledge where you\'re going to be able to follow along\\nwith the tutorial and understand exactly what to do. And if you want to create your own\\nmodel, so long as you can get enough sufficient training data, you can load that training\\ndata into your computer. Put that in A NumPy array, then what you can do is create a model\\nlike we\'ve just done using even something like the mobile net, what is it v2 that we\\ntalked about previously, but could even get up, I need to close this output, oh my gosh,\\nthis just was massive output here, where\'s this begin to pre train model? Yeah, mobile\\nnet v2, you can use the base of that, and then add your own classifier on, do a similar\\nthing to what I\'ve done with that dense neuron and that global average layer. And hopefully,\\nyou should get a decent result from that. So this is just showing you what you can do,\\nobviously, you can pick a different base layer, depending on what kind of problem you\'re trying\\nto solve. So anyways, that has been conditional neural networks. I hope you\\nenjoyed that module. Now we\'re on to recurrent neural networks, which is actually gonna be\\npretty interesting. So see you in that module. Hello, everyone, and welcome to the next module\\nin this course, which is covering natural language processing with recurrent neural\\nnetworks. Now, what we\'re going to be doing in this module here is, first of all, first\\noff discussing what natural language processing is, which I guess I\'ll start with here, essentially,\\nfor those of you that don\'t know, natural language processing, or NLP, for short, is\\nthe field or discipline in computing, or machine learning that deals with trying to understand\\nnatural Earth human languages. Now, the reason we call them natural is because these are\\nnot computer languages, or programming languages, per se. And actually, computers are quite\\nbad at understanding textual information and human languages. And that\'s what we\'ve come\\nup with this entire discipline focused on how they can do that. So we\'re going to do\\nthat using something called recurrent neural networks. But some examples of natural language\\nprocessing would be something like spellcheck, autocomplete, voice assistants, translation\\nbetween languages, there\'s all different kinds of things, chatbots, but essentially, anything\\nthat deals with textual data, so you like paragraphs, sentences, even words, that is\\nprobably going to be classified under natural language processing in terms of doing some\\nkind of machine learning stuff with it. Now, we are going to be talking about a different\\nkind of neural network in this series called recurrent neural networks. Now, these are\\nvery good, classifying and understanding textual data. And that\'s why we\'ll be using them.\\nBut they are fairly complex. And there\'s a lot of stuff that goes into them. Now, in\\nthe interest of time, and just not knowing a lot of your math background, I\'m not going\\nto be getting into the exact details of how this works on a lower level, like I did, when\\nI explained kind of our, I guess, fundamental learning algorithms, which are a bit easier\\nto grasp. And even just regular neural networks in general, we\'re going to be kind of skipping\\nover that, and really focusing on why this works the way it does, rather than how and\\nwhen you should use this. And then maybe understanding a few of the different kinds of layers that\\nhave to do with recurrent neural networks. But again, we\'re not going to get into the\\nmath, if you\'d like to learn about that there will be some sources at the bottom of the\\nguide. And you can also just look up recurrent neural networks. And you\'ll find lots of resources\\nthat explain all of the fancy math that goes on behind them. Now, the exact applications\\nand kind of things we\'ll be working towards here is sentiment analysis, that\'s the first\\nkind of task or thing we\'re going to do, we\'re actually going to use movie reviews and try\\nto determine whether these movie reviews are positive or negative by performing sentiment\\nanalysis on them. Now, if you\'re unfamiliar with sentiment analysis, we\'ll talk about\\nit more later. But essentially means trying to determine how positive or negative a sentence\\nor piece of text is, once you can see why that\'d be useful for movie reviews. Next,\\nwe\'re going to do character slash text generation. So essentially, we\'re going to use a natural\\nlanguage processing model, I guess, if you want to call it that, to generate the next\\ncharacter in a sequence of text for us. And we\'re going to use that model a bunch of times\\nto actually generate an entire play. Now, I know this seems a little bit ridiculous\\ncompared to some of the trivial examples we\'ve done before, this will be quite a bit more\\ncode than anything we\'ve really looked at yet. But this is very cool, because we\'re\\nactually going to train a model to learn how to write a play. That\'s literally what it\'s\\ngoing to do, it\'s going to read through a play, I believe it\'s Rumi, Romeo and Juliet.\\nAnd then we\'re going to give it a little prompt when we\'re actually using the model and say,\\nOkay, this is the first part of the play, write the rest of it, and then it will actually\\ngo and write the rest of the characters in the play. And we\'ll see that we can get something\\nthat\'s pretty good using the techniques that we\'ll talk about. So the first thing that\\nI want to do is talk about data. So I\'m going to hop onto my drawing tablet here. And we\'re\\ngoing to compare the difference between textual data and numeric data like we\'ve seen before,\\nand why we\'re going to have to employ some pretty complex and different steps to turn\\nsomething like this, you know, a block of text into some meaningful information that\\nour neural networks actually going to be actually going to be able to understand and process.\\nSo let\'s go ahead and get over to that. Okay, so now we\'re going to get into the problem\\nof how we can turn some textual data into numeric data that we can feed to our neural\\nnetwork. Now, this is a pretty interesting problem. And we\'ll kind of go through as we\\nstart going through it, you should see why this is interesting and why there\'s like difficulties\\nwith the different methods that we pick But the first method that I want to talk about\\nis something called bag of words, in terms of how we can kind of encode and pre process\\ntext into integers. Now, obviously, I\'m not the first person to come up with this bag\\nof words is a very famous almost, I want to say algorithm or method of converting textual\\ndata to numeric data. Although it is pretty flawed. It only really works for simple tasks.\\nAnd we\'re going to understand why in a second. So we\'re going to call this bag of words.\\nEssentially, what bag of words says is, what we\'re going to do is we\'re going to look at\\nour entire training data set Rex, we\'re going to be turning our training data set into a\\nform the network can understand. And we\'re going to create a dictionary lookup of the\\nvocabulary. Now what I mean by that is, we\'re going to say that every single unique word\\nin our data set is the vocabulary, right? That\'s the amount of words that the model\\nis expected to understand, because we\'re going to show all those words to the model. And\\nwe\'re going to say that every single one of these words, so every single one of these\\nwords in the vocabulary is going to be placed in a dictionary. And Beside that, we\'re going\\nto have some integer that represents it. So for example, maybe the vocabulary of our data\\nset is the words you know, I, a, maybe, Tim, maybe day, me, right, we\'re gonna have a bunch\\nof arbitrary words, let\'s put.dot.to show that this kind of goes to the length of the\\nvocabulary. And every single one of these words, we place in a dictionary, which we\'re\\njust going to call kind of our lookup table or word index table. And we\'re going to have\\na number that represents every single one of them. So you can imagine that in very large data\\nsets, we\'re going to have you know, 10s, of 1000s of hundreds of 1000s, sometimes even\\nmaybe millions of different words, and they\'re all going to be encoded by different integers.\\nNow, the reason we call this bag of words is because what we\'re actually going to do\\nwhen we look at a sentence is we\'re only going to keep track of the words that are present\\nand the frequency of those words. And in fact, what we\'ll do well is we\'ll create what we\\ncall a bag, and whenever we see a word appears, we\'ll simply add its number into the bag.\\nSo if I have a sentence, like, you know, I am, Tim de, de, I\'m just going to do like\\na random sentence like that, then what we\'re going to do is, every time we see a word,\\nwe\'re going to take its number and throw it into the back. So we\'re gonna say, all right,\\nI, that\'s zero AM. That\'s one, Tim, that\'s two, day, that\'s three. That\'s three again,\\nand notice that what\'s happening here is we\'re losing the ordering of these words, but we\'re\\njust keeping track of the frequency. Now there\'s lots of different ways to kind of format how\\nwe want to do bag of words. But this is the basic idea I\'m not going to go too far in\\nbecause we\'re not actually really going to use this technique. But essentially, you lose\\nthe ordering in which words appear, but you just keep track of the frequency and what\\nwords appear. So this can be very useful when you\'re looking, you know, you\'re doing very\\nsimple tasks, where the presence of a certain word will really influence the kind of type\\nof sentence it is, or the meaning that you\'re going to get from it. But when we\'re looking\\nat more complex input, where you know, different words have different meanings, depending on\\nwhere they are in a sentence, this is a pretty flawed way to encode this data. Now, I won\'t\\ngo much further into this, this is not the exact way the bag of words works. But I just\\nwanted to show you kind of an idea here, which is we just encode every single unique word\\nby an integer. And then we don\'t even really care about where these words are, we just\\nthrow them into a bag and we say, Alright, you know, this is our bag right here that\\nI\'m doing the arrow to, we\'ll just throw in three, as many times as you know, the word\\nde appears, we\'ll throw in one as many times as the word, I guess, m appears, and so on\\nand so forth. And then what will happen is we\'ll feed this bag to our neural network\\nin some form, depending on the network that we\'re using. And it will just look at and\\nsay, OK, so I have all these different numbers, that means these words are present, and try\\nto do something with it. Now I\'m going to show you a few examples of where this kind\\nof breaks down. But just understand that this is how this works. This is the first technique\\ncalled bag of words, which again, we will not be using. So what happens when we have\\na sentence where the same word conveys a very different meaning. Right? And I\'m actually\\nI think I have an example on the slides here that I\'ll go into. Yes. So like this. Okay,\\nso for our bag of words technique, which we can kind of see here, and maybe we\'ll go through\\nit. Let\'s consider the two sentences. Where are they here? I thought the movie was going\\nto be bad, but it was actually amazing. And I thought the movie was going to be amazing,\\nbut it was actually bad. Right? So consider these two sentences. Now I know you guys already\\nknow what I\'m going to get at. But essentially, these sentences use the exact same words.\\nIn fact, they use the exact same number of words, the exact same words in total. And\\nwell, they have a very different meaning. With our bag of words technique. We\'re actually\\ngoing to encode these two sentences using the exact same representation because remember,\\nall we do is we care about the frequency What words appear, but we don\'t care about where\\nthey appear. So we end up losing that meaning from the sentence. Because the sentence, I\\nthought the movie was going to be bad, but it was actually amazing is encoded and represented\\nby the same thing as this sentences. So that, you know, obviously is an issue. That\'s a\\nflaw. And that\'s one of the reasons why bag of words is not very good to use. Because\\nwe lose the context of the words within the sentence, we just pick up the frequency and\\nthe fact that these words exist. So that\'s the first technique that\'s called bag of words,\\nI\'ve actually written a little function here that does this. For us, this is not really\\nthe exact way that we would write a bag of words function, but you kind of get the idea\\nthat when I have a text, this is a test to see if this test will work is test a, I\'ve\\njust did a bunch of random stuff. So we can see, what I\'m doing is printing out the bag,\\nwhich I get from this function. And you guys can look at this, if you kind of want to see\\nhow this works. And essentially, what it tells us is the word one appears two times. Yes,\\nthe word two appears three times the word three appears three times word four appears\\nthree times 51617. ones, so on, that\'s the information we get from our back right from\\nthat encoding. And then if we look up here, this is our vocabulary. So this stands for\\none is is to AES three, so on, and you can kind of get the idea from that. So that is\\nhow we would use bag of words, right? If we did an encoding kind of like this, that\'s\\nwhat that does. And that\'s one way of encoding it. Now I\'m going to go back and we\'ll talk\\nabout another method here as well, actually a few more methods before we get into anything\\nfurther. Alright, so I\'m sure a lot of you were looking at the previous example I did.\\nAnd you saw the fact that what I did was completely remove the idea of kind of sequence or ordering\\nof words, right. And what I did was just throwing in a bank, and I said, Alright, we\'re just\\ngonna keep track of the fact that we have, you know, three A\'s, or we have for those\\nare seven Tim\'s right, and we\'re gonna just going to lose the fact that, you know, words\\ncome after one each other, we\'re going to lose their ordering in the sentence. And that\'s\\nhow we\'re going to encode it. And I\'m sure a lot of you are saying, Well, why don\'t we\\njust not lose the ordering of those words, we\'ll just encode every single word with an\\ninteger and just leave it in its space where it would have been in the original string.\\nOkay, good idea. So what you\'re telling me to do something like this, you know, Tim,\\nis here will be our sentence. Let\'s say we encode the word Tim was zero is one, here\'s\\ntwo. And then that means our translation goes 012. And that means, right, if we have a translation,\\nsay, like 210, even though these use the exact same number of words, and exact same representation\\nfor all these words, well, this is a different sentence. And our model should be able to\\ntell that because these words come in a different order. And to you good point, if you made\\nthat point. But I\'m going to discuss where this falls apart as well, and why we\'re not\\ngoing to use this method. So although this does solve the problem I talked about previously,\\nwhere we\'re going to kind of lose out on the context of a word, there\'s still a lot of\\nissues with this. And they come especially when you\'re dealing with very large vocabularies.\\nNow let\'s take an example where we actually have a vocabulary of, say, 100,000 words.\\nAnd we know that that means we\'re going to have to have 100,000 unique mappings from\\nwords to integers. So let\'s say our mappings are something like this one, maps to the string\\nhappy, the word happy, right? Two maps to sad. And let\'s say that the string 100,000,\\nor the number 100,000, maps to the word, I don\'t know, let\'s say Good. Now we know as\\nhumans, but kind of just thinking about, let\'s consider the fact that we\'re going to try\\nto classify sentences as a positive or negative. So sentiment analysis, that the words happy\\nand good in that regard, you know, sentiment analysis are probably pretty similar words,\\nright. And then if we were going to group these words, we\'d probably put them in a similar\\ngroup, we classify them as similar words, we could probably interchange them in a sentence,\\nand it wouldn\'t change the meaning a whole ton. I mean, it might, but it might not as\\nwell. And then we could say, these are kind of similar. But our model or our encoder,\\nright, whatever we\'re doing to translate our text into integers here, has decided that\\n100,000 is going to represent good and one is going to represent happy and well, there\'s\\nan issue with that, because that means when we pass in something like one, or 100,000\\nto our model, it\'s gonna have a very difficult time determining the fact that one and 100,000,\\nalthough they\'re 99,999 kind of units apart, are actually very similar words. And that\'s\\nthe issue we get into when we do something like this is that the numbers we decide to\\npick to represent each word are very important. And we don\'t really have a way of being able\\nto look at words, group them, and saying, Okay, well, we need to put all of the happy\\nwords in the range of zero to 100. All of the like adjectives in this range, we don\'t\\nreally have a way to do that. And this gets even harder for a model when we have these\\narbitrary mappings, right? And then we have something like to in between where two is\\nvery close to one, right? Yet these words are complete opposites. In fact, I\'d say they\'re\\nprobably polar opposites. Our model trying to learn that the difference between one and\\ntwo is actually way larger. than the difference between one and 100,000 is going to be very\\ndifficult. And say it\'s even able to do that as soon as we throw in the mapping 900. Not\\nright, the 99,900 we put that as bad. Well, now it gets even more difficult, because it\'s\\nnow like, Okay, what the range is this big, then that means these words are actually very\\nsimilar. But then you throw another word in here like this, and it messes up the entire\\nsystem. So that\'s kind of what I want to show is that that\'s where this breaks apart on\\nthese large vocabularies. And that\'s what I\'m going to introduce us now to another concept\\ncalled word embeddings. Now, what word embeddings does is essentially try to find a way to represent\\nwords that are similar using very similar numbers. And in fact, what a word embedding\\nis actually going to do. And I\'ll talk about this more in detail as we go on is classify\\nor translate every single one of our words into a vector. And that vector is going to\\nhave some, you know, n amount of dimensions, usually, we\'re going to use something like\\n64, or maybe 128 dimensions for each vector. And every single component of that vector\\nwill kind of tell us what group it belongs to, or how similar it is to other words, so\\nlet me give you an idea what I mean. So we\'re going to create something called a word embeddings.\\nNow don\'t ask why it\'s called embeddings. I don\'t know the exact reason but I believe\\nit\'s to have has to do something with the fact that they\'re vectors. And let\'s just\\nsay we have a 3d plane like this. So we\'ve already kind of looked at what vectors are\\nbefore. So I\'ll skip over explaining them. And what we\'re going to do is take some word.\\nSo let\'s say we have the word good. And instead of picking some integer to represent it, we\'re\\ngoing to pick some vector, which means we\'re going to draw some vector in this 3d space,\\nactually, let\'s make this a different color. Let\'s make this vector say red, like this.\\nAnd this vector represents this word good. And in this case, we\'ll say we have x 1x 2x. Three is our dimensions, which means\\nthat every single word in our data set will be represented by three coordinates. So one\\nvector with three different dimensions, where we have x 1x, two and x three. And our hope\\nis that by using this word embeddings layer, and we\'ll talk about how it accomplishes this\\nin a second is that we can have vectors that represent very similar words being very similar,\\nwhich means that you know, if we have the vector good here, we would hope the vector\\nhappy from our previous example, right would be a vector that points in a similar direction\\nto it, that is kind of a similar looking thing where the angle between these two vectors,\\nright, and maybe I\'ll draw it here, so we can see is small so that we know that these\\nwords are similar. And then we would hope that if we had a word that was much different,\\nmaybe say like the word bad, that that would point in a different direction, the vector\\nthat represents it, and that that would tell our model, because the angle between these\\ntwo vectors is so big, that these are very different words, right? Now, in theory, does\\nthe embedding word layer work like this? You know, not always. But this is what it\'s trying\\nto do is essentially pick some representation in a vector form for each word. And then these\\nvectors, we hope, if there\'s similar words are going to be pointing in a very similar\\ndirection. And that\'s kind of the best explanation of a word embeddings layer I can give you.\\nNow, how do we do this, though? How do we actually you know, go from Word to vector,\\nand have that be meaningful? Well, this is actually what we call a layer. So word embeddings\\nis actually a layer, it\'s something we\'re going to add to our model. And that means\\nthat this actually learns the embeddings for our words. And the way it does that is by\\ntrying to kind of pick out context in the sentence and determine based on where a word\\nis in a sentence, kind of what it means, and then encodes it doing that. I know, that\'s\\nkind of a rough explanation to give to you guys, I don\'t want to go too far into Word\\nembeddings, in terms of the math, because I don\'t want to get, you know, waste our time\\nor get too complicated if we don\'t need to, but just understand that our word embeddings\\nare actually trained, and that the model actually learns these word embeddings as it goes. And\\nwe hope that by the time it\'s looked at enough training data, it\'s determined really good\\nways to represent all of our different words, so that they make sense to our model and the\\nfurther layers. And we can use pre trained word embedding layers if we\'d like just like\\nwe use that pre trained convolutional base in the previous section. And we might actually\\nend up doing that, actually, probably not in this tutorial, but it is something to consider\\nthat you can do that. So that\'s how word embeddings work. This is how we encode textual data.\\nAnd this is why it\'s so important that we kind of consider the way that we pass information\\nto our neural network, because it makes a huge difference. Okay, so now that we\'ve talked\\nabout kind of the form that we need to get our data in before we can pass it further\\nin the neural network, right before we can get past that embedding layer, before it can\\nget put in, put into any dense neurons before we can even really do any math with it. We\\nneed to turn it into numbers, right our textual data so now that we know that it\'s time to\\ntalk about recurrent neural networks. Now recurrent neural networks are the type of\\nnetworks we use when we process textual data. Typically, you don\'t always have to use these\\nbut they are just the best for natural language processing. And that\'s why They\'re kind of\\ntheir own class right? Now the fundamental difference between a recurrent neural network\\nand something like a dense neural network or a convolutional neural network, is the\\nfact that it contains an internal loop. Now, what this really means is that the recurrent\\nneural network does not process our entire data at once. So it doesn\'t process the entire\\ntraining example, or the entire input to the model at once. What it does is processes it\\nat different time steps, and maintains what we call an internal memory, and kind of an\\ninternal state so that when it looks at a new input, it will remember what it seen previously,\\nand treat that input based on kind of the context of the understanding, it\'s already\\ndeveloped. Now, I understand that this doesn\'t make any sense right now, with a dense neural\\nnetwork, or the neural networks we looked at so far, we call those something called\\nfeed forward neural networks. What that means is we give all of our data to it at once,\\nand we pass that data from left to right, or I guess for you guys from left to right.\\nSo we give all of the information, you know, we would pass those through the convolutional\\nlayer to start, maybe we pass them through dense neurons, but they get given all of the\\ninfo. And then that information gets translated through the network to the very end again,\\nfrom left to right. Whereas here, with recurrent neural networks, we actually have a loop,\\nwhich means that we don\'t feed the entire textual data at once we actually feed one\\nword at a time, he processes that word, generate some output based on that word, and uses the\\ninternal memory state that is keeping track of to do that as part of the calculation.\\nSo essentially, the reason we do this is because just like humans, when we, you know, look\\nat text, we don\'t just take a photo of this text and process it all at once we read it left to right, word to word. And\\nbased on the words that we\'ve already read, we start to slowly develop an understanding\\nof what we\'re reading, right? If I just read the word Now, that doesn\'t mean much to me,\\nif I just read the word in code, that doesn\'t mean much. Whereas if I read the entire sentence,\\nnow that we\'ve learned a little bit about how we can encode text, I start to develop\\nan understanding about what this next word means based on the previous words before it\\nright. And that\'s kind of the point here is that this is what a recurrent neural network\\nis going to do for us, it\'s going to read one word at a time, and slowly start building\\nup its understanding of what the entire textual data means. And this works in kind of a more\\ncomplicated sense than that will draw it out a little bit. But this is kind of what would\\nhappen if we um, I guess unraveled a recurrent layer, because recurrent neural network, yes,\\nit has a loop in it. But really, the recurrent aspect of a neural network is the layer that\\nimplements this recurrent functionality with a loop. Essentially, what we can see here\\nis that we\'re saying x is our input, and h is our output, x t is going to be our input\\nat time t, whereas each T is going to be our output at time t, if we had a text of, say,\\nlength four, so for words like we\'ve encoded them into integers, now at this point, the\\nfirst input at time zero will be the first word into our network, right, or the first\\nword that this layer is going to see. And the output at that time is going to be our\\ncurrent understanding of the entire text after looking at just that one word. Next, what\\nwe\'re going to do is process input one, which will be the next word in the sentence. But\\nwe\'re going to use the output from the previous kind of computation of the previous iteration.\\nTo do this, so we\'re going to process this word in combination with what we\'ve already\\nseen, and then have a new output, which hopefully should now give us an understanding of what\\nthose two words mean. Next, we\'ll go to the third word, and so forth, and slowly start\\nbuilding our understanding what the entire textual data means by building it up one by\\none, the reason we don\'t pass the entire sequence at once is because it\'s very, very difficult\\nto just kind of look at this huge blob of integers and figure out what the entire thing\\nmeans. If we can do it one by one and understand the meaning of specific words based on the\\nwords that came before it and start learning those patterns, that\'s going to be a lot easier\\nfor a neural network to deal with, than just passing it all at once looking at it in trying\\nto get some output. And that\'s why we have these recurrent layers. There\'s a few different\\ntypes of them. And I\'m going to go through them, and then we\'ll talk a little bit more\\nin depth of how they work. So the first one is called long short term memory. And actually,\\nin fact, before we get into this, let\'s, let\'s talk about just a firt, like a simple layer\\nso that we kind of have a reference point before going here. Okay, so this is kind of\\nthe example I want to use here to illustrate how a recurrent neural network works and a\\nmore teaching style rather than what I was doing before. So essentially, the way that\\nthis works is that this whole thing that I\'m drawing here, right, all of this circle stuff\\nis really one layer. And what I\'m doing right now is breaking this layer apart and showing\\nyou kind of how this works in a series of steps. So rather than passing all the information\\nat once, we\'re going to pass it as a sequence, which means that we\'re going to have all these\\ndifferent words. And we\'re going to pass them one at a time to the code to the layer right\\nto this recurrent layer. So we\'re going to start from this left side over here, as well\\nas right, you know, start over here at time step zero, that\'s what zero mean. So time\\nstep is just you know the order. In this case, this is the first word. So let\'s say we have\\nthe sentence Hi, I am Tim, right, we\'ve broken these down into vectors, they\'ve been turned\\ninto their numbers, I\'m just writing them here. So we can kind of see what I mean in\\nlike a natural language. And they are the input to this recurrent layer. So all of our\\ndifferent words, right, that\'s how many kind of little cells we\'re going to draw here is\\nhow many words we have in this sequence that we\'re talking about. So in this case, we have\\nfour, right four words. So that\'s why I\'ve drawn four cells to illustrate that. Now,\\nwhat we do is that time step zero, the internal state of this layer is nothing, there\'s no\\nprevious output, we haven\'t seen anything yet. Which means that this first kind of cell,\\nwhich is what I\'m looking at right here, what I\'m drawing in this first cell, is only going\\nto look and consider this first word and kind of make some prediction about it and do something\\nwith it, we\'re gonna pass high to the sell, some math is going to go on in here. And then\\nwhat it\'s going to do is it\'s going to output some value, which you know, tells us something\\nabout the word high, right, some numeric value, we\'re not going to talk about what that is,\\nbut it\'s gonna be there\'s gonna be some output. Now, what happens is after the cell has finished\\nprocessing this, so right, so this one\'s done, this is completed h zero, the outputs there,\\nwe\'ll do a check mark to say that that\'s done, it\'s finished processing, this output gets\\nfed into actually the same thing. Again, we\'re kind of just keeping track of it. And now\\nwhat we do is we processed the next input, which is AI. And we use the output from the\\nprevious cell to process this and understand what it means. So now, technically, we should\\nhave some output from the previous cell. So from whatever high was right, we do some analysis\\non the word AI, we kind of combine these things together. And that\'s the output of this cell\\nis our understanding of not only the current input, but the previous input with the current\\ninput. So we\'re slowly kind of building up our understanding of what this word AI means,\\nbased on the words we saw before. And that\'s the point I\'m trying to get at is that this\\nnetwork uses what it\'s seen previously, to understand the next thing that it sees it\'s\\nbuilding a context is trying to understand not only the word but what the word means,\\nyou know, in relation to what\'s come before it. So that\'s what\'s happening here. So then\\nthis output here, right, we get some output, we finish this, we get some output h one,\\nH, one is passed into here. And now we have the understanding of what high and\\nAI means. And we add em like that, we do some kind of computations, we build an understanding\\nwhat the sentences, and then we get the output h2, that passes to H three. And they\'ll Finally\\nwe have this final output H three, which is going to understand hopefully, what this entire\\nthing means. Now, this is good, this works fairly well. And this is called a simple RNN\\nlayer, which means that all we do is we take the output from the previous cell of the previous\\niteration, because really all of these cells is just an iteration, almost an a for loop,\\nright based on all the different words in our sequence. And we slowly start building\\nto that understanding as we go through the entire sequence. Now, the only issue with\\nthis is that as we have a very long sequence, so sequences of length, say 100, or 150, the\\nbeginning of those sequences starts to kind of get lost as we go through this because\\nremember, all we\'re doing right is the output from h2 is really a combination of the output\\nfrom h zero and H one. And then there\'s a new word that we\'ve looked at, and H three\\nis now a combination of everything before it and this new word. So it becomes increasingly\\ndifficult for our model to actually build a really good understanding of the text in\\ngeneral, when the sequence gets long, because it\'s hard for me to remember what it seemed\\nat the very beginning because that is now so insignificant, there\'s been so many outputs\\ntacked on to that, that is hard for it to go back and see that if that makes any sense.\\nOkay, so what I\'m going to do now is try to explain the next layer we\'re going to look\\nat which is called LS tm. So the previous layer, we just looked at the recurrent layer\\nwas called a simple RNN layer. So simple recurrent neural network layer, whatever you want to\\ncall it, right simple, recurrent layer. Now we\'re going to talk about the layer which\\nis lsdm, which stands for long short term memory. Now long and short, are hyphenated\\ntogether. But essentially what we\'re doing and it just gets a little bit more complex,\\nbut I won\'t go into the math is we add another component that keeps track of the internal\\nstate. So right now, the only thing that we were tracking As kind of our internal state\\nas the memory for this model was the previous output. So whatever the previous output was,\\nso for example, at time zero here, there was no previous output, so there was nothing being\\nkept in this model. But at time one, the output from this cell right here was what we were\\nstoring. And then at sell to, the only thing we were storing was the output at time one,\\nright, and we\'ve lost now the output from time zero, what we\'re adding in long short\\nterm memory is an ability to access the output from any previous state at any point in the\\nfuture when we want it. Now, what this means is that rather than just keeping track of\\nthe previous output, we\'ll add all of the outputs that we\'ve seen so far into what\\nI\'m going to call my little kind of conveyor belt, it\'s going to run at the top up here,\\nI know it\'s kind of hard to see, but it\'s just what I\'m highlighting, it\'s almost just\\nlike a lookup table that can tell us the output at any previous cell mean that we want. So\\nwe can kind of add things to this conveyor belt, we can pull things off, we can look\\nat them. And this just adds a little bit of complexity to the model, it allows us to not\\njust remember the last state, but look anywhere at any point in time, which can be useful.\\nNow, I don\'t want to go into much more depth about exactly how this works. But essentially,\\nyou know, just think about the idea that as the sequence gets very long, it\'s pretty easy\\nto forget the things we saw at the beginning. So if we can keep track of some of the things\\nwe\'ve seen at the beginning, and some of the things in between on this little conveyor\\nbelt, and we can access them whenever we want, then that\'s going to make this probably a\\nmuch more useful layer, right, we can look at the first sentence and the last sentence\\nof a big piece of text at any point that we want, and say, okay, you know, this tells\\nus x about the meaning of this text, right. So that\'s what this lsdm does. I again, I\\ndon\'t want to go too far, we\'ve already spent a lot of time kind of covering, you know,\\nrecurrent layers and how all this works. Anyways, if you do want to look it up some great mathematical\\ndefinitions, again, I will source everything at the bottom of this document, so you can\\ngo there. But again, that\'s lsdm long short term memory. That\'s what we\'re going to use\\nfor some of our examples. Although simple, RNN does work fairly well for shorter length\\nsequences. And again, remember, we\'re treating our text as a sequence. Now, we\'re going to\\nfeed each word into the recurrent layer, and it\'s going to slowly start to develop an understanding\\nas it reads through each word right and processes that Okay, so now we are on to our first example,\\nwhere we\'re going to be performing sentiment analysis on movie reviews to determine whether\\nthey are positive reviews or negative reviews. Now, we already know what sentiment means.\\nThat\'s essentially what I just described. So picking up you know whether a block of\\ntext is considered positive or negative. And for this example, we\'re gonna be using the\\nmovie review data sets. Now, as per usual, this is based off of this TensorFlow tutorial\\nslash guide, I found this one kind of confusing to follow on the TensorFlow website. But obviously,\\nyou can follow along with that if you not prefer that version overmind. But anyways,\\nwe\'re going to be talking about the movie review data set. So this data set is straight\\nfrom Kara\'s, and contains 25,000 reviews, which are already pre processed and labeled.\\nNow what that means for us is that every single word is actually already encoded by an integer.\\nAnd in fact, they\'ve done kind of a clever encoding system where what they\'ve done is\\nsaid, if a character is encoded by say, integer zero, that represents how common that word\\nis in the entire data set. So if an integer was encoded by or non integer, a word was\\nencoded by integer three, that would mean that it is the third most common word in the\\ndata set. And in this specific data set, we have vocabulary size of 88,584, unique words,\\nwhich means that something that was classified as this, so 88,584, would be the least common\\nword in the data set. So certainly keep in mind, we\'re going to load in the data set\\nand do our imports just by hitting run here. And as I\'ve mentioned previously, you know,\\nI\'m not going to be typing this stuff out, it\'s just kind of a waste of time, I don\'t\\nhave all the syntax memorize, I would never expect you guys to memorize this either. But\\nwhat I will do is obviously walk through the code step by step, and make sure you understand\\nwhy it is that we have what we have here. Okay. So what we\'ve done is defined the vocabulary\\nsize, the max length of review, and the batch size. Now, what we\'ve done is just loaded\\nin our data set, by defining the vocabulary size. So this is just the words that will\\ninclude so in this case, all of them. Then we have trained data, train labels, test data,\\ntest labels, and we can look at a review and see what it looks like by doing something\\nlike this. So this is an example of our first review, we can see kind of the different encodings\\nfor all of these words. And this is what it looks like they\'re already in integer form.\\nNow, just something to note here is that the length of our reviews are not unique. So if\\nI do the Len of train data, I guess I wouldn\'t say unique, but I mean, they\'re just all different.\\nSo the lead of trained at zero is different than the land of trained data one, right?\\nSo that\'s something to consider, as we go through this and something we\'re actually\\ngoing to have to handle. Okay, so More pre processing. So this is what I was talking\\nabout. If you have a look at our loaded interviews, we\'ll notice they\'re of different lengths.\\nThis is an issue, we cannot pass different like data into our neural network, which is\\ntrue. Therefore, we must make each review the same length. Okay, so what we\'re going\\nto do for now is we\'re actually going to pad our sequences. Now, what that means is, we\'re\\ngoing to follow this kind of step that I\'ve talked about here. So if the review is greater\\nthan 250 words, we will trim off extra words, if the review is less than 250 words will\\nadd the necessary amount of this should actually be zeros in here, let\'s fix this of zeros\\nto make it equal to 250. So what that means is, we\'re essentially going to add some kind\\nof padding to a review. So in this case, I believe we\'re actually going to pad to the\\nleft side, which means that say we have a review of length, you know, 200, we\'re going\\nto add 50, just kind of blank words, which will represent with the index zero to the\\nleft side of the review to make it the necessary length. So that\'s, that\'s good, we\'ll do that.\\nSo if we look at train data and test data, what this does is we\'re just gonna use something\\nfrom Kara\'s, which we\'ve imported above. So we\'re saying from Kara\'s pre processing, import\\nsequence, again, we\'re treating our text data as a sequence, as we\'ve talked about, we\'re\\ngonna say sequence dot pad sequences, train data, and then we define the length that we\\nwant to pad it to. So that\'s what this will do, it will perform these steps that we\'ve\\nalready talked about. And again, we\'re just going to assign test data and train data to\\nyou know, whatever this does for us, we pass the entire thing, it\'ll pass all of them for\\nus at once. Okay, so let\'s run that. And then let\'s just have a look at say, train data\\none now, because remember, this was like 189, right? So if we look at train data, so train\\nunderscore data, one, like that, we can see those an array with a bunch of zeros before,\\nbecause that is the padding that we\'ve employed to make it the correct length. Okay, so that\'s\\npadding, that\'s something that we\'re probably gonna have to do most of the time when we\\nfeed something to our neural networks. Alright, so the next step is actually to create the\\nmodel. Now, this model is pretty straightforward. We have an embedding layer and lsdm, and a\\ndense layer here. So the reason we\'ve done dense with the activation function of sigmoid\\nat the end, is because we\'re trying to pretty much predict the sentiment of this, right,\\nwhich means that if we have the sentiment between zero and one, then if a number is\\ngreater than 0.5, we could classify that as a positive review. And if it\'s less than 0.5,\\nor equal, you know, whatever you want to set the bounds at, then we can say that\'s a negative\\nreview. So sigmoid, as we probably might recall, squishes, our values between zero and one,\\nso whatever the value is, at the end of the network will be between zero and one, which\\nmeans that you know, we can make the accurate prediction. Now here, the reason we have the\\nembedding layer, like Well, we\'ve already pre processed our review is, even though we\'ve\\npre processed this with these integers, and they are a bit more meaningful than just our\\nrandom lookup table that we\'ve talked about before, we still want to pass that to an embedding\\nlayer, which is going to find a way more meaningful representation for those numbers than just\\nthere integer values already. So it\'s going to create those vectors for us. And this 32\\nis denoting the fact that we\'re going to make the output of every single one of our embeddings,\\nor vectors that are created 32 dimensions, which means that when we pass them to the\\nlsdm layer, we need to tell the lsdm layer, it\'s going to have 32 dimensions for every\\nsingle word, which is what we\'re doing. And this will implement that long short term memory\\nprocess we talked about before, and output the final output to tf Kerris layers dense,\\nwhich will tell us you know, that\'s what this is right? It\'ll make the prediction. So that\'s\\nwhat this model is, we can see, let me give us a second to run here, the model summary,\\nwhich is already printed out, we can look at the fact that the embedding layer actually\\nhas the most amount of parameters, because essentially, it\'s trying to figure out, you\\nknow, all these different numbers, how can we convert that into a tensor of 32 dimensions,\\nwhich is not that easy to do. And this is going to be the major aspect that\'s being\\ntrained. And then we have our lsdm layer, we can see the parameters there. And our final\\ndense layer, which is eight getting 33 parameters. That\'s because the output from every single\\none of these dimensions 32 plus a bias node, right that we need. So that\'s what we\'ll get\\nthere. You can see monitored summary, we get the sequential model. Okay. So training. Alright,\\nso now it\'s time to compile and train the model, you can see I\'ve already trained mine.\\nWhat I\'m going to say here is if you want to speed up your training, because this will\\nactually take a second and we\'ll talk about why we pick these things in a minute is go\\nto runtime, change runtime type, and add a hardware accelerator of GPU. What this will\\nallow you to do is utilize a GPU while you\'re training, which should speed up your training\\nby about 10 to 20 times. So I probably should have mentioned that beforehand. But you can\\ndo that. And please do for these examples. So model compile. Alright, so we\'re compiling\\nour model. We\'re picking the loss function as binary cross entropy. The reason we\'re\\npicking this is because this is going to essentially tell us how far away From the correct probability,\\nright, because we have two different things we could be predicting. So you know, either\\nzero or one so positive or negative. So this will give us a correct loss for that kind\\nof problem that we\'ve talked about before. The optimizer, we\'re gonna use RMS prop again,\\nI\'m not going to discuss all the different optimizers, you can look them up if you care\\nthat much about what they do. And we\'re gonna use metrics as ACC, one thing I will say is\\nthe optimizer is not crazy important. For this one, you can use atom if you wanted to,\\nand it would still work fine. My usual go to is just use the atom optimizer unless you\\nthink there\'s a better one to use. But anyways, that\'s something to mention. Okay, so finally,\\nwe will fit the model, we\'ve looked at the syntax a lot before. So model that fit will\\ngive the training data, the training labels, the epochs, and we\'ll do a validation split\\nof 20%, such as 0.2 stands for, which means that what we\'re going to be doing is using\\n20% of the training data to actually evaluate and validate the models we go through. And\\nwe can see that after training, which I\'ve already done, and you guys are welcome to\\nobviously do on your own computer, we kind of stall out an evaluation accuracy of about\\n88%. Whereas the model actually gets overfit to about 97 98%. So what this is telling us\\nessentially, is that we don\'t have enough training data and that after we\'ve even done\\njust one epoch, we\'re pretty much stuck on the same validation accuracy, and that there\'s\\nsomething that needs to change in the model to make it better. But for now, that\'s fine.\\nWe\'ll leave it the way that it is. Okay, so now we can look at the results. I\'ve already\\ndid the results here, just to again, speed up some time. But we\'ll do the evaluation\\non our test data and test labels to get a more accurate kind of result here. And that\\ntells us we have an accuracy of about 85.5%, which you know, isn\'t great, but it\'s decent,\\nconsidering that we didn\'t really write that much code to get to the point that we\'re at\\nright now. Okay, so that\'s what we\'re getting the models been trained. Again, it\'s not too\\ncomplicated. And now we\'re on to making predictions. So the idea is that now we\'ve trained our\\nmodel, and we want to actually use it to make a prediction on some kind of movie review.\\nSo since our data was pre processed, when we gave it to the model, that means we actually\\nneed to process anything, we want to make a prediction on in the exact same way, we\\nneed to use the same lookup table, we need to encode it, you know, precisely the same.\\nOtherwise, when we give it to the model, it\'s going to think that the words are different,\\nand it\'s not going to make an accurate prediction. So what I\'ve done here is I\'ve made a function\\nthat will encode any text into what he called the proper pre processed kind of integers,\\nright, just like our training data was pre processed, that\'s what this function is going\\nto do for us is pre processed some line of text. So what I\'ve done is actually gotten\\nthe lookup table. So essentially, the mappings from IBM IB I am IMDb could read that properly\\nfrom that data set that we loaded earlier. So let me go see if I can find where I defined\\nIMDb. You can see up here. So Kara\'s dot data sets import IMDb, just like we loaded it in,\\nwe can also actually get all of the word indexes in that map, we can actually print this out\\nif we want to look at what it is after. But anyways, we have that mapping, which means\\nthat all we need to do is Cara\'s pre processing text, text to word sequence What this means\\nis give given some text, convert all of that text into what we call tokens, which are just\\nthe individual words themself. And then what we\'re going to do is just use a kind of for\\nloop inside of here that says word index at word if word in Word index, LC, euro for word\\nand tokens. Now what this means is essentially, if the word that\'s in these tokens now is\\nin our mapping, so in that vocabulary of 88,000 words, then what we\'ll do is replace its location\\nin the list with that specific word, or with that specific integer that represents it.\\nOtherwise, we\'ll put zero just to stand for, you know, we don\'t know what this character\\nis. And then what we\'ll do is return sequence dot pad sequences. And we\'ll pad this token\\nsequence. And just return actually the first index here. The reason we\'re doing that is\\nbecause this pad sequences works on a list of sequences, so multiple sequences. So we\\nneed to put this inside a list, which means that this is going to return to us a list\\nof lists. So we just obviously want the first entry because we only want you know that one\\nsequence that we padded. So that\'s how this works. Sorry, it\'s a bit of a mouthful to\\nexplain. But you guys can run through and print this stuff out if you want to see how\\nall of it works specifically. But yeah, so we can run this cell and have a look at what\\nthis actually does for us on some sample text. So that movie was just amazing. So amazing.\\nWe can see we get the output that we were kind of expecting so integer encoded words\\ndown here, and then a bunch of zeros just for all the padding. Now while we\'re at it,\\nI decided why not? Why don\'t we make a decode function so that if we have any movie review\\nlike this, that\'s in the integer form, we can decode that into the text value. So the\\nway we\'re going to do that is start by reversing the word index that we just created. Now the\\nreason for that is the word index we looked at which is this right? goes from Word to\\ninteger. But we actually now want to go from integer to word so that we can actually translate\\na sentence, right. So what I\'ve done is made this decode integers function, we\'ve set the\\npadding key zero, which means that if we see zero, that\'s really just means you know nothing\'s\\nthere, we\'re going to create a text string, which we\'re going to add to that I\'m ucsa.\\nFor num in integers, integers is our input, which will be a list that looks something\\nlike this, or an array, whatever you want to call it, we\'re gonna say if number does\\nnot equal pad, so essentially, if the number is not zero, right, it\'s not padding, then\\nwhat we\'ll do is add the lookup of reverse word index num. So whatever that number is,\\ninto this new string plus a space and then just return text colon negative one, which\\nmeans return everything except the last space that we would have added. And then if I print\\nthe decode integers, we can see that this encoded thing that we had before, which looks\\nlike this gets encoded by the string, that movie was just amazing soulmates are not encoded\\ndecoded, because this was the encoded form. So that\'s how that works. Okay, so now it\'s\\ntime to actually make a prediction. So I\'ve written a function here that will make a prediction\\non some piece of text as the movie review for us. And I\'ll just walk us through quickly\\nhow this works, then I\'ll show us the actual output from our model, you know, making predictions\\nlike this. So what we say is, we\'ll take some parameter text, which will be our movie review.\\nAnd we\'re going to encode that text using the ENCODE text function we\'ve created above.\\nSo just this one right here, that essentially takes our sequence of words, we get the pre\\nprocessing, so turn that into a sequence, remove all the spaces, whatnot, you know,\\nget the words, then we turn those into the integers, we have that we return that. So\\nhere we have our proper pre processed text, then what we do is we create a blank NumPy\\narray, that is just a bunch of zeros, that\'s in the form one 254 in that shape. Now, the\\nreason I\'m putting in that in that shape is because the shape that our model expects is\\nsomething 250, which means some number of entries, and then 250, integers representing\\neach word, right, because that\'s the length of movie review, is what we\'ve told the model\\nis like 250. So that\'s the length of the review, then what we do is we put press zero, so that\'s\\nwhat\'s up here, equals the encoded text. So we just essentially insert our one entry into\\nthis, this array we\'ve created, then what we do is say model dot predict on that array,\\nand just return and print the result zero. Now, that\'s pretty much all there is to it.\\nI mean, that\'s how it works. The reason we\'re doing result zero is because again, model\\nis optimized to predict on multiple things, which means like, I would have to do you know,\\nlist of encoded text, which is kind of what I\'ve done by just doing this prediction lines\\nhere, which means it\'s going to return to me an array of arrays. So if I want the first\\nprediction, I need to index zero, because that will give me the prediction for our first\\nand only entry. Alright, so I hope that makes sense. Now we have a positive review, I\'ve\\nwritten in a negative review, and we\'re just going to compare the analysis on both of them.\\nSo that movie was so awesome, I really loved it, and would watch it again, because it was\\namazingly great. And then that movie sucked, I hated it and wouldn\'t watch it again, was\\none of the worst things I\'ve ever watched. So let\'s look at this. Now, we can see the\\nfirst one gets predicted at 72% positive, whereas the other one is 23%. positive. So\\nessentially, what that means is that, you know, if the lower the number, the more negative\\nwe\'re predicting it is, the higher the number, the more positive we\'re predicting it is if\\nwe wanted to not just print out this value, and instead what we wanted to do was print\\nout, you know, positive or negative, we could just make a little if statement, it says if\\nthis number is greater than 0.5, say positive, otherwise say not say negative, right. And\\nI just want to show you that changing these reviews ever so slightly actually makes a\\nbig difference. So if I remove the word Awesome, so that movie was so and then I run this,\\nyou can see that, oh, wow, this actually increases and goes up to 84%. Right? So the presence\\nof certain words and certain locations actually makes a big difference. And especially when\\nwe have a shorter length review, right? If we have a longer length review, it won\'t make\\nthat big of a difference. But even the removal of a few words here. And let\'s see. So the\\nremoving the word awesome changed it by almost like 10%. Right? Now, if I move. So let\'s\\nsee if that makes a bigger difference, it makes very little difference because it\'s\\nlearned at least the model, right that the word so doesn\'t really make a huge impact\\ninto the type of review. Whereas if I remove the word I let\'s see if that makes a big impact.\\nProbably not right now it goes back up to 84. So that\'s cool. And that\'s something to\\nplay with is removing certain words and seeing how much impact those actually carry. And\\neven if I just add the word great, like would great. Watch it again, just in the middle\\nof the sentence doesn\'t have to make any sense. Let\'s look at this here. Oh, boom, we increase\\nlike a little bit right? And let\'s say if I add this movie, you really suck. Let\'s see\\nif that makes a difference. No, that just reduces it like a tiny bit. So swing cool,\\nsomething to play with me. Now let\'s move on to the next example. So now we\'re on to\\nour last and final example, which is going to be creating a recurrent neural network\\nplate generator, this is going to be the first kind of neural network we\'ve done, that\'s\\nactually going to be creating something for us. But essentially, what we\'re going to do\\nis make a model that\'s capable of predicting the next character in a sequence. So we\'re\\ngoing to give it some sequence as an input. And what it\'s going to do is just simply predict\\nthe most likely next character. Now there\'s quite a bit that\'s going to go into this,\\nbut the way we\'re going to use this to predict a play is we\'re going to train the model on\\na bunch of sequences of texts from the play Romeo and Juliet. And then we\'re going to\\nhave it so that we\'ll ask the model, we\'ll give it some starting prompt some string to\\nstart with. And that\'ll be the first thing we pass to it, it will predict to us with\\nthe most likely next character for that sequence is, and we\'ll take the output from the model\\nand feed it as the input again to the model and keep predicting sequence of characters.\\nSo keep predicting the next character from the previous output as many times as we want\\nto generate an entire play. So we\'re gonna have this neural network that\'s capable of\\npredicting one letter at a time, actually end up generating an entire play for us by\\nrunning it multiple times on the previous output from the last iteration. Now, that\'s\\nkind of the problem. That\'s what we\'re trying to solve. So let\'s go ahead and get into it\\nand talk about what\'s involved in doing this. So the first thing we\'re going to do, obviously,\\nis our imports. So from Kara\'s pre processing, import sequence, import Kara\'s we need TensorFlow\\nNumPy, and oh, S. So we\'ll load that in. And now what we\'re gonna do is download the file,\\nso the data set for Romeo and Juliet, which we can get by using this line here. So Kerris\\nhas this utils thing, which will allow us to get a file, save it as whatever we want.\\nIn this case, we\'re gonna save it as Shakespeare dot txt, and we\'re going to get that from\\nthis link. Now, I believe this is just some like shared drive that we have access to from\\nKara\'s, so we\'ll load that in here. And then this will simply give us the path on this\\nmachine, because remember, this is Google Collaboratory, to this text file. Now, if\\nyou want, you can actually load in your own text data. So we don\'t necessarily need to\\nuse the Shakespeare play, we can use anything we want. In fact, an example that I\'ll show\\nlater is using the B movie script. But the way you do that is run this block of code\\nhere. And you\'ll see that it pops up this thing for choose files, just choose a file\\nfrom your local computer. And then what that will do\\nis just save this on Google Collaboratory. And then that will allow you to actually use\\nthat. So make sure that\'s a txt file that you\'re loading in there. But regardless, that\\nshould work. And then from there, you\'ll be good to go. So if you, you know, you don\'t\\nneed to do that, you can just run this block of code here, if you want to load in the Shakespeare.\\ntxt, but otherwise, you can load in your own file. Now, after we do that, we want to do\\nis actually open this file. So remember, that was just saving the path to it. So we\'ll open\\nthat file in RB mode, which is read bytes mode, I believe. And then we\'re going to say\\ndot read, and we\'re going to read that in as an entire string, we\'re going to decode\\nthat into UTF, eight format. And then we\'re just printing the length of the text or the\\namount of characters in the text. So if we do that, we can see we have the length of\\nthe text is 1.1 million characters approximately. And then we can have a look at the first 250\\ncharacters by doing this. So we can see that this is kind of what the plate looks like\\nwe have whoever speaking colon, then some line, whoever speaking colon, some line, and\\nthere\'s all these brake lines. So backslash ends, which are telling us, you know, go to\\nthe next line, right. So it\'s going to be important, because we\'re going to hope that\\nour neural network will be able to predict things like brake lines and spaces, and even\\nthis kind of format as we teach it more and get further in. But now it\'s time to talk\\nabout encoding. So obviously, all of this text is in text form, it\'s not pre processed\\nfor us, which means we need to pre process it and encode it as integers before we can\\nmove forward. Now fortunately, for us, this problem is actually a little bit easier than\\nthe problem we discussed earlier with encoding words, because what we\'re going to do is simply\\nencode each character in the text with an integer. Now, you can imagine why this makes\\nthis easier because there really is a finite set of characters. Whereas there\'s kind of\\nindefinite, or, you know, I guess, infinite amount of words that could be created. So\\nwe\'re not really going to run into the problem where, you know, two words are encoded with\\nsuch differ two characters are encoded with such different integers. That makes it difficult\\nfor the model to understand because, I mean, we can look at what the value vocab is here,\\nwe\'re only going to have so many characters in the text. And for characters, it just doesn\'t\\nmatter as much because you know, an R isn\'t like super meaningful compared to an A. So\\nwe can kind of encode in a simple format, which is what we\'re going to do. So essentially,\\nwe need to figure out how many unique characters are in our vocabulary. So to do that, we\'re\\ngoing to say vocab equals sorted set text. This will sort all of the unique characters\\nin the text. And then what we\'re going to do is create a mapping from unique characters\\nto index indices. So essentially we\'re gonna say UI for IU in a new enumerate vocabulary.\\nWhat this will do is give us, essentially zero, whatever the string is, one, whatever\\nthe string is to whatever the string is, for every single letter or character in our vocabulary,\\nwhich will allow us to create this mapping. And then what we\'ll do is just turn this initial\\nvocabulary into a list or into an array. So we can just use the index at which a letter\\nappears as the reverse mapping. So going from index to letter, rather than lettered index,\\nwhich is what this one\'s doing here. Next, I\'ve just written a function that takes some\\ntext and converts that to an int, or the into representation for it just to make a little\\nbit easier for us as we get later on in the tutorial. So we\'re just going to say NP dot\\narray of in this case, and we\'re just going to convert every single character in our text\\ninto its integer representation by just referencing that character, and putting that in a list\\nhere, and then obviously, converting that to NumPy array. So then, if we wanted to have\\na look at how this works, we can say text as int equals text to int text. So remember,\\ntext is that entire loaded file that we had above here. So we\'re just going to convert\\nthat to its integer representation entirely using this function. And now we can look at\\nhow this works down here. So we can see that the text first citizen, which is the first\\n13 letters, is encoded by 1840 750-657-5081. And obviously, each character has its own\\nencoding. And you can go through and kind of figure out what they are based on the ones\\nthat are repeated, right. So that is how that works. Now, I figured while we were at it,\\nwe might as well write a function that goes the other way. So into Tech\'s reason I\'m trying\\nto convert this to a NumPy array first is just because we\'re going to be passing in\\ndifferent objects potentially in here. So if it\'s not already a NumPy array, it needs\\nto be a NumPy array, which is kind of what this is doing. Otherwise, we\'re just going\\nto pass on that we don\'t need to convert it to a NumPy array, if it already has one, we\\ncan just join all of the characters from this list into here. So that\'s essentially what\\nthis is doing for us it just joining into text. And then we can see if we go into text\\ntext is int, colon 13. That translates that back to us first citizen. I mean, you can\\nlook more into this function if you want, but it\'s not that complicated. Okay, so now\\nthat we have all this text encoded as integers, what we need to do is create some training\\nexamples, it\'s not really feasible to just pass the entire, you know, 1.1 million characters\\nto our her model at once for training, we need to split that up into something that\'s\\nmeaningful. So what we\'re actually going to be doing is creating training examples where\\nwe have B first, where the training input, right, so the input value is going to be some\\nsequence of some length, we\'ll pick the sequence length, in this case, we\'re actually going\\nto pick 100, and then the output or the expected output, so I guess, like the label for that\\ntraining example, is going to be the exact same sequence shifted right by one character.\\nSo essentially, I put a good example here, our input will be something like hell, right.\\nNow, our output will be e Ll O. So what it\'s going to do is predict this last\\ncharacter, essentially. And these are what our training samples are going to look like.\\nSo the entire beginning sequence, and then the output sequence should be that beginning\\nsequence minus the first letter, but tack on what the last letter should be. So that\\nthis way, we can look at some input sequence and then predict that output sequence that\\nyou know, plus a character, right. Okay, so that\'s how that works. So now we\'re going\\nto do is define a sequence length of 100, we\'re going to say the amount of examples\\nper epoch is going to be the length of the text divided by the sequence length plus one.\\nThe reason we\'re doing this is because for every training example, we need to create\\na sequence input that\'s 100 characters long. And we need to create a sequence output that\'s\\n100 characters long, which means that we need to have 101 characters that we use for every\\ntraining example, right? Hopefully, that would make sense. So what this next line here is\\ngoing to do is convert our entire string data set into characters. And it\'s actually going\\nto allow us to have a stream of characters, which means that it\'s going to essentially\\ncontain 1.1 million characters inside of this TF dot data set object from tensor slices.\\nThat\'s what that\'s doing. Next, so let\'s run this and make sure this works. All right,\\nwhat we\'re going to do is say sequences is equal to char data set dot batch sequence\\nlength is the length of each batch. So in this case, one to one, and then drop remainder\\nmeans let\'s say that we have, you know, 105 characters in our text. Well, since we need\\nsequences of length 101, we\'ll just drop the last four characters of our tax because we\\ncan even put those into a batch. So that\'s what this is doing for us is going to take\\nour entire character data set here that we\'ve created, and batch it into length of 101,\\nand then just drop the remainder. So that\'s what we\'re going to do. sequences does. Now\\nsplit input target. What this is going to do essentially is just create those training\\nexamples that we needed. So taking this these sequences of 101 length, and converting them\\ninto the input and target text, and I\'ll show you how they work in a second, we can do this\\nconvert the sequences to that by just mapping them to this function. So that\'s what this\\nfunction does. So if we say sequences dot map, and we put this function here, that means\\nevery single sequence will have this operation applied to it. And that will be stored inside\\nthis data set object. Or I guess you\'d say object, but we\'ll also just say that\'s it\'s\\ngonna be, you know, the variable, right. So if we want to look at an example of how this\\nworks, we can kind of see so it just says example. The input will be first citizen.\\nBefore we proceed any further hear me speak, all speak speak, first citizen you and the\\noutput, notice the first characters gone, starts at I, in the last character is actually\\njust a space here. Whereas here, it didn\'t have a space. So you can see there\'s no space.\\nHere, there is a space, that\'s kind of what I\'m trying to highlight for you. The next\\nexample, we get are all resolved rather to die rather than family, whatever it goes to\\nhere, right. And then you can see here, we omit that a, and the next letter is actually\\na K, right? That\'s added in there. So that\'s how that works. Okay, so next, we need to\\nmake training batches. So we\'re gonna say the batch size equals 64. The vocabulary size\\nis the length of the vocabulary, which if you remember, all the way back up to the top\\nof the code was the set, or the sorted set of the text, which essentially told us how\\nmany unique characters are in there, the embedding dimension is 256, the RNN units is 1024. And\\nthe buffer size is 10,000. What we\'re going to do now is create a data set that shuffles\\nwe\'re going to switch around all these sequences, they don\'t get shown in the proper order,\\nwhich we actually don\'t want. And I\'m going to batch them by the batch size. So if we\\nhaven\'t kind of gone over what batching. And all this does before. I mean, you can read\\nthese comments as a straight from the TensorFlow documentation, what we want to do is feed\\nour model 64 batches of data at a time. So what we\'re going to do is shuffle all the\\ndata batches into that size, and then again, drop the remainder. If there\'s not enough\\nbatches, which is what we\'ll do, we\'re going to define the embedding dimension, which is\\nessentially, how big we want every single vector to represent our words are in the embedding\\nlayer, and then the RNN units, I won\'t really discuss what that is right now. But that\'s\\nessentially how many, it\'s hard to really, I\'m just gonna omit describing that for right\\nnow. Because I don\'t want to butcher an explanation. It\'s not that important. Anyways, okay, so\\nnow we\'re gonna go down to building the model. So we\'ve kind of set these parameters up here,\\nremember what those are, we\'ve batched. And we\'ve shuffled the data set. And again, that\'s\\nhow this works, you can print it out if you want to see what a batch actually looks like.\\nBut essentially, it\'s just 64 entries of those sequences, right. So 64 different training\\nexamples is what a batch of that is. Alright, so now we go down here, and we\'re gonna say\\nbuild model, we\'re actually making a function is going to return to us a built model. The\\nreason for this is because, right now, we\'re going to pass the model batches of size 64,\\nfor training, right. But what we\'re going to do later is save this model, and then we\'re\\ngoing to patch pass it batches of one pieces of you know, training, whatever data so that\\nyou can actually make a prediction on just one piece of data. Because for right now,\\nwhat it\'s going to do is take a batch size of 64, it\'s gonna take 64 training examples\\nand return to a 64 outputs. That\'s what this model is going to be built to do the way we\\nbuild it now to start. But later on, we\'re going to rebuild the model using the same\\nparameters that we\'ve saved and trained for the model. But change it just be a batch size\\nof one. So that that way, we can get one prediction for one input sequence, right? So that\'s why\\nI\'m creating this build model function. Now in here, it\'s going to have the vocabulary\\nsizes first argument, the embedding dimension, which remember was 256 as a second argument,\\nbut also these are the parameters up here, right? And then we\'re going to find the batch\\nsize, as you know, batch size none would this none means is we don\'t know how long the sequences\\nare going to be in each batch. All we know is that we\'re going to have 64 entries in\\neach batch. And then of those 64 entries. So training examples, right, we don\'t know\\nhow long each one will be, although in our case, we\'re going to use ones that are length\\n100. But when we actually use the model to make predictions, we don\'t know how long the\\nsequence is going to be that we input so we leave this nun. Next we\'ll make an LSTM layer,\\nwhich is long short term memory RNN units, which is 1024, which again, I don\'t really\\nwant to explain, but you can look up if you want return sequences means return the intermediate\\nstage at every step. The reason we\'re doing this is because we want to look at what the\\nmodel is seeing at the end. immediate steps and not just the final stage. So if you leave\\nthis as false, and you don\'t set this to true, what happens is this lsdm just returns one\\noutput, that tells us what the model kind of found at the very last time step. But we\\nactually want the output at every single time step for this specific model. And that\'s why\\nwe\'re setting this true stateful, I\'m not going to talk about that one, right now, that\'s\\nsomething you can look up if you want. And then recurrent initializer is just what these\\nvalues are going to start at, in the lsdm. We\'re just picking this because this is what\\nTensorFlow is kind of said is a good default to pick, I won\'t go into more depth about\\nthat, again, things that you can look up more if you want. Finally, we have a dense layer,\\nwhich is going to contain the amount of vocabulary size notes. The reason we\'re doing this is\\nbecause we want the final layer to have the amount of nodes in it equal to the amount\\nof characters in the vocabulary. This way, every single one of those nodes can represent\\na probability distribution that that character comes next. So all of those nodes value some\\nsum together should give us the value of one. And that\'s going to allow us to look at that\\nlast layer as a predictive layer, where it\'s telling us the probability that these characters\\ncome next, we\'ve discussed how that\'s worked previously with other neural networks. So\\nlet\'s run this now. Name embedding dem is not defined, which I mean believes I have\\nnot ran this yet. So now we run that, and we should be good. So we look at the model\\nsummary, we can see we have our initial embedding layer, we have our lsdm. And then we have\\nour dense layer at the end. Now notice 64 is the batch size, right? That\'s the initial\\nshape, none is the length of the sequence, which we don\'t know. And then this is going\\nto be just the output dimension, or sorry, this is the amount of\\nvalues in the vector, right, so we\'re gonna start with 256, we\'ll just do 1024 units in\\nthe lsdm. And then 65 stands for the amount of nodes, because that is the length of the\\nvocabulary. Alright, so combined, that\'s how many trainable parameters we get, you can\\nsee each of them for each layer. And now it\'s time to move on to the next section. Okay,\\nso now we\'re moving on to the next step of the tutorial, which is creating a loss function\\nto compile our model with. Now I\'ll talk about why we need to do this in a second. But I\\nfirst want to explore the output shape of our model. So remember, the input to our model\\nis something that is of length 64, because we\'re going to have batches of 64 training\\nexamples, right? So every time we feed our model, we\'re going to give it 64 training\\nexamples. Now, what those training examples are, are sequences of length 100, that\'s what\\nI want you to remember, we\'re passing 64 entries, that are all of length 100, into the model\\nas its training data, right. But sometimes, and when we make predictions with the model,\\nlater on, we\'ll be passing it just one entry that is of some variable length, right. And\\nthat\'s why we\'ve created this build model function. So we can build this model using\\nthe parameters that we\'ve saved later on, once we train the model, and it can expect\\na different input shape, right? Because when we\'re training it, it\'s gonna be given a different\\nshape than we\'re actually testing with it. Know, what I want to do is explore the output\\nof this model, though, at the current point in time. So we\'ve created a model that accepts\\na batch of 64 training examples that are length 100. So let\'s just look at what the output\\nis from the final layer, give this a second to run, we get 64 165. And that represents\\nthe batch size, the sequence length, and the vocabulary size. Now the reason for this is\\nwe have to remember that when we create a dense layer as our last layer that has 65\\nnodes, every prediction is going to contain 65 numbers. And that\'s going to be the probability\\nof every one of those characters occurring, right. That\'s what that does it the last one\\nfor us. So obviously, our last dimension is going to be 65. For the vocabulary size. This\\nis the sequence length, and that\'s a batch, I just want to make sure this is really clear\\nbefore we keep going. Otherwise, this can get very confusing very quickly. So what I\\nwant to do now is actually look at the length of the example batch predictions, and just\\nprint them out and look at what they actually are. So example batch predictions is what\\nhappens when I use my model on some random input example actually pulled the first one\\nfrom my data set with when it\'s not trained. So I can actually use my model before it\'s\\ntrained with random weights and random biases and parameters by simply using model and then\\nI can put little brackets like this and just pass in some example that I want to get a\\nprediction for. So that\'s what I\'m going to do. I\'m going to give it the first batch and\\nit can even it shows me the shape of this batch 64 100. I\'m going to pass that to the\\nmodel. And it\'s going to give us a prediction for that. And in fact, it\'s actually going\\nto give us a prediction For every single element in the batch, right, every single training\\nexample in the batch is going to give us a prediction for. So let\'s look at what those\\npredictions are. So this is what we get, we get a length 64 tensor, right. And then inside\\nof here, we get a list inside of a list or an array inside of an array with all these\\ndifferent predictions. So we\'ll stop there, for this, like explaining this aspect here.\\nBut you can see we\'re getting 64 different predictions, because there\'s 64 elements in\\nthe batch. Now, let\'s look at one prediction. So let\'s look at the very first prediction\\nfor say, the first element in the batch, right. So let\'s do that here. And we see now that\\nwe get a length 100 tensor. And that this is what it looks like, there\'s still another\\nlayer inside. And in fact, we can see that there\'s another nested layer here, right,\\nanother nested array inside of this array. So the reason for this is because at every\\nsingle time step, which means the length of the sequence, right? Because remember, a recurrent\\nneural network is going to feed one at a time, every word in the sequence. In this case,\\nour sequences are length 100, at every time step, we\'re actually saving that output as\\na as a prediction, right, and we\'re passing that back. So we can see that for one batch one training,\\nsorry, not one batch one training example, we get 100 outputs. And these outputs are\\nin some shape, we\'ll talk about what those are in a second. So that\'s something to remember\\nthat for every single training example, we get whatever the length of that training example\\nwas outputs, because that\'s the way that this model works. And then finally, we look at\\nthe prediction at just the very first time step. So this is 100 different time steps.\\nSo let\'s look at the first time step and see what that prediction is. And we can see that\\nnow we get a tensor of length 65. And this is telling us the probability of every single\\ncharacter occurring next at the first time step. So that\'s what I want to walk through,\\nis showing you what\'s actually outputted from the model, the current way that it works.\\nAnd that\'s why we need to actually make our own loss function to be able to determine\\nhow, you know, good our models performing, when it outputs something ridiculous that\\nlooks like this, because there is no just built in loss function in TensorFlow that\\ncan look at a three dimensional nested array of probabilities over, you know, the vocabulary\\nsize, and tell us how different the two things are. So we need to make our own loss function.\\nSo if we want to determine the predicted character, from this array, so what we\'ll go there now,\\nwhat we can do is get the categorical, with this call, we can sample the categorical distribution.\\nAnd that will tell us the predicted character. So what I mean is, let\'s just look at this,\\nand then we\'ll explain this. So since our model works on random weights and biases,\\nright now, we haven\'t trained yet, this is actually all of the predicted characters that\\nit had. So at every time step at the first time step, a predicted age, then it predicted\\nhyphen, then age, then G, then u, and so on so forth, you get the point, right. So what we\'re doing to get this value is we\'re going\\nto sample the prediction. So at this, this is just the first time step, actually, we\'re\\nsample the prediction. Actually, no, sorry, we\'re sampling every time step by bad there.\\nWe\'re gonna say sampled indices equals NP dot reshapes there\'s reshaping this just changing\\nthe shape of it, we\'re gonna say predicted characters equals into two text sampled indices.\\nSo it\'s a really, it\'s hard to explain all this, if you guys don\'t have a statistics\\nkind of background a little bit to talk about why we\'re sampling, and not just taking the\\nargument max value of like this array, because you would think that what we\'ll do is just\\ntake the one that has the highest probability out of here, and that will be the index of\\nthe next predicted character. There\'s some issues with doing that for the loss function,\\njust because if we do that, then what that means is, we\'re going to kind of get stuck\\nin an infinite loop almost where we just keep accepting the biggest character. So what we\'ll\\ndo is pick a character based on this probability distribution. Kind of Yeah, again, it\'s hard,\\nit\'s called sampling the distribution, you can look that up if you don\'t know what that\\nmeans. But sampling is just like trying to pick a character based on a probability distribution,\\nit doesn\'t guarantee that the character with the highest probability is going to be picked,\\nit just uses those probabilities to pick it. I hope that makes sense. I know that was like\\na really rambley definition, but that\'s the best I can do. So here, we reshaped the array\\nand convert all the integers to numbers to see the actual characters. So that\'s what\\nthese two lines are doing here. And then I\'m just showing the predicted characters by showing\\nyou this. And you know, the character here is what was predicted at time step zero to\\nbe the next character, and so on. Okay, so now we can create a loss function that actually\\nhandles this for us. So this is the loss function that we have karass has like a built in one\\nthat we can utilize which is what we\'re doing What this is going to do is take all the labels\\nand all of the probability distributions, which is what this is legit. So I\'m not going\\nto talk about that, really. And we\'ll compute a loss on those. So how different or how similar\\nthose two things are. Remember, the goal of our algorithm and the neural network is to\\nreduce the loss, right? Okay, so next, we\'re going to compile the model, which we\'ll do\\nhere. So we\'re going to compile the model with the atom optimizer and the loss function\\nas loss, which we defined here. And now we\'re going to set up some checkpoints. I\'m not\\ngoing to talk about how these work, you can kind of just read through this if you want.\\nAnd then we\'re going to train the model. Remember to start your GPU hardware accelerator under\\nruntime, change runtime type, GPU, because if you do not, then this is going to be very\\nslow. But once you do that, you can train the model, I\'ve already trained it. But if\\nwe go through this training, we can see it\'s gonna say train for 172 steps, it\'s gonna\\ntake about, you know, 30 seconds per epoch, probably maybe a little bit less than that.\\nAnd the more epochs you run this for, the better it will get, this is a different, we\'re\\nnot likely going to overfit here. So we can run this for like, say, 100 epochs if we wanted\\nto. For our case, let\'s actually start by just training this on, let\'s say two epochs,\\njust to see how it does. And then we\'ll train it on like 1020 4050. And compare the results.\\nBut you\'ll notice the more epochs, the better it\'s going to get. But just like for our case,\\nwe\'ll start with two and then we\'ll work our way up. So while that trains will actually explain the next aspect of this\\nwithout running the code. So essentially, what we need to do, after we\'ve trained the\\nmodel, we\'ve initialized the weights and biases, we need to rebuild it using a new batch size\\nof one. So remember, the initial batch size was 64, which means that we\'d have to pass\\nit 64 inputs or sequences for to work properly. But now what I\'ve done is I\'m going to rebuild\\nthe model and change it to a batch size of one so that we can just pass it some sequence\\nof whatever length we want, and it will work. So if we run this, we\'ve rebuilt the model\\nwith batch size one, that\'s the only thing we\'ve changed. And now what I can do is load\\nthe weights by saying model dot load weights, TF dot train, dot latest checkpoint, checkpoint\\ndirectory, and then build the model. Using the tensor shape one, none. I know sounds\\nstrange. This is how we do this rebuild the model. One nine is just saying expect the\\ninput one and then none means we don\'t know what the next dimension length will be. But\\nhere, checkpoint directory is just we\'ve defined where on our computer, we\'re going to save\\nthese TensorFlow checkpoints. This is just saying this is the was the prefix we\'re going\\nto save the checkpoint with. So we\'re going to do the checkpoint directory. And then checkpoint\\nepoch where epoch will stand for obviously, whatever epoch we\'re on. So we\'ll save checkpoint\\nhere, we\'ll save a checkpoint at epoch one, a checkpoint at epoch two, to get the latest\\ncheckpoint, we do this. And then if we wanted to load any intermediate checkpoint, say,\\nlike checkpoint 10, which is what I\'ve defined here, we can use this block of code down here.\\nAnd I\'ve just hardwired the checkpoint that I\'m loading by saying TF dot train dot load\\ncheckpoint, whereas this one just gets the most recent, so we\'ll get the most recent\\nwhich should be checkpoint two for me. And then what we\'re going to do is generate the\\ntext. So this function, oh, dig into it in a second. But I just want to run and show\\nyou how this works. Because I feel like we\'ve done a lot of work for not very many results\\nright now. And I\'m just gonna type in the string Romeo. And just show you that when\\nI do this, we give it a second. And it will actually generate an output sequence like\\nthis. So we have Romeo loose give this is the beginning of our sequence that says Lady\\nCapulet, food martone. Father gnomes come to those shell, right? So it\'s like pseudo\\nEnglish. Most of it are like kind of proper words. But again, this is because we train\\nit on just two epochs. So I\'ll talk about how we build this in a second. But if you\\nwanted a better output for this part, then you would train this on more epochs. So now\\nlet\'s talk about how I actually generated that output. So we rebuilt the model to accept\\na batch size of one, which means that I can pass it a sequence of any length. And in fact,\\nwhat I start by doing is passing the sequence that I\'ve typed in here, which was Romeo,\\nthen what that does, is we run this function generate text, I just stole this from TensorFlow\\nas website like I\'m stealing almost all of this code. And then we say the number of characters\\nto generate is 800. The input evaluation which is now what we need to pre process this text\\nagain, so that this works properly, we could use my little function, or we can just write\\nthis line of code here, which does what the function that I wrote does for us, so char\\nto ID x s for S and start string start string is what we typed in that case Romeo, then\\nwhat we\'re going to do is expand the dimensions. So essentially turn just a list like this that has all these numbers\\n987 into a double list. So just a nested list because that\'s what it\'s expecting as the\\ninput one batch one entry, then what we do is we\'re going to say the string that we want\\nto store because we want to print this out at the end, right? We\'ll put in this text\\ngenerated list, temperature equals 1.0. What this will allow us to do is if we change this\\nvalue to be higher, well, I mean, you can read the comment here, right, low temperature\\nresults in more predictable text, higher temperature results in more surprising text. So this is\\njust a parameter to mess with, if you want, you don\'t necessarily need it. And I would\\nlike I\'ve just left mine at one for now, we\'re gonna start by resetting the status of the\\nmodel. This is because when we rebuild the model, it\'s gonna have stored the last state\\nthat it remembered when it was training. So we need to clear that before we pass new input\\ntext to it. And we say for i in range num generate, which means how many characters\\nwe want to generate, which is 800. Here, what we\'re going to do is, say predictions equals\\nmodel, input a Val, that\'s going to start as the start string that\'s encoded, right.\\nAnd then what we\'re going to do is say predictions equals TF dot squeeze, prediction zero, what\\nthis does is take our predictions, which is going to be in a nested list, and just removes\\nthat exterior dimension. So we just have the predictions that we want, we don\'t have that\\nextra dimension that we need to index again. And then we\'re gonna say using a categorical\\ndistribution to predict the character returned by the model. That\'s what he writes here.\\nWe\'ll divide by the temperature, if it\'s one, that\'s not going to do anything. And we\'ll\\nsay predicted ID equals we\'ll sample whatever the output was from the model, which is what\\nthis is doing. And then we\'re going to take that output, so the predicted ID, and we\'re\\ngoing to add that to the input evaluation. And then what we\'re going to say is text generate\\ndot append, and we\'re going to convert the text that are integers now, back into a string, and return all of this. Now, I know this seems\\nlike a lot, again, this is just given to us, by TensorFlow to, you know, create this aspect,\\nyou can read through the comments yourself, if you want to understand it more, but I think\\nthat was a decent, decent explanation of what this is doing. So yeah, that is how we can\\ngenerate, you know, sequences using a recurrent neural network. Now, what I\'m going to do\\nis go to my other window here, where I\'ve actually typed all the code just in full and\\ndo a quick summary of everything that we\'ve done, just because there was a lot that went\\non. And then from there, I\'m actually going to train this on a B movie script and show\\nyou kind of how that works in comparison to the Romeo and Juliet. Okay, so what I\'m in\\nnow is just the exact same notebook we had before, but I\'ve just pretty much copied all\\nthe text in here. Or it\'s the exact same code we had before. So we just don\'t have all that\\nother text in between. So I can kind of do a short summary of what we did, as well as\\nshow you how this worked when I trained it on the B movie script. So I did mention that\\nI was going to show you that I\'m not lying, I will show you can see I\'ve got B movie dot\\ntxt loaded in here. And in fact, actually, I\'m gonna just show you the script first,\\nto show you what it looks like. So this is what the B movie script looks like. You can\\nsee it just like a long, you know, script of text, I just download this for free off\\nthe internet. And it\'s actually not as long as the Romeo and Juliet play. So we\'re not\\ngoing to get as good of results from our model. But it should hopefully be okay. So we just\\nstart and I\'m just gonna do a brief summary. And then I\'ll show you the results from the\\nB movie script, just so that people that are confused, maybe have something that wraps\\nit up here, we\'re doing our imports, I don\'t think I need to explain that this part up\\nhere is just loading in your file, again, I don\'t think I need to explain that, then\\nwe\'re actually going to read the file. So open it from our directory, decode it into\\nUTF, eight, we\'re going to create a vocabulary and encode all of the text that\'s inside of\\nthis file, then what we\'re going to do is turn all of that text into, you know, the\\nencoded version, we\'re writing a function here that goes the other way around. So from\\nint to tax, not from text to int, we\'re going to define the sequence length that we want\\nto train with, which will be sequence length of 100, you can decrease this value, if you\\nwant you go 50 go 20, it doesn\'t really matter, it\'s up to you, it just that\'s going to determine\\nhow many training examples you\'re going to have right as the sequence length. Next, what\\nwe\'re going to do is create a character data set from a tensor slices from text as int,\\nwell, this is going to do is just convert our entire text that\'s now an integer array\\ninto a bunch of slices of characters. Um, so that\'s what this is doing here. So are\\nnot slices, what am I saying? You\'re just going to convert, like, split that entire\\narray into just characters. Like that\'s pretty much what it\'s doing. And then we\'re gonna\\nsay sequences equals chart data set dot batch, which now is going to take all those characters\\nand batch them in length of 101. We\'re going to do then is split all of that into the training\\nexamples. So like this, right atll and then ELO. We\'re going to map this function to sequences,\\nwhich means we\'re going to apply this to every single sequence and store that in data set.\\nThen, we\'re going to find the parameters for our initial network. We\'re going to shuffle\\nthe data set and batch that into now 64 training examples. And then we\'re going to make the\\nfunction that builds the model which already discussed, we\'re going to actually build the\\nmodel starting with the batch size of 64. We\'re going to create our loss function, compile\\nthe model, set our checkpoints for saving, and then train the model and make sure that\\nwe say checkpoint callback, as the checkpoint callback for the model, which means it\'s going\\nto save every epoch, the weights of the model had computed at that epoch. So after we do\\nthat, then our models trained. So we\'ve trained the model, you can see I trained this on 50\\nepochs for the B movie script, and then we\'re gonna do is build the model now with a batch\\nsize of one. So we can pass with one example tune and get a prediction, we\'re going to\\nload the most recent weights into our model from the checkpoint directory that we defined\\nabove. And then what we\'re going to do is build the model and tell it to expect the\\nshape one, none as its initial input. Now, none just means we don\'t know what that value\\nis going to be. But we know we\'re gonna have one entry. Alright, so now we have this generate\\ntext method, or function here, which I\'ve already kind of went through how that works.\\nAnd then we can see that if I type in input string, so we type, you know, input string,\\nlet\'s say, Hello, and hit enter, we\'ll watch and we can see that the B movie, you know,\\ntrained model comes up with its output here. Now unfortunately, the B movie script does\\nnot work as well as Romeo and Juliet. That\'s just because Romeo and Juliet is a much longer\\npiece of text. It\'s much better only it\'s formatted a lot nicer and a lot more predictable.\\nBut yeah, you kind of get the idea here. And it\'s kind of cool to see how this performs\\non different data. So I would highly recommend that you guys find some training data that\\nyou could give this other than just the Romeo and Juliet or maybe even try another play\\nor something and see what you can get out of it. Also, quick side note to make your\\nmodel better increase the amount of epochs here, ideally, you want this loss to be as\\nlow as possible, you can see mine was still actually moving down at epoch 50, you will\\nreach a point where the amount of epochs won\'t make a difference. Although, with models like\\nthis, the more epochs typically the better because it\'s difficult for it to kind of overfit.\\nBecause all you want it to do really is just kind of learn how the language works, and\\nthen be able to replicate that to you almost right. So that\'s kind of the idea here. And\\nwith that being said, I\'m going to say that this section is probably done. Now, I know\\nthis was a long, probably confusing section for a lot of you. But this is you know what\\nhappens when you start getting into some more complex things in machine learning, it\'s very\\ndifficult to kind of grasp and understand all these concepts in an hour of me just explaining\\nthem. What I try to do in these videos is introduce you to the syntax show you how to\\nget a working, you know, kind of prototype and hopefully give you enough knowledge to\\nthe fact where if you\'re confused by something that I said, you can go, and you can look\\nthat up. And you can figure out kind of the more important details for yourself, because\\nI really just I can\'t go into all you know, the extremes in these videos. So anyways,\\nthat has been this section. I hope you guys enjoyed doing this, I thought this was pretty\\ncool. And in the next section, we\'re gonna be talking about reinforcement learning. Hello,\\neveryone, and welcome to the next module in this course on reinforcement learning. So\\nwhat we\'re gonna be doing in this module is talking about another technique in machine\\nlearning called reinforcement learning. Now, if you remember, at the very beginning of\\nthis course, which I know for you guys is probably at like six hours ago, at this point,\\nwe did briefly discuss what reinforcement learning was now go through a recap here just\\nto make sure everyone\'s clear on it. But essentially, reinforcement learning is kind of the strategy\\nin machine learning where rather than feeding a ton of data and a ton of examples to our\\nmodel, we let the model or in this case, we\'re going to call it agent actually come up with\\nthese examples itself. And we do this by letting an agent explore an environment. Now essentially,\\nthe concept here is just like humans, the way that we learn to do something, say like\\nplay a game is by actually doing it, we get put in the environment, we try to do it. And\\nthen you know, we\'ll make mistakes, we\'ll encounter different things, we\'ll see what\\ngoes correctly. And based on those experiences we learned and we figure out the correct things\\nto do. A very basic example is, you know, say we play a game. And when we go left, we\\nfell off a cliff or something right. Next time we play that game. And we get to that\\npoint, we\'re probably not going to go left, because we\'re going to remember the fact that\\nthat was bad, and hence learned from our mistakes. So that\'s kind of the idea here with reinforcement\\nlearning. I\'m gonna go through exactly how this works and give some better examples and\\nsome math behind one of the implementations we\'re going to use. But I just want to make\\nthis clear that there\'s a lot of different types of reinforcement learning. In this example,\\nwe\'re just going to be talking about something called q learning and I\'m going to keep this\\nmodule shorter compared to the other ones, because this field of AI and machine learning\\nis pretty complex and can get pretty difficult pretty quickly. So it\'s something that\'s maybe\\na more advanced topic for some of you guys. Alright, so anyways, now we need to define\\nsome terminology before I can even start really explaining the technique we\'re going to use\\nand how this works. So we have something called an environment agent, state, action and reward.\\nNow I\'m hoping that some of you guys will remember this from the very beginning but\\nenvironment is essentially what we\'re trying to solve or what we\'re trying to do. So in reinforcement learning, we have\\nthis notion of an agent. And the agent is what\'s going to explore the environment. So\\nif we\'re thinking about reinforcement learning when it comes to say, training an AI to play\\na game, well, in that instance, so we\'re talking about Mario, the agent would be Mario is that\\nis the thing that\'s moving around and exploring our environment. And the environment would\\nbe the level in which we\'re playing in. So you know, in another example, maybe an example\\nwe\'re going to use below, we\'re actually going to be kind of in almost a maze. So the environment\\nis going to be the maze, and the agent is going to be the character or the entity or\\nwhatever you want to call it that\'s exploring that maze. So it\'s pretty, it\'s usually pretty\\nintuitive to come up with what the environment and the agent are. Although in some more complex\\nexamples, it might not always be clear. But just understand that reinforcement learning\\ndeals with an agent, something exploring an environment, and a very common application\\nof reinforcement learning is in training AI\'s on how to play games. And it\'s actually very\\ninteresting what they\'ve been able to do in that field recently. Okay, so we have environments\\nan agent, hopefully, that makes sense, the next thing to talk about is state. So essentially,\\nthe state is where you are in the environment. So obviously, inside of the environment, we\\ncan have many different states. And a state could also be associated with the, you know,\\nAgent itself. So we\'re gonna say the agent is in a specific state, whenever it is in\\nsome part of the environment. Now, in the case of our game, the state that an agent\\nwould be in would be their position in the level, say, if they\'re at, you know, X, Y\\ncoordinates, like 1020, they would be at state or in state 1020. That\'s kind of how we think\\nabout states. Now, obviously, state can be applied in some different instance, as well,\\nwe\'re playing say, maybe a turn based game, you know, she that\'s not really a great example,\\nI\'m trying to think of something where the state wouldn\'t necessarily be a position,\\nmaybe if you\'re playing a game where you have like health or something like that. And part\\nof the states might be the health of the character, this can get complicated depending on what\\nyou\'re trying to do. But just understand the notion that for most of our examples, state\\nis simply going to be location, although it really is just kind of telling us information\\nabout where the agent is, and its status in the environment. So next, we have this notion\\nof an action. So in reinforcement learning, our agent is exploring the environment, it\'s\\ntrying to figure out the best way or how to accomplish some kind of goal in the environment.\\nAnd the way that it interacts with the environment is with something called actions. Now, actions\\ncould be say, moving the left arrow key, right, moving to the left, and the environment moving\\nto the right, it could be something like jumping in an action can actually be not doing something\\nat all. So when we say, you know, Agent performed action, that could really mean that the action\\nin that maybe time step was that they didn\'t do something right that they didn\'t do anything\\nthat was their action. So it\'s kind of the idea of action. In the example of our Mario\\none, which I keep going back to in action would be something like jumping, and typically\\nactions will change the state of our entity or agent. Although they might not necessarily\\ndo that. In fact, we will observe with a lot of the different actions that we could actually\\nbe in the same state after performing that action. Alright, so now we\'re on to the last\\npart, which is actually the most important to understand. And this is reward. So reward\\nis actually what our agent is trying to maximize. Well, it is in the environment. So the goal\\nof reinforcement learning is to have this agent navigate this environment, go through\\na bunch of the different states of it, and determine which actions maximize the reward\\nat every given state. So essentially, the goal of our agent is to maximize a reward.\\nBut what is a reward? Well, after every action that\'s taken, the agent will receive a reward.\\nNow, this reward is something that us as the programmer need to come up with. The reason\\nwe need to do this is because we need to tell the agent when it\'s performing well, and when\\nit\'s performing poorly. And just like we had like a loss function in neural networks, when\\nwe were using those before, this is almost like our loss function, you know, the higher\\nthis number is, the more reward the agent gets, the better, the lower the reward, you\\nknow, it\'s not as good as not doing as well. So that\'s how we kind of monitor and assess\\nperformance where agents is by determining the almost average amount of reward that they\'re\\nable to achieve. And their goal is really to you know, it\'s almost an optimization problem\\nwhere they\'re trying to maximize this reward. So what we\'re going to do in reinforcement\\nlearning is have this agent exploring the environment, going through these different\\nstates and performing these different actions trying to maximize its reward. And obviously,\\nif we\'re trying to get the agent to say finish a level or you know, complete the game, then\\nthe maximum maximum reward will be achieved once it\'s completed the level of completed\\nthe game. And if it does, things that we don\'t like say like dying or like jumping in the\\nwrong spot, we could give it a negative reward to try to influence it to not do that. And\\nour goal, you know when we train these agents is for them to get the most reward. And we\\nhope that they\'re going to learn the optimal route through a level or through some environment\\nthat will maximize that reward for them. Okay, so now I\'m going to talk about a technique\\ncalled cue learning, which is actually just an algorithm that we\'re going to use to implement\\nthis idea of reinforcement learning, we\'re not going to get into anything too crazy in\\nthis last module, because this is meant to be more of an introduction into the kind of\\nfield of reinforcement learning than anything else. But q learning is the most basic way\\nto implement reinforcement learning, at least that I have discovered. And essentially what\\nq learning is, and I don\'t actually really know why they call it Q, although I should\\nprobably know that is creating some kind of table or matrix likes data structure, that\'s\\ngoing to contain as the What is it, I guess, the rows every single state, and as the columns\\nevery single action that could be taken in all of those different states. So for an example\\nhere, and we\'ll do one on kind of the whiteboard later on, if we can get there. But here, we\\ncan see that this is kind of my cue table. And what I\'m saying is that we have a one,\\na two, a three a four as all the possible actions that can be performed in any given\\nstate. And we have three states denoted by the fact that we have three rows, and the\\nnumbers in this, this table with this Q, what are they called Q matrix Q table, whatever\\nyou want to call it, the numbers that are present here represent what the predicted\\nreward will be, given that we take an action, whatever this action is, in this state. So\\nI\'m not sure if this is making sense to you guys. But essentially, if we\'re saying that\\nrow zero is state zero, action to a two, this value tells us what reward we should expect\\nto get, if we take this action while we\'re in this state. That\'s what that is trying\\nto tell us. That\'s what that means. Same thing here in, you know, state two, we can see that\\nthe optimal action to take would be action two, because that has the highest reward for\\nthis state. And that\'s what this table is that we\'re going to try to generate with this\\ntechnique called q learning. A table that can tell us given any state with the predicted\\nreward will be for any action that we take. And we\'re going to generate this table by exploring the environment many\\ndifferent times, and updating these values according to what we kind of see or what the\\nagencies in the environment and the rewards that receives for any given action in any\\ngiven state. And we\'ll talk about how we\'re going to update that later. But this is the\\nbasic premise. So that is kind of cue learning. We\'re gonna hop on the whiteboard now. And\\nwe\'ll do a more in depth example. But then we\'re going to talk about how we actually\\nlearned this cue table that I just discussed. Okay, so I\'ve drawn a pretty basic example\\nright now that I\'m going to try to use to illustrate the idea of Q learning and talk\\nabout some problems with it, and how we can kind of combat those as we learn more about\\nhow q learning works. But the idea here is that we currently have three states and why\\nwhat is happening, why was that happening up at the top, I don\'t know. Anyways, the\\nidea is, we have three states s one, s two and s three. And at each state, we have two\\npossible actions that can be taken, we can either stay in this state or we can move.\\nNow what I\'ve done is kind of just written some integers here that represent the reward\\nthat we\'re going to get or that the agent is going to get such that it takes that action\\nin a given state. So if we take the action, here, in s one, right of moving, then we will\\nreceive a reward of one because that\'s what we\'ve written here is the reward that we get\\nfrom moving. Whereas if we stay, we\'ll get a reward of three, you know, same concept\\nhere, if we stay, we get to if we move, we get one, and I think you understand the point.\\nSo the goal of our agent to remember is to maximize its reward in the environment. And\\nwhat we\'re going to call the environment is this right here, the environment is essentially\\ndefines the number of states the number of actions and you know, the way that the agent\\ncan interact with these states and these actions. So in this case, the agent can interact with\\nthe states by taking actions that change its state, right. So that\'s what we\'re getting\\nat with this. Now, what I want to do is show you how we use this cue table, or learn this\\ncue table to come up with kind of the almost, you know the model like the machine learning\\nmodel that we\'re going to use. So essentially, what we would want to have here is we want\\nto have a kind of pattern in this table that allows our agent to receive the maximum reward.\\nSo in this case, we\'re going to say that our agent will start at state s one. And obviously,\\nwhenever we\'re doing this reinforcement learning, we need to have some kind of start state that\\nthe agent will start in this could be a random state, it could change, but it doesn\'t start\\nin some state. So in this case, we\'re going to say it starts at s one. Now when we\'re\\nin s one, the agent has two things that it can do. It can stay in the current state and\\nreceive a reward of three or it can move and receive a reward of one, right if we get to\\ns two in this state. What can we do? We can Stay, which means we receive a reward of two,\\nor we can move, which means we get a reward of one. And same thing for s3, we can stay,\\nwe get a reward of four, and we can move, we get a reward of one. Now, right now, if\\nwe had just ran this one time and have the agent stay in each state, like start in each\\nunique state, this is what the cue table we would get would look like. Because after looking\\nat this just one time starting in each state, with the agent would be able to or I guess\\ntwo times because it would have to try each action. Let\'s say we had the agent starting\\neach state twice. So it started as one twice, it started as two twice, and it started in\\ns3 twice. And every time it started there, it tried one of the different actions. So\\nwhen it started as one it tried moving once and then it tried staying once, we would have\\na cue table that looks like this, because what would happen is we would update\\nvalues in our cue table to represent the reward we received when we took that action from\\nthat state. So we can see here, the one we were in state s one, and we decided to stay\\nwhat we did is we wrote a three inside of the state column, because that is how much\\nreward we received when we moved, right? Same thing for state two, when we moved for state\\ntwo or I guess sorry, state when we stayed in state two, we received a reward of two,\\nsame thing for four. Now, this is okay, right? This tells us kind of, you know, the optimal\\nmove to make in any state to receive the maximum reward. But what if we introduce the idea\\nthat you know, our agent, we want it to receive the maximum total reward possible, right.\\nSo if it\'s in state one, Ideally, we\'d like it to move to state two, and then move to\\nstates three, and then just stay in state three, because it will receive the most amount\\nof reward? Well, with the current table that we\'ve developed, if we just follow this, and\\nwe look at the table, we say, Okay, if we want to use this cue learning table now to\\nyou know, move an agent around our level, what we\'ll do is we\'ll say, Okay, what state\\nis it in, if it\'s in state two, we\'ll do stay, because that\'s the highest reward that we\\nhave in this table. If that\'s the approach we use, then we can see that if our, you know,\\nAgent start in state one or state two, it would stay in what we call a local minima,\\nbecause it\'s not able to kind of realize from this state, that it can move any further and\\nreceive a much greater reward. Right. And that\'s kind of the concept we\'re going to\\ntalk about as we implement and, you know, discuss further how q learning works. But\\nhopefully, it gives you a little bit of insight into what we do with this table, essentially,\\nwhen we\'re updating these table values is when we\'re exploring this environments, when\\nwe explore this environment, and we start in a state, when we take an action to another\\nstate, we observe the reward that we got from going there, and we observe the state that\\nwe change to right, so we observe the fact that in state one, when we go to state two,\\nwe receive the reward of one. And what we do is we take that observation, and we use\\nit to update this cue table. And the goal is at the end of all of these observations,\\nand it could be millions of them, that we have a cue table that tells us the optimal\\naction to take in any single state. So we\'re actually hard coding, this kind of mapping,\\nthat essentially just tells us given any state, all you have to do is look up in this table,\\nlook at all of the actions that could be taken, and just take the maximum action or the reward\\nthat\'s supposed to give, I guess, the action that\'s supposed to give the maximum reward.\\nAnd if we were to follow that on this, we can see we get stuck in the local minima,\\nwhich is why we\'re going to introduce a lot of other concepts. So our reinforcement learning\\nmodel and Q learning, we have to implement the concept of being able to explore the environment,\\nnot based on previous experiences, right, because if we just tell our model, okay, what\\nwe\'re going to do is we\'re going to start in all these different states, we\'re going\\nto start in the start state and just start navigating around. If we update our model\\nimmediately, or update our cue table immediately and put this three here for state, we can\\nalmost guarantee that since this three is here, when our model is training, right, if\\nit\'s using this cue table to determine what state to move to next, when it\'s training\\nand determining what to do, it\'s just always gonna stay, which means we\'ll never get a\\nchance to even see what we could have gotten to at s3. So we need to kind of introduce\\nsome concept of taking random actions, and being able to explore the environment more\\nfreely, before starting to look at these q values, and use that for the training. So\\nI\'m actually going to go back to my slides now to make sure I don\'t get lost, because\\nI think I was starting to ramble a little bit there. So we\'re gonna now talk about learning\\nthe cue table. So essentially, I showed you how we use that cue table, which is given\\nsome state we just look that state up in the cue table, and then determine what the maximum\\nreward we could get by taking you know, some actions and then take that action. And that\'s\\nhow we would use the cue table later on when we\'re actually using the model. But when we\'re\\nlearning the cue table, that\'s not necessarily what we want to do. We don\'t want to explore\\nthe environment by just taking the maximum reward. We\'ve seen so far and just always\\ngoing that direction, we need to make sure that we\'re exploring in a different way and\\nlearning the correct values for the cue table. So essentially, our agent learns by exploring\\nthe environment and observing the outcome slash reward from each action it takes in\\na given state, which we\'ve already set. But how does it know what action to take in each\\nstate? When it\'s learning? That\'s the question I need to answer for you now, well, there\'s\\ntwo ways of doing this, our agent can essentially, you know, use the current cue table to find the best action, which is kind of\\nwhat I just discussed. So taking, looking at the cue table, looking at the state and\\njust taking the highest reward, or it can randomly pick a valid action. And our goal\\nis going to be when we create this Q learning algorithm to have a really great balance of\\nthese two, where sometimes we use the Q table to find the best action, and sometimes we\\ntake a random action. So that is one thing. But now I\'m just going to talk about this\\nformula for how we actually update q values. So obviously, what\'s gonna end up happening\\nin our Q learning is, we\'re gonna have an agent, that\'s going to be in the learning\\nstage, exploring the environment, and having all these actions and all these rewards and\\nall these observations happening. And it\'s going to be moving around the environment\\nby following one of these two kind of principles, randomly picking a ballot action or using\\nthe current cue table to find the best action. And when it gets into a new state, and it\\nyou know, moves from state to state, it\'s going to keep updating this cue table telling\\nit, you know, this is what I\'ve learned about the environment, I think this is a better\\nmove, we\'re going to update this value. But how does it do that in a way, that\'s going\\nto make sense because we can\'t just put, you know, the maximum value we got from moving\\notherwise, we\'re going to run into that issue, which I just talked about, where we get stuck\\nin that local maxima, right? I\'m not sure if I called it minimum before. But anyways,\\nit\'s local maxima, where we see this high reward. But that\'s preventing us if we keep\\ntaking that action from reaching a potentially high reward in a different state. So the formula\\nthat we actually use to update the cue table is this. So cue state action equals q state\\naction, and a state action is just referencing first the rows for the state and then the\\naction as the column plus alpha times. And then this is all in brackets, right? reward,\\nplus, I believe this is gamma times max Q of new states minus q state action. So what\\nthe heck does this mean? What are these constants? What is all this? We\'re going to talk about\\nthe constants in a minute, but I want to Yeah, I want to explain this formula, actually.\\nSo let\'s Okay, well, I guess we\'ll go through the constants, it\'s hard to go through a complicated\\nmath formula. So A stands for the learning rate, and gamma stands for the discount factor.\\nSo alpha learning rate, gamma discount factor. Now, what is the learning rate? Well, this\\nis a little blurb on what this is. But essentially, the learning rate ensures that we don\'t update\\nour cue table too much on every observation, so before, right when I was showing you like\\nthis, if we can go back to my Windows Ink, was it\'s not working. I guess I\'m just not\\npatient enough. before when I was showing you, all I did when I took an action was I\\nlooked at the reward that I got from taking that action. And I just put that in my cue\\ntable right? Now, obviously, that is not an optimal approach to do this, because that\\nmeans that in the instance, where we hit state one, well, I\'m not going to be able to get\\nto this reward of four, because I\'m going to throw that you know, three in here, and\\nI\'m just going to keep taking that action. We need to, you know, hopefully make this\\nmove action actually have a higher value than stay. So that next time we\'re in state one,\\nwe consider the fact that we can move to state two, and then move to state three to optimize\\na reward. So how do we do that? Well, the learning rate is one thing that helps us kind\\nof accomplish this behavior. Essentially, what it is telling us and this is usually\\na decimal value, right is how much we\'re allowed to update every single cue value by on every\\nsingle action or every single observation. So if we just use the approach before, then\\nwe\'re only going to need to observe given the amount of states and the amount of actions\\nand we\'ll be able to completely fill in the cue table. So in our case, if we had like\\nthree states and three actions, we could, you know, nine iterations, we\'d be able to\\nfill the entire cue table, the learning rate means that it\'s going to just update a little\\nbit slower, and essentially, change the value in the cue table very slightly. So you can\\nsee that what we\'re doing is taking the current value of the cue table, so whatever is already\\nthere, and then what we\'re going to do is add some value here. And this value that we\\nadd is either going to be positive or negative, essentially telling us you know, whether we\\nshould take this new action or whether we shouldn\'t take this new action. Now, the way\\nthat this kind of value is calculated, right, is obviously our alpha is multiply this by\\nthis, but we have the reward, plus, in this case, gamma, which is just going to actually\\nbe the discount factor. And I\'ll talk about how that works in a second of the maximum\\nof the new state we moved into. Now what this means is find the maximum reward that we could\\nreceive in the new state by taking any action and multiply that by what we call The discount\\nfactor, what this part of the formula is trying to do is exactly what I\'ve kind of been talking\\nabout, try to look forward and say, okay, so I know\\nif I take this action in this state, I receive this amount of reward. But I need to factor\\nin the reward I could receive in the next state, so that I can determine the best place\\nto move to. That\'s kind of what this Max and this gamma are trying to do for us. So this\\ndiscount factor, whatever you want to call it, it\'s trying to factor in a little bit\\nabout what we could get from the next state into this equation. So that hopefully, our\\nkind of agent can learn a little bit more about the transition states. So states that\\nmaybe are actions that maybe don\'t give us an immediate reward, but lead to a larger\\nreward in the future. That\'s what this wine max are trying to do. Then what we do is we\\nsubtract from this the state and action, this is just to make sure that we\'re adding what\\nthe difference was, in, you know, what we get from this versus what the current value\\nis, and not like multiplying these values, crazily. I mean, you can look into more of\\nthe math here and plug in like some values later. And you\'ll see how this kind of works.\\nBut this is the basic format. I feel like I explained that in depth enough. Okay. So\\nnow that we\'ve done that, and we\'ve updated this, we\'ve learned kind of how we update\\nthe cells and how this works. I could go back to the whiteboard and draw it out. But I feel\\nlike that makes enough sense, we\'re going to look at what the next state is, we\'re going\\nto factor that into our calculation, we have this learning rate, which tells us essentially\\nhow much we can update each cell value by and we have this, what do you call it here\\ndiscount factor, which essentially tries to kind of define the balance between finding\\nreally good rewards in our current state, and finding the rewards in the future state.\\nSo the higher this value is, the more we\'re going to look towards the future, the lower\\nit is, the more we\'re going to focus completely on our current reward, right. And obviously,\\nthat makes sense, because we\'re going to add the maximum value. And if we\'re multiplying\\nthat by a lower number, that means we\'re going to consider that less than if that was greater.\\nAwesome. Okay. So now that we kind of understand that, I want to move on to a Q learning example.\\nAnd what we\'re going to do for this example, is actually use something called the open\\nAI gym, I just need to throw my drawing tablet away right there so that we can get started.\\nBut open AI gym is actually really interesting kind of module, I don\'t even actually I don\'t\\neven really know the way to describe it almost tool that was actually developed by open AI,\\num, you know, coincidentally by the name, which is founded by Elan Musk, and someone\\nelse. So he\'s actually, you know, made this kind of, I don\'t really don\'t know the word\\nto describe it, I almost want to say tool that allows programmers to work with these\\nreally cool gym environments, and train reinforcement learning models. So you\'ll see how this works\\nin a second. But essentially, there\'s a ton of graphical environments that have very easy\\ninterfaces to use. So like moving characters around them, that you\'re allowed to experiment\\nwith completely for free as a programmer to try to, you know, make some cool reinforcement\\nlearning models. That\'s what opening a gym is. And you can look at it, I mean, we\'ll\\nclick on it here, actually, to see what it is. You can see, Jim, there\'s all these different\\nAtari environments, and it\'s just a way to kind of train reinforcement learning models.\\nAlright, so now we\'re gonna start by just importing Jim, if you\'re in Collaboratory,\\nthere\'s nothing you need to do here. If you\'re in your own thing, you\'re going to have to\\npip install Jim. And then what we\'re going to do is make this frozen lake v zero, Jim.\\nSo essentially, what this does is just set up the environment that we\'re going to use.\\nNow I\'ll talk more about what this environment is later. But I want to talk about how Jim\\nworks, because we are going to be using this throughout the thing. So the open AI gym is\\nmeant for reinforcement learning. And essentially what it has is an observation space and an\\naction space for every environment. Now, the observation space is what we call our environment,\\nright. And that will tell us the amount of states that exist in this environment. Now\\nin our case, we\'re going to be using kind of like a maze like thing, which I\'ll show\\nyou in a second, so you understand why we get the values we do. Action space tells us\\nhow many actions we can take when we do the dot n at any given state. So if we print this\\nout, we get 16 and four, representing the observation space. In other words, the number\\nof states is 16. And the amount of actions we can take in every single state is four.\\nNow in this case, these actions can be left down, up and right. But yes, now Nv dot reset.\\nSo essentially, we have some commands that allow us to move around the environment, which are actually down here. If we want to\\nreset the environment in start back in the beginning state, then we do MV dot reset,\\nyou can see this actually returns to us the starting state, which obviously is going to\\nbe zero. Now, we also have the ability to take a random action, or select a random action\\nfrom the action space. So what this line does right here, say of the action space, so all\\nthe commands that are there are all the actions we could take, pick a random one and return\\nthat. So if you do that, actually, let\'s just print action and see what this As you\'ll see,\\nwe get zero to write, it just gives us a random action that is valid from the action space.\\nAlright, next, what we have is this NB dot step in action. Now what this does is take\\nwhatever action we have, which in this case is three, and perform that in the environment.\\nSo tell our agent to take this action in the environment and return to us a bunch of information.\\nSo the first thing is the observation, which essentially means what state do we move into\\nnext. So I could call this new underserve state. reward is what reward that we receive\\nby taking that action. So there\'ll be some value right? In our in this case, the reward\\nis either one or zero. But that\'s not that important to understand. And then we have\\na bool of done, which tells us did we lose the game? Or did we win the game, yes or no,\\nso true. So if this is true, what this means is we need to reset the environment because\\nour agent either lost or won, and is no longer in a valid state in the environment. info\\ngives you us a little bit of information. It\'s not showing me anything here. We\'re not\\ngoing to use info throughout this, but figured I\'d let you know that now. Nv dot render,\\nI\'ll actually render this for you and show you renders a graphical user interface that\\nshows you the environment. Now, if you use this while you\'re training, so you actually\\nwatch the agent do the training, which is what you can do with this, it slows it down\\ndrastically, like probably by you know, 10 or 20 times because it actually needs to draw\\nthe stuff on the screen. But you know, you can use it if you want. So this is what our\\nfrozen lake example looks like. You can see that the highlighted square is where our agent\\nis. And in this case, we have four different blocks. We have s, f, h, and G. So S stands\\nfor start, F stands for a frozen, is this a frozen lake. And the goal is to\\nnavigate to the goal without falling in one of the holes, which is represented by H. And\\nthis here tells us the action that we just took now I guess the starting action is up\\nbecause that\'s zero, I believe. But yes, so if we run this a bunch of times, we\'ll see\\nthis updating. Unfortunately, this doesn\'t work very well in Google Collaboratory, the\\ngooeys. But if you did this in your own command line, and you\'d like did some different steps\\nand rounding it all out, you would see this working properly. Okay, so now we\'re on to\\ntalking about the frozen lake environment, which is kind of what I just did. So now we\'re\\njust going to move to the example where we actually implement cue learning to essentially\\nsolve the problem, how can we train an AI to navigate this environment and get to the\\nstart to the goal? How can we do that? Well, we\'re gonna use q learning. So let\'s start.\\nSo the first thing we need to do is import Jim, import NumPy and then create some constants\\nhere. So we\'ll do that we\'re gonna say the amount of states is equal to the line I showed\\nyou before. So Nv dot observation space dot n actions is equal to n v dot action space\\nn. And then we\'re going to say Q is equal to NP dot zeroes, states and actions. So something\\nI guess I forgot to mention is when we initialize the Q table, we just initialize all blank\\nvalues or zero values, because obviously, at the beginning of our learning, our model,\\nor our agent doesn\'t know anything about the environment yet, so we just leave those all\\nblank, which means we\'re going to more likely be taking random actions at the beginning\\nof our training, trying to explore the environment space more. And then as we get further on\\nand learn more about the environment, those actions will likely be more calculated based\\non the cue table values. So we print this out, we can see this is the array that we\\nget, we\'ve had to beat, build a 16 by four, I guess not array, well, I guess this technically\\nis an array, and we\'ll call it matrix 16 by four, so every single row represents a state,\\nand every single column represents an action that could be taken in that state. Alright,\\nso we\'re going to find some constants here, which we talked about before. So we have the\\ngamma, the learning rate, the maximum of steps and the number of episodes. So the number\\nof episodes is actually how many episodes you want to train your agent on. So how many\\ntimes do you want it to run around and explore the environment? That\'s what episode stands\\nfor? Max steps essentially says, okay, so if we\'re in the environment, and we\'re kind\\nof navigating and moving around, we haven\'t died yet. How many steps are we going to let\\nthe agent take before we cut it off, because what could happen is we could just bounce\\nin between two different states indefinitely. So we need to make sure we have a max steps\\nso that at some point, if the agent is just doing the same thing, we can, you know, and\\nthat or if it\'s like going in circles, we can end that and start again, with different\\nyou know, q values. Alright, so episode Yeah, we already talked about that learning rate,\\nwe know what that is gamma, we know what that is, mess with these values as we go through.\\nAnd you\'ll see the difference that makes in our training, actually include a graph down\\nbelow. So we\'ll talk about that to kind of show us the outcome of our training but learning\\nrate, the higher This is, the faster I believe that it learns, yes. So a high learning\\nrate means that each update will introduce larger change to the current state. So yeah,\\nso that makes sense based on the equation as well. Just want to make sure that I wasn\'t\\ngoing crazy there. So let\'s run this constant block to make sure. And now we\'re going to\\ntalk about picking an action. So remember how I said and I actually wrote them down\\nhere, there\'s essentially two things we can Do at every, what do we call it? Step right?\\nWe can randomly pick valid action. Or we can use the current cue table to find the best\\naction. So how do we actually implement that into our open AI gym? Well, I just wanted\\nto write a little code block here to show you the exact code that will do this for us.\\nSo we\'re gonna introduce this new concept, or this new, I can almost call it constant\\ncalled epsilon. I think, epsilon, I think I spelt this wrong, app salon. Yeah, that\\nshould be how you spell it. So we\'re gonna start the epsilon value essentially tells\\nus the percentage chance that we\'re going to pick a random action. So here, we\'re gonna\\nuse a 90% epsilon, which essentially means that every time we take an action, there\'s\\ngonna be a 90% chance, it\'s random and 10% chance that we look at the cue table to make\\nthat action, now won\'t reduce this epsilon value as we train so that our model will start\\nbeing able to explore, you know, as much as it possibly can in the environment by just\\ntaking random actions. And then after we have enough observations, and we\'ve explored the\\nenvironment enough, we\'ll start to slowly decrease the epsilon, so that it hopefully\\nfinds a more optimal route for things to do. Now, the way we do this is we save NP dot\\nrandom dot uniform 01, which essentially means pick a random value between zero and one is\\nless than epsilon and salon like, that\'s, I think I\'m gonna have to change some other\\nstuff. But we\'ll see that action equals Nv dot action spaced out samples. So take a random\\naction, that\'s what this means store what that action is in here. Otherwise, we\'re going\\nto take the argument max of the state row in the cue table. So what this means is find\\nthe maximum value in the cue table and tell us what row it\'s in. So that way we know what\\naction to take. So if we\'re in row, I guess not sorry, not row, column four and column\\none, you know, that\'s maximum value, take action one, that\'s what this is saying. So\\nusing a cue table to pick the best action. Alright, so we don\'t need to run this because\\nthis is just going to be, we just I just wrote that to show you. Now how do we update the\\nQ values? Well, this is just following the equation that I showed above. So this is the\\nline of code that does this, I just want to write it out. So you guys could see exactly\\nwhat each line is doing and kind of explore it for yourself. But essentially, you get\\nthe point, you know, you have your learning rate, reward gamma, take the max. So NP dot\\nmax does the same thing as a max function in Python, this is going to take the max value,\\nnot the argument max from the next state, right, the new state that we moved into, and\\nthen subtracting, obviously, the queue state action. Alright, so putting it all together.\\nSo now we\'re actually going to show how we can train and create this cue table and then\\nuse that cue table. So this is the pretty much all this code that I have, we\'ve already\\nactually written at least this block here. That\'s why I put it in its own block. So just\\nall the constants, I\'ve included this render constant to tell us whether we want to draw\\nthe environment or not, in this case, I\'m gonna leave it false. But you can make it\\ntrue. If you want episodes, I\'ve left that 1500. For this, if you want to make your model\\nbetter, typically, you train it on more episodes. But that\'s up to you. And now we\'re gonna\\nget into the big chunk of code, which I\'m going to talk about. So what this is going\\nto do, we\'re going to have a rewards list, which is actually just going to store all\\nof the rewards we see just so I can graph that later for you guys. Then we\'re going\\nto say for episode in range episodes. So this is just telling us, you know, for every episode,\\nlet\'s do the steps I\'m about to do so maximum episodes, which is our training length, essentially,\\nwe\'re going to reset the state, obviously, which makes sense. So state equals n v dot\\nreset, which will give us the starting state, we\'re going to say for underscore in range\\nmax steps, which means Okay, we\'re going to do you know, we\'re going to explore the environment\\nup to maximum steps, we do have a done here, which will actually break the loop if we breach\\nthe goal, which we\'ll talk about further. So the first thing we\'re gonna do is say if\\nrender, you know, render the environment, that\'s pretty straightforward. Otherwise,\\nlet\'s take an action. So for each time step, we need to take an action. So epsilon i think\\nis spelt correctly here. Yeah, I believe that\'s right. I\'m gonna say action equals mv dot\\naction space, this is already the code we\'ve looked at. And then we\'re gonna say is next\\nstate reward done, underscore equals EMB, dot step action, we\'ve put an underscore here,\\nbecause we don\'t really care about this info value. So I\'m not going to store it. But we\\ndo care about what the next state will be the reward from that action and if we were\\ndone or not. So we take that action, that\'s what does this MV dot step, and then when\\nwe do is, say, Q, state action, and we just update the q value using the formula that\\nwe\'ve talked about. So this is the formula, you can look at it more in depth if you want,\\nbut based on whatever the reward is, you know, that\'s how we\'re going to update those q values.\\nAnd after a lot of training, we should have some decent q values in there. Alright, so\\nthen we set the current state to be the next state so that when we run this time step again, now our agent is in the next state, and can\\nstart exploring the environment again, in this current, you know, iteration almost,\\nif that makes sense. So then we say if done, so essentially, if the agent died, or if they\\nlost or with whatever it was, we\'re going to append whatever reward they got from their\\nlast step into the rewards up here, and it\'s worthy of noting that the way the rewards\\nwork here is you get one reward if you move to a valid block, and you get zero reward\\nif you die. So every time we move to a valid spot, we get one, otherwise we get zero. I\'m\\npretty sure that\'s the way it works at least. But that\'s something that\'s important to know.\\nSo then what we\'re going to do is reduce the epsilon, if we die by just a fraction of an\\namount, you know, 0.001, just so we slowly start decreasing the epsilon moving in the\\ncorrect direction. And then we\'re going to break because we\'ve reached the goals, print\\nthe cue table, and then print the average reward. Now this takes a second to train,\\nlike, you know, a few seconds really, that one\'s pretty fast, because I\'ve set this at\\nwas 1500. But if you want, you can set this up, say 10,000, wait another few minutes or\\nwhatever, and then see how much better you can do. So we can see that after that I received\\nan average reward of 0.288866667. This is actually what the cue table values look like.\\nSo all these decimal values, after all these updates, I just decided to print them out,\\nI just want to show you the average reward so that we can compare that to what we can\\nget from testing or this graph. So now I\'m just going to graph this. And we\'re going\\nto see this is what the graph, so you don\'t have to really understand this code if you\\ndon\'t want to. But this is just graphing the average reward over 100 steps from the beginning\\nto the end. So essentially, I\'ve been I\'ve calculated the average of every 100 episodes,\\nand then just graph this on here, we can see that we start off very poorly in terms of\\nreward because the epsilon value is quite high, which means that we\'re taking random\\nactions pretty much all the time. So if we\'re taking a bunch of random actions, obviously,\\nchances are, we\'re probably going to die a lot, we\'re probably going to get rewards of\\nzeros quite frequently. And then after we get to about 600 episodes, you can see that\\nsix actually represents 600, because this is in hundreds, we start to slowly increase.\\nAnd then actually, we go on a crazy increase here, when we start to take values more frequently.\\nSo the epsilon is increasing, right. And then after we get here, we kind of level off. And\\nI this does show a slight decline. But I guarantee you, if we ran this for you know, like 15,000,\\nit would just go up and down and Bob up and down. And that\'s just because even though\\nwe have increased the epsilon, there is still a chance that we take a random action and\\nyou know, gets your reward. So that is pretty much it for this Q learning example. And I\\nmean, that\'s pretty straightforward. To use the cue table, if you actually wanted to say,\\nyou know, watch the agent move around the thing, I\'m going to leave that to you guys,\\nbecause if you can follow what I\'ve just done in here, and understand this, it\'s actually\\nquite easy to use the cue table. And I think as like a final almost like, you know, trust\\nin you guys, you can figure out how to do that. The hint is essentially do exactly what\\nI\'ve done in here, except don\'t update the cue table values, just use the cue table values\\nalready. And that\'s, you know, pretty much all there is to Q learning. So this has been\\nthe reinforcement learning module for this TensorFlow course, which actually is the last\\nmodule in this series. I hope you guys have enjoyed up until this point, just emphasis\\nagain, this was really just an introduction to reinforcement learning, this technique\\nin this problem itself is not very interesting and not, you know, the best way to do things\\nis not the most powerful, it\'s just to get you thinking about how reinforcement learning\\nworks. And potentially, if you\'d like to look into that more, there\'s a ton of different\\nresources and you know, things you can look at in terms of reinforcement learning. So\\nthat being said, that has been this module. And now we\'re going to move into the conclusion\\nwe\'ll we\'ll talk about some next steps and some more things that you guys can look at\\nto improve your machine learning skills. So finally, after about seven hours, of course\\ncontent, we have reached the conclusion of this course. Now, what I\'m going to do in\\nthis last brief short section is just explained to you where you can go for some next steps\\nand some further learning with TensorFlow and machine learning artificial intelligence\\nin general. Now, what I\'m going to be recommending to you guys is that we look at the TensorFlow\\nwebsite, because they have some amazing guides and resources on here. And in fact, a lot\\nof the examples that we used in our notebooks were based off of or exactly the same as the\\noriginal TensorFlow guide. And that\'s because the code that they have is just very good,\\nthey\'re very good and easy to understand examples. And in terms of learning, I find that these\\nguides are great for people that want to get in quickly see the examples and then go and\\ndo some research on their own time and understand why they work. So if you\'re looking for some\\nfurther steps, at this point in time, you have gained a very general and broad knowledge\\nof machine learning and AI, you have some basic skills in a lot of the different areas.\\nAnd hopefully, this has introduced you to a bunch of different concepts and the possibilities\\nof what you are able to do using modules like TensorFlow. Now, what I\'m going to suggest\\nto all of you is that if you find a specific area of machine learning or AI that you are\\nvery interested in that you would dial in on that area and focus most of your time into\\nlearning that. That is because when you get to a point in machine learning in AI, where\\nyou really get specific and pick one kind of strain or one kind of area, it gets very\\ninteresting very quickly and you can devote most of your time to getting as deep as possible\\nin that space. cific topic. And that\'s something that\'s really cool. And most people that are\\nexperts in the AI or machine learning field typically have one area of specialization.\\nNow, if you\'re someone who doesn\'t care to specialize an area, or you just want to play\\naround and see some different things, the TensorFlow website is great to really get\\nkind of a general introduction to a lot of different areas and be able to kind of use\\nthis code, tweak it a little bit on your own, and implement it into your own projects. And\\nin fact, the next kind of steps and resources I\'m going to be showing you here involves\\nsimply going to the TensorFlow website, going to the tutorial page, this is very easy to\\nfind, I don\'t even need to link it, you can just search TensorFlow. And you\'ll find this\\nonline. And looking at some more advanced topics that we haven\'t covered. So we\'ve covered\\na few of the topics and tutorials that are here, I\'ve just kind of modified their version,\\nand thrown out in the notebook and explained it in words and video content. But if you\'d\\nlike to move on to say a next step, or something very cool, something I would recommend is\\ndoing the deep dream in the generic, generic neural network section on the TensorFlow website,\\nbeing able to make something like this, I think is very cool. And this is an example\\nwhere you can tweak this a ton by yourself and get some really cool results. So some\\nthings like this are definitely next steps. There\'s tons and tons of guides and tutorials\\non this website, they make it very easy for anyone to get started. And with these guides,\\nwhat I will say is typically what will end up happening is they just give you the code\\nand brief explanations of why things work, you should really be researching and looking\\nup some more, you know, deep level explanations of why some of these things work as you go\\nthrough if you want to have a firm and great understanding of why the model performs the\\nway that it does. So with that being said, I believe I\'m going to wrap up the course\\nnow, I know you guys can imagine how much work I put into this. So please do leave a\\nlike, subscribe to the channel, leave a content show your support. This I believe is the largest\\nopen source machine learning course in the world that deals completely with TensorFlow\\nand Python. And I hope that this gave you a lot of knowledge. So please do give me your\\nfeedback down below in the comments. With that being said again, I hope you enjoyed\\nand I hopefully I will see you again in another tutorial guide or series."", metadata={\'source\': \'tPYj3fFJGjk\'})]""""""', '""""""[Document(page_content=""first we import tensorflow as tf then we print out the tensorflow version that we are using we are using tensorflow 1.0.1 in this video we\'re going to create a tensorflow constant tensor populated with a scalar value by using the tensorflow constant operation as well as defining the shape and the data type alright let\'s get started for the first example we\'ll create a tensorflow constant tensor with dimensions 2 3 4 which is populated with the scalar value 10.0 and the data type of float32 note that we use tf.constant and we assign it to the python variable constant underscore flow underscore tensor something to note is that if we don\'t specify the shape then tensorflow.constant will use the dimensions of the value that we pass in to create the constant and because we\'re passing in a scalar which has dimensions of 0 the constant wouldn\'t be a tensor so we need to pass in the shape that we want which is two by three by four we give it a data type and so when it produces this constant it\'ll be a tensor that\'s two by three by four filled with 10.0 for every entry let\'s now print to see what we have we see that it is a tensorflow tensor its name is const the shape is two by three by four and the data type is flow 32 because we haven\'t run and evaluated the tensor in the tensorflow session we don\'t see any values for the second example we\'ll create a tensorflow constant tensor with dimensions of 1 by 2 by 3 with a data type of n32 the value we want to fill this tensor with is negative 255 and we\'re using the tensorflow.constant operation and we\'re going to assign it to the python variable constant underscore end underscore tensor and we print it to see what we have we see that it is a tensorflow tensor the name has changed the const underscore one that\'s because this one had the name of constant the shape is one by two by three and the data type is in 32. now that we have created our tensorflow tensors it\'s time to run the computational graph we launch the graph in a session then we initialize all the global variables and tensors in the graph let\'s now print our two constant tensors we created to see what\'s inside we first print constant underscore flow underscore tensor and a session.run and we see that it is a 2 by 3 by 4 tensor filled with 10.0 10.0 10.0 for every single element we next print constant in tensor constant underscore nt underscore tensor and we see that it is a shape one by two by three and it is filled with negative 255 and it has no decimal points which shows us visually that it is not a float32 beta type it as an int 32 data type perfect it worked we were able to create our two tensorflow constants with the dimensions that we wanted and the data types that we wanted finally we closed the tensorflow session to release the tensorflow resources used within the session and that is how you create a tensorflow constant tensor populated with a scalar value by using the tensorflow constant operation as well as defining the shape and data type that you want"", metadata={\'source\': \'Jn5sQjYi1FU\'})]""""""']","{'https://stackoverflow.com/questions/61059725/why-does-tf-constant-give-a-dtype-error-if-we-pass-in-a-tensor', 'https://stackoverflow.com/questions/44880564/tf-variable-vs-tf-constant-in-tensorflow'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nWhy does tf.constant give a dtype error if we pass in a tensor? Asked 4 years, 2 months ago\n\nModified 4 years, 2 months ago\n\na = tf.range(10) b = tf.constant(a, dtype=tf.float32)\n\ngives the following error:\n\nTypeError: Expected tensor with type tf.float32 not tf.int32\n\nAlthough from the documentation, setting dtype means that tf.constant is supposed to cast a to the specified data type. So I don\'t see why this should give a type error. a = np.arange(10) b = tf.constant(a, dtype=tf.float32)\n\ndoes not give an error. So actually, I\'m mainly wondering about what\'s happening under the hood here.""""""', '""""""Alexander SoareAlexander Soare\n\n\n\nIf you look at the source here, you will see that EagerTensor gets a special treatment. Basically, if the dtype of an EagerTensor doesn\'t match the new dtype, an error is raised. Here, tf.range() produces an EagerTensor. I\'m not sure why the special treatment for EagerTensors though. Could be a performance related restriction. """"""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nWhy does tf.constant give a dtype error if we pass in a tensor? Asked 4 years, 2 months ago\n\nModified 4 years, 2 months ago\n\na = tf.range(10) b = tf.constant(a, dtype=tf.float32)\n\ngives the following error:\n\nTypeError: Expected tensor with type tf.float32 not tf.int32\n\nAlthough from the documentation, setting dtype means that tf.constant is supposed to cast a to the specified data type. So I don\'t see why this should give a type error. a = np.arange(10) b = tf.constant(a, dtype=tf.float32)\n\ndoes not give an error. So actually, I\'m mainly wondering about what\'s happening under the hood here.""""""']"
71149271,tf.data.Dataset,example required,"How to remove single feature from tensorflow dataset, how to use apply on single feture?","<p>I created dataset from csv file with dataset = tf.data.experimental.make_csv_dataset() function but My dataset has categorical and numeric features.</p>
<pre><code>dataset=
color  price weight
red    120    1.2
blue    80     2.0
green   90     3
</code></pre>
<p>Question 1:
The question is how can I  modify  only single feature, for example weight +2, to:</p>
<pre><code>dataset=
color  price weight
red    120    3.2
blue    80     4.0
green   90     5
</code></pre>
<p>I try to do something like:</p>
<pre><code>dataset = dataset.apply(lambda x: x['weight']+2)
</code></pre>
<p>but the error is: &quot;TypeError: 'FilterDataset' object is not subscriptable&quot;</p>
<p>Example from the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply</a> doesn't show it.</p>
<p>Question 2:
How can I remove single feature ? Is there any equivalent to pandas drop column?</p>
","<p>You can remove features by only filtering the features that you want. This how you can modify only one feature:</p>
<pre><code>import tensorflow as tf
import pandas as pd

df = pd.DataFrame(data={'color': ['red', 'blue','green'], 'price': [120, 80, 90], 'weight': [3.2, 4.0, 5]})
df.to_csv('data.csv', index=False)

dataset = tf.data.experimental.make_csv_dataset('/content/data.csv', batch_size=1, num_epochs = 1, shuffle=False)
dataset = dataset.map(lambda x: (x['color'], x['price'], x['weight']+2))

for x in dataset:
  print(x[0], x[1], x[2])
</code></pre>
<pre><code>tf.Tensor([b'red'], shape=(1,), dtype=string) tf.Tensor([120], shape=(1,), dtype=int32) tf.Tensor([5.2], shape=(1,), dtype=float32)
tf.Tensor([b'blue'], shape=(1,), dtype=string) tf.Tensor([80], shape=(1,), dtype=int32) tf.Tensor([6.], shape=(1,), dtype=float32)
tf.Tensor([b'green'], shape=(1,), dtype=string) tf.Tensor([90], shape=(1,), dtype=int32) tf.Tensor([7.], shape=(1,), dtype=float32)
</code></pre>
","<pre><code>import tensorflow as tf
import pandas as pd

df = pd.DataFrame(data={'color': ['red', 'blue','green'], 'price': [120, 80, 90], 'weight': [3.2, 4.0, 5]})
df.to_csv('data.csv', index=False)

dataset = tf.data.experimental.make_csv_dataset('/content/data.csv', batch_size=1, num_epochs = 1, shuffle=False)
dataset = dataset.map(lambda x: (x['color'], x['price'], x['weight']+2))

for x in dataset:
  print(x[0], x[1], x[2])
</code></pre>
<pre><code>tf.Tensor([b'red'], shape=(1,), dtype=string) tf.Tensor([120], shape=(1,), dtype=int32) tf.Tensor([5.2], shape=(1,), dtype=float32)
tf.Tensor([b'blue'], shape=(1,), dtype=string) tf.Tensor([80], shape=(1,), dtype=int32) tf.Tensor([6.], shape=(1,), dtype=float32)
tf.Tensor([b'green'], shape=(1,), dtype=string) tf.Tensor([90], shape=(1,), dtype=int32) tf.Tensor([7.], shape=(1,), dtype=float32)
</code></pre>","['How to modify a single feature in a TensorFlow dataset created from a CSV file?', 'How to apply transformations to specific columns in a TensorFlow dataset?', 'How to add a constant value to a numeric feature in a TensorFlow dataset?', 'How to remove a single feature from a TensorFlow dataset?', 'Is there an equivalent to pandas drop column in TensorFlow dataset API?', 'How to use tf.data.Dataset.map to modify specific columns?']","['How to modify a single feature in a TensorFlow dataset created from a CSV file?', 'How to add a constant value to a specific column in a TensorFlow dataset?', 'How to remove a single feature from a TensorFlow dataset?', 'Is there an equivalent to pandas drop column in TensorFlow dataset?', 'How to apply transformations to specific columns in a TensorFlow dataset?']",set(),[],"{'https://stackoverflow.com/questions/52787372/tensorflow-add-dimension-column-with-constant-value', 'https://stackoverflow.com/questions/71149271/how-to-remove-single-feature-from-tensorflow-dataset-how-to-use-apply-on-single'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nTensorFlow: Add dimension (column) with constant value\n\nAsked 5 years, 9 months ago\n\nModified 3 years, 5 months ago\n\nI have a Tensor of shape (-1,) which represents a list of indices. I want to create a Tensor of shape (-1,2). The first column should be the same as the list of indices, while the second column should be filled with a constant. Eg (let\'s say the constant is 6):\n\nindices = [4, 35, 230, 235] my_goal = [[4, 6], [35, 6], [230, 6], [235, 6]]\n\nWhat is the best way to do this? I was hoping a broadcasting-tf.concat would work, but tf.concat doesn\'t seem to support broadcasting. Martijn CourteauxMartijn Courteaux\n\n\n\nYou can use tensorflow.pad. But first you have to make it a two dimensional tensor. indices = tf.constant([1,2,3,4]) indices = tf.expand_dims(tf, 1) # now you have a (4,1) tensor padding = [[0,0],[0,1]] # no padding before or after the first dimension # no padding before second dimension. Single-element padding # after the second dimension my_goal = tf.pad(indices, padding, constant_values=6)\n\nPadding has to be [n,2] tensor. For more information, look into: https://www.tensorflow.org/api_docs/python/tf/pad.""""""', '""""""Is there any equivalent to pandas drop column? Peter PirogPeter Pirog\n\nYou can remove features by only filtering the features that you want. This how you can modify only one feature:\n\nimport tensorflow as tf import pandas as pd df = pd.DataFrame(data={\'color\': [\'red\', \'blue\',\'green\'], \'price\': [120, 80, 90], \'weight\': [3.2, 4.0, 5]}) df.to_csv(\'data.csv\', index=False) dataset = tf.data.experimental.make_csv_dataset(\'/content/data.csv\', batch_size=1, num_epochs = 1, shuffle=False) dataset = dataset.map(lambda x: (x[\'color\'], x[\'price\'], x[\'weight\']+2)) for x in dataset: print(x[0], x[1], x[2])\n\ntf.Tensor([b\'red\'], shape=(1,), dtype=string) tf.Tensor([120], shape=(1,), dtype=int32) tf.Tensor([5.2], shape=(1,), dtype=float32) tf.Tensor([b\'blue\'], shape=(1,), dtype=string) tf.Tensor([80], shape=(1,), dtype=int32) tf.Tensor([6.], shape=(1,), dtype=float32) tf.Tensor([b\'green\'], shape=(1,), dtype=string) tf.Tensor([90], shape=(1,), dtype=int32) tf.Tensor([7.], shape=(1,), dtype=float32)\n\nAloneTogetherAloneTogether\n\n 0\n\n""""""', '""""""Is there any equivalent to pandas drop column? Peter PirogPeter Pirog\n\nYou can remove features by only filtering the features that you want. This how you can modify only one feature:\n\nimport tensorflow as tf import pandas as pd df = pd.DataFrame(data={\'color\': [\'red\', \'blue\',\'green\'], \'price\': [120, 80, 90], \'weight\': [3.2, 4.0, 5]}) df.to_csv(\'data.csv\', index=False) dataset = tf.data.experimental.make_csv_dataset(\'/content/data.csv\', batch_size=1, num_epochs = 1, shuffle=False) dataset = dataset.map(lambda x: (x[\'color\'], x[\'price\'], x[\'weight\']+2)) for x in dataset: print(x[0], x[1], x[2])\n\ntf.Tensor([b\'red\'], shape=(1,), dtype=string) tf.Tensor([120], shape=(1,), dtype=int32) tf.Tensor([5.2], shape=(1,), dtype=float32) tf.Tensor([b\'blue\'], shape=(1,), dtype=string) tf.Tensor([80], shape=(1,), dtype=int32) tf.Tensor([6.], shape=(1,), dtype=float32) tf.Tensor([b\'green\'], shape=(1,), dtype=string) tf.Tensor([90], shape=(1,), dtype=int32) tf.Tensor([7.], shape=(1,), dtype=float32)\n\nAloneTogetherAloneTogether\n\n 0\n\n""""""', '""""""Is there any equivalent to pandas drop column? Peter PirogPeter Pirog\n\nYou can remove features by only filtering the features that you want. This how you can modify only one feature:\n\nimport tensorflow as tf import pandas as pd df = pd.DataFrame(data={\'color\': [\'red\', \'blue\',\'green\'], \'price\': [120, 80, 90], \'weight\': [3.2, 4.0, 5]}) df.to_csv(\'data.csv\', index=False) dataset = tf.data.experimental.make_csv_dataset(\'/content/data.csv\', batch_size=1, num_epochs = 1, shuffle=False) dataset = dataset.map(lambda x: (x[\'color\'], x[\'price\'], x[\'weight\']+2)) for x in dataset: print(x[0], x[1], x[2])\n\ntf.Tensor([b\'red\'], shape=(1,), dtype=string) tf.Tensor([120], shape=(1,), dtype=int32) tf.Tensor([5.2], shape=(1,), dtype=float32) tf.Tensor([b\'blue\'], shape=(1,), dtype=string) tf.Tensor([80], shape=(1,), dtype=int32) tf.Tensor([6.], shape=(1,), dtype=float32) tf.Tensor([b\'green\'], shape=(1,), dtype=string) tf.Tensor([90], shape=(1,), dtype=int32) tf.Tensor([7.], shape=(1,), dtype=float32)\n\nAloneTogetherAloneTogether\n\n 0\n\n""""""']"
63146831,tf.custom_gradient,example required,What is the analytic interpretation for Tensorflow custom gradient?,"<p>In the official <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">tf.custom_gradient</a> documentation it shows how to define custom gradients for <code>log(1 + exp(x))</code></p>
<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient
def log1pexp(x):
  e = tf.exp(x)
  def grad(dy):
    return dy * (1 - 1 / (1 + e))
  return tf.math.log(1 + e), grad
</code></pre>
<p>When <code>y = log(1 + exp(x))</code>, analytically the derivative comes out to be <code>dy/dx = (1 - 1 / (1 + exp(x)))</code>.</p>
<p>However in the code <code>def grad</code> says its <code>dy * (1 - 1 / (1 + exp(x)))</code>.
<code>dy/dx = dy * (1 - 1 / (1 + exp(x)))</code> is not a valid equation. While <code>dx = dy * (1 - 1 / (1 + exp(x)))</code> is wrong as it should be the reciprocal.</p>
<p>What does the <code>grad</code> function equate to?</p>
","<p>I finally figured it out. The <code>dy</code> should be called <code>upstream_gradient</code> or <code>upstream_dy_dx</code>.</p>
<p>By chain rule we know that</p>
<p><a href=""https://i.stack.imgur.com/7g3aZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7g3aZ.png"" alt=""chain rule"" /></a></p>
<p>where <code>dx[i]/dx[i+1]</code> is the gradient of the current function.</p>
<p>So <code>dy</code> is the product of all the gradients upstream before this function.</p>
<p><a href=""https://i.stack.imgur.com/nu4Z8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nu4Z8.png"" alt=""enter image description here"" /></a></p>
<p>So, if you forget to multiply the <code>dy</code> it is effectively the same as <a href=""https://www.tensorflow.org/api_docs/python/tf/stop_gradient"" rel=""nofollow noreferrer"">tf.stop_gradient</a></p>
<p>Here is a code which demos this. Full notebook <a href=""https://github.com/Ghost---Shadow/differentiable-programming-handbook/blob/master/notebooks/custom-gradient.ipynb"" rel=""nofollow noreferrer"">here</a></p>
<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient
def foo(x):
    tf.debugging.assert_rank(x, 0)

    def grad(dy_dx_upstream):
        dy_dx = 2 * x
        dy_dx_downstream = dy_dx * dy_dx_upstream
        tf.print(f'x={x}\tupstream={dy_dx_upstream}\tcurrent={dy_dx}\t\tdownstream={dy_dx_downstream}')
        return dy_dx_downstream
    
    y = x ** 2
    tf.print(f'x={x}\ty={y}')
    
    return y, grad


x = tf.constant(2.0, dtype=tf.float32)

with tf.GradientTape(persistent=True) as tape:
    tape.watch(x)
    y = foo(foo(foo(x))) # y = x ** 8

tf.print(f'\nfinal dy/dx={tape.gradient(y, x)}')
</code></pre>
<p>Output</p>
<pre><code>x=2.0   y=4.0
x=4.0   y=16.0
x=16.0  y=256.0
x=16.0  upstream=1.0    current=32.0        downstream=32.0
x=4.0   upstream=32.0   current=8.0     downstream=256.0
x=2.0   upstream=256.0  current=4.0     downstream=1024.0

final dy/dx=1024.0
</code></pre>
","<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient
def foo(x):
    tf.debugging.assert_rank(x, 0)

    def grad(dy_dx_upstream):
        dy_dx = 2 * x
        dy_dx_downstream = dy_dx * dy_dx_upstream
        tf.print(f'x={x}\tupstream={dy_dx_upstream}\tcurrent={dy_dx}\t\tdownstream={dy_dx_downstream}')
        return dy_dx_downstream
    
    y = x ** 2
    tf.print(f'x={x}\ty={y}')
    
    return y, grad


x = tf.constant(2.0, dtype=tf.float32)

with tf.GradientTape(persistent=True) as tape:
    tape.watch(x)
    y = foo(foo(foo(x))) # y = x ** 8

tf.print(f'\nfinal dy/dx={tape.gradient(y, x)}')
</code></pre>","['Understanding tf.custom_gradient in TensorFlow', 'How to define custom gradients in TensorFlow', 'Explanation of custom gradient function in TensorFlow', 'TensorFlow custom gradient example log1pexp', 'How does the grad function work in tf.custom_gradient', 'TensorFlow custom gradient tutorial', 'Defining and using custom gradients in TensorFlow', 'TensorFlow custom gradient API documentation explained', 'Step-by-step guide to tf.custom_gradient in TensorFlow', 'Understanding the grad function in TensorFlow custom gradients']","['What does the grad function in tf.custom_gradient represent?', 'How does the grad function in tf.custom_gradient relate to the derivative of the function?', 'Why is dy multiplied by the derivative in the grad function of tf.custom_gradient?', ""How to correctly interpret the grad function in TensorFlow's tf.custom_gradient?"", 'What is the purpose of the dy parameter in the grad function of tf.custom_gradient?']","{'https://www.youtube.com/watch?v=-0bF9tEv9YU', 'https://www.youtube.com/watch?v=VmaBfi-CWv4'}","['""""""[Document(page_content=""hello guys and welcome to another tensorflow tutorial today I\'ll be showing you guys how to make a custom layer with custom gradient so without further Ado let\'s just start coding so obviously we\'re going to import dense flow as TF as always and then we\'re gonna actually make it close let me just add this a few lines so that python doesn\'t complain about formatting issues so you\'re going to be replicating the dense layer so I\'m just going to call it my dense layer and then we have to we\'re going to extend off the the layer class so layers.layer then now we have the make an init function um begin I want to pass in the input size and the hidden hidden size then we\'ll just initialize W this is not really needed like all these initializes these next three lines that I\'m going to do but I\'m just going to put them on so it\'s easier to convert this to make it more robust which I\'ll explain to you guys later how you can make it more robust um then so yeah we\'re just gonna re we\'re gonna write over W now which is solve.add I\'m going to solve that ad weight and then we\'re just going to name this W then shape equals input size sorry input size then hidden it\'s actually soft but here in size we\'ll just leave it at that salon so this is we can just hold paste this into somewhere else to make a more robust in the future then we\'re gonna have an initializer it\'s going to be a random normal then we have to set trainable to true Okay cool so off that what is oh okay so yeah we\'ve got something really important which is we have to add this line in um and actually I have to add in the class name as well comma solve then that should yeah okay that works and then we want to do the same for w as well but W is going to be a bit different because the shape is actually it\'s just the hidden hidden size and we\'ll just add a comma afterwards okay check trainable to True randomly um I think we can for now we\'ll just send this but normally you just set um B2B 0 that\'s fine W has to be randomly initialized so that it\'s not symmetrical because if you set it to zero then it\'s just all the neurons are going to basically do the same function it\'s the same operation the same inputs so it\'s good the function is going to be symmetrical well the operation is going to be symmetrical so what we want to do next is wanna just create the core function this is going to be the the forward pass basically and this would just be return matte sorry TF dot Matt small tf.map more and then why what do we have to do with the scanner yeah so this would be solve Dot W and then I\'m just trying to think now if we think it\'ll be soft so yeah okay so that\'s to be X first and then yeah solve the dot solve the W and then we Plus solve that b so this is how you just replicate like a dense layer and also this is actually the an indent this that should be fine okay so yeah let\'s format that so this is without like a custom gradient this is just you can use tensorflows functions to build your own custom layer and as long as you\'re using tensorflow\'s functions a tensor will be able to keep track of the the computational graph but if you\'re not gonna if you want to create your own function with your own gradients you\'ll have to actually make your own tensorflow function with that with a custom gradient so um to do that we\'ll just um we\'ll have to start with TF Dot well we\'ll just call this custom we\'ll make the function for gradient then we\'re going to take in a WRB and an X and then we have to decorate the function just return decorate the function with TF dot custom gradient there is no brackets of that okay so um four passes the same as autopia so let\'s just go paste this and take out the solves by the way also note that the um this this function is actually outside of the class but you can put it in but like yeah it\'s better to but uh it\'s fine if you have it outside as well um after that we actually Gonna Wanna do the back propagation so we\'re gonna create the gradient function so that\'s gonna take in dldz which is the the gradients that have been back propagated through the network so we take that in and before actually I go into this I\'m going to explain to you guys how like how I came about these formulas and like where I got them from Etc so you guys can follow along easily and explain to you a bit about that so I\'ll see you there okay cool so these are the these are the standard formulas for computing the gradients for the fully connected layer or dense layer intense flows the case so first I want you to notice that um the input data X at the bottom right over here it\'s uh it\'s in well the each training example is in its own column so like a training example would be like one image or one row of a table if you were working with tabular data um but yeah so as you can see tensorflow actually stores the the data in the opposite way that was in the previous slide so like it\'s actually the rows are for each training example so that\'s why we\'re gonna have to tweak it a bit so to get these formulas that I have in front of you over here what I\'ve actually done is I\'ve just transposed X so like the tensorflow X X of T and I\'m multiplied by dldz deltz is also like transpose from the previous slide so the the LDL dldz is the The Still d said but transpose then yeah I did that for both W and wnx so I basically just transpose this W or the X and I swap these two the dldb is basically the same as before because it\'s just straight up a dld of all the bias grain is basically the ldb is just this dldz it\'s straight up just equal to that the catch for that is that we actually are working in batches so we have many dld said it\'s not like exactly so so this would be like 100 Vector but this would be like 32 by a hundred so what we\'re gonna have to do is that we\'re gonna we\'re going to have to um we\'re gonna have to sum across the the batching dimension so that would be the First Dimension but yeah that\'s all you kind of need to know so yeah let\'s continue coding so from the previous previous uh slides we actually need to compute two things quick before do anything else I\'m gonna copy the transverse of w and then transpose of X TF dot transpose and X easy as that tldw so dldw was actually just TF dot mat mole of X of t d l d z if you can remember and then dldx is equal to TF dot map Mall of DLT said and WFT and then the ldb I said was equal to so dldb is equal to TF dot reduce sum of the LTZ axis so I was I was actually just equal to dltz but we\'re going to want to sum this so it\'s just some quick so tf.reduce sum and then we\'re gonna do it across the batching Dimension which is zero and then we want to return the ldw dldb DL DX the order of this is very important first of all I just want to make two comments so the order of this is very important as to be the same order as the as the parameters are passed into the actual like the the function it should be custom operation and second of all that this W has to be the same Dimension as this B has to be the same Dimension as this x has to be the same Dimension as this well sorry this has to be the same Dimension as X for this to work all stance flow is going to throw some errors after that we kind of we just have to return we have to return the Y of course and then we have the return grad function but we don\'t actually turn the the function we just returned point all the we don\'t return like a value from the function we turn the function itself so we don\'t put a bracket at the end there so after that actually it\'s Gonna Wanna I\'m just gonna put this in here and then we\'re actually going to change this to custom operation then that should be the same so I\'m just double checking everything everything looks good so let me just show you guys how to actually use this so it\'s just a if name equals main then I\'m just gonna pull in we can use mnst to test this so X train comma y train comma X test comma y test then we want to pull in the TF dot qrs.datorsets dot and then we want mnest mnest.load data X train so we want to actually pre-process extra invest it\'s uh 28 by 28 by one so you want to kind of reshape it so that we can flatten it into a two-dimensional tensor so what we\'re going to do for that is we\'re going to go X train and then minus one so tens flow is going to infer the dimension while the the value of this Dimension or how big this is and then the image is 28 by 28 so that\'s why we\'re going to add you know the 28 by 28 and then I\'m just gonna put this to float32 I don\'t think this is really needed because when we divide by 255.0 I think it will change that to float32 anyway and we\'ll do the same for X test so let\'s just that could paste this for X test cool all right so let\'s just first um I just want to print because we\'re gonna do this we\'re gonna do a test for both the custom dance layer and the intense Flow State so this one I\'ll print this I\'m gonna make like a heading there basically and off that we\'re gonna actually create our model so without custom layer in it so TF Dot curs.sequential sorry about that and then tf.curus we want an input layer sorry layers Dot input and then shape is equal to 28 times 28. that\'s fine off that put a comma at the end and then Rihanna put in our dense layer so the input is going to be 28 times 28. and then we want also the output size of the header and size this would be 64. and then just copy paste this three times okay so we actually have to so this is we\'re gonna feed a dimension of 64 in here so we\'re gonna want to change this to 64. you can lower this this is going to be 32 this will be 10. after that we\'ll actually I think that\'s it um then we\'ll add model zero dot compile and then we want to just set our losses loss is equal tip TFT losses dot sparse categorical entropy and then from logit\'s multi true so basically um normally we\'d put it into a soft Max but since we\'re not putting it into a soft Max we\'re going to say it\'s from the largest so it\'s going to apply the soft Max and then it\'s going to apply this loss function um yeah and after that we will just do Optimizer equals TF dot curious Dot optimizers dot atom and then we\'ll just have the default learning rate so we don\'t need a actually add anything after that we\'ll have metrics this is obviously accuracy tens flows well Python\'s getting in the way accuracy um after that we\'ll just we can just fit the model Modelo dot fit extreme y train and then we\'re just gonna do four five epochs um and we\'ll do even worry about it we\'ll evaluate it on the test set um evaluate X test whitest and then so I said we\'re gonna do this for both uh our custom layer and also our of all tense flows dense layers so let\'s just change this um so tensorflow no I\'m not the right one this is tensorflow I just want to add this up here quick so we know it when it ends we\'re going to change this to an equals double line to show that it\'s done this at the bottom here as well so I don\'t forget later tensorflow dance layer okay so we want to change this to so for with python we can just you can just middle click and well not middle click sorry you click on your scroller and you just drag and it does this like a block highlight so tf.kiris dot layers dot dance and then we don\'t need this and we don\'t need this sorry I don\'t need first numbers 64 and this would so you can see the difference between all those right here just in terms of like when you initialize them you have to add both the inputs but tensorflow kind of um just infers the size so yeah uh everything seems to be set up so we can just actually run this up we got an error what is this it\'s not callable oh I think I did something yeah I\'ve got the dot reshape we have to reshape this all right let\'s run this again oh another area Okay um object has no attribute X we have to not double check this so let\'s just change this quick solter W salt dot b and then we we don\'t put in solve.x we put in x all right let\'s try this one more time this should work cool there\'s a working so yeah off this is done training I\'ll get back to you guys all right cool so it\'s done we can see that the results are very similar so it starts off at like 80 89 this starts off at like maybe 89.5 this is 88.5 so percent higher then afterwards it gets to about 92 this gets to 92.35 but the tensorflow actually beats it out by a a fraction of a percent in on the test set but this is basically due to how the weights are initialized and yeah that would depend on like maybe the this uh first first layer got better initialization weights and was able to train faster but yeah um they seem quite similar and there\'s very little difference let me just tell you guys how how you can make this more robust and you don\'t have to actually add in an input layer so what we can do is instead of having it in it well this this coding in it we can actually make a a bold function and this is called when tensorflow gets the input shape and maybe the models compiled I\'m not completely sure when this is run it\'s run like different size but basically it passes in the input shape and we can use this input shape to actually initialize our weights and we won\'t have to actually get in the input shape from the U from the the function initialization actually get our when tensorflow finds out the input shape and bolts the the neural network so let\'s just change our code so that it fits and this would be -1 because we want the last we can also just put one here because we\'re expecting two-dimensional input but yeah let\'s just leave it at one minus one so that it\'s more robust after that we actually have to change this so let\'s just so we don\'t need any of this and our layers are basically equal now and if we run it it should work but yeah that\'s what you that\'s how you create a custom layer with custom gradient intense flow hope you guys enjoyed please leave a like And subscribe if you want to see more content like this also drop a comment if you guys want to see anything if you guys want me to explain or make a tutorial on something that you guys are confused about hope you guys have a great day bye"", metadata={\'source\': \'VmaBfi-CWv4\'})]""""""', '""""""[Document(page_content=""so have you ever looked at machine learning source code for tensorflow kira\'s in this case and thought wow there\'s a lot going on there that\'s complicated what i\'m going to show you in this video i\'m trying something a bit new so let me know with a like or in the comments if you like this format or if you don\'t i\'m going to look at complicated machine learning code well beyond just the simple classification i don\'t know iris data set or even simple computer vision we\'re going to look through code that was implemented for a paper in this case we\'re going to look at style transfer but what this shows you how to do is a custom optimizer using the gradient tape so how you can pretty much just optimize anything that you can throw a tensorflow function at and how you can use transfer learning to in this case to bring embeddings in from the vgg trained neural network we\'re going to look at data that\'s not in rgb format we\'re going to see also how we process and create a multi-objective loss function that is coming from three different sources so the term complicated source code that\'s completely relative that\'s that\'s like when people say oh that\'s high school math i it\'s it\'s completely relative to yours to your skill level something that might seem simple for me might be complicated for you something that might seem simple for you could be complicated for me i\'m not just going to point the lines one by one i\'m going to show you how i take a piece of source code that i don\'t completely understand and pick it apart line it up to the paper line it up to documentation in kara\'s and make our way through it we\'re going to be looking at code that i did not create we\'re going to look at an example that was implemented according to the original paper from francois chalet who is the creator the original sort of creator of kara\'s so this is i really like looking at code by very advanced individuals because this this improves me it\'s like reading fine literature although i don\'t do that that often i did read some shakespeare in high school but basically it lets you really see how things should be implemented [Music] so the code that we\'re going to take a look at is the neural style transfer this was created by francois charlier it\'s about four years old at this point and it was last modified in 2020 so this is good they\'ve been keeping it up we\'re gonna look at it actually in collab but just if you\'re not familiar with what this code does it essentially takes a regular photograph like you see here of paris it then takes some sort of a painting and then applies through a bunch of code not a bunch of code it\'s relatively small the style to it and you\'re left with this i want to demonstrate the code that was created to do this because it shows some advanced techniques that can be very useful in tensorflow style game when i look at code like this first of all i want to get the the paper open because we will refer to the paper a couple of times as we as we go through this the paper is really pretty readable and approachable we\'ll talk about a couple of a couple of techniques that it pulls into here so i often hear about using these frameworks for quote unquote research i would say this falls under that category if you\'re taking something that\'s a bit non-standard that is not just a typical classification or image recognition problem and you\'re trying to actually apply it so we\'ll refer back to this the paper is not that long and it\'s not really what i would say that mathematically dense so there\'s the paper let me leave that open just surveying this you see some of the things going on in the very first part they\'re loading the images that\'s not terribly complicated displaying them there\'s some pre-processing steps and deprocessing steps going on here if you\'ve not looked at vgg which is the neural network that we\'re going to use for some style transfer and in layer embedding then this might seem a little bit complicated in terms of what is going on here we\'ll we\'ll get into that as we as we go through that why are those numbers being added to the color components why are we clipping to this range what what\'s with this weird colon colon negative one that\'s all vgg related stuff and we\'ll we\'ll talk about that in a moment then here\'s where a lot of it gets pretty complicated you\'ve got the the gram matrix so we need to deal with why we\'re doing a gram transformation on the matrix it\'s dealing with introducing some correlations between the various layers of the vgg network that we\'re using and we\'ll get into why we\'re doing that and then what really gets interesting with this particular neural network is we are using three different components to the loss function and to make those three custom loss functions actually be used we have to give kara\'s a way to form gradients on those so that we can apply an optimization function and here\'s where we actually use vgg this is actually the only neural network that\'s used in in this so this is this is using neural network almost just for pre-processing the actual work that the model is doing is not it\'s sort of a neural network we\'ll get to that in a moment this is the complete loss function so we\'ll we\'ll deal with that we make it a compiled tensorflow function for optimization and this is the real training loop that\'s going on here just to talk about this at a high level we\'re going through 4 000 iterations and when i am trying to understand source code like this i need to know the overall structure of what\'s going on because one of the things when i first saw style transfer like this i thought oh i\'m going to just apply this to a video and do every single frame and and create kind of a cool effect as the intro no that that actually doesn\'t work and i want to explain why that doesn\'t work because that becomes an important characteristic of this so you have to think about what you\'re really doing so you\'re using an optimizer and the optimizer is stochastic gradient descent but we\'re not just going to call akira\'s fit function in this case we\'re going to literally and this looks almost pi torch like we\'re going to go through all of the iterations by hand we\'re going to call compute loss and gradients which comes from kara\'s so this is going to use this optimizer to well the optimizer is going to actually apply the gradients we\'re going to compute the gradients with this compute loss and grad function so this is this is really getting a little more lower level where we\'re not just calling fit running through a bunch of iterations we\'re in control of every iteration we\'re computing our loss and our gradients and we\'re also applying the gradients using the optimizer now if you if you\'re a little unfamiliar with this the gradients that\'s that\'s essentially the instantaneous rate of change it\'s a calculus concept you can think of the gradients at a very high level i\'m skipping all the math on this one for a moment as sort of hints as far as which way each individual weight needs to go in order to minimize the loss function so you\'re creating these three loss functions each of which returns sort of a number the optimizers trying to crunch that number as close to zero as it possibly can and the the gradients are hints as far as how to do that on each weight now when i say weight that\'s an important characteristic here too because we have the loss we have the gradients we are going to use the optimizer and we\'re going to apply it to the to the gradients the weight is actually what\'s this this combination image that\'s created up here so if you see what we\'re doing take a step back we\'re getting the base image that\'s paris we\'re getting the style reference image that is the starry night looking thing the painting and then we\'re getting the combination image the combination image if you notice it\'s exactly the same thing almost it\'s it comes from the base image so at the beginning the base image and the combination image are really the same thing the combination image is the weights so that\'s what\'s going to be modified that\'s the parameters of the objective function is going to give the optimizer the guest a gradient descent the way to to crunch this down so when i first was learning this algorithm i was looking at this completely the wrong way i thought we were training a neural network to emulate the style that we have up here i thought we were training in a neural network that would take in this apply the style that we had taught it to do and then give us out the final version here and if that\'s what we would do applying this to video would be relatively easy you would simply take that neural network that you just trained and put every video frame into it ffmpeg the whole thing together that\'s how you combine individual frames into an mp4 file but it\'s not that easy because what we\'re really doing here we\'re not training anything really we\'re simply taking the combination image which is paris and each of these iterations that we\'re going through we\'re modifying the weights but the weights are paris it\'s it\'s that actual image so we\'re gradually stepping through and modifying the weights slowly so that each of those three objectives that we have which we\'re going to get to in a moment are satisfied as much as possible so we\'re trying to push all three of those together and those three are doing things like making sure it still looks something like the original applying the style and then making sure that the pixels close together are not too much of a divergent we\'ll get to why all three of those are important but we\'re not training any neural network we\'ve got a neural network vgg that is giving us some features that are being used to calculate those loss functions so if i wanted to truly apply this to to video i would essentially have to retrain the neural network each time and i could do that but it\'s going to take a lot of time on a higher end gpu it wouldn\'t be horrible i could certainly do it probably let it run overnight or a day but the problem you\'ll have is you\'ve got there\'s really i mean there is the stochastic nature from the stochastic gradient descent i believe you\'d have to think about if there\'s any stochastic initialization going on in here and i didn\'t check into that because then you could get kind of a weird flicker going on with the image where each each frame sort of has a different um a different look i don\'t know if you\'ve seen some of the animation like mtv\'s liquid tv where they had the really kind of squiggly lines around animation that\'s that\'s sort of what what you would end up looking like and not intentionally so let\'s take this apart and try to really understand what is actually going on here to do this i am going to go ahead and open this up in collab and this is this is the process that i go through when i\'m trying to really understand code that i don\'t understand and learn the actual technique that\'s happening or when i\'m intensely debugging my own code so here it is we\'re going to go to runtime we\'re going to change the runtime type to don\'t need high ram but i do need a gpu i\'m using google colepro so i\'ll have either a p100 or v100 so google pro go web pro is great i\'m going to do an updated 2021 video of that it\'s it\'s completely worth it i have a i have an a6000 and i still use google pro collab pro just to just to kind of prototype things there\'s there\'s definite disadvantages but it\'s not it\'s it\'s a great deal for 10 usd a month so let\'s start to run some of the code we\'re going to just take this completely through normally i would run the entire thing completely through just verify that it works and that i get the expected output but i\'m going to start running it through and try to really understand it looking at the code and seeing what it\'s doing so here we\'re loading paris we\'re loading starry night we\'re using kira\'s get file that\'s basically just a download the result prefix is just going to be we\'re going to save the frames of each of the images at the end because we\'re going to see how it it gradually gets more and more concrete as far as what we want it to display and again what we\'re saving we\'re saving the images we\'re not saving a neural network because we\'re not training any neural network here we\'re not saving the weights because the weights is actually the image so we\'re saving those but at the end you\'ve got nothing you\'ve got basically the image converted into paris but you don\'t have anything that could be used on any other image you\'ve got that image that\'s all you have if you want to apply this to video there\'s other subsequent papers that have done some very interesting things we\'ll play around with these a bit these are the weights so remember there\'s three parts of the objective function this is how important each of it is and these don\'t sum to zero or anything you can see they\'re very small numbers so they\'re one out to the sixth decimal place one out to the six decimal place those are actually equal and then the content weighting is is even smaller so if you think of what these are doing the style weight is how well are we implementing that abstract painting style the content weight is does it still look like what we what we wanted it to if if you just focused on style the neural network would be like fine i\'ll just copy it done but you need to have multiples going on the variation weight i\'ll show you some results with and without this one i wasn\'t impressed with this one helping or not i\'ll show you exactly what it what it does and by the way let\'s let\'s go ahead and take a look at that up front so the first thing i did with this is i ran it completely through and i set each of these to zero one by one so i do that a lot if you\'ve got a multiple objective function and you want to understand really why it needs three different objectives set one to zero run it and see what your end results are and i have those here so the first thing that i did is i just ran the whole thing through just to establish a baseline this is getting the same result as what the the original code did so let\'s keep that up there as a reference when i\'m editing the video i\'ll probably put them in bigger so you can see it easier but the first thing i did was i totally turned off the variation so this first one i set that to zero and let\'s see what that looks like this is the one that i was less i don\'t know i i i guess i can kind of see why it\'s useful but if you look at these images very very closely side by side look at the detailing on the windows it\'s it\'s much more abstract in the so let\'s look at the style weight the second one this one you see a drastic difference so if we turn off the style then kind of what is this thing even doing it\'s not even it\'s it\'s no longer saying that it has to be using that same style so it looks like a blurry photograph essentially the sort of the the first objective that we looked at here that was introducing the blur it\'s still there but it\'s it\'s it\'s all that\'s happening so you you have no style being given to it at all and then the the final one the one that is basically asking that the content be there this one also it didn\'t it did not change it a whole lot i can barely detect actually the differences here i think the reason we\'re not seeing as much of a change because you\'d think okay i turned off the content objective it\'s just it\'s just going to be uh it it\'s just going to copy the painting across but i believe information about the painting is seeping through as a result of the the total variation one that we see here which is basically looking at introducing the blur so i think you\'ve got some information slipping slipping in here but i i do like turning these on and off because you can you can see that really certain parts of the paper are much much more important than others and what what i\'m looking at doing with this is i may want to introduce some of my own so that i can add objectives related to very specific styles that i may want it to learn to emulate just just some ideas there so we ran that we run this part this just displays the images not not too much excitement there let me go ahead and run these two so this is your pre-process and d process image essentially what this is going to do is pre-process the image so that it can be read by the vgg neural network and vgg neural network it\'s a network that was trained on 1 000 images from imagenet and what it is mainly contributing to this is we\'re feeding the we\'re feeding the the images that we\'re working with into it to extract features from them from those convolution layers that are inside of it and we\'re we\'re using those to help it detect the style because embedded in vgg is going to be things about corners edges eyes and all sorts of different things that it extracted to know how to process those images and classify them so this is i guess this is somewhere between transfer learning and sort of embeddings this is almost like using vgg as sort of word to vect if you\'ve worked with the the the natural language processing because in natural language processes you can take individual words and you can pass the letters of them into the neural network but that doesn\'t tell the neural network all that much because it doesn\'t know the meanings of them just like the images it doesn\'t know the meanings of of what it\'s seeing in there but if you put something like vgg in there you\'re you\'re going to communicate some some meaning there process image this is there\'s not a lot going on here it\'s just getting into the form that we can pro send it into this pre-process image that is provided by vgg all of the cara\'s transfer learning models that they give you have a process input and that basically takes the image and puts it into the form that the neural network that you\'re transferring in needs to have vgg has some very specific input formats and that\'s all handled for you in process image however when you want to take something back out of it and make it look like a real image again you have to convert it out of vgg 19 form and and that\'s what all this code is doing and this code might look a bit complex i mean when i first look at it why these numbers the first thing that i always do to figure out something like this is i will take those numbers and scan the paper okay is it a paper thing no they\'re not in the paper anyway the first thing that was just kind of popping into yeah i\'m going to use the gpu in a minute patience google so basically these numbers are right about in the middle of the the 255 range that 24-bit color is is used in so my initial guess when i first saw this is it\'s it\'s doing something some sort of a shift to move those inputs so that they\'re centered around zero for the input to the neural network because that that tends to help neural networks so it\'s moving it out of that 255 range and making it more centered around zero which is always a good thing for neural net networks but nonetheless just to show you how i research some of this the google i would do right here on this is 103 116 123. just that alone nothing um i\'m wondering if it has something to do with vgg and now look at this how to normalize data for the vgg16 pre-training process and you see there are those those numbers and now you can start to figure out what the heck was going on there those numbers come from the original vgg paper i dug deeper back when i first used vgg and that\'s exactly what it\'s doing it\'s centering those are essentially from the data from the images that vgg was trained on where are essentially the probably the medians maybe the maybe the means of all of those rgb values so what this is doing is saying for all of the rows and columns that\'s those first two colons for the first one for the for the b actually because these are not in rgb format normally that would be red but for the blue for the green and for the red add that amount so that is now taking those numbers that are spanning between zero and spanning right across zero probably 120 negative 127 to positive 127 more or less but it\'s going to then move them into into more of a zero to 255 range like we\'re going to deal with this image is also stored not in rgb but in bgr so why bgr uh you can definitely google and research that a bit but essentially a lot of cameras internally do store it as bgr and opencv uses bgr and i believe vgg was used a lot with opencv so they they essentially just just copied it so you just have to flip the r and you essentially have to flip it uh backwards i mean the human race will store exactly the same thing in a bunch of really different ways just look at all the adapters you need for your laptop if you\'re a world traveler this means all the rows all the columns but you might not have seen two colons colon colon like that basically just means start colon and you\'re probably used to that it if you don\'t put a start or an end it\'s going to go from the start to the end and that\'s what we\'re doing in all three of these but there is actually a third parameter that you might not have noticed which is step and you can put a negative on it to make it go backwards negative one so what this is really doing is just flipping the rgb order so that\'s some numpy you you might have seen that a thousand times or you might not have seen that before so these two functions are quite useful at the beginning in the end to move the image in and out now we need to compute the style loss we\'re using something called a gram matrix yes gram matrix so it\'s essentially it\'s for an inner product space but we\'re actually using it for an outer product space so i\'ll show you what that means in a moment in inner product space in mathematics inner product space is oh a hilbert space hilbert\'s base that has ruined the career of braver youtubers than than me but nonetheless it\'s hilbert spaces we don\'t need to get into that fortunately for for this one but basically what we\'re doing here is this transformation where we\'re taking the transpose not the inverse but the transpose of a matrix and multiplying it by itself we\'ll we\'ll see why to do that i\'ll actually take that function apart it\'s kind of it\'s kind of interesting so here we are basically getting the the we\'re getting the gram matrix that part is really just the gram this is just setting it up for the gram and all the gram is is we\'re taking the features we\'re taking some sort of a a matrix we\'re transposing it and then we\'re multiplying it by itself that basically just sets up a bunch that kind of cross-pollinates the the features so that they\'re all related and now correlated to to each other we\'ll we\'ll see that in a moment and then the style loss we take these two grams we deal with the number of channels this is just so we can average and then the size of the image by the way image size i\'ll show you this up here too image size basically the author decided to just limit it to 400 which is which is fine a little bit low res you can actually make these anything that you want to because really the images are just going into vgg and vgg has its own set input size but you\'re you\'re going to have to you\'re just going to get maybe fewer details going into there to get those features it it really doesn\'t it really doesn\'t matter this is just a convenience now if your images are much higher resolution than what vgg deals with and vgg is pretty low res that\'s what that pre-process function is going to actually handle for you this is going to basically just scale it down to whatever vgg actually needed this one here actually okay so let\'s go ahead and define all of these i\'m going to let them run because i\'m not ready to rip them apart yet but we are going to rip all three of these apart and see what they do we\'ll go ahead and load vgg it\'s it\'s coming in here we are creating a outputs dictionary this is kind of interesting so when i want to know what\'s happening with something like this well if you\'re not familiar with it models dot layers i mean that\'s basically all of the the layers in that model so there\'s all your convolution layers what it is doing is going through each of those layers and taking the layer name and the layer output it is basically building a map a lookup to go from the human readable name to the actual dictionary so block one convolution is this keras tensor that\'s all that\'s happening there we\'ll need that in a moment just so that we can look them up we then create the feature extractor and this is using a keras model the input is going to be the model inputs basically from vgg so if we do model dot inputs it shows you here basically is is the input this is really not telling you too much it\'s just telling you three is rgb that\'s the batch size and then the rows and columns is essentially what is going into there the output from this is going to be a dictionary so the output is going to be not just the output layer like you normally had but it\'s going to be all those layers keyed by the layer names so this is this is a useful technique that you\'ll see sometimes when you really want to have the outputs from every layer of the neural network which is what we\'re doing they\'re using multiple layers because that gave them better renditions of the of the style because the layers closest to the input layer are going to be very concrete in terms of the image the ones further out are going to be very abstract in terms of building up features from from previous layers this comes right from the paper these are the layers that we are going to use the outputs from those to detect the style now there\'s been other papers that have done style detection so it could even look at something and say oh that\'s renaissance that\'s picasso era abstract um i\'m not an art guy so it looks it could use those this paper extended on that and tried to use it to actually replicate the style and then the layer to do content loss so detecting if it\'s still the image we\'re not just doing a pixel to pixel comparison we\'re looking at the actual features coming out of it so in in older computer vision if you\'re trying to make something i don\'t know look like a mosaic you\'d do a pixel to pixel comparison of your output in the input that\'s the old school way to do it the newer way is you have you extract those features from the convolution and you compare feature to feature and that gives you that gives you a positional and variant way so if if it\'s seen something at the top or the bottom do the scanning nature of the filters of the convolution neural network that will that\'s why they\'re doing that and then this is the the big hairy compute loss it\'s actually not that bad these are the three that initializes it and then these are the three parts of it we\'ll jump into that code in a moment i want to get it all running because i want to get the output this just brings it all together it uses gradient tape that is so that we can actually get those derivatives of it you can take the derivative of the whole thing and get the the individual weights component gradient or run that [Music] and this is the training loop let\'s go ahead and kick this off just so that it starts crunching through i\'m going to break it because i don\'t want it to actually go through we\'re using the optimizer so the initial learning rate is 100 which is which is big and the decay step so over a hundred we\'re going to decay it by a rate of 0.96 so that\'s pretty common you take the learning rate down as you go the learning rate is like a magnifying glass you\'ve got those gradients if you wanted to go completely crazy you would multiply the gradients by something like you\'re doing here and just sum them right into the weights but that might be too extreme or it might be too slow so you can change the learning rate to determine how how much of the gradient is actually going into the weight this is trial and error typically you usually want to decay it so that it as it learns more and more it becomes less intense of an update we talked about these three before we\'re loading the base image the style image and then this is the weights this is what we\'re actually training we\'re literally starting with the photographic image and training it as we go through we go through all the iterations we get the loss and the gradients we apply this is where the image actually changes we apply the gradients to it you could definitely play around with these and see how it actually adjusts those if if if you wanted smaller steps or bigger steps smaller steps will sometimes give you better better results but it takes longer and then every 100 iterations we\'re going to print something out so you can see if you\'re used to normal higher level cara\'s there\'s no model fit in here this this looks a lot i mean to me this looks a lot more like pie torch and when people complain kira\'s is horrible for research because you can\'t control the lower level details yes that\'s true but this is how you\'re kind of doing the same thing with it and this used to be a pain in the rear in tensorflow 1.0 especially before you had the pre-calculation steps on the graph but you you can really do a lot of this stuff i do feel like cara\'s has closed and tensorflow has closed a lot of those complaints but nonetheless it was it was bad enough that they have lost a lot of mind share of research papers so i i tend to i tend to work with both of them and here you can see it\'s training as training i\'m going to go ahead and stop this because i want to look at how these loss functions are actually happening so the way i tend to pick this kind of stuff apart is i run the code and watch it at each step so we\'ve got the compute loss here and i\'m going to take literally these two functions these two lines of code i should say multiple lines and i am going to take them down after the training loop and i\'m going to run them just so i can start to pick that apart and see what it\'s actually doing so we are going to create an input tensor i think everything\'s being the same okay good so that worked so let\'s see what that input tensor actually looks like what are we really doing here because if you notice the input tensor is this is essentially a batch because you\'re going to be passing three things into the model you\'re passing the base image the style reference image and the the combination image so if we look at that you can see let\'s do a dot shape you can see it\'s essentially a batch size of 3 and a 400 by 599 and then you\'ve got your rgb obviously if you let it just stream out you can see that weird vgg format where it\'s trying to span from sort of negative 127 to positive 127 or so there\'s a 128 either on the front of the tail but that is that\'s what it\'s doing then it\'s passing that into features to the feature extractor now remember the feature extractor is going to take in a vgg style input tensor and it\'s going to return a map basically or a dictionary of all of those various layers so if we do that we\'re going to get a explosion of stuff let\'s do that keys so there are essentially all that\'s that\'s the output so these are all of these individual layers if we wanted to see just one of them because we\'re going to deal with them one by one as we get into it so this is one of the layers in there so this is basically giving us a three that\'s your batch size again so those are your three that\'s the base image the style reference so we just send all three of them in one batch that\'s more efficient than calling it three times this is essentially the scan size so that\'s that square that\'s going across as you\'re doing the convolution and 64 that is the number of filters that you have on the convolution layer what do these all mean this is essentially information that gives you clues as to the features that were detected in the image by vgg so that is the first part of it we\'re getting let\'s go back up to where that was that i took that from we\'re going to initialize the loss to zero but let\'s deal first with the content loss so what this is doing is we\'re taking the layer features so we\'re we\'re getting the features from remember we have that content layer name and then we are going to get that also for the base image features and the combination features so remember that batch size zero one two that is where we\'re basically zero means the base image and the two means the combination image so that\'s where that\'s coming from and it\'s grabbing the whole thing from those colons and then we\'re going to do loss equals loss plus content image and then we\'re calling a function here called the content loss that is going to basically get calculate the actual content loss for all of these these these two features that we\'re passing in the the original image and then where we\'re currently at in our training this is essentially a root mean square you\'re you\'re squaring the combination in the base so you\'re taking the base image minus the combination image now that could be positive that could be negative so you\'ve got to do either an absolute or a square as far as that the the reason we\'re doing a square over in absolute is the the derivative is easier the absolute value the derivative is undefined i think it\'s zero so that that causes uh that causes some issues there you can google absolute value versus square in loss functions and there\'s all kinds of information on that so this is this is a pretty this is a pretty simple one in terms of what we\'re doing there and by the way the reduce this comes back to just a single a single number so the loss is being added to it remember the content weight that we had that\'s how important it is of those three numbers the ones that i set to zero to see to drop out these various objectives so that\'s that\'s basically just taking a root mean square difference a euclidean distance between the features of the original image and where we\'re currently at and the the fascinating thing here is we\'re not comparing the individual pixels of each we\'re comparing the vgg features extracted from them and that gives it so much more intelligence about what\'s going on actually in the image let\'s skip style loss for a moment because it is the most complicated of the ones that we\'re looking at and by the way if i wanted to back to content loss for a moment if i wanted to continue to pick this apart and understand really what\'s going on what i would do is continue with what i was doing here so we would get the layer features just just like that you\'d run it you\'d see your layer features which is that big we saw that before and this is what that particular one is outputting it\'s 25 by 37 so this is a higher level set of features it\'s not as high-res as before so these are like higher higher level features like maybe eyes and hair and other things that it\'s it\'s detecting put the next bit of the code in there we get the base image feature and the combination features so we can take that off if we run this you get both of those [Music] if you run this dot shape you\'ll see it\'s just extracted it that batch isn\'t on there anymore because we we\'ve pulled it out and now to actually get the loss i\'m not going to sum the loss because i don\'t have it defined but you can see basically it calling that and that is that so that loss is not a matrix or anything it is essentially a number and that is that component of it that you would then multiply by the content weight and continue to uh continue to build that up if you didn\'t want to add it to the existing loss that\'s just what the individual component is so it\'s 46. so let\'s keep ripping that part up and that\'s that\'s how i really debug into these things i just run the code a little by little by little and watch the whole thing happen now the style loss is a bit more complicated the style loss comes from across several layers we\'re getting the features but this is very similar we\'re getting the layer features just like we did up here and we\'re getting the style so this is this is important to note when we\'re doing content loss we were comparing the base to where we\'re currently at we were not considering the style it was zero and two now it\'s one and two so we\'re considering style to where we\'re at you wouldn\'t compare the style to the original because that\'s just your starting point so we\'re going to call style loss with the style features and the combination features and then we\'re just going to multiple we\'re going to use the style weight you have now why are we doing this slightly more complicated math here rather than just adding it like we did here basically because we have several layers and this is essentially averaging them so that each one takes an equal part of of the whole as we put it back together but let\'s look at how we break the style apart because i find this really really quite interesting so we\'re going to call the gram matrix on the style and the combination the gram matrix let\'s rip this apart and really understand what\'s happening here because there there\'s a fair amount happening go back down to where i was at let\'s just put it in here we\'re done with that part so we need an x because we\'re going to transpose it and to get that that x is going to be basically the the features for one of these so let\'s let\'s grab the code from what was calling it so the style loss basically we just need the features for for one of these layers it it almost does it almost doesn\'t matter which one we\'re using just for explanation purposes we care mainly about the shapes so let\'s go back down to here let\'s just grab the the combination features that we just had here so we\'re going to say x equals the combination features and i think this is going to work yeah so let\'s look at what x is because x was transposed x dot let\'s do it before and after before and after look it\'s just it\'s just flipping it around basically so what this is is 25 by 37 that\'s the dimension of this particular feature and then our layer and then that\'s how many filters we have we want to get filters to the beginning because all of those filters those are just different ways of looking those are just individual components so each filter is learning different things scanning across by a 25 by 37 box so we want to get this to the beginning as you can see there and then we\'re going to reshape it and that\'s what this two zero one means that\'s the dimensions so the the first what would have been the first one goes to there because zero\'s the first two it\'s just a set of indexes basically we\'re gonna put features there and then let\'s continue to print this out gotta run this first and then we print out the feature shape so this is reshaping it notice that 512 is still there but this got much bigger that\'s that 25 times 37 so you\'re you\'re taking the matrix and flattening it into into a vector so now we\'ve got a nice matrix this 512 by 925 and to take the gram of this what we\'re going to do is we\'re going to do this whole thing let me just put graham in there for now and then we\'ll run it and we\'ll see what the gram looks like but then we\'ll break that apart it\'s going to be a nice square matrix so 512 by 512. so this is basically those 512 this is almost like a dimension reduction a little bit not exactly it\'s more like a correlation matrix but it is it\'s essentially cross-pollinating all of those all of those features because we want to look at them together we don\'t want to look at them univariately all separately we want them combined because together all of those features represent the style of the of the image so that\'s 512 by 512 and all we\'re doing to create the gram is features that shape if we print that out i mean that\'s the by 9 24 and if you transpose it that shape then you\'ll see it there so you\'re just taking the transpose of that and then you\'re going to multiply it so matrix multiplication you can do a whole video on that there\'s tons of them out there but essentially the result these two have got to be the same the 925s so whenever i\'m looking at matrix multiplication basically these two need to be the same and then your resulting matrix is going to be that by that that\'s the quick way that i just sort of think of matrix multiplication and you\'re multiplying the matrix by its transpose which is essentially what the gram matrix is so now you\'ve got these two matrices that are all nice and cross-correlated and you can now basically calculate the loss which was here so you\'re calculating the gram matrix for the style the gram matrix for where we\'re currently at and then you\'re just going to essentially take the difference of them you\'re going to take the difference square it and sum it you see this over and over and over in machine learning it\'s basically rooting square error it\'s the it\'s the euclidean distance so your your you\'re going down one by one by one looking at each difference subtracting them well that could be positive or negative you don\'t want to penalize for one of the other so you square it now that\'s a positive number think of it like an absolute value and then the sum you\'re just adding them all up so it\'s like taking an average at that point and then you just need to divide it by the number of numbers that you would have in there and that\'s what this that\'s what this is basically doing the channels the size uh and and this gets it more this normalizes it is what this is doing that\'s essentially the size of of the whole thing so that\'s that\'s how your style loss is happening and that gives it a good indication of the style there\'s a lot of prior research as to why that that does it but basically you\'re looking at the style of the you\'re looking at the features from vgg of both of both the style image and where you\'re currently at and then if you look at this last one this is where we\'re doing the variation loss this is what makes it more fuzzy if you look at it we\'re basically taking a difference and again we\'re we\'re doing we\'re we\'re squaring it well we\'re not squaring it here it\'s it\'s not a pure square radical it\'s it\'s a 1.25 so they\'re apparently reducing the intensity the paper probably discusses that would be my guess or that might be a math i\'m not familiar with that as a general machine learning construct if anybody does on that one let me know in the comments but essentially it\'s it\'s reducing the intensity of this the squaring so it\'s almost putting a weight on it i would think but we\'re we\'re raising it to a power that gets rid of the negative and then we\'re reducing the sum and all we\'re doing here is taking the the image and we\'re and this is comparing itself this is where we\'re currently at we\'re taking a slight offset so this one starts at the beginning to just at the edge and then this one shifts it down a little bit so this this looks at neighboring pixels and sees how similar they are and reducing this causes it to get less resolution and more fuzzy so those are your three lost components and essentially we\'re just modifying the images of the pixel of the image further and further and further until you get left with something like that and that\'s basically how this works so that was a pretty low level description of how i rip code apart and truly understand what\'s going i feel like i understand really every every inch of this code at this point and i want to do some related of my own kind of not style transfer but modifications to images that i\'ll probably do more videos on in the future if that seems interesting but let me know in the comments was this too low level did you was this useful really truly seeing how you can you can break apart the code and really understand what\'s actually going with tensorflow and curas would you like to see the same thing in pi torch that\'s basically but that\'s that\'s basically it"", metadata={\'source\': \'-0bF9tEv9YU\'})]""""""']","{'https://stackoverflow.com/questions/50030026/how-to-provide-custom-gradient-in-tensorflow', 'https://stackoverflow.com/questions/52622343/tensorflow-what-gradients-needed-to-be-defined-for-custom-operation', 'https://stackoverflow.com/questions/54819947/defining-custom-gradient-as-a-class-method-in-tensorflow', 'https://stackoverflow.com/questions/52604879/how-excute-custom-gradient-with-tf-multiply', 'https://stackoverflow.com/questions/43839431/tensorflow-how-to-replace-or-modify-gradient', 'https://stackoverflow.com/questions/50203668/using-tf-custom-gradient-in-tensorflow-r1-8'}","['""""""1844.]]\n\n 4\n\nThanks! Does that mean in the custom gradient function, I need to return the same results as what tf.gradients should give, of which each elements are summed partial derivatives of dy/dx? @NathanExplosion Yes, that sounds right. I have added a snippet that (I hope) demonstrates how tf.gradients and gradient functions relate to each other. I tried tf.gradients(c[0,0], a), it will return dc[0,0]/da. But if we defined the returned gradients as the summation of partial gradients, how could it derive an individual gradient? @NathanExplosion In that case the flow goes like this. You have a slice operation that gives you a scalar, so you start the gradient computation with the scalar 1 as dc[0,0]/dc[0,0]. Then you compute dc[0,0]/dc, which is a matrix shaped like c with the gradient of c[0,0] wrt each element - so it is a matrix, grad_c, with all 0 except a 1 in the first value of the first row. Then you can get dc[0,0]/da, which is (dc[0,0]/dc)*(dc/da). We saw it ended up being grad_c * b.T, so you get a matrix the size of a where the first row is the first column of b and all other rows are 0. """"""', '""""""Also, this attached image describes the solution as expected by manually calulation\n\nIf I do not use the @tf.custom_gradient then the TensorFlow gives the desired solution as expected. My question is that how can I provide custom gradient for y=Ax? We know that dy/dx = A^T as shown in the above attachment which shows steps of calculation that matches the TensorFlow output. import tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') y=f1(A,x) # This works as desired #y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run(g)\n\nSince your function f2() has two inputs, you have to provide a gradient to flow back to each of them. The error you see:\n\nNum gradients 2 generated for op name: ""IdentityN"" [...] do not match num inputs 3\n\nis admittedly quite cryptic, though. Supposing you never want to calculate dy/dA, you can just return None, dzByDx. The code below (tested):\n\nimport tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return None, dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') #y=f1(A,x) # This works as desired y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run( g )\n\n[array([[20.], [28.]], dtype=float32)]\n\nPeter SzoldanPeter Szoldan\n\n 1\n\nSure, I\'m happy to help! :)\n\n– Peter Szoldan Apr 25, 2018 at 22:29\n\n""""""', '""""""Also, this attached image describes the solution as expected by manually calulation\n\nIf I do not use the @tf.custom_gradient then the TensorFlow gives the desired solution as expected. My question is that how can I provide custom gradient for y=Ax? We know that dy/dx = A^T as shown in the above attachment which shows steps of calculation that matches the TensorFlow output. import tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') y=f1(A,x) # This works as desired #y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run(g)\n\nSince your function f2() has two inputs, you have to provide a gradient to flow back to each of them. The error you see:\n\nNum gradients 2 generated for op name: ""IdentityN"" [...] do not match num inputs 3\n\nis admittedly quite cryptic, though. Supposing you never want to calculate dy/dA, you can just return None, dzByDx. The code below (tested):\n\nimport tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return None, dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') #y=f1(A,x) # This works as desired y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run( g )\n\n[array([[20.], [28.]], dtype=float32)]\n\nPeter SzoldanPeter Szoldan\n\n 1\n\nSure, I\'m happy to help! :)\n\n– Peter Szoldan Apr 25, 2018 at 22:29\n\n""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nDefining custom gradient as a class method in Tensorflow\n\nAsked 5 years, 4 months ago\n\nModified 5 years, 4 months ago\n\nI need to define a method to be a custom gradient as follows:\n\nclass CustGradClass: def __init__(self): pass @tf.custom_gradient def f(self,x): fx = x def grad(dy): return dy * 1 return fx, grad\n\nI am getting the following error:\n\nValueError: Attempt to convert a value (<main.CustGradClass object at 0x12ed91710>) with an unsupported type () to a Tensor. The reason is the custom gradient accepts a function f(*x) where x is a sequence of Tensors. And the first argument being passed is the object itself i.e., self. From the documentation:\n\nf: function f(*x) that returns a tuple (y, grad_fn) where: x is a sequence of Tensor inputs to the function. y is a Tensor or sequence of Tensor outputs of applying TensorFlow operations in f to x. grad_fn is a function with the signature g(*grad_ys)\n\nHow do I make it work? Do I need to inherit some python tensorflow class? I am using tf version 1.12.0 and eager mode. Mr.""""""', '""""""Also, this attached image describes the solution as expected by manually calulation\n\nIf I do not use the @tf.custom_gradient then the TensorFlow gives the desired solution as expected. My question is that how can I provide custom gradient for y=Ax? We know that dy/dx = A^T as shown in the above attachment which shows steps of calculation that matches the TensorFlow output. import tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') y=f1(A,x) # This works as desired #y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run(g)\n\nSince your function f2() has two inputs, you have to provide a gradient to flow back to each of them. The error you see:\n\nNum gradients 2 generated for op name: ""IdentityN"" [...] do not match num inputs 3\n\nis admittedly quite cryptic, though. Supposing you never want to calculate dy/dA, you can just return None, dzByDx. The code below (tested):\n\nimport tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return None, dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') #y=f1(A,x) # This works as desired y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run( g )\n\n[array([[20.], [28.]], dtype=float32)]\n\nPeter SzoldanPeter Szoldan\n\n 1\n\nSure, I\'m happy to help! :)\n\n– Peter Szoldan Apr 25, 2018 at 22:29\n\n""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nDefining custom gradient as a class method in Tensorflow\n\nAsked 5 years, 4 months ago\n\nModified 5 years, 4 months ago\n\nI need to define a method to be a custom gradient as follows:\n\nclass CustGradClass: def __init__(self): pass @tf.custom_gradient def f(self,x): fx = x def grad(dy): return dy * 1 return fx, grad\n\nI am getting the following error:\n\nValueError: Attempt to convert a value (<main.CustGradClass object at 0x12ed91710>) with an unsupported type () to a Tensor. The reason is the custom gradient accepts a function f(*x) where x is a sequence of Tensors. And the first argument being passed is the object itself i.e., self. From the documentation:\n\nf: function f(*x) that returns a tuple (y, grad_fn) where: x is a sequence of Tensor inputs to the function. y is a Tensor or sequence of Tensor outputs of applying TensorFlow operations in f to x. grad_fn is a function with the signature g(*grad_ys)\n\nHow do I make it work? Do I need to inherit some python tensorflow class? I am using tf version 1.12.0 and eager mode. Mr.""""""', '""""""Also, this attached image describes the solution as expected by manually calulation\n\nIf I do not use the @tf.custom_gradient then the TensorFlow gives the desired solution as expected. My question is that how can I provide custom gradient for y=Ax? We know that dy/dx = A^T as shown in the above attachment which shows steps of calculation that matches the TensorFlow output. import tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') y=f1(A,x) # This works as desired #y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run(g)\n\nSince your function f2() has two inputs, you have to provide a gradient to flow back to each of them. The error you see:\n\nNum gradients 2 generated for op name: ""IdentityN"" [...] do not match num inputs 3\n\nis admittedly quite cryptic, though. Supposing you never want to calculate dy/dA, you can just return None, dzByDx. The code below (tested):\n\nimport tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return None, dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') #y=f1(A,x) # This works as desired y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run( g )\n\n[array([[20.], [28.]], dtype=float32)]\n\nPeter SzoldanPeter Szoldan\n\n 1\n\nSure, I\'m happy to help! :)\n\n– Peter Szoldan Apr 25, 2018 at 22:29\n\n""""""', '""""""61. 68.]] tf.gradients(c, a)[0]: [[21. 30.] [21. 30.]] matmul_grad(c.op, tf.ones_like(c))[0]: [[21. 30.] [21. 30.]] tf.gradients(c * tf.stop_gradient(c), a)[0]: [[ 573. 816.] [1295. 1844.]] matmul_grad(c.op, c)[0]: [[ 573. 816.] [1295.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nDefining custom gradient as a class method in Tensorflow\n\nAsked 5 years, 4 months ago\n\nModified 5 years, 4 months ago\n\nI need to define a method to be a custom gradient as follows:\n\nclass CustGradClass: def __init__(self): pass @tf.custom_gradient def f(self,x): fx = x def grad(dy): return dy * 1 return fx, grad\n\nI am getting the following error:\n\nValueError: Attempt to convert a value (<main.CustGradClass object at 0x12ed91710>) with an unsupported type () to a Tensor. The reason is the custom gradient accepts a function f(*x) where x is a sequence of Tensors. And the first argument being passed is the object itself i.e., self. From the documentation:\n\nf: function f(*x) that returns a tuple (y, grad_fn) where: x is a sequence of Tensor inputs to the function. y is a Tensor or sequence of Tensor outputs of applying TensorFlow operations in f to x. grad_fn is a function with the signature g(*grad_ys)\n\nHow do I make it work? Do I need to inherit some python tensorflow class? I am using tf version 1.12.0 and eager mode. Mr.""""""', '""""""Also, this attached image describes the solution as expected by manually calulation\n\nIf I do not use the @tf.custom_gradient then the TensorFlow gives the desired solution as expected. My question is that how can I provide custom gradient for y=Ax? We know that dy/dx = A^T as shown in the above attachment which shows steps of calculation that matches the TensorFlow output. import tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') y=f1(A,x) # This works as desired #y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run(g)\n\nSince your function f2() has two inputs, you have to provide a gradient to flow back to each of them. The error you see:\n\nNum gradients 2 generated for op name: ""IdentityN"" [...] do not match num inputs 3\n\nis admittedly quite cryptic, though. Supposing you never want to calculate dy/dA, you can just return None, dzByDx. The code below (tested):\n\nimport tensorflow as tf #I want to write custom gradient for this function f1 def f1(A,x): y=tf.matmul(A,x,name=\'y\') return y #for y= Ax, the derivative is: dy/dx= transpose(A) @tf.custom_gradient def f2(A,x): y=f1(A,x) def grad(dzByDy): # dz/dy = 2y reaches here correctly. dzByDx=tf.matmul(A,dzByDy,transpose_a=True) return None, dzByDx return y,grad x= tf.constant([[1.],[0.]],name=\'x\') A= tf.constant([ [1., 2.], [3., 4.]],name=\'A\') #y=f1(A,x) # This works as desired y=f2(A,x) #This line gives Error z=tf.reduce_sum(y*y,name=\'z\') g=tf.gradients(ys=z,xs=x) with tf.Session() as sess: print sess.run( g )\n\n[array([[20.], [28.]], dtype=float32)]\n\nPeter SzoldanPeter Szoldan\n\n 1\n\nSure, I\'m happy to help! :)\n\n– Peter Szoldan Apr 25, 2018 at 22:29\n\n""""""', '""""""61. 68.]] tf.gradients(c, a)[0]: [[21. 30.] [21. 30.]] matmul_grad(c.op, tf.ones_like(c))[0]: [[21. 30.] [21. 30.]] tf.gradients(c * tf.stop_gradient(c), a)[0]: [[ 573. 816.] [1295. 1844.]] matmul_grad(c.op, c)[0]: [[ 573. 816.] [1295.""""""']"
59998335,tf.cond,example required,Constantly update tf.cond based on bool value,"<p>I am using <code>tf.cond</code> for controlling the flow of the Tensorflow graph. I went through the documentation and was able to implement <code>tf.cond</code> based branching successfully. But my concern is that while the graph is being loaded the value of the <code>bool</code> variable is checked and the branching decision is made at the initialization step itself. Any further changes in the <code>bool</code> is not tracked. Following is the MWE that better describes the problem:</p>

<pre class=""lang-py prettyprint-override""><code>def funa():
    return tf.constant(32)

def funb():
    return tf.constant(25)

foo = True
x = tf.cond(tf.convert_to_tensor(foo), lambda: funa(), lambda: funb())
for i in range(20):
    global foo
    if i &gt; 10:
        foo = False
    print(sess.run(x))    
</code></pre>

<p>This prints only <code>32</code>s. </p>

<p>I tried with <code>eager_execution</code> too with the following code:</p>

<pre class=""lang-py prettyprint-override""><code>tf.enable_eager_execution()
def funa():
    return tf.constant(32)

def funb():
    return tf.constant(21)

foo = True
x = tf.cond(tf.convert_to_tensor(foo), lambda: funa(), lambda: funb())
for i in range(20):
    if i &gt; 10:
        foo = False
    print(x)
</code></pre>

<p>Still the same result.</p>

<p>So my question is how can I write code such that one part of the graph is chosen dynamically, based on the updates to the <code>bool</code> variable (if possible)? Thanks. I am using Tensorflow v1.14.</p>
","<p>You can make a placeholder for <code>foo</code> and feed it's value while running the session. Modified code:</p>

<pre><code>import tensorflow as tf

def funa():
    return tf.constant(32)

def funb():
    return tf.constant(25)

foo = True
foo_p = tf.placeholder(tf.bool)

sess = tf.Session()

x = tf.cond(foo_p, lambda: funa(), lambda: funb())
for i in range(20):
    if i &gt; 10:
        foo = False
    print(sess.run(x, {foo_p:foo}))
</code></pre>
","<pre><code>import tensorflow as tf

def funa():
    return tf.constant(32)

def funb():
    return tf.constant(25)

foo = True
foo_p = tf.placeholder(tf.bool)

sess = tf.Session()

x = tf.cond(foo_p, lambda: funa(), lambda: funb())
for i in range(20):
    if i &gt; 10:
        foo = False
    print(sess.run(x, {foo_p:foo}))
</code></pre>","['How to use tf.cond with dynamic boolean values in TensorFlow?', 'TensorFlow v1.14: How to dynamically control graph flow with tf.cond?', 'How to update TensorFlow graph based on changing boolean variable?', 'Using tf.cond for dynamic branching in TensorFlow', 'How to make TensorFlow graph respond to variable changes during execution?', 'TensorFlow v1.14: Handling dynamic conditions in graph execution', 'How to implement dynamic control flow in TensorFlow with tf.cond?', 'Why does tf.cond not update with changing boolean values in TensorFlow?', 'How to use tf.cond with variables that change during TensorFlow session?', 'Best practices for dynamic branching in TensorFlow graphs']","['How to dynamically update the condition in tf.cond in TensorFlow?', 'How to use tf.cond with a variable that changes during execution in TensorFlow?', 'How to make tf.cond re-evaluate the condition on each run in TensorFlow?', 'How to control TensorFlow graph flow based on a variable that changes during execution?', 'How to use TensorFlow v1.14 to dynamically choose graph parts based on a changing boolean variable?']","{'https://www.youtube.com/watch?v=IzKXEbpT9Lg', 'https://www.youtube.com/watch?v=FmIcZoLmvL0', 'https://www.youtube.com/watch?v=jh4ITuOytE4'}","['""""""[Document(page_content=""[MUSIC PLAYING] SPEAKER: In this\\nvideo, I\'ll show you how you can use Autograph to\\nwrite complex, high performance TensorFlow code\\nusing normal Python. Autograph is available in\\nthe new TF2 function API, makes it easy to run TensorFlow\\ncomputations in a way that\'s efficient and portable. When you annotate a Python\\nfunction with tf.function, Autograph will automatically\\nconvert its Python code to TensorFlow graph code. The code is then\\ncompiled into a graph and executed when you\\ncall the function. Let\'s look at an example. This simple function calculates\\nthe square of a scalar input if it\'s positive. In TensorFlow 2.0, you don\'t\\nhave to use tf.cond anymore. You can just write a\\nnormal if statement, and Autograph will generate\\na tf.cond operation so that the entire\\ncomputation runs as a graph. This is the generated code\\nthat Autograph writes for you. Notice that we\'re writing\\ntrue and false functions that would normally be fed\\ninto a tf.cond statement. Instead of writing\\nthese, you can simply use Python if statements. Let\'s take a look at a\\nmore complicated example. This is a bare bones RNN cell. Note that it contains a\\ndata dependent for loop, and it also contains a data\\nindependent if statement. Autograph will only run the\\ndata dependent loop in the graph and leave the data independent\\nif statement untouched. Simply adding a\\ntf.function as a decorator still lets you call the function\\ndirectly and get results immediately. But the function\\nruns in graph mode. It prints results. And we can also time it. Now, if we remove the\\ntf.function decorator, which I\'ve preemptively done here, and\\nrun the function in eager mode, we get the same results out. However, it\'s going to be a\\nlittle bit slower because we won\'t have coalesced the entire\\nfunction into a single tf.graph op. We can time both options\\nwith tf.function in Autograph and without. You\'ll note that using\\ntf.function, which requires only a single\\nfunction decorator, is significantly faster\\nthan the eager mode version without tf.function. [MUSIC PLAYING]"", metadata={\'source\': \'jh4ITuOytE4\'})]""""""', '""""""[Document(page_content=\'SKYE WANDERMAN-MILNE: I\\\'m Skye,\\nfor those who don\\\'t know me. I\\\'ve been working on\\nControl Flow in TensorFlow for quite some time, with\\nthe help of [? Sarab ?] and many other\\nindividuals on the team. And so my goal with\\nthis talk is to tell you everything I know about\\nControl Flow that\\\'s important. Let\\\'s get started. I\\\'m going to start\\nby going over the lay of the land with Control\\nFlow in TensorFlow. So starting with what I\\\'m\\ngoing to call the Base APIs, tf dot cond and\\ntf dot while loop. So these are the\\nprimitives that are exposed in the public\\nPython API for users to access Control Flow. So you have conditional\\nexecution and loops. That\\\'s it. So you might be wondering, what\\nabout all the other Control Flow functions I know and\\nlove, like map or case? These are all built on those two\\nbase APIs, cond and while loop. They\\\'re sort of\\nwrappers around it that add useful functionality. So diving down\\ninto the stack, how are these primitives, cond and\\nwhile, actually implemented? How are they represented\\nin the graph? So in TensorFlow 1.x, we have\\nthese low-level Control Flow ops. You might have heard of them,\\nExit, Enter, Nextiteration, Switch, and Merge. We\\\'ll talk more\\nabout these in a bit. There\\\'s also an\\nalternate representation. That\\\'s what Control Flow\\nversion 2 is all about. These are the ""functional"" ops. And I put ""functional"" in\\nquotes because it\\\'s caused some confusion in the past. It\\\'s not like pure functional. In the programming sense,\\nthey\\\'re still state. But they\\\'re higher\\norder functions that take functions as input. So now, the cond branches will\\nbe represented as functions. So these sort of do the same\\nthing as the low-level ops, but the higher level\\nfunctionality is all wrapped up into a single op. Moving back up the\\nstack, you might be wondering what\\\'s going to\\nhappen with TensorFlow 2.0. If you\\\'re using Eager\\nexecution, you just write Python and you just use\\nPython Control Flow. So if statements, or loops,\\nor list comprehensions, that kind of thing. So there\\\'s no arrow connecting\\nit to this graph mode stuff. But if you use tf dot\\nfunction, maybe some people have heard of Autograph,\\nwhich is automatically included in tf dot\\nfunction, and this attempts to take your eager\\nstyle, just Python code, and convert it into new Python\\ncode that calls the TensorFlow graph APIs. So it\\\'s going to\\ntry to rewrite all that Python Control Flow, your\\nif statements and while loops, into tf dot cond and\\ntf dot while loop. So note that Autograph\\nis just dealing at this abstraction layer of\\nthe public TensorFlow API. It doesn\\\'t have to dive\\ndown into the low-level ops or anything like that. So that\\\'s kind of\\nwhere we\\\'re at. We have the 2.0 world where you\\njust write Python that maybe it can get converted into our\\npublic Graph APIs, which in turn are producing these\\nvarious operators in the graph. And one more thing. Right now, in this\\nnew implementation of Control Flow,\\nControl Flow version 2, we are still converting\\nthe functional ops back into the low-level ops. This is basically a\\nperformance optimization. I hope we don\\\'t have\\nto do it in the future. That\\\'s why it\\\'s this\\nfaded-dash arrow. So this talk, we\\\'re gonna\\nfocus on the base API and how it\\\'s implemented. I think there\\\'ll be another\\ntalk about Autographs, so hopefully they can talk\\nabout Control Flow there. Maybe there\\\'s also talk\\nabout Eager execution and the high-level APIs\\nthat are not so complicated. So leave that as an\\nexercise to the viewer. OK. So I\\\'m going to start with\\ngoing over Control Flow v1, the original\\nlow-level representation. You might be asking, why? Why do we care at all? So like I showed\\nin the diagram, we do still convert the functional\\nops to this representation. So this is basically how\\nit\\\'s executed today, always. Furthermore, this is still\\nwhat we use in TensorFlow 1.x. So all 1.x code is\\nusing Control Flow v1. Still very much alive. And I hope it provides a\\nlittle bit of motivation for why we wanted to\\nimplement Control Flow using the functional ops. So I\\\'m going to start\\nwith these low-level ops. So up here, Switch and Merge are\\nused for conditional execution, this is tf dot cond. Also in while loops to determine\\nwhether we need to keep iterating or we\\\'re done. And then Enter, Exit,\\nand Nextiteration are just used while loops\\nto manage the iterations. So let\\\'s dive in. So Switch and Merge, these\\nare for conditionals. Let\\\'s just start with Switch. The idea is you get your\\npredicate tensor in, this is a Boolean, that tells\\nyou which conditional branch you want to take. And then it has a\\nsingle data input, so [INAUDIBLE] some tensor. And it\\\'s just going to\\nforward that data input to one of its two outputs\\ndepending on the predicate. So in this picture, the\\npredicate must be false. And so the data\\\'s coming\\nout of the false output. Merge basically\\ndoes the opposite. It takes two inputs,\\nbut it only expects data from one of its inputs. And then it just\\noutputs a single output. So Switch is how you start\\nyour conditional execution, because it\\\'s going to divert\\nthat data into one branch. And then Merge brings\\nit back together into your mainline execution. It\\\'s not conditional anymore. One implementation detail\\nI\\\'m going to mention here is dead tensors. So you might think\\nthat nothing is going to come out of the\\ntrue output of the Switch, but it actually does output\\na special dead tensor, which is just like a sentinel value. Like a little tiny thing. And dead tensors flow\\nthrough the whole untaken conditional branch. And eventually, you\\\'re\\ngoing to get a dead tensor into this Merge. It just ignores it and outputs\\nwhatever data tensor it gets. So dead tensors are needed\\nfor distributed Control Flow, which I\\\'m actually not\\ngoing to cover in this talk. Because it\\\'s kind\\nof technical and I haven\\\'t found it that important\\nto know the details of it. It\\\'s covered in Yuan\\\'s paper. But I\\\'m mentioning dead\\ntensors because they do show up a lot in the execution. Like, if you look at\\nthe executor code, there\\\'s all this special\\ncase for dead tensors. This is what they\\\'re about,\\nit\\\'s for conditional execution so we can do distribution. SPEAKER 1: And retval\\nzero doesn\\\'t help any. SKYE WANDERMAN-MILNE: Oh, yeah. And that famous\\nerror message I want to put on a t-shirt, retval\\nzero does not have a value. That means you\\\'re trying\\nto read a dead tensor, or it probably\\nmeans there\\\'s a bug. OK. Moving on to the low-level\\nops we use for while loops. These manage\\niterations, basically. The concept you need to know\\nabout in execution is frames. So you have one\\nframe per execution. And this is what\\nallows the executor to keep track of\\nmultiple iterations, and allows a single op to\\nbe run multiple times as you do multiple iterations. So a frame defines a name, which\\nis for the whole while loop. And then it also has\\nan iteration number. So the Enter op, that just\\nestablishes a new frame. It means we\\\'re starting\\na new while loop. So it just forwards its input. It\\\'s like an identity,\\nexcept that output is now in this new frame. And it has an attribute\\nthat\\\'s the frame name, starts at frame 0. Exit\\\'s the opposite. It just it\\\'s like an\\nidentity, except it strips the frame from its input. So output is now not\\nin that frame anymore. And these can be stacked. So if you have a bunch of\\nEnters on a bunch of frames, you have a bunch of Exits, it\\\'ll\\npop them off one at the time. The Nextiteration\\\'s just\\nthe final piece in order to increment that\\niteration count. This might make more sense\\nwhen we put it all together, so let\\\'s do that. Starting with tf cond again. Let\\\'s just work through this. So down here, you have the\\nAPI call that we\\\'re using. So we start, we\\nhave this predicate. Note that the predicate isn\\\'t\\nactually part of the cond. It happens outside here,\\nbut then we feed it into the Switch operators. So the Switches and\\nMerges mark the boundary of the conditional\\nexecution, remember. So we\\\'ll feed this predicate\\nand then, the true branch is an Add. So we have a Switch\\nfor each input, for x and z, which is\\nthe external tensors we use in that branch. You\\\'ll note that they\\nare only being emitted from the true side of it. So if the false branch is taken,\\nnothing\\\'s connected to that. That comes out of Add, then\\nsimilarly on the other side, we\\\'re Squaring y, so we\\nhave a Switch for the y. This time, it\\\'s going to be\\nemitted from the false branch into the Square. And then, we only\\nhave one output from this cond so we\\nhave a single Merge. Either the Square or the\\nAdd, only one of those is going to actually have data,\\nand that\\\'s what will be output. So note that there is\\na Switch for each input and a Merge for each output,\\nthey don\\\'t have to match. And in this example,\\nthe two branches are using disjoint tensors. But say, we did the\\nSquare of x instead of y, then you would have\\nan edge from both the true output and the\\nfalse output, depending. Go to the Add or the Square. Let\\\'s quickly, actually,\\ngo over the while loop API, just to make\\nsure we all remember. So the first argument,\\nis a function. That\\\'s the predicate function. The second function is the body\\nthat we\\\'re going to execute. And this is where it\\\'s\\nkind of interesting. So you have some inputs, these\\nare called the loop variables, the input to the while loop. And then it\\\'s going to\\noutput updated versions of those same loop variables. So the inputs of the body\\nmatch the outputs of the body. Like, same number-type shape\\nof tensors because they\\\'re just the updated variables. SPEAKER 2: Can\\\'t the\\nshape-type [INAUDIBLE] SKYE WANDERMAN-MILNE: The\\nshape can change, you\\\'re right. Same number and types. And then the final, we\\\'d\\nprovide some initial input to start it off. So that\\\'s the 0,\\nthe final argument. And then the output\\nis going to be whatever the final value\\nof the loop variables are. And then the predicate function\\ntakes those same loop variables as input but just\\noutputs a Boolean, like, do we continue execution or not? So now we\\\'ll start\\nwith the inter-node. This, remember,\\nestablishes the new frame. We\\\'re starting a new while loop. I guess it\\\'s called L for loop. We go through a Merge now,\\nkind of reversed from the cond where you start with the Switch. Now you start with a Merge. Because it\\\'s choosing is\\nthis the initial value or is this the new, updated\\nvalue from an iteration? That feeds into the predicate. Note that the predicate\\nis inside the while loop now because it has to\\nexecute multiple times. The output goes\\ninto the Switch node to choose whether if\\nit\\\'s false, and we\\\'re going to exit the while\\nloop with that exit node. Otherwise, we go into the body,\\nwhich is an Add in this case, take the output of the body,\\nfeed it to the next iteration. Because we have to bump\\nthat frame count, remember? And then feed it\\nback into the Merge, which will forward it\\nback again and again, until we get to the Exit. So, hopefully, this\\nkind of makes sense. You can see there\\\'s\\na loop in there. That\\\'s the while loop. SPEAKER 3: For sequential\\nones, how does the Merge know to select the z or [INAUDIBLE]? Because wouldn\\\'t neither of them\\nbe dead tensors at that point? SKYE WANDERMAN-MILNE: I\\ndon\\\'t know the details of how this is implemented. But I think because\\nthe frame is different, z only is in the first frame. Because each frame\\nis conceptually like you made a\\ncopy of the body, it\\\'s going to keep track\\nof different pending counts for each node in\\nthe body, or the Merge, or the Switch. So I think that\\\'s why. OK. All right, so that\\\'s\\nall I\\\'m going to go over with Control Flow v1. It does have some advantages. It all, kind of,\\nfalls out of the fact that these low-level operators\\nare designed to naturally fit within the dataflow model,\\nbecause data graphs are dataflow graphs. So you get nice\\nfeatures like pruning, works pretty naturally,\\nbecause it\\\'s all regular nodes, sort of, for pruning. You can have parallel execution\\nof while loop iterations, which is actually pretty\\ncool, I think. Because once you add\\nin this frames logic, it kind of naturally keeps\\ntrack of all the pending counts. It runs just like a regular-- like, if you unrolled\\nthe loop and the data will flow through\\nas far as it can. Ops will be executed\\nas soon as they can. It just kind of works. However, there are\\nsome disadvantages. It\\\'s very complicated. Like, you can see that\\nthis is a bunch of nodes to express what in most\\nprogramming languages is like one line, like while. This shows up\\nespecially in gradients and nested Control Flow. You end up with all\\nthese crazy edge cases where you didn\\\'t hook\\nup the inner Merges correctly or whatever. As a result of this complexity,\\nhigher order derivatives are not implemented. This is not like a\\ndesign problem, per se. It\\\'s just it\\\'s so\\ncomplicated and there\\\'s so many edge cases no one\\nhas been able to do it, or has wanted to do it. Similarly to graph\\nconstruction being complicated, the runtime is complicated. Because you have to have\\nall this dead tensor logic, all this firm logic, and\\nit\\\'s very intricately baked into the executor. And this makes it hard\\nto read and maintain, and also, adds\\nperformance overhead. It\\\'s hard for other\\ndownstream things to analyze and make sense of. An example of this\\nis [INAUDIBLE] has been trying to do\\n[? auto ?] clustering for XLA, and so he has like\\nwhole docs written on how to handle dead\\ntensors, because they can show up anywhere. Similarly, XLA actually\\nrepresents Control Flow in a functional way\\nif in while ops. So when they consume\\nTensorFlow graphs, they have to pattern-match\\nthis crazy stuff back into just the while op that\\noriginally produced it. And especially with gradients\\nand nested Control Flow, it gets very complicated. There is a number of edge cases. This was actually one\\nof the main motivations for building Control Flow v2. Because we were fixing\\nso many bugs and how this was represented in so many\\nedge cases, that it\\\'s like, we just need a simpler\\nrepresentation. OK. So, hopefully, this\\nwill be simpler. I can fit it on\\none slide for both. [LAUGHTER] So tf dot cond, it\\\'s\\njust an if op now. You have the Boolean\\npredicate coming in. These arrows represent the\\ntype signature of the op, not individual tensors per se. So then this could be\\nany number and type of tensors coming into input. And then similarly, any number\\nof type tensor is coming out. They don\\\'t have to match. Then these represent,\\nthey\\\'re technically function attributes,\\nbut they\\\'re basically functions attached to this op\\nrepresenting the true branch and the false branch. So they\\\'re like,\\nlittle subgraphs. One thing to note that\\\'s\\nimportant with these functions is that the function\\nsignatures have to match. So the functions have the same\\ninputs and the same outputs. The inputs and\\noutputs don\\\'t have to match, what but they have to\\nmatch across the two branches. SPEAKER 4: [INAUDIBLE]\\nthe type, not values? SKYE WANDERMAN-MILNE: Yes. Sorry. Well, we\\\'re just talking\\nsignatures right now. So just type and possibly\\nshape in some cases. Yeah, it doesn\\\'t even have\\nto be implemented this way, but it is. It makes somethings\\nsimpler to think about. But keep that in mind. Similarly, tf dot while loop\\njust turns into a while op now. Now all our inputs and outputs\\nare just the loop variables. Because, remember, the predicate\\ntakes those loop variables as inputs. So you have a cond function\\nor a predicate function, takes a loop verbals as\\ninput, output, or Bool. And then the body function that\\ntakes the loop variable inputs and outputs, the updated\\nversion, which will eventually be-- the final value will be\\nupdated output from the op. So does this make sense? This picture. SPEAKER 4: One thing to clarify\\nis, in tf cond it doesn\\\'t have, actually, any concept of\\nvariables in the higher level API. So this is things we\\ncapture and we take care of making sure they match. So from the user\\\'s\\npoint of view, they don\\\'t have to\\ndo anything special. SKYE WANDERMAN-MILNE: Right. That\\\'s, kind of, like the\\nwhile op very closely matches the TensorFlow semantics. But the if op is a\\nlittle bit different. They have to match [INAUDIBLE]\\ninputs at all, because we do it through closures and API. That\\\'s like, you do\\nit within your code. So if this is good\\nfor everyone, I\\\'m going to move on to\\ngoing over gradients. I\\\'m going over how gradients\\nwork in Control Flow v2. It is somewhat general. It\\\'s much simpler to think\\nabout with the functional ops. So let\\\'s start at a high level. Just conceptually, what\\nis the gradient of a cond? It\\\'s basically,\\njust another cond. And you take the same\\npredicate, and you take the gradient of both sides. So if we took the\\nforward true branch, then we want to take the\\ngradient of the true branch on the way back. Make sense? Hopefully, this is good. While loops, a little bit\\nmore complicated, not too bad. So say we have this\\nforward while loop, you have your cond\\nand body functions. Just assume it executes end\\ntimes for now, we just know. So now the gradient, we\\nhave to execute the gradient of the body function N times. Like we just have\\nto do the reverse. Imagine an unrolled loop, we\\ndid N invocations of the body. Now we\\\'re going to\\ndo N invocations of the gradient of the body. And you pass in the grad y\\\'s\\nor cotangents or whatever. And those are your\\nloop variables. Then your predicate,\\nnow, is just this counter to make\\nsure we execute N times. So, hopefully, this makes sense. The big question is, how\\ndo we know what N is? The answer is that, at\\nleast in Control Flow v2, we just add a little counter\\nto every a while loop. That just outputs the\\ntotal number of iterations. And we don\\\'t return\\nthis to the user, but we can wire it through to\\nthe gradient when we need it. Does this make sense\\nat a high level? We\\\'re going to dive\\ninto the details. But this is concept. OK. So I\\\'m about to go into\\nmore concrete examples. And I\\\'m also going to\\ndiscuss the tricky part about gradients, which\\nis intermediate values. Basically, when you\\nhave a data dependency from the forward pass\\nto the backwards pass. So start with cond. Here is a similar diagram. I rearranged it to\\nmake it fit nicer. But one important\\nthing to notice is that now the arrows\\nare actual tensors. They\\\'re not just type\\nsignatures anymore. So the predicate is a Boolean. In this example, there\\\'s only\\none input and one output, maybe they\\\'re different\\ntypes, who knows. Doesn\\\'t matter for this example. And then you have the\\ntrue and false functions with the same types. OK. So here\\\'s the gradient function. It\\\'s just another if. This time we\\\'re dealing\\nwith the cotangents instead of the initial forward values. And we have the gradient\\nof the true function and the gradient of\\nthe false function. Looks good so far. Hopefully. If there was no\\ndata dependencies between the forward and backward\\npass, like if you\\\'re doing y equals x plus 1,\\nthis is all you need. But what if somewhere in\\nthe forward pass, let\\\'s say the true function,\\nthere\\\'s an op? And we need to use its\\noutput in the backwards pass? So this is conceptually\\nwhat we need to do. We need z in the\\ngradient function. This is a problem,\\nbecause you can\\\'t just have an edge between two\\nfunction definitions. You need to have\\ninputs and outputs. Like, they need to go-- The If ops need to be attached\\nto each other with an edge. This doesn\\\'t make\\nsense by itself. So we\\\'re, basically,\\ngoing to do just that. We\\\'re going to make\\ninputs and outputs. We\\\'re going to add\\nthem to the if op. So let\\\'s do that. So we\\\'re going to output\\nz from true function. And then similarly,\\nadd it as an output from the if op, because the if\\nop is calling true function. And then we\\\'re going to add\\nit as an input to the gradient if op. And add it as an input to\\nthe gradient true function. OK, there\\\'s still\\none problem, though. And that\\\'s that now the true\\nand false branches of both if op don\\\'t match anymore. We need them to have\\nthe same signature. So let\\\'s just add some\\ninputs and outputs. Starting on the gradient\\nside, this is fine. We can just add z as an\\ninput to the false function. It\\\'s just going to ignore\\nit, it\\\'s an unused input. But on the forward\\npass, this is a problem. Because we need to add z as an\\noutput to the false function, but we don\\\'t actually\\nhave anything to output. It\\\'s like, what is\\nthis question mark op? And it needs to be the same\\ntype, and possibly shape, if we want to keep a strong\\nshape, or a fully known shape. And we might not know\\nthe shape until runtime. So what we do? I had to think about\\nthis for a long time and came up with many\\ndifferent solutions. And I partially\\nimplemented all of them before coming up\\nwith using Optionals. Optionals are maybe types. You\\\'ve heard of that? It\\\'s a special\\nkind of tensor that can hold another tensor\\ninside of it or not. So it\\\'s just a wrapper that may\\nor may not have another tensor inside of it. And it\\\'s also a tensor. It\\\'s like a variant tensor. So the true function is\\ngoing to return an Optional with the z value inside of it. The false function is\\ngoing to return an Optional with no value inside of it. OK, great. Now they\\\'re the\\nsame type, Optional. Could have the same\\nthing inside them. In a gradient true\\nfunction, we can unwrap that Optional\\nto get the raw z value. And then the false\\nfunction still just ignores it, which\\nis great, because there\\\'s nothing inside of it. I didn\\\'t know how to draw\\nthis, but that\\\'s what we do. So all the intermediate\\nvalues that are needed by the\\ngrading computation are added as Optional\\noutputs of the forward pass. Does this make\\nsense to everyone? That\\\'s it for cond gradients. SPEAKER 3: Conceptually, what\\\'s\\nthe difference between doing this and the dead tensor stuff? SKYE WANDERMAN-MILNE: Oh. Yeah. Great question. I meant to go over that,\\nso thank you for asking. At a high level,\\nthis is just how it works in Control Flow v1. The gradient if cond\\nis another cond. You can express that\\ninto low-level ops. But the dead tensors\\nare the big difference. So v1 was, kind of, using dead\\ntensors instead of Optionals. And you would just\\nhave that edge because there\\\'s no\\nfunctions [INAUDIBLE].. You could just draw\\nthat edge between the forward and backward pass. And if it\\\'s the\\nuntaken branch, you\\\'ll have a dead tensor\\nflowing across that edge. There\\\'s none of this\\nmatching business, you just draw the edge. SPEAKER 3: The interesting\\nthing with the Optional is that it tells you in the type\\nof it that it might be that. Where in the dead tensor you\\nhad no such information around. SKYE WANDERMAN-MILNE: Right. SPEAKER 3: So someone\\nlike [INAUDIBLE] doesn\\\'t have to spend as much\\ntime reverse engineering. [INAUDIBLE] exactly what it was\\nmeant to do complicated cases. So now what tensors\\nmight be dead or not? SPEAKER 3: So this\\nis, essentially, a much more explicit way\\nof making it clear what it be done versus what might now. SKYE WANDERMAN-MILNE: It\\\'s\\nkind of like, more complicated. Like, this was actually\\nsimpler in Control Flow v2, because you\\\'re just\\nlike, draw the edge, and the executor will take care\\nof all this dead tensor stuff. Yeah, it made the whole system\\nmore complicated as a whole to support that. OK, so let\\\'s move on\\nto while gradients. So again, we\\\'re dealing,\\nnow, with concrete tensors. So input x, output y. They have the same type but\\nthey are different values. The body function--\\nnote that I used xi because it\\\'s run multiple times. And each time it\\ntakes, it might be x or it might be an\\nintermediate value and outputs the updated\\nvalue of y of i. Then I drew the\\ncond function small. And I didn\\\'t draw as\\ninputs and outputs, because they don\\\'t really matter\\nthat much for the gradient, but they\\\'re there. It does have them. So same thing for the gradient. Very similar to the\\ncond case, now we\\\'re dealing with the cotangents. Hoping this makes sense. We took the gradient of the\\nbody and we\\\'re running N times. I forgot to draw N,\\ntoo, but it\\\'s there. Same scenario. Oh, no. What are we going to do? We can\\\'t just draw this edge\\nbetween the two function definitions. So this time, we don\\\'t have to\\nworry about the matching thing anymore. Thank goodness. We\\\'ll add the input\\nto the grad body function and the\\ngrad cond function, but that\\\'s fine because\\nwe can ignore inputs. But we have a new problem,\\nwhich is that there\\\'s actually multiple values of z. Because the body\\nfunction is going to execute multiple times,\\nthere\\\'s no guarantee that this op that\\noutputs z is going to output the same value\\non every iteration. So we actually have to\\noutput all the values of z from the forward\\npass, and we don\\\'t know how many that\\nwill be until we run it and take them as input\\nto the gradient function. So we use stacks,\\notherwise known as accumulators in\\nthe code sometimes. So we\\\'re going to\\nstart with an empty-- we use tensor lists, which are\\nkind of like tensor arrays, but not stateful. You can see in these\\nlittle function signatures, we\\\'re going to start\\nwith an empty tensor list that we pass through the while. And then in the\\nforward pass, we\\\'re going to push values onto\\nthat stack, or that list. And since it\\\'s stateless,\\nyou take the list in as input and the value\\nyou want to add to it and it, conceptually, returns\\nyou a new list that has that new element added to it. Under the hood it\\ndoesn\\\'t actually have to make all\\nthese copies, I hope. Similarly in the backwards. So then we\\\'re going to\\nkeep pushing values, outputting these new lists,\\nand keep pushing to them until we get the full list\\nwith all the values in it. That\\\'s output from\\nthe while loop. Actually, I have a\\npicture for this. So I guess the point is\\nthat, in the backwards pass you just pop,\\nopposite of push, to get the value out again. And so, this is a\\nlittle bit complicated. But you start with the\\nempty list as input, now these lists are\\nactually loop variables. So the stateless tensor list\\nworks quite nicely with this, because the loop\\nvariable is going to have whatever has accumulated\\nso far as input to the body function. And it adds the\\nnew z and outputs that as the updated version. And so the final\\nlist is going to be the full list, which you pass\\ninto the gradient function. It\\\'s going to do the same\\nthing, except popping to pass, to get that raw value of z. And then finally, the list\\nshould be empty at the end. And then, since it\\\'s\\na loop variable, we end up outputting\\nan empty list, but we don\\\'t actually\\nneed that output. That\\\'s just how it works. SPEAKER 2: I have a question. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 2: Are you saying\\nthe gradient values always [INAUDIBLE]? SKYE WANDERMAN-MILNE: It\\\'s only\\nwhen you when you need them. SPEAKER 2: It\\\'s just\\nalways [INAUDIBLE].. OK. Thank you. SKYE WANDERMAN-MILNE: Yeah. That\\\'s a good question. SPEAKER 4: Now you\\ncould [INAUDIBLE] in the normal TensorFlow\\ngraph probably is able to remove them. SKYE WANDERMAN-MILNE:\\nYeah, that\\\'s the way it actually used to do. Although, that\\\'s a little\\nweird through functions so we changed it. SPEAKER 3: Another question. Does this imply that\\nin your while loop, your memory consumption\\nis, basically, linear in the number of\\nvariations you go through? SKYE WANDERMAN-MILNE: Yeah, if\\nyou have a gradient like this. That\\\'s some future work. I would love to see\\ndoing re-materialization, or check-pointing, I think\\nit\\\'s called in the literature. But we don\\\'t do that. SPEAKER 2: Can explain\\nagain, in the if, why can\\\'t you draw a line\\njust from the original-- SKYE WANDERMAN-MILNE: Oh, yeah. The blue boxes are\\nfunction definition. And then the while op is\\ngoing to call that function many times. So it\\\'s sort of like, if you\\\'re\\nwriting two functions in Python and they\\\'re not\\nnested or anything, they\\\'re just side by side. You can\\\'t take an intermediate\\nvariable from one function and use it in another one. It\\\'s going to be like, I\\ndon\\\'t know what this is. You have to output\\nit then have it as input to the other function. Or at least in TensorFlow we\\ndon\\\'t have closures or anything fancy like that. So that\\\'s how we do it. Does that make sense? SPEAKER 2: Kind of. SPEAKER 3: The value for\\na particular execution of a function of particular\\nintermediate value of a particular\\nfunction execution doesn\\\'t have a name that\\ncan be addressed in order-- And if it had a name,\\nit would greatly complicate the lifetime issues. We wouldn\\\'t be\\nable to [INAUDIBLE] intermediate\\n[INAUDIBLE] functions. SKYE WANDERMAN-MILNE:\\nOr maybe another way is that these\\nfunction definitions aren\\\'t actually in the graph. I draw them as if they are,\\nbut they\\\'re off to the side. All you see are the while ops. And then when you call the\\nfunction, then you see that. But you only see\\nit for that call. So it\\\'s like this z op in\\nhere doesn\\\'t exist out here in the main graph where this\\ngradient while op can see it, or in this other\\nfunction definition. Oh, and to compare to\\nControl Flow v1 again, same general idea. These while ops could be the\\nwhole mess of low-level ops and, due to some true while\\nloops, represent it that way. The big difference, this\\ntime, is in the stacks. They use the old resource\\nback tensor arrays, which were stateful. SPEAKER 4: We actually use the\\nresource [INAUDIBLE] stack. SKYE WANDERMAN-MILNE:\\nOh, you\\\'re right. You\\\'re right. SPEAKER 4: Separate nests. SKYE WANDERMAN-MILNE: OK, yeah. But they were\\nstateful, is the point. So they were\\nactually just inputs. They weren\\\'t outputs. And you just modify that state. One big disadvantage of\\nthis was that you couldn\\\'t take higher-order derivatives\\nbecause you would exhaust the stack once,\\nand it\\\'s stateful and you can\\\'t get\\nit back anymore. Whereas these, it\\\'s\\nthis full list. Because it\\\'s a\\nstateless thing, I can pass it to another\\nwhile op, no problem. So coming back to\\nControl Flow v2. Let\\\'s recap what\\\'s\\ngood and bad about it. So now we can take\\nhigher-order derivatives because it\\\'s very simple. The gradient code, when\\nit\\\'s looking at an if op, it doesn\\\'t know if\\nthat if op was actually the first derivative\\nof some other if op. They\\\'re are all the same. Inputs and outputs\\njust are normal. It\\\'s much easier to\\nconvert to the XLA if and while ops and\\ndownstream TPU integration. Graph construction\\nlogic, I hope is simpler. Take a look for yourself. So besides being\\neasier to maintain, this lets us give\\nbetter error messages, and hopefully there\\\'ll\\nbe fewer bugs. OK. So now assuming that we\\njust run the functional ops, even though I said\\nwe don\\\'t, assume we do. The execution could\\nbe much simpler, because we don\\\'t\\nhave dead tensors or because we use Optionals now. And we don\\\'t have frames because\\nit\\\'s managed by the while op. But the disadvantage\\nof running these ops is that they aren\\\'t as\\nperformant for a number of reasons listed there. So we could fix this\\nwith the functional ops. And it would make sense to do\\nthis because a lot of these also apply to just regular\\nfunction calls, which are kind of a big deal now. But for now, we decided to\\njust take the functional op. So right before you run it--\\nso you\\\'ve already constructed the graph, you\\\'re\\nready to run it-- we\\\'re going to convert it\\nback into the old low-level representation. So now we get rid\\nof the disadvantages because we\\\'re, hopefully,\\njust running the same thing. But we also don\\\'t get our\\nsimpler execution because we\\\'re still running the old thing. So we call this\\nlowering, because they\\\'re sort of lowering to this\\nmore low-level form. This was, basically,\\na staging trick so that we can do all the\\ngraph construction stuff, which is taking quite some time,\\nwithout having to worry about the execution as much. Because there were\\nstill some issues. It\\\'s very similar to\\nfunction in-lining. An if op and a while op are kind\\nof very fancy function calls. And so this is how\\nyou in-line them, with these low-level\\nlevel dataflow operators. And so it runs with in-lining\\nbefore anything else happens, and this is so we\\ncan take advantage of any downstream optimization\\nor placement or whatever. In the case of\\nControl Flow, we want it to work the same as it did\\nbefore in Control Flow v1. And I think Eugene is\\nfixing this all up, so this is actually true now. As of, like, last week. SPEAKER 5: So this converting\\nwill be removed eventually? SKYE WANDERMAN-MILNE: I\\nwould love to see it removed. Oh, yeah. So right now we\\nin-line everything, including function calls,\\nbecause similar story for functions, it makes\\na lot of things easier. I hope that we don\\\'t\\ndepend on this forever. That we sort of\\ndo try to make it so function calls are just\\nas performant and as good not in-line. Because it\\\'s the same\\nfor Control Flow. If we always assume\\neverything\\\'s in-line, then we\\\'re never going\\nto be able to get our simpler execution and\\njust run the functional ops. Because they\\\'re very, very\\nsimilar function calls, they have the same problems. So if you fix it\\nfor functions it\\\'s not a huge step to, then,\\nfix it for Control Flow. Where are we at with\\nControl Flow v2? It\\\'s still under development. There\\\'s bugs and features\\nthat need to be implemented. But it\\\'s basically on in tf 2.0,\\nif you\\\'re using pure 2.0 code. So remember Eager, doing his\\nown thing, just use Python. And then, Control Flow v2 is\\nalways on in tf dot functions. There\\\'s no way to\\nget old Control Flow. If you want to run new Control\\nFlow in either 1.x code or you\\\'re using a\\ncompact dot v1 dot graph, those still use the\\nold Control Flow, you can use this environment\\nvariable to turn it on. So now when people ping\\nme in and are like, I have this horrible\\nControl Flow bug. I\\\'m like, try the\\nenvironment variable. And sometimes it fixes it. Or sometimes it at least\\ngives an easier to debug error message. Unfortunately, I\\nwould love to have realized the glorious future,\\nwhere it\\\'s all new Control Flow. Old Control Flow doesn\\\'t exist. We can delete that code. I don\\\'t know if it makes\\nsense to do the work to make it so we can\\nturn it on in 1.x code because there\\\'s a\\nfew big blockers. Namely, functions don\\\'t\\nwork with ref variables. And so by extension,\\nthese functional ops don\\\'t work with ref variables. That would be a lot\\nof work to implement. And the question that you asked\\nabout how we add the gradient outputs when you\\nrequest a gradient, only when they\\\'re needed,\\nwhich it will only know after you build\\nthe gradient graph and see what incoming\\nedges you have. This actually breaks sessions. Sessions do not like it when you\\nadd inputs and outputs to ops. And will potentially make\\nyour session unusable. You\\\'ll have to\\nmake a new session. So in 2.0 we don\\\'t\\nhave sessions, great. But in 1.x we definitely\\nhave sessions. Another little note. In addition to Control\\nFlow V2, there\\\'s a new effort to\\nre-implement tensor arrays. And I sort of hinted\\nat this by incorrectly stating the old tensor array as\\nstacks but it\\\'s the same idea. Tensor arrays were these\\nresource back stateful things. Now we\\\'re going to\\nmake tensor arrays. It\\\'s still the same\\nAPI, so nothing should change for the\\nuser, but under the hood, we\\\'re going to use immutable\\ntensor lists, which are variants instead of resources. And so you get\\nhigher-order derivatives, it\\\'s easier to reason\\nabout something that\\\'s dataflow style instead\\nof stateful in our dataflow graphs. It\\\'s nicer. And then in particular, an\\narea of active development is that we do need to make these\\nnew tensor arrays work in XLA. So this is kind of annoying,\\nbecause we\\\'ve kept saying, oh, the new Control\\nFlow [INAUDIBLE],, it\\\'s going to make XLA so easy. It\\\'s just going to work. But we do have to\\nimplement this one thing. [? Sarab\\\'s ?] working on this. I think it\\\'s almost there. We\\\'ll see. SPEAKER 4: Getting there. Question. So is it true that\\nTensorFlow [INAUDIBLE] where you only use\\nthe [INAUDIBLE]?? SKYE WANDERMAN-MILNE: Yes. Yeah, so it\\\'s\\nmaybe theoretically different from Control Flow,\\nbecause it\\\'s tensor arrays. But tensor arrays are so\\ntightly linked to Control Flow. And we only support\\nthe new tensor arrays in new Control Flow\\nbecause we don\\\'t want to deal with\\nthe stateful thing. SPEAKER 2: You don\\\'t know\\nwhat tensor array is. Usually when you do\\nControl Flow and it models, you have something like an\\nRNN, that computes something for [INAUDIBLE]. And you often want to\\ntake a single tensor that represents the results of\\nall time steps together. And tensor array is\\nthe data structure that lets you do that. SKYE WANDERMAN-MILNE: Yeah. I don\\\'t think there\\\'s too\\nmuch use for tensor array outside of while loops,\\nI\\\'m sure I would stand corrected if I looked into it. So these are some details\\non what\\\'s going on here. That\\\'s all I have. I\\\'m going to end on\\nthis slide so you can look at the beautiful picture. And I guess we have plenty\\nof time for questions. So what was your Control\\nFlow v1 question? SPEAKER 3: How does it work\\nwith the branches [INAUDIBLE]?? SKYE WANDERMAN-MILNE:\\nOh, good question. So this is when you\\nhave a tf dot cond, remember just takes lambdas and\\ncaptures everything by closure. So you could just not\\nclose over anything. Like, return one or two. SPEAKER 1: Or like, it\\\'s a\\nsourceless op like [INAUDIBLE].. SKYE WANDERMAN-MILNE: Yeah. It uses the predicate. It wires together all the\\ndataflow using the predicate. And in particular,\\nyou can also have a cond that doesn\\\'t\\nreturn anything, it just has side effects. And I think in\\nControl Flow v1, it will return to predicate value. I thinl it does that\\nin Control Flow v2 because I wanted to test\\nthe pass in both cases. But it\\\'s a little arbitrary. SPEAKER 4: So the\\nway to do this is you have ops that have a control\\ndependency on something that depends on the Switch. Because [INAUDIBLE] propagates\\nthrough [INAUDIBLE] as well. So this is how it\\\'s actually\\nimplemented in Control Flow v1. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 1: Well, it can\\\'t\\ndepend on the Switch. It has to depend\\non like one output. SPEAKER 4: Yeah. So you have a Switch\\nof the predicate. And on each side\\nof that [INAUDIBLE] that takes the predicate twice. Then you have an identity\\nop on each branch. And every op that\\\'s inside\\none of the Switch branches has a control dependency on\\nthat corresponding identity. So because, then, this\\npropagates through control edges, it makes things work. SPEAKER 1: That makes sense. SKYE WANDERMAN-MILNE: That\\\'s a\\npart of why we were able to do [INAUDIBLE]. There\\\'s a lot of storage. Yeah? SPEAKER 2: So when you\\ndescribed the graph modification for taking gradients of if, when\\ndoes this modification happen? Does it happen when\\nyou construct the if op or when you\\\'re taking gradients? SKYE WANDERMAN-MILNE:\\nGreat question. It happens when you\\ntake the gradient. SPEAKER 2: The gradient. So for those-- SPEAKER 3: Does that depend\\non whether you\\\'re using tape gradients or tf dot gradients? SKYE WANDERMAN-MILNE: No. SPEAKER 2: We could\\n[INAUDIBLE] early if you\\\'re doing tape gradients. We currently do not. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 4: So that means for\\nthose function arguments, or functional attributes, you\\ncannot draw lines between two, but you can modify one. SKYE WANDERMAN-MILNE:\\nYeah, you can modify them to add\\ninputs and outputs, which you\\\'re not really supposed\\nto do with sessions. But we do it. The reason we do it when you\\nrequest a gradient is that, a, if you never take\\nthe gradient we don\\\'t want to add extra stuff,\\nalthough it could get pruned. SPEAKER 4: You want\\nto look [INAUDIBLE].. SKYE WANDERMAN-MILNE: It makes\\nyour graph look nice at least, to not have all\\nthe extra outputs. And also, you don\\\'t\\nknow which intermediates you\\\'re going to need until\\nyou build the gradient graph. So if we did it\\nwith the tape, we could say, oh,\\npresumably because you\\\'re running with a\\ntape, you are going to want to take the\\ngradient at some point. SPEAKER 4: We can\\nactually ask the tape if the tape is\\ngoing to integrate into one of those outputs. We can\\\'t answer their questions. SKYE WANDERMAN-MILNE: So\\nthen we could proactively create the gradient\\nat the same time as you create the forward pass\\nand add the outputs there, all at once. But since we have\\nthe two code pass, we just do it the same\\nin a two code pass. Because with tf\\ndoc gradients, you have no idea if\\nyou\\\'re gonna call it or not until it happens. That\\\'s a good question. Functions work the same\\nway too, because they have like a similar-- if you just have\\na function call, you\\\'ll have the same\\nthing with intermediates and you\\\'ll have to add\\ninputs and outputs. So we\\\'re back in\\nControl Flow v1, right? This is what it looks\\nlike, this stuff. What if you want to run your\\nbranch functions or your body or whatever on multiple devices? So I don\\\'t totally\\nunderstand this myself. It\\\'s going to be brief. Cond, it\\\'s pretty simple. You just do it like\\nnormal, I guess. You add the sends and\\nreceives, dead tensors can flow through these. So this is why you\\nneed the dead tensors. Because for the untaken\\nbranch, you basically need to tell other\\ndevice, this isn\\\'t taken. Stop waiting for inputs on this. So you can shut\\ndown or whatever. SPEAKER 4: Another,\\nwe could have chosen to send the predicate instead. But was a simple modification\\nof the existing TensorFlow that had a huge cost. If I had chosen to\\nsend the predicate, we wouldn\\\'t need so much of\\nthat tensor propagation and all the bugs associated with it. SKYE WANDERMAN-MILNE: Dead\\ntensors are kind of crazy. In really big graphs, you will\\nspend time just propagating all the dead tensors, and\\nsend data across the network, or whatever. It\\\'s one of those things. We added all this\\nstuff and now this is very conceptually simple. You just add the\\nsend and receive. It just works. Can we do the same\\nthing for while loops? Just add the sends and receives. This time it\\\'s going\\nto be in a loop. Seems fine. It\\\'s not fine. The problem is that\\nthis device doesn\\\'t know that this op is supposed\\nto be run multiple times. I guess we didn\\\'t forward\\nthe frame information. SPEAKER 3: It doesn\\\'t know\\nhow many times it should run. SKYE WANDERMAN-MILNE:\\nWell, it\\\'s going to run once or like 0\\ntimes, then you\\\'ll have-- or maybe the dead\\ntensor will work. But if you run it\\nonce, it\\\'s just going to immediately shut down\\nbecause it thinks that it has to run once, like a regular op. So the solution, you, basically,\\nbuild a tiny little while loop on the other device. And so you can see\\nthere\\\'s no real data going through this computation. But it\\\'s just used through\\ncarefully placed control dependencies to drive this\\nop as many times as you need. So this is like a whole\\nlittle while loop built just to run this op n times. This while loop is indirectly\\ndriven by the real one. SPEAKER 3: It\\\'s driven\\nby the predicate. SKYE WANDERMAN-MILNE: Yeah. Right, exactly. You can see that this guy\\ndoes not have a predicate. SPEAKER 4: So we\\\'re essentially\\nsending the predicate around for the while loop case but\\nnot doing it for the cond case. SKYE WANDERMAN-MILNE: And we\\nbuild a little tiny while loop to actually use that predicate. SPEAKER 4: And essentially, if\\nwe wanted to partition into two ops, we would have\\nto build something like this for both the\\ncond and [INAUDIBLE].. Or it would at least\\nlook simpler, I think. SPEAKER 1: Well, the control\\ncould be centralized. SPEAKER 4: Well, you\\ncould send the predicate to other places, yes. SPEAKER 1: [INAUDIBLE]\\nexecution, yeah. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 4: You would need a\\nwhile loop [INAUDIBLE] device, but the predicate computation\\nonly needs to happen once. SKYE WANDERMAN-MILNE: Do we? Because we have\\nmulti-device functions, you could just call that\\nmultiple times, right? SPEAKER 4: Yeah. I mean, sure. SKYE WANDERMAN-MILNE: You won\\\'t\\nget like parallel iterations and everything. So that\\\'s distribution. SPEAKER 6: I\\\'m glad\\nyou speak clear. SPEAKER 3: How did the\\nintermediate value sharing work with distribution [INAUDIBLE]? SPEAKER 1: It\\nworks the same way, except there\\\'s a\\nlot more arrows. [LAUGHTER] Conceptually, they do not\\ninterfere with [INAUDIBLE].. But you end up with the diagram\\nto show both at the same time would be overwhelming. SKYE WANDERMAN-MILNE: Yeah,\\nthat\\\'s a good point, though. I feel like it\\\'s not\\nimmediately obvious that it works with all\\nthe dead tensors and stuff between the forward\\nand backwards pass. Because now you\\\'re like\\nmixing [INAUDIBLE].. But it does somehow work. SPEAKER 4: You need to\\nthink of the intermediates as happening before you\\ndo the partitioning, and then you can see\\nwhat should happen. SKYE WANDERMAN-MILNE: I\\\'ll\\ngo back to my pretty picture. Well, thanks, everyone. SPEAKER 6: Thank you. [APPLAUSE]\', metadata={\'source\': \'IzKXEbpT9Lg\'})]""""""', '""""""[Document(page_content=""Please Subscribe and you can download this code from description below dot when working with tensor flow you might encounter a common error message that says type error using a tf. tensor as a python buol is not allowed this error occurs when you try to use a tensorflow tensor as a python Boolean value in a context where tensorflow expects a tensorflow operation or tensor in this tutorial we will explain why this error occurs and provide code examples to help you understand how to resolve it the error message using a tf. tensor as a python bull is not allowed indicates that you are trying to use a tensorflow tensor as a python Boolean value in a way that tensorflow doesn\'t support tensor flow is designed to build computational graphs and execute operations on tensors efficiently it doesn\'t evaluate tensors in the same way as python does when when you use a tensorflow tensor in a python context that expects a Boolean value tensorflow doesn\'t know how to handle it conditionals in Python control flow the error often occurs when you use a tensor flow tensor as a condition in Python control flow statements like if or while tensor flow operations involving tensors should be executed within tensor flows computational graph not in Python control flow indexing with tensors trying to use a tensorflow tensor as an index for a python list or numpy array can also trigger this error tensorflow tensors are not valid index values in Python let\'s look at an example that triggers the using a tf. tensor as a python buol is not allowed error in this example we created a tensorflow tensor X and then we attempted to use it as a condition in an if statement this will result in the type error to resolve the using a tf. tensor as a python bu is not AOW error you should ensure that you use tensorflow tensors within tensor flow\'s computational graph here are some ways to do that the using a tf. tensor as a python bu is not allowed error is a common issue when working with tensor flow to resolve this error make sure you use tensor flow tensors within tensor flows computation graph and use tensor flow operations for conditional logic Additionally you can enable eager execution mode when needed or convert tensors to number Pi arrays using numpy if you are working in eager mode chat GPT that"", metadata={\'source\': \'FmIcZoLmvL0\'})]""""""']","{'https://stackoverflow.com/questions/37063952/confused-by-the-behavior-of-tf-cond', 'https://stackoverflow.com/questions/35833011/how-to-add-if-condition-in-a-tensorflow-graph'}","['""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nHow to add if condition in a TensorFlow graph? Asked 8 years, 5 months ago\n\nModified 5 years, 1 month ago\n\nLet\'s say I have following code:\n\nx = tf.placeholder(""float32"", shape=[None, ins_size**2*3], name = ""x_input"") condition = tf.placeholder(""int32"", shape=[1, 1], name = ""condition"") W = tf.Variable(tf.zeros([ins_size**2*3,label_option]), name = ""weights"") b = tf.Variable(tf.zeros([label_option]), name = ""bias"") if condition > 0: y = tf.nn.softmax(tf.matmul(x, W) + b) else: y = tf.nn.softmax(tf.matmul(x, W) - b)\n\nWould the if statement work in the calculation (I do not think so)? If not, how can I add an if statement into the TensorFlow calculation graph? You\'re correct that the if statement doesn\'t work here, because the condition is evaluated at graph construction time, whereas presumably you want the condition to depend on the value fed to the placeholder at runtime. (In fact, it will always take the first branch, because condition > 0 evaluates to a Tensor, which is ""truthy"" in Python.)\n\nTo support conditional control flow, TensorFlow provides the tf.cond() operator, which evaluates one of two branches, depending on a boolean condition. To show you how to use it, I\'ll rewrite your program so that condition is a scalar tf.int32 value for simplicity:\n\nx = tf.placeholder(tf.float32, shape=[None, ins_size**2*3], name=""x_input"") condition = tf.placeholder(tf.int32, shape=[], name=""condition"") W = tf.Variable(tf.zeros([ins_size**2 * 3, label_option]), name=""weights"") b = tf.Variable(tf.zeros([label_option]), name=""bias"") y = tf.cond(condition > 0, lambda: tf.matmul(x, W) + b, lambda: tf.matmul(x, W) - b)\n\n\n\n 4\n\n@mrry Are both branches executed by default ? I have tf.cond(c, lambda x: train_op1, lambda x: train_op2) and both train_ops are executed at each execution of cond independently of the value of c. Am I doing something wrong? @PiotrDabkowski This is a sometimes surprising behavior of tf.cond(), which is touched upon in the docs. In short, you need to create the ops that you want to run conditionally inside the respective lambdas. Everything that you create outside the lambdas but refer to in either branch will execute in both cases. @mrry Wow, that\'s rather unexpected :) Thanks for the answer, defining ops inside functions solved the problem. Is the condition/( application of the logic) element-wise? TF 2.0 introduces a feature called AutoGraph which lets you JIT compile python code into Graph executions. This means you can use python control flow statements (yes, this includes if statements). From the docs,\n\nAutoGraph supports common Python statements like while, for, if, break, continue and return, with support for nesting. That means you can use Tensor expressions in the condition of while and if statements, or iterate over a Tensor in a for loop. You will need to define a function implementing your logic and annotate it with tf.function. Here is a modified example from the documentation:\n\nimport tensorflow as tf @tf.function def sum_even(items): s = 0 for c in items: if tf.equal(c % 2, 0): s += c return s sum_even(tf.constant([10, 12, 15, 20])) # <tf.Tensor: id=1146, shape=(), dtype=int32, numpy=42>\n\n 2\n\nWhy are you using tf.equal()? Shouldn\'t you be able to use == and let AutoGraph compile it automatically?""""""']"
70747499,tf.map_fn,example required,Using tf.map_fn when the function has multiple outputs,"<p>I can easily use tf.map_fn when the function has one output:</p>
<pre><code>import tensorflow as tf
tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]])

def my_fun(x):
    return x[0]

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<p><strong>output:</strong></p>
<pre><code>tf.Tensor([1. 4.], shape=(2,), dtype=float32)
</code></pre>
<p>But, when the function has two outputs:</p>
<pre><code>def my_fun(x):
    return [x[0],x[1]]

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<p>I get an error. Not sure what is going on. I read the information about tf.map_fn in here <a href=""https://www.tensorflow.org/api_docs/python/tf/map_fn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/map_fn</a>, but not sure how to fix this:</p>
<p>map_fn also supports functions with multi-arity inputs and outputs:</p>
<p><em>If elems is a tuple (or nested structure) of tensors, then those tensors must all have the same outer-dimension size (num_elems); and fn is used to transform each tuple (or structure) of corresponding slices from elems. E.g., if elems is a tuple (t1, t2, t3), then fn is used to transform each tuple of slices (t1[i], t2[i], t3[i]) (where 0 &lt;= i &lt; num_elems).
If fn returns a tuple (or nested structure) of tensors, then the result is formed by stacking corresponding elements from those structures.</em></p>
<p><strong>Output:</strong></p>
<pre><code>~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\util\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites)
    317     _pywrap_tensorflow.AssertSameStructure(nest1, nest2, check_types,
--&gt; 318                                            expand_composites)
    319   except (ValueError, TypeError) as e:

ValueError: The two structures don't have the same nested structure.

First structure: type=DType str=&lt;dtype: 'float32'&gt;

Second structure: type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]

More specifically: Substructure &quot;type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]&quot; is a sequence, while substructure &quot;type=DType str=&lt;dtype: 'float32'&gt;&quot; is not

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
&lt;ipython-input-36-5b11c7fef461&gt; in &lt;module&gt;
      5     return [x[0],x[1]]
      6 
----&gt; 7 print(tf.map_fn(my_fun,tensaki))

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)
    266         back_prop=back_prop,
    267         swap_memory=swap_memory,
--&gt; 268         maximum_iterations=n)
    269     results_flat = [r.stack() for r in r_a]
    270 

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)
   2712                                               list(loop_vars))
   2713       while cond(*loop_vars):
-&gt; 2714         loop_vars = body(*loop_vars)
   2715         if try_to_pack and not isinstance(loop_vars, (list, _basetuple)):
   2716           packed = True

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\control_flow_ops.py in &lt;lambda&gt;(i, lv)
   2703         cond = lambda i, lv: (  # pylint: disable=g-long-lambda
   2704             math_ops.logical_and(i &lt; maximum_iterations, orig_cond(*lv)))
-&gt; 2705         body = lambda i, lv: (i + 1, orig_body(*lv))
   2706       try_to_pack = False
   2707 

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\map_fn.py in compute(i, tas)
    256       packed_values = input_pack([elem_ta.read(i) for elem_ta in elems_ta])
    257       packed_fn_values = fn(packed_values)
--&gt; 258       nest.assert_same_structure(dtype or elems, packed_fn_values)
    259       flat_fn_values = output_flatten(packed_fn_values)
    260       tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\util\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites)
    323                   &quot;Entire first structure:\n%s\n&quot;
    324                   &quot;Entire second structure:\n%s&quot;
--&gt; 325                   % (str(e), str1, str2))
    326 
    327 

ValueError: The two structures don't have the same nested structure.

First structure: type=DType str=&lt;dtype: 'float32'&gt;

Second structure: type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]

More specifically: Substructure &quot;type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]&quot; is a sequence, while substructure &quot;type=DType str=&lt;dtype: 'float32'&gt;&quot; is not
Entire first structure:
.
Entire second structure:
[., .]```
</code></pre>
","<p>You should make sure you are returning a tensor. Maybe concatenate or stack the list of values:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]])

def my_fun(x):
    x = tf.stack([x[0], x[1]], axis=0)
    return x

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<pre><code>tf.Tensor(
[[1. 2.]
 [4. 5.]], shape=(2, 2), dtype=float32)
</code></pre>
<p>Of course, it all depends on the output you are expecting.</p>
","<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]])

def my_fun(x):
    x = tf.stack([x[0], x[1]], axis=0)
    return x

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<pre><code>tf.Tensor(
[[1. 2.]
 [4. 5.]], shape=(2, 2), dtype=float32)
</code></pre>","['How to use tf.map_fn with functions that return multiple outputs?', 'Handling multiple outputs in tf.map_fn in TensorFlow', 'Examples of tf.map_fn with multi-arity outputs', 'Common errors and solutions when using tf.map_fn with multiple return values', 'TensorFlow tf.map_fn function with nested structures']","['How to use tf.map_fn with a function that returns multiple outputs?', 'Handling multiple outputs in tf.map_fn in TensorFlow', 'Example of tf.map_fn with a function returning a list of tensors', 'How to structure the output of a function used in tf.map_fn when it returns multiple values?', 'Common errors and solutions when using tf.map_fn with multiple outputs']",{'https://www.youtube.com/watch?v=jipSAXT2E_I'},"['""""""[Document(page_content=""[Music] all right guys we\'re back with another technical question I\'ll be going through the question the answer and I\'m hoping just like me you stay a little bit crazy to get that answer all the way through guys let\'s get [Music] started [Music] [Music] [Music] [Music] [Music] n [Music] and that\'s it guys I hope that video helped find the resolution you\'re looking for if it did please I\'d appreciate it if you could hit subscribe until the next time you need more technical help I hope you have a good one cheers"", metadata={\'source\': \'jipSAXT2E_I\'})]""""""']","{'https://stackoverflow.com/questions/56663912/how-can-i-apply-tf-map-fn-using-multiple-inputs-in-tensorflow', 'https://stackoverflow.com/questions/70747499/using-tf-map-fn-when-the-function-has-multiple-outputs', 'https://stackoverflow.com/questions/42892347/can-i-apply-tf-map-fn-to-multiple-inputs-outputs', 'https://stackoverflow.com/questions/64508203/i-dont-understand-map-fn-with-two-inputs'}","['""""""Can I apply tf.map_fn(...) to multiple inputs/outputs? Asked 6 years, 11 months ago\n\nModified 3 months ago\n\na = tf.constant([[1,2,3],[4,5,6]]) b = tf.constant([True, False], dtype=tf.bool) a.eval() array([[1, 2, 3], [4, 5, 6]], dtype=int32) b.eval() array([ True, False], dtype=bool)\n\nI want to apply a functions to the inputs above, a, and b using tf.map_fn. It will input both [1,2,3], and True and output similar values. Let\'s say out function is simply the identity: lambda(x,y): x,y so, given an input of [1,2,3], True, it will output those identical tensors. I know how to use tf.map_fn(...) with one variable, but not with two. And in this case I have mixed data types (int32 and bool) so I can\'t simply concatenate the tensors and split them after the call. Can I use tf.map_fn(...) with multiple inputs/outputs of different data types? David ParksDavid Parks\n\n\n\nFigured it out. You have to define the data types for each tensor in dtype for each of the different tensors, then you can pass the tensors as a tuple, your map function receives a tuple of inputs, and map_fn returns back back a tuple. a = tf.constant([[1,2,3],[4,5,6]]) b = tf.constant([True, False], dtype=tf.bool) c = tf.map_fn(lambda x: (x[0], x[1]), (a,b), dtype=(tf.int32, tf.bool)) c[0].eval() array([[1, 2, 3], [4, 5, 6]], dtype=int32) c[1].eval() array([ True, False], dtype=bool)\n\nDavid ParksDavid Parks\n\n 3\n\nBe warned that if you use this the processing will be done in CPU, not on the GPU. This can be especially detrimental to speed when training on a GPU.""""""', '""""""Using tf.map_fn when the function has multiple outputs\n\nAsked 2 years, 3 months ago\n\nModified 2 years, 3 months ago\n\nI can easily use tf.map_fn when the function has one output:\n\nimport tensorflow as tf tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]]) def my_fun(x): return x[0] print(tf.map_fn(my_fun,tensaki))\n\ntf.Tensor([1. 4.], shape=(2,), dtype=float32)\n\nBut, when the function has two outputs:\n\ndef my_fun(x): return [x[0],x[1]] print(tf.map_fn(my_fun,tensaki))\n\nI get an error. Not sure what is going on. I read the information about tf.map_fn in here https://www.tensorflow.org/api_docs/python/tf/map_fn, but not sure how to fix this:\n\nmap_fn also supports functions with multi-arity inputs and outputs:\n\nIf elems is a tuple (or nested structure) of tensors, then those tensors must all have the same outer-dimension size (num_elems); and fn is used to transform each tuple (or structure) of corresponding slices from elems. E.g., if elems is a tuple (t1, t2, t3), then fn is used to transform each tuple of slices (t1[i], t2[i], t3[i]) (where 0 <= i < num_elems). If fn returns a tuple (or nested structure) of tensors, then the result is formed by stacking corresponding elements from those structures. ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites) 317 _pywrap_tensorflow.AssertSameStructure(nest1, nest2, check_types, --> 318 expand_composites) 319 except (ValueError, TypeError) as e: ValueError: The two structures don\'t have the same nested structure. First structure: type=DType str=<dtype: \'float32\'> Second structure: type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>] More specifically: Substructure ""type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>]"" is a sequence, while substructure ""type=DType str=<dtype: \'float32\'>"" is not During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) <ipython-input-36-5b11c7fef461> in <module> 5 return [x[0],x[1]] 6 ----> 7 print(tf.map_fn(my_fun,tensaki)) ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name) 266 back_prop=back_prop, 267 swap_memory=swap_memory, --> 268 maximum_iterations=n) 269 results_flat = [r.stack() for r in r_a] 270 ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure) 2712 list(loop_vars)) 2713 while cond(*loop_vars): -> 2714 loop_vars = body(*loop_vars) 2715 if try_to_pack and not isinstance(loop_vars, (list, _basetuple)): 2716 packed = True ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in <lambda>(i, lv) 2703 cond = lambda i, lv: ( # pylint: disable=g-long-lambda 2704 math_ops.logical_and(i < maximum_iterations, orig_cond(*lv))) -> 2705 body = lambda i, lv: (i + 1, orig_body(*lv)) 2706 try_to_pack = False 2707 ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in compute(i, tas) 256 packed_values = input_pack([elem_ta.read(i) for elem_ta in elems_ta]) 257 packed_fn_values = fn(packed_values) --> 258 nest.assert_same_structure(dtype or elems, packed_fn_values) 259 flat_fn_values = output_flatten(packed_fn_values) 260 tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)] ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites) 323 ""Entire first structure:\\n%s\\n"" 324 ""Entire second structure:\\n%s"" --> 325 % (str(e), str1, str2)) 326 327 ValueError: The two structures don\'t have the same nested structure. First structure: type=DType str=<dtype: \'float32\'> Second structure: type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>] More specifically: Substructure ""type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>]"" is a sequence, while substructure ""type=DType str=<dtype: \'float32\'>"" is not Entire first structure: . Entire second structure: [., .]```\n\nYou should make sure you are returning a tensor. Maybe concatenate or stack the list of values:\n\nimport tensorflow as tf tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]]) def my_fun(x): x = tf.stack([x[0], x[1]], axis=0) return x print(tf.map_fn(my_fun,tensaki))\n\ntf.Tensor( [[1. 2.] [4.""""""', '""""""Using tf.map_fn when the function has multiple outputs\n\nAsked 2 years, 3 months ago\n\nModified 2 years, 3 months ago\n\nI can easily use tf.map_fn when the function has one output:\n\nimport tensorflow as tf tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]]) def my_fun(x): return x[0] print(tf.map_fn(my_fun,tensaki))\n\ntf.Tensor([1. 4.], shape=(2,), dtype=float32)\n\nBut, when the function has two outputs:\n\ndef my_fun(x): return [x[0],x[1]] print(tf.map_fn(my_fun,tensaki))\n\nI get an error. Not sure what is going on. I read the information about tf.map_fn in here https://www.tensorflow.org/api_docs/python/tf/map_fn, but not sure how to fix this:\n\nmap_fn also supports functions with multi-arity inputs and outputs:\n\nIf elems is a tuple (or nested structure) of tensors, then those tensors must all have the same outer-dimension size (num_elems); and fn is used to transform each tuple (or structure) of corresponding slices from elems. E.g., if elems is a tuple (t1, t2, t3), then fn is used to transform each tuple of slices (t1[i], t2[i], t3[i]) (where 0 <= i < num_elems). If fn returns a tuple (or nested structure) of tensors, then the result is formed by stacking corresponding elements from those structures. ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites) 317 _pywrap_tensorflow.AssertSameStructure(nest1, nest2, check_types, --> 318 expand_composites) 319 except (ValueError, TypeError) as e: ValueError: The two structures don\'t have the same nested structure. First structure: type=DType str=<dtype: \'float32\'> Second structure: type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>] More specifically: Substructure ""type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>]"" is a sequence, while substructure ""type=DType str=<dtype: \'float32\'>"" is not During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) <ipython-input-36-5b11c7fef461> in <module> 5 return [x[0],x[1]] 6 ----> 7 print(tf.map_fn(my_fun,tensaki)) ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name) 266 back_prop=back_prop, 267 swap_memory=swap_memory, --> 268 maximum_iterations=n) 269 results_flat = [r.stack() for r in r_a] 270 ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure) 2712 list(loop_vars)) 2713 while cond(*loop_vars): -> 2714 loop_vars = body(*loop_vars) 2715 if try_to_pack and not isinstance(loop_vars, (list, _basetuple)): 2716 packed = True ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in <lambda>(i, lv) 2703 cond = lambda i, lv: ( # pylint: disable=g-long-lambda 2704 math_ops.logical_and(i < maximum_iterations, orig_cond(*lv))) -> 2705 body = lambda i, lv: (i + 1, orig_body(*lv)) 2706 try_to_pack = False 2707 ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in compute(i, tas) 256 packed_values = input_pack([elem_ta.read(i) for elem_ta in elems_ta]) 257 packed_fn_values = fn(packed_values) --> 258 nest.assert_same_structure(dtype or elems, packed_fn_values) 259 flat_fn_values = output_flatten(packed_fn_values) 260 tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)] ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites) 323 ""Entire first structure:\\n%s\\n"" 324 ""Entire second structure:\\n%s"" --> 325 % (str(e), str1, str2)) 326 327 ValueError: The two structures don\'t have the same nested structure. First structure: type=DType str=<dtype: \'float32\'> Second structure: type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>] More specifically: Substructure ""type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>]"" is a sequence, while substructure ""type=DType str=<dtype: \'float32\'>"" is not Entire first structure: . Entire second structure: [., .]```\n\nYou should make sure you are returning a tensor. Maybe concatenate or stack the list of values:\n\nimport tensorflow as tf tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]]) def my_fun(x): x = tf.stack([x[0], x[1]], axis=0) return x print(tf.map_fn(my_fun,tensaki))\n\ntf.Tensor( [[1. 2.] [4.""""""', '""""""Using tf.map_fn when the function has multiple outputs\n\nAsked 2 years, 3 months ago\n\nModified 2 years, 3 months ago\n\nI can easily use tf.map_fn when the function has one output:\n\nimport tensorflow as tf tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]]) def my_fun(x): return x[0] print(tf.map_fn(my_fun,tensaki))\n\ntf.Tensor([1. 4.], shape=(2,), dtype=float32)\n\nBut, when the function has two outputs:\n\ndef my_fun(x): return [x[0],x[1]] print(tf.map_fn(my_fun,tensaki))\n\nI get an error. Not sure what is going on. I read the information about tf.map_fn in here https://www.tensorflow.org/api_docs/python/tf/map_fn, but not sure how to fix this:\n\nmap_fn also supports functions with multi-arity inputs and outputs:\n\nIf elems is a tuple (or nested structure) of tensors, then those tensors must all have the same outer-dimension size (num_elems); and fn is used to transform each tuple (or structure) of corresponding slices from elems. E.g., if elems is a tuple (t1, t2, t3), then fn is used to transform each tuple of slices (t1[i], t2[i], t3[i]) (where 0 <= i < num_elems). If fn returns a tuple (or nested structure) of tensors, then the result is formed by stacking corresponding elements from those structures. ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites) 317 _pywrap_tensorflow.AssertSameStructure(nest1, nest2, check_types, --> 318 expand_composites) 319 except (ValueError, TypeError) as e: ValueError: The two structures don\'t have the same nested structure. First structure: type=DType str=<dtype: \'float32\'> Second structure: type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>] More specifically: Substructure ""type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>]"" is a sequence, while substructure ""type=DType str=<dtype: \'float32\'>"" is not During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) <ipython-input-36-5b11c7fef461> in <module> 5 return [x[0],x[1]] 6 ----> 7 print(tf.map_fn(my_fun,tensaki)) ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name) 266 back_prop=back_prop, 267 swap_memory=swap_memory, --> 268 maximum_iterations=n) 269 results_flat = [r.stack() for r in r_a] 270 ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure) 2712 list(loop_vars)) 2713 while cond(*loop_vars): -> 2714 loop_vars = body(*loop_vars) 2715 if try_to_pack and not isinstance(loop_vars, (list, _basetuple)): 2716 packed = True ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in <lambda>(i, lv) 2703 cond = lambda i, lv: ( # pylint: disable=g-long-lambda 2704 math_ops.logical_and(i < maximum_iterations, orig_cond(*lv))) -> 2705 body = lambda i, lv: (i + 1, orig_body(*lv)) 2706 try_to_pack = False 2707 ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in compute(i, tas) 256 packed_values = input_pack([elem_ta.read(i) for elem_ta in elems_ta]) 257 packed_fn_values = fn(packed_values) --> 258 nest.assert_same_structure(dtype or elems, packed_fn_values) 259 flat_fn_values = output_flatten(packed_fn_values) 260 tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)] ~Users\\user2\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites) 323 ""Entire first structure:\\n%s\\n"" 324 ""Entire second structure:\\n%s"" --> 325 % (str(e), str1, str2)) 326 327 ValueError: The two structures don\'t have the same nested structure. First structure: type=DType str=<dtype: \'float32\'> Second structure: type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>] More specifically: Substructure ""type=list str=[<tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0>, <tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0>]"" is a sequence, while substructure ""type=DType str=<dtype: \'float32\'>"" is not Entire first structure: . Entire second structure: [., .]```\n\nYou should make sure you are returning a tensor. Maybe concatenate or stack the list of values:\n\nimport tensorflow as tf tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]]) def my_fun(x): x = tf.stack([x[0], x[1]], axis=0) return x print(tf.map_fn(my_fun,tensaki))\n\ntf.Tensor( [[1. 2.] [4.""""""']"
57449484,tf.compat.v1.layers.batch_normalization,example required,What is trainable parameter in tensorflow?,"<p>tf.compat.v1.layers.batch_normalization takes <code>trainable</code> as an input. The documentation says:</p>

<blockquote>
  <p>Boolean, if True also add variables to the graph collection GraphKeys.TRAINABLE_VARIABLES (see tf.Variable).</p>
</blockquote>

<p>I think only scaling factor (gamma) and offset (beta) should be added to trainable variables and I am skeptical if even moving averages will get added to GraphKeys.TRAINABLE_VARIABLES. Can somebody tell me how trainable input is influencing the behavior of batch_normalization</p>
","<p>First of all, this function is <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">deprecated</a> and should not be used.</p>

<p><code>trainable</code> arguments means that scaling factor (gamma) and offset (beta) will be trainable and it's true by default.</p>

<p>When it comes to moving averages, those <strong>are not trainable</strong>, they are only updated after each batch pass, those are not parameters (<code>tf.Variable</code> objects).</p>

<p>Please notice, you can set <code>trainable</code> to false, in such case, if <code>beta</code> and <code>gamma</code> are set to defaults (zero and one respectively), they won't affect the moving averages. You can turn them off by issuing <code>center</code> (for <code>beta</code>) or <code>scale</code> (for <code>gamma</code>).</p>
",,"[""How does the 'trainable' parameter in tf.compat.v1.layers.batch_normalization affect the variables added to GraphKeys.TRAINABLE_VARIABLES?"", ""Does the 'trainable' parameter in tf.compat.v1.layers.batch_normalization add moving averages to GraphKeys.TRAINABLE_VARIABLES?"", ""What variables are added to GraphKeys.TRAINABLE_VARIABLES when 'trainable' is set to True in tf.compat.v1.layers.batch_normalization?"", 'Are the scaling factor (gamma) and offset (beta) the only variables added to GraphKeys.TRAINABLE_VARIABLES in tf.compat.v1.layers.batch_normalization?']","[""How does the 'trainable' parameter in tf.compat.v1.layers.batch_normalization affect the variables added to GraphKeys.TRAINABLE_VARIABLES?"", ""Does setting 'trainable=True' in tf.compat.v1.layers.batch_normalization add moving averages to GraphKeys.TRAINABLE_VARIABLES?"", ""Which variables are added to GraphKeys.TRAINABLE_VARIABLES when using tf.compat.v1.layers.batch_normalization with 'trainable=True'?"", 'Are the scaling factor (gamma) and offset (beta) the only trainable variables in tf.compat.v1.layers.batch_normalization?']",set(),[],"{'https://stackoverflow.com/questions/58097348/whats-the-differences-between-tf-graphkeys-global-variables-and-tf-graphkeys-tr', 'https://stackoverflow.com/questions/55619070/graphkeys-trainable-variables-vs-tf-trainable-variables'}","['""""""What\'s the differences between tf.GraphKeys.GLOBAL_VARIABLES and tf.GraphKeys.TRAINABLE_VARIABLES in tensorflow? Asked 4 years, 5 months ago\n\nModified 4 years, 5 months ago\n\nFrom https://www.tensorflow.org/api_docs/python/tf/GraphKeys\n\nGLOBAL_VARIABLES: the default collection of Variable objects, shared across distributed environment (model variables are subset of these). See tf.compat.v1.global_variables for more details. Commonly, all TRAINABLE_VARIABLES variables will be in MODEL_VARIABLES, and all MODEL_VARIABLES variables will be in GLOBAL_VARIABLES\n\nTRAINABLE_VARIABLES: the subset of Variable objects that will be trained by an optimizer. See tf.compat.v1.trainable_variables for more details. So as I understand TRAINABLE_VARIABLES is subset of GLOBAL_VARIABLES, so what else GLOBAL_VARIABLES contain? Also for this simple example statement Commonly, all TRAINABLE_VARIABLES variables will be in MODEL_VARIABLES, and all MODEL_VARIABLES variables will be in GLOBAL_VARIABLES don\'t hold:\n\nIMAGE_HEIGHT = 5 IMAGE_WIDTH = 5 with tf.Graph().as_default(): with tf.variable_scope(\'my_scope\', reuse=tf.AUTO_REUSE): x_ph = tf.placeholder( dtype=tf.float32, shape=[None, IMAGE_HEIGHT, IMAGE_WIDTH, 3], name=\'input\' ) x_tf = tf.layers.conv2d(x_ph, 32, 1, 1, padding=\'valid\') with tf.Session() as sess: sess.run(tf.global_variables_initializer()) x_np = np.random.rand(1, IMAGE_HEIGHT, IMAGE_WIDTH, 3) out_np = sess.run(x_tf, {x_ph:x_np}) print(\'out_np.shape\', out_np.shape) print(\'-\'*60) global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES) print(\'len(global_vars)\', len(global_vars)) print(\'global_vars params:\', sum([np.prod(var.shape) for var in global_vars])) print(global_vars) print(\'-\'*60) model_vars = tf.get_collection(tf.GraphKeys.MODEL_VARIABLES) print(\'len(model_vars)\', len(model_vars)) print(\'model_vars params:\', sum([np.prod(var.shape) for var in model_vars])) print(model_vars) print(\'-\'*60) trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) print(\'len(trainable_vars)\', len(trainable_vars)) print(\'trainable_vars params:\', sum([np.prod(var.shape) for var in trainable_vars])) print(trainable_vars)\n\nout_np.shape (1, 5, 5, 32) ------------------------------------------------------------ len(global_vars) 2 global_vars params: 128 [<tf.Variable \'my_scope/conv2d/kernel:0\' shape=(1, 1, 3, 32) dtype=float32_ref>, <tf.Variable \'my_scope/conv2d/bias:0\' shape=(32,) dtype=float32_ref>] ------------------------------------------------------------ len(model_vars) 0 model_vars params: 0 [] ------------------------------------------------------------ len(trainable_vars) 2 trainable_vars params: 128 [<tf.Variable \'my_scope/conv2d/kernel:0\' shape=(1, 1, 3, 32) dtype=float32_ref>, <tf.Variable \'my_scope/conv2d/bias:0\' shape=(32,) dtype=float32_ref>]\n\nWhy Commonly, all TRAINABLE_VARIABLES variables will be in MODEL_VARIABLES, and all MODEL_VARIABLES variables will be in GLOBAL_VARIABLES don\'t hold for this example. What additional variables GLOBAL_VARIABLES contain besides TRAINABLE_VARIABLES? Is it true that TRAINABLE_VARIABLES will be always subset of GLOBAL_VARIABLES or they can just intersect partially? Note: All of this applies to TF version 1 only, as all variable collections have been deprecated and (IIRC) won\'t be in TF v2. Starting from question 2:\n\nWhat additional variables GLOBAL_VARIABLES contain besides TRAINABLE_VARIABLES? global_step, for example, is a global variable which is not trainable. It\'s a variable, because you update it at every step, it\'s not trainable because it\'s not part of the optimization process (as in, it\'s not a weight/bias that is altered in order to minimize the loss). Is it true that TRAINABLE_VARIABLES will be always subset of GLOBAL_VARIABLES or they can just intersect partially? In principle, the two groups can just intersect partially, although this would be very odd. An example I can think of would be something like a custom distributed training environment where each machine has its own optimizer and where some of the trainable variables are defined as local variables (i.e., each machine has its own copy and these copies are not kept in sync). Why would you do that?""""""', '""""""Share Your Experience: GraphKeys.TRAINABLE_VARIABLES vs tf.trainable_variables()\n\nAsked 5 years, 1 month ago\n\nModified 5 years, 1 month ago\n\nIs GraphKeys.TRAINABLE_VARIABLES is the same as tf.trainable_variables() ? Is GraphKeys.TRAINABLE_VARIABLES actually tf.GraphKeys.TRAINABLE_VARIABLES? Looks like networks successfully trains with:\n\noptimizer = tf.train.AdamOptimizer(config.LEARNING_RATE) with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): self.train_op = optimizer.minimize(self.loss, var_list=tf.trainable_variables())\n\noptimizer = tf.train.AdamOptimizer(config.LEARNING_RATE) with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): self.train_op = optimizer.minimize(self.loss)\n\nAccording to documentation:\n\nvar_list: Optional list or tuple of Variable objects to update to minimize loss. Defaults to the list of variables collected in the graph under the key GraphKeys.TRAINABLE_VARIABLES.""""""']"
63004540,tf.pad,example required,How to pad 1 dimensinal vector in tensorflow? Getting InvalidArgumentError: paddings must be a matrix with 2 columns with tf.pad,"<p>I am trying to use tf.pad. Here is my attempt to pad the tensor to length 20, with values 10.</p>
<pre><code>tf.pad(tf.constant([1, 2, 3, 45]), paddings=20, constant_values=10)
</code></pre>
<p>I get this error message</p>
<pre><code>InvalidArgumentError: paddings must be a matrix with 2 columns: [2,1] [Op:PadV2]
</code></pre>
<p>I am looking at the documentation</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/pad"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/pad</a></p>
<blockquote>
<p>paddings is an integer tensor with shape [n, 2], where n is the rank of tensor. For each dimension D of input, paddings[D, 0] indicates how many values to add before the contents of tensor in that dimension, and paddings[D, 1] indicates how many values to add after the contents of tensor in that dimension</p>
</blockquote>
<p>But I am unable to figure out how to shape the pad value</p>
","<p>You have to specify the padding at the beginning and the padding at the end of your vector by matrix of shape (1,2) :</p>
<pre><code>tf.pad(tf.constant([1, 2, 3, 45]), [[ 0 , 20]], constant_values=10)
</code></pre>
<p>if you have three-dimensional tensor (rank = 3 e.g : (225,225,3) ) the padding matrix has to be of shape (3, 2 ) where &quot;3&quot; is the rank, and &quot;2&quot; to specify the padding at the beginning and end of each dimension.</p>
<p>For example, a padding matrix  = [ [0,2], [5,5], [2,0] ], means that we want to pad the first dimension by 0 at the beginning (=no padding) and 2 at the end .padding the second dimension by 5 at beginning and 5 at the end.</p>
",,"['How to use tf.pad in TensorFlow?', 'What is the correct way to specify the paddings parameter in tf.pad?', 'How to pad a tensor to a specific length using tf.pad in TensorFlow?', 'Examples of using tf.pad to pad a tensor with constant values in TensorFlow']","['How to use tf.pad to pad a tensor to a specific length in TensorFlow?', 'What is the correct way to specify the paddings parameter in tf.pad?', 'Examples of using tf.pad with constant_values in TensorFlow', 'How to pad a 1D tensor to a specific length with a constant value in TensorFlow?']",set(),[],"{'https://stackoverflow.com/questions/42334646/tensorflow-pad-unknown-size-tensor-to-a-specific-size', 'https://stackoverflow.com/questions/43928642/how-does-tensorflow-pad-work'}","['""""""For processing, a static length makes them easier to work with. golmschenkgolmschenk\n\n\n\nYes. There is. Provided you do not need to change the rank of the tensor, it\'s very simple. tf.pad() accepts regular python lists with tensors. The format of the padding is a list of pairs of how much to pad on each side of that dimension. t = tf.constant([[1, 2], [3, 4]]) paddings = [[0, 0], [0, 4-tf.shape(t)[0]]] out = tf.pad(t, paddings, \'CONSTANT\', constant_values=-1) sess.run(out) # gives: # array([[ 1, 2, -1, -1], # [ 3, 4, -1, -1]], dtype=int32)\n\nIf you want to generalise this to a useful function, you could do something like:\n\ndef pad_up_to(t, max_in_dims, constant_values): diff = max_in_dims - tf.shape(t) paddings = tf.pad(diff[:, None], [[0, 0], [1, 0]]) return tf.pad(t, paddings, \'CONSTANT\', constant_values=constant_values) # (note: see edits for the solution referred to by other answers on this question)\n\nwhere max_in_dims is essentially the desired shape of the output. Note: this function will fail if you provide a shape that is strictly smaller than t in any dimension. You can use it like:\n\nt = tf.constant([[1, 2], [3, 4]]) # shape = [2, 2] t_padded = pad_up_to(t, [2, 4], -1) # shape = [2, 4], padded with -1s\n\nt = tf.placeholder(tf.float32, [None, None]) # shape = [?, ?] t_padded = pad_up_to(t, [5,5], -1) # shape = [5, 5], padded with -1s t_np = np.random.uniform(0, 1, [3,4]) # shape = [3,4], no padding t_padded_out = sess.run(t_padded, {t: t_np}) t_np2 = np.random.uniform(0, 1, [2,1]) # shape = [2,1], no padding t_padded_out2 = sess.run(t_padded, {t: t_np2})\n\nAlthough the dimension sizes are calculated dynamically, the number of dimensions is not, so make sure that max_in_dims has the same number of elements as t.shape. MultihunterMultihunter\n\n 12\n\nWhat if t has a dynamic size (e.g., its size is determined only after some placeholder is fed)? In my provided function, s is a tensor that is the shape of t, so the amount to pad is calculated dynamically. The number of dimensions is not calculated dynamically, so just make sure your max_in_dims is a vector with has the same number of elements as your t has dimensions. If you do this it will just work (I wrote the function with this use-case in mind). I didn\'t expect it to work with a dynamic size but to my surprise, it does! Thanks! Good reference to not waste time finding a more off the shelf solution. This didn\'t really work for me in TF 2.3 with dynamic sizes since m is evaluated to None which throws an error for the subtraction. However, the fix is to simply change the line to [[0, m - s[i]] if m != None else [0,0] for (i, m) in enumerate(max_in_dims)]. | Show 7 more comments\n\nAn extension of Multihunter\'s solution so that padding is only performed when necessary and does not yield an error for longer inputs:\n\nSuppose we have a sequential input called inp_seq, which is a tensor of rank 4 and should be padded in order to have a minimum length of filter_size in dimension 1. def dynamic_padding(inp, min_size): pad_size = min_size - tf.shape(inp)[1] paddings = [[0, 0], [0, pad_size], [0, 0], [0, 0]] # assign here, during graph execution return tf.pad(inp, paddings) # Pad only if necessary padded = tf.cond(tf.less(tf.shape(inp_seq)[1], filter_size), true_fn=lambda: dynamic_padding(inp_seq, filter_size), false_fn=lambda: inp_seq)\n\n1,2\n\nThe line creating a tf.Variable is redundant, since the subsequent line overwrites it with a python list. You can remove that line and it will function the same. (Also, a sequence is a class defined by the python base libraries, while a tensor is defined by tensorflow: I think you should clarify which of these your inp_seq actually is; I presume that what you\'re dealing with is actually a sequence (or list) of Tensors like inp_seq=[Tensor, Tensor, Tensor])\n\n\n\nI removed the redundant line, thank you for the suggestion. The input is simply a tensor; I used the term sequence with its broader meaning (to refer to data of high dimensionality which are sequential along one dimension, namely the one to pad), I was not referring to the python base libraries. I clarified this in the edit.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow - Pad unknown size tensor to a specific size? Asked 7 years, 4 months ago\n\nModified 1 year, 3 months ago\n\nIs there a way to pad a tensor of variable size to a given shape with a specific pad value? For example given the tensors:\n\n[[1, 2, 3], [4, 5, 6]]\n\nIs there a way to have a generic operation which would take either and pad them with a value (say, to shape [2, 4] with value -1) to result in:\n\n[[1, 2, -1, -1], [3, 4, -1, -1]]\n\n[[1, 2, 3, -1], [4, 5, 6, -1]]\n\nrespectively? My reasoning (in case there is a better solution) is that I have examples from a TFRecords file, part of which has a variable length.""""""', '""""""For processing, a static length makes them easier to work with. golmschenkgolmschenk\n\n\n\nYes. There is. Provided you do not need to change the rank of the tensor, it\'s very simple. tf.pad() accepts regular python lists with tensors. The format of the padding is a list of pairs of how much to pad on each side of that dimension. t = tf.constant([[1, 2], [3, 4]]) paddings = [[0, 0], [0, 4-tf.shape(t)[0]]] out = tf.pad(t, paddings, \'CONSTANT\', constant_values=-1) sess.run(out) # gives: # array([[ 1, 2, -1, -1], # [ 3, 4, -1, -1]], dtype=int32)\n\nIf you want to generalise this to a useful function, you could do something like:\n\ndef pad_up_to(t, max_in_dims, constant_values): diff = max_in_dims - tf.shape(t) paddings = tf.pad(diff[:, None], [[0, 0], [1, 0]]) return tf.pad(t, paddings, \'CONSTANT\', constant_values=constant_values) # (note: see edits for the solution referred to by other answers on this question)\n\nwhere max_in_dims is essentially the desired shape of the output. Note: this function will fail if you provide a shape that is strictly smaller than t in any dimension. You can use it like:\n\nt = tf.constant([[1, 2], [3, 4]]) # shape = [2, 2] t_padded = pad_up_to(t, [2, 4], -1) # shape = [2, 4], padded with -1s\n\nt = tf.placeholder(tf.float32, [None, None]) # shape = [?, ?] t_padded = pad_up_to(t, [5,5], -1) # shape = [5, 5], padded with -1s t_np = np.random.uniform(0, 1, [3,4]) # shape = [3,4], no padding t_padded_out = sess.run(t_padded, {t: t_np}) t_np2 = np.random.uniform(0, 1, [2,1]) # shape = [2,1], no padding t_padded_out2 = sess.run(t_padded, {t: t_np2})\n\nAlthough the dimension sizes are calculated dynamically, the number of dimensions is not, so make sure that max_in_dims has the same number of elements as t.shape. MultihunterMultihunter\n\n 12\n\nWhat if t has a dynamic size (e.g., its size is determined only after some placeholder is fed)? In my provided function, s is a tensor that is the shape of t, so the amount to pad is calculated dynamically. The number of dimensions is not calculated dynamically, so just make sure your max_in_dims is a vector with has the same number of elements as your t has dimensions. If you do this it will just work (I wrote the function with this use-case in mind). I didn\'t expect it to work with a dynamic size but to my surprise, it does! Thanks! Good reference to not waste time finding a more off the shelf solution. This didn\'t really work for me in TF 2.3 with dynamic sizes since m is evaluated to None which throws an error for the subtraction. However, the fix is to simply change the line to [[0, m - s[i]] if m != None else [0,0] for (i, m) in enumerate(max_in_dims)]. | Show 7 more comments\n\nAn extension of Multihunter\'s solution so that padding is only performed when necessary and does not yield an error for longer inputs:\n\nSuppose we have a sequential input called inp_seq, which is a tensor of rank 4 and should be padded in order to have a minimum length of filter_size in dimension 1. def dynamic_padding(inp, min_size): pad_size = min_size - tf.shape(inp)[1] paddings = [[0, 0], [0, pad_size], [0, 0], [0, 0]] # assign here, during graph execution return tf.pad(inp, paddings) # Pad only if necessary padded = tf.cond(tf.less(tf.shape(inp_seq)[1], filter_size), true_fn=lambda: dynamic_padding(inp_seq, filter_size), false_fn=lambda: inp_seq)\n\n1,2\n\nThe line creating a tf.Variable is redundant, since the subsequent line overwrites it with a python list. You can remove that line and it will function the same. (Also, a sequence is a class defined by the python base libraries, while a tensor is defined by tensorflow: I think you should clarify which of these your inp_seq actually is; I presume that what you\'re dealing with is actually a sequence (or list) of Tensors like inp_seq=[Tensor, Tensor, Tensor])\n\n\n\nI removed the redundant line, thank you for the suggestion. The input is simply a tensor; I used the term sequence with its broader meaning (to refer to data of high dimensionality which are sequential along one dimension, namely the one to pad), I was not referring to the python base libraries. I clarified this in the edit.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow - Pad unknown size tensor to a specific size? Asked 7 years, 4 months ago\n\nModified 1 year, 3 months ago\n\nIs there a way to pad a tensor of variable size to a given shape with a specific pad value? For example given the tensors:\n\n[[1, 2, 3], [4, 5, 6]]\n\nIs there a way to have a generic operation which would take either and pad them with a value (say, to shape [2, 4] with value -1) to result in:\n\n[[1, 2, -1, -1], [3, 4, -1, -1]]\n\n[[1, 2, 3, -1], [4, 5, 6, -1]]\n\nrespectively? My reasoning (in case there is a better solution) is that I have examples from a TFRecords file, part of which has a variable length.""""""', '""""""For processing, a static length makes them easier to work with. golmschenkgolmschenk\n\n\n\nYes. There is. Provided you do not need to change the rank of the tensor, it\'s very simple. tf.pad() accepts regular python lists with tensors. The format of the padding is a list of pairs of how much to pad on each side of that dimension. t = tf.constant([[1, 2], [3, 4]]) paddings = [[0, 0], [0, 4-tf.shape(t)[0]]] out = tf.pad(t, paddings, \'CONSTANT\', constant_values=-1) sess.run(out) # gives: # array([[ 1, 2, -1, -1], # [ 3, 4, -1, -1]], dtype=int32)\n\nIf you want to generalise this to a useful function, you could do something like:\n\ndef pad_up_to(t, max_in_dims, constant_values): diff = max_in_dims - tf.shape(t) paddings = tf.pad(diff[:, None], [[0, 0], [1, 0]]) return tf.pad(t, paddings, \'CONSTANT\', constant_values=constant_values) # (note: see edits for the solution referred to by other answers on this question)\n\nwhere max_in_dims is essentially the desired shape of the output. Note: this function will fail if you provide a shape that is strictly smaller than t in any dimension. You can use it like:\n\nt = tf.constant([[1, 2], [3, 4]]) # shape = [2, 2] t_padded = pad_up_to(t, [2, 4], -1) # shape = [2, 4], padded with -1s\n\nt = tf.placeholder(tf.float32, [None, None]) # shape = [?, ?] t_padded = pad_up_to(t, [5,5], -1) # shape = [5, 5], padded with -1s t_np = np.random.uniform(0, 1, [3,4]) # shape = [3,4], no padding t_padded_out = sess.run(t_padded, {t: t_np}) t_np2 = np.random.uniform(0, 1, [2,1]) # shape = [2,1], no padding t_padded_out2 = sess.run(t_padded, {t: t_np2})\n\nAlthough the dimension sizes are calculated dynamically, the number of dimensions is not, so make sure that max_in_dims has the same number of elements as t.shape. MultihunterMultihunter\n\n 12\n\nWhat if t has a dynamic size (e.g., its size is determined only after some placeholder is fed)? In my provided function, s is a tensor that is the shape of t, so the amount to pad is calculated dynamically. The number of dimensions is not calculated dynamically, so just make sure your max_in_dims is a vector with has the same number of elements as your t has dimensions. If you do this it will just work (I wrote the function with this use-case in mind). I didn\'t expect it to work with a dynamic size but to my surprise, it does! Thanks! Good reference to not waste time finding a more off the shelf solution. This didn\'t really work for me in TF 2.3 with dynamic sizes since m is evaluated to None which throws an error for the subtraction. However, the fix is to simply change the line to [[0, m - s[i]] if m != None else [0,0] for (i, m) in enumerate(max_in_dims)]. | Show 7 more comments\n\nAn extension of Multihunter\'s solution so that padding is only performed when necessary and does not yield an error for longer inputs:\n\nSuppose we have a sequential input called inp_seq, which is a tensor of rank 4 and should be padded in order to have a minimum length of filter_size in dimension 1. def dynamic_padding(inp, min_size): pad_size = min_size - tf.shape(inp)[1] paddings = [[0, 0], [0, pad_size], [0, 0], [0, 0]] # assign here, during graph execution return tf.pad(inp, paddings) # Pad only if necessary padded = tf.cond(tf.less(tf.shape(inp_seq)[1], filter_size), true_fn=lambda: dynamic_padding(inp_seq, filter_size), false_fn=lambda: inp_seq)\n\n1,2\n\nThe line creating a tf.Variable is redundant, since the subsequent line overwrites it with a python list. You can remove that line and it will function the same. (Also, a sequence is a class defined by the python base libraries, while a tensor is defined by tensorflow: I think you should clarify which of these your inp_seq actually is; I presume that what you\'re dealing with is actually a sequence (or list) of Tensors like inp_seq=[Tensor, Tensor, Tensor])\n\n\n\nI removed the redundant line, thank you for the suggestion. The input is simply a tensor; I used the term sequence with its broader meaning (to refer to data of high dimensionality which are sequential along one dimension, namely the one to pad), I was not referring to the python base libraries. I clarified this in the edit.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow - Pad unknown size tensor to a specific size? Asked 7 years, 4 months ago\n\nModified 1 year, 3 months ago\n\nIs there a way to pad a tensor of variable size to a given shape with a specific pad value? For example given the tensors:\n\n[[1, 2, 3], [4, 5, 6]]\n\nIs there a way to have a generic operation which would take either and pad them with a value (say, to shape [2, 4] with value -1) to result in:\n\n[[1, 2, -1, -1], [3, 4, -1, -1]]\n\n[[1, 2, 3, -1], [4, 5, 6, -1]]\n\nrespectively? My reasoning (in case there is a better solution) is that I have examples from a TFRecords file, part of which has a variable length.""""""']"
62752605,tf.nn.sampled_softmax_loss,example required,Loss function in tf.nn.sampled_softmax_loss,"<p>I have a question regarding Tensorflow:</p>
<p>Which loss function is used in <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""nofollow noreferrer""><code>tf.nn.sampled_softmax_loss</code></a>?</p>
<p>I believe it's <em><strong>cross-entropy</strong></em>, but it is not written on the official website. Can anyone confirm my guess?</p>
","<p>Based on <a href=""https://stackoverflow.com/questions/35241251/in-tensorflow-what-is-the-difference-between-sampled-softmax-loss-and-softmax-c"">this other question</a>, it looks like it is cross entropy.</p>
<p>Besides, the main difference between <code>sampled_softmax_loss</code> and <code>softmax_cross_entropy_with_logits</code> (the standard cross_entropy loss in TF) is that the first only takes into account a subset V of your vocabulary to calculate your loss, while the second takes into account your entire vocabulary.</p>
",,"['What is the loss function used in tf.nn.sampled_softmax_loss in TensorFlow?', 'Does tf.nn.sampled_softmax_loss use cross-entropy as its loss function?', 'Explanation of tf.nn.sampled_softmax_loss in TensorFlow', 'How does tf.nn.sampled_softmax_loss work in TensorFlow?', 'TensorFlow tf.nn.sampled_softmax_loss detailed tutorial']","['What loss function does tf.nn.sampled_softmax_loss use in TensorFlow?', 'Is cross-entropy the loss function used in tf.nn.sampled_softmax_loss?', 'Can someone confirm if tf.nn.sampled_softmax_loss in TensorFlow uses cross-entropy as its loss function?', 'What type of loss function is implemented in tf.nn.sampled_softmax_loss according to TensorFlow documentation?']",{'https://www.youtube.com/watch?v=FZ-iwMSkJoQ'},"['""""""[Document(page_content=""in this video we are going to look at how to use sampled soft Max loss in tensor flow how do we calculate it and for that I\'ve created these examples where we have the tensor for weights then we have tensor for bias labels inputs and then we have uh generated sample values so all of these we are going to input it to the ef. NN do sampled uncore soft maxcore loss as we see here in the docs so in the docs we have all of these values and the rest of them they are refilled except for the sampled values we are going to leave the others as is and so once we put all the values so weights we have bias and then labels we are uh uh using the tf. expands labels and then for inputs we have the inputs number sampled number classes that we have specified here two and three and then the sampled value so when we run this the you get here in the output which is the sampled softmax loss if you have any questions or comments please do let me know in the comments comment section below I hope to see you all in the next video thank you"", metadata={\'source\': \'FZ-iwMSkJoQ\'})]""""""']","{'https://stackoverflow.com/questions/47034888/how-to-choose-cross-entropy-loss-in-tensorflow', 'https://stackoverflow.com/questions/35241251/in-tensorflow-what-is-the-difference-between-sampled-softmax-loss-and-softmax-c'}","['""""""The arguments weights and biases specify a separate fully-connected layer that is used to compute the logits for a chosen sample. Like above, labels are not one-hot encoded, but have the shape [batch_size, num_true]. Sampled functions are only suitable for training. In test time, it\'s recommended to use a standard softmax loss (either sparse or one-hot) to get an actual distribution. Another alternative loss is tf.nn.nce_loss, which performs noise-contrastive estimation (if you\'re interested, see this very detailed discussion). I\'ve included this function to the softmax family, because NCE guarantees approximation to softmax in the limit. 1\n\nMay I ask for a point of clarification regarding sigmoid cross entropy (sigCE)? If it solves for N binary classification tasks at once, is N = prod(output.shape), e.g. shape = [batch, examples, channels]; N = (batch * examples * channels)? If tf.losses expect ""logits"" (output of network), should I also return the probabilities for ease of use? could you maybe look at stackoverflow.com/questions/53612973/…\n\n\n\nHowever, for version 1.5, softmax_cross_entropy_with_logits_v2 must be used instead, while using its argument with the argument key=..., for example\n\nsoftmax_cross_entropy_with_logits_v2(_sentinel=None, labels=y, logits=my_prediction, dim=-1, name=None)\n\n\n\n 0\n\nWhile it is great that the accepted answer contains lot more info than what is asked, I felt that sharing a few generic thumb rules will make the answer more compact and intuitive:\n\nThere is just one real loss function. This is cross-entropy (CE). For a special case of a binary classification, this loss is called binary CE (note that the formula does not change) and for non-binary or multi-class situations the same is called categorical CE (CCE). Sparse functions are a special case of categorical CE where the expected values are not one-hot encoded but is an integer\n\nWe have the softmax formula which is an activation for multi-class scenario. For binary scenario, same formula is given a special name - sigmoid activation\n\nBecause there are sometimes numerical instabilities (for extreme values) when dealing with logarithmic functions, TF recommends combining the activation layer and the loss layer into one single function. This combined function is numerically more stable. TF provides these combined functions and they are suffixed with _with_logits\n\nWith this, let us now approach some situations. Say there is a simple binary classification problem - Is a cat present or not in the image? What is the choice of activation and loss function? It will be a sigmoid activation and a (binary)CE. So one could use sigmoid_cross_entropy or more preferably sigmoid_cross_entropy_with_logits. The latter combines the activation and the loss function and is supposed to be numerically stable. How about a multi-class classification. Say we want to know if a cat or a dog or a donkey is present in the image. What is the choice of activation and loss function? It will be a softmax activation and a (categorical)CE. So one could use softmax_cross_entropy or more preferably softmax_cross_entropy_with_logits. We assume that the expected value is one-hot encoded (100 or 010 or 001). If (for some weird reason), this is not the case and the expected value is an integer (either 1 or 2 or 3) you could use the \'sparse\' counterparts of the above functions. There could be a third case.""""""', '""""""In Tensorflow, what is the difference between sampled_softmax_loss and softmax_cross_entropy_with_logits\n\nAsked 8 years, 3 months ago\n\nModified 4 years, 3 months ago\n\nIn tensorflow, there are methods called softmax_cross_entropy_with_logits and sampled_softmax_loss. I read the tensorflow document and searched google for more information but I couldn\'t find the difference. It looks like to me both calculates the loss using softmax function. Using sampled_softmax_loss to calculate the loss\n\nloss = tf.reduce_mean(tf.nn.sampled_softmax_loss(...))\n\nUsing softmax_cross_entropy_with_logits to calculate the loss\n\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(P, Q))\n\nTo me, calculating softmax loss is same as calculating softmaxed cross entropy (e.g. cross_entropy(softmax(train_x)))\n\nCould somebody tell me the why there is two different methods and which method should I use in which case? HongKun YooHongKun Yoo\n\n 0\n\nIf your target vocabulary(or in other words amount of classes you want to predict) is really big, it is very hard to use regular softmax, because you have to calculate probability for every word in dictionary. By Using sampled_softmax_loss you only take in account subset V of your vocabulary to calculate your loss. Sampled softmax only makes sense if we sample(our V) less than vocabulary size. If your vocabulary(amount of labels) is small, there is no point using sampled_softmax_loss. You can see implementation details in this paper: http://arxiv.org/pdf/1412.2007v2.pdf\n\nAlso you can see example where it is used - Sequence to sequence translation in this example\n\n 2\n\nHi Farseer, I kind of struggle with the same issue as above. My output vocabulary is only around 100 labels. Now, tensorflow only provides the sampled_softmax_loss function. Instead of this one, could I use the tf.nn.softmax(tf.matmul(inputs, tf.transpose(weights)) + biases) function? Or can I just use the seq2seq_model.py as it is?""""""']"
66874943,tf.data.Dataset,example required,Why iterations over the same tf.data.Dataset give different data each iteration?,"<p>I'm trying to understand how <strong>tf.data.Dataset</strong> works.</p>
<p>It says on the documentation that <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take"" rel=""nofollow noreferrer"">take</a> returns a dataset with a certain amount of elements from that dataset. You can then iterate over a single sample (in this case a batch):</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow.compat.v2 as tf
import tensorflow_datasets as tfds

# Construct a tf.data.Dataset
ds = tfds.load('mnist', split='train', shuffle_files=True)

# Build your input pipeline
ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

single_batch_dataset = ds.take(1)

for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)
# ...
</code></pre>
<p>Outputs:</p>
<pre><code>tf.Tensor([2 0 6 6 8 8 6 0 3 4 8 7 5 2 5 7 8 7 1 1 1 8 6 4 0 4 3 2 4 2 1 9], shape=(32,), dtype=int64)
</code></pre>
<p>However, iterating over it again, gives different labels: (continuation of last code)</p>
<pre class=""lang-py prettyprint-override""><code>for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)

for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)

</code></pre>
<p>Outputs:</p>
<pre><code>tf.Tensor([7 3 5 6 3 1 7 9 6 1 9 3 9 8 6 7 7 1 9 7 5 2 0 7 8 1 7 8 7 0 5 0], shape=(32,), dtype=int64)
tf.Tensor([1 3 6 1 8 8 0 4 1 3 2 9 5 3 8 7 4 2 1 8 1 0 8 5 4 5 6 7 3 4 4 1], shape=(32,), dtype=int64)
</code></pre>
<p>Shouldn't the labels be the same, given that the dataset is the same?</p>
","<p>This is because the data files are shuffled and the dataset is shuffled with <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=ru#shuffle"" rel=""nofollow noreferrer""><code>dataset.shuffle()</code></a>.</p>
<p>With <code>dataset.shuffle()</code>, the data will be shuffled in a different way on each iteration by default.</p>
<p>One can remove <code>shuffle_files=True</code> and set the argument <code>reshuffle_each_iteration=False</code> to prevent reshuffling on different iterations.</p>
<p>The <code>.take()</code> function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them.</p>
<pre class=""lang-py prettyprint-override""><code># Construct a tf.data.Dataset
ds = tfds.load('mnist', split='train', shuffle_files=False)

# Build your input pipeline
ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

single_batch_dataset = ds.take(1)

for example in single_batch_dataset:
    image, label = example[&quot;image&quot;], example[&quot;label&quot;]
    print(label)
    
for example in single_batch_dataset:
    image, label = example[&quot;image&quot;], example[&quot;label&quot;]
    print(label)
</code></pre>
<p>Output:</p>
<pre class=""lang-py prettyprint-override""><code>tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)
tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)
</code></pre>
","<pre class=""lang-py prettyprint-override""><code># Construct a tf.data.Dataset
ds = tfds.load('mnist', split='train', shuffle_files=False)

# Build your input pipeline
ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

single_batch_dataset = ds.take(1)

for example in single_batch_dataset:
    image, label = example[&quot;image&quot;], example[&quot;label&quot;]
    print(label)
    
for example in single_batch_dataset:
    image, label = example[&quot;image&quot;], example[&quot;label&quot;]
    print(label)
</code></pre>","['Understanding tf.data.Dataset take method in TensorFlow', 'How does tf.data.Dataset.shuffle affect dataset iteration in TensorFlow', 'Why does iterating over a tf.data.Dataset with take(1) give different results each time', 'TensorFlow tf.data.Dataset take method behavior explained', 'How to ensure consistent batches with tf.data.Dataset in TensorFlow']","['Why does iterating over a tf.data.Dataset multiple times yield different results?', 'How does the shuffle operation in tf.data.Dataset affect the output of the dataset?', 'Does the take method in tf.data.Dataset create a static snapshot of the dataset?', 'How to ensure consistent output when iterating over a tf.data.Dataset multiple times?', 'What is the effect of prefetching on the output of a tf.data.Dataset?']",{'https://www.youtube.com/watch?v=n7byMbl2VUQ'},"['""""""[Document(page_content=""ROHAN JAIN: Hi, all. I\'m Rohan, and I\'m\\nhere to talk to you about how you can scale up\\nor input data processing with tf.data. So let\'s start with a high-level\\nview of your ML training job. Typically, your ML training\\nstep will have two phases to it. The first is data\\npreprocessing, where you\'re going to look\\nat the input files and do all kinds of\\ntransformations on them to make them ready for\\nthe next phase, which is model computation. While you\'re doing data\\npreprocessing, which happens in the CPU,\\nyou might be doing some kind of things such as-- for images, you\'re\\ncropping them. For videos, you may be\\nsampling them and whatnot. So if your training\\nspeed is slow, you could have a bottleneck in\\neither one of these two places. And I hope that the\\ntalk on profiling would give you an\\nindication on how to figure out which\\none of the two phases you\'re getting slow at. And I\'m here to talk to\\nyou about the first kind of preprocessing bottleneck--\\nthe bottleneck which is data preprocessing. So let\'s try to look into what\\nthis bottleneck really is. So in the last few years\\nwe\'ve done a fantastic job making accelerators which do\\nthe ML operations really fast. And so the amount\\nof time it takes us to do a matrix\\noperation and all the linear algebra our\\noperations is a lot smaller. But the hosts and the\\nCPUs that feed the data to these accelerators have not\\nbeen able to keep up with them, and so there ends up\\nbeing a bottleneck. We thought that we\\ncould mitigate this by making the\\nmodels more complex, but what happens is that the\\naccelerators have constraints on how much RAM they have,\\nand, more importantly, where you deploy\\nthese models tends to be something like a mobile\\ndevice or something like that, which tends to restrict\\nthe amount of complexity you can introduce\\ninto your model. So that hasn\'t\\nreally panned out. The second approach\\npeople take is that they try to turn larger batch sizes. But larger batch sizes\\nrequire a larger amount of preprocessing to\\nassemble the batch, so then that puts\\nfurther pressure on them. So that\'s why this is becoming\\nan increasingly larger problem within Alphabet and\\neven externally. And I\'m going to\\ntalk to you about how you can solve it using tf.data. tf.data is TensorFlow\'s data\\npreprocessing framework. It\'s fast, it\'s flexible,\\nand it\'s easy to use. And you can learn more\\nabout it at our guide. For background for\\nthe rest of the talk, I think I\'m going to go through\\na typical tf.data pipeline, and that\'ll help us\\nin the later stages. So suppose you have some data in\\nsome tf.data record files which are your training data. So you can now start\\noff with the TF record data set with that data. And then after that, you start\\ndoing your preprocessing. This is typically the\\nbulk of the logic. So if it\'s images, you\'re\\ndoing cropping, maybe flipping, all sorts of things there. After that, you\\nshuffle the data so that you don\'t train to\\nthe order in which you see the examples and the input. And that helps you with\\ntheir training accuracy. And after that, we will batch it\\nso that the accelerator can now make use of vectorized\\ncomputations. Finally, you want to do some\\nsoftware pipelining so that you ensure that while\\nthe model is off working on one batch of data,\\nthe preprocessing side can produce the next batch\\nso that everything works very efficiently. Finally, you can then\\nfeed this tf.data dataset to a Keras model,\\nso that you can now start doing your training. So given that sort\\nof basic pipeline, and suppose you\\nhave a bottleneck, the first thing I\'d\\nrecommend you to do is to go through our single\\nhost performance guide, and try to utilize every\\ntrick and transformation that is available in tf-data\\nto be able to extract the maximum possible\\nperformance, so that you\'re using all the\\n[INAUDIBLE] and whatever. There\'s excellent information\\nat the guide that we have here. And [INAUDIBLE] did a\\ngreat talk at the ML Tokyo Summit, which you can take\\na look at to learn more about this. So that\'s the first thing\\nI\'d recommend you do. But suppose you have\\ndone that and you\'ve tried all the different\\nrecommendations that we have here, but you\'re still\\nbottlenecked on that data preprocessing part. And don\'t worry,\\nyou\'re not alone. This is very common. We\'ve increasingly\\nseen this with a lot of internal customers. And so now I\'m very pleased to\\npresent a couple of solutions that we\'ve been\\nworking on on the team to help you solve that problem. So the first idea\\nis that why don\'t we just reuse the computation? So suppose you\'re playing\\naround with different model architectures. Your input pre-processing\\nsort of part kind of remains the same. And if it\'s expensive and\\ntime-consuming, why don\'t we just do it once,\\nsave it, and then every subsequent time,\\nwe just read from it, and do that quickly? So we noticed a bunch of\\ninternal customers, teams within Alphabet, who\\nwere trying to do this on their own outside\\nof tf.data, and we decided to bring\\nit in to tf.data and make it incredibly fast,\\nflexible, and easy to use. And so this is what\\nwe call Snapshot. The idea is what I\\nexplained to you. You materialize the output of\\nyour data pre-processing once, and then you can use\\nit many, many times. This is incredibly\\nuseful for playing around with different\\nmodel architectures and if you settle down\\non an architecture doing hyperparameter tuning. And so you can get that\\nspeed up using Snapshot. Next, I\'m going to go\\nthrough the pipeline that we talked about before and\\nsee how you can add Snapshot to it to make it faster. So that\'s the original\\npipeline that we had. And so notice that there\'s\\nthis pre-processing step, which is expensive. So now with Snapshot, you just\\nadd a snapshot transformation right after that with a\\ndirectory [INAUDIBLE].. And with this, everything that\\nis before the snapshot will now be written to disk the\\nfirst time it\'s run. And then every subsequent time,\\nwe will just read from it. And we would go through the\\nrest of the steps as usual. One thing I\'d like\\nto point out is that we place the snapshot\\nat a particular location before the shuffle, because\\nif it\'s after the shuffle, everything gets frozen. So all the randomization\\nthat you get out of shuffle you lose, because\\nevery subsequent time, you\'re just going to be reading\\nthe same exact order again and again. So that\'s why we introduce it\\nat that stage in the pipeline. So Snapshot, we\\ndeveloped it internally. There are internal\\nusers and teams that are using it and\\nderiving benefit out of it. And now we\'re bringing it\\nto the open source world. We published an RFC, which\\nhas more information about it and some other\\ntechnical details. And this will be available\\nin TensorFlow 2.3, but I believe it will be\\navailable in the [INAUDIBLE] shortly. So remember, I talked\\nabout two ideas. So the second idea is that,\\nnow, not all computation is reusable, so because suppose\\nyou had someone randomized crops in there. And if you wrote that to\\ndisk and read them back, you\'d, again, lose\\nthat randomization. And so a snapshot\\nis probably not applicable in that scenario. So the second idea is to be able\\nto distribute the computation. So the initial setup is that\\nyou have one host CPU, which is driving a bunch of\\nthese accelerators, but now you can offload\\nthis computation from this host to\\nmaybe a cluster. And now you can\\nutilize the ability and the computational\\npower that you have for all these\\ndifferent workers to be able to feed the\\nhost, so that you\'re not bottlenecked on the input\\npre-processing anymore and things move fast. This is tf.data service. It\'s a tf.data feature\\nthat allows you to scale your workload horizontally. So if you\'re seeing a slowness\\nin your input pre-processing, you can start adding workers,\\nand it\'ll just scale up. It\'s got a master-worker\\narchitecture, where the master drives the work\\nfor the different workers and it gives you\\nfault tolerance. So if one of the workers\\nfails, you\'re still good and you still can make progress. So let\'s see how you can use the\\ntf.data service for the example that we have. So here, instead of having sort\\nof an expensive pre-processing, let\'s say you have some\\nrandomized pre-processing. So now this is not snapshotable,\\nbecause if you snapshot, then you lose the randomization. So we\'ll provide\\nyou a binary which allows you to run the data\\nservice on the cluster setup manager that you like, whether\\nit\'s Kubernetes or Cloud or something like that. And then once you have\\nthat up and running, you can just add a\\ndistribute transformation to your tf.data pipeline and\\nprovide the master address. Anything before the\\ndistribute transformation would now get run on the\\ncluster that you have set up and everything after\\nwill run on the host. And so this allows you\\nto sort of scale up. Again, note that\\nbecause we are not doing any kind of\\nfreezing of the data, we can output this\\ntransformation as late as possible in there. So notice that I\'ve put it after\\nthe shuffle transformation. The service, like\\nSnapshot, has been developed with internal users. They\'ve been using it. And it\'s been, like, a\\ngame-changer in terms of [INAUDIBLE] utilization. And now, again, we\'re\\nbringing it to you. And so we published an RFC,\\nwhich was well-received, and this should be\\navailable in 2.3 for you to play around with. So to summarize, what\\ndid I talk about today? So as with various trends\\nin hardware and software, we\'ve ended up in a scenario\\nwhere a lot of input machine learning jobs are\\ngetting bottlenecked on input pre-processing. And I\'ve told\\nabout two solutions that tf.data team\\nhas been working on to help you solve\\nthis bottleneck. First is Snapshot,\\nwhich allows you to reuse your pre-processing,\\nso that you don\'t have to do it multiple times. And the second is\\nthe tf.data service, which allows you to distribute\\nthis computation to a cluster, so that you get the\\nscale-up that you need. I hope you play around with\\nthese and give us feedback. And thank you for your time. [MUSIC PLAYING]"", metadata={\'source\': \'n7byMbl2VUQ\'})]""""""']","{'https://stackoverflow.com/questions/58663198/does-tf-data-dataset-take-return-random-sample', 'https://stackoverflow.com/questions/47067401/how-to-iterate-a-dataset-several-times-using-tensorflows-dataset-api', 'https://stackoverflow.com/questions/66874943/why-iterations-over-the-same-tf-data-dataset-give-different-data-each-iteration', 'https://stackoverflow.com/questions/51995267/what-is-the-mechanism-for-tf-data-dataset-shuffle'}","['""""""edit: twice\n\n\n\n@NicolasGervais - perhaps one could imagine a scenario where the shuffling is defined once and is used for every iteration. @jakub ah yes it makes sense from that perspective\n\n\n\nThis is because the data files are shuffled and the dataset is shuffled with dataset.shuffle(). With dataset.shuffle(), the data will be shuffled in a different way on each iteration by default. One can remove shuffle_files=True and set the argument reshuffle_each_iteration=False to prevent reshuffling on different iterations. The .take() function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them. # Construct a tf.data.Dataset ds = tfds.load(\'mnist\', split=\'train\', shuffle_files=False) # Build your input pipeline ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE) single_batch_dataset = ds.take(1) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label)\n\ntf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64) tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)\n\n\n\n""""""', '""""""edit: twice\n\n\n\n@NicolasGervais - perhaps one could imagine a scenario where the shuffling is defined once and is used for every iteration. @jakub ah yes it makes sense from that perspective\n\n\n\nThis is because the data files are shuffled and the dataset is shuffled with dataset.shuffle(). With dataset.shuffle(), the data will be shuffled in a different way on each iteration by default. One can remove shuffle_files=True and set the argument reshuffle_each_iteration=False to prevent reshuffling on different iterations. The .take() function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them. # Construct a tf.data.Dataset ds = tfds.load(\'mnist\', split=\'train\', shuffle_files=False) # Build your input pipeline ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE) single_batch_dataset = ds.take(1) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label)\n\ntf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64) tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)\n\n\n\n""""""', '""""""edit: twice\n\n\n\n@NicolasGervais - perhaps one could imagine a scenario where the shuffling is defined once and is used for every iteration. @jakub ah yes it makes sense from that perspective\n\n\n\nThis is because the data files are shuffled and the dataset is shuffled with dataset.shuffle(). With dataset.shuffle(), the data will be shuffled in a different way on each iteration by default. One can remove shuffle_files=True and set the argument reshuffle_each_iteration=False to prevent reshuffling on different iterations. The .take() function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them. # Construct a tf.data.Dataset ds = tfds.load(\'mnist\', split=\'train\', shuffle_files=False) # Build your input pipeline ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE) single_batch_dataset = ds.take(1) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label)\n\ntf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64) tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)\n\n\n\n""""""', '""""""edit: twice\n\n\n\n@NicolasGervais - perhaps one could imagine a scenario where the shuffling is defined once and is used for every iteration. @jakub ah yes it makes sense from that perspective\n\n\n\nThis is because the data files are shuffled and the dataset is shuffled with dataset.shuffle(). With dataset.shuffle(), the data will be shuffled in a different way on each iteration by default. One can remove shuffle_files=True and set the argument reshuffle_each_iteration=False to prevent reshuffling on different iterations. The .take() function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them. # Construct a tf.data.Dataset ds = tfds.load(\'mnist\', split=\'train\', shuffle_files=False) # Build your input pipeline ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE) single_batch_dataset = ds.take(1) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label)\n\ntf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64) tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)\n\n\n\n""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nHow to iterate a dataset several times using TensorFlow\'s Dataset API? Asked 6 years, 8 months ago\n\nModified 4 years, 5 months ago\n\nHow to output the value in a dataset several times? (dataset is created by Dataset API of TensorFlow)\n\nimport tensorflow as tf dataset = tf.contrib.data.Dataset.range(100) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() sess = tf.Session() epoch = 10 for i in range(epoch): for j in range(100): value = sess.run(next_element) assert j == value print(j)\n\ntensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_INT64], _device=""/job:localhost/replica:0/task:0/cpu:0""](OneShotIterator)]]\n\nHow to make this work? First of all I advice you to read Data Set Guide.""""""']"
60398554,tf.keras.Model,example required,"Should we apply repeat, batch shuffle to tf.data.Dataset when passing it to fit function?","<p>I still don't after having read documentation about <code>tf.keras.Model.fit</code> and <code>tf.data.Dataset</code>, when passing <code>tf.data.Dataset</code> to fit function, should I call <code>repeat</code> and <code>batch</code> on the dataset object or should I provide the <code>batch_size</code> and <code>epochs</code> arguments to fit instead? or both? Should I apply the same treatment to the validation set?</p>

<p>And while I'm here, can I <code>shuffle</code> the dataset before the <code>fit</code>? (seems like it's an obvious yes)
If so, before, after calling <code>Dataset.batch</code> and <code>Dataset.repeat</code> (if calling them)?</p>

<p><strong>Edit:</strong> When using <code>batch_size</code> argument, and without having called <code>Dataset.batch(batch_size)</code> previously, I am getting the following error:</p>

<pre><code>ValueError: The `batch_size` argument must not be specified for the given input type.
Received input: &lt;MapDataset shapes: ((&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;), (&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;)), 
types: ((tf.float32, tf.float32, tf.float32, tf.float32), (tf.float32, tf.float32, tf.float32))&gt;, 
batch_size: 1
</code></pre>

<p>Thanks</p>
","<p>There's different ways to do what you want here, but the one I always use is: </p>

<pre><code>batch_size = 32
ds = tf.Dataset()
ds = ds.shuffle(len_ds)
train_ds = ds.take(0.8*len_ds)
train_ds = train_ds.repeat().batch(batch_size)
validation_ds = ds.skip(0.8*len_ds)
validation_ds = train_ds.repeat().batch(batch_size)
model.fit(train_ds,
          steps_per_epoch = len_train_ds // batch_size,
          validation_data = validation_ds,
          validation_steps = len_validation_ds // batch_size,
          epochs = 5)
</code></pre>

<p>This way you have access to all the variables after model fitting as well, for example if you want to visualize the validation set, you can. This is not really possible with <code>validation_split</code>. If you remove <code>.batch(batch_size)</code>, you should remove the <code>// batch_size</code>s, but I would leave them, as it clearer what is happening now.</p>

<p>You always have to provide epochs.</p>

<p>Calculating the length of your train/validation sets requires you to loop over them: </p>

<pre><code>len_train_ds = 0
for i in train_ds:
  len_train_ds += 1
</code></pre>

<p>if in <code>tf.Dataset</code> form.</p>
","<pre><code>batch_size = 32
ds = tf.Dataset()
ds = ds.shuffle(len_ds)
train_ds = ds.take(0.8*len_ds)
train_ds = train_ds.repeat().batch(batch_size)
validation_ds = ds.skip(0.8*len_ds)
validation_ds = train_ds.repeat().batch(batch_size)
model.fit(train_ds,
          steps_per_epoch = len_train_ds // batch_size,
          validation_data = validation_ds,
          validation_steps = len_validation_ds // batch_size,
          epochs = 5)
</code></pre>","['How to use tf.data.Dataset with tf.keras.Model.fit?', 'Should I call repeat and batch on tf.data.Dataset before passing to tf.keras.Model.fit?', 'How to handle batch_size and epochs arguments when using tf.data.Dataset with tf.keras.Model.fit?', 'How to prepare validation set when using tf.data.Dataset with tf.keras.Model.fit?', 'Can I shuffle tf.data.Dataset before using it with tf.keras.Model.fit?', 'When to call shuffle, batch, and repeat on tf.data.Dataset for training with tf.keras.Model.fit?', 'Error handling for batch_size argument in tf.keras.Model.fit with tf.data.Dataset']","['When using tf.data.Dataset with tf.keras.Model.fit, should I call repeat and batch on the dataset object or provide batch_size and epochs arguments to fit?', 'Should I apply the same treatment to the validation set when using tf.data.Dataset with tf.keras.Model.fit?', 'Can I shuffle the dataset before calling fit in TensorFlow? If so, should I shuffle before or after calling Dataset.batch and Dataset.repeat?', ""What does the error 'ValueError: The `batch_size` argument must not be specified for the given input type' mean when using tf.data.Dataset with tf.keras.Model.fit?""]","{'https://www.youtube.com/watch?v=dzoh8cfnvnI', 'https://www.youtube.com/watch?v=U8Ixc2OLSkQ'}","['""""""[Document(page_content=""hey I\'m maybe from deep lizard in this episode we\'ll demonstrate how we can use tensorflow scarus API to create a validation set on the fly during training before we demonstrate how to build a validation set using Kerris let\'s first talk about what exactly a validation set is so whenever we train a model our hope is that when we train it that we see good results from the training output that we have low loss and high accuracy but we don\'t ever train a model just for the sake of training it we want to take that model and hopefully be able to use it in some way on data that it wasn\'t necessarily exposed to during the training process and although this new data is data that the models never seen before the hope is that the model will be good enough to be able to generalize well on this new data and give accurate predictions for it we can actually get an understanding of how well our model is generalizing by introducing a validation set during the training process to create a validation set before training begins we can choose to take a subset of the training set and then separate it into a separate set labeled as validation data and then during the training process the model will only train on the training data and then we\'ll validate on the separated validation data so what do we mean by validating well essentially if we have the addition of a validation set then during training the model will be learning the features of the training set just as we\'ve already seen but in addition in each epoch after the model has gone through the actual training process it\'ll take what it\'s learned from the training data and then validate by predicting on the data in the validation set using only what it\'s learned from the training data though so then during the training process when we look at the output of the accuracy and loss not only will we be seeing that accuracy and loss computed for the training set we\'ll also see that computed on the validation set it\'s important to understand though that the model is only learning on or training on the training data it\'s not taking the validation set into account during training the validation set is just for us to be able to see how well the model is able to predict on data that it was not exposed to during the training process in other words it allows us to see how general our model is how well it\'s able to generalize on data that is not included in the training data so knowing this information will allow us to see if our model is running into the famous overfitting problem so overfitting occurs when the model has learned the specific features of the training set really well but it\'s unable to generalize on data it hasn\'t seen before so if while training we see that the model is giving really good results for the training set but less than good results for the validation set then we can conclude that we have an overfitting problem and then take the steps necessary to combat that specific issue if you\'d like to see the overfitting problem covered in more detail then there is an episode for that in the deep learning fundamentals course all right so now let\'s discuss how we can create and use a validation set with a Karass sequential model there\'s actually two ways that we can create and work with validation sets with a sequential model and the first way is to have a completely separate validation set from the training set and then to pass that validation set to the model in the fit function there is a validation data parameter and so we can just set that equal to the structure that is holding our validation data and there\'s a write-up in the corresponding blog for this episode that contains more details about the format that that data needs to be in but we\'re going to actually only focus on the second way of creating and using a validation set this step actually saves us a step because we don\'t have to explicitly go through the creation process of the validation set instead we can get carers to create it for us all right so we\'re back in our Jupiter notebook right where we left off last time and we\'re here on the model dot Fit function and recall this is what we use last time to train our model now I\'ve already edited this cell to include this new parameter which is validation split and what validation split does is it does what it sounds like it splits out a portion of the training set into a validation set so we just set this to a number between 0 and 1 so just a fractional number to tell Karis how much of the training set we need to split out into the validation set so here I\'m splitting out 10% of the training set so it\'s important to note that whenever we do this the validation set is completely held out of the training set so the training samples that we remove from the training set into validation set are no longer contained within the training data any longer so using this approach the validation set will be created on the fly whenever we call the fit function now there\'s one other thing worth mentioning here and remember last time I discussed this shuffle equals true parameter and I said that by default the training set is shuffled whenever we call fit so this shuffle equals true is already set by default but I was just bringing it up to let you know that that the training set is being shuffled so that is a good thing we want the training set to be shuffled but whenever we call validation split in this way this split occurs before the training set is shuffled meaning that if we created our training set and say we put all of the sick patients first and then the non sick patients second and then we say that we want to split off the last 10% of the training data to be our validation data it\'s going to take the last 10% of the training data and therefore it could just take all of the the second group that we put in the training set and not get any of the first group so I wanted to mention that because although the training data is being shuffled with the fit function if you haven\'t already shuffled your training data before you pass it to fit then you also use the split parameter it\'s important to know that your validation set is going to be the last X percent of your training set and therefore may not be shuffled and may yield some strange results because you think that everything has been shuffled when really it\'s only the training set has been shuffled after the validation set has been taken out so just keep that in mind the way that we created our training set before this episode we actually shuffled the training data before it\'s ever passed to the fit function so in the future whenever you\'re working with data it\'s a good idea to make sure that your data is also shuffled beforehand especially if you\'re going to be making use of the validation split parameter to create a validation set all right so now we\'ll run this cell one more time calling the fit function but this time not only will we see loss and accuracy metrics for the training set we\'ll also see these metrics for the validation set all right so the model has just finished running it\'s 30 epochs and now we see both the loss and accuracy on the left-hand side as well as the validation loss and validation accuracy on the right-hand side so we can see let\'s just look at the accuracy between the two they\'re both starting at around the same 50 percent mark and going up gradually around the same rate so we just scroll all the way to our last epoch we can see that the accuracy and validation accuracy are pretty similar with only one percent difference between the two and yeah the loss values are similar as well so we can see in this example that our model is not overfitting it is actually performing pretty well or just as well rather on the validation set as it is on the training set so our model is generalizing well if however we saw that the opposite case was true and our validation accuracy was seriously lagging behind our training accuracy then we know that we have a overfitting problem and we would need to take steps to address that issue alright so we\'ve now seen how to train the model how to validate the model and how to make use of both training and validation that\'s in the next episode we\'re going to see how to make use of a third data set the test data set to use the model for inference by the way we are currently in Vietnam filming this episode if you didn\'t know we also have a vlog channel where we document our travels and share a little bit more about ourselves so check that out at people\'s our vlog on YouTube also be sure to check out the corresponding blog for this episode along with other resources available on deep loser calm and check out the people\'s archive mine where you can gain exclusive access to perks and rewards thanks for contributing to collective intelligence I\'ll see you next time [Music] [Music]"", metadata={\'source\': \'U8Ixc2OLSkQ\'})]""""""', '""""""[Document(page_content=""[Music] in this video we\'re going to be demonstrating how to use care us to create a validation set in our previous video we showed how to train the model that we\'ve been working with in the past several videos of this playlist and we\'re going to continue working with the same model so as a prerequisite to this video I would recommend you watching all of the videos in my getting started with Karis playlist first so that you can fully understand where we are and what we\'re dealing with in this video the videos that will get you up to speed to where we are now we\'ll cover the prerequisites need to start working with Karos how to pre-process data for training building a Karass model and training a Karos model so assuming that these prerequisites have been met we\'re now going to show how to create a validation set in this video so before we show how to do that we need to discuss exactly what a validation set is and before directly answering that let\'s start with a bit of background so we\'ve built our training set that contains all of our samples and during each epoch our model is going to be getting trained over and over and over again on that data and continuing to learn the features of that data so the hope is then later that you can take this model and apply it to new data and the model will be able to accurately predict on data that it\'s not seen before based solely on the data that it was trained on so with the validation set you\'re essentially taking some percentage of your existing samples in your training set and saying no you\'re not going to train on these samples instead you\'re going to validate on them so you want to train on most of the data that you have and your training set and then you want to take data that you\'ve stored elsewhere and a validation set and have the model predict on that data during training and look and see how well it did so it\'s learning over and over again the features of the training set and then during each epoch when it\'s being trained it\'s going to be predicting on the validation set so moving forward you\'re not going to just be seeing the loss in accuracy on your training set you\'re also going to see loss and accuracy on your validation set as well the thing that\'s cool about this is that your models not seeing this validation data but or since it wasn\'t included in the training set so essentially it\'s brand-new data so the models taking what it\'s learned from that training and then trying to generalize and make a prediction on data that it\'s not seen before in the validation set and this allows you to see how well your model generalizes it also helps you make sure that you\'re not overfitting and over fitting is when your model is only learning the specificities to the training data and it\'s not able to generalize well on data outside of the training set all right so now that we\'ve got down what a validation set is how do we actually create one so there\'s two ways one is that you can just have a structure that holds your validation set you would tell the fit function which is the function that we call when we say model dot fit you would tell that about your validation set just like you would the training set in labels so let\'s just see how that would look so here\'s what we\'re calling fit like we did in previous videos so now if I created a set called valid set I would set it equal to a structure that looks like this it would be an array and each element in this array would be a tuple that would have a sample in its corresponding label and the next element would have a sample in a corresponding label and these samples and labels are not the ones that are included in your existing training set and labels this is going to be separate data so if we did that then whenever we called model dot fit we would pass in validation data equals and then we would pass in our variable here that we called a valid set and then whenever we ran this function the model would be training on everything in this scaled trained samples here along with its corresponding train labels and it would be validating on our valid set there\'s another way within Kerris that you can create a validation set and it\'s a bit simpler to me so let\'s get this out of here we\'re not going to use that anymore and rather than specifying validation data equals valid set we are going to specify validation split equals 0.1 so what is this doing caris is going to look at the scaled trained samples along with its course labels and it\'s going to split out 10% in this case because I\'m supposed to find point 1 but you can specify any fraction between 0 & 1 it\'s going to split out whatever you specify here into a validation set that\'s going to basically look like that validation set that we just created as an example so it\'s going to take this validation data the 10% that it\'s splitting off from the training samples it\'s going to hold it out and whatever it trains it\'s not going to be training on this 10% here it\'s going to be training on our scale train samples with their corresponding labels and then it\'s going to be validating on the 10% that you\'ve split out so what we\'re going to do now is just run this cell again so before this is what we saw we saw we have loss and accuracy being displayed for each epoch and we ran 20 epochs here we had lost going steadily down and accuracy going steadily up now let\'s see what it looks like whenever we run the same exact set function the only thing that we\'ve changed is that we added this validation split equals zero point 1 parameter all right so now we see we have similar output but we have two new attributes that are being shown so along with the loss and accuracy as we were seeing last time we now have Val loss and Val accuracy which is the loss in accuracy that we\'re getting only on this 10% of our data which is in our validation data set and if we look here we have this output that says training on 1890 samples validating on 210 samples so I have 20 100 samples total and I specified the validation split to be 10% so that\'s where this 210 is being calculated from so if we look now solely at the Lawson accuracy what we had last time we see it we\'re starting at 0.7 three on the loss and we are steadily going down until we reach about 0.3 0 on the accuracy we\'re starting at about 50% and we are steadily going up to again reaching about 93% all right so that is similar to what we saw last time when we didn\'t have a validation set now if we look at our validation loss so our loss calculated only on these 210 samples that are being validated on on each run through the data on each epoch we\'re going from point seven one loss and we are steadily declining until we reach about point one nine and then with the accuracy we\'re starting at about 50% steadily climbing until we\'re actually reaching about 100% accuracy on our validation set so like I said this is really good for you to be able to have to see how well your model is generalizing on data that it\'s not been trained on and which is ultimately able to tell you if your model is overfitting to your training set or not in this case we see that our models not overfitting and the reason why is because we have similar results both on our training loss and accuracy as well as our validation loss and accuracy so an indication of overfitting would be if our model was continuously going up in accuracy and down in loss for our training loss in accuracy but our validation loss and accuracy we\'re not doing so well so maybe they\'re stalling out or maybe the accuracy can\'t get past 50% that would be a good indication that our model is learning only the specificities of our training data and it\'s not generalizing well on data that it\'s not seen before now one last thing that I\'d like to point out before we wrap up here is whenever we specify this validation split equals 10% recall how I mentioned last time this shuffle equals true parameter means that all of the data that your model is training on it\'s going to be shuffled over each epoch that\'s not going to be true for your validation data so the validation split is actually taking whatever you specify here in my case 10% is going to take literally the last 10% of the data that are in your training samples so it\'s not going to be shuffled it\'s going to be the same data every time for over every run and it\'s going to be the last 10% that is here so because of that I did need to make a quick change in how I was generating the sample data that we used here so if you were following along from the beginning and actually writing the same code and using the same data as I was and used the data that I generated in the pre-processing data video then I\'m just going to scroll back up to the top of this notebook and show you the change that I made so that you can pause the video rearrange your code in a similar fashion as well and like I said the only reason I did it is so that the data at the end of my training samples was at all uniform because then our validation split wouldn\'t be a very accurate depiction it would all be uniform data and that our model wouldn\'t be able to validate really well on that so if we scroll back up here this is where I generated the sample data so I\'ll just leave this on the screen here so that you can maybe pause the video and compare what I have in this cell to what you wrote previously so that you can rearrange the only thing that I did actually is change the order in which these four loops run so I\'ll let you take a look at that let me know if you have any questions about that step in the comments below in future videos we\'re going to continue learning new techniques that we can use with Kara\'s we\'re going to start building more complex models and convolutional neural networks so I hope you stick around for those and I hope you found this video helpful if you did please like the video subscribe suggest and comment and thanks for watching [Music]"", metadata={\'source\': \'dzoh8cfnvnI\'})]""""""']","{'https://stackoverflow.com/questions/50184144/shuffle-in-the-model-fit-of-keras', 'https://stackoverflow.com/questions/64356209/how-does-model-fit-methods-shuffle-deals-with-batches-when-using-a-tf-data-da', 'https://stackoverflow.com/questions/50955798/keras-model-fit-with-tf-dataset-api-validation-data'}","['""""""How does Model.fit() method\'s shuffle deals with Batches when using a tf.data.Dataset? Asked 3 years, 5 months ago\n\nModified 3 years, 5 months ago\n\nI am using tensorflow 2. When using the Model.fit() method with a tf.data.Dataset, the argument \'batch_size\' is ignored. Thus to train my model on batches, I have to first change my dataset of samples into a dataset of batches of samples by calling tf.data.Dataset.batch(batch_size). Then, after reading the documentation, I don\'t understand clearly how the .fit() method will shuffle my dataset at each epoch. Since my dataset is a dataset of batches, will it shuffle the batches among each other (the batches remain unchanged) ? Or will it shuffle all the samples and then regroup them into new batches (which is the desired behaviour) ? Thanks a lot for your help. The shuffle parameter has no effect on the fit function when using the tf.data.Dataset API. If we read the documentation (emphasis is mine) :\n\nshuffle: Boolean (whether to shuffle the training data before each epoch) or str (for \'batch\'). This argument is ignored when x is a generator. \'batch\' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None. It\'s not super clear, but we can have a hint that the shuffle argument will be ignored when using a tf.data.Dataset, as it behave like a generator. To be certain, lets dive in the code.""""""', '""""""There is described all the details of DataSet API. Your question is about iterating over the data several times. Here are two solutions for that:\n\nIterating all epochs at once, no information about end of individual epochs\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 j = 0 while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 if j > 99: # new epoch j = 0 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\nSecond option inform you about ending each of epoch, so you can ex. check validation loss:\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) iterator = dataset.make_initializable_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 for e in range(epoch): print (""Epoch: "", e) j = 0 sess.run(iterator.initializer) while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\n\n\nIf your tensorflow version is 1.3+, I recommend the high-level API tf.train.MonitoredTrainingSession. The sess created by this API can automatically detect tf.errors.OutOfRangeError with sess.should_stop(). For most of training situations, you need to shuffle data and get a batch each step, I have added these in the following code. import tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=32) # batch_size=1 if you want to get only one element per step dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() num_batch = 0 with tf.train.MonitoredTrainingSession() as sess: while not sess.should_stop(): value = sess.run(next_element) num_batch += 1 print(""Num Batch: "", num_batch)\n\n\n\n\n\nwhile True: try: print(sess.run(value)) except tf.errors.OutOfRangeError: break\n\nWhenever the dataset iterator reaches the end of the data, it will raise tf.errors.OutOfRangeError, you can catch it with except and start the dataset from the beginning. Grigor CarranGrigor Carran\n\n1\n\nYou should explain your code or include comments as well\n\n\n\nSimilar to Toms answer, for tensorflow 2+, you can use the following high-level API calls (the code proposed in his answer is deprecated in tensorflow 2+):\n\nepoch = 10 batch_size = 32 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=batch_size) dataset = dataset.repeat(epoch) num_batch = 0 for batch in dataset: num_batch += 1 print(""Num Batch: "", num_batch)\n\nA helpful call to track progress is the total number of batches that will be iterated over (to be used after the batch and the repeat calls):\n\nnum_batches = tf.data.experimental.cardinality(dataset)\n\nNote that currently (tensorflow 2.1), the cardinality method is still experimental. """"""', '""""""How does Model.fit() method\'s shuffle deals with Batches when using a tf.data.Dataset? Asked 3 years, 5 months ago\n\nModified 3 years, 5 months ago\n\nI am using tensorflow 2. When using the Model.fit() method with a tf.data.Dataset, the argument \'batch_size\' is ignored. Thus to train my model on batches, I have to first change my dataset of samples into a dataset of batches of samples by calling tf.data.Dataset.batch(batch_size). Then, after reading the documentation, I don\'t understand clearly how the .fit() method will shuffle my dataset at each epoch. Since my dataset is a dataset of batches, will it shuffle the batches among each other (the batches remain unchanged) ? Or will it shuffle all the samples and then regroup them into new batches (which is the desired behaviour) ? Thanks a lot for your help. The shuffle parameter has no effect on the fit function when using the tf.data.Dataset API. If we read the documentation (emphasis is mine) :\n\nshuffle: Boolean (whether to shuffle the training data before each epoch) or str (for \'batch\'). This argument is ignored when x is a generator. \'batch\' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None. It\'s not super clear, but we can have a hint that the shuffle argument will be ignored when using a tf.data.Dataset, as it behave like a generator. To be certain, lets dive in the code.""""""', '""""""There is described all the details of DataSet API. Your question is about iterating over the data several times. Here are two solutions for that:\n\nIterating all epochs at once, no information about end of individual epochs\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 j = 0 while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 if j > 99: # new epoch j = 0 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\nSecond option inform you about ending each of epoch, so you can ex. check validation loss:\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) iterator = dataset.make_initializable_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 for e in range(epoch): print (""Epoch: "", e) j = 0 sess.run(iterator.initializer) while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\n\n\nIf your tensorflow version is 1.3+, I recommend the high-level API tf.train.MonitoredTrainingSession. The sess created by this API can automatically detect tf.errors.OutOfRangeError with sess.should_stop(). For most of training situations, you need to shuffle data and get a batch each step, I have added these in the following code. import tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=32) # batch_size=1 if you want to get only one element per step dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() num_batch = 0 with tf.train.MonitoredTrainingSession() as sess: while not sess.should_stop(): value = sess.run(next_element) num_batch += 1 print(""Num Batch: "", num_batch)\n\n\n\n\n\nwhile True: try: print(sess.run(value)) except tf.errors.OutOfRangeError: break\n\nWhenever the dataset iterator reaches the end of the data, it will raise tf.errors.OutOfRangeError, you can catch it with except and start the dataset from the beginning. Grigor CarranGrigor Carran\n\n1\n\nYou should explain your code or include comments as well\n\n\n\nSimilar to Toms answer, for tensorflow 2+, you can use the following high-level API calls (the code proposed in his answer is deprecated in tensorflow 2+):\n\nepoch = 10 batch_size = 32 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=batch_size) dataset = dataset.repeat(epoch) num_batch = 0 for batch in dataset: num_batch += 1 print(""Num Batch: "", num_batch)\n\nA helpful call to track progress is the total number of batches that will be iterated over (to be used after the batch and the repeat calls):\n\nnum_batches = tf.data.experimental.cardinality(dataset)\n\nNote that currently (tensorflow 2.1), the cardinality method is still experimental. """"""', '""""""How does Model.fit() method\'s shuffle deals with Batches when using a tf.data.Dataset? Asked 3 years, 5 months ago\n\nModified 3 years, 5 months ago\n\nI am using tensorflow 2. When using the Model.fit() method with a tf.data.Dataset, the argument \'batch_size\' is ignored. Thus to train my model on batches, I have to first change my dataset of samples into a dataset of batches of samples by calling tf.data.Dataset.batch(batch_size). Then, after reading the documentation, I don\'t understand clearly how the .fit() method will shuffle my dataset at each epoch. Since my dataset is a dataset of batches, will it shuffle the batches among each other (the batches remain unchanged) ? Or will it shuffle all the samples and then regroup them into new batches (which is the desired behaviour) ? Thanks a lot for your help. The shuffle parameter has no effect on the fit function when using the tf.data.Dataset API. If we read the documentation (emphasis is mine) :\n\nshuffle: Boolean (whether to shuffle the training data before each epoch) or str (for \'batch\'). This argument is ignored when x is a generator. \'batch\' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None. It\'s not super clear, but we can have a hint that the shuffle argument will be ignored when using a tf.data.Dataset, as it behave like a generator. To be certain, lets dive in the code.""""""', '"""""" Keras model.fit() with tf.dataset API + validation_data\n\nAsked 5 years, 11 months ago\n\nModified 5 years, 1 month ago\n\nSo I have got my keras model to work with a tf.Dataset through the following code:\n\n# Initialize batch generators(returns tf.Dataset) batch_train = build_features.get_train_batches(batch_size=batch_size) # Create TensorFlow Iterator object iterator = batch_train.make_one_shot_iterator() dataset_inputs, dataset_labels = iterator.get_next() # Create Model logits = .....(some layers) keras.models.Model(inputs=dataset_inputs, outputs=logits) # Train network model.compile(optimizer=train_opt, loss=model_loss, target_tensors=[dataset_labels]) model.fit(epochs=epochs, steps_per_epoch=num_batches, callbacks=callbacks, verbose=1)\n\nhowever when I try to pass validation_data parameter to the model. fit it tells me that I cannot use it with the generator. Is there a way to use validation while using tf.Dataset\n\nfor example in tensorflow I could do the following:\n\n# initialize batch generators batch_train = build_features.get_train_batches(batch_size=batch_size) batch_valid = build_features.get_valid_batches(batch_size=batch_size) # create TensorFlow Iterator object iterator = tf.data.Iterator.from_structure(batch_train.output_types, batch_train.output_shapes) # create two initialization ops to switch between the datasets init_op_train = iterator.make_initializer(batch_train) init_op_valid = iterator.make_initializer(batch_valid)\n\nthen just use sess.run(init_op_train) and sess.run(init_op_valid) to switch between the datasets\n\nI tried implementing a callback that does just that (switch to validation set, predict and back) but it tells me I can\'t use model.predict in a callback\n\ncan someone help me get validation working with Keras+Tf.Dataset\n\nedit: incorporate answer into the code\n\nso FINALLY what worked for me, thanks to the selected answer is:\n\n# Initialize batch generators(returns tf.Dataset) batch_train = # returns tf.Dataset batch_valid = # returns tf.Dataset # Create TensorFlow Iterator object and wrap it in a generator itr_train = make_iterator(batch_train) itr_valid = make_iterator(batch_train) # Create Model logits = # the keras model keras.models.Model(inputs=dataset_inputs, outputs=logits) # Train network model.compile(optimizer=train_opt, loss=model_loss, target_tensors=[dataset_labels]) model.fit_generator( generator=itr_train, validation_data=itr_valid, validation_steps=batch_size, epochs=epochs, steps_per_epoch=num_batches, callbacks=cbs, verbose=1, workers=0) def make_iterator(dataset): iterator = dataset.make_one_shot_iterator() next_val = iterator.get_next() with K.get_session().as_default() as sess: while True: *inputs, labels = sess.run(next_val) yield inputs, labels\n\nThis doesn\'t introduce any overhead\n\nMark RofailMark Rofail\n\n 2\n\nAfter your change, how do you get dataset_inputs into model? I\'m not getting how line keras.models.Model(inputs=dataset_inputs, outputs=logits), and i\'m assuming this is the contents of the ""model"" variable, could you please complete the code, i have the exact same problem but can\'t seem to know how to apply your code, thanks in advance\n\n@mark rofail, I believe this line is incorrect and should receive batch_valid: itr_valid = make_iterator(batch_train)\n\n– Robert Lugg Mar 4, 2020 at 19:05\n\nI solved the problem by using fit_genertor. I found the solution here. I applied @Dat-Nguyen\'s solution. You need simply to create two iterators, one for training and one for validation and then create your own generator where you will extract batches from the dataset and provide the data in form of (batch_data, batch_labels) . Finally in model.fit_generator you will pass the train_generator and validation_generator. 8\n\nso I have to wrap tensorflow iterators in a python generator like: iterator = ds.make_one_shot_iterator() while True: next_val = iterator.get_next() yield sess.run(next_val)\n\n– Mark Rofail Jun 22, 2018 at 12:18\n\nHi, It is me this time asking you :). I am facing now another problem with fit_genertor which is I can get access to validation data. For example you want to evaluate the value of prediction at batch level, in order to accumulated them and then calculate the prediction for the whole epoch in order to use it for AUC metric. DO you have any idea how we can accomplish this? or I should open a new post for it. – W.""""""', '""""""There is described all the details of DataSet API. Your question is about iterating over the data several times. Here are two solutions for that:\n\nIterating all epochs at once, no information about end of individual epochs\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 j = 0 while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 if j > 99: # new epoch j = 0 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\nSecond option inform you about ending each of epoch, so you can ex. check validation loss:\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) iterator = dataset.make_initializable_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 for e in range(epoch): print (""Epoch: "", e) j = 0 sess.run(iterator.initializer) while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\n\n\nIf your tensorflow version is 1.3+, I recommend the high-level API tf.train.MonitoredTrainingSession. The sess created by this API can automatically detect tf.errors.OutOfRangeError with sess.should_stop(). For most of training situations, you need to shuffle data and get a batch each step, I have added these in the following code. import tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=32) # batch_size=1 if you want to get only one element per step dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() num_batch = 0 with tf.train.MonitoredTrainingSession() as sess: while not sess.should_stop(): value = sess.run(next_element) num_batch += 1 print(""Num Batch: "", num_batch)\n\n\n\n\n\nwhile True: try: print(sess.run(value)) except tf.errors.OutOfRangeError: break\n\nWhenever the dataset iterator reaches the end of the data, it will raise tf.errors.OutOfRangeError, you can catch it with except and start the dataset from the beginning. Grigor CarranGrigor Carran\n\n1\n\nYou should explain your code or include comments as well\n\n\n\nSimilar to Toms answer, for tensorflow 2+, you can use the following high-level API calls (the code proposed in his answer is deprecated in tensorflow 2+):\n\nepoch = 10 batch_size = 32 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=batch_size) dataset = dataset.repeat(epoch) num_batch = 0 for batch in dataset: num_batch += 1 print(""Num Batch: "", num_batch)\n\nA helpful call to track progress is the total number of batches that will be iterated over (to be used after the batch and the repeat calls):\n\nnum_batches = tf.data.experimental.cardinality(dataset)\n\nNote that currently (tensorflow 2.1), the cardinality method is still experimental. """"""', '""""""How does Model.fit() method\'s shuffle deals with Batches when using a tf.data.Dataset? Asked 3 years, 5 months ago\n\nModified 3 years, 5 months ago\n\nI am using tensorflow 2. When using the Model.fit() method with a tf.data.Dataset, the argument \'batch_size\' is ignored. Thus to train my model on batches, I have to first change my dataset of samples into a dataset of batches of samples by calling tf.data.Dataset.batch(batch_size). Then, after reading the documentation, I don\'t understand clearly how the .fit() method will shuffle my dataset at each epoch. Since my dataset is a dataset of batches, will it shuffle the batches among each other (the batches remain unchanged) ? Or will it shuffle all the samples and then regroup them into new batches (which is the desired behaviour) ? Thanks a lot for your help. The shuffle parameter has no effect on the fit function when using the tf.data.Dataset API. If we read the documentation (emphasis is mine) :\n\nshuffle: Boolean (whether to shuffle the training data before each epoch) or str (for \'batch\'). This argument is ignored when x is a generator. \'batch\' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None. It\'s not super clear, but we can have a hint that the shuffle argument will be ignored when using a tf.data.Dataset, as it behave like a generator. To be certain, lets dive in the code.""""""', '"""""" Keras model.fit() with tf.dataset API + validation_data\n\nAsked 5 years, 11 months ago\n\nModified 5 years, 1 month ago\n\nSo I have got my keras model to work with a tf.Dataset through the following code:\n\n# Initialize batch generators(returns tf.Dataset) batch_train = build_features.get_train_batches(batch_size=batch_size) # Create TensorFlow Iterator object iterator = batch_train.make_one_shot_iterator() dataset_inputs, dataset_labels = iterator.get_next() # Create Model logits = .....(some layers) keras.models.Model(inputs=dataset_inputs, outputs=logits) # Train network model.compile(optimizer=train_opt, loss=model_loss, target_tensors=[dataset_labels]) model.fit(epochs=epochs, steps_per_epoch=num_batches, callbacks=callbacks, verbose=1)\n\nhowever when I try to pass validation_data parameter to the model. fit it tells me that I cannot use it with the generator. Is there a way to use validation while using tf.Dataset\n\nfor example in tensorflow I could do the following:\n\n# initialize batch generators batch_train = build_features.get_train_batches(batch_size=batch_size) batch_valid = build_features.get_valid_batches(batch_size=batch_size) # create TensorFlow Iterator object iterator = tf.data.Iterator.from_structure(batch_train.output_types, batch_train.output_shapes) # create two initialization ops to switch between the datasets init_op_train = iterator.make_initializer(batch_train) init_op_valid = iterator.make_initializer(batch_valid)\n\nthen just use sess.run(init_op_train) and sess.run(init_op_valid) to switch between the datasets\n\nI tried implementing a callback that does just that (switch to validation set, predict and back) but it tells me I can\'t use model.predict in a callback\n\ncan someone help me get validation working with Keras+Tf.Dataset\n\nedit: incorporate answer into the code\n\nso FINALLY what worked for me, thanks to the selected answer is:\n\n# Initialize batch generators(returns tf.Dataset) batch_train = # returns tf.Dataset batch_valid = # returns tf.Dataset # Create TensorFlow Iterator object and wrap it in a generator itr_train = make_iterator(batch_train) itr_valid = make_iterator(batch_train) # Create Model logits = # the keras model keras.models.Model(inputs=dataset_inputs, outputs=logits) # Train network model.compile(optimizer=train_opt, loss=model_loss, target_tensors=[dataset_labels]) model.fit_generator( generator=itr_train, validation_data=itr_valid, validation_steps=batch_size, epochs=epochs, steps_per_epoch=num_batches, callbacks=cbs, verbose=1, workers=0) def make_iterator(dataset): iterator = dataset.make_one_shot_iterator() next_val = iterator.get_next() with K.get_session().as_default() as sess: while True: *inputs, labels = sess.run(next_val) yield inputs, labels\n\nThis doesn\'t introduce any overhead\n\nMark RofailMark Rofail\n\n 2\n\nAfter your change, how do you get dataset_inputs into model? I\'m not getting how line keras.models.Model(inputs=dataset_inputs, outputs=logits), and i\'m assuming this is the contents of the ""model"" variable, could you please complete the code, i have the exact same problem but can\'t seem to know how to apply your code, thanks in advance\n\n@mark rofail, I believe this line is incorrect and should receive batch_valid: itr_valid = make_iterator(batch_train)\n\n– Robert Lugg Mar 4, 2020 at 19:05\n\nI solved the problem by using fit_genertor. I found the solution here. I applied @Dat-Nguyen\'s solution. You need simply to create two iterators, one for training and one for validation and then create your own generator where you will extract batches from the dataset and provide the data in form of (batch_data, batch_labels) . Finally in model.fit_generator you will pass the train_generator and validation_generator. 8\n\nso I have to wrap tensorflow iterators in a python generator like: iterator = ds.make_one_shot_iterator() while True: next_val = iterator.get_next() yield sess.run(next_val)\n\n– Mark Rofail Jun 22, 2018 at 12:18\n\nHi, It is me this time asking you :). I am facing now another problem with fit_genertor which is I can get access to validation data. For example you want to evaluate the value of prediction at batch level, in order to accumulated them and then calculate the prediction for the whole epoch in order to use it for AUC metric. DO you have any idea how we can accomplish this? or I should open a new post for it. – W.""""""', '""""""There is described all the details of DataSet API. Your question is about iterating over the data several times. Here are two solutions for that:\n\nIterating all epochs at once, no information about end of individual epochs\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 j = 0 while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 if j > 99: # new epoch j = 0 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\nSecond option inform you about ending each of epoch, so you can ex. check validation loss:\n\nimport tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) iterator = dataset.make_initializable_iterator() next_element = iterator.get_next() sess = tf.Session() num_batch = 0 for e in range(epoch): print (""Epoch: "", e) j = 0 sess.run(iterator.initializer) while True: try: value = sess.run(next_element) assert j == value j += 1 num_batch += 1 except tf.errors.OutOfRangeError: break print (""Num Batch: "", num_batch)\n\n\n\nIf your tensorflow version is 1.3+, I recommend the high-level API tf.train.MonitoredTrainingSession. The sess created by this API can automatically detect tf.errors.OutOfRangeError with sess.should_stop(). For most of training situations, you need to shuffle data and get a batch each step, I have added these in the following code. import tensorflow as tf epoch = 10 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=32) # batch_size=1 if you want to get only one element per step dataset = dataset.repeat(epoch) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() num_batch = 0 with tf.train.MonitoredTrainingSession() as sess: while not sess.should_stop(): value = sess.run(next_element) num_batch += 1 print(""Num Batch: "", num_batch)\n\n\n\n\n\nwhile True: try: print(sess.run(value)) except tf.errors.OutOfRangeError: break\n\nWhenever the dataset iterator reaches the end of the data, it will raise tf.errors.OutOfRangeError, you can catch it with except and start the dataset from the beginning. Grigor CarranGrigor Carran\n\n1\n\nYou should explain your code or include comments as well\n\n\n\nSimilar to Toms answer, for tensorflow 2+, you can use the following high-level API calls (the code proposed in his answer is deprecated in tensorflow 2+):\n\nepoch = 10 batch_size = 32 dataset = tf.data.Dataset.range(100) dataset = dataset.shuffle(buffer_size=100) # comment this line if you don\'t want to shuffle data dataset = dataset.batch(batch_size=batch_size) dataset = dataset.repeat(epoch) num_batch = 0 for batch in dataset: num_batch += 1 print(""Num Batch: "", num_batch)\n\nA helpful call to track progress is the total number of batches that will be iterated over (to be used after the batch and the repeat calls):\n\nnum_batches = tf.data.experimental.cardinality(dataset)\n\nNote that currently (tensorflow 2.1), the cardinality method is still experimental. """"""']"
55909188,tf.nn.conv2d,example required,How can I apply a TensorFlow 2D Convolution (tf.nn.conv2d) to a single (non-batch) 2D image?,"<p>I would like to use the function <code>tf.nn.conv2d()</code> on a <strong>single</strong> image example, but the TensorFlow documentation seems to only mention applying this transformation to a <strong>batch</strong> of images. </p>

<p>The docs mention that the input image must be of shape <code>[batch, in_height, in_width, in_channels]</code> and the kernel must be of shape <code>[filter_height, filter_width, in_channels, out_channels]</code>. However, what is the most straightforward way to achieve 2D convolution with input shape <code>[in_height, in_width, in_channels]</code>?</p>

<p>Here is an example of the current approach, where <code>img</code> has shape (height, width, channels):</p>

<pre><code>img = tf.random_uniform((10,10,3))  # a single image
img = tf.nn.conv2d([img], kernel)[0] # creating a batch of 1, then indexing the single example
</code></pre>

<p>I am reshaping the input as follows:</p>

<p><code>[in_height, in_width, in_channels]-&gt;[1, in_height, in_width, in_channels]-&gt;[in_height, in_width, in_channels]</code> </p>

<p>This feels like an unnecessary and costly operation when I am only interested in transforming one example.</p>

<p>Is there a simple/standard way to do this that doesn't involve reshaping?</p>
","<p>AFAIK there is no way around it. It seems (<a href=""https://stackoverflow.com/questions/50779869/does-tensorflow-tf-slice-incur-allocation-and-or-memory-copy"">here</a> and <a href=""https://stackoverflow.com/questions/53398721/tensorflow-can-reshape-create-a-copy"">here</a>) that the first operation creates a copy (someone correct me if I'm wrong). You may use <a href=""https://www.tensorflow.org/api_docs/python/tf/expand_dims"" rel=""nofollow noreferrer""><code>tf.expand_dims</code></a> instead though, it's IMO more readable because of it's verbosity.</p>

<p>On the other hand, taking <code>0</code> element from the tensor should not perform a copy in this case and is almost free.</p>

<p><strong>Most importantly</strong>, except for a little inconvenience with syntax (e.g. <code>[0]</code>) those operations definitely <strong>are not costly</strong>, especially in the context of performing convolution.</p>

<p>BTW. Other ready alternative layers like the ones in <code>tf.keras</code>, require batch as first dimension as well.</p>
",,"['How to use tf.nn.conv2d on a single image in TensorFlow?', 'TensorFlow tf.nn.conv2d single image example', 'Efficient way to apply 2D convolution on a single image using TensorFlow', 'Avoid reshaping when using tf.nn.conv2d on a single image', 'TensorFlow 2D convolution without batch dimension', 'Best practices for using tf.nn.conv2d with single image input']","['How to use tf.nn.conv2d on a single image in TensorFlow?', 'Is there a way to apply tf.nn.conv2d without reshaping a single image to a batch of one?', 'Efficient methods to perform 2D convolution on a single image using TensorFlow', 'Can tf.nn.conv2d be used directly on an image with shape [in_height, in_width, in_channels]?', 'Best practices for applying convolution to a single image in TensorFlow']",{'https://www.youtube.com/watch?v=7gGxBGvSAa0'},"['""""""[Document(page_content=""hi welcome back to you new listen this is let\'s me can\'t you re and we are gonna use a tensor flow 2.0 with the inbuilt Kara\'s to make a two dimensional CNN in which we will be using C for 10 dataset and it will be a kind of image classifier and the dataset is available at Carol here and the C for 10 object recognition in images it has total 60,000 the training images and ten thousands for for the testing and and and the size of each image is 32 cross 32 pixels and it is RGB image color image does mean the the size of each image is 32 cross 32 cross 3 and the last three is three dimension is four red blue and green green pixels to represent its its image into a at the color image perfect so and the another thing here new in this lesson is that instead of using Jupiter notebook we are gonna use here at Google collab why we need to use Google : because we need to implement deep learning algorithm and the Google the collab provides a free GPU and the tip you and the size of RAM and the disk you can get from here and it says that I think yeah it\'s a 12 GB of RAM and 48 and 49 it\'s you can see around 50 GB of a hard disk so the Google Cola provides this in a free of cost and you can go ahead at this link cool I have not researched or google.com and once you open this it will open this notebook welcome dot IP and why we are the default page and then you need to create here a new Python 3 notebook right so it will create a new file entry notebook and although this is the online color but moreover it\'s like the Jupiter notebook which we have been using and then you can change here the name name of your file and other things will be almost the same like inserting the text let\'s say okay and if you want to bring this text upper you can go ahead and move these syllables and then this is kind of the mark of where you can give your heading okay so and then here you can code so this is how you will be working with the google cool laughs notebook now let\'s go ahead and come back to deletion so I have already created this notebook online so I\'m going to work with this notebook but you can work in this new notebook otherwise you have some other the way to you know to download my this notebook from the github repository the link for this notebook is given into a video description and then you can go out here at add the file and then you can upload a notebook so you can upload it from your computer itself otherwise from Google Drive or github okay so all these options are available perfect alright so let\'s come back here and in this lesson we are gonna cover what is CNN and the important terms of a scene in like what is the convolutional layer activation function a filter or a kernel size with the number of filters stride size padding max pooling flattening and dense layer and then finally we will start working with download of the data and model building so these convolutional neural network which is in sort known as CNN is a class of deep neural networks and most commonly it is applied in to our images and you know the visual imaginary techniques and these sealants are regular eyes to version of multi-layer perceptrons which we have seen in our previous video and if you don\'t know you can go ahead at my channel kgp talky there you can see all those previous videos or the deep learning and the Fightin\'s and along with the classical machine learning with the feature selections and so so the multi-layer perceptrons usually means a fully connected networks that is each neuron in one layer is connected to all neurons in the next layer right but in but in the in the convolutional neural network it doesn\'t happen like that because in that case like a multi-layer perceptron model or a fully connected layers and in that case the models are very prone to overfit so that is why the ceilings are more over the regularized two version of multi-layer perceptrons right and these convolutional layers are inspired by biological process in there the connectivity patterns between the neurons resembles and the organization of the you know the visual cortex so this is how it it is working and these are you can say the convolutional layer and these are the pooling layers and then finally the convolutional neural networks have a flattening layers and fully connected layers in the last are the network and then finally with the softmax softmax activation function it cry it detects the classes it detects the classes perfect now let\'s go ahead and see what are the important terms like what is the convolutional layer what is the activation functions what is the pooling layers and what are the flattening fully connected layers so the convolutional layers as I said that so this is kind of regularized fortune of multi-layer perceptron and moreover it uses the techniques kind of biological techniques visual cortex technique so there it try to the scan image are the two-dimensional at the data are three dimensional multi-dimensional data and nowadays the one dimensional CNN is also coming so he tries to the scan the data and and the size of this scanner is the filter size and otherwise it is also known as a kernel and then it it scans and then it tries to find out the features of these images okay so then it stress the features and you see here this number of you know these number of the layers so these are tea you can say the depth of the convolutional neural network otherwise you can see these are the total number of failures and these things you know go on if you make a multi layer the convolutional neural network and but you know the data gets larger and the larger as you add the number of filters more then what we need to do we need to minimize the data with the minimal loss of the information then we come with the new term moon as a max pooling so we apply some kind of here a filter in which we we see all the parameters within those filter and then we get the and we extract the maximum numbers from that filters and then finally the information get you know the feed it to the fully connected layers before the Platinum the flattening and then after fully connected layers and then finally with the softmax or the sigmoid if there is two two classes 2d tapes then the see what can be used but if there are multiple classes then we need to use here the softmax are some other kind of under the activation function so the question is what is the activation function if you remember in my previous video I have explained what is these neurons so this is kind of you know the biological in our brain so brains are made of the billions of the billion neurons and the similarly the machine learning artificial neural networks we are multiple neurons and there\'s been the multiple neurons with multiplied by the weights the input weights and this these comes to a single points okay these comes to a single point and there with the activation functions they get multiplied and they get multiplied and you know a dash together so these the activation function desire decides where what will be the final value okay so there are multiple kind of the activation functions like here a sigmoid which have just zero to one value to maximum and here we have a tiny we have a rail ooh but the real you have a problem if input is you know the less than the zero then then there is no gradient so so the another version of the rail you comes like is Leakey value so the leaky Valu comes with some kind of the gradient if input is negative and then we have here a maxout and the ALU this kind of you know activation functions as I told you the filter size the filter size means you know how many filters see each filters extracts different kind of the features from the image so we need to apply there the multiple filter multiple filters so that it can scan the images be correctly and it can extract the maximum amount of the information but the number of filters should not you know the exceed some you know some particular level otherwise your model might get or fit okay and these number of filters are also known as a depth of your you know the convolutional neural network for that particular Network okay I mean the D depth of B filters actually and then here we have a stride sighs okay let\'s go ahead and see what is this tri size and the padding let\'s suppose that you have these just these without the zero so this is your two dimensional network and these the blue you know the blue rectangle this blue square is the filter hour and these the filter size total number of pixels 3 cross 3 is the filter size and how it is moving I mean how many pixels it is skipping that is known as a stride size and if you see in this it is skipping just one that is keeping just one one pixel that\'s mean default I stride size here each one and the padding means after this you know the actual data there is zero padded along with all those height although the dimensions all these four dimensions so that is known as your padding so the padding get sided with the zero and then these the filter goes along and it scans two dimensional data and then finally it gets multiplied by with this cardinal value and then finally it extracts these features out of this out of these images okay and these are the more relevant features perfect and the max pooling is kind of it gets the maximum value see here we have max pooling and the average pooling so let\'s say these are the square in square it detects the maximum number so in this that we have a maximum 20 and then with this tight size of the two so this move here along with this side with the two pixels then it selects the maximum here is the 30 and in this square we have a maximum 112 and here 37 and similarly it is taking every of all these force here okay now let\'s go ahead and to see the final layer which is flattening in the dense layer in the CNN we definitely need a flattening and the dense layer in between these congressional layers and the fully connected layer there has to be a flattening layer we transform this two-dimensional data into a matrix feed into it to a into a vector then finally that can be fed into a fully connected neural into a classifier and then after with the softmax our sigmoid regular resistor Sigma and softmax are a sigmoid activation function then we finally can ticket the final output perfect so this is all about in the theory now let\'s go ahead and learn how we can download the data and then how we can finally implement our two-dimensional the convolutional neural network into tensorflow 2.0 all right so let\'s the start download the data and the model building we need to first since we are working with the in the collab so every time we need to install a tensorflow GPU and we will be also working with the email extent library to plot our confusion matrix after the model training so we need to install these two library it\'s not like a typical computer where we need to just install a single time the as many number of times you reset your runtime you need to install this live but before installing these libraries come back to the runtime once you come here at the runtime then you need to change your runtime type here okay so if you have a nun then you need to either select a GPU or a TPU I have found that the TPU is a little faster than the GPU so I\'m going to select here a TPU and select a TPU and the save it so once you save it now the backend of this Google Kolev file will be using it tip you and after that let\'s go ahead and install these two libraries you need to install every time okay how many times you open this file after closing this file you need to install otherwise here it will not work so let\'s go ahead and run this it will install tensorflow GPU 2.0 Vita version so currently we have a tensorflow 2.0 Vita version only and it takes sometimes a little time so let\'s go ahead run this one and this cell as well and here we have very recent words any zero point one seven zero if you don\'t put this line then it installs ml extends 0.14 version that is lower than you know three versions lower than the current versions and that doesn\'t supports you know the advanced techniques in ml extend perfect so just let\'s wait for some time to install these two library I think it has an install so now let\'s go ahead and import tensorflow as a TF in meantime we can keep writing the code while it is installing so we are gonna here import TF sorry we are gonna import here a tensorflow as DF and in meantime we are gonna import Kara\'s from a tensorflow I don\'t think we need Akira so we are not gonna import Kira\'s but we are gonna import the sequences model and and the layers so here we have a tensor view dot sorry dot Kira\'s import here sequins ear okay and after need after that we need to import these layers like a flattening layer so dense convolutional smack spooling and dropouts and and vice normalizes I I think I\'ll take another lessons and West normalization so in this lesson we are not gonna work with match normalization okay so here we have installed over the tensorflow GPU version of 2.0 tensorflow and we have installed ml x10 0.17 we are good to go now we are gonna import I\'m sorry I this should be actually from instead of import so here from the tensorflow sorry now so here we have a tensor flow dot Kira\'s dot layers and then we need to import flatten dense if you are wondering how I am getting these suggestions then I am using kind of advanced version of Google cool air editor you can also switch to advanced version of Google cool air editor you need to come here these are the new features if it is really well then there you would get an options there okay if you want to go to check a new editor then you can just tell you to change this helical type and I am finding this editor is quite good so I\'m going to stay opt in for this editor okay so while on the fly it suggests you so here we have now dents and then here we have a convolutional 2d that\'s the kana 2d and then we have here a max pool but the max pool today so if you type here the max fool you get so many you know the options like max pool 2d and the max pooling 2d and max pool today and the max pooling TD is Max pulling 2d is the same thing so you don\'t to worry you know anything now let\'s go ahead and you know use the drop out as well so these are the some layers which we will be using like flattened ends come to d-max pull to D in the drop out it says that it doesn\'t have sequins here so let\'s go ahead and see ya here it has sequins here ok so we have got here our layers and the Kira\'s model now let\'s go ahead and check the version the tensorflow version which we can change which we can check by D F dot and then version so let\'s go ahead and run this it should say here the 2.0 release candidate zero which is a Vita version now let\'s go ahead and the import supporting libraries as well like numpy pandas in my flat lip although we don\'t need panels but we will we might need an umpire so I\'m just going to import the numpy SNP and I\'m gonna import the matplotlib dot Phi plot as PFD and I\'m gonna also import Matt Ratliff we will be needing this Matt float live the during the plot of our the confusion matrix perfect now let\'s go ahead so we have imported no necessary necessary packages now we need to download the data so we are going to work with the c-4 dataset which we have here in at the Kira\'s but we are not going to download from the Kira\'s the tensorflow 2.0 automatically have it here you know the c4 10 dataset so we are going to download that from Kira\'s data sets itself so that we can download from Kira\'s sorry for tensorflow dot Kira\'s and then dot data sets and then here we have import and then finally here we have C 14 perfect so we have imported C 14 reference so let\'s go ahead and download this data set which we can download data sent by calling here by calling the c14 then dot load data so it will return at Apple for training in the testing so we will get to Tuffle here so the first of all is for training and the data file is for testing so let\'s go ahead and read this data into X underscore train and the y underscore train and then finally X underscore test and then Y underscore test right so let\'s go ahead and load this data so it takes a little time to download a complete data in meantime you see here this data set have a ten classes and c14 these large teams represents that it has a ten classes if you come here at the data it might under so you otherwise you yeah I think it has here so these are the ten classes which are the airplane Auto Mobile\'s bird cat etc so we are going to create here a list of the classes so they\'re the classes name and we are gonna create this list like we have here airplane images of airplane and then here we have images of the automobile and then we have images of bird as well as we have images of cat and then we have images of deer as well and the images of dog and then finally we have images a frog then finally we have horse and sheep and the truck so here we have sheep and then finally we have a truck perfect so these are the classes which we have in our c4 ten dataset we have already got the training and the testing data set since these images which we are gonna huge however are the maximum value which is 255 and how you can get that you can write year X underscore train and then dot match it will return you the maximum value present in this training data set which is 255 but the artificial neural network in general the prefer if value is closer to 1 since we have seen in two hour you know the activation function so the mostly the value we get the maximum gradients when we lose our somewhere nearby Cheeto okay r1 so that\'s why we prefer mostly if values you know almost nearby a zero so moreover we would prefer if it is in between somewhere zero to one so what we are going to do here we are going to divide our X train data set with the 255 so that the maximum value should be 1 and similarly we are gonna divide our X test dataset with 255 as well so now maximum value has come under 1 now let\'s go ahead and check the safe of these data sets so here we have a safe which should be 32 by 32 and then 3 so this is the safe of each images and this says that we have total 50,000 image actually I am sorry initially I told you that we have 60,000 images but we have actually you know the 50,000 images and 10,000 images for training purposes right so which we can check here with X test dot zip and there it says that we have a 10,000 image and each images have 32 cross 32 width pixels and each pixels have a 3 depth which is RGB that\'s mean each pixels are color of XS now let\'s go ahead and see see some images how we can see those images with the PLT dot I am I am so so with these I am so which is image so with this we can pass here the first value of x test are extreme whatever with the 0 that\'s mean it will show a first image so here you get this is a bird actually how would you make sure that season bar you can print here at whitest and if you print whitelist you see your first level is 3 and the 3 is which one is 3 ah it is actually the kite ok so this is the 3 since it starts from the 0 that\'s why this is actually a kite okay so this array starts from 0 to 9 maximum ok so it says that it has a 3 there perfect so now let\'s go ahead and build our CNN model and before building scene and model let\'s go ahead and insert a few cells for coding so that we can get in a free space to code and before that I\'m gonna insert a text here where I\'m gonna write build CNN model alright so here I\'m gonna build a scene in model so scene and building a scene in model is fairly simple we need to first get a sequential object here so once we get this sequential model and then we are going to I adhere the convolutional layers are flattened layers and the dense layers so the model dot ahead and then here we have Cana 2d okay so here we have a convolutional 2d inside the convolutional 2d now you see it ask suppose how many filters do you want what should be a kernel size what is a stride size what would be the padding and what will be the data formats etc and that Commission size way so these things we can pass here so let us go ahead and pass these information so the first we are gonna pass here of filters how many filters we are going to use we are going to use initially 32 filters so it is up to you how many filters you want to use moreover it depends on testing and the trial error so you need to apply a multiple type of the filters with a multiple size then you can select which one is here now giving maximum results for your task so let\'s go ahead and fit a kernel size which is a 3 here if you give just a single name of 3 and then it will make a 3 by 3 otherwise you can give here a couple like a three three by two okay as well so let\'s go ahead and make it simple here so we have here a 3 cross 3 carnal sides and now here the pairing which we are gonna use instead of valid we are gonna use the same pairing here and then the activation function we are gonna here huge array Lu actuation and the input shape so input CF we have initially how many input hold the shape of our input that is a 32 cross 32 cross 3 so we have 32 across 32 cross 3 right so these are the our inputs if so we have build our the first model now let us go ahead and run this and see and see okay what happens it says that there is error perhaps I think yes we need to close this one as well so now you see we have here we will add the new convolutional layer perfect so now let\'s go ahead and actually the best practice to keep all those the model building at the same in the same cell otherwise sometimes what happens you you know if you run a cell multiple times so you could get disturbs and now we have added the first convolutional layer so let\'s go ahead and copy this and paste it here and since we are going to add the another kernel snow layer that will be the inside so in that case we don\'t need actually the input safe okay so in that case we can delete this input safe so let\'s go ahead and delete why if you see these can volitional layers so these are the first Canales the layer where we need to define what is the input size but after that we don\'t need to define the input size all right and now we are going to apply here max pooling okay so have we imported the max pool yes so we have a max pool and the drop okay so let\'s go ahead and add a max pooling as well so that we can reduce the overhead so here we have a max pool 2d and the max pool 2d it asked about what will be the full size okay that\'s fine what will be decides on which we are going to look for the maximum value so the pole size we are gonna use here a 2 cross 2 right and then what will be destroyed which we are going to use so the stride size I am gonna use here too and then it asks about what will be depending okay so I\'m gonna use so pairing is you know the valid can see right so in case of the invalid pairing it try to you know reduce the dimensions but with the same padding it try to keep the same dimensions on which we are applying the filter so we have max pull the data now let\'s go ahead and apply a dropout so after a max pooling I am also going to apply a dropout so the dropout what it will do it will try to you know it will try to make sure that the some cell in convolutional layer gets died out okay so that it should not over fit actually so the dropout actually prevent overfitting alright so we have here a dropout in which I\'m going to drop 50 percents of input so that is 0.5 so the 50% input will not be the considered while calculating the next stage now let us go ahead so here we are going to just use the 2 layer of the convolutional layer and i\'m now going to add a flattening layer so here we have a model dot and and then here we have here a flattening layer with a flattened and after this I\'m going to add a finally a dense layer okay so we have a model dot ad we have got our flattening layer now I\'m going to add here a dense layer so the dense layer asks the vols mult asks about her multiple input parameters like how many units that\'s mean how many are how many neurons we want we want let\'s say the 128 neurons and then it says that which activation function we want to apply on these freely connected networks which is also known as internet work I\'m going to say that we want here array Lu so on this activation on this fully connected layer I have applied here riilu activation function now let\'s go ahead and add a final output layer so in output layer we need to keep the the units which will be the equal which will be equal to number of outputs so here we should have units is equal to 10 since we have a ten classes to predict and then the activation function we should keep here softmax we cannot use riilu we cannot use sigmoid and we should use here softmax why we cannot use a Sigma because Sigma can\'t predict only the binary prediction 0 r1 so here we have a sort max finally we are done with the building our model so the model has been builded let us go ahead and print the summary of this model which we can print with model dot summary and in this you see this is summary of our model so we have here two convolutional layer and then finally we have a max pooling after second convolutional layer then we have a dropout after that I have added a flattening layer then dense layer and then finally output layer which is also a dense layer a kind of okay so this is one of the very simplest convolutional neural network if you want to add the more then what you can do you can just copy these three lines and you can paste it here and you can keep pasting you can increase the size of your model okay right so all the way but as of now we are going to just to go ahead with this simple model so that it should not take much you know the training time otherwise we need to wait for much larger much much larger time to complete the training if we make a complex network now let\'s go ahead compile our model so we can compile our model by calling model dot compiled and there we need to pass what is the loss what should be the optimizes and what should be the metrics on which your model should be optimized so so I\'m gonna first pass here the optimal here and I\'m gonna use here ada mokka measure and then it is asking about what should we do love us okay so I\'m gonna use loss which will be a sparse categorical cross entropy so here we have sparse categorical cross entropy then finally it asks about what should be the metrics on which we are going to calculate the output off okay we are going to optimize our model so so the metrics on which we are going to optimize our model is sparse categorical accuracy which we can get by here with sparse categorical accuracy perfect so let us go ahead and compile this model and after this now the most exciting part of this convolutional neural network is model fitting so once we type here model dot fit there you see it asks about multiple parameter like X train and Y train the best size and a pox and the verbose so what we are going to do here we are going to the pass here the first extreme dataset on which the training will be done and then why trained by which it will be compared and then I\'m gonna pass here the bite size I\'m gonna pass here a 10 bite size and then it asks about how many a pox we want so here I\'m gonna pass a total teeny pox and then it finally asks about the huevos okay so here I\'m gonna pass over woes is equal to 1 that\'s mean it will keep printing the progress of our training model and then I\'m gonna pass the validation data as well so what should be a validation data that\'s been during the training it will also keep validating our model okay so for a validation data what I am going to pass here I\'m going to pass here at Apple that\'s mean the X test and the Y test will be used for a validation okay so this is the all information and other informations we can neglect right so one more thing if you see here our model dot faith returns returns our history of our training a tree in the model okay so to record that history what we can do we can just record that history if we you know take that parameter in history so after the training this model then we will be getting all the history for each a box its training accuracies and the loss for validation in the training set then finally we can plot the learning curve of this model as well so let\'s go ahead and hit the enter it will take some time to complete the training of this model so we need to wait to who get it done so it might take about an hour to complete this training although we are using the GPU so this was the difficult to train on your computer so if you are using a computer please don\'t run it in your computer if it doesn\'t have a GPU if you are working in the CPU then it can\'t do you need to come back here at the Google cool F where you can play at the GPU on this training on this training of seen in model so let us go ahead and wait for some time to get it complete alright so our model has been trained here so we had selected a batch size tin box tin and verbose one and this is a complete verbose to our model and it says that here the maximum training I could see it has achieved at the point six five but if you see here a validation accuracy well it is an accuracy is just seventy point to it this is the difference okay in between accuracy the training and validation accuracy says that our model is you were 15 if well it is an accuracy is less than training accuracy then the mobile model over field and if validation accuracy is you know the more than the training accuracy that\'s when our model is under fitting so in this case our model is overfitting so let\'s plot our this learning curve against the loss I\'m the accuracy of a training and validation set then let\'s understand with this loss how these models are overfitting and at which training epoch model started overfitting perhaps after fourth époque here you see the fourth epoch which we have the training accuracy is around 70 percents and here it\'s around the 68% and perhaps after this after the third epoch and between the fourth high pop the model started overfitting so let\'s go ahead and plot this and see how it is overfitting so we need to plot it in in the matplotlib to do that what we we need to do here we need to the clock the call matplotlib PLT function so I have already written the code since this is a very traditional code and if you don\'t know how to plot do plotting in the mat flatly then what you can do you can to go ahead my my flat lip tutorial here and I have shown there a detailed you know the matplotlib tutorial and you can learn more about the matplotlib so let\'s come back to this cell here let me explain you the info currents which we are taking here since this is a 10-8 box so we should take here 11 the range will be 1 to 10 and here we are plotting a PO currents against the one to ten that\'s mean here the epoch which we had selected for her those number of epochs for which we had three in our model and here you see the history dot history so the history returns the it\'s kind of the call back which will cause all these information that\'s been the losses and I couldn\'t see over the training set as well as for winding sunset and then the history taught history so this is kind of our the dictionary the sparse categorical accuracy so I mean these values is there and validation sparse degree accuracy these values will be you know recorded is recorded actually in digital in these variables and India just the title and the Y and X level along with diligence and then he had the same we are doing for a loss as well history taught history with in in log in the dictionary and the lost keys and the validation lost key is representing the loss of the training and the weld is sunset respectively so let\'s go ahead and run this cell and see a plot of learning curve so here we have a plot of the learning curve and in this you see the accuracy of a training set it\'s kept increasing okay for each of these epochs but the accuracy for a validation say it has came to you know the V Lowden the training set after the third Apoc that\'s mean it is saying that that\'s mean it is saying that the accuracy the accuracy validation accuracy is less than the training set that\'s been the model is your footing and here with the loss you can also verify that a validation loss has you know saturated after the three epoch that\'s mean the model is not learning but we you know we kept running our model and I I mean we kept training our model and the training error has you know the training loss kept decreasing but the validation loss was not decreasing this says that our model is overfitting that\'s mean we had increased the complexity of our model but but it doesn\'t love actually you know generalize it it could not generalize actually and the one more thing you can\'t make the changes here in the model you can copy in the paste it and you can similarly change the drop out layers and the filter size stride size the kernel sizes are all or the filter size and then finally you can you can really in this model I had taken the simple CNN model because it takes a lot of the time it has taken almost one hour in my you know this cool ever the notebook it will lie I think I will take almost the same time in your cool air as well so that\'s why I had taken just as small and simple scene in model for this so let\'s go ahead and plot a confusion matrix for this to plot a confusion matrix as I have already told initially in this video that we need to install a mail exchanger library so let\'s go ahead and import broad conclusion matrix from ml extant library so from that we need to write here email email extent dot the plotting and then we need to write here import and then brought confusion matrix and then here from a scalar so hidden from a scale and dot matrix import the confusion matrix so here we have a confusion matrix now we are going to import the mat floor I think I have already imported the matplotlib so I don\'t need to import that one now let\'s go ahead and the import now now let\'s go ahead and do a pull and the class predict so what we can do here we can call here Y prayer is equal to the model and then dot are the predict classes and for predict classes we need to pass here X underscore test so in now wipe read it will predict the classes and then in Y test the y underscore test is the original class predict original the result you see here and let\'s go ahead and the print wipe read here and if you see the wipe right there and here the original class so it says that the 3/8 the correctly predicted but the 0 here the prediction is wrong for this one so this is how we can see the y test and the wipe read now let\'s go ahead and plot a confusion matrix in just a three line of code we can do it very easily the math is equal to the confusion matrix here which we had imported from ml extent library it takes the white roof which is y test and then it takes wipe read and then finally it takes the yeah so this is all it takes now let\'s go ahead and get the confusion matrix so with this we have got the confusion matrix which is in to the mat now you can see this is a confusion matrix and with this here you see the label as well there we can also pass here label which is actually classes names with this level I think on the level is not true here so let\'s just delete it we will pass this level in while plotting the curve a while while plotting this the confusion matrix so we have here the matrix let\'s go ahead and the plot it this is really very simple in one line of the code we can plot this so here we have a plot and then underscore confusion matrix and here you see a input it takes input confusion matrix in that confusion matrix we need to fast math and then hire this fine we don\'t need to give any parameters there let\'s go ahead and set figure sighs and I\'m gonna figure set a figure site or vital and then after this it takes the input like like the classes and here we take classes names is equal to the classes names and after that it also takes few other inputs but we are not going to pass that let\'s go ahead and see the confusion matrix all right so here you see the confusion matrix I think the plot I have plotted it quite large plot let\'s go ahead and see it into the six by six plot so with this confusion matrix we can also see the classes here and this is a predicted class and this is a true level and we can also get here are some the probability I mean the accuracy for each classes that we can get with the so normed is equal to the true so if I write here so normed is equal to true then we will also get the probability for each classes so we can also increase it this by nine by nine let\'s see nine by nine then there would be a larger figure there and now we can see the accuracy for each classes so with this you can see the maximum accuracy which we are getting in this sheep classes the truck and frogs cetera but the lower accuracy has been reported for our cat and for a dog and for a bird so these are the lower accuracy but for others the accuracy is quite good okay and now you see here the cat this is the predicted and this is the true level so let\'s say if the true level this is the plated one and this is the true level so with this it says that here the true level for the airplane okay and the predicted level is for airplane is you know it\'s around the 687 that is the truly predicted but for the airplane the 23-year plane has been predicted as the automobiles and the 59 has been predicted al-jabbar and the 21 airplane has been predicted as a cat so these are the error actually for the airplane but if you see here the automobiles okay so these are the automobiles here it has been you know the predicted the wrongly you know 136 automobiles this is the true label so 136 automobiles has been predicted as a truck and you see here the 199 cat has been predicted as a dog and now you see here 182 that is 18% 18% dogs has been predicted as a cat so this this can be you know the in co2 as a dog can be predicted in the cat and the cat has been predicted into the dog alright so but you see here the accuracy in the Miss classification in the dog and the automobiles is really very low right so with this you can understand the meaning of the confusion matrix so this is all about in this lesson so in this lesson you have learned so many things the first you have learned what is the scene in and how it works and then you have learned how you can install the tensorflow GPU and email extent library and then you have learned how you can the build your scene in model and then finally how you can train it and then finally how you can draw the learning curve and the confusion matrix in this lesson so thank you so much for watching this video please do not forget to Like and subscribe this channel bye bye have a nice day"", metadata={\'source\': \'7gGxBGvSAa0\'})]""""""']","{'https://stackoverflow.com/questions/52923062/tensorflow-compute-tf-nn-conv2d', 'https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow', 'https://stackoverflow.com/questions/55909188/how-can-i-apply-a-tensorflow-2d-convolution-tf-nn-conv2d-to-a-single-non-batc', 'https://stackoverflow.com/questions/65542469/how-do-i-use-tensorflow-tf-nn-conv2-to-make-a-convolutional-layer'}","['""""""OverflowAI is here! AI power for your Stack Overflow for Teams knowledge community. Learn more\n\nHow can I apply a TensorFlow 2D Convolution (tf.nn.conv2d) to a single (non-batch) 2D image? Modified 5 years ago\n\nI would like to use the function tf.nn.conv2d() on a single image example, but the TensorFlow documentation seems to only mention applying this transformation to a batch of images. The docs mention that the input image must be of shape [batch, in_height, in_width, in_channels] and the kernel must be of shape [filter_height, filter_width, in_channels, out_channels]. However, what is the most straightforward way to achieve 2D convolution with input shape [in_height, in_width, in_channels]? Here is an example of the current approach, where img has shape (height, width, channels):\n\nimg = tf.random_uniform((10,10,3)) # a single image img = tf.nn.conv2d([img], kernel)[0] # creating a batch of 1, then indexing the single example\n\nI am reshaping the input as follows:\n\n[in_height, in_width, in_channels]->[1, in_height, in_width, in_channels]->[in_height, in_width, in_channels]\n\nThis feels like an unnecessary and costly operation when I am only interested in transforming one example. Is there a simple/standard way to do this that doesn\'t involve reshaping?""""""', '""""""Gabriel IbagonGabriel Ibagon\n\nAFAIK there is no way around it. It seems (here and here) that the first operation creates a copy (someone correct me if I\'m wrong). You may use tf.expand_dims instead though, it\'s IMO more readable because of it\'s verbosity. On the other hand, taking 0 element from the tensor should not perform a copy in this case and is almost free. Most importantly, except for a little inconvenience with syntax (e.g. [0]) those operations definitely are not costly, especially in the context of performing convolution. BTW. Other ready alternative layers like the ones in tf.keras, require batch as first dimension as well. Szymon MaszkeSzymon Maszke\n\n\n\n""""""', '""""""OverflowAI is here! AI power for your Stack Overflow for Teams knowledge community. Learn more\n\nHow can I apply a TensorFlow 2D Convolution (tf.nn.conv2d) to a single (non-batch) 2D image? Modified 5 years ago\n\nI would like to use the function tf.nn.conv2d() on a single image example, but the TensorFlow documentation seems to only mention applying this transformation to a batch of images. The docs mention that the input image must be of shape [batch, in_height, in_width, in_channels] and the kernel must be of shape [filter_height, filter_width, in_channels, out_channels]. However, what is the most straightforward way to achieve 2D convolution with input shape [in_height, in_width, in_channels]? Here is an example of the current approach, where img has shape (height, width, channels):\n\nimg = tf.random_uniform((10,10,3)) # a single image img = tf.nn.conv2d([img], kernel)[0] # creating a batch of 1, then indexing the single example\n\nI am reshaping the input as follows:\n\n[in_height, in_width, in_channels]->[1, in_height, in_width, in_channels]->[in_height, in_width, in_channels]\n\nThis feels like an unnecessary and costly operation when I am only interested in transforming one example. Is there a simple/standard way to do this that doesn\'t involve reshaping?""""""', '""""""..... Now with ""SAME"" padding:\n\ninput = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,1])) op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n\nThis gives a 5x5 output image (size 1x5x5x1). This is done by centering the filter at each position on the image. Any of the 5-element dot products where the filter sticks out past the edge of the image get a value of zero. So the corners are only sums of 4, 5-element dot products. Now with multiple filters. input = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n\nThis still gives a 5x5 output image, but with 7 channels (size 1x5x5x7). Where each channel is produced by one of the filters in the set. Now with strides 2,2:\n\ninput = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n\nNow the result still has 7 channels, but is only 3x3 (size 1x3x3x7). This is because instead of centering the filters at every point on the image, the filters are centered at every other point on the image, taking steps (strides) of width 2. The x\'s below represent the filter center for each output pixel, on the input image. x.x.x ..... x.x.x ..... x.x.x\n\nAnd of course the first dimension of the input is the number of images so you can apply it over a batch of 10 images, for example:\n\ninput = tf.Variable(tf.random_normal([10,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n\nThis performs the same operation, for each image independently, giving a stack of 10 images as the result (size 10x3x3x7)\n\n 7\n\n@ZijunLost No, the docs state that the first and last element must be 1. Must have strides[0] = strides[3] = 1. For the most common case of the same horizontal and vertices strides, strides = [1, stride, stride, 1]. Is this Toeplitz matrix-based implementation of convolution? Regarding this: ""This still gives a 5x5 output image, but with 7 channels (size 1x5x5x7). Where each channel is produced by one of the filters in the set."", I still have difficulty understanding where the 7 channels are from? what do you mean ""filters in the set""? Thanks. @mdaoust Hi, regarding your second example where the 3x3 image and the 1x1 filter each have 5 channels, I find the result is different from the manually calculated dot product. @derek I have the same question, does the ""output_channel"" same as ""number of filters""??? if so why are they named ""output_channel"" in the tensorflow docs? | Show 2 more comments\n\n2D convolution is computed in a similar way one would calculate 1D convolution: you slide your kernel over the input, calculate the element-wise multiplications and sum them up. But instead of your kernel/input being an array, here they are matrices. In the most basic example there is no padding and stride=1. Let\'s assume your input and kernel are:\n\nWhen you use your kernel you will receive the following output: , which is calculated in the following way:\n\n14 = 4 * 1 + 3 * 0 + 1 * 1 + 2 * 2 + 1 * 1 + 0 * 0 + 1 * 0 + 2 * 0 + 4 * 1\n\n6 = 3 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 0 * 1 + 1 * 0 + 2 * 0 + 4 * 0 + 1 * 1\n\n6 = 2 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 2 * 1 + 4 * 0 + 3 * 0 + 1 * 0 + 0 * 1\n\n12 = 1 * 1 + 0 * 0 + 1 * 1 + 2 * 2 + 4 * 1 + 1 * 0 + 1 * 0 + 0 * 0 + 2 * 1\n\nTF\'s conv2d function calculates convolutions in batches and uses a slightly different format. For an input it is [batch, in_height, in_width, in_channels] for the kernel it is [filter_height, filter_width, in_channels, out_channels]. So we need to provide the data in the correct format:\n\nimport tensorflow as tf k = tf.constant([ [1, 0, 1], [2, 1, 0], [0, 0, 1] ], dtype=tf.float32, name=\'k\') i = tf.constant([ [4, 3, 1, 0], [2, 1, 0, 1], [1, 2, 4, 1], [3, 1, 0, 2] ], dtype=tf.float32, name=\'i\') kernel = tf.reshape(k, [3, 3, 1, 1], name=\'kernel\') image = tf.reshape(i, [1, 4, 4, 1], name=\'image\')\n\nAfterwards the convolution is computed with:\n\nres = tf.squeeze(tf.nn.conv2d(image, kernel, [1, 1, 1, 1], ""VALID"")) # VALID means no padding with tf.Session() as sess: print sess.run(res)\n\nAnd will be equivalent to the one we calculated by hand. For examples with padding/strides, take a look here. Salvador DaliSalvador Dali\n\n 2\n\nNice example, however some links are broken.""""""', '""""""Gabriel IbagonGabriel Ibagon\n\nAFAIK there is no way around it. It seems (here and here) that the first operation creates a copy (someone correct me if I\'m wrong). You may use tf.expand_dims instead though, it\'s IMO more readable because of it\'s verbosity. On the other hand, taking 0 element from the tensor should not perform a copy in this case and is almost free. Most importantly, except for a little inconvenience with syntax (e.g. [0]) those operations definitely are not costly, especially in the context of performing convolution. BTW. Other ready alternative layers like the ones in tf.keras, require batch as first dimension as well. Szymon MaszkeSzymon Maszke\n\n\n\n""""""', '""""""OverflowAI is here! AI power for your Stack Overflow for Teams knowledge community. Learn more\n\nHow can I apply a TensorFlow 2D Convolution (tf.nn.conv2d) to a single (non-batch) 2D image? Modified 5 years ago\n\nI would like to use the function tf.nn.conv2d() on a single image example, but the TensorFlow documentation seems to only mention applying this transformation to a batch of images. The docs mention that the input image must be of shape [batch, in_height, in_width, in_channels] and the kernel must be of shape [filter_height, filter_width, in_channels, out_channels]. However, what is the most straightforward way to achieve 2D convolution with input shape [in_height, in_width, in_channels]? Here is an example of the current approach, where img has shape (height, width, channels):\n\nimg = tf.random_uniform((10,10,3)) # a single image img = tf.nn.conv2d([img], kernel)[0] # creating a batch of 1, then indexing the single example\n\nI am reshaping the input as follows:\n\n[in_height, in_width, in_channels]->[1, in_height, in_width, in_channels]->[in_height, in_width, in_channels]\n\nThis feels like an unnecessary and costly operation when I am only interested in transforming one example. Is there a simple/standard way to do this that doesn\'t involve reshaping?""""""', '""""""..... Now with ""SAME"" padding:\n\ninput = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,1])) op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n\nThis gives a 5x5 output image (size 1x5x5x1). This is done by centering the filter at each position on the image. Any of the 5-element dot products where the filter sticks out past the edge of the image get a value of zero. So the corners are only sums of 4, 5-element dot products. Now with multiple filters. input = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n\nThis still gives a 5x5 output image, but with 7 channels (size 1x5x5x7). Where each channel is produced by one of the filters in the set. Now with strides 2,2:\n\ninput = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n\nNow the result still has 7 channels, but is only 3x3 (size 1x3x3x7). This is because instead of centering the filters at every point on the image, the filters are centered at every other point on the image, taking steps (strides) of width 2. The x\'s below represent the filter center for each output pixel, on the input image. x.x.x ..... x.x.x ..... x.x.x\n\nAnd of course the first dimension of the input is the number of images so you can apply it over a batch of 10 images, for example:\n\ninput = tf.Variable(tf.random_normal([10,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n\nThis performs the same operation, for each image independently, giving a stack of 10 images as the result (size 10x3x3x7)\n\n 7\n\n@ZijunLost No, the docs state that the first and last element must be 1. Must have strides[0] = strides[3] = 1. For the most common case of the same horizontal and vertices strides, strides = [1, stride, stride, 1]. Is this Toeplitz matrix-based implementation of convolution? Regarding this: ""This still gives a 5x5 output image, but with 7 channels (size 1x5x5x7). Where each channel is produced by one of the filters in the set."", I still have difficulty understanding where the 7 channels are from? what do you mean ""filters in the set""? Thanks. @mdaoust Hi, regarding your second example where the 3x3 image and the 1x1 filter each have 5 channels, I find the result is different from the manually calculated dot product. @derek I have the same question, does the ""output_channel"" same as ""number of filters""??? if so why are they named ""output_channel"" in the tensorflow docs? | Show 2 more comments\n\n2D convolution is computed in a similar way one would calculate 1D convolution: you slide your kernel over the input, calculate the element-wise multiplications and sum them up. But instead of your kernel/input being an array, here they are matrices. In the most basic example there is no padding and stride=1. Let\'s assume your input and kernel are:\n\nWhen you use your kernel you will receive the following output: , which is calculated in the following way:\n\n14 = 4 * 1 + 3 * 0 + 1 * 1 + 2 * 2 + 1 * 1 + 0 * 0 + 1 * 0 + 2 * 0 + 4 * 1\n\n6 = 3 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 0 * 1 + 1 * 0 + 2 * 0 + 4 * 0 + 1 * 1\n\n6 = 2 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 2 * 1 + 4 * 0 + 3 * 0 + 1 * 0 + 0 * 1\n\n12 = 1 * 1 + 0 * 0 + 1 * 1 + 2 * 2 + 4 * 1 + 1 * 0 + 1 * 0 + 0 * 0 + 2 * 1\n\nTF\'s conv2d function calculates convolutions in batches and uses a slightly different format. For an input it is [batch, in_height, in_width, in_channels] for the kernel it is [filter_height, filter_width, in_channels, out_channels]. So we need to provide the data in the correct format:\n\nimport tensorflow as tf k = tf.constant([ [1, 0, 1], [2, 1, 0], [0, 0, 1] ], dtype=tf.float32, name=\'k\') i = tf.constant([ [4, 3, 1, 0], [2, 1, 0, 1], [1, 2, 4, 1], [3, 1, 0, 2] ], dtype=tf.float32, name=\'i\') kernel = tf.reshape(k, [3, 3, 1, 1], name=\'kernel\') image = tf.reshape(i, [1, 4, 4, 1], name=\'image\')\n\nAfterwards the convolution is computed with:\n\nres = tf.squeeze(tf.nn.conv2d(image, kernel, [1, 1, 1, 1], ""VALID"")) # VALID means no padding with tf.Session() as sess: print sess.run(res)\n\nAnd will be equivalent to the one we calculated by hand. For examples with padding/strides, take a look here. Salvador DaliSalvador Dali\n\n 2\n\nNice example, however some links are broken.""""""', '""""""It would be extremely helpful if anyone could tell me what process yields this output. input = tf.Variable(tf.random_normal([1,2,2,1])) filter = tf.Variable(tf.random_normal([1,1,1,1])) op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\') init = tf.initialize_all_variables() with tf.Session() as sess: sess.run(init) print(""input"") print(input.eval()) print(""filter"") print(filter.eval()) print(""result"") result = sess.run(op) print(result)\n\ninput [[[[ 1.60314465] [-0.55022103]] [[ 0.00595062] [-0.69889867]]]] filter [[[[-0.59594476]]]] result [[[[-0.95538563] [ 0.32790133]] [[-0.00354624] [ 0.41650501]]]]\n\nShubhashisShubhashis\n\n 2\n\nActually cudnn is enabled by default on GPU in tf.nn.conv2d(), so the method in question is not used at all when we use TF with GPU support, unless use_cudnn_on_gpu=False is specified explicitly. there is an answer on the stats exchange with an animation that I found extremely helpful: stats.stackexchange.com/a/454115/44735\n\n\n\nOk I think this is about the simplest way to explain it all.""""""', '""""""OverflowAI is here! AI power for your Stack Overflow for Teams knowledge community. Learn more\n\nHow can I apply a TensorFlow 2D Convolution (tf.nn.conv2d) to a single (non-batch) 2D image? Modified 5 years ago\n\nI would like to use the function tf.nn.conv2d() on a single image example, but the TensorFlow documentation seems to only mention applying this transformation to a batch of images. The docs mention that the input image must be of shape [batch, in_height, in_width, in_channels] and the kernel must be of shape [filter_height, filter_width, in_channels, out_channels]. However, what is the most straightforward way to achieve 2D convolution with input shape [in_height, in_width, in_channels]? Here is an example of the current approach, where img has shape (height, width, channels):\n\nimg = tf.random_uniform((10,10,3)) # a single image img = tf.nn.conv2d([img], kernel)[0] # creating a batch of 1, then indexing the single example\n\nI am reshaping the input as follows:\n\n[in_height, in_width, in_channels]->[1, in_height, in_width, in_channels]->[in_height, in_width, in_channels]\n\nThis feels like an unnecessary and costly operation when I am only interested in transforming one example. Is there a simple/standard way to do this that doesn\'t involve reshaping?""""""', '""""""..... Now with ""SAME"" padding:\n\ninput = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,1])) op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n\nThis gives a 5x5 output image (size 1x5x5x1). This is done by centering the filter at each position on the image. Any of the 5-element dot products where the filter sticks out past the edge of the image get a value of zero. So the corners are only sums of 4, 5-element dot products. Now with multiple filters. input = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n\nThis still gives a 5x5 output image, but with 7 channels (size 1x5x5x7). Where each channel is produced by one of the filters in the set. Now with strides 2,2:\n\ninput = tf.Variable(tf.random_normal([1,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n\nNow the result still has 7 channels, but is only 3x3 (size 1x3x3x7). This is because instead of centering the filters at every point on the image, the filters are centered at every other point on the image, taking steps (strides) of width 2. The x\'s below represent the filter center for each output pixel, on the input image. x.x.x ..... x.x.x ..... x.x.x\n\nAnd of course the first dimension of the input is the number of images so you can apply it over a batch of 10 images, for example:\n\ninput = tf.Variable(tf.random_normal([10,5,5,5])) filter = tf.Variable(tf.random_normal([3,3,5,7])) op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n\nThis performs the same operation, for each image independently, giving a stack of 10 images as the result (size 10x3x3x7)\n\n 7\n\n@ZijunLost No, the docs state that the first and last element must be 1. Must have strides[0] = strides[3] = 1. For the most common case of the same horizontal and vertices strides, strides = [1, stride, stride, 1]. Is this Toeplitz matrix-based implementation of convolution? Regarding this: ""This still gives a 5x5 output image, but with 7 channels (size 1x5x5x7). Where each channel is produced by one of the filters in the set."", I still have difficulty understanding where the 7 channels are from? what do you mean ""filters in the set""? Thanks. @mdaoust Hi, regarding your second example where the 3x3 image and the 1x1 filter each have 5 channels, I find the result is different from the manually calculated dot product. @derek I have the same question, does the ""output_channel"" same as ""number of filters""??? if so why are they named ""output_channel"" in the tensorflow docs? | Show 2 more comments\n\n2D convolution is computed in a similar way one would calculate 1D convolution: you slide your kernel over the input, calculate the element-wise multiplications and sum them up. But instead of your kernel/input being an array, here they are matrices. In the most basic example there is no padding and stride=1. Let\'s assume your input and kernel are:\n\nWhen you use your kernel you will receive the following output: , which is calculated in the following way:\n\n14 = 4 * 1 + 3 * 0 + 1 * 1 + 2 * 2 + 1 * 1 + 0 * 0 + 1 * 0 + 2 * 0 + 4 * 1\n\n6 = 3 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 0 * 1 + 1 * 0 + 2 * 0 + 4 * 0 + 1 * 1\n\n6 = 2 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 2 * 1 + 4 * 0 + 3 * 0 + 1 * 0 + 0 * 1\n\n12 = 1 * 1 + 0 * 0 + 1 * 1 + 2 * 2 + 4 * 1 + 1 * 0 + 1 * 0 + 0 * 0 + 2 * 1\n\nTF\'s conv2d function calculates convolutions in batches and uses a slightly different format. For an input it is [batch, in_height, in_width, in_channels] for the kernel it is [filter_height, filter_width, in_channels, out_channels]. So we need to provide the data in the correct format:\n\nimport tensorflow as tf k = tf.constant([ [1, 0, 1], [2, 1, 0], [0, 0, 1] ], dtype=tf.float32, name=\'k\') i = tf.constant([ [4, 3, 1, 0], [2, 1, 0, 1], [1, 2, 4, 1], [3, 1, 0, 2] ], dtype=tf.float32, name=\'i\') kernel = tf.reshape(k, [3, 3, 1, 1], name=\'kernel\') image = tf.reshape(i, [1, 4, 4, 1], name=\'image\')\n\nAfterwards the convolution is computed with:\n\nres = tf.squeeze(tf.nn.conv2d(image, kernel, [1, 1, 1, 1], ""VALID"")) # VALID means no padding with tf.Session() as sess: print sess.run(res)\n\nAnd will be equivalent to the one we calculated by hand. For examples with padding/strides, take a look here. Salvador DaliSalvador Dali\n\n 2\n\nNice example, however some links are broken.""""""', '""""""Nicolas GervaisNicolas Gervais\n\n 1\n\nGreat. One big motivation is to use dilate and stride at the same time, which seems to work with tf.nn.conv2d, but not with keras Conv2D. For some reasons, keras has not implemented that. """"""']"
63919438,tf.keras.Model,example required,TensorFlow keras model fit() parameters steps_per_epoch and epochs behavior on train set,"<p>I'm using a tf.data dataset containing my training data consisting of (lets say) 100k images.
I'm also using a tf.data dataset containing my validation set.
Since an epoch of all 100k images takes quite long (in my case approximately one hour) before I get any feedback on performance on the validation set, I set the <code>steps_per_epoch</code> parameter in tf.keras.Model <code>fit()</code> to <code>10000</code>.
Using a batch size of 1 this results into having 10 validation scores when reaching 100k of images.
In order to complete one epoch of 100k images of my entire training dataset, I set the <code>epochs</code> parameter to <code>10</code></p>
<p>However, I'm not sure if using <code>steps_per_epoch</code> and <code>epochs</code> this way has any other consequences. Is it correct to use these parameters in order to get more frequent feedback on performance?
And also a more specific question, does it use all 100k images or does it use the same first 10k images of my training set at every 'epoch'?
I already dug into the <a href=""https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">TensorFlow docs</a> and read several different stack overflow questions, but I couldn't find anything conclusive to answer my own question. Hope you can help!</p>
<p>Tensorflow version I'm using is 2.2.0.</p>
","<blockquote>
<p>Is it correct to use these parameters in order to get more frequent
feedback on performance?</p>
</blockquote>
<p>Yes, it is correct to use these parameters. Here is the code that i used to fit the model.</p>
<pre><code>model.fit(
train_data,
steps_per_epoch = train_samples//batch_size,
epochs = epochs,
validation_data = test_data,
verbose = 1,
validation_steps = test_samples//batch_size)
</code></pre>
<blockquote>
<p>does it use all 100k images or does it use the same first 10k images of my
training set at every 'epoch'?</p>
</blockquote>
<p>It use all images in your training data.</p>
<p>For better understanding <code>Epoch</code> is the number times the learning algorithm will work through the entire training data set.</p>
<p>Where as <code>steps_per_epoch</code> is the total number of samples in your training data set divided by the batch size.</p>
<p>For example, if you have 100000 training samples and use a batch size of 100, one epoch will be equivalent to 1000 steps_per_epoch.</p>
<p><em>Note: We generally observe batch size to be the power of 2, this is because of the effective work of optimized matrix operation libraries.</em></p>
",,"['How to use steps_per_epoch and epochs parameters in tf.keras.Model fit() in TensorFlow 2.2.0?', 'Does setting steps_per_epoch in tf.keras.Model fit() use the same subset of training data in each epoch?', 'How to get more frequent feedback on validation performance using tf.keras.Model fit()?', 'What are the consequences of setting steps_per_epoch and epochs in TensorFlow 2.2.0?', 'How does tf.data dataset interact with steps_per_epoch and epochs in TensorFlow 2.2.0?']","['What does the steps_per_epoch parameter do in tf.keras.Model.fit()?', 'How does the epochs parameter interact with steps_per_epoch in tf.keras.Model.fit()?', 'Does setting steps_per_epoch to a value less than the total number of batches in the dataset cause the same subset of data to be used in each epoch?', 'How to ensure that all data in the tf.data dataset is used when steps_per_epoch is set in tf.keras.Model.fit()?', 'What are the best practices for setting steps_per_epoch and epochs to get frequent feedback on validation performance in TensorFlow?', 'Does tf.keras.Model.fit() shuffle the dataset when using steps_per_epoch and epochs parameters?']","{'https://www.youtube.com/watch?v=SftOqbMrGfE', 'https://www.youtube.com/watch?v=S6tLSI8bjGs'}","['""""""[Document(page_content=""at the start of every deep learning problem we have a data set and a largely untrained model now there are multiple open questions about how and how often we present this data to the model and i will address some of them in this video let\'s first look at the general training cycle from our database we get features for example images and labels or targets for example describing what is on the image we send the features into the network and let it make a prediction on that data we then compare the prediction with the true labels from the database by calculating the loss behind the scenes in pi torch or tensorflow the calculations up to this point are being tracked and we can automatically get the gradient which points us into the direction in which the network will be better at the just shown data that is roughly what happens during back propagation normally we then adjust the weights of the network with this new information after each prediction so that\'s the basics that are important to this video iterations are the first keyword we\'re talking about here because every for loop or iterative update can be called an iteration this is not really a clear-cut definition as far as i could tell but you can either say one iteration is finished every time the network weights are updated or every time we make a prediction which would be an iteration of the for loop that goes through the data loader in most cases these two are the same so don\'t worry if you don\'t really understand the distinction you could however do gradient descend and accumulate gradients until you have seen the whole data set before making an update in which case these two definitions would be different we have multiple for loops over the data loader but then at the end only one update of the network weights if you\'re a beginner just think of an iteration as one loop through this training cycle on the right also most research literature i\'ve read often talks about training steps to specifically mean the times when we update the neural network weights so i would encourage you to use that term as well next is the epoch an epoch is finished once the neural network has seen all the data once typically we are not finished after that because gradient descent variants only take small update steps and we usually need more updates than are possible within one epoch to reach a good model so we train for multiple epochs and it\'s hard to give a number because it\'s very dependent on the network size and training data however it\'s often more than 40 epochs i personally have trained some small image classification models on my local hardware and i used between 5 and 40 epochs just to throw this out as a super rough estimate it\'s also very different how long an epoch takes in terms of time it could be just seconds or even hours per epoch again that\'s very dependent on the type of network being trained and the data set overall epochs are a nice metric to describe training length so they are often used in papers and such because they are independent from the batch size and the concrete layout of iterations we have talked about iterations and epochs but what about batch size there\'s a bit more to talk about here we need to show the training data to the network and one of the ways we can do this is with full batch gradient descent for that we use the full data set at once the pros are that it is the most accurate at minimizing the training loss function after all we want the network to become better at all the training examples and not only some of them so it needs to take all of them into account when optimizing we can also calculate many of the example predictions on parallel with gpus which makes batch descend possible in the first place the cons however are firstly logistical the memory we have available is often too small modern neural networks are already quite big in themselves and the data sets can be many gigabytes big so they will not fit into memory completely as i mentioned before we could also split them into batches and then accumulate the gradients and only do an update at the end however that would take extremely long because gradient descent needs to take many training steps to get good and if every training step takes super long it\'s just ineffective the main takeaway from this is that you need to choose the batch size at least small enough so you don\'t run out of memory now let\'s look at what happens if we don\'t wait with our network update until we have seen the whole data set in stochastic gradient descent we only select one data point randomly for each training update most of what i say now also applies to the often used mini batch stochastic gradient descent in this algorithm we choose a random selection of points from the data set how many depends on the batch size that we choose for our problem the main advantage originally for this algorithm was that we can train faster by making more frequent updates even without having complete information about the whole data set this speeds up training but what happens to our accuracy first it\'s not as good as gradient descent because like i said we make updates before having all the information in this plot you can see three different functions f1 f2 and f3 and they represent the loss of just one data point and you can see the average of those three in red which would be the loss over all data points that we want to minimize so ultimately we want to minimize the red line to reach the point at almost x equals negative 0.5 however if we look at what would happen if we follow one of the other lines to their minimum then we can see that they would lead us in different directions sometimes even in the opposite direction of where we want to go but since we only take small steps and switch the leading line after every step they still roughly average out over time just not exactly to the average so that is something to keep in mind similarly to this view stochastic gradient descent introduces noise and in this image here i try to showcase the path which we would go with gradient descent as the solid line and the path we would take with storage gradient descent as the dotted line this is quite a mild view because here we never go into the opposite direction of gradient descent but it is still a good mental image to have of the process you can also see that we do not end up in exactly the same spot as grade intercent does now there is some discussion and theories going on that this noise is actually helping us train the network to some extent but that is a topic for its own video and it\'s also not fully understood in research yet but i still wanted to mention this because this randomness and training is not completely negative which is why it is used in most applications successfully to train newer networks some last remarks as a conclusion like i said mini badge is most often used so not the whole data set at once but also not just single points the exact batch size depends on your project and you should try out different ones to see which one works best in every case a good guideline however is to choose exponentials of two so 16 or 32 or 64 for your batch size as that uses the memory most efficiently so that\'s all for this quick lesson in the basics of deep learning thank you for watching and see you in the next one"", metadata={\'source\': \'SftOqbMrGfE\'})]""""""', '""""""[Document(page_content=""alrighty what is going on guys welcome back for another video in this video we\'re gonna explore uh how to build uh more flexible training loops uh so far we\'ve been using model.fit and uh if you can use modeler fit that\'s great but sometimes you need more flexibility so in this video we will look at customizing model.fit and then in the next video how we will look at how to build custom training loops from scratch all right so first of all here are just some basic imports those are you\'ve all seen those uh before and then we\'re just gonna load the uh the mnist data set so we\'re not going to do anything complicated i\'m just going to show you the general structure and then that can be applied to many different problems all right so we\'re going to x train y train x test y test and we\'re just going to mnist load data then we\'re going to do x train is x stream dot reshape then we\'re just going to have i guess a minus one for all the examples and then 28.81 and we\'re doing reshape here just to add this channel right here and then as type converted to flow 32 and then normalize with dividing by 255. so let\'s see let\'s copy this and let\'s go new line and do x test test and then let\'s create our model first of all so let\'s do model is equal to keras dot sequential then we\'re going to do layers dot input and then the shape of the input is 28 28 1 layers come to the 64 3 kernel size and i\'m padding same so i\'m just going through this quickly this is not really the most important part of the video so now that we have a model we\'re going to create a class and we\'re going to call it custom fit and we\'re going to inherit from keras.model and then the first thing we\'re going to do is we\'re going to create an init function and all we\'re going to send in here is the model so we\'re going to first call super to inherit from carousel model so we\'re going to do self and then init then we\'re going to do self.models equal to model then what we\'re going to do is we\'re going to define one training step and that\'s going to be used in a model.fit right so our goal is basically we want to do something like uh training is a custom uh custom wait custom what the hell custom fit of that model we\'re going to send in that model then we\'re going to do training dot fit and we\'re going to send in x train y train and then batch size and the number of epochs sort of as normal although this dot fit is going to be done in a custom way we\'re gonna sort of define how we want that to be done so um i mean there are many use cases of this where you want where you need to do custom training loops um and sort of you you use model of it when you can and when you can\'t you try to customize your model that fit which is what we\'re doing in this video and then for that most flexibility you do the training loops from scratch but an example of when you actually need to do this is uh generative adversarial networks i\'m not assuming you\'re familiar with that i\'m just sort of saying there are many examples where uh this is useful all right so let\'s then do uh train step uh we\'re gonna send in data and then we\'re gonna that\'s gonna be a tuple of x and y so we\'re just gonna do x and y is equal to data then what we\'re gonna do is uh we\'re gonna do with tf gradient tape as tape and why we\'re doing this is uh because now we\'re going to do the forward propagation and then the loss function and when we\'re doing it under that tape it\'s going to record all of the operations that was done and then that will then be useful for calculating the gradients for back propagation so basically we\'re going to do y prediction is a self.model we\'re going to send in x we\'re going to specify training is true and then for this loss function we\'re going to do loss equals self.compiled loss and then we\'re going to set in y and then y prediction and this is going to be done in the compile so right here we\'re going to do training dot compile we\'re going to send in and here we\'re going to send in optimizer is kara\'s optimizers adam then we\'re going to send in loss is keras losses sparse categorical cross entropy and from logits equals true then also we\'re going to do metrics is uh accuracy and so this is for the first one where we\'re doing the compile i\'m also going to show you how to do a custom compile um but but let\'s let\'s take that as we go so we we\'re going to first now continue doing the train step when we have this compile and so this self.compiledloss is using this sparse categorical cross-entropy from the training.compile after that we basically want to get the gradients right we\'ve now done the forward propagation this part is a for propagation which we\'re doing with this uh gradient under this tape to record all of the operations then we\'re going to do training variables is our self.trainable variables and these are all stored from from this uh parent class this uh keras.model so we don\'t have to bother with that then we want to get the gradients we\'re going to do tape dot gradient and we\'re going to do uh loss and then training variables right so we\'re getting the gradient uh of the loss with respect to the the training variables and which is ultimately what we want to change then uh we\'re gonna do a step an optimizer step a gradient descent step and we\'re gonna do self.optimizer.apply gradients and then here we\'re gonna do zip gradients and then training variables and then we\'re going to do self.compiledmetrics.updatestate y and then my prediction and this is this is going to be for the accuracy and then in the end we\'re going to return m.name and you\'ll see what it means so m.name m.result for m in self.metrics all right so we\'re getting the m.name which is going to be the loss for example and then we\'re getting the result which is the current loss and then we\'re doing that for all of the metrics and that\'s going to be the loss and the accuracy in this case and uh yeah so i think that\'s it for just this first step and i think we should now be able to run this and as you can see here it uh does seem to work and uh yeah so basically basically the next step now is that we want to do our own uh compile so what we\'re going to do right here is we\'re going to define compile we\'re going to send in the optimizer and we\'re going to send in the loss and we\'re going to do super custom fit self dot compile so yeah and then we\'re going to do self.optimizer is equal to optimizer self.loss is equal to loss and all we have to do then is uh we have basically the same thing right uh training.compile except we\'re not going to send in a metric right here so we\'re just going to use the optimizer and the loss and uh and that should also basically be it now we just have to change this right here to this compiled loss we\'re just going to do self.loss it\'s uh which we\'ve stored right here so self.loss and then let\'s see yeah and then we can still use self.optimizer and let\'s just rerun it and now as you can see we\'re not getting an accuracy so we\'re going to have to keep track of a that metric by ourself so what we can do is um for example we could uh create it right here we could do accuracy metric is uh keras.metrics dot sparse categorical accuracy and let\'s just call it name name equals accuracy and then in the and then right here instead of the compiled metric what we\'re going to do is uh is accuracymetric.updatestate we\'re going to send in y and then y prediction and then we can remove this compiled metric um and yeah so that should hopefully be it let\'s see if we can run this all right so now since we\'re keeping track of the accuracy by ourself what we\'re going to do here is uh we\'re going to write it explicitly so we\'re going to do loss is in this case just loss and then we\'re going to do accuracy is accuracy metric dot result and hopefully now we should get the loss and uh the accuracy yeah so this looks pretty familiar to what we did previously except now we\'re doing the compile completely by ourself and then all right so now we got the compile we got a train step what we normally do as well is in the end after training we\'re doing training dot evaluate and then x test y test and then we\'re specifying batch size let\'s say 32 one thing here is that this dot fit works on the train step and then evaluate works on a test step so to make this work we actually need to define another function i\'m going to do test step although this one is going to be a little bit easier since um well first of all we\'re going to unpack the data and then we\'re going to compute predictions we\'re going to do y prediction is self.model x and then we\'re specifying the training is false and what we\'re doing is this is if we\'re using batch norm or dropout that has different behaviors during testing and training we\'re just telling the model this is now in testing so make sure that those modules that have different behaviors are set to test mode or evaluation mode then we\'re going to compute the loss which is self.loss of y y prediction and then we\'re going to do accuracymetric accuracymetric.update state y y prediction and in the end we\'re going to return a dictionary of loss which is just going to be loss and then accuracy we\'re doing accuracymetric.result all right so this is a very like it\'s very similar to the training step although it\'s much more simplified and it\'s simplified because we\'re not doing a gradient descent update so we don\'t need to keep track of of this tape of making sure that we have all the gradients and and all of that stuff and yeah so let\'s run this for yeah two epochs and then let\'s do the evaluation all right so after this we see that we get 93 at the first epoch 97 and then almost 98 on the test set but yeah so i mean what we want to establish here that this does seem to train and it\'s working so so yeah that\'s how you create your own um you know specifying the training step and a test that which overwrites how the training that fit and then training that evaluate is done so in this way you can build more complicated and complex models uh in the in the training steps uh but still have the flexibility of doing training.fit um and that means that you can still use the training.compile although in this last one we we overwrote the the compile but but you get the point and you can still use the their compile and the metrics and all of that stuff but yeah if you have any questions leave them in the comment section below thank you so much for watching the video and i hope to see you in the next one [Music]"", metadata={\'source\': \'S6tLSI8bjGs\'})]""""""']","{'https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow', 'https://stackoverflow.com/questions/54575714/combining-keras-model-fits-steps-per-epoch-with-tensorflows-dataset-apis-b'}","['""""""If we look at the code of the fit method, you will see that the data is handled by a special class, DataHandler. Looking at the code of this class, we see that this is an Adapter class to handle different kind of data. We are interrested in the class that handle tf.data.Dataset, DatasetAdapter, and we can see that this class does not take into account the shuffle parameter :\n\ndef __init__(self, x, y=None, sample_weights=None, steps=None, **kwargs): super(DatasetAdapter, self).__init__(x, y, **kwargs) # Note that the dataset instance is immutable, its fine to reuse the user # provided dataset. self._dataset = x # The user-provided steps. self._user_steps = steps self._validate_args(y, sample_weights, steps)\n\nIf you want to shuffle your dataset, use the shuffle function from the tf.data.Dataset API. 2\n\nThank you for your explanation. To go further, If I want to shuffle my dataset each epoch during training. Would doing dataset.shuffle(len_dataset).batch(batch_size) and model.fit(num_epochs, ....) be enough ? Or do I have have to call, dataset.shuffle(len_dataset).batch(batch_size).repeat() and model.fit(steps_per_epoch=len_dataset//batch_size, ...). Or is it equivalent ? @Matt I am pretty certain that calling shuffle once should reshuffle the dataset between each epoch. It is something you could verify with a toy example.""""""', '""""""there I start doubting this method. As I am currently experimenting with the tf.estimator API I would like to add my dewy findings here, too. I don\'t know yet if the usage of steps and epochs parameters is consistent throughout TensorFlow and therefore I am just relating to tf.estimator (specifically tf.estimator.LinearRegressor) for now. Training steps defined by num_epochs: steps not explicitly defined\n\nestimator = tf.estimator.LinearRegressor(feature_columns=ft_cols) train_input = tf.estimator.inputs.numpy_input_fn({\'x\':x_train},y_train,batch_size=4,num_epochs=1,shuffle=True) estimator.train(input_fn=train_input)\n\nComment: I have set num_epochs=1 for the training input and the doc entry for numpy_input_fn tells me ""num_epochs: Integer, number of epochs to iterate over data. If None will run forever."". With num_epochs=1 in the above example the training runs exactly x_train.size/batch_size times/steps (in my case this was 175000 steps as x_train had a size of 700000 and batch_size was 4). Training steps defined by num_epochs: steps explicitly defined higher than number of steps implicitly defined by num_epochs=1\n\nestimator = tf.estimator.LinearRegressor(feature_columns=ft_cols) train_input = tf.estimator.inputs.numpy_input_fn({\'x\':x_train},y_train,batch_size=4,num_epochs=1,shuffle=True) estimator.train(input_fn=train_input, steps=200000)\n\nComment: num_epochs=1 in my case would mean 175000 steps (x_train.size/batch_size with x_train.size=700,000 and batch_size=4) and this is exactly the number of steps estimator.train albeit the steps parameter was set to 200,000 estimator.train(input_fn=train_input, steps=200000). Training steps defined by steps\n\nestimator = tf.estimator.LinearRegressor(feature_columns=ft_cols) train_input = tf.estimator.inputs.numpy_input_fn({\'x\':x_train},y_train,batch_size=4,num_epochs=1,shuffle=True) estimator.train(input_fn=train_input, steps=1000)\n\nComment: Although I have set num_epochs=1 when calling numpy_input_fnthe training stops after 1000 steps. This is because steps=1000 in estimator.train(input_fn=train_input, steps=1000) overwrites the num_epochs=1 in tf.estimator.inputs.numpy_input_fn({\'x\':x_train},y_train,batch_size=4,num_epochs=1,shuffle=True). Conclusion: Whatever the parameters num_epochs for tf.estimator.inputs.numpy_input_fn and steps for estimator.train define, the lower bound determines the number of steps which will be run through. 1,0\n\nEpoch: A training epoch represents a complete use of all training data for gradients calculation and optimizations(train the model). Step: A training step means using one batch size of training data to train the model. Number of training steps per epoch: total_number_of_training_examples / batch_size. Total number of training steps: number_of_epochs x Number of training steps per epoch. 1\n\nJust to add on to this, if there is a validation set of size V, then the number of training steps per epoch is (total_number_of_training_examples - V)/batch_size\n\n\n\nAccording to Google\'s Machine Learning Glossary, an epoch is defined as\n\n""A full training pass over the entire dataset such that each example has been seen once. Thus, an epoch represents N/batch_size training iterations, where N is the total number of examples.""\n\nIf you are training model for 10 epochs with batch size 6, given total 12 samples that means:\n\nthe model will be able to see whole dataset in 2 iterations ( 12 / 6 = 2) i.e. single epoch. overall, the model will have 2 X 10 = 20 iterations (iterations-per-epoch X no-of-epochs)\n\nre-evaluation of loss and model parameters will be performed after each iteration! Since there’re no accepted answer yet : By default an epoch run over all your training data. In this case you have n steps, with n = Training_lenght / batch_size. If your training data is too big you can decide to limit the number of steps during an epoch.[https://www.tensorflow.org/tutorials/structured_data/time_series?_sm_byp=iVVF1rD6n2Q68VSN]\n\nWhen the number of steps reaches the limit that you’ve set the process will start over, beginning the next epoch. When working in TF, your data is usually transformed first into a list of batches that will be fed to the model for training. At each step you process one batch. As to whether it’s better to set 1000 steps for 1 epoch or 100 steps with 10 epochs I don’t know if there’s a straight answer. But here are results on training a CNN with both approaches using TensorFlow timeseries data tutorials :\n\nIn this case, both approaches lead to very similar prediction, only the training profiles differ. steps = 20 / epochs = 100\n\nsteps = 200 / epochs = 10\n\nYoan B. M.ScYoan B. M.Sc\n\n1,Divide the length of x_train by the batch size with\n\nsteps_per_epoch = x_train.shape[0] // batch_size\n\n\n\nWe split the training set into many batches. When we run the algorithm, it requires one epoch to analyze the full training set. An epoch is composed of many iterations (or batches). Iterations: the number of batches needed to complete one Epoch. Batch Size: The number of training samples used in one iteration. Epoch: one full cycle through the training dataset. A cycle is composed of many iterations. Number of Steps per Epoch = (Total Number of Training Samples) / (Batch Size)\n\nExample Training Set = 2,000 images Batch Size = 10\n\nNumber of Steps per Epoch = 2,000 / 10 = 200 steps\n\nHope this helps for better understanding. Tejas BadheTejas Badhe\n\nIn a nutshell the expression can be denoted as follows\n\n𝜎 = (𝜀 × 𝜂) ÷ 𝛽\n\nthe above expression would be used calculate the steps\n\nand would be used conversantly to calculate the epochs\n\n𝜀 = (𝜎 × 𝛽) ÷ 𝜂\n\nedited Jun 5 at 6:27\n\nanswered Jun 5 at 6:21\n\nCliff NjorogeCliff Njoroge\n\n""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nWhat is the difference between steps and epochs in TensorFlow? Asked 8 years, 1 month ago\n\nModified 2 months ago\n\nIn most of the models, there is a steps parameter indicating the number of steps to run over data. But yet I see in most practical usage, we also execute the fit function N epochs. What is the difference between running 1000 steps with 1 epoch and running 100 steps with 10 epoch? Which one is better in practice? Any logic changes between consecutive epochs?""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nCombining Keras model.fit\'s `steps_per_epoch` with TensorFlow\'s Dataset API\'s `batch()`\n\nAsked 5 years, 6 months ago\n\nModified 5 years, 6 months ago\n\nI\'m looking at the performance and GPU usage during training of a CNN model with Keras+TensorFlow. Similar to this question, I\'m having a hard time to understand the combined use of Keras model.fit\'s steps_per_epoch and TensorFlow\'s Dataset API\'s .batch(): I set a certain batch size on the input pipeline dataset = dataset.batch(batch_size) and later I use\n\nfit = model.fit(dataset, epochs=num_epochs, steps_per_epoch=training_set_size//batch_size)\n\nbut I see that one can actually set any number of steps per epoch, even more than training_set_size//batch_size. From the documentation I understand that on Keras an epoch is not necessarily a pass over the entire training set as usually, but anyway I\'m a bit confused and now I\'m not entirely sure if I\'m using it right. Is dataset.batch(batch_size) + steps_per_epoch=training_set_size//batch_size defining a minibatch SGD that runs over the entire training set by minibatches of batch_size samples? Are epochs larger than one pass over the training set if steps_per_epoch is set to more than training_set_size//batch_size? steps_per_epoch is the number of batches of your set batch size is ran through the network in one epoch. You have set your steps_per_epoch to be training_set_size//batch_size for a good reason. This ensures all data are trained upon in one epoch, providing the number divides exactly (if not it rounds by the // operator). That is to say if you had a batch size of 10 and a training set size of 30, then steps_per_epoch = 3 ensures all data are used. And to quote your question:\n\n""Are epochs larger than one pass over the training set if steps_per_epoch is set to more than training_set_size//batch_size?""\n\nYes. Some data will be passed through again in the same epoch.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nWhat is the difference between steps and epochs in TensorFlow? Asked 8 years, 1 month ago\n\nModified 2 months ago\n\nIn most of the models, there is a steps parameter indicating the number of steps to run over data. But yet I see in most practical usage, we also execute the fit function N epochs. What is the difference between running 1000 steps with 1 epoch and running 100 steps with 10 epoch? Which one is better in practice? Any logic changes between consecutive epochs?""""""', '""""""edit: twice\n\n\n\n@NicolasGervais - perhaps one could imagine a scenario where the shuffling is defined once and is used for every iteration. @jakub ah yes it makes sense from that perspective\n\n\n\nThis is because the data files are shuffled and the dataset is shuffled with dataset.shuffle(). With dataset.shuffle(), the data will be shuffled in a different way on each iteration by default. One can remove shuffle_files=True and set the argument reshuffle_each_iteration=False to prevent reshuffling on different iterations. The .take() function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them. # Construct a tf.data.Dataset ds = tfds.load(\'mnist\', split=\'train\', shuffle_files=False) # Build your input pipeline ds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE) single_batch_dataset = ds.take(1) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label) for example in single_batch_dataset: image, label = example[""image""], example[""label""] print(label)\n\ntf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64) tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)\n\n\n\n""""""']"
53032922,tf.while_loop,example required,TensorFlow while loop with condition dependent on body,"<p>I want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don't know how to accomplish this with <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop()</code></a>.</p>

<p>My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by</p>

<pre><code>import numpy as np
import tensorflow as tf
IMAGE_SHAPE = [960, 720]
CROP_SHAPE = [320, 240]
max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE)
crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index)
img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])
</code></pre>

<p>and the condition is</p>

<pre><code>cond = tf.count_nonzero(img_crop &gt; 0) &gt; 0.5 * tf.size(img_crop)
</code></pre>

<p>Going over the documentation and examples of <code>tf.while_loop(cond, body, loop_vars, ...)</code>, what I understand is that both <code>cond</code> and <code>body</code> should take the same arguments given in <code>loop_vars</code>.
I don't see how I can have <code>cond</code> depend on <code>img_crop</code> which would be calculated inside <code>body</code>, and isn't provided in <code>loop_vars</code>.</p>

<p>I could equivalently compute <code>cond</code> using <code>crop_begin_index</code> without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem.</p>

<p>Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use <code>tf.while_loop()</code>?</p>
","<p>The arguments that are passed on to the <code>condition</code> function are the arguments returned from your <code>body</code> function. So you just have to return that value that you want to base your condition on in the <code>body</code> function, then carry out the condition on that value in your <code>cond</code> function. Something like, </p>

<pre><code>def body(image_shape, crop_shape, img_crop):
    max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE)
    crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index)
    img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])
    return (image_shape, crop_shape, img_crop)

def cond(image_shape, crop_shape, img_crop):
    return tf.count_nonzero(img_crop &gt; 0) &gt; 0.5 * tf.size(img_crop)

image_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))
</code></pre>

<p>Don't have access to an interpreter right now, so there might be some syntax problems there, but something like that. </p>

<p>Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions.</p>

<p>Also note, you'll need to specify some initial value for <code>img_crop</code> in the loop vars.</p>

<p>Moreover, by default, <code>tf.while_loop</code> expects the shapes of all the <code>loop_vars</code> to remain the same across all loop runs. You can modify this through the <code>shape_invariants</code> argument. </p>
",,"['How to use tf.while_loop with condition dependent on tensor computed in the loop body', 'TensorFlow tf.while_loop tutorial with dynamic condition', 'Using tf.while_loop for random cropping with quality check', 'TensorFlow while loop with condition based on intermediate tensor', 'Implementing conditional random cropping in TensorFlow using tf.while_loop', 'How to pass loop variables in tf.while_loop for dynamic conditions', 'TensorFlow tf.while_loop example with tensor condition', 'Handling random operations inside tf.while_loop in TensorFlow']","['How to use tf.while_loop with a condition dependent on a tensor computed inside the loop body?', 'How to handle random cropping with quality checks in TensorFlow using tf.while_loop?', 'Examples of using tf.while_loop where the condition depends on values computed within the loop body', 'How to pass and update loop variables in tf.while_loop?', 'How to implement a loop in TensorFlow that discards low-quality examples based on a condition evaluated inside the loop?']","{'https://www.youtube.com/watch?v=306tG48lhhQ', 'https://www.youtube.com/watch?v=H_9dthbtV68', 'https://www.youtube.com/watch?v=A6qJMB3stE4', 'https://www.youtube.com/watch?v=iFZRUwGcrxQ', 'https://www.youtube.com/watch?v=_u7AVsxANes'}","['""""""[Document(page_content=""what is going on guys hope you\'re doing freaking awesome in this video i\'m gonna show you how to do training loops from scratch so this means that we\'re no longer using model.fit but rather we\'re doing everything by ourselves from scratch uh if you\'re familiar with coding in pytorch then this is going to be more how you\'re used to training networks but anyways let\'s get started and uh we aren\'t going to do anything complicated in this video in terms of what we\'re going to train on and the data and so on uh the point is just to show you the general structure of how it looks like so the starter code right here is just some basic imports that you\'ve seen in previous videos we\'re going to use tensorflow data sets so if you haven\'t watched that video then it\'s going to be in the top right corner so we\'re loading the mnist data set right here uh the so we have the training and the test set and then we\'re just uh so we have a function for normalized images and all of this is from that video just copy paste it and then we have some very very simple model right here just some one convolutional layer and then one dense layer and let\'s do layers that dense here just like that and then so then let\'s get started and what we\'re going to do is first of all we\'re going to have some metrics so let\'s do accuracy metric is uh keras dot metrics dots bars categorical accuracy and then let\'s do first let\'s do the training loop so uh the first thing we\'re going to do is we\'re going to train it for a number of epochs so we\'re going to train for epochs is five in this case so what we just do is we we write for epoch in range epochs or maybe we should call it num epochs so num ebox right there and then we could do print um just let\'s do print slash n and then start of uh training epoch and then we could do we could do it like this epoch now let\'s do f string and so then we\'re going to iterate through all of the batches in our training uh and so we\'re going to do for batch index and then x batch comma y batch in enumerate a ds train all right so we\'re going to go through the s train for a number of epochs so right here we\'re going to first of all write the width tf gradient tape as tape and this is for recording all of the operations that we\'re going to do in the forward propagation so that we can then do back propagation for the um the model weights so we\'re going to do y prediction is model x batch and then specify training is true then we\'re going to do loss is the loss function right that we specified over here and we\'re going to send in the y batch the true labels and then the y predictions uh the one we just calculated for from forward propagation all right so then we have those under that tape then we can do gradients r equal tape dot gradients and then we specify the loss and then model.trainable weights so we basically want the gradients of of the loss with respect to the trainable parameters then or the trainable weights rather and then we\'re going to do optimizer dot apply gradients we\'re going to do zip gradients model.trainable weight and then we\'re going to do accuracymetric dot update state y batch and then y prediction just so that we have a sense of what the accuracy was of that epoch so at the end here we\'re going to do training accuracy is equal to accuracy metric dot result and then we could print that so we could do accuracy over epoch and then we could just do a train accuracy like that and then we could reset the accuracy metric so that it\'s going to be zeroed for the next epoch so accuracymetric dot reset states and that\'s it for the training loop so that\'s that\'s how it would look like it\'s very similar to the last video where we went through how to customize model.fit except now we\'re just removing the model that fit and we\'re just adding a loop here for the number of epochs that we want to train and then all we want to do is i guess uh so test loop so this is for the training and then we\'re going to want to have a test loop to evaluate our model and then we don\'t need to run it for a couple of epochs we could just run through the uh the data set once so we\'re gonna do batch index and then x batch y batch enumerate ds test and i guess right now we\'re not using the batch index but i mean you could so yeah i guess you could just iterate through the ds test as well there\'s no point of doing the enumerate but sometimes you want the batch index anyways uh we don\'t need to do gradient tape we\'re not going to collect the gradients so we\'re just going to do y prediction is model of x batch training equals true and then accuracy metric dot update state y badge and then y prediction then in the end we could do uh train accuracy is accuracymetric.result right same as we did right here and then we could i guess we could print accuracy over test set then we could just write training accuracy and then in the end we could again reset it we don\'t have to do this though since that\'s that\'s the last thing we\'re going to do but anyways that\'s how it looks like if you want a training loop and a test loop of course you can also i mean you could put this right here in a function like define train or something and then you could uh you know for epoch in range of you could just call that function train one epoch maybe and then run run it so you know you could think of this structure of how you could think of how you want to structure this but this is the fundamentals of how you do a training loop it\'s very simple we\'ve done it in the most simple way that we can and of course if you\'re doing something more complicated like generative adversarial networks or gans then it\'s going to look more complicated than this but it\'s still gonna be a fundamentally the same method and i think if you sort of understand this basic layout then and then when you do more complicated things it\'s gonna help you and understand the general structure all right so first of all we should run this and make sure that it works [Music] and it doesn\'t so it has no attribute gradients that\'s because we want to have a tape dot gradient all right and as we can see we uh it makes sense it\'s training and this works uh so yeah uh anyways that\'s it for this video hopefully you found this useful if you have any questions then leave them in the comment section below uh i think i said thank you for watching but thank you for watching and i hope to see you in the next video"", metadata={\'source\': \'_u7AVsxANes\'})]""""""', '""""""[Document(page_content=""welcome back everyone to this Channel and in this tensor FL tutorial today I\'m going to explain how to itate over a tenser so let\'s first know about the term iterate over so iterate over uh is a term used in every programming language it is the way to visit each element of collection of items sequentially one by one and the collection can be any iterable data structure such as dictionary set list or the tensor so this tutorial is about tensor flow so we will see how we can iterate over tensor only so we can use uh two methods in first method we will use the for Loop to iterate over tensor and in the second we will use the while loop and if you are a python programmer and as a python beginner uh you must already know how for Loop and my Loop works so let\'s begin so first import the tensor flow Library so write import tensor flow s DF and after this uh let\'s create a tensor data so tensor data and here I\'m going to use a constant function of T tensor to create a tensor data and provide a list of uh values on which you you will iterate using for Loop so here I\'m going going to take the country name like a USA this is the list of string and we will itate over it and second is the Brazil and third is the Australia let\'s take one more string value and which is a Canada now this is tensor data contains a list of strings and we can it it over it and for that let\'s uh write a four data in tser data then print the data value so here this four data represent the each element of this list so this is your tensor data this tensor data contain a list of a string and it\'s type is tenser let me also print the type so we don\'t need to print the type it will automatically print because we are printing here data let\'s execute this block of code as you can see in the output it itated over each element of the tensor data and you can see here the first tensor data is the string USA and its type is a string and the second is Brazil and and third Australia and fourth is the Canada so here using the power Loop uh we Tred over at tenser data this is the tensor data its type is tensor if we print its type let\'s check this type print and then use the python type function and type here tensor data execute this cell look its type is a eager tensor so the format of this variable tensor data is a eager tensor or it is in tensor format so this is how you can iterate over uh tensor data using the for Loop you can access individual value now next let\'s see how we can uh do that using the while loop so for while loop let\'s again initialize another tensor data so here I\'m going to store that tensor data into a tensor values named variable then TF dot constant let\'s create a list of integer so here I\'m going to use a list of integer 5 6 7 8 and then 55 like this and let\'s initialize a true variable first tensor L and this variable will store the length of this tensor values variable so for that you can use the python Len function and pass the tensor values variable like this so this line will uh store the length of this tensor values variable so uh it\'s length will be four because it contains a Four Element now let\'s also create one more variable data and in slize it with value zero now let\'s use the while loop while so I want to print the all the values of this tensor values or tensor variable while data is less than tens are L and if you don\'t use this your Loop will run forever or it will run for infinite time then print tensor values then data accessing each element and finally increasing the value of data by one each time plus equal to 1 let\'s execute this block of code so now you can see you get all the elements of the tensor values using the while loop so here we have a initialize data equal to zero and tensor L equal to length of this uh tensor values variable so let me explain how this is working so here uh it checks condition if data is less than tens that means you can see initial value of data is zero and you can think you can represent this condition like this and tensor Lane value current value is four because if you print here let me show you if you print the tensor Lane value you will get its size is four you can see here because this tensor value variable containing four elements now as you can see whenever this Loop runs first time it checks d is less than tens L which means 0 is less than four and that is true because currently the value of data is zero so it execute this line of code and here use the concept of indexing to access the value of tensor variable so here you can represent this one like this tensor values and then within this zero like this so This Means accessing the first elements of first element of a tensor values and then finally after printing the element we are incrementing the data value by one so this means data equal to data + 1 that means again 0 + 1 and which assigns a uh value or initialize a value of data to one so in the next tion it becomes one and when when it again checks 1 is less than four which is true so again it execute the next line and here instead of zero it uses one and then it access the second element of the list like this and print it on the terminal so same way it goes uh uh till 4 and after 4 it stops the while loop and it prints all the uh values of the list you can see here 23 56 78 and 55 so this is how you can use the while loop toit over a tensor and this is the very basic concept of for Loop while loop and if you have ever used a for Loop while loop on a python list and the same concept is applied here only Chang is the data type of the variable you can see data type is a tensor so I hope that you understand how to iterate over a tensor in a tensor flow using using for and Y Loop so at last I want to say don\'t forget to subscribe our YouTube channel and thank you"", metadata={\'source\': \'H_9dthbtV68\'})]""""""', '""""""[Document(page_content=""hey everyone and welcome back to this class unsupervised machine learning hidden Markov models in Python in this lecture we are going to go over the very important scan function in tensorflow we just did this in Theano but we\'re going to do it again from scratch in tensorflow - just in case you\'re not comfortable with piano and you\'re more comfortable with tensorflow so why is this important think about how tensorflow works you have to create variables and link them together functionally but they don\'t have values until you actually run the functions so when you create your X matrix you don\'t give it a shape you just say here is a placeholder I\'m going to call X and this is a possible shape for it but remember that the shape argument is optional therefore for all intents and purposes we can assume that we do not know the shape of X what happens if you want to live through all the elements of X what you can in order to read a for loop you have to specify how many times that loop will run but in order to know how many times the loop will run we must know the number of elements in X which we do not generally speaking we cannot usually guarantee the length of our training sequences so what happens if you want to do something like for I in range xj0 what you can\'t do this since x doesn\'t have a value yet xscape zero also does not have a value yet remember X is just a placeholder it only has a value when we call session dot run later and pass in X with the feedback this is where the tensorflow scan function comes into play the scan function allows you to live through a tensor flow array without knowing its size this is similar to how everything else in tensorflow of Vienna works using scan we can tell tensorflow how to run the for loop without actually running it there is another reason why the scan function is important other than the fact that we don\'t know beforehand how many times the loop will go remember that tensorflow does automatic differentiation it keeps track of how all the variables in your graph link together so that it can automatically calculate the gradient for you when you do gradient descent the scan function keeps track of this when it performs the loop let\'s now look at the anatomy of the scan function this is the scan function in its simplest form the first argument is some function that it\'s going to apply to every element of the sequence that you pass it the second argument is the actual sequence to pass it so every individual element in this sequence will have some function applied to it if this all sounds too abstract for you don\'t worry because we are going to see some examples very soon the way that we define the function that goes into the FN argument is very specific in a way it\'s much more strict than the piano in particular it must always take in two arguments the first argument is the last output of this function the second argument is the current element of the sequence the tensorflow scan function returns the outputs concatenated together so for example if I pass two three and my function is square then the outputs will be one four nine now of course the output that PF dot scan returns is still a tensor flow graph code so to get an actual value out of it you need to run it inside a session let\'s now look at the full code to implement a squaring function the relevant file in the course repo is hmm class /t f underscore scan 1 PI if you want to look at it on github numpy and tensorflow of course and then we create a placeholder for X notice how it\'s going to be a one-dimensional array that means each element of the sequence is a scalar next we define our square function notice how to square the current value we don\'t need to use the last value however because the function argument the scan requires us to conform to a specific interface we need to define the square function this way taking in both the last output and current element of the input sequence examples where we do need to use the last value will be more complicated and we\'ll look at those later next week all scan this takes in as input the recurrence function which is square and the sequence which is the placeholder X the output is a tensor flow graph node that represents the output of the scan will name this square up finally we need to actually call the square up in a session and pass in the value for X as we discussed earlier let\'s run this until we get you of course the scan function can do more complex things than this so let\'s incorporate another argument initializer which allows us to compute recurrence relations first just think about why we might need this well we can see that the recurrence function takes in two things the last output from itself and the current element in the sequence that we\'re scanning over but what is the last output the first time this runs well it\'s kind of undefined how can the last output of a function we\'ve never run before have any value so this is why the initialized argument is important the initializer argument represents the initial value of the output which we did not make use of in the square example because squaring only requires looking at the current element one thing to keep in mind when you use initializer is that it\'s very strict in particular it must be the exact same type as the output of recurrence for example if you need to return multiple things from occurrence is going to be returned as a tuple that means the argument to initializer it can be a list it must be a tuple even though Python coders typically use the two interchangeably this also means that a tuple containing five five is not the same as a tuple containing 5.0 5.0 as before you as a Python coder might think of these as equivalent but tensorflow scan does not as in exercise we are going to use our new knowledge of tensor flow scan to implement the Fibonacci sequence take a minute to try this yourself before moving on to the next slide if you don\'t remember how Fibonacci works it\'s a simple recurrence relation the current value is just the sum of the previous two values and the first two initial values are just zero and one ok so now we\'re going to tensorflow code that implements Fibonacci the relevant file in the course repo is hmm class /tf scan 2pi if you want to look at it on github so the first thing we do is we create a placeholder called n this is going to represent the number of Fibonacci numbers that we want remember that this has to be an integer and if you don\'t know how to create a scalar placeholder now you know it\'s just a tuple with no values in the recurrence function we need to return two things why is this well because in the Fibonacci series we need two pieces of information the last value and the second last value notice how everything here is consistent if the thing returned by the recurrence is a tuple of size 2 then we can index it using 0 & 1 therefore we can index last output by 0 & 1 where the element at index 0 represents the last last value and the element at index 1 represents the last value notice how in this example we don\'t use the current input at all in fact we\'re not even quite sure what it is yet next we have the scan function clearly FN should be the recurrence function we just defined the sequence we want to loop through is range of n this makes sense because if we loop through range of n that means we did something n times which is exactly what we want to do in order to get n Fibonacci numbers this also explains why we never use the elements of the sequence directly the tricky part is the initializer argument we know it has to be a tuple we also know it has to be consistent with what\'s being returned by the recurrence which is easy to see since all we do is addition the last thing we need to do as you know is run this in a session and pass in some value for n so let\'s try this and see what we get you our third example is going to be a simple low-pass filter also known as a moving average filter the recurrence relation for a low-pass filter is given by this equation s at time T equals the decay rate times s at time t minus 1 plus 1 minus the decay rate times X of T where s of T is the output and X of T is the input we can do this using only the knowledge we\'ve learned so far our goal is to be able to retrieve the clean version of a noisy signal to simulate this we\'re going to create a sine wave and add some noise to it and then try to recover the sine wave so if you want to try to code this yourself first please give it a try as it would be a great exercise the relevant file in the course repo is hmm class /tf scans three pi if you want to look at it on github okay so in addition to importing numpy and tensorflow we\'re going to import matplotlib to visualize the signal the first step is to create the signal which as we\'ve stated is going to be a sine wave plus some random noise we plot it here so you can see what it looks like next we set up placeholders for both the sequence and the decay rate although it\'s not really needed for the decay rate next we implement the recurrence function which is exactly what we stated earlier in the slides finally we define our low-pass filter to be to scan over this sequence using the recurrence we just defined the initial value here is arbitrary you could set it to zero you could also set it to the initial value of the sequence finally we call the low-pass filter in a session passing in the sequence and the decay rate and then plotting the result let\'s run this and see what we get you"", metadata={\'source\': \'A6qJMB3stE4\'})]""""""', '""""""[Document(page_content=""hello and welcome back in this video we are going to look at how to build a simple linear model using tensorflow and also Keras and what we\'ll do is we\'ll write some classes and we\'ll bring together all the information from the previous videos where we learned about tensors variables gradient tape modules layers Etc so let\'s get started the first thing we\'ll do is import libraries so we need tensorflow so import tensor flow as TF and then we need for plotting matplotlib the import matplot.lib Dot Pi plot as PLT and again with this we\'ll get the colors so colors is equal to PLT dot RC params and within this we have axes Dot prop underscore cycle and then we have the by underscore key to get the dictionary and then we get the value or the key color so if we if we just run this part what this gives us if we comment this out what we get is this which is a object if you look at the type of what this object is it\'s a cycler object so if you look at the type it\'s cycler and when we use the dot key dot by underscore key what we are getting is our dictionary so when we run this we get a type dictionary and this is how the dictionary looks like where we have the color which is the key and so if if we get the value if we need to get these values for the key color then we can simply put color in front of it in square brackets and you get this list of colors so we\'ll use those colors as we go through this particular video now the entire example that we are going to look at today is directly from the docs so let me go ahead and add the link here so if you need to go back and look at it further the exact code is copy pasted from that particular document and I\'m just going to walk through it explain it maybe type it and kind of uh we\'ll see how we can use the code that\'s there to create a simple linear model so the tips that to before we get started the code here are a couple of tips for solving any type of machine learning model uh these are the highlights that we we already know or we should be looking at is first thing we need to do is we need to obtain the data uptrend training data and once we have the data we can define a model and then we need to define a loss function and once we have these done we can train the model so we can run through the training data training data and then calculate the loss and what law says is it\'s a way to kind of quantify the difference between the actual value and the predicted value once we do once we do that then we can calculate calculate gradients and the reason for calculus then gradients of all the laws is because we can then update the parameters such as W and X in this particular case that will bring the predicted values closer to the actual values and thus reduce the difference between those and hence reduce loss and then the next step of course would be to evaluate the results with this in mind then let\'s see how our simple linear model equation would look like and it\'s going to be Y is equal to or let\'s say f of x is equal to X star W plus b and here what we have is w is the we\'ll call it as weights and then the B we\'ll call this as the bias all right so now the very first step we are going to do is create the data so we\'ll create the data for this example and the data is going to be pretty simple we\'ll declare some Global variables uh so that we will fix the values of w and B and those would be the actual values so this is the actual values actual values for the Y that will be create of that PV will be predicting so true is equal to 3.0 and true B is equal to 2.0 and we\'ll set the number of examples or the number of Records to 201 next we\'ll create the values for X so this usually we would say these are the features X is equal to TF dot Lin space and we\'ll get values from minus 2 to 2 and the number of values we need is same as num examples and when we look at the X it is going to be these are the values between minus 2 and then we have the 2 right here and the data type is float64 so what we can do is is convert this to floor 32 so we can cast X to TF Dot float32 and so now when we look at the same X we have the data type as float32 additionally we can go ahead and Define a function to calculate r y function to calculate y so let\'s call this d e d f f of x this takes in just our input value of x and it will return x times W so this is going to be true w plus true B okay so that\'s how the function would be defined and then we\'ll create a noise to a gaussian noise that will add to the values of Y that will be created by this function so let\'s create some uh gaussian noise and so noise is equal to TF dot random dot normal and here will the shape of that of course will be the same number of records as we have up above so example with a s examples and then we\'ll calculate the Y so Y is going to be equal to f of x so f of x will get us the calculate the values for a y for each of the x\'s and then we add the noise to it and so this is how our y values are going to look like again those will be floor 32 as we can see let\'s now plot these values and see how they look like on a scatter plot so to plot these we would simply say PLT Dot Plot X comma Y and then within codes we can put a dot and then PLT dot show so let\'s look at this so here\'s our plot that\'s the data and it\'s looking pretty good now let\'s look at how we can Define the model by creating a class and this is going to be similar method that we have already seen in previous videos where they are going to create a class using TF dot module so class my mod my model and then we have TF dot module and inside of this we have the init method if in it and inside of this we have the keyword argument so self and Then star star keyword arcs and then within this we have the super dot underscore underscore init and within this then we have the keyword also again star star keyword arguments and now what we can do is declare the create the variables for self and B sorry W and B so self dot w is equal to TF dot variable and let\'s set the value of this to 5 and then we have cell dot b is equal to TF dot variable and let\'s set the value of this to 0.0 with this now we are ready to create the method call so DF underscore call underscore underscore self and we have a input value of x that comes in and then we return the calculated value of y which is going to be simply x times x times W so self W plus p and so we\'ll type self dot b in this case so that\'s our class my model and we are going to now use it to create the model so model is equal to my model open close parenthesis and we can look at the variables so we can print variables for this so print model dot variables and this will give us the variables that are in this model so why don\'t we do one thing we can name this so let\'s add the name here name W for this and then you can add a name is equal to B for this one so now when we run both of these cells again what we have is this model with a variable variables we have B and then the second variable we have is w and they are accordingly set to the values 0 and 5 that we have earlier in this particular class uh we can also check to see if the model works correctly and to do that uh let\'s so we\'ll call this verify that model works and you can use the assert statement assert model and if we pass in the value of 3.0 which if you look at the calculations we will have 3 times 5 which is from here so that is 15 plus 0 and so the output the return from this should be 15 and so we\'ll check that value if that value is equal to 15.0 and if it is we should get a true in the output so well I do not see anything here in the output so let\'s see if we can run that again okay so looks like we are good there now let\'s define a loss function Define a loss function and here what we\'ll create is d f loss and this will take in the two input values Target underscore Y and predicted underscore Y and then this will return the square difference so we have uh tf.reduce underscore so essentially what we are doing is first we are getting the difference so Target underscore y minus predicted underscore y so once we have that we can square this so TF dot square and once we have the squared value you get the mean value of this so for that we would simply type TF dot reduce mean reduce underscore mean in front of it so that\'s our loss function next what we can do is plot the values for the X Y and the predicted values and see what sort of plot we get PLT Dot Plot X comma Y and the for in the first case what we\'ll do is we\'ll simply have a DOT so this would be the original data when we will label this as label is equal to uh this would be just data original that we have then we\'ll plot the ground rules so PLT Dot Plot and this would be X and this would directly be calculated from the equation so we just use the f of x there and we label this as the ground truth ground truth and finally we have the predicted value prte Dot Plot and this will again take X so then the predictions would be not from f of x but from model X and again here we would use the labels and the labels would be predictions now with all this setup we can print the Legends Legend and we can then print uh we can type plt.show to PLT dot show and get the final plot printed and here is the plot we have oh well the reason why we have that works so beautifully is because I already ran the other model so let\'s run this again okay so that\'s what I wanted to show so what we have is the original data which is the ground truth and then we have the original data is in blue then we have the orange color line that\'s the ground root and we have the predicted line which is the green line you can see that that line is pretty off and the reason because reason is because uh that\'s just gone through one iteration of the training and so the values of w are never updated if we print the loss so if it\'s a print a small print and if you print the current loss and print the law says loss we can calculate directly from Y and using model or model X and then convert it to num pi and oops sorry that should be parenthesis instead of 90 there all right so when we run this we we should get the plot and we are missing a parenthesis again so it should be working okay so here\'s what we have we have the plus that is 10 and that kind of tells us that our line is not your best fit and as we\'ll go through this now we\'ll set up a training and we\'ll see that the loss comes down quite a bit to around one now let\'s define a training Loop I\'m going to create a text cell here EF Define a training Loop foreign [Music] specific tasks and let\'s see what those tasks are the first one is sending a batch of inputs through so let\'s put it in short so what we send is a batch of inputs and we send this through the model and thus we generate the outputs that\'s one thing and then then is calculating the loss so we calculate the loss and then use gradient tape use gradient tape to find gradients and this is to find the gradients and finally optimize the variables with those gradients so optimize uh optimize variables this is using the gradients so let\'s look at how we can perform these tasks very first thing that we\'ll do is we\'ll Define a function train so Define train and this will take in input arguments model X Y and the learning rate and inside of this then we have with TF dot gradient tape and we have as T so let\'s call as tape and here we\'ll say current underscore loss is equal to loss into y so so this is going we are calling the last function loss Y and then model y so we have the actual value and the predicted value from model y then we calculate the gradient so d w DB those are the gradients and this is tape dot gradient and this will use the current underscore loss and then we use the model dot w and model dot b like so and then we have model.w dot assign underscore sub learning underscore rate and then we have star DW they are modeled or model dot b dot assign underscore thumb learning [Music] underscore rate star and this is going to be DB so that\'s that\'s the function that will use to train and so what this will do is take the model uh then have the X and Y uh values and then the learning rate and we\'ll calculate the loss the gradient update the values for the gradients now let\'s look at the training so training and what we\'ll do here is create a model using my model that we have above class above and then during this we\'ll collect data for history so we\'ll collect the weights bits and we have a empty list biases and we have a empty list then we have epochs and we have range of let\'s say a range of 10 epochs 10 iterations and now we are going to define the training Loop training Loop and inside of this we have will create a report at each end of end of each Epoch and the report will consists of the values for the loss uh then parameters W and B so they will just return a string in this case of string will have W is equal to inside of the breast so curly braces we have model dot w dot numpy so we have an array and we specify the the number of decimals to 0.1.2 F and after this we have the second variable B that is equal to again another dictionary you can put in there and then finally we will have loss that is going to be equal to another dictionary right there so for the B what we are going to type is model dot b Dot numpy and again this can be 1.2 F and finally for the loss in this case we\'ll set this to loss and then 2.5 f so that\'s our that\'s our function which will give us the string back for uh to so that we can see that in the output while the training is going on and then we have the train Loop itself or training Loop itself and so well so here we have we are already in that so why not just delete that training underscore Loop this takes in the model takes in y takes in x and then for epoch in epox here first thing we\'ll do is update the model with a single giant batch and the reason for that is the data set is very small so we can just input the entire data at once so train and inside of this we have model X Y and learning rate we can set it to 0.1 so let\'s put a 0.1 there and after this we have the width so let\'s write this here so one update the model update the model and then we have right here are track track variables uh variables and losses so we\'ll just put a word track there so in track again we are going to append the values so weights dot append model dot w dot numpy and then we have biases dot append model dot b Dot numpy and then we have current underscore loss is equal to loss and then inside of this we have y and of course we need the that was the actual ground truth and this is the going to be the predicted value so we are going to track that put that in the empty list we created above and then we are going to print this string so this is going to be Epoch and this is the epoch and 2D close the curly braces colon and then they will put the starting loss here and the rest of it would be printed by the report so print We can spray one two three couple of spaces one two three four and then report inside of this model and current underscore loss okay so that\'s the okay that was something new there okay so that\'s the uh training Loop that we have created now let\'s do the training let\'s do some training let\'s do some training and here what we are going to do is create some more cells now for training we are going to use current underscore loss is equal to loss and this will be y comma model what we are trying to do here is we are getting the current loss and printing it the very initial first loss of before we use the report statement to print us the loss from the history that\'s going to be printed so print F and this is the starting starting and we have print and inside of this here one two three four one two three four and Report model dot model and then your comma current underscore loss okay and finally we have the training Loop we call that function with the model X and Y now here\'s what\'s happening before we run this let\'s step through this and see what\'s happening so the very first thing is we calculate the last printed so this is the ones first step you will see the last printed out then we are calling the training underscore Loop what that will do is will go back up call this Loop and this will run the for Loop uh it will run 10 times and in each each time it runs each iteration we are calling the train we are calling the train and that\'s uh the function up above what this will do is in the first iteration it will calculate the loss it will calculate the gradient update the values for w and B and then ah update the values for w and B and so when we are back here we what we do is put them in our history and then print whatever those values or whatever loss we are reporting in the second iteration again we go back in here again we call the train so it come we come back here and each time we are calculating this new gradient and when we are doing this we are also passing the model which is uh what we have here as well and that model then is the model that we have defined above right here which is based on the class model and so the updated W\'s that we get in each iteration will calculate a new value of in this equation that would be returned and when it is returned ah right here that difference between the value return by model and the actual value of y will diminish and thus the loss with diminish and so we should see that the current loss diminishes as the number of epochs increase so let\'s run this and see what we get so as you can see here we have the loss initial loss was 10 and after these many iterations 10 iterations the loss goes down to 1.0 and accordingly we see the value of w seems to change but after some time it changes little bit it reaches three it changes by a few decimals and same thing with the B once it reaches 1 it changes ah it it has changed quite a bit but not much change between these two right here let\'s now look at how we can plot the weights and the biases so we\'ll create a plot PLT Dot Plot the Box on the x-axis rates on the y-axis and we\'ll have the labels so the weights and we\'ll set the color is equal to colors and we\'ll use the color that\'s at zero so this is a nice method where we can have a control or what color we can assign to the line epox and here we\'ll use the true value of w and we create a list which has the same length as the epox has so we type the epochs here into lengthy box and then I will set the style of this line to our dashed line finally we have the label that is going to be the ground truth or true weight and uh then we have the color color would put the same color as we had above for that line and we\'ll copy the same two lines put them down below and use them for the biases so why why it says is here and will of course label this as a bias and change the color to the one same thing here we have the value of true B that we would like to print and the label is going to be true bias and finally we change this color right here to one and with that then we I think we are ready to plot this uh all we need to do is create add the legend line PLT dot Legend and Final pld.show now the output that we\'ll see now is this pretty interesting and informative output where we have the trend that shows how the value for the weights has decreased and it gradually approaches close to 3 and similar to the value for the bias it increases and gradually approaches the value of 2 so this is what uh kind of informs us how the values for the weights and biases change over time now let\'s look at how the Trend models perform on the data that we have so we\'ll plot again have the scatter plot plt.plot X and Y X sorry X comma y with the dot in there for printing and we label this as our original data and then below that we have plt.plot and we have X comma f of x and here then we have the label this label is going to be the ground truth ground truth t r u t h and then we have the prediction so PLT Dot Plot and for predictions of course we are going to use the model X model f of model X and then we have a level for this so let\'s add the label is equal to this is the predictions now we land this with the legend and plt.show PLT dot Legend and then we have pl2. show all right so let\'s print this and see what output where we get so as you can see oh okay so there\'s I think uh I need to go back and run these lines again because uh earlier I went Gap backup and run hard on the earlier itself and that\'s why that line was not fitting okay so now we are good what we have is the same set of data points as we had earlier and the orange line that was there and now as you can see the pitted line is pretty close to the ground truth which is the Orange Line the green line is very close to the orange line and so that\'s how the up on the process of updating the weights and biases helped us reduce the loss and bring the predictions closer to reality we can also print the loss of this model and so if you print current loss and we can we can get the current loss of course from the loss function so loss and we have the model X so the in earlier value of y and then you have the value from the model X and we can convert this to an numpy array and so in the output again we should see the same plot and the value of loss so here the current loss is 1 as opposed to the earlier case where we had this line which was not a good fit line and where we saw that the current loss at that time was 10. so that\'s how we can proceed through updating the weights and biases to arrive at the final answer now let\'s take a small uh detour from Keras uh created from tensorflow uh cold tensorflow and look at how we could get the same solution in Keras so let\'s look at Keras now and the setup is similar as we have seen in previous class where we created modules for that so in this case we create a model Keras so it was the same class my model and we\'ll add Keras in front of it and instead of TF dot module not now we are going to use tf.keras.model and inside of this again we have the same init class so init and here we have the same self and we have the same keyword arguments star star k w a r g s and we also have the same super Dot in it and here we have uh keyword arguments keyword arcs and so that that\'s that now we again need to Define w and B so let\'s define that self dot w is equal to TF dot variable and assign it to value of 5.0 and likewise we have self dot b and we\'ll assign it a value of 0. so that was 5 and now we\'ll assign a value of 0. so like so so with this then we have defined these two things next we need to define the call and because we are inside of we are using Keras model now we instead of writing this underscore underscore call we are simply going to type call and then we have self comma X colon and inside of this we\'ll perform the calculation and return the value of the Y so self this is going to be x times self dot w plus self dot b and so that\'s how we have our model ready now in addition to this we we now create a Keras model so Keras underscore model is equal to my model Keras and open close parenthesis of course we can use the same training Loop that we had earlier so uh we let\'s use that so we have a model ready and now we are going to reuse the training Loop with Keras model eras model and here we will use training underscore Loop and Keras underscore underscore model comma X comma y now uh just to recap if you go back up and look at the training model uh the class the sorry the training Loop the function that we have created is this one it takes in Model X and Y so all we are doing is replacing the model and this will call the train and train is right up here which will calculate the gradients form all right so now with this we can run this and uh we have we can see the loss as the initial loss was four I came down to three and sorry the weight was four came down to three and the last was six and it comes down to one now we can also use the checkpoint built-in that is built in Keras so we could also save the model uh like so so we can use a checkpoint uh inside of this so Keras underscore model dot save underscore weights and we can call this my underscore checkpoint and that will save the file that will save the weights so if you go back here putting uh this is several files I may have run earlier so that\'s how the checkpoint file will be saved that has the weights in it and now let\'s look at another way in which we can look at functionalities in Keras so for this we can we will need to use compile so that\'s again like another way so let\'s say another way another way to work in Keras and here what we do is Keras underscore model again we can use the same my model Keras and what we can do now is we can perform a com we can compile we can use model.compile so Keras underscore model dot compile and inside of this we can specify a certain uh of of arguments so here we can specify a run eagerly p-a-g-e-r and Y is equal to false and then we can specify optimizer is equal to RTF dot Keras Dot optimizers dot SGD stochastic gradient descent and we set the learning underscore rate is equal to 0.1 and in finally we can use loss is equal to TF dot errors dot passes dot mean underscore squared underscore underscore error so so this is the short and sweet way we can write a concise code using Keras and with this if we run this I think this there\'s an error there uh because we forgot to put a comma now okay so that did run and now we can perform the fit the print x dot shape zero look at the shape of X and then we can use Keras underscore model dot fit so if you\'ve looked at scikit learns this is similar way we can use the Keras at least in terms of fit epox is equal to 10 and that\'s underscore size is equal to 1000. so when we run this what we see here in the output is we have the epoch so one out of 10 and last one is 10 out of 10. uh we see the time it took to run that step and finally we see the loss the starting loss is 10 as we have been seeing earlier and the final loss are at end of the training is one so at this step the predictions should be preferably close to the actual values that are for the that we have for the ground tooth so that\'s it then that\'s how we can create a simple linear model using tensorflow or from scratch and we also looked at implementations using pure Keras or combination of tensorflow and Keras and we I hope this model this particular video can consolidates your knowledge from all of the previous videos in this series starting from the gradients or what are gradients what are variables what are constants modules layers Etc and if you have any questions comments or suggestions please do let me know in the comment section below I hope to see you all in this uh oncoming videos in this series please like share and subscribe it means a lot to me thank you"", metadata={\'source\': \'306tG48lhhQ\'})]""""""', '""""""[Document(page_content=""in this video we\'ll look at pf dot functions so let\'s go ahead and import the libraries first import tensorflow as tf and as we have seen in the previous video we\'ll try to create a function in python and then use the tf dot function decorator so tf so here we have def and the function let\'s say it\'s f which takes in two input well arguments x and y and what it returns is a square of x plus square of y and to this we are going to add the decorator tf dot function and so when the tensorflow executes this it will create a graph for this function now we can define the input values for x and y so x is equal to tf dot constant and let\'s say we have the values 1 and 2 and similarly for y i will create another variable here and the values would be minus 1 and minus 2. now when we call f with the input arguments x and y what we get in the output is the tensor which is shown over here which is a rank one tensor it has a shape of two and these are the values in the numpy array two and eight now we know that this is how the function is used in tensorflow let\'s look at a variation where we are trying to append a value to a list using function in python and let\'s see how tensorflow works with this so let\'s give this a heading called append and now here we\'ll create a function we\'ll first initialize the list so let\'s initialize the empty list and let\'s call this list as x list now we\'ll create a function and this would be df and let\'s call it f of x and within this function now we will create a for loop which such as like this for i in x print i colon i and then we are going to append so x list dot append i plus 1 so that\'s the function we have and to work with tensorflow we are going to add the decorator at tf dot function on top of this so with this then we can now create the input argument values so x is equal to tf dot constant and these values could be an array one dimensional so let\'s need the square bracket one two and three and now if we call f of x here and then if we try to print the value for our x list here we should see so what we see here is we have the uh tensor in the output which is this type as we can see here now the difference here is that the x list is outside of this function where we have the decorator and f of x and the for loop what the document suggest is instead of doing it like this there is an alternative way to do this using t t dot write so [Music] let\'s see how that would work we will create a function def function this is again f of x and here we\'ll create and tensor array t is equal to tf dot tensor array and we\'ll give it a data type the type is equal to tf dot in 32 and let\'s give it a size of zero and dynamic size is equal to true as new values get added it will change the size of t automatically and then we have the for loop here for i in range length of x which is the input argument we have and now to write to this tensor array that we initialized here we would simply write t is equal to t dot right and within this we specify i which is the value that we are getting in the for loop comma x i plus 1 so at each of these index we are going to add value of x i incremented by 1 and once that for loop is done we can then return this value t dot stack and now and finally we need to decorate this add tf dot function now if we initialize value of x such that x is equal to t f dot constant and here we specify values such as 1 2 and 3. now if we call f of x we get this output where we have a tensor as output and because everything here is in tensorflow uh this is the recommended way to perform append inside a function just using this dot write next let\'s let\'s look at concrete functions again we looked at this briefly in previous video we\'ll look at one example again in this video concrete functions and what concrete functions are are the few characteristics about the concrete functions are they\'re build on fly as the generic function is called as the generic function is called and again uh it is called every time that either the type changes or the shape changes or the python values then a new concrete function is created python arguments now let\'s see examples of these so we\'ll create a function again f of x and we\'ll start by decorating it with the tf dot function and then initialize sorry call it t f space f of x and then return the value of absolute value of x now with this if we call this function if we create uh f1 is equal to f dot get underscore concrete underscore function so we get the concrete function for f what this means is when we the when a tensorflow runs this particular function it creates a it will create a graph and the conc get concrete function will get the concrete function that is within that graph so we have done that for f1 and what we\'ll do next is we\'ll put a value here just an integer value of 1 within this as an input argument and then we\'ll create another function right here which is f2 we have f dot get underscore concrete underscore function and let\'s input a value of 2 now if we print with print if f1 is equal to f2 if then if f1 is f2 is it the same concrete function then in the output we see that it\'s set it\'s false and that tells us that when tensorflow created a graph while executing this function when the input value was 1 it was a different graph different concrete function within the graph and when the input value was 2 it was another concrete function in the graph now what happens when using in these situations is this particular execution becomes slow because a new graph is created a new concrete function is created within the graph so to make this work faster alternative is to input arguments that are tensorflow arguments so instead of input as of 1 we will say input where tf dot constant and here we have this rank 0 tensor so here we have tf dot constant and we specify 2 and this is now faster because the only one concrete function is created and that same concrete function is used in the second operation where we are trying to get the value for f2 additionally there are something called as input signatures and let\'s look at an example of that and again input signatures are another way to tell tensorflow that you can automatically convert some of the python items into tensorflow to make the quadrant faster create less concrete functions so let\'s create an uh function df f of x and we\'ll return a value of x plus one and here we\'ll add the decorator tf dot function now with this we\'ll create input values of x so let\'s first pass a vector and let\'s create that by calling tf dot constant and we can have values such as 1.0 and 2.0 next is equal to tf dot constant and we have two square records this time now if we try to get the concrete function f dot get underscore concrete underscore function using the x vector and then check if that is indeed the same from concrete function as we would get with the x matrix so f dot get underscore concrete underscore function x underscore matrix and here we see that that is not the case these two input arguments create different concrete functions within the tensorflow graph and that\'s because we have two different functions or two different shapes right here let\'s look at another example where we can update a tensorflow variable from within a function and this is a recommendation from tensorflow docs that the tf dot variable we defined outside of a function so let\'s see how we can do that tf dot variable is outside tf dot function and for let\'s say we define a variable var is equal to tf dot variable with the value of one and then we create the function add tf dot function and df f of x and here we have var dot assign add x so we are adding the value from x to the tf.variable and by doing this we should be able to update the tf dot variable that outside this function so now if we call f and we pass in the input argument tf dot constant let\'s say we pass in a value of 1 and now if we print var here we see that the value is updated to 2 so we incremented the value of 1 by adding this 1 to 2 and this is a recommended way of working with a variable other way that is also possible is the regular using a return statement within the function so let\'s say we have we defined c is equal to tf dot constant and assigned a value of 1 and then we create a function tf dot function and here we have we define f which takes into our input argument c and one so we have to pass in this as well as the incrementer that need to be added to c and within the inside the function then we can perform the operation and then return the value of c so here if we look at if we call this function f and we pass in the value c and then pass in the value of tf dot constant and value of 1 there now when we run this we get again the output 2 but the difference is that here the tensorflow variable is outside this function and in the output what we get is a variable whereas in this case the output that we get is a tensor now a couple of items to note as we move forward is tracing so in when the python is when tensorflow is computing a graph for a function the python operations are executed only once a python operations are executed only once and that\'s during the first time the code is run and for to test that let\'s try this function tf dot function and all these functions are directly from the docs so if you need more information you can always refer to the user guide df and here we can define f of a and b and sorry about that now if we print so printing at trace time and here we print the value of a is equal to a and then we print value of b is equal to is equal to b and then we return value of b so the first item let\'s say we said the value of a is equal to 1 and we said the value of b is equal to tf dot constant and let\'s say the value is again 1. now if we call the function with the input arguments a and b and when we look at the output we see that during the during tracing in the first cycle this was print the print statement was executed we have the value of a is equal to one assigned and b is equal to this particular tensor which is what we had passed here tf dot constant 1 and we have the value of 1 right here in the output that is returned by b now if we change the input values a little bit if we now say that we have the value of a is equal to 2 and if we have the value of b as the same as tf dot constant 1 and now if we run this this time again because we have this value that is different it will create another graph and therefore this line is printed again and so we have a is equal to 2 in the output and for b the return value of b we have 1 in the output now however if we now take this copy this uh let\'s say copy selection and now instead of changing the integer value of a if we change the value of b and now if you run this it uses the same graph as before so the print statement is not exactly executed python statement is ignored because the graph is already created and the reason why it is using the same graph is because the value of a is the same and the value for the tensor is the same shape and it\'s the same type so all we have done is replaced changed 1 by 2 and so in the output we get the value of b written as 2 as we can see here now let\'s look at a few ways in which tensorflow has provisions where we can allow it to automatically decide what atoms could be converted to tensorflow on data types so let\'s create a heading here using type annotations this is to improve performance the very first thing we\'ll try it is we\'ll create a function df and this is with hints and these examples again are directly from the docs here we specify x is equal to tf dot tensor as an input so that\'s could be the hint to tensorflow that incoming value could be represented as a tensor and here we can say tracing i\'m going to give this an arrow pointing left side and then we\'ll return a value of x and on top of this so let\'s try one more thing here we can use the tf dot function decorator this is the usual way we would write this but now for allowing annotations what we need to also input ntf dot function is experimental follow type hints is equal to true so that\'s why we have the name of the function with hints and copy this paste it here and what we\'ll do we\'ll also copy this line and we\'ll set it to false right here and rest of it stays the same and with will change the name of the function to no hints now with this setup let\'s run this uh with and with hints and no ends and see if what difference it makes the first item will try to run it will try to print f no hints and we\'ll pass in a value one and let me copy this and paste it here again we\'ll create a new line and similarly copy this and paste it here we have value of 2 and again a value of 2 here and we\'ll copy this entire block paste it down below and here we\'ll use the function with instead of no and here we have width and what i\'m going to do now is change all of these and now if we run this we should see the difference so as we can see here we have when we run without hints as we can see in the first two cases we have the value of tensor tf.tensor is one and we have the print statement executed in the second case also we have the print statement executed because we are not going giving tensorflow any hint that the values that are coming in could be represented as a tensor but when we specify a hints is equal to true in those cases when we pass in a value of 1 the tensorflow interprets it as a tensor and not just an integer and so while tracing while creating a graph it is it does print the print statement very first time but then second time it automatically detects these two as a tensor considers these two as a tensor and therefore it doesn\'t bother creating a new graph it uses the previous graph and therefore the tracing print statement is ignored and we just have this output right here so that was it for this video i hope in this video you got some additional information about how the tf dot function works in tensorflow we\'ll continue with other topics in tensorflow in following videos please like share and subscribe i hope to see you all in the next video thank you"", metadata={\'source\': \'iFZRUwGcrxQ\'})]""""""']","{'https://stackoverflow.com/questions/53032922/tensorflow-while-loop-with-condition-dependent-on-body', 'https://stackoverflow.com/questions/37441140/how-to-use-tf-while-loop-in-tensorflow'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow while loop with condition dependent on body\n\nAsked 5 years, 8 months ago\n\nModified 5 years, 8 months ago\n\nI want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don\'t know how to accomplish this with tf.while_loop(). My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by\n\nimport numpy as np import tensorflow as tf IMAGE_SHAPE = [960, 720] CROP_SHAPE = [320, 240] max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])\n\nand the condition is\n\ncond = tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop)\n\nGoing over the documentation and examples of tf.while_loop(cond, body, loop_vars, ...), what I understand is that both cond and body should take the same arguments given in loop_vars. I don\'t see how I can have cond depend on img_crop which would be calculated inside body, and isn\'t provided in loop_vars. I could equivalently compute cond using crop_begin_index without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem. Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use tf.while_loop()? The arguments that are passed on to the condition function are the arguments returned from your body function. So you just have to return that value that you want to base your condition on in the body function, then carry out the condition on that value in your cond function. Something like,\n\ndef body(image_shape, crop_shape, img_crop): max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1]) return (image_shape, crop_shape, img_crop) def cond(image_shape, crop_shape, img_crop): return tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop) image_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))\n\nDon\'t have access to an interpreter right now, so there might be some syntax problems there, but something like that. Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions. Also note, you\'ll need to specify some initial value for img_crop in the loop vars. Moreover, by default, tf.while_loop expects the shapes of all the loop_vars to remain the same across all loop runs. You can modify this through the shape_invariants argument. Sean BugejaSean Bugeja\n\n1\n\nGot it. I was also able to use just crop_begin_index as a variable like I wrote so the loop is more concise. Thanks!""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow while loop with condition dependent on body\n\nAsked 5 years, 8 months ago\n\nModified 5 years, 8 months ago\n\nI want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don\'t know how to accomplish this with tf.while_loop(). My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by\n\nimport numpy as np import tensorflow as tf IMAGE_SHAPE = [960, 720] CROP_SHAPE = [320, 240] max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])\n\nand the condition is\n\ncond = tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop)\n\nGoing over the documentation and examples of tf.while_loop(cond, body, loop_vars, ...), what I understand is that both cond and body should take the same arguments given in loop_vars. I don\'t see how I can have cond depend on img_crop which would be calculated inside body, and isn\'t provided in loop_vars. I could equivalently compute cond using crop_begin_index without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem. Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use tf.while_loop()? The arguments that are passed on to the condition function are the arguments returned from your body function. So you just have to return that value that you want to base your condition on in the body function, then carry out the condition on that value in your cond function. Something like,\n\ndef body(image_shape, crop_shape, img_crop): max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1]) return (image_shape, crop_shape, img_crop) def cond(image_shape, crop_shape, img_crop): return tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop) image_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))\n\nDon\'t have access to an interpreter right now, so there might be some syntax problems there, but something like that. Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions. Also note, you\'ll need to specify some initial value for img_crop in the loop vars. Moreover, by default, tf.while_loop expects the shapes of all the loop_vars to remain the same across all loop runs. You can modify this through the shape_invariants argument. Sean BugejaSean Bugeja\n\n1\n\nGot it. I was also able to use just crop_begin_index as a variable like I wrote so the loop is more concise. Thanks!""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow while loop with condition dependent on body\n\nAsked 5 years, 8 months ago\n\nModified 5 years, 8 months ago\n\nI want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don\'t know how to accomplish this with tf.while_loop(). My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by\n\nimport numpy as np import tensorflow as tf IMAGE_SHAPE = [960, 720] CROP_SHAPE = [320, 240] max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])\n\nand the condition is\n\ncond = tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop)\n\nGoing over the documentation and examples of tf.while_loop(cond, body, loop_vars, ...), what I understand is that both cond and body should take the same arguments given in loop_vars. I don\'t see how I can have cond depend on img_crop which would be calculated inside body, and isn\'t provided in loop_vars. I could equivalently compute cond using crop_begin_index without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem. Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use tf.while_loop()? The arguments that are passed on to the condition function are the arguments returned from your body function. So you just have to return that value that you want to base your condition on in the body function, then carry out the condition on that value in your cond function. Something like,\n\ndef body(image_shape, crop_shape, img_crop): max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1]) return (image_shape, crop_shape, img_crop) def cond(image_shape, crop_shape, img_crop): return tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop) image_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))\n\nDon\'t have access to an interpreter right now, so there might be some syntax problems there, but something like that. Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions. Also note, you\'ll need to specify some initial value for img_crop in the loop vars. Moreover, by default, tf.while_loop expects the shapes of all the loop_vars to remain the same across all loop runs. You can modify this through the shape_invariants argument. Sean BugejaSean Bugeja\n\n1\n\nGot it. I was also able to use just crop_begin_index as a variable like I wrote so the loop is more concise. Thanks!""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow while loop with condition dependent on body\n\nAsked 5 years, 8 months ago\n\nModified 5 years, 8 months ago\n\nI want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don\'t know how to accomplish this with tf.while_loop(). My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by\n\nimport numpy as np import tensorflow as tf IMAGE_SHAPE = [960, 720] CROP_SHAPE = [320, 240] max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])\n\nand the condition is\n\ncond = tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop)\n\nGoing over the documentation and examples of tf.while_loop(cond, body, loop_vars, ...), what I understand is that both cond and body should take the same arguments given in loop_vars. I don\'t see how I can have cond depend on img_crop which would be calculated inside body, and isn\'t provided in loop_vars. I could equivalently compute cond using crop_begin_index without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem. Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use tf.while_loop()? The arguments that are passed on to the condition function are the arguments returned from your body function. So you just have to return that value that you want to base your condition on in the body function, then carry out the condition on that value in your cond function. Something like,\n\ndef body(image_shape, crop_shape, img_crop): max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1]) return (image_shape, crop_shape, img_crop) def cond(image_shape, crop_shape, img_crop): return tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop) image_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))\n\nDon\'t have access to an interpreter right now, so there might be some syntax problems there, but something like that. Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions. Also note, you\'ll need to specify some initial value for img_crop in the loop vars. Moreover, by default, tf.while_loop expects the shapes of all the loop_vars to remain the same across all loop runs. You can modify this through the shape_invariants argument. Sean BugejaSean Bugeja\n\n1\n\nGot it. I was also able to use just crop_begin_index as a variable like I wrote so the loop is more concise. Thanks!""""""', '""""""Can anyone give me few more complex example? Also, in such case that if the future computation is based on the tensor output (ex: the RNN stop based on the output criterion), which is very common case. Is there an elegant way or better way instead of dynamic graph? 1\n\nstackoverflow.com/q/66185202/14337775. I\'m facing a problem where the gradients are None while implementing SimpleRNN using subclassing. I\'m wondering whether I need symbolic loop or can I manage without it? What is stopping you from adding more functionality to the body? You can build whatever complex computational graph you like in the body and take whatever inputs you like from the enclosing graph. Also, outside of the loop, you can then do whatever you want with whatever outputs you return. As you can see from the amount of \'whatevers\', TensorFlow\'s control flow primitives were built with much generality in mind. Below is another \'simple\' example, in case it helps. import tensorflow as tf import numpy as np def body(x): a = tf.random_uniform(shape=[2, 2], dtype=tf.int32, maxval=100) b = tf.constant(np.array([[1, 2], [3, 4]]), dtype=tf.int32) c = a + b return tf.nn.relu(x + c) def condition(x): return tf.reduce_sum(x) < 100 x = tf.Variable(tf.constant(0, shape=[2, 2])) with tf.Session(): tf.global_variables_initializer().run() result = tf.while_loop(condition, body, [x]) print(result.eval())\n\nPeter GoldsboroughPeter Goldsborough\n\n1,3\n\nGood explanation. My problem is the condition I need is calculated after run the body once. So it is like I need to use the return value of body as a parameter for condition. What you want is precisely what happens. The loop is while(condition(tensors)) { tensors = body(tensors); }, so the tensors you pass are updated to the tensors returned by the body each time, and then those updated tensors are passed to condition. The only time condition is called before body is the very first time, before the body of the pseudo-code loop above is entered. However, in that case, it\'s just about initializing the tensors you pass in loop_vars correctly. For example, you could pass the result of body as the loop_vars tensors to while_loop. oh, with loop_vars I refer to the function definition of while_loop, which is while_loop(condition, body, loop_vars) (its the tensors that are passed to condition and body)\n\n\n\n""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nTensorFlow while loop with condition dependent on body\n\nAsked 5 years, 8 months ago\n\nModified 5 years, 8 months ago\n\nI want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don\'t know how to accomplish this with tf.while_loop(). My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by\n\nimport numpy as np import tensorflow as tf IMAGE_SHAPE = [960, 720] CROP_SHAPE = [320, 240] max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])\n\nand the condition is\n\ncond = tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop)\n\nGoing over the documentation and examples of tf.while_loop(cond, body, loop_vars, ...), what I understand is that both cond and body should take the same arguments given in loop_vars. I don\'t see how I can have cond depend on img_crop which would be calculated inside body, and isn\'t provided in loop_vars. I could equivalently compute cond using crop_begin_index without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem. Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use tf.while_loop()? The arguments that are passed on to the condition function are the arguments returned from your body function. So you just have to return that value that you want to base your condition on in the body function, then carry out the condition on that value in your cond function. Something like,\n\ndef body(image_shape, crop_shape, img_crop): max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE) crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index) img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1]) return (image_shape, crop_shape, img_crop) def cond(image_shape, crop_shape, img_crop): return tf.count_nonzero(img_crop > 0) > 0.5 * tf.size(img_crop) image_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))\n\nDon\'t have access to an interpreter right now, so there might be some syntax problems there, but something like that. Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions. Also note, you\'ll need to specify some initial value for img_crop in the loop vars. Moreover, by default, tf.while_loop expects the shapes of all the loop_vars to remain the same across all loop runs. You can modify this through the shape_invariants argument. Sean BugejaSean Bugeja\n\n1\n\nGot it. I was also able to use just crop_begin_index as a variable like I wrote so the loop is more concise. Thanks!""""""', '""""""Can anyone give me few more complex example? Also, in such case that if the future computation is based on the tensor output (ex: the RNN stop based on the output criterion), which is very common case. Is there an elegant way or better way instead of dynamic graph? 1\n\nstackoverflow.com/q/66185202/14337775. I\'m facing a problem where the gradients are None while implementing SimpleRNN using subclassing. I\'m wondering whether I need symbolic loop or can I manage without it? What is stopping you from adding more functionality to the body? You can build whatever complex computational graph you like in the body and take whatever inputs you like from the enclosing graph. Also, outside of the loop, you can then do whatever you want with whatever outputs you return. As you can see from the amount of \'whatevers\', TensorFlow\'s control flow primitives were built with much generality in mind. Below is another \'simple\' example, in case it helps. import tensorflow as tf import numpy as np def body(x): a = tf.random_uniform(shape=[2, 2], dtype=tf.int32, maxval=100) b = tf.constant(np.array([[1, 2], [3, 4]]), dtype=tf.int32) c = a + b return tf.nn.relu(x + c) def condition(x): return tf.reduce_sum(x) < 100 x = tf.Variable(tf.constant(0, shape=[2, 2])) with tf.Session(): tf.global_variables_initializer().run() result = tf.while_loop(condition, body, [x]) print(result.eval())\n\nPeter GoldsboroughPeter Goldsborough\n\n1,3\n\nGood explanation. My problem is the condition I need is calculated after run the body once. So it is like I need to use the return value of body as a parameter for condition. What you want is precisely what happens. The loop is while(condition(tensors)) { tensors = body(tensors); }, so the tensors you pass are updated to the tensors returned by the body each time, and then those updated tensors are passed to condition. The only time condition is called before body is the very first time, before the body of the pseudo-code loop above is entered. However, in that case, it\'s just about initializing the tensors you pass in loop_vars correctly. For example, you could pass the result of body as the loop_vars tensors to while_loop. oh, with loop_vars I refer to the function definition of while_loop, which is while_loop(condition, body, loop_vars) (its the tensors that are passed to condition and body)\n\n\n\n""""""']"
