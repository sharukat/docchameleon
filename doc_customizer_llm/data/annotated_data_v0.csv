,QuestionId,Title,Body,DocRelated,Issue Type
0,34619177,What does tf.nn.conv2d do in tensorflow?,"<p>I was looking at the docs of tensorflow about <code>tf.nn.conv2d</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""noreferrer"">here</a>. But I can't understand what it does or what it is trying to achieve. It says on the docs,</p>
<blockquote>
<p>#1 : Flattens the filter to a 2-D matrix with shape</p>
<p><code>[filter_height * filter_width * in_channels, output_channels]</code>.</p>
</blockquote>
<p>Now what does that do? Is that element-wise multiplication or just plain matrix multiplication? I also could not understand the other two points mentioned in the docs. I have written them below :</p>
<blockquote>
<p># 2: Extracts image patches from the the input tensor to form a virtual tensor of shape</p>
<p><code>[batch, out_height, out_width, filter_height * filter_width * in_channels]</code>.</p>
<p># 3: For each patch, right-multiplies the filter matrix and the image patch vector.</p>
</blockquote>
<p>It would be really helpful if anyone could give an example, a piece of code (extremely helpful) maybe and explain what is going on there and why the operation is like this.</p>
<p>I've tried coding a small portion and printing out the shape of the operation. Still, I can't understand.</p>
<p>I tried something like this:</p>
<pre class=""lang-python prettyprint-override""><code>op = tf.shape(tf.nn.conv2d(tf.random_normal([1,10,10,10]), 
              tf.random_normal([2,10,10,10]), 
              strides=[1, 2, 2, 1], padding='SAME'))

with tf.Session() as sess:
    result = sess.run(op)
    print(result)
</code></pre>
<p>I understand bits and pieces of convolutional neural networks. I studied them <a href=""http://cs231n.github.io/convolutional-networks/"" rel=""noreferrer"">here</a>. But the implementation on tensorflow is not what I expected. So it raised the question.</p>
<p><strong>EDIT</strong>:
So, I implemented a much simpler code. But I can't figure out what's going on. I mean how the results are like this. It would be extremely helpful if anyone could tell me what process yields this output.</p>
<pre class=""lang-python prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,2,2,1]))
filter = tf.Variable(tf.random_normal([1,1,1,1]))

op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME')
init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)

    print(&quot;input&quot;)
    print(input.eval())
    print(&quot;filter&quot;)
    print(filter.eval())
    print(&quot;result&quot;)
    result = sess.run(op)
    print(result)
</code></pre>
<p>output</p>
<pre><code>input
[[[[ 1.60314465]
   [-0.55022103]]

  [[ 0.00595062]
   [-0.69889867]]]]
filter
[[[[-0.59594476]]]]
result
[[[[-0.95538563]
   [ 0.32790133]]

  [[-0.00354624]
   [ 0.41650501]]]]
</code></pre>
",1,Documentation Replication on Other Examples
1,34642595,Tensorflow Strides Argument,"<p>I am trying to understand the <strong>strides</strong> argument in tf.nn.avg_pool, tf.nn.max_pool, tf.nn.conv2d. </p>

<p>The <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#max_pool"" rel=""noreferrer"">documentation</a> repeatedly says </p>

<blockquote>
  <p>strides: A list of ints that has length >= 4. The stride of the sliding window for each dimension of the input tensor.</p>
</blockquote>

<p>My questions are:</p>

<ol>
<li>What do each of the 4+ integers represent?</li>
<li>Why must they have strides[0] = strides[3] = 1 for convnets?</li>
<li>In <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3%20-%20Neural%20Networks/convolutional_network.ipynb"" rel=""noreferrer"">this example</a> we see <code>tf.reshape(_X,shape=[-1, 28, 28, 1])</code>. Why -1?</li>
</ol>

<p>Sadly the examples in the docs for reshape using -1 don't translate too well to this scenario.</p>
",1,Documentation Ambiguity
2,34931121,Can cond support TF ops with side effects?,"<p>The (source code) documentation for <code>tf.cond</code> is unclear on whether the functions to be performed when the predicate is evaluated can have side effects or not. I've done some tests but I'm getting conflicting results. For example the code below does not work:</p>

<pre><code>import tensorflow as tf
from tensorflow.python.ops import control_flow_ops

pred = tf.placeholder(tf.bool, [])
count = tf.Variable(0)
adder = count.assign_add(1)
subtractor = count.assign_sub(2)

my_op = control_flow_ops.cond(pred, lambda: adder, lambda: subtractor)

sess = tf.InteractiveSession()
tf.initialize_all_variables().run()

my_op.eval(feed_dict={pred: True})
count.eval() # returns -1

my_op.eval(feed_dict={pred: False})
count.eval() # returns -2
</code></pre>

<p>I.e. no matter what value the predicate evaluates to, both functions are getting run, and so the net result is a subtraction of 1. On the other hand, this code snippet does work, where the only difference is that I add new ops to the graph every time <code>my_op</code> is called:</p>

<pre><code>pred = tf.placeholder(tf.bool, [])
count = tf.Variable(0)

my_op = control_flow_ops.cond(pred, lambda:count.assign_add(1), lambda:count.assign_sub(2))

sess = tf.InteractiveSession()
tf.initialize_all_variables().run()

my_op.eval(feed_dict={pred: False})
count.eval() # returns -2

my_op.eval(feed_dict={pred: True})
count.eval() # returns -1
</code></pre>

<p>Not sure why creating new ops every time works while the other case doesn't, but I'd obviously rather not be adding nodes as the graph will eventually become too big.</p>
",1,Documentation Replicability
3,35689547,How to process single training file in parallel,"<p>I have a file <code>train.csv</code> that contains paths to images and their labels. ie:</p>

<pre><code>img1.jpg 3
img2.jpg 1
...
</code></pre>

<p>After going through the <a href=""https://www.tensorflow.org/versions/r0.7/how_tos/reading_data/index.html"" rel=""nofollow"">reading data tutorial</a> I came up with some code to go through each image, resize it and apply distortions:</p>

<pre><code>def apply_distortions(resized_image):
    # do a bunch of tf.image distortion...
    return float_image

def processing(filename):
    file_contents = tf.read_file(filename)
    image = tf.image.decode_jpeg(file_contents, channels=3)
    resized_image = tf.image.resize_images(image, 299, 299)
    distorted_image = apply_distortions(resized_image)
    return distorted_image

def parse_csv(filename_queue):
    line_reader = tf.TextLineReader()
    key, line = line_reader.read(filename_queue)
    filename, label = tf.decode_csv(line,     # line_batch or line (depending if you want to batch)
                               record_defaults=[tf.constant([],dtype=tf.string),
                                                tf.constant([],dtype=tf.int32)],
                               field_delim=' ')
    processed_image = processing(filename)
    return processed_image, label
</code></pre>

<p>The problem now is that I'm confused how to do these operations across the file in parallel. The documentation suggests either using <code>tf.train.batch_join</code> or <code>tf.train.batch</code> with num_threads=N.</p>

<p>I first tried following the example code using <code>tf.train.batch_join</code> but this seems to be intended for processing multiple files in parallel. In my case however I just have 1 file. </p>

<pre><code>filename_queue = tf.train.string_input_producer([""train.txt""], num_epochs=1, shuffle=True)    
example_list = [parse_csv(filename_queue) for _ in range(8)]
example_batch, label_batch = tf.train.batch_join(example_list, batch_size)
</code></pre>

<p>I also tried setting <code>tf.train.batch([example, label], batch_size, num_threads=8)</code> but its not clear to me if this is doing the right thing (although I can see more cpu cores in use)</p>

<pre><code>filename_queue = tf.train.string_input_producer([""train.txt""], num_epochs=1, shuffle=True)
example, label = parse_csv(filename_queue)
example_batch, label_batch = tf.train.batch([example, label], batch_size, num_threads=8)
</code></pre>

<p>Here is my code for executing the graph:</p>

<pre><code>sess.run(tf.initialize_all_variables())
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess,coord)
try:
    while not coord.should_stop():
        X, Y = sess.run([example_batch, label_batch])
        # Now run a training step
except tf.errors.OutOfRangeError:
    print('Done training -- epoch limit reached')
finally:
    # When done, ask the threads to stop.
    coord.request_stop()
coord.join(threads)
sess.close()
</code></pre>

<p>Whats the best way to process this file in parallel?</p>
",1,Documentation Replication on Other Examples
4,36223157,Set weight and bias tensors of tensorflow conv2d operation,"<p>I have been given a trained neural network in torch and I need to rebuild it exactly in tensorflow. I believe I have correctly defined the network's architecture in tensorflow but I am having trouble transferring the weight and bias tensors. Using a third party package, I converted all the weight and bias tensors from the torch network to numpy arrays then wrote them to disk. I can load them back into my python program but I cannot figure out a way to assign them to the corresponding layers in my tensorflow network. </p>

<p>For instance, I have a convolution layer defined in tensorflow as</p>

<pre><code>kernel_1 = tf.Variable(tf.truncated_normal([11,11,3,64], stddev=0.1))
conv_kernel_1 = tf.nn.conv2d(input, kernel_1, [1,4,4,1], padding='SAME')
biases_1 = tf.Variable(tf.zeros[64])
bias_layer_1 = tf.nn_add(conv_kernel_1, biases_1)
</code></pre>

<p>According to the tensorflow documentation, the tf.nn.conv2d operation uses the shape defined in the kernel_1 variable to construct the weight tensor. However, I cannot figure out how to access that weight tensor to set it to the weight array I have loaded from file. </p>

<p><strong>Is it possible to explicitly set the weight tensor? And if so, how?</strong> </p>

<p>(The same question applies to bias tensor.)</p>
",1,Lack of Alternative Solutions/Documentation
5,36570729,tf.IndexedSlicesValue when returned from tf.gradients(),"<p>I'm having the following problem, I have four embedding matrices and want to get the gradients of my loss function with respect to those matrices.</p>

<p>When I run the session to return the values for the gradients, two of those returned objects are of type tensorflow.python.framework.ops.IndexedSlicesValue, the other two are numpy arrays. Now for the numpy arrays, their shape corresponds to the shape of their corresponding embedding matrix, but I'm having problems with the IndexedSlicesValue objects. </p>

<p>If I call .values on one of those objects, I get an array whose shape does not match that of the gradient, the shape of the embedding matrix is [22,30], but calling .values on the IndexedSlicesValue object I get an array with shape [4200,30] ( The shape of my input tensor had dimensions of [30,20,7], the product of those dimensions equals 4200, not sure if this is relevant).
The IndexedSlicesValue object has an attribute called dense_shape, which is an array that holds the dimensions the gradient should have, i.e. array([22,30]) is value returned by .dense_shape.</p>

<p>I don't really understand the docs here: <a href=""https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#IndexedSlices"" rel=""noreferrer"">https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#IndexedSlices</a></p>

<p>It says:</p>

<blockquote>
  <p>An IndexedSlices is typically used to represent a subset of a
  larger tensor dense of shape [LARGE0, D1, .. , DN] where LARGE0 >> D0.
  The values in indices are the indices in the first dimension of the
  slices that have been extracted from the larger tensor.</p>
</blockquote>

<p>So this array of shape (4200,30) is extracted from an array corresponding to an even larger, dense tensor?</p>

<p>What exactly is the gradient in this IndexedSlicesValue object and why does tensorflow automatically use this type for some gradients returned by tf.gradients()?</p>

<p>Here is my code:</p>

<pre><code>input_tensor = tf.placeholder(tf.int32, shape = [None, memory_size, max_sent_length], name = 'Input')
q_tensor = tf.placeholder(tf.int32, shape = [None,max_sent_length], name = 'Question')
a_tensor = tf.placeholder(tf.float32, shape = [None,V+1], name = 'Answer')
# Embedding matrices
A_prior = tf.get_variable(name = 'A', shape = [V+1,d], initializer = tf.random_normal_initializer(stddev = 0.1))
A = tf.concat(0,[tf.zeros(shape = tf.pack([1,tf.shape(A_prior)[1]])),tf.slice(A_prior,[1,0],[-1,-1])])
B = tf.get_variable(name = 'B', shape = [V+1,d], initializer = tf.random_normal_initializer(stddev = 0.1))
C = tf.get_variable(name = 'C', shape = [V+1,d], initializer = tf.random_normal_initializer(stddev = 0.1))
W = tf.get_variable(name = 'W', shape = [V+1,d], initializer= tf.random_normal_initializer(stddev = 0.1))
embeddings = tf.reduce_sum(tf.nn.embedding_lookup(A,input_tensor),2)
u = tf.reshape(tf.reduce_sum(tf.nn.embedding_lookup(B,q_tensor),1),[-1,1,d])
test = tf.transpose(embeddings, perm = [0,2,1])
test_batch_mul = tf.squeeze(tf.batch_matmul(u,test))
cond = tf.not_equal(test_batch_mul,0.0)
tt = tf.fill(tf.shape(test_batch_mul),-1000.0)
softmax_in = tf.select(cond, test_batch_mul, tt)
p_values = tf.nn.softmax(softmax_in)
c_values = tf.reduce_sum(tf.nn.embedding_lookup(C,input_tensor),2)
o = tf.squeeze(tf.batch_matmul(tf.expand_dims(p_values,1),c_values))
a_pred = tf.nn.softmax(tf.matmul(tf.squeeze(u)+o,tf.transpose(W)))
loss = tf.nn.softmax_cross_entropy_with_logits(a_pred, a_tensor, name = 'loss')
cost = tf.reduce_mean(loss)
global_step = tf.Variable(0,name = 'global_step', trainable= False)
#optimizer = tf.train.MomentumOptimizer(0.01,0.9)
vars_list = tf.trainable_variables()
grads = tf.gradients(cost, vars_list)
#train_op = optimizer.minimize( cost, global_step, vars_list, name = 'train_op')

sess = tf.Session()
init = tf.initialize_all_variables()
sess.run(init)
input_feed = {input_tensor : phrases, q_tensor : questions, a_tensor : answers}
grad_results = sess.run(grads, feed_dict = input_feed)
</code></pre>
",1,Documentation Replication on Other Examples
6,37376861,what does the tf.nn.lrn() method do?,"<p>Here is the code-snipped from the cifar10-tutorial. It's from the cifar10.py.</p>

<pre><code># conv1
with tf.variable_scope('conv1') as scope:
kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64],
                                     stddev=1e-4, wd=0.0)
conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')
biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))
bias = tf.nn.bias_add(conv, biases)
conv1 = tf.nn.relu(bias, name=scope.name)
_activation_summary(conv1)

# pool1
pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],
                     padding='SAME', name='pool1')
# norm1
norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,
                name='norm1')
</code></pre>

<p>What does the tf.nn.lrn-Method do? I can't find a definition in the API Documentation on <a href=""https://www.tensorflow.org/versions/r0.8/api_docs/python/index.html"" rel=""noreferrer"">https://www.tensorflow.org/versions/r0.8/api_docs/python/index.html</a></p>
",1,Lack of Alternative Solutions/Documentation
7,38033079,Tensorflow understanding tf.train.shuffle_batch,"<p>I have a single file of training data, about 100K rows, and I'm running a straightforward <code>tf.train.GradientDescentOptimizer</code> on each training step.  The setup is essentially taken directly from Tensorflow's MNIST example.  Code reproduced below:</p>

<pre><code>x = tf.placeholder(tf.float32, [None, 21])
W = tf.Variable(tf.zeros([21, 2]))
b = tf.Variable(tf.zeros([2]))
y = tf.nn.softmax(tf.matmul(x, W) + b)

y_ = tf.placeholder(tf.float32, [None, 2])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
</code></pre>

<p>Given that I'm reading training data from a file, I'm using <code>tf.train.string_input_producer</code> and <code>tf.decode_csv</code> to read rows from the csv, and then <code>tf.train.shuffle_batch</code> to create batches that I then train on.</p>

<p>I'm confused as to what my parameters should be for <code>tf.train.shuffle_batch</code>.  I read Tensorflow's documentation, and yet I'm still not sure what the ""optimal"" batch_size, capacity, and min_after_dequeue values are.  Can anyone help shed some light on how I go about choosing proper values for these parameters, or link me to a resource where I can learn more?  Thanks-- </p>

<p>Here's the API link: <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/io_ops.html#shuffle_batch"" rel=""nofollow"">https://www.tensorflow.org/versions/r0.9/api_docs/python/io_ops.html#shuffle_batch</a></p>
",1,Documentation Ambiguity
8,38045785,Does the example for decaying the learning rate in TensorFlow website actually decay the learning rate?,"<p>I was reading the decaying learning rate and thought there might be a mistake in the docs and wanted to confirm. It says that the decay equation is:</p>

<blockquote>
  <p>decayed_learning_rate = learning_rate *
                          decay_rate ^ (global_step / decay_steps)</p>
</blockquote>

<p>however, if <code>global_step  = 0</code> I'd guess there is never a decay, right? However, look at the example:</p>

<pre><code>...
global_step = tf.Variable(0, trainable=False)
starter_learning_rate = 0.1
learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,
                                           100000, 0.96, staircase=True)
# Passing global_step to minimize() will increment it at each step.
learning_step = (
    tf.GradientDescentOptimizer(learning_rate)
    .minimize(...my loss..., global_step=global_step)
)
</code></pre>

<p>It has a <code>global_step = tf.Variable(0, trainable=False)</code> that is set equal to zero. Thus, no decay. Is this correct deduction?</p>

<p>I thought there might be a caveat due to integer division when staircase function is set to true, but even in integer division that still seems that there is no decay. Or is there a misunderstanding of what staircase does?</p>
",1,Documentation Replicability
9,38111170,How is the input tensor for TensorFlow's tf.nn.dynamic_rnn operator structured?,"<p>I am trying to write a language model using word embeddings and recursive neural networks in TensorFlow 0.9.0 using the <code>tf.nn.dynamic_rnn</code> graph operation, but I don't understand how the <code>input</code> tensor is structured.</p>

<p>Let's say I have a corpus of <em>n</em> words. I embed each word in a vector of length <em>e</em>, and I want my RNN to unroll to <em>t</em> time steps. Assuming I use the default <code>time_major = False</code> parameter, what shape would my <code>input</code> tensor <code>[batch_size, max_time, input_size]</code> have?</p>

<p>Maybe a specific tiny example will make this question clearer. Say I have a corpus consisting of <em>n=8</em> words that looks like this.</p>

<pre><code>1, 2, 3, 3, 2, 1, 1, 2
</code></pre>

<p>Say I embed it in a vector of size <em>e=3</em> with the embeddings 1 -> [10, 10, 10], 2 -> [20, 20, 20], and 3 -> [30, 30, 30], what would my <code>input</code> tensor look like?</p>

<p>I've read the <a href=""https://www.tensorflow.org/versions/r0.9/tutorials/recurrent/index.html#recurrent-neural-networks"" rel=""nofollow"">TensorFlow Recurrent Neural Network tutorial</a>, but that doesn't use <code>tf.nn.dynamic_rnn</code>. I've also read the documentation for <code>tf.nn.dynamic_rnn</code>, but find it confusing. In particular I'm not sure what ""max_time"" and ""input_size"" mean here.</p>

<p>Can anyone give the shape of the <code>input</code> tensor in terms of <em>n</em>, <em>t</em>, and <em>e</em>, and/or an example of what that tensor would look like initialized with data from the small corpus I describe?</p>

<p><em>TensorFlow 0.9.0, Python 3.5.1, OS X 10.11.5</em></p>
",1,Documentation Replicability
10,38114534,Basic 1d convolution in tensorflow,"<p>OK, I'd like to do a 1-dimensional convolution of time series data in Tensorflow. This is apparently supported using <code>tf.nn.conv2d</code>, according to <a href=""https://github.com/tensorflow/tensorflow/issues/2165"" rel=""noreferrer"">these</a> <a href=""https://github.com/tensorflow/tensorflow/issues/1136"" rel=""noreferrer"">tickets</a>, and <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#convolution"" rel=""noreferrer"">the manual</a>. the only requirement is to set <code>strides=[1,1,1,1]</code>. Sounds simple!</p>

<p>However, I cannot work out how to do this in even a very minimal test case. What am I doing wrong?</p>

<p>Let's set this up.</p>

<pre><code>import tensorflow as tf
import numpy as np
print(tf.__version__)
&gt;&gt;&gt; 0.9.0
</code></pre>

<p>OK, now generate a basic convolution test on two small arrays. I will make it easy by using a batch size of 1, and since time series are 1-dimensional, I will have an ""image height"" of 1. And since it's a univariate time series, clearly the number of ""channels"" is also 1, so this will be simple, right?</p>

<pre><code>g = tf.Graph()
with g.as_default():
    # data shape is ""[batch, in_height, in_width, in_channels]"",
    x = tf.Variable(np.array([0.0, 0.0, 0.0, 0.0, 1.0]).reshape(1,1,-1,1), name=""x"")
    # filter shape is ""[filter_height, filter_width, in_channels, out_channels]""
    phi = tf.Variable(np.array([0.0, 0.5, 1.0]).reshape(1,-1,1,1), name=""phi"")
    conv = tf.nn.conv2d(
        phi,
        x,
        strides=[1, 1, 1, 1],
        padding=""SAME"",
        name=""conv"")
</code></pre>

<p>BOOM. Error.</p>

<pre><code>ValueError: Dimensions 1 and 5 are not compatible
</code></pre>

<p>OK, For a start, I don't understand how this should happen with <em>any</em> dimension, since I've specified that I'm padding the arguments in the convolution OP. </p>

<p>but fine, maybe there are limits to that. I must have got the documentation confused and set up this convolution on the wrong axes of the tensor. I'll try all possible permutations:</p>

<pre><code>for i in range(4):
    for j in range(4):
        shape1 = [1,1,1,1]
        shape1[i] = -1
        shape2 = [1,1,1,1]
        shape2[j] = -1
        x_array = np.array([0.0, 0.0, 0.0, 0.0, 1.0]).reshape(*shape1)
        phi_array = np.array([0.0, 0.5, 1.0]).reshape(*shape2)
        try:
            g = tf.Graph()
            with g.as_default():
                x = tf.Variable(x_array, name=""x"")
                phi = tf.Variable(phi_array, name=""phi"")
                conv = tf.nn.conv2d(
                    x,
                    phi,
                    strides=[1, 1, 1, 1],
                    padding=""SAME"",
                    name=""conv"")
                init_op = tf.initialize_all_variables()
            sess = tf.Session(graph=g)
            sess.run(init_op)
            print(""SUCCEEDED!"", x_array.shape, phi_array.shape, conv.eval(session=sess))
            sess.close()
        except Exception as e:
            print(""FAILED!"", x_array.shape, phi_array.shape, type(e), e.args or e._message)
</code></pre>

<p>Result:</p>

<pre><code>FAILED! (5, 1, 1, 1) (3, 1, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (3, 1) Input: (1, 1)',)
FAILED! (5, 1, 1, 1) (1, 3, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (1, 3) Input: (1, 1)',)
FAILED! (5, 1, 1, 1) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 1 and 3 are not compatible',)
FAILED! (5, 1, 1, 1) (1, 1, 1, 3) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 5, 1, 1) (3, 1, 1, 1) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 5, 1, 1) (1, 3, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (1, 3) Input: (5, 1)',)
FAILED! (1, 5, 1, 1) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 1 and 3 are not compatible',)
FAILED! (1, 5, 1, 1) (1, 1, 1, 3) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 1, 5, 1) (3, 1, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (3, 1) Input: (1, 5)',)
FAILED! (1, 1, 5, 1) (1, 3, 1, 1) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 1, 5, 1) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 1 and 3 are not compatible',)
FAILED! (1, 1, 5, 1) (1, 1, 1, 3) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 1, 1, 5) (3, 1, 1, 1) &lt;class 'ValueError'&gt; ('Dimensions 5 and 1 are not compatible',)
FAILED! (1, 1, 1, 5) (1, 3, 1, 1) &lt;class 'ValueError'&gt; ('Dimensions 5 and 1 are not compatible',)
FAILED! (1, 1, 1, 5) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 5 and 3 are not compatible',)
FAILED! (1, 1, 1, 5) (1, 1, 1, 3) &lt;class 'ValueError'&gt; ('Dimensions 5 and 1 are not compatible',)
</code></pre>

<p>Hmm. OK, it looks like there are two problems now. Firstly, the <code>ValueError</code> is about applying the filter along the wrong axis, I guess, although there are two forms.</p>

<p>But then the axes along which I can apply the filter are confusing too - notice that it actually constructs the graph with input shape (5, 1, 1, 1)  and filter shape (1, 1, 1, 3). AFAICT from the documentation, this should be a filter that looks at on example from the batch, one ""pixel"" and one ""channel"" and outputs 3 ""channels"". Why does that one work, then, when others do not?</p>

<p>Anyway, sometimes it does not fail while constructing the graph.
Sometime it constructs the graph; then we get the <code>tensorflow.python.framework.errors.InvalidArgumentError</code>. From some <a href=""https://github.com/tensorflow/tensorflow/issues/524"" rel=""noreferrer"">confusing github tickets</a> I gather this is probably due to <del>the fact that I'm running on CPU instead of GPU, or vice versa</del> the fact that the convolution Op is only defined for 32 bit floats, not 64 bit floats. If anyone could throw some light on <em>which</em> axes I should be aligning <em>what</em> on, in order to convolve a time series with a kernel, I'd be very grateful.</p>
",1,Documentation Ambiguity
11,38356622,Distributing graphs across several machines in Distributed Tensorflow,"<p>I am currently working on a project using Distributed Tensorflow. My goal is to run several independent graphs across several different machines.</p>

<p>As an example, I want to do something like this (assume that the server is open on each machine)</p>

<pre><code>import tensorflow as tf
a = tf.constant(3)
b = tf.constant(2)
x = tf.mul(a,b)             # To be run on ""grpc://www.example0.com:2222""
y = tf.mul(a,b)             # To be run on ""grpc://www.example1.com:2222""
z = tf.mul(a,b)             # To be run on ""grpc://www.example2.com:2222""

with tf.Session() as sess:
    sess.run([x,y,z])       # Ops x,y,z are run on different machines in parallel
</code></pre>

<p>My current attempt at this is shown in the following code. However, this code runs the sessions in serial, but I want them to be executed in a parallel distributed manner.</p>

<pre><code>import tensorflow as tf
a = tf.constant(3)
b = tf.constant(2)
x = tf.mul(a,b)             # To be run on ""grpc://www.example0.com:2222""
y = tf.mul(a,b)             # To be run on ""grpc://www.example1.com:2222""
z = tf.mul(a,b)             # To be run on ""grpc://www.example2.com:2222""

with tf.Session(""grpc://www.example0.com:2222"") as sess:
    sess.run(x)
with tf.Session(""grpc://www.example1.com:2222"") as sess:
    sess.run(y)
with tf.Session(""grpc://www.example2.com:2222"") as sess:
    sess.run(z)
</code></pre>

<p>While reading the documentation about Distributed Tensorflow, I found that <code>tf.device</code> allows me to set which CPU or GPU to run Tensorflow Ops on. Is there something similar that allows me to set the <code>session target</code> to specify which machine will run which op? Or is there another way of distributing Tensorflow Ops?</p>
",1,Documentation Replication on Other Examples
12,38641887,How to save a trained tensorflow model for later use for application?,"<p>I am a bit of a beginner with tensorflow so please excuse if this is a stupid question and the answer is obvious. </p>

<p>I have created a Tensorflow graph where starting with placeholders for X and y I have optimized some tensors which represent my model. Part of the graph is something where a vector of predictions can be calculated, e.g. for linear regression something like </p>

<pre class=""lang-py prettyprint-override""><code>y_model = tf.add(tf.mul(X,w),d)
y_vals = sess.run(y_model,feed_dict={....})
</code></pre>

<p>After training has been completed I have acceptable values for w and d and now I want to save my model for later. Then, in a different python session I want to restore the model so that I can again run</p>

<pre class=""lang-py prettyprint-override""><code>## Starting brand new python session
import tensorflow as tf
## somehow restor the graph and the values here: how????
## so that I can run this:
y_vals = sess.run(y_model,feed_dict={....})
</code></pre>

<p>for some different data and get back the y-values. </p>

<p>I want this to work in a way where the graph for calculating the y-values from the placeholders is also stored and restored - as long as the placeholders get fed the correct data, this should work transparently without the user (the one who applies the model) needing to know what the graph looks like). </p>

<p>As far as I understand tf.train.Saver().save(..) only saves the variables but I also want to save the graph. I think that tf.train.export_meta_graph could be relevant here but I do not understand how to use it correctly, the documentation is a bit cryptic to me and the examples do not even use export_meta_graph anywhere. </p>
",1,Inadequate Examples
13,38893526,What's the meaning of tf.nn.embedding_lookup_sparse in TensorFlow?,"<p>We spend a lot of time in reading the API document of <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#embedding_lookup_sparse"" rel=""nofollow"">tf.nn.embedding_lookup_sparse</a>. The meaning of <code>embedding_lookup_sparse</code> is confusing and it seems quite different from <code>embedding_lookup</code>.</p>

<p>Here's what I think and please correct me if I'm wrong. The example of wide and deep model uses <code>contrib.layers</code> APIs and call <code>embedding_lookup_sparse</code> for sparse feature colume. If it gets the SparseTensor(for example, country, which is sparse), it creates the embedding which is actually for one-host encoding. Then call <code>to_weights_sum</code> to return the result of <code>embedding_lookup_sparse</code> as <code>prediction</code> and the embedding as <code>variable</code>.</p>

<p>The the result of <code>embedding_lookup_sparse</code> add <code>bias</code> and become the <code>logits</code> for loss function and training operation. That means the <code>embedding_lookup_sparse</code> do something like <code>w * x</code>(part of <code>y = w * x + b</code>) for dense tensor.</p>

<p>Maybe for one-hot encoding or SparseTensor, the <code>weight</code> from <code>embedding_lookup_sparse</code> is actually the value of <code>w * x</code> because the look-up data is always <code>1</code> and no need to add other <code>0</code>s.</p>

<p>What I said is also confusing. Can anyone help to explain this in detail?</p>
",1,Documentation Replication on Other Examples
14,38962308,Unclear behavior for sampler in Tensorflow,"<p>For the samplers implemented in tensorflow, e.g. tf.nn.fixed_unigram_candidate_sampler. The behavior is not well-defined in the document. For instance, I would expect the labels specified in true_classes will be excluded from the sampling pool, and the sampling will be conducted for each batch. But according to my experiments, neither of above is true.</p>

<p>Consider the following code:</p>

<pre><code>import tensorflow as tf

labels_matrix = tf.reshape(tf.constant([1, 2, 3, 4], dtype=tf.int64), [-1, 1])

sampled_ids, _, _ = tf.nn.fixed_unigram_candidate_sampler(
true_classes = labels_matrix,
num_true = 1,
num_sampled = 1,
unique = True,
range_max = 5,
distortion = 0.0,
unigrams = range(5)
)

init = tf.initialize_all_variables()
with tf.Session() as sess:
sess.run(init)
print sess.run([sampled_ids])
</code></pre>

<p>The output can be 3, which actually belongs to the set of true classes. - Also, the output has the dimension [1], which basically means that the sampling is only conducted once, not for each batch.</p>

<p>Can someone help to clarify this?</p>
",1,Documentation Ambiguity
15,39008821,Tensorflow: When to use tf.expand_dims?,"<p>Tensorflow tutorials include the use of <code>tf.expand_dims</code> to add a &quot;batch dimension&quot; to a tensor. I have read the docs for this function but it still is rather mysterious to me. Does anyone know exactly under what circumstances this must be used?</p>
<p>My code is below. My intent is to calculate a loss based on the distance between the predicted and actual bins. (E.g. if <code>predictedBin = 10</code> and <code>truthBin = 7</code> then <code>binDistanceLoss = 3</code>).</p>
<pre class=""lang-py prettyprint-override""><code>batch_size = tf.size(truthValues_placeholder)
labels = tf.expand_dims(truthValues_placeholder, 1)
predictedBin = tf.argmax(logits)
binDistanceLoss = tf.abs(tf.sub(labels, logits))
</code></pre>
<p>In this case, do I need to apply <code>tf.expand_dims</code> to <code>predictedBin</code> and <code>binDistanceLoss</code>? Thanks in advance.</p>
",1,Documentation Replication on Other Examples
16,39133312,Why does setting an initialization value prevent placing a variable on a GPU in TensorFlow?,"<p>I get an exception when I try to run the following very simple TensorFlow code, although I virtually copied it from the documentation:</p>

<pre><code>import tensorflow as tf

with tf.device(""/gpu:0""):
  x = tf.Variable(0, name=""x"")

sess = tf.Session()
sess.run(x.initializer) # Bombs!
</code></pre>

<p>The exception is:</p>

<pre><code>tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to
node 'x': Could not satisfy explicit device specification '/device:GPU:0' because
no supported kernel for GPU devices is available.
</code></pre>

<p>If I change the variable's initial value to <code>tf.zeros([1])</code> instead, everything works fine:</p>

<pre><code>import tensorflow as tf

with tf.device(""/gpu:0""):
  x = tf.Variable(tf.zeros([1]), name=""x"")

sess = tf.Session()     
sess.run(x.initializer)  # Works fine
</code></pre>

<p>Any idea what's going on?</p>
",1,Documentation Replicability
17,39210093,regarding the correct way to understand the result of tf.pad,"<p>When reading the document for <a href=""https://www.tensorflow.org/versions/r0.10/api_docs/python/array_ops.html#pad"" rel=""noreferrer"">tf.pad</a>, I feel quite confusing about the example given in the tutorial. For instance, padding is <code>[[1,1,],[2,2]]</code>, how does it cause the resulting tensor has the shape as shown in the figure. Besides, what's the mechanism to generate those padded values, e.g., the ones marked in red circle. It is not very clear how to connect the explanation with the example.</p>

<p><a href=""https://i.stack.imgur.com/7OHis.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/7OHis.jpg"" alt=""enter image description here""></a></p>
",1,Lack of Alternative Solutions/Documentation
18,39211332,Custom initializer for get_variable,"<p>How can one specify a custom initializer as the third argument for <code>tf.get_variable()</code>? Specifically, I have a variable <code>y</code> which I want to initialize using another (already initialized) variable <code>x</code>. </p>

<p>This is easy to do using <code>tf.Variable()</code>, just say, <code>y = tf.Variable(x.initialized_value())</code>. But I couldn't find an analog in the documentation for <code>tf.get_variable()</code>.</p>
",1,Lack of Alternative Solutions/Documentation
19,39681026,Tensorflow: How to pass output from previous time-step as input to next timestep,"<p>It is a duplicate of this question <a href=""https://stackoverflow.com/questions/35145645/how-can-i-feed-last-output-yt-1-as-input-for-generating-yt-in-tensorflow-rnn#"">How can I feed last output y(t-1) as input for generating y(t) in tensorflow RNN?</a></p>

<p>I want to pass the output of RNN at time-step T as the input at time-step T+1. <code>input_RNN(T+1) = output_RNN(T)</code>
As per the documentation, the  tf.nn.rnn as well as tf.nn.dynamic_rnn functions explicitly take the complete input to all time-steps. </p>

<p>I checked the seq2seq example at <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py</a>
It uses a loop and calls the cell(input,state) function. The cell can be lstm or gru or any other rnn cell. I checked the documentation to find the data type and shape of the arguments to cell(), but I found only the contructor of the form cell(num_neurons). 
I would like to know the correct way of passing output to input. I don't want to use other libraries/wrappers like keras built over tensorflow. Any suggestions?</p>
",1,Documentation Completeness
20,40195549,tf.rank function in Tensorflow,"<p>I ma trying to understand tf.rank function in tensorflow. From the documentation <a href=""https://www.tensorflow.org/versions/r0.11/api_docs/python/array_ops.html#rank"" rel=""nofollow"">here</a>, I understood that rank should return the number of distinct elements in the tensor. </p>

<p>Here x and weights are 2 distinct 2*2 tensors with 4 distinct elemnts in each of them. However, rank() function outputs are:</p>

<blockquote>
  <p>Tensor(""Rank:0"", shape=(), dtype=int32) Tensor(""Rank_1:0"", shape=(),
  dtype=int32)</p>
</blockquote>

<p>Also, for the tensor x, I used tf.constant() with dtype = float to convert ndarray into float32 tensor but the rank() still outputs as int32.</p>

<pre><code>g = tf.Graph()
with g.as_default():
    weights = tf.Variable(tf.truncated_normal([2,2]))
    x = np.asarray([[1 , 2], [3 , 4]])
    x = tf.constant(x, dtype = tf.float32)
    y = tf.matmul(weights, x)
    print (tf.rank(x), tf.rank(weights))


with tf.Session(graph = g) as s:
    tf.initialize_all_variables().run()
    print (s.run(weights), s.run(x))
    print (s.run(y))
</code></pre>

<p>How should I interpret the output.</p>
",1,Documentation Replication on Other Examples
21,40394910,What do classes tf.train.Coordinator and class tf.train.QueueRunner do in tensorflow?,"<p>I understand that both classes deal with threads. According to the documentation, tf.train.Coordinator coordinates the termination of a set of threads and tf.train.QueueRunner holds a list of enqueue operations for a queue, each to be run in a thread. </p>

<p>However, what is their role in simple words? When are they necessary during the training?</p>
",1,Documentation Replicability
22,40451974,"Tensorflow, restore variables in a specific device","<p>Maybe my question is a bit naive, but I really didn't find anything in the tensorflow documentation.</p>

<p>I have a trained tensorflow model where the variables of it was placed in the GPU. Now I would like to restore this model and test it using the CPU.</p>

<p>If I do this via 'tf.train.Saver.restore` as in the example:
<code>
 saver = tf.train.import_meta_graph(""/tmp/graph.meta"")
 saver.restore(session, ""/tmp/model.ckp"")
</code></p>

<p>I have the following excpetion:</p>

<p><code>
InvalidArgumentError: Cannot assign a device to node 'b_fc8/b_fc8/Adam_1': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0
</code></p>

<p>How can I make restore these variables in the <code>CPU</code>?</p>

<p>Thanks</p>
",1,Documentation Replication on Other Examples
23,40518132,regarding the usage of tf.tile and tf.pack,"<p>I saw a program including the following two lines of codes  </p>

<pre><code>exponential_map = tf.exp(output_map)
sum_exp = tf.reduce_sum(exponential_map, 3, keep_dims=True)
tensor_sum_exp = tf.tile(sum_exp, tf.pack([1, 1, 1, tf.shape(output)[3]]))
</code></pre>

<p>The <code>output_map</code> is of shape <code>(1,255,255,2)</code>. I can see <code>sum_exp</code> generally add the two channels for the <code>exponential_map</code> into one. So <code>sum_exp</code> should be of shape <code>(1,255,255,1)</code>. But I am confused about what does <code>tensor_sum_exp = tf.tile(sum_exp, tf.pack([1, 1, 1, tf.shape(output)[3]]))</code> aim to do?</p>
",1,Documentation Replicability
24,41125183,Tensorflow: split_v with variable num_splits,"<p>I am wondering if the same holds for <code>tf.split_v()</code> as <code>tf.split()</code>.</p>

<p>According to the documentation <code>split_v</code> also accepts a Tensor as second argument.</p>

<p>However, when I try this code</p>

<pre><code>batch_size_ph = tf.placeholder(dtype = tf.int32, name='BatchSize')
seq_length_ph = tf.placeholder(dtype = tf.int32, name='SeqLength')
input_data = tf.placeholder(dtype=tf.float32, shape=[50, 25, 10])


inputs = tf.split_v(input_data,seq_length_ph, 1) #tf.ones(seq_length_ph, tf.int32)
#inputs = [tf.squeeze(input_, [1]) for input_ in inputs]

with tf.Session() as sess:
    [out] = sess.run([inputs],feed_dict = {batch_size_ph: 50,
                                           seq_length_ph: 25,
                                           input_data: np.random.rand(50,25,10)})

print out
print len(out)
print out[0].shape
</code></pre>

<p>The error is</p>

<blockquote>
  <p>NameError: global name 'value_shape' is not defined</p>
</blockquote>

<p>Is this possible or not?</p>
",1,Documentation Replicability
25,41125728,"When should tf.add(t, 0) be used instead of tensor t directly?","<p>In <a href=""https://github.com/tensorflow/tensorflow/blob/294442996b2aeff00b1bfdc7e7169f7cb35bbf3d/tensorflow/contrib/layers/python/layers/layers.py#L625"" rel=""nofollow noreferrer"">tensorflow.contrib.slim.batch_norm</a>, <code>math_ops.add(moving_mean, 0)</code> is used to copy the value of <code>moving_mean</code>, which is <a href=""https://github.com/tensorflow/tensorflow/blob/294442996b2aeff00b1bfdc7e7169f7cb35bbf3d/tensorflow/contrib/layers/python/layers/layers.py#L629"" rel=""nofollow noreferrer"">passed to <code>nn.moments</code></a> subsequently.</p>

<p>Would it be a problem if we just pass <code>moving_mean</code> to <code>nn.moments</code> directly?</p>

<p>Are there any guidelines on the use of <em>copy</em> operation (<code>tf.add(t, 0)</code>)?</p>
",1,Documentation Completeness
26,41283115,"Tensorflow, difference between tf.nn.softmax_cross_entropy_with_logits and tf.nn.sparse_softmax_cross_entropy_with_logits","<p>I have read the <a href=""https://www.tensorflow.org/api_docs/python/nn/classification"" rel=""nofollow noreferrer"">docs of both functions</a>, but as far as I know, for function <code>tf.nn.softmax_cross_entropy_with_logits(logits, labels, dim=-1, name=None)</code>, the result is the cross entropy loss, in which the dimensions of <code>logits</code> and <code>labels</code> are the same.</p>

<p>But, for function <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code>, the dimensions of <code>logits</code> and <code>labels</code> are not the same?</p>

<p>Could you give a more detail example of <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code>?</p>
",1,Requesting (Additional) Documentation/Examples
27,41308515,Force copy of tensor when enqueuing,"<p>first, I'm not sure if the title is very good, but it was the best I could come up with given my understanding of the situation.</p>

<p>The background is that I'm trying to understand how queues work in tensorflow and ran into the following issue which puzzled me.</p>

<p>I have a variable <em>n</em>, which I enqueue to a <em>tf.FIFOQueue</em>, and then I increment the variable. This is repeated several times, and one would expect a result similar to 0, 1, 2, ... However, when emptying the queue all values are the same.</p>

<p>More precisely, the code is as follows:</p>

<pre><code>from __future__ import print_function

import tensorflow as tf

q = tf.FIFOQueue(10, tf.float32)

n = tf.Variable(0, trainable=False, dtype=tf.float32)
inc = n.assign(n+1)
enqueue = q.enqueue(n)

init = tf.global_variables_initializer()

sess = tf.Session()
sess.run(init)

sess.run(enqueue)
sess.run(inc)

sess.run(enqueue)
sess.run(inc)

sess.run(enqueue)
sess.run(inc)

print(sess.run(q.dequeue()))
print(sess.run(q.dequeue()))
print(sess.run(q.dequeue()))
</code></pre>

<p>Which I expect would print:</p>

<pre><code>0.0
1.0
2.0
</code></pre>

<p>Instead I get the following result:</p>

<pre><code>3.0
3.0
3.0
</code></pre>

<p>It seems like I'm pushing some pointer to n to the queue, instead of the actual value, which is what I want. However, I don't really have any actual understanding of tensorflow internals, so maybe something else is going on?</p>

<p>I tried changing</p>

<pre><code>enqueue = q.enqueue(n)
</code></pre>

<p>to</p>

<pre><code>enqueue = q.enqueue(tf.identity(n))
</code></pre>

<p>since answers to <a href=""https://stackoverflow.com/questions/33717772/how-can-i-copy-a-variable-in-tensorflow"">How can I copy a variable in tensorflow</a> and <a href=""https://stackoverflow.com/questions/34877523/in-tensorflow-what-is-tf-identity-used-for"">In TensorFlow, what is tf.identity used for?</a> gives me the impression that it might help, but it does not change the result. I also tried adding a tf.control_dependencies(), but again, all values are the same when dequeueing.</p>

<p>Edit: The output above is from running the code on a computer with a single CPU, when trying to see if there was some difference between different versions of tensorflow, I noticed if I run the code on a computer with CPU and GPU I get the ""expected"" result. Indeed, if I run with CUDA_VISIBLE_DEVICES="""" I get the result above, and with CUDA_VISIBLE_DEVICES=""0"" I get the ""expected"" result.</p>
",1,Documentation Ambiguity
28,41353079,Tensorflow image.central_crop (mis)behavior,"<p>In the Tensorflow documentation for <a href=""https://www.tensorflow.org/api_docs/python/image/cropping#central_crop"" rel=""nofollow noreferrer"">tf.image.central_crop</a> function:</p>

<pre><code>Remove the outer parts of an image but retain the central region of
the image along each dimension. If we specify central_fraction = 0.5,
this function returns the region marked with ""X"" in the below diagram.

 --------
|        |
|  XXXX  |
|  XXXX  |
|        |   where ""X"" is the central 50% of the image.
 --------
</code></pre>

<p>Consider the following code:</p>

<pre><code>In [2]: import tensorflow as tf
In [3]: image_raw = tf.placeholder(tf.string)
In [4]: image = tf.image.decode_jpeg(image_raw, channels=3)
In [5]: crop = tf.image.central_crop(image, central_fraction=0.5)
In [6]: init_op = tf.global_variables_initializer()
In [7]: sess = tf.Session()
In [8]: sess.run(init_op)
In [9]: image_np, crop_np = sess.run([image, crop],
   ...:     feed_dict={image_raw: open(""/tmp/test.jpg"", 'rb').read()})
In [10]: image_np.shape
Out[10]: (456, 450, 3)
</code></pre>

<p>Original image size is 456x450</p>

<pre><code>In [11]: crop_np.shape
Out[11]: (228, 226, 3)
</code></pre>

<p>Crop size is 228x226</p>

<p>Which gives area ratio of:</p>

<pre><code>In [12]: 228*226 / (456*450.)
Out[12]: 0.2511111111111111
</code></pre>

<p>Not 0.5 as I expected. Can someone help to clarify this?</p>
",1,Documentation Ambiguity
29,41437483,How does tf.nn.conv2d calculate its values?,"<p>I've looked at the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn/convolution"" rel=""nofollow noreferrer"">documentation</a> for <code>tf.nn.conv2d</code> but it didn't really help much. So I tried to multiply the first 4 values of my input array that form a square <code>(0, 1, 2, 2.5)</code> with the first column of the <code>filter_weights</code> array <code>(0.19041163, -0.36705261, 0.69018674, 1.7655524)</code>. But regardless of how I multiply these values I'm not getting <code>1.13938534</code>, I don't know what I'm doing wrong. </p>

<p>Below I have the code that I used.</p>

<p>Given an array:</p>

<pre><code>x = np.array([
[0, 1, 0.5, 10],
[2, 2.5, 1, -8],
[4, 0, 5, 6],
[15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))

X = tf.constant(x)
</code></pre>

<p>And weights:</p>

<pre><code>filter_weights = tf.truncated_normal([2,2,1,3])
</code></pre>

<p>Which prints:</p>

<pre><code>[[[[ 0.19041163  0.59322315  0.27544078]]

  [[-0.36705261 -1.18738699  1.45393717]]]


 [[[ 0.69018674  1.08702338 -1.15911126]]

  [[ 1.76255524 -1.42660797 -0.18624328]]]]
</code></pre>

<p>How does:</p>

<pre><code>strides = [1, 2, 2, 1]
padding = ""SAME""
tf.nn.conv2d(input, F_W, strides, padding)
</code></pre>

<p>Give:</p>

<pre><code> [[[[  1.13938534  -5.06340981  -4.23629761]
   [-18.01530266  -4.67841816  16.20156288]]

  [[ -9.49576092  -4.87288237   6.77371216]
   [ -0.57718992 -12.70932484   0.89242649]]]]
</code></pre>
",1,Lack of Alternative Solutions/Documentation
30,41467115,"Using word2vec pretrained vectors, how to generate ids of a sentence as input to tf.nn.embedding_lookup function in tensorflow?","<p>To extract the embedding representations of input data, the tensorflow documentation says we can use the following:</p>

<pre><code>embed = tf.nn.embedding_lookup(embeddings, input_data)
</code></pre>

<p>Accdg to the <a href=""https://www.tensorflow.org/api_docs/python/nn/embeddings#embedding_lookup"" rel=""nofollow noreferrer"">TF documentation</a>, the 2nd parameter of the function tf.nn.embedding_lookup is a tensor of ids:</p>

<blockquote>
  <p>ids: A Tensor with type int32 or int64 containing the ids to be looked up in params.</p>
</blockquote>

<p>My question is: Given a sentence, say, </p>

<blockquote>
  <p>""Welcome to the world""</p>
</blockquote>

<p>how can I represent and transform it into <code>ids</code>? In the code below, how can I transform my sentence into <code>input_data</code>. </p>

<pre><code>from gensim import models
embedding_path = ""../embeddings/GoogleNews-vectors-negative300.bin""
w = models.Word2Vec.load_word2vec_format(embedding_path, binary=True)
X = w.syn0
W = tf.Variable(tf.constant(0.0, shape=X.shape),trainable=False, name=""W"")
embedding_placeholder = tf.placeholder(tf.float32, X.shape)
embedding_init = W.assign(embedding_placeholder)
embed = tf.nn.embedding_lookup(embedding_init, input_data)
sess = tf.Session()
sess.run(embed, feed_dict={embedding_placeholder: X})
</code></pre>
",1,Documentation Replication on Other Examples
31,41602374,tf.zeros doesn't return a 1D tensor?,"<p>I'm trying to duplicate a tensor across a new axis, like this:</p>

<pre><code>original_tensor = tf.constant([1,2,3,4,5])
made_copies_tensor = tf.tile(original_tensor, 5)
final_result = tf.reshape([5,5])
</code></pre>

<p>However I'm getting this error:</p>

<pre><code>File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 650, in with_rank
raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape () must have rank 1
</code></pre>

<p>In the documentation it says the way I wrote tf.constant is supposed to have it return a 1D tensor but when I checked its shape with get_shape(), it has (5,) as its shape. I tried reshaping it but nothing changed.</p>

<p>Why am I getting this error? Thanks.</p>
",1,Documentation Replicability
32,41780655,What is the difference between tf.group and tf.control_dependencies?,"<p>Aside from <code>tf.control_dependencies</code> being a context manager (i.e. used with Python <code>with</code>), what's the difference between <code>tf.group</code> and <code>tf.control_dependencies</code>? </p>

<p>When should which be used? </p>

<p>Is it that <code>tf.group</code> doesn't have any particular order of operations? I'd assume <code>tf.group([op_1, op_2, op_3])</code> executes ops in the list's order, but maybe that's not the case? The docstring doesn't specify a behaviour.</p>
",1,Documentation Replicability
33,41789133,What are c_state and m_state in Tensorflow LSTM?,"<p>Tensorflow r0.12's documentation for tf.nn.rnn_cell.LSTMCell describes this as the init:</p>

<pre><code>tf.nn.rnn_cell.LSTMCell.__call__(inputs, state, scope=None)
</code></pre>

<p>where <code>state</code> is as follows:</p>

<blockquote>
  <p>state: if state_is_tuple is False, this must be a state Tensor, 2-D, batch x state_size. If state_is_tuple is True, this must be a tuple of state Tensors, both 2-D, with column sizes c_state and m_state.</p>
</blockquote>

<p>What aare <code>c_state</code> and <code>m_state</code> and how do they fit into LSTMs? I cannot find reference to them anywhere in the documentation.</p>

<p><a href=""https://web.archive.org/web/20170223030652/https://www.tensorflow.org/versions/r0.11/api_docs/python/rnn_cell/rnn_cells_for_use_with_tensorflow_s_core_rnn_methods"" rel=""noreferrer"">Here is a link to that page in the documentation.</a></p>
",1,Lack of Alternative Solutions/Documentation
34,41941940,TensorFlow: Understanding the `collections` argument in tf.summary.scalar,"<p>I am working with TensorBoard, specifically <code>tf.summary.scalar</code>. In the <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/summary.md#tfsummaryscalarname-tensor-collectionsnone-scalar"" rel=""nofollow noreferrer"">documentation</a> it has an arugment <code>collections=None</code>, which is described as:</p>

<blockquote>
  <p><code>collections</code>: Optional list of graph collections keys. The new summary op is added to these collections. Defaults to <code>[GraphKeys.SUMMARIES]</code>.</p>
</blockquote>

<p>I don't understand this description, and what <code>collections</code> is used for. Can someone please explain this to me, and perhaps point me towards a good example use-case?</p>
",1,Documentation Ambiguity
35,41953678,Documentation for Inference from saved model in Tensorflow,"<p>As explained at <a href=""https://www.tensorflow.org/tutorials/mnist/pros/#build_a_multilayer_convolutional_network"" rel=""nofollow noreferrer"">Multilayer CNN for MNIST Digit Recognition</a> I created a CNN for MNIST image recognition dataset. I don't want to test it in the same script so I trained the model, saved the checkpoint files and graph structure and then using <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py"" rel=""nofollow noreferrer"">freeze_graph.py</a> script. I froze it into one single .pb file. Now using this .pb file I want to infer for MNIST test dataset and check the accuracy of the model but there is no clear documentation as to how to do it. There is one example written in examples/label_images directory but that too is in C++ and for inception network. I have already parsed the .pb file and made a tf.Graph object. And also why can't a single inference script be provided since whole graph structure can be read from graph saved in the .pb file.</p>
",1,Documentation Replication on Other Examples
36,42022950,Which seeds have to be set where to realize 100% reproducibility of training results in tensorflow?,"<p>In a general tensorflow setup like</p>

<pre><code>model = construct_model()
with tf.Session() as sess:
    train_model(sess)
</code></pre>

<p>Where <code>construct_model()</code> contains the model definition including random initialization of weights (<code>tf.truncated_normal</code>) and <code>train_model(sess)</code> executes the training of the model -</p>

<p>Which seeds do I have to set where to ensure 100% reproducibility between repeated runs of the code snippet above? <a href=""https://www.tensorflow.org/api_docs/python/tf/random/set_random_seed"" rel=""nofollow noreferrer"">The documentation</a> for <code>tf.random.set_random_seed</code> may be concise, but left me a bit confused. I tried:</p>

<pre><code>tf.set_random_seed(1234)
model = construct_model()
    with tf.Session() as sess:
        train_model(sess)
</code></pre>

<p>But got different results each time. </p>
",1,Documentation Replicability
37,42095625,What does the function control_dependencies do?,"<p>I would like to have an example illustrating the use of the function <a href=""https://www.tensorflow.org/api_docs/python/tf/control_dependencies"" rel=""noreferrer""><code>tf.control_dependencies</code></a>. For example, I want to create two tensors <code>X</code> and <code>Y</code> and if they are equal do or print something. </p>

<pre><code>import tensorflow as tf

session = tf.Session()

X = tf.constant(5)
Y = tf.constant(50)

with tf.control_dependencies([tf.assert_equal(X, Y)]):
    print('X and Y are equal!')
</code></pre>

<p>In the code above, <code>X</code> is clearly not equal to <code>Y</code>. What is <code>tf.control_dependencies</code> doing in this case?</p>
",1,Documentation Replication on Other Examples
38,42133661,Tensorflow - LSTM state reuse within batch,"<p>I am working on a Tensorflow NN which uses an LSTM to track a parameter (time series data regression problem). A batch of training data contains a batch_size of <em>consecutive</em> observations. I would like to use the LSTM state as input to the next sample. So, if I have a batch of data observations, I would like to feed the state of the first observation as input to the second observation and so on. Below I define the lstm state as a tensor of size = batch_size. I would like to reuse the state <em>within</em> a batch:</p>

<pre><code>state = tf.Variable(cell.zero_states(batch_size, tf.float32), trainable=False)
cell = tf.nn.rnn_cell.BasicLSTMCell(100)
output, curr_state = tf.nn.rnn(cell, data, initial_state=state) 
</code></pre>

<p>In the API there is a tf.nn.state_saving_rnn but the documentation is kinda vague. <strong>My question</strong>: How to reuse curr_state <em>within</em> a training batch.</p>
",1,Documentation Ambiguity
39,42333101,Predicting Next Word of LSTM Model from Tensorflow Example,"<p>My buddy and I are trying to utilize the trained model from the LSTM tensorflow example <a href=""https://www.tensorflow.org/tutorials/recurrent"" rel=""nofollow noreferrer"">here</a>. We've been able to train our model, save the model, and then import the model. We've just used tensorflow's Supervisor. It was in the tutorial, but you can read more about it <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard6/tf.train.Supervisor.md"" rel=""nofollow noreferrer"">here</a>. </p>

<p>It's weird because there's not a whole lot of clear documentation for this. I understand that tensorflow is an API that's going through a lot of changes and adaptations right now, but it's hard to find clear answers. For example, we want to use <code>tf.train.Saver()</code>, but we aren't sure if there is anything comparable to <code>tf.train.Supervisor()</code>'s <code>managed_session</code>. </p>

<p>More to the point, however, we <em>just want to use our model</em>. We want to be able to map a string using <code>tensorflow.models.rnn.ptb.reader</code>. We're not sure how to do this. We pass in a string, and we want to do a simple prediction in terms of like predicting the next word in a string. So, something similar to this:</p>

<pre><code>import tensorflow as tf
sess = tf.Session()
new_saver = tf.train.import_meta_graph('ptbmodel.meta')
new_saver.restore(sess, tf.train.latest_checkpoint('./')) # latest checkpoint
all_vars = tf.global_variables()
# just want to make sure all our variables are there!
for v in all_vars:
    v_ = sess.run(v)
    print(""This is {} with value: {}"".format(v.name, v_))


sent = raw_input(""Enter a string where you want to predict the next word: "")
split_sent = sent.split()
# THEN map these words into our LSTM model and pull off the most likely word that 
# is coming next
</code></pre>

<p>But again, my buddy and I are pretty new to this, so we're not sure about where to go. I know this is probably too broad of a question for stack, but we've been pouring over the documentation and haven't been able to make much progress. <strong>ANY</strong> help would be appreciated so much! </p>

<p>We've already found these other Stack links. Check them out <a href=""https://stackoverflow.com/questions/36286594/predicting-the-next-word-using-the-lstm-ptb-model-tensorflow-example"">here</a> and <a href=""https://stackoverflow.com/questions/33773661/predicting-next-word-using-the-language-model-tensorflow-example"">here</a>.</p>

<p>We are not sure how to associate the <code>logits</code> probability list with any meaningful words.</p>
",1,Documentation Replication on Other Examples
40,42334855,state output from tf.nn.dynamic_rnn operation,"<p>For this code snippet:</p>

<pre><code>rnn_cell = tf.contrib.rnn.BasicRNNCell(config.hidden_size, activation=tf.tanh)
initial_state = rnn_cell.zero_state(config.batch_size, tf.float32)
rnn_out, state = tf.nn.dynamic_rnn(rnn_cell, embed_out, initial_state=initial_state)
</code></pre>

<p>I was expected the last time index from rnn_out to be equal to state. Or, perhaps the tanh of the state. But this isn't what I am seeing - they don't match. In the context of this RNN recurrence relation, what value does state contain?</p>

<p>h(t) = tanh[b + W<em>h(t-1) + U</em>x(t)]</p>

<p>The answer here, implies the last time index of rnn_out and state should be equal (but they are not):</p>

<p><a href=""https://stackoverflow.com/questions/40384791/for-the-tf-nn-rnn-cell-basicrnn-whats-the-difference-between-the-state-and-outp"">for the tf.nn.rnn_cell.BasicRNN,what&#39;s the difference between the state and output</a></p>

<p>The TF documentation isn't clear to me on this point.</p>
",1,Documentation Ambiguity
41,42338981,It seems inconsistent the ways tensorflow allows me to specify variable length dimension,"<p>I'm a novice to tensorflow. I was practicing coding with this <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py"" rel=""nofollow noreferrer"">tutorial code</a>. Most of all the code made sense to me but at some points I got stuck.</p>

<pre><code>import tensorflow as tf
x = tf.placeholder(""float"", [None, n_steps, n_input])
x = tf.transpose(x, [1, 0, 2])
x = tf.reshape(x, [-1, n_input])
</code></pre>

<p>With <code>tf.placholder</code> function I had to specify variable length dimesion with <code>None</code>. But with <code>tf.reshape</code> I had to use <code>-1</code>, not <code>None</code>. In documentation for the two functions, both of the pertaining arguments have the name <code>shape</code>. So I am feeling lost here. Do they really have different meanings? Or is it just a small design mistake of the tensorflow developers?</p>
",1,Documentation Ambiguity
42,42399401,Use of grads_ys parameter in tf.gradients - TensorFlow,"<p>I want to understand the <code>grad_ys</code> paramter in <code>tf.gradients</code>. I've seen it used like a multiplyer of the true gradient but its not crear in the definition. Mathematically how would the whole expression look like?</p>
",1,Lack of Alternative Solutions/Documentation
43,42618350,Tensorflow consecutive slice_input_producer,"<p>I am confused with how does <code>tf.train.slice_input_producer</code> works, I know it returns a dequeue op, but if I apply another <code>slice_input_producer</code> on the previous dequeued tensor, it seems the second <code>slice_input_producer</code> triggered the first ones dequeue op without finishing slicing. </p>

<p>Here is an example code:</p>

<pre><code>x = np.arange(6).reshape([2, 3])
input_x = tf.constant(x, dtype=tf.int32)

[row] = tf.train.slice_input_producer([input_x], num_epochs=1, shuffle=False)
[cloumn] = tf.train.slice_input_producer([row], num_epochs=1, shuffle=False)

init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())

sess = tf.Session()
sess.run(init_op)

coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)

print(x)
col = sess.run(cloumn)
print(col)
col = sess.run(cloumn)
print(col)
</code></pre>

<p>I am expecting 0,1,2,3,4,5 each time I eval <code>column</code>. But it gives 0 and 4, the second <code>slice_input_producer</code> didn't finishing slicing the first row.</p>

<p>How can I fix this? Many thanks in advance. </p>
",1,Documentation Ambiguity
44,42695305,Accessing row in a 2-D tensor,"<p>I have the following code of an incredibly simple neural network (this code is actually an adaptation for an easy question):</p>

<pre><code>import numpy as np
import tensorflow as tf

with tf.device(""cpu:0""):
    sess = tf.InteractiveSession()
    nNodes = 3
    inputDim = 1

    rowIdxs = np.zeros([nNodes, nNodes])
    colIdxs = np.zeros([nNodes, nNodes])
    for rowIdx in range(nNodes):
        for colIdx in range(nNodes):
            rowIdxs[rowIdx, colIdx] = rowIdx
            colIdxs[rowIdx, colIdx] = colIdx

    rowIdxs = np.reshape(rowIdxs, [-1])
    colIdxs = np.reshape(colIdxs, [-1])

    # build a matrix with nNodes x nNodes elements
    # with each row i containing the distance from node i to all the other nodes
    distances = np.zeros([nNodes, nNodes])
    for i in range(nNodes):
        for j in range(nNodes):
            distances[i, j] = ((rowIdxs[i] - rowIdxs[j]) ** 2 + (colIdxs[i] - colIdxs[j]) ** 2)
    print('distances=', distances)

    # tensorflow constant from distances matrix
    distances_ = tf.constant(distances, dtype=tf.float32)

    # w corresponds to a weight matrix in a neural network
    w = tf.random_uniform((nNodes, inputDim), 0.0, 1.0)

    # x corresponds to the input to the network
    x = tf.random_uniform((1, inputDim), 0.0, 1.0)

    xx = tf.tile(x, [nNodes,1])
    print('w', w.shape)
    print('x', x.shape)
    print('xx', xx.shape)

    # differences between weights and input vector
    diff = tf.reduce_sum(tf.abs(tf.subtract(xx, w)), 1)
    print('diff.shape', diff.shape)


    # index of the best matching unit
    bmu = tf.arg_min(diff, 0)       

    # Now I need to access the distances from BMU to the other nodes
    slice = tf.slice(distances_, [bmu, 0], [bmu, -1])

    sess.run(tf.global_variables_initializer())
    sess.run(slice)
    print('slice=', slice.eval())
    print('diff', diff.eval())
    print('bmu=', bmu.eval())
</code></pre>

<p>Basically, given an input <code>x</code>, compare it to the weights <code>w</code> and choose the node <code>BMU</code> with the minimum differences.</p>

<p>I have several problems with that code:</p>

<p><strong>1. sometimes it works without errors sometimes it raises an exception.</strong> </p>

<p><strong>When it DOES NOT work</strong>, the output is this:</p>

<pre><code>distances= 
 [[ 0.  1.  4.]
 [ 1.  0.  1.]
 [ 4.  1.  0.]]

w (3, 1)
x (1, 1)
xx (3, 1)
diff.shape (3,)

InvalidArgumentError (see above for traceback): Expected size[0] in [0, 1], but got 2
 [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]
</code></pre>

<p>The full stack follows:</p>

<pre><code>Traceback (most recent call last):
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1022, in _do_call
    return fn(*args)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""D:\python\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected size[0] in [0, 1], but got 2
     [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 44, in &lt;module&gt;
    sess.run(slice)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 767, in run
    run_metadata_ptr)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected size[0] in [0, 1], but got 2
     [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]

Caused by op 'Slice', defined at:
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 39, in &lt;module&gt;
    slice = tf.slice(distances_, [bmu, 0], [bmu, -1])
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 561, in slice
    return gen_array_ops._slice(input_, begin, size, name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 3053, in _slice
    name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Expected size[0] in [0, 1], but got 2
     [[Node: Slice = Slice[Index=DT_INT64, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Const, Slice/begin, Slice/size)]]
</code></pre>

<p><strong>When it works</strong></p>

<pre><code>w (3, 1)
x (1, 1)
xx (3, 1)
diff.shape (3,)
slice= [[ 1.  0.  1.]]
diff [ 0.29777944  0.08669317  0.09722018]
bmu= 0
</code></pre>

<p><code>bmu</code> is wrong, it should be <code>1</code>, but the slice is correct.</p>

<p>Sometimes I get this:</p>

<pre><code>w (3, 1)
x (1, 1)
xx (3, 1)
diff.shape (3,)
slice= []
diff [ 0.33319855  0.12426794  0.49753141]
bmu= 1
</code></pre>

<p><code>bmu</code> is 1, but slice is empty.</p>

<p><strong>2. When I switch to the GPU, I have an exception telling me I cannot use <code>bmu</code> for indexing.</strong>
Starting with <code>with tf.device(""gpu:0""):</code>, I get this:</p>

<pre><code>InvalidArgumentError (see above for traceback): Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]
</code></pre>

<p>The full stack trace follows:</p>

<pre><code>Traceback (most recent call last):
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1022, in _do_call
    return fn(*args)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""D:\python\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 45, in &lt;module&gt;
    sess.run(slice)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 767, in run
    run_metadata_ptr)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]

Caused by op 'Slice/size', defined at:
  File ""D:/workspace/LiClipse Workspace/kerasPython/exercises/testIndexing.py"", line 40, in &lt;module&gt;
    slice = tf.slice(distances_, [bmu, 0], [bmu, -1])
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 561, in slice
    return gen_array_ops._slice(input_, begin, size, name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 3053, in _slice
    name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 491, in apply_op
    preferred_dtype=default_dtype)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 923, in _autopacking_conversion_function
    return _autopacking_helper(v, inferred_dtype, name or ""packed"")
  File ""D:\python\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 886, in _autopacking_helper
    return gen_array_ops._pack(elems_as_tensors, name=scope)
  File ""D:\python\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 2041, in _pack
    result = _op_def_lib.apply_op(""Pack"", values=values, axis=axis, name=name)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""D:\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device to node 'Slice/size': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
     [[Node: Slice/size = Pack[N=2, T=DT_INT64, axis=0, _device=""/device:GPU:0""](ArgMin, Slice/size/1)]]
</code></pre>

<p>I cannot understand what's happening: I have an idea, but cannot find any reference in the documentation or anywhere else. May be I use the wrong keywords.</p>

<p>Is there anyone who can help me?</p>
",1,Lack of Alternative Solutions/Documentation
45,42754259,Sampled softmax loss over variable sequence batches?,"<p><strong>Background info</strong>: I'm working on sequence-to-sequence models, and right now my model accepts variable-length input tensors (not lists) with input shapes corresponding to [batch size, sequence length]. However, in my implementation, sequence length is <em>unspecified</em> (set to None) to allow for variable length inputs. Specifically, input sequence batches are padded only to the length of the longest sequence in that batch. This has sped up my training time considerably, so I'd prefer to keep it this way, as opposed to going back to bucketed models and/or padded all sequences in the training data to the same length. I'm using TensorFlow 1.0.0.</p>

<p><strong>Problem</strong>: I'm currently using the following to compute the loss (which runs just fine).</p>

<pre><code>loss = tf.losses.sparse_softmax_cross_entropy(
    weights=target_labels,  # shape: [batch size, None]
    logits=outputs[:, :-1, :], # shape: [batch size, None, vocab size]
    weights=target_weights[:, :-1]) # shape: [batch size, None]
</code></pre>

<p>where vocab size is typically about 40,000. I'd like to use a sampled softmax, but I've ran into an issue that's due to the unspecified nature of the input shape. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""nofollow noreferrer"">documentation for tf.nn.sampled_softmax_loss</a>, <strong>it requires the inputs to be fed separately for each timestep</strong>. However, I can't call, for example,  </p>

<pre><code>tf.unstack(target_labels, axis=1)
</code></pre>

<p>since the axis is unknown beforehand.Does anyone know how I might go about implementing this? One would assume that since both dynamic_rnn and <a href=""https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy"" rel=""nofollow noreferrer"">tf.losses.sparse_softmax_cross_entropy</a> seem to have no issue doing this, that a workaround could be implemented with the sampled softmax loss somehow. After digging around in the source code and even models repository, I've come up empty handed. Any help/suggestions would be greatly appreciated.</p>
",1,Documentation Replicability
46,42785026,tf.nn.conv2d vs tf.layers.conv2d,"<p>Is there any advantage in using <code>tf.nn.*</code> over <code>tf.layers.*</code>?</p>

<p>Most of the examples in the doc use <code>tf.nn.conv2d</code>, for instance, but it is not clear why they do so.</p>
",1,Lack of Alternative Solutions/Documentation
47,42818819,What is the difference between tensorflow conv2d_transpose and conv2d_backprop_filter?,"<p>Can someone please explain in simple terms and examples on how these work after performing the conv2d forward pass.</p>

<p>Let me add to this question - What is the difference between conv2d_backprop_filter and tf.nn.conv2d_backprop_input?</p>
",1,Documentation Ambiguity
48,42933599,Slice a tensor in half in tensorflow,"<p>I have a tensor of shape <code>(32, 32, 32, 1)</code> and I want to slice it into two tensors, along the first dimension, containing the first and second halves like so</p>

<pre><code>half1  with shape = (16, 32, 32, 1)
half2  with shape = (16, 32, 32, 1)
</code></pre>

<p>I am trying to use tf.slice but I don't know how to use the begin and end indices, and the documentation is anything but clear. </p>
",1,Documentation Ambiguity
49,43175272,check if tensorflow placeholder is filled,"<p>Suppose I have two placeholder quantities in tensorflow: placeholder_1 and placeholder_2. Essentially I would like the following computational functionality: ""if placeholder_1 is defined (ie is given a value in the feed_dict of sess.run()), compute X as f(placeholder_1), otherwise, compute X as g(placeholder_2)."" Think of X as being a hidden layer in a neural network that can optionally be computed in these two different ways. Eventually I would use X to produce an output, and I'd like to backpropagate error to the parameters of f or g depending on which placeholder I used. </p>

<p>One could accomplish this using the tf.where(condition, x, y) function if there was a way to make the condition ""placeholder_1 has a value"", but after looking through the tensorflow documentation on booleans and asserts I couldn't find anything that looked applicable.</p>

<p>Any ideas? I have a vague idea of how I could accomplish this basically by copying part of the network, sharing parameters and syncing the networks after updates, but I'm hoping for a cleaner way to do it.</p>
",1,Lack of Alternative Solutions/Documentation
50,43367697,Batching and shuffling padded tf.train.SequenceExample,"<p>I have some training example of a sequence-to-sequence scenario which are stored as <code>tf.train.SequenceExample</code> in one (or more) file(s) written <code>TFRecordWriter</code>. I would like to read, decode them and feed shuffled batches of them into my network. I have been struggling with the documentation and some tutorials found here and there but I could not make anything out of such stuff. I am working on a self-contained example, here below. </p>

<pre><code>import random

import tensorflow as tf

from six.moves import xrange


MIN_LEN = 6
MAX_LEN = 12
NUM_EXAMPLES = 20
BATCH_SIZE = 3
PATH = 'ciaone.tfrecords'
MIN_AFTER_DEQUEUE = 10
NUM_THREADS = 2
SAFETY_MARGIN = 1
CAPACITY = MIN_AFTER_DEQUEUE + (NUM_THREADS + SAFETY_MARGIN) * BATCH_SIZE


def generate_example():
    # fake examples which are just useful to have a quick visualization.
    # The input is a sequence of random numbers.
    # The output is a sequence made of those numbers from the
    # input sequence which are greater or equal then the average.
    length = random.randint(MIN_LEN, MAX_LEN)
    input_ = [random.randint(0, 10) for _ in xrange(length)]
    avg = sum([1.0 * item for item in input_]) / len(input_)
    output = [item for item in input_ if item &gt;= avg]
    return input_, output


def encode(input_, output):
    length = len(input_)
    example = tf.train.SequenceExample(
        context=tf.train.Features(
            feature={
                'length': tf.train.Feature(
                    int64_list=tf.train.Int64List(value=[length]))
            }),
        feature_lists=tf.train.FeatureLists(
            feature_list={
                'input': tf.train.FeatureList(
                    feature=[
                        tf.train.Feature(
                            int64_list=tf.train.Int64List(value=[item]))
                        for item in input_]),
                'output': tf.train.FeatureList(
                    feature=[
                        tf.train.Feature(
                            int64_list=tf.train.Int64List(value=[item]))
                        for item in output])
            }
        )
    )
    return example


def decode(example):
    context_features = {
        'length': tf.FixedLenFeature([], tf.int64)
    }
    sequence_features = {
        'input': tf.FixedLenSequenceFeature([], tf.int64),
        'output': tf.FixedLenSequenceFeature([], tf.int64)
    }
    ctx, seq = tf.parse_single_sequence_example(
        example, context_features, sequence_features)
    input_ = seq['input']
    output = seq['output']
    return input_, output

if __name__ == '__main__':
    # STEP 1. -- generate a dataset.
    with tf.python_io.TFRecordWriter(PATH) as writer:
        for _ in xrange(NUM_EXAMPLES):
           record = encode(*generate_example())
           writer.write(record.SerializeToString())

    with tf.Session() as sess:
        queue = tf.train.string_input_producer([PATH])
        reader = tf.TFRecordReader()
        _, value = reader.read(queue)
        input_, output = decode(value)

        # HERE I AM STUCK!

        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        sess.run(tf.local_variables_initializer())
        sess.run(tf.global_variables_initializer())
        try:
            while True:
                # do something...
        except tf.errors.OutOfRangeError, e:
            coord.request_stop(e)
        finally:
            coord.request_stop()
            coord.join(threads)
        coord.request_stop()
        coord.join(threads)
</code></pre>

<p>Can anyone suggest me how to proceed?
Thanks in advance!</p>

<p>P.S. as a side request: any pointer about resources to better understand the input pipeline APIs of TensorFlow is appreciated.</p>
",1,Requesting (Additional) Documentation/Examples
51,43411738,tf.image.pad_to_bounding_box VS tf.pad and tf.image.crop_to_bounding_box VS tf.slice,"<p>I'd like to understand why does the two functions <code>tf.image.crop_to_bounding_box</code> and <code>tf.image.pad_to_bounding_box</code> exists, since the behaviour of these two functions can be done really simply with respectively <code>tf.slice</code> and <code>tf.pad</code>.</p>

<p>They are not so much easier to understand, and their scope is narrow since they accept only 3D and 4D tensors. Furthermore, they tend to be slower in terms of time of execution. </p>

<p>Is there something I miss here ? </p>
",1,Documentation Replicability
52,43422949,CTC Loss InvalidArgumentError: sequence_length(b) <= time,"<p>I am running into this error while trying to use tf.nn.ctc_loss through keras (ctc_batch_cost):</p>

<blockquote>
  <p>InvalidArgumentError (see above for traceback): sequence_length(4) &lt;= 471</p>
</blockquote>

<p>According to the documentation for tf.nn.ctc_loss, Input requirements are:</p>

<blockquote>
  <p>sequence_length(b) &lt;= time for all b</p>
  
  <p>max(labels.indices(labels.indices[:, 1] == b, 2))   &lt;=
  sequence_length(b) for all b.</p>
</blockquote>

<p>I am having a hard time understanding what this means-- what is <code>b</code> and what is <code>sequence_length(b)</code>? </p>
",1,Documentation Ambiguity
53,43443205,Tensorflow tf.nn.conv2d clarification,"<p>In reading through the Tensorflow tutorial and API documentation, I do not understand how they defined the shape of the convolution input and filter arguments. The method is: <code>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)</code>, where the input is shape: <code>[batch, in_height, in_width, in_channels]</code> and the filter is shape: <code>[filter_height, filter_width, in_channels, out_channels]</code>. If anyone could shed light on how to properly define the ""in_channel"" and ""out_channel"" sizes, that would be very helpful. </p>
",1,Documentation Ambiguity
54,43460838,tensorflow tfrecord storage for large datasets,"<p>I'm trying to understand the ""proper"" method of storage for large datasets for tensorflow ingestion. The documentation seems relatively clear that no matter what, tfrecord files are preferred. Large is a subjective measure, but the examples below are randomly generated regression datasets from sklearn.datasets.make_regression() of 10,000 rows and between 1 and 5,000 features, all float64.</p>

<p>I've experimented with two different methods of writing tfrecord files with dramatically different performance.</p>

<p>For numpy arrays, <code>X</code>, <code>y</code> (X.shape=(10000, n_features), y.shape=(10000,)</p>

<h2><code>tf.train.Example</code> with per-feature <code>tf.train.Features</code></h2>

<p>I construct a tf.train.Example in the way that tensorflow developers seem to prefer, at least judging by tensorflow example code at <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py</a>. </p>

<p>For each observation or row in <code>X</code>, I create a dictionary keyed with feature names (f_0, f_1, ...) whose values are <code>tf.train.Feature</code> objects with the feature's observation data as a single element of its float_list.</p>

<pre><code>def _feature_dict_from_row(row):
    """"""
    Take row of length n+1 from 2-D ndarray and convert it to a dictionary of
    float features:

      {
        'f_0': row[0],
        'f_1': row[1],
        ...
        'f_n': row[n]
      }
    """"""
    def _float64_feature(feature):
        return tf.train.Feature(float_list=tf.train.FloatList(value=[feature]))

    features = { ""f_{:d}"".format(i): _float64_feature(value) for i, value in enumerate(row) }
    return features

def write_regression_data_to_tfrecord(X, y, filename):
    with tf.python_io.TFRecordWriter('{:s}'.format(filename)) as tfwriter:
        for row_index in range(X.shape[0]):
            features = _feature_dict_from_row(X[row_index])
            features['label'] = y[row_index]

            example = tf.train.Example(features=tf.train.Features(feature=features))
            tfwriter.write(example.SerializeToString())
</code></pre>

<h2><code>tf.train.Example</code> with one large <code>tf.train.Feature</code> containing all features</h2>

<p>I construct a dictionary with one feature (really two counting the label) whose value is a <code>tf.train.Feature</code> with the entire feature row in as its float_list</p>

<pre><code>def write_regression_data_to_tfrecord(X, y, filename, store_by_rows=True):
    with tf.python_io.TFRecordWriter('{:s}'.format(filename)) as tfwriter:
        for row_index in range(X.shape[0]):
            features = { 'f_0': tf.train.Feature(float_list=tf.train.FloatList(value=X[row_index])) }
            features['label'] = y[row_index]

            example = tf.train.Example(features=tf.train.Features(feature=features))
            tfwriter.write(example.SerializeToString())
</code></pre>

<p>As the number of features in the dataset grows, the second option gets considerably faster than the first, as shown in the following graph. <em>Note the log scale</em></p>

<p><strong>10,000 rows:</strong></p>

<p><img src=""https://i.stack.imgur.com/p4w9M.png"" alt=""graph""></p>

<p>It makes intuitive sense to me that creating 5,000 <code>tf.train.Feature</code> objects is significantly slower than creating one object with a float_list of 5,000 elements, but it's not clear that this is the ""intended"" method for feeding large numbers of features into a tensorflow model.</p>

<p>Is there something inherently wrong with doing this the faster way?</p>
",1,Documentation Replication on Other Examples
55,43792961,Understanding the while loop in Tensorflow,"<p>I am using the <a href=""https://www.tensorflow.org/api_docs/python/"" rel=""noreferrer"">Python API for Tensorflow</a>. I am trying to implement the <a href=""https://www.sfu.ca/~ssurjano/rosen.html"" rel=""noreferrer"">Rosenbrock function</a> given below without the use of a Python loop:</p>

<p><a href=""https://i.stack.imgur.com/9AdOH.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/9AdOH.png"" alt=""Rosenbrock function""></a></p>

<p>My current implementation is as follows:</p>

<pre><code>def rosenbrock(data_tensor):
    columns = tf.unstack(data_tensor)

    summation = 0
    for i in range(1, len(columns) - 1):
        first_term = tf.square(tf.subtract(columns[i + 1], tf.square(columns[i])))
        second_term = tf.square(tf.subtract(columns[i], 1.0))
        summation += tf.add(tf.multiply(100.0, first_term), second_term)

    return summation
</code></pre>

<p>I have tried implementing the summation in a <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""noreferrer""><code>tf.while_loop()</code></a>; however, I found the API somewhat unintuitive when it comes to using an index integer that is meant to remain separate from the data. The example given in the <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""noreferrer"">documentation</a> uses the data as the index (or vice-versa):</p>

<pre><code>i = tf.constant(0)
c = lambda i: tf.less(i, 10)
b = lambda i: tf.add(i, 1)
r = tf.while_loop(c, b, [i])
</code></pre>
",1,Documentation Replication on Other Examples
56,43827792,How do I use strided_slice to select all the element in tensorflow?,"<p>I read the examples in document:</p>

<pre><code># 'input' is [[[1, 1, 1], [2, 2, 2]],
#             [[3, 3, 3], [4, 4, 4]],
#             [[5, 5, 5], [6, 6, 6]]]
tf.strided_slice(input, [1, 0, 0], [2, 1, 3], [1, 1, 1]) ==&gt; [[[3, 3, 3]]]
tf.strided_slice(input, [1, 0, 0], [2, 2, 3], [1, 1, 1]) ==&gt; [[[3, 3, 3],
                                                               [4, 4, 4]]]
tf.strided_slice(input, [1, -1, 0], [2, -3, 3], [1, -1, 1]) ==&gt;[[[4, 4, 4],
                                                                 [3, 3, 3]]] 
</code></pre>

<p>It seems like that I can not simply use <code>input[:,:]</code> to select all the element, instead I have to use the syntax like <code>input[:-1, :-1]</code>. However in this way <code>input[:-1, :-1]</code> , I will miss the last row or last column. What should I do?</p>

<p>I take an example:</p>

<pre><code>ph = tf.placeholder(shape=[None, 3], dtype=tf.int32)
x = tf.strided_slice(ph, [0,0],[-1,-1],[1,1])
input_ = np.array([[1,2,3],
                  [3,4,5],
                  [7,8,9]])
sess = tf.InteractiveSession()
sess.run(x,feed_dict={ph:input_})
</code></pre>

<p>output:</p>

<pre><code>array([[1, 2],
       [3, 4]])
</code></pre>

<p>I read a lot of material and I found that I can use <code>tf.shape(ph)</code>,let see:</p>

<pre><code>ph = tf.placeholder(shape=[None, 3], dtype=tf.int32)
x = tf.strided_slice(ph, [0,0],tf.shape(ph),[1,1])
input_ = np.array([[1,2,3],
                  [3,4,5],
                  [7,8,9]])
sess = tf.InteractiveSession()
sess.run(x,feed_dict={ph:input_})
</code></pre>

<p>out:</p>

<pre><code>array([[1, 2, 3],
       [3, 4, 5],
       [7, 8, 9]])
</code></pre>

<p>However, if I want to get the result like this:</p>

<pre><code>[[1, 2],
 [3, 4],
 [7, 8]]
</code></pre>

<p>What can I do?</p>
",1,Documentation Replicability
57,43885770,Clarification of tf.name_scope in TensorFlow documentation,"<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/name_scope"" rel=""nofollow noreferrer"">TensorFlow documentation</a> mentions the following for <code>tf.name_scope</code></p>

<pre><code>This context manager validates that the given values are from the same
graph, makes that graph the default graph, and pushes a name scope in 
that graph.
</code></pre>

<p>What is the meaning of <code>given values are from the same graph, makes that graph the default graph</code> ? </p>

<p><code>Same graph</code> refers to which graph ?</p>

<p>Also, what is the use of <code>values</code> parameter in <code>tf.name_scope</code> ? </p>
",1,Documentation Ambiguity
58,43916019,Control dependencies and order of evaluation,"<p>Please consider the following code: </p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

with tf.device(""gpu:0""):
    sess = tf.InteractiveSession()
    idx = tf.constant(0)
    # 10 iterations
    while_condition = lambda i: tf.less(i, tf.constant(10))        
    acc = tf.Variable(0, dtype=tf.float64)
    # the body of the while adds 1 to acc in each iteration
    def body_accumulator(i):
        mainOp = tf.assign_add(acc, 1.0)
        return tf.tuple([tf.add(i, 1)], control_inputs=[mainOp])
    whileOp = tf.while_loop(while_condition, body_accumulator, [idx])

    # My idea: return acc after evaluating whileOp, whose code modifies acc
    def f(dummy):
        with tf.control_dependencies([whileOp]):
            # with return tf.identity(acc) it works
            return acc
    def g():
        return acc

    sess.run(tf.global_variables_initializer())
    print('""g: return acc .eval()"" - this is the only time where I would expect 0')
    print(g().eval())
    print('f(dummy)')
    print(f(1).eval())
    print('whileOp.eval()')
    print(whileOp.eval())
    print('acc value:')
    print(acc.eval())
    print('""g: return acc .eval()""')
    print(g().eval())
</code></pre>

<p>The output is:</p>

<pre><code>""g: return acc .eval()"" - this is the only time where I would expect 0
0.0
f(dummy)
0.0
whileOp.eval()
10
acc value:
10.0
""g: return acc .eval()""
10.0
</code></pre>

<p>My question is:</p>

<p>why does <code>f(1).eval()</code> return 0 even if there is a control dependency on the <code>whileOp</code> that modifies the returned variable <code>acc</code>?</p>

<p>After reading the documentation, I was expecting <code>whileOp</code> to be evaluated before returning acc. How should I write the function <code>f(.)</code> in order to force the evaluation of <code>whileOp</code>?</p>

<p>In <code>f(.)</code>, if I return <code>tf.identity(acc)</code> instead of <code>acc</code>, it works as I expect.</p>
",1,Inadequate Examples
59,44123088,How tf.nn.softmax_cross_entropy_with_logits can compute softmax cross entropy in tensorflow?,"<p>tf.nn.softmax_cross_entropy_with_logits, Documentation says that it computes softmax cross entropy between logits and labels what does it mean? Is it not applying cross entropy loss function formula on it? Why documentation says that it computes sofmax cross entropy?</p>
",1,Documentation Ambiguity
60,44162432,Analysis of the output from tf.nn.dynamic_rnn tensorflow function,"<p>I am not able to understand the output from <code>tf.nn.dynamic_rnn</code> tensorflow function. The document just tells about the size of the output, but it doesn't tell what does each row/column means. From the documentation:</p>

<blockquote>
  <p><strong>outputs</strong>: The RNN output <code>Tensor</code>.</p>
  
  <p>If time_major == False (default), this will be a <code>Tensor</code> shaped:
      <code>[batch_size, max_time, cell.output_size]</code>.</p>
  
  <p>If time_major == True, this will be a <code>Tensor</code> shaped:
      <code>[max_time, batch_size, cell.output_size]</code>.</p>
  
  <p>Note, if <code>cell.output_size</code> is a (possibly nested) tuple of integers
  or <code>TensorShape</code> objects, then <code>outputs</code> will be a tuple having the<br>
  same structure as <code>cell.output_size</code>, containing Tensors having shapes
  corresponding to the shape data in <code>cell.output_size</code>.</p>
  
  <p><strong>state</strong>: The final state.  If <code>cell.state_size</code> is an int, this   will
  be shaped <code>[batch_size, cell.state_size]</code>.  If it is a<br>
  <code>TensorShape</code>, this will be shaped <code>[batch_size] + cell.state_size</code>.<br>
  If it is a (possibly nested) tuple of ints or <code>TensorShape</code>, this will
  be a tuple having the corresponding shapes.</p>
</blockquote>

<p>The <code>outputs</code> tensor is a 3-D matrix but what does each row/column represent?</p>
",1,Documentation Completeness
61,44206534,Why is tf.transpose so important in a RNN?,"<p>I've been reading the docs to learn TensorFlow and have been struggling on when to use the following functions and their purpose.</p>

<pre><code>tf.split()
tf.reshape()
tf.transpose()
</code></pre>

<p>My guess so far is that:</p>

<p>tf.split() is used because inputs must be a sequence.</p>

<p>tf.reshape() is used to make the shapes compatible (Incorrect shapes tends to be a common problem / mistake for me). I used numpy for this before. I'll probably stick to tf.reshape() now. I am not sure if there is a difference between the two. </p>

<p>tf.transpose() swaps the rows and columns from my understanding. If I don't use tf.transpose() my loss doesn't go down. If the parameter values are incorrect the loss doesn't go down. So the purpose of me using tf.transpose() is so that my loss goes down and my predictions become more accurate. </p>

<p>This bothers me tremendously because I'm using tf.transpose() because I have to and have no understanding why it's such an important factor. I'm assuming if it's not used correctly the inputs and labels can be in the wrong position. Making it impossible for the model to learn. If this is true how can I go about using tf.transpose() so that I am not so reliant on figuring out the parameter values via trial and error?  </p>
",1,Documentation Replicability
62,44315874,Is adding a dimension broadcasting?,"<p>Given</p>

<pre><code>a = tf.constant([[1, 2, 3], [10, 20, 30], [100, 200, 300], [1000, 2000, 3000]])
</code></pre>

<p>all of the following are equivalent</p>

<pre><code>b = tf.constant([100000, 200000, 300000])
print((a+b).eval())

bb = tf.constant([[100000, 200000, 300000]])
print((a+bb).eval())

bbb = tf.constant([[100000, 200000, 300000], [100000, 200000, 300000], [100000, 200000, 300000], [100000, 200000, 300000]])
print((a+bbb).eval())
</code></pre>

<p>and produce</p>

<pre><code>[[100001 200002 300003]
 [100010 200020 300030]
 [100100 200200 300300]
 [101000 202000 303000]]
</code></pre>

<p>I understand that <code>bb</code> is ""broadcast"" to the value corresponding to <code>bbb</code> by <code>tf.add</code> (here <code>+</code>). Is the addition of a dimension that transforms <code>b</code> to the value of <code>bbb</code> all broadcasting, or is it something else?</p>
",1,Documentation Replication on Other Examples
63,44339463,confusing situations when `tf.constant` not displayed in `tensorboard`?,"<p>Below is the working code where some <code>tf.constant</code> get displayed in <code>tensorboard</code>, some don't. </p>

<p>However, I have no idea why those don't get displayed. </p>

<p>Could anyone help me out here? Thanks</p>

<pre><code>import tensorflow as tf
import numpy as np
# tf.constant(value, dtype=None, shape=None,
# name='Const', verify_shape=False)


a = tf.constant([2, 2], name=""a"")
b = tf.constant([[0, 1], [2, 3]], name=""b"")
x = tf.add(a, b, name=""add"")
y = tf.multiply(a, b, name=""mul"")

# verify_shape=True, error if shape not match
# edge1 = tf.constant(2, dtype=None, shape=[2,2], name=""wrong_shape"", verify_shape=True)


# verify_shape=False, if shape not match, will add to match
edge2 = tf.constant(2, dtype=None, shape=[2,2], name=""edge2"", verify_shape=False)
# increase row by row, from left to right
edge3 = tf.constant([1,2,3,4], dtype=None, shape=[4,3], name=""edge3"", verify_shape=False)

# reassign works
edge2c = edge2
edge3c = edge3

edge4 = tf.constant(np.ones((2,2)), dtype=None, shape=None, name=""shape22"", verify_shape=False)
# increase row by row, from left to right
edge5 = tf.constant(np.ones((4,3)), dtype=None, shape=[4,3], name=""shape43"", verify_shape=False)


with tf.Session() as sess:
    writer = tf.summary.FileWriter('./log/01_tf', sess.graph)
    x, y = sess.run([x, y])
    sess.run(edge4)
    sess.run(edge5)
    sess.run(edge2c)
    sess.run(edge3c)

writer.close()
</code></pre>
",1,Documentation Replicability
64,44357675,Documentation on how to use tf.estimator in TensorFlow,"<p>I understand that we can write custom models and encapsulate it using tf.estimator. But I just can't seem to find any documentation with an example.</p>

<p>I know that you have to define your model inside a 'model_fn' but what exactly should I return from this function. Also am I supposed to put the the loss and the training step within the 'model_fn' or just the network.  How should I modify the code give below to make it work with tf.estimator. Would really appreciate some help.</p>

<pre><code>def test_model(features,labels):
    X = tf.placeholder(tf.float32,shape=(None,1),name=""Data_Input"")
    #Output
    Y = tf.placeholder(tf.float32,shape=(None,1),name=""Target_Labels"")
    W =  tf.Variable(tf.random_normal([0],stddev=stddev0)) 
    b = tf.Variable(tf.random_normal([0],stddev=stddev0))

    Ypredict = W*X + b
    return Ypredict

 estimator = tf.estimator.Estimator(model_fn = test_model)
</code></pre>
",1,Documentation Replicability
65,44415901,tensorflow using tf.train.string_input_producer,"<p>I'm using tf.train.string_input_producer to read data from tfRecord file. I suppose it create a queue and pipeline and the data will automatically loaded and feed into my model. However, it stuck at the first batch, and show this exception:</p>

<blockquote>
  <p>FailedPreconditionError (see above for traceback): Attempting to use uninitialized value input_producer/limit_epochs/epochs</p>
</blockquote>

<p>my tfrecord was made by tf.train.SequenceExample, instead of tf.train.Example, which don't have clear documentation in the official guide.</p>

<p>here is code snapshot to reproduce my problem. (I believe my problem come from the queue initializing or sth. because it seems that the whole pipeline is hang up)</p>

<pre><code>from config.config import get_config

init = tf.global_variables_initializer()
config = get_config()

filename_queue = tf.train.string_input_producer(['data0.tfrecord,data1.tfrecord'], 5, capacity=16384)
reader = tf.TFRecordReader()

(keys, values) = reader.read_up_to(filename_queue, config.batch_size)

context_features = {
    ""seq_len"": tf.FixedLenFeature([1], dtype=tf.int64),
}
audio_features = {
    ""audio"": tf.FixedLenSequenceFeature([config.num_features], dtype=tf.float32),
    ""label"": tf.FixedLenSequenceFeature([config.num_classes], dtype=tf.float32)
}
audio_list = []
label_list = []
len_list = []

for i in range(config.batch_size):
    print(i)
    context, sequence = tf.parse_single_sequence_example(
        serialized=values[i],
        context_features=context_features,
        sequence_features=audio_features
    )
    audio = sequence['audio']
    label = sequence['label']
    # seq_len = context['seq_len'][0]
    seq_len = tf.shape(audio)[0]
    audio_list.append(audio)
    label_list.append(label)
    len_list.append(seq_len)

audio_tensor = tf.stack(audio_list)
label_tenor = tf.stack(label_list)
len_tensor = tf.stack(len_list)

with tf.Session() as sess:
    sess.run(init)

    threads = tf.train.start_queue_runners(sess=sess)
    for i in range(3):
        x, y, z = sess.run([audio_tensor, label_tenor, len_tensor])
        print(z)
</code></pre>
",1,Lack of Alternative Solutions/Documentation
66,44415901,tensorflow using tf.train.string_input_producer,"<p>I'm using tf.train.string_input_producer to read data from tfRecord file. I suppose it create a queue and pipeline and the data will automatically loaded and feed into my model. However, it stuck at the first batch, and show this exception:</p>

<blockquote>
  <p>FailedPreconditionError (see above for traceback): Attempting to use uninitialized value input_producer/limit_epochs/epochs</p>
</blockquote>

<p>my tfrecord was made by tf.train.SequenceExample, instead of tf.train.Example, which don't have clear documentation in the official guide.</p>

<p>here is code snapshot to reproduce my problem. (I believe my problem come from the queue initializing or sth. because it seems that the whole pipeline is hang up)</p>

<pre><code>from config.config import get_config

init = tf.global_variables_initializer()
config = get_config()

filename_queue = tf.train.string_input_producer(['data0.tfrecord,data1.tfrecord'], 5, capacity=16384)
reader = tf.TFRecordReader()

(keys, values) = reader.read_up_to(filename_queue, config.batch_size)

context_features = {
    ""seq_len"": tf.FixedLenFeature([1], dtype=tf.int64),
}
audio_features = {
    ""audio"": tf.FixedLenSequenceFeature([config.num_features], dtype=tf.float32),
    ""label"": tf.FixedLenSequenceFeature([config.num_classes], dtype=tf.float32)
}
audio_list = []
label_list = []
len_list = []

for i in range(config.batch_size):
    print(i)
    context, sequence = tf.parse_single_sequence_example(
        serialized=values[i],
        context_features=context_features,
        sequence_features=audio_features
    )
    audio = sequence['audio']
    label = sequence['label']
    # seq_len = context['seq_len'][0]
    seq_len = tf.shape(audio)[0]
    audio_list.append(audio)
    label_list.append(label)
    len_list.append(seq_len)

audio_tensor = tf.stack(audio_list)
label_tenor = tf.stack(label_list)
len_tensor = tf.stack(len_list)

with tf.Session() as sess:
    sess.run(init)

    threads = tf.train.start_queue_runners(sess=sess)
    for i in range(3):
        x, y, z = sess.run([audio_tensor, label_tenor, len_tensor])
        print(z)
</code></pre>
",1,Documentation Replicability
67,44478812,What kind of calculation does tf.nn.dynamic_rnn do with its input parameters?,"<p>What kind of calculation does <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer""><code>tf.nn.dynamic_rnn</code></a> perform? How does it use the parameters <code>cell</code> and <code>inputs</code> (to create the result)? </p>

<p>I have looked up in the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">documentation</a>, but I have not found an explanation.</p>
",1,Documentation Completeness
68,44526763,How to perform tf.image.per_image_standardization on a batch of images in tensorflow,"<p>I would like to know how to perform image whitening on a batch of images. </p>

<p>According to the documentation in <a href=""https://www.tensorflow.org/api_docs/python/tf/image/per_image_standardization"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/image/per_image_standardization</a>, it is said that <code>tf.image.per_image_standardization</code> takes as input a 3D tensor, that is an image, of shape: <code>[height, width, channels]</code>. </p>

<p>Is it a missing feature or there is a different method?</p>

<p>Any help is much appreciated. </p>
",1,Documentation Replicability
69,44640357,Does Tensorflow's tf.while_loop automatically capture dependencies when executing in parallel?,"<p>I am interested in implementing a Recursive Neural Network in Tensorflow, like what has been done in <a href=""https://stackoverflow.com/questions/37054188/how-can-i-implement-a-recursive-neural-network-in-tensorflow"">How can I implement a recursive neural network in TensorFlow?</a>. </p>

<p>However, in his implementation, the <code>parallel_iterations</code> of the <code>tf.while_loop</code> statement was fixed to be 1. I fear that this might be too slow. Since the tree I am going to feed into tensorflow have parts that are not dependent on each other, I would hope that I could set <code>parallel_iterations</code> to a higher value. However, it is inevitable that there are some dependencies required in the tree I feed in as input to tensorflow, and I am afraid that setting it to higher value may break the dependency property. </p>

<p>So my question is, had Tensorflow's <code>tf.while_loop</code> automatically captured dependencies already, in order to only use paralleism on placed that are not dependent on each other?</p>

<p>The tensorflow documentation says the following:</p>

<blockquote>
  <p>For correct programs, while_loop should return the same result for any
  parallel_iterations > 0.</p>
</blockquote>

<p>But I am not sure what they mean by ""correct programs"".</p>
",1,Documentation Ambiguity
70,44690363,How to use tf.train.ExponentialMovingAverage in Android/IOS,"<p>I use <code>freeze_graph</code> to export my model to a file named <code>""frozen.pb""</code>. But Found that the accuracy of predictions on <code>frozen.pb</code> is very bad.</p>

<p>I know the problem maybe <code>MovingAverage</code> not included in <code>frozen.pb</code>.</p>

<p>When I use <code>model.ckpt</code> files to restore model for evaluating, if I call <code>tf.train.ExponentialMovingAverage(0.999)</code> , then the accuracy is good as expected, else the accuracy is bad.</p>

<p><strong>So How To export a binary model which performance is the same as the one restored from checkpoint files?</strong>  I want to use <code>"".pb""</code> files in Android Devices.</p>

<p><a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/train/moving_averages"" rel=""nofollow noreferrer"">The official document</a> doesn't mention this.</p>

<p>Thanks!!</p>

<p>Freeze Command:</p>

<pre><code>~/bazel-bin/tensorflow/python/tools/freeze_graph \
  --input_graph=./graph.pbtxt \
  --input_checkpoint=./model.ckpt-100000 \
  --output_graph=frozen.pb \
  --output_node_names=output  \
  --restore_op_name=save/restore_all \
  --clear_devices
</code></pre>

<p>Evaluate Code:</p>

<pre><code>... ...
logits = carc19.inference(images)
top_k = tf.nn.top_k(logits, k=10)

# Precision: 97%
# Restore the moving average version of the learned variables for eval.
variable_averages = tf.train.ExponentialMovingAverage(carc19.MOVING_AVERAGE_DECAY)
variables_to_restore = variable_averages.variables_to_restore()
for k in variables_to_restore.keys():
  print (k,variables_to_restore[k])
saver = tf.train.Saver(variables_to_restore)

# Precision: 84%
#saver = tf.train.Saver()

#model_path = '/tmp/carc19_train/model.ckpt-9801'
with tf.Session() as sess:
  saver.restore(sess, model_path)
... ...
</code></pre>
",1,Lack of Alternative Solutions/Documentation
71,44707368,Batch variable length sequences in tensorflow,"<p>I am reading variable length input sequences from files as numpy arrays, each of size <code>[timesteps_i, feature_size]</code>, and store them in a Python list.</p>

<p>Passing this list as argument to <code>tf.train.batch</code> results in a list of the same length, containing Tensors of size <code>[batch_size, timesteps_i, feature_size]</code>. </p>

<pre><code>inputs_batch_padded = tf.train.batch(
                tensors=inputs_chunk,
                batch_size=batch_size,
                capacity=128,
                enqueue_many=False,
                dynamic_pad=True)
</code></pre>

<ol>
<li><p>How can I obtain an output list that is <code>batch_size</code> times shorter than the original list?</p></li>
<li><p>How can it be inferred the original length of the sequences for each batch that is being passed to a <code>feed_dict</code>? I am checking out the seq to seq library, and it requires a list of lengths for each batch.</p></li>
<li><p>Am I supposed to pass numpy arrays for <code>tensors</code>? The <code>dynamic_pad</code> argument allows a <code>None</code> for the variable length dimension, but this will be known in advance in my case.</p></li>
<li><p>How should I interpret the following line from the API doc:
""An input tensor with shape [x, y, z] will be output as a tensor with shape [batch_size, x, y, z]"" ?
Is the same input tensor being replicated <code>batch_size</code> times ?</p></li>
</ol>
",1,Documentation Replicability
72,44753916,How to slice a part of tensor?,"<p>I want to slice [3.0 ,33.0].I have tried to access this slice by following code. I'm not so clear about tf.slice command. I'm not so clear about begin and size mentioned in documentaion about this command. Can someone please make it easy to understand.  </p>

<pre><code>batch = tf.constant([
  [#First image
    [[0.0,10.0],[1.0,11.0]],
    [[3.0,33.0],[4.0,44.0]]
  ],
  [#Second image
    [[5.0,55.0],[6.0,66.0]],
    [[7.0,77.0],[8.0,88.0]]
  ]
])
slice1 = tf.slice(batch,[0,0,0,0], [0,0,1,0]) 
sess = tf.InteractiveSEssion()
sess.run(tf.initialize_all_variables())
print slice1.eval()
</code></pre>
",1,Documentation Ambiguity
73,44871420,TensorFlow dynamic_rnn input for regression,"<p>I'm stuck trying to convert an existing tensorflow sequence to sequence classifier to a regressor.</p>

<p>Currently I'm stuck in handling the input for <code>tf.nn.dynamic_rnn()</code>. According to the documentation and other answers, input should be in the shape of <code>(batch_size, sequence_length, input_size)</code>. However my input data has only two dimensions: <code>(sequence_length, batch_size)</code>.</p>

<p>The original solution uses <code>tf.nn.embedding_lookup()</code> as an intermediate step before feeding input to <code>dynamic_rnn()</code>. If I understand correctly, I believe I don't need this step since I'm working on a regression problem, not a classification problem.</p>

<p>Do I need the embedding_lookup step? If so, why? If not, how can I fit my <code>encoder_inputs</code> directly into <code>dynamic_rnn()</code>?</p>

<p>Below is a working minimalized example of the general idea:</p>

<pre><code>import numpy as np
import tensorflow as tf

tf.reset_default_graph()
sess = tf.InteractiveSession()

PAD = 0
EOS = 1
VOCAB_SIZE = 10 # Don't think I should need this for regression?
input_embedding_size = 20

encoder_hidden_units = 20
decoder_hidden_units = encoder_hidden_units

LENGTH_MIN = 3
LENGTH_MAX = 8
VOCAB_LOWER = 2
VOCAB_UPPER = VOCAB_SIZE
BATCH_SIZE = 10

def get_random_sequences():
    sequences = []
    for j in range(BATCH_SIZE):
        random_numbers = np.random.randint(3, 10, size=8)
        sequences.append(random_numbers)
    sequences = np.asarray(sequences).T
    return(sequences)

def next_feed():
    batch = get_random_sequences()

    encoder_inputs_ = batch
    eos = np.ones(BATCH_SIZE)
    decoder_targets_ = np.hstack((batch.T, np.atleast_2d(eos).T)).T
    decoder_inputs_ = np.hstack((np.atleast_2d(eos).T, batch.T)).T

    #print(encoder_inputs_)
    #print(decoder_inputs_)

    return {
        encoder_inputs: encoder_inputs_,
        decoder_inputs: decoder_inputs_,
        decoder_targets: decoder_targets_,
    }

### ""MAIN""

# Placeholders
encoder_inputs = tf.placeholder(shape=(LENGTH_MAX, BATCH_SIZE), dtype=tf.int32, name='encoder_inputs')
decoder_targets = tf.placeholder(shape=(LENGTH_MAX + 1, BATCH_SIZE), dtype=tf.int32, name='decoder_targets')
decoder_inputs = tf.placeholder(shape=(LENGTH_MAX + 1, BATCH_SIZE), dtype=tf.int32, name='decoder_inputs')

# Don't think I should need this for regression problems
embeddings = tf.Variable(tf.random_uniform([VOCAB_SIZE, input_embedding_size], -1.0, 1.0), dtype=tf.float32)
encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)
decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)

# Encoder RNN
encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)
encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_inputs_embedded, # Throws 'ValueError: Shape (8, 10) must have rank at least 3' if encoder_inputs is used
    dtype=tf.float32, time_major=True,
)

# Decoder RNN
decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)
decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(
    decoder_cell, decoder_inputs_embedded, 
    initial_state=encoder_final_state,
    dtype=tf.float32, time_major=True, scope=""plain_decoder"",
)
decoder_logits = tf.contrib.layers.linear(decoder_outputs, VOCAB_SIZE)
decoder_prediction = tf.argmax(decoder_logits, 2)

# Loss function
loss = tf.reduce_mean(tf.squared_difference(decoder_logits, tf.one_hot(decoder_targets, depth=VOCAB_SIZE, dtype=tf.float32)))
train_op = tf.train.AdamOptimizer().minimize(loss)


sess.run(tf.global_variables_initializer())

max_batches = 5000
batches_in_epoch = 500

print('Starting train')
try:
    for batch in range(max_batches):
        feed = next_feed()
        _, l = sess.run([train_op, loss], feed)

        if batch == 0 or batch % batches_in_epoch == 0:
            print('batch {}'.format(batch))
            print('  minibatch loss: {}'.format(sess.run(loss, feed)))
            predict_ = sess.run(decoder_prediction, feed)
            for i, (inp, pred) in enumerate(zip(feed[encoder_inputs].T, predict_.T)):
                print('  sample {}:'.format(i + 1))
                print('    input     &gt; {}'.format(inp))
                print('    predicted &gt; {}'.format(pred))
                if i &gt;= 2:
                    break
            print()
except KeyboardInterrupt:
    print('training interrupted')
</code></pre>

<p>I have read similar questions here on stackoverflow but find my self still puzzled as to how to solve this.</p>

<p>EDIT:
I think I should clarify that the code above works well, however the real desired output should mimic a noisy signal (text to speech for example) which is why I think I need continuous output values instead of words or letters.</p>
",1,Documentation Replication on Other Examples
74,44936825,use variational_recurrent in tf.contrib.rnn.DropoutWrapper,"<p>In the api of <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"" rel=""nofollow noreferrer"">tf.contrib.rnn.DropoutWrapper</a>, I am trying to set <code>variational_recurrent=True</code>, in which case, input_size is mandatory. As explained, <code>input_size</code> is <code>TensorShape</code> objects containing the <strong>depth(s)</strong> of the input tensors. </p>

<p><strong>depth(s)</strong> is confusing, what is it please? Is it just the shape of the tensor as we can get by <code>tf.shape()</code>? Or the number of channels for the special case of images? But my input tensor is not an image.</p>

<p>And I don't understand why <code>dtype</code> is demanded when <code>variational_recurrent=True</code>.</p>

<p>Thanks!</p>
",1,Documentation Ambiguity
75,44939540,How to get tensorflow to do a convolution on a 2 x 2 matrix with a 1 x 2 kernel?,"<p>I have the following matrix:</p>

<p><img src=""https://latex.codecogs.com/gif.latex?%5Cbegin%7Bbmatrix%7D&space;0&space;&amp;&space;1%5C%5C&space;2&space;&amp;&space;3&space;%5Cend%7Bbmatrix%7D"" title=""\begin{bmatrix} 0 &amp; 1\\ 2 &amp; 3 \end{bmatrix}"" /></p>

<p>and the following kernel:</p>

<p><img src=""https://latex.codecogs.com/gif.latex?%5Cbegin%7Bbmatrix%7D&space;1&space;&amp;&space;2&space;%5Cend%7Bbmatrix%7D"" title=""\begin{bmatrix} 1 &amp; 2 \end{bmatrix}"" /></p>

<p>If I do a convolution with no padding and slide by 1 row, I should get the following answer:</p>

<p><img src=""https://latex.codecogs.com/gif.latex?%5Cbegin%7Bbmatrix%7D&space;2&space;%5C%5C&space;8&space;%5Cend%7Bbmatrix%7D"" title=""\begin{bmatrix} 2 \\ 8 \end{bmatrix}"" /></p>

<p>Because:</p>

<p><img src=""https://latex.codecogs.com/gif.latex?2&space;=&space;(0%5Ctimes1)&space;&plus;&space;(1%5Ctimes&space;2)"" title=""2 = (0\times1) + (1\times 2)"" /></p>

<p><img src=""https://latex.codecogs.com/gif.latex?8&space;=&space;(2%5Ctimes&space;1)&space;&plus;&space;(3&space;%5Ctimes&space;2)"" title=""8 = (2\times 1) + (3 \times 2)"" /></p>

<p>Based the documentation of  <code>tf.nn.conv2d</code>, I thought this code expresses what I just described above:</p>

<pre><code>import tensorflow as tf

input_batch = tf.constant([
    [
        [[.0], [1.0]],
        [[2.], [3.]]
    ]
])

kernel = tf.constant([
    [
        [[1.0, 2.0]]
    ]
])

conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 1, 1, 1], padding='VALID')
sess = tf.Session()

print(sess.run(conv2d))
</code></pre>

<p>But it produces this output:</p>

<pre><code>[[[[ 0.  0.]
   [ 1.  2.]]

  [[ 2.  4.]
   [ 3.  6.]]]]
</code></pre>

<p>And I have no clue how that is computed. I've tried experimenting with different values for the strides padding parameter but still am not able to produce the result I expected.</p>
",1,Documentation Ambiguity
76,44946189,TypeError: __init__() got an unexpected keyword argument 'shape',"<p>I am new to Tensorflow and I met an error while trying to run some sample codes.</p>

<pre><code>import tensorflow as tf

g1 = tf.Graph()
with g1.as_default():
    v = tf.get_variable(""v"", initializer=tf.zeros_initializer(shape=[1]))
</code></pre>

<p>Running the code above gives the error:
TypeError: __init__() got an unexpected keyword argument 'shape'.</p>

<p>The comment below says that tf.zeros_initializer does not accept 'shape' argument according to the documentation. I tried</p>

<pre><code>v = tf.get_variable(""v"", initializer=tf.zeros_initializer())
</code></pre>

<p>and it says ValueError: Shape of a new variable (v) must be fully defined, but instead was .</p>

<p>So, what kind of argument/expression should I use to define the shape without causing a type error?</p>

<p>I cannot find how to solve it online. Please help. Thank you</p>
",1,Documentation Replication on Other Examples
77,44963306,Cannot printout concatenated tensor by tf.concat() (tensorflow 1.2.1 - gpu / py36),"<p>Learning <strong><a href=""https://www.tensorflow.org/api_docs/python/"" rel=""nofollow noreferrer"">Tensorflow</a></strong> (Python bindings) since the last month. I've been reading the docs on <code>tf.concat()</code>, but cannot resolve the problem as shown below, so I'm asking for your help!</p>

<p>What I want to do is to see the contents of the concatenated tensor.
I tried <code>Tensor.eval()</code>.</p>

<pre><code>import tensorflow as tf 
import numpy as np 

a=np.zeros([3,3])
a_trail=np.ones([3,3])

with tf.Session() as sess:
    concatenated=tf.concat([a, a_trail], axis=0) 
    print(concatenated)
    print(type(concatenated)) 
    concatenated.eval() 
    sess.run(concatenated) 
    sess.run(tf.constant(concatenated)) 
</code></pre>

<p><strong>Output:</strong>   </p>

<pre><code>Tensor(""concat_2:0"", shape=(6, 3), dtype=float64)
&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;
(nothing prints)
(nothing shows up either meh =/)
Error: List of Tensors when single Tensor expected    
</code></pre>

<p><code>tf.concat()</code> supposed to return <code>Tensor</code> and looks like it does. But why aren't <code>T.eval()</code> and <code>sess.run()</code> not working?</p>
",1,Documentation Replication on Other Examples
78,45030619,Detecting out-of-bounds slicing with tf.slice like in numpy,"<p>In tensorflow, I'm trying to use tf.slice, but <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/array_ops/slicing_and_joining"" rel=""nofollow noreferrer"">as its documentation states</a>, it requires the slice to fit in the input array. For instance, if you try to slice the first 5 positions of the tensor [1,2,3,4] it will crash. I want to have the same functionality we get with python lists or numpy arrays where slicing gets you the intersection of the original array and the slice you asked for. For instance if you ask for positions 2 to 6 of [1,2,3,4] you'll get [2,3,4].</p>

<p>How can I do that in tensorflow?</p>

<p>Thanks!</p>
",1,Documentation Replication on Other Examples
79,45077445,How to use method recover_last_checkpoints of tf.train.Saver()?,"<p>The documentation writes that a list of checkpoint paths should be passed to it, but how to get the list? By hard coding? No, it's a silly practice. By parsing the protocol buffer file (a file named as <code>checkpoint</code> in your model directory)? But tensorflow does not implement a parser, does it? So do I have to implement one by myself? <strong>Do you have a good practice to get the checkpoint paths list?</strong></p>

<p>I raise this question because these days I am troubled by one thing. As you know, a days-long training may crash for some reason, and I have to recover it from the latest checkpoint. Recovering training is easy, since I just need to write the following code:</p>

<pre><code>restorer = tf.train.Saver()
restorer.restore(sess, latest_checkpoint)
</code></pre>

<p>I can hard code <code>latest_checkpoint</code>, or somewhat wiser, use <code>tf.train.latest_checkpoint()</code>.</p>

<p>However, a problem arises after I recover the training. Those old checkpoints files that are created before crash are left there. The Saver only manages the checkpoint files created in one run. I hope it could also manage the previously created checkpoints files so they would be automatically deleted, and I don't have to manually delete them every time. I think such repeating work is really silly.</p>

<p>Then I find the <code>recover_last_checkpoints</code> method in class <code>tf.train.Saver()</code>, which allows Saver to manage old checkpoints. But it's not handy to use. So is there any good solution?</p>
",1,Lack of Alternative Solutions/Documentation
80,45090843,Does sequence_length help performance of dynamic_rnn?,"<p>In <a href=""https://github.com/tensorflow/nmt"" rel=""nofollow noreferrer"">Google's recent nmt tutorial</a>, they say this: </p>

<blockquote>
  <p>Note that sentences have different lengths to avoid wasting computation, we tell dynamic_rnn the exact source sentence lengths through source_seqence_length</p>
</blockquote>

<p>with this code: 
<code>encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_emb_inp,
    sequence_length=source_seqence_length, time_major=True)
</code></p>

<p>However, I was reading <a href=""https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn.py"" rel=""nofollow noreferrer"">dynamic_rnn's documentation</a> and it says: </p>

<blockquote>
  <p>The parameter <code>sequence_length</code> is optional and is used to copy-through state
    and zero-out outputs when past a batch element's sequence length. So it's more
    for correctness than performance.</p>
</blockquote>

<p>I'm just wondering if sequence_length really helps performance of dynamic_rnn, e.g. they do some kind of dynamic bucketing? If they do, is there any place where I can read more about it? Thanks a lot.</p>
",1,Requesting (Additional) Documentation/Examples
81,45151015,How does tf.gradients behave when passed a list of `ys` tensors?,"<p>How exactly does <code>tf.gradients</code> behave when passed a list of tensors as its first argument? Take this very small example:</p>

<pre><code>a = tf.constant(5)
b = tf.constant(7)
c = a + 2 * b
</code></pre>

<p>If I compute the gradients of a single tensor, <code>c</code>, with respect to <code>[a,b]</code>, I get the expected answer:</p>

<pre><code>grads = tf.gradients(c, [a, b])
with tf.Session() as sess:
    sess.run(grads) # returns (1, 2)
</code></pre>

<p>According to the Tensorflow documentation, if you pass in a <em>list</em> of tensors as your first argument <code>ys</code>, <code>tf.gradients</code> will sum the gradients over that list, returning <code>sum_over_ys(dy/dx)</code> for each <code>x</code> in your second argument. So I would expect:</p>

<pre><code>tf.gradients([a, b, c], [a, b])
</code></pre>

<p>to behave the same way as:</p>

<pre><code>tf.gradients(a + b + c, [a, b])
</code></pre>

<p>Am I reading the docs wrong? When I test this code, I get the expected result <code>[2, 3]</code> for the second expression (explicitly summing <code>a + b + c</code>), but <code>[2, 1]</code> for the first. Where is this <code>[2, 1]</code> coming from?</p>
",1,Documentation Ambiguity
82,45203872,How tf.train.shuffle_batch works?,"<p>Does it do one shuffling in one epoch, or else?</p>

<p>What is the difference of tf.train.shuffle_batch and tf.train.batch?</p>

<p>Could someone explain it? Thanks.</p>
",1,Requesting (Additional) Documentation/Examples
83,45217998,Tensorflow: Weighted sparse softmax with cross entropy loss,"<p>I am doing image segmentation using fully convolutional neural networks (link to the paper): <a href=""https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf"" rel=""nofollow noreferrer"">https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf</a></p>

<p>This can be considered as pixel classification (in the end each pixel is getting a label)</p>

<p>I am using the tf.nn.sparse_softmax_cross_entropy_with_logits loss function.</p>

<pre><code>loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,
                                                                      labels=tf.squeeze(annotation, squeeze_dims=[3]),
                                                                      name=""entropy""))) 
</code></pre>

<p>Everything is going well. However, I saw that one class occurs in the vast majority of pixels (95%+), call this class 0. Lets say that we have another three classes, 1, 2 and 3.</p>

<p>What would be the easiest way to put weights to the classes? Essentially, I would like to have very low weight for class 0 (like 0.1) compared to the other three classes who should have normal weight 1.</p>

<p>I know that this function exists: <a href=""https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy</a></p>

<p>It just looks to me that it does something totally different and I do not understand how the weights should have the same rank as labels. I mean, in my case, weights should be something like Tensor([0.1, 1, 1, 1]) so shape (4,) and rank 1, while labels have shape (batch_size, width, height) and so rank 3. Am I missing something?</p>

<p>The equivalent on PyTorch would be </p>

<pre><code>torch.nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100)
</code></pre>

<p>where weight is a torch tensor [0.1, 1, 1, 1]</p>

<p>Thanks!</p>
",1,Documentation Ambiguity
84,45247909,Tensorflow - How to get the gradients of the output w.r.t the model parameters,"<p>I would like to know if it is possible to compute the gradients of the output of a model with respect to the model parameters.  In other words I would like to compute <code>dy / d theta</code>.</p>

<p>Here is a short example of what I mean:</p>

<pre><code>import keras
import tensorflow as tf

# Dummy input
test = np.random.rand(1, 32, 32, 1)

x = tf.placeholder(tf.float32, shape=(None, 32, 32, 1))

model = keras.layers.Conv2D(16, 5, padding = 'same', activation='elu') (x)
model = keras.layers.Flatten() (model)
model = keras.layers.Dense(128, activation='relu') (model)
predictions = keras.layers.Dense(1) (model)

with tf.Session() as sess:
    init_op = tf.global_variables_initializer()
    sess.run(init_op)
    y = sess.run(predictions, feed_dict={x: test})

    # Get gradients of y w.r.t model parameters.
    gradients = sess.run(tf.gradients(y, model_parameters))
</code></pre>

<p>I have looked at the documentation of <code>tf.gradients()</code> and it states</p>

<blockquote>
  <p><code>ys</code> and <code>xs</code> are each a <code>Tensor</code> or a list of tensors. <code>grad_ys</code> is a list of <code>Tensor</code>, holding the gradients received by the <code>ys</code>. The list must be the same length as <code>ys</code>.</p>
</blockquote>

<p>So I do understand that both args need to be a tensor. However, when I try </p>

<p><code>model_parameters = tf.trainable_variables()</code></p>

<p><code>model_parameters</code> is a list of elements of type <code>tensorflow.python.ops.variables.Variable</code></p>

<p>Is there a way to get the parameters of the model as a tensor to use for differentiation?</p>
",1,Documentation Replicability
85,45290607,Tensorflow tf_strided_slice elaboration,"<p>I'm trying to understand how tf.strided_slice works. In order to do this, I've written the following code:</p>

<pre><code>import numpy as np
import tensorflow as tf

# parameters
record_size = 841

# create a random vector of 1682 integers in range [0.255]
content = np.random.randint(255,size=[1682])

depth_major = tf.reshape(
  tf.strided_slice(content, [0],
                   [record_size]),
                   [1, 29, 29])

depth_major1 = tf.reshape(
  tf.strided_slice(content, [record_size+1],
                   [2*record_size]),
                   [1, 29, 29])

# Initializing the variables
init = tf.global_variables_initializer()

with tf.Session as sess:
  sess.run(depth_major)
  print(""depth_major"", depth_major.shape)
</code></pre>

<p>When I execute the above example, I get the following error:</p>

<pre><code>ValueError: Cannot reshape a tensor with 840 elements to shape [1,29,29] (841 elements) for 'Reshape_1' (op: 'Reshape') with input shapes: [840], [3] and with input tensors computed as partial shapes: input[1] = [1,29,29].
</code></pre>

<p>I simply cannot understand why the number of elements is 840 since I start at [0] and end at [record_size]? </p>
",1,Documentation Replicability
86,45401311,What are channels in tf.nn.conv2D?,"<p>I've looked through some <a href=""https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow"">great explanations</a> on what different arguments of tf.nn.conv2D represent, but I still can't understand what exactly in_channels and out_channels represent.</p>

<p>Could someone please clarify this for me?</p>
",1,Documentation Replicability
87,45428557,Tensorflow: How to make return value of tf.unique same size as input,"<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/unique"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/unique</a>, <code>tf.unique(x)</code> returns a tuple <code>(y, idx)</code>,  The <strong>shape of y is (?, )</strong> is not known during build time. Is there anyway I can pad <code>y</code> to match the input size <code>x</code>?.</p>

<p>For example, </p>

<pre><code># tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
y, idx = unique(x)
y ==&gt; [1, 2, 4, 7, 8]
idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
</code></pre>

<p>I wanna make y = [1, 2, 4, 7, 8, 0, 0, 0, 0]</p>
",1,Inadequate Examples
88,45553038,How to compile custom ops in tensorflow without having to dynamically import them in python?,"<p>I checked through tensorflow documentation and they seem to only give information about compiling a custom op through a bazel rule:</p>

<pre><code>load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")

tf_custom_op_library(
    name = ""zero_out.so"",
    srcs = [""zero_out.cc""],
)
</code></pre>

<p>Once bazel builds it, you get a zero_out.so file which you can import into python like below:</p>

<pre><code>import tensorflow as tf
zero_out_module = tf.load_op_library('./zero_out.so')
</code></pre>

<p>Is there anyway you can link custom_ops during the bazel build of tensorflow so that you don't need to manually import custom ops through tf.load_op_library?</p>
",1,Documentation Completeness
89,45553280,TensorArray Initialization from another tensor,"<p>What is the right way to initialize a tensorarray from another tensor in tensorflow. </p>

<p>Suppose I have a tensor</p>

<pre><code>T1 

TensorArr = tf.TensorArray(tf.int32, 1, dynamic_size=True)
</code></pre>

<p>What is way to say that this tensorarray depends on T1?  Looking at the <a href=""https://www.tensorflow.org/api_docs/python/tf/TensorArray"" rel=""nofollow noreferrer"">documentation</a> I cant figure out how to initialize this. </p>

<p>Correct me if my understanding is wrong, T1 is a nested tensor and I want to loop over a dimension using tf.while_loop and hence I want to initialize the TensorArray with it. </p>
",1,Documentation Replication on Other Examples
90,45595419,Is it possible to have multiple conditions defined in tf.while_loop,"<p>Is it possible to define to multiple conditions for termination of a tf.while_loop in tensorflow? For example depending on the two tensor values achieving two specific values. eg. <code>i==2</code> and <code>j==3</code> ?</p>

<p>Also can I have several blocks of code in the body? In all the examples in the documentation, it seems that the body is more like a single statement returning a value or a tuple. I want to execute a set of several ""<strong>sequential</strong>"" statements in the body.</p>
",1,Inadequate Examples
91,45634450,What are the advantages of using tf.train.SequenceExample over tf.train.Example for variable length features?,"<p>Recently I read <a href=""http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features"" rel=""noreferrer"">this</a> guide on undocumented featuers in TensorFlow, as I needed to pass variable length sequences as input. However, I found the protocol for <code>tf.train.SequenceExample</code> relatively confusing (especially due to lack of documentation), and managed to build an input pipe using <code>tf.train.Example</code> just fine instead.</p>

<p>Are there any advantages to using <code>tf.train.SequenceExample</code>? Using the standard example protocol when there is a dedicated one for variable length sequences seems like a cheat, but does it bear any consequence?</p>
",1,Documentation Replicability
92,45678931,tensorflow input pipeline returns multiple values,"<p>I'm trying to make an input pipeline in tensorflow for image classification, therefore I want to make batches of images and corresponding labels. The Tensorflow document suggests that we can use tf.train.batch to make batches of inputs:</p>

<pre><code>train_batch, train_label_batch = tf.train.batch(
[train_image, train_image_label],
batch_size=batch_size,
num_threads=1,
capacity=10*batch_size,
enqueue_many=False,
shapes=[[224,224,3], [len(labels),]],
allow_smaller_final_batch=True
)
</code></pre>

<p>However, I'm thinking would it be a problem if I feed in the graph like this:</p>

<pre><code>cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_label_batch, logits=Model(train_batch)))
</code></pre>

<p>The question is does the operation in the cost function dequeues images and their corresponding labels, or it returns them separately? Therefore causing the training with wrong images and labels.</p>
",1,Documentation Replicability
93,45705070,how to load and use a saved model on tensorflow?,"<p>I have found 2 ways to save a model in Tensorflow: <code>tf.train.Saver()</code> and <code>SavedModelBuilder</code>. However, <strong>I can't find documentation on using the model</strong> after it being loaded  the second way.</p>

<p>Note: I want to use <code>SavedModelBuilder</code> way because I train the model in Python and will use it at serving time in another language (Go), and it seems that <code>SavedModelBuilder</code> is the only way in that case.</p>

<p>This works great with <code>tf.train.Saver()</code> (first way):</p>

<pre><code>model = tf.add(W * x, b, name=""finalnode"")

# save
saver = tf.train.Saver()
saver.save(sess, ""/tmp/model"")

# load
saver.restore(sess, ""/tmp/model"")

# IMPORTANT PART: REALLY USING THE MODEL AFTER LOADING IT
# I CAN'T FIND AN EQUIVALENT OF THIS PART IN THE OTHER WAY.

model = graph.get_tensor_by_name(""finalnode:0"")
sess.run(model, {x: [5, 6, 7]})
</code></pre>

<p><code>tf.saved_model.builder.SavedModelBuilder()</code> is defined in the <a href=""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/saved_model/"" rel=""noreferrer"">Readme</a>  but after loading the model with <code>tf.saved_model.loader.load(sess, [], export_dir)</code>), I can't find documentation on getting back at the nodes (see <code>""finalnode""</code> in the code above)</p>
",1,Lack of Alternative Solutions/Documentation
94,45784815,How best to implement a matrix mask operation in tensorflow?,"<p>I had a case where I needed to fill some holes (missing data) in an image processing application in tensorflow. The 'holes' are easy to locate as they are zeros and the good data is not zeros. I wanted to fill the holes with random data. This is quite easy to do using python numpy but doing it in tensorflow requires some work. I came up with a solution and wanted to see if there is a better or more efficient way to do the same thing. I understand that tensorflow does not yet support the more advanced numpy type indexing yet but there is a function tf.gather_nd() that seems promising for this. However, I could not tell from the documentation how to us it for what I wanted to do. I would appreciate answers that improve on what I did or especially if someone can show me how to do it using tf.gather_nd(). Also, tf.boolean_mask() does not work for what I am  trying to do because it does not allow you to use the output as an index.  In python what I am trying to do:</p>

<pre><code>a = np.ones((2,2))
a[0,0]=a[0,1] = 0
mask = a == 0
a[mask] = np.random.random_sample(a.shape)[mask]
print('new a = ', a)
</code></pre>

<p>What I ended up doing in Tensorflow to achieve same thing (skipping filling the array steps)</p>

<pre><code>zeros = tf.zeros(tf.shape(a))  
mask = tf.greater(a,zeros)
mask_n = tf.equal(a,zeros)
mask = tf.cast(mask,tf.float32)
mask_n = tf.cast(mask_n,tf.float32
r = tf.random_uniform(tf.shape(a),minval = 0.0,maxval=1.0,dtype=tf.float32)
r_add = tf.multiply(mask_n,r)
targets = tf.add(tf.multiply(mask,a),r_add)
</code></pre>
",1,Inadequate Examples
95,45879776,TensorFlow how to make results reproducible for `tf.nn.sampled_softmax_loss`,"<p>I would like to get reproducible results for my tensorflow runs. The way I'm trying to make this happen is to set up the numpy and tensorflow seeds:</p>

<pre><code>import numpy as np
rnd_seed = 1
np.random.seed(rnd_seed)

import tensorflow as tf
tf.set_random_seed(rnd_seed)
</code></pre>

<p>As well as make sure that the weights of the neural network, that I initialized with <code>tf.truncated_normal</code> also use that seed: <code>tf.truncated_normal(..., seed=rnd_seed)</code></p>

<p>For reasons that are beyond the scope of this question, I'm using the sampled softmax loss function, <code>tf.nn.sampled_softmax_loss</code>, and unfortunately, I'm not able to control the stochasticity of this function with a random seed.</p>

<p>By a look at the TensorFlow documentation of this function (<a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss</a>), I can see that parameter <code>sampled_values</code> should be the only parameter that affects randomization, but I'm not able to understand how to actually use a seed.</p>

<p>[EDITED]
This is (part of) my script</p>

<pre><code>import numpy as np
# set a seed so that the results are consistent
rnd_seed = 1
np.random.seed(rnd_seed)

import tensorflow as tf
tf.set_random_seed(rnd_seed)

embeddings_ini = np.random.uniform(low=-1, high=1, size=(self.vocabulary_size, self.embedding_size))

with graph.as_default(), tf.device('/cpu:0'):

    train_dataset = tf.placeholder(tf.int32, shape=[None, None])
    train_labels = tf.placeholder(tf.int32, shape=[None, 1])
    valid_dataset = tf.constant(self.valid_examples, dtype=tf.int32)

    # Variables.
    initial_embeddings = tf.placeholder(tf.float32, shape=(self.vocabulary_size, self.embedding_size))
    embeddings = tf.Variable(initial_embeddings)

    softmax_weights = tf.Variable(
        tf.truncated_normal([self.vocabulary_size, self.embedding_size],
                            stddev=1.0 / math.sqrt(self.embedding_size), seed=rnd_seed))
    softmax_biases = tf.Variable(tf.zeros([self.vocabulary_size]))

    # Model.
    # Look up embeddings for inputs.
    if self.model == ""skipgrams"":
        # Skipgram model
        embed = tf.nn.embedding_lookup(embeddings, train_dataset)
    elif self.model == ""cbow"":
        # CBOW Model
        embeds = tf.nn.embedding_lookup(embeddings, train_dataset)
        embed = tf.reduce_mean(embeds, 1, keep_dims=False)

    # Compute the softmax loss, using a sample of the negative labels each time.
    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights,
                                                     biases=softmax_biases,
                                                     inputs=embed,
                                                     labels=train_labels,
                                                     num_sampled=self.num_sampled,
                                                     num_classes=self.vocabulary_size))
</code></pre>
",1,Documentation Replicability
96,45900233,tf.slice and tf.strided_slice,"<p>trying to comprehend tensorflow strided_slice and slice</p>

<pre><code>x = tf.constant(np.array(   [[[111, 112, 113], [121, 122, 123]],
                            [[211, 212, 213], [221, 222, 223]],
                            [[311, 312, 313], [321, 322, 323]]]))
with tf.Session() as sess:
    print(""tf.shape ------------------"")
    print(sess.run(tf.shape(x)))
    print(""tf.slice ------------------------"")
    print(sess.run((tf.slice(x, [1, 0, 0], [2, 1, 3]) )))
    print(""tf.strided_slice ------------------------"")
    print(sess.run(tf.strided_slice(x, [1, 0, 0], [2, 1, 3], [1, 1, 1])))
    print(sess.run(tf.strided_slice(x, [1, -1, 0], [2, -3, 3], [1, -1, 1])))
    print(sess.run(x[1,-1,0]))
    print(sess.run(x[2,-3,3]))
</code></pre>

<p>output</p>

<pre><code>tf.shape ------------------
[3 2 3]
tf.slice ------------------------
[[[211 212 213]]

 [[311 312 313]]]
tf.strided_slice ------------------------
[[[211 212 213]]]
[[[221 222 223]
  [211 212 213]]]
221
ValueError: slice index -1 of dimension 1 out of bounds. for 'strided_slice_8' (op: 'StridedSlice') with input shapes: [3,2,3], [3], [3], [3] and with computed input tensors: input[1] = &lt;2 -3 3&gt;, input[2] = &lt;3 -2 4&gt;, input[3] = &lt;1 1 1&gt;.
</code></pre>

<p>for tf.slice i understand we have to mentions slice sizes in each dimension and hence out of range values makes sense. but in strided slice the end is a tensor index in the tensor itself, how come  out of size value is valid. </p>

<p>Example is taken from
<a href=""https://www.tensorflow.org/api_docs/python/tf/strided_slice"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/strided_slice</a></p>

<p>Trying to implement folding layer part from paper <a href=""https://arxiv.org/abs/1404.2188"" rel=""nofollow noreferrer"">A Convolutional Neural Network for Modelling Sentences</a></p>

<blockquote>
  <p>In the formulation of the network so far, feature detectors applied to
  an individual row of the sentence matrix s can have many orders and
  create complex dependencies across the same rows in multiple feature
  maps. Feature detectors in different rows, however, are independent of
  each other until the top fully connected layer. Full dependence
  between different rows could be achieved by making M in Eq. 5 a full
  matrix instead of a sparse matrix of diagonals. Here we explore a
  simpler method called folding that does not introduce any additional
  parameters. After a convolutional layer and before (dynamic) k-max
  pooling, <strong>one just sums every two rows in a feature map component-wise</strong>.
  For a map of d rows, folding returns a map of d/2 rows, thus halving
  the size of the representation. With a folding layer, a feature
  detector of the i-th order depends now on two rows of feature values
  in the lower maps of order i − 1. This ends the description of the
  DCNN.</p>
</blockquote>
",1,Documentation Replicability
97,45955241,How do I create padded batches in Tensorflow for tf.train.SequenceExample data using the DataSet API?,"<p>For training an <strong>LSTM model</strong> in <strong>Tensorflow</strong>, I have structured my data into a <strong>tf.train.SequenceExample</strong> format and stored it into a <strong>TFRecord file</strong>. I would now like to use the new DataSet API to <strong>generate padded batches for training</strong>. In <a href=""https://www.tensorflow.org/programmers_guide/datasets"" rel=""noreferrer"">the documentation</a> there is an example for using padded_batch, but for my data I can't figure out what the value of <em>padded_shapes</em> should be.</p>

<p>For reading the TFrecord file into the batches I have written the following Python code:</p>

<pre><code>import math
import tensorflow as tf
import numpy as np
import struct
import sys
import array

if(len(sys.argv) != 2):
  print ""Usage: createbatches.py [RFRecord file]""
  sys.exit(0)


vectorSize = 40
inFile = sys.argv[1]

def parse_function_dataset(example_proto):
  sequence_features = {
      'inputs': tf.FixedLenSequenceFeature(shape=[vectorSize],
                                           dtype=tf.float32),
      'labels': tf.FixedLenSequenceFeature(shape=[],
                                           dtype=tf.int64)}

  _, sequence = tf.parse_single_sequence_example(example_proto, sequence_features=sequence_features)

  length = tf.shape(sequence['inputs'])[0]
  return sequence['inputs'], sequence['labels']

sess = tf.InteractiveSession()

filenames = tf.placeholder(tf.string, shape=[None])
dataset = tf.contrib.data.TFRecordDataset(filenames)
dataset = dataset.map(parse_function_dataset)
# dataset = dataset.batch(1)
dataset = dataset.padded_batch(4, padded_shapes=[None])
iterator = dataset.make_initializable_iterator()

batch = iterator.get_next()

# Initialize `iterator` with training data.
training_filenames = [inFile]
sess.run(iterator.initializer, feed_dict={filenames: training_filenames})

print(sess.run(batch))
</code></pre>

<p>The code works well if I use <code>dataset = dataset.batch(1)</code> (no padding needed in that case), but when I use the <code>padded_batch</code> variant, I get the following error:</p>

<blockquote>
  <p>TypeError: If shallow structure is a sequence, input must also be a
  sequence. Input has type: .</p>
</blockquote>

<p>Can you help me figuring out what I should pass for the <em>padded_shapes</em> parameter?</p>

<p>(I know there is lots of example code using threading and queues for this, but I'd rather use the new DataSet API for this project)</p>
",1,Documentation Replication on Other Examples
98,46046145,TensorFlow: How to get sub array for each row in tensor,"<p>I have following code:</p>

<pre><code>import numpy as np
import tensorflow as tf

series = tf.placeholder(tf.float32, shape=[None, 5])
series_length = tf.placeholder(tf.int32, shape=[None])
useful_series = tf.magic_slice_function(series, series_length)

with tf.Session() as sess:
    input_x = np.array([[1, 2, 3, 0, 0],
                        [2, 3, 0, 0, 0],
                        [1, 0, 0, 0, 0]])
    input_y = np.array([[3], [2], [1]])
    print(sess.run(useful_series, feed_dict={series: input_x, series_length: input_y}))
</code></pre>

<p>Expected output as following</p>

<p>[[1,2,3],[2,3],[1]]</p>

<p>I have tried several functions, etc tf.gather, tf.slice. All of them do not work.
What is the <strong>magic_slice_function</strong>?</p>
",1,Documentation Replicability
99,46062649,tensorflow slim concurrent train and evaluation loops; single device,"<p>I am interested in using the tensorflow slim library (tf.contrib.slim) to do evaluation of a model performance on a(n) (entire) test set periodically during training. The documentation is pretty clear that slim.evaluation.evaluation_loop is the way to go, and it looks promising. The issue is that I don't have a second gpu to spare, this model parameters take up an entire gpu's worth of memory, and I would like to do concurrent evaluation.</p>

<p>For example, if I had 2 GPUs, I could run a python script that terminated with ""slim.learning.train()"" on the first gpu, and another that terminated with ""slim.evaluation.evaluation_loop()"" on the second gpu.</p>

<p>Is there an approach that can manage 1 gpu's resources for both tasks? tf.train.Supervisor comes to mind, but I don't honestly know.</p>
",1,Documentation Replication on Other Examples
100,46139202,Tensorflow: TypeError with numpy_input_fn,"<p>I am coding a Convolutional Neural Network to classify images in TensorFlow but there is a problem:</p>

<p>When I try to feed my NumPy array of flattened  images (3 channels with RGB values from 0 to 255) to a tf.estimator.inputs.numpy_input_fn I get the following error:</p>

<pre><code>  TypeError: Failed to convert object of type &lt;class 'dict'&gt; to Tensor. 
  Contents: {'x': &lt;tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(8, 
  196608) dtype=uint8&gt;}. Consider casting elements to a supported type.
</code></pre>

<p>My numpy_imput_fn looks like this:</p>

<pre><code>train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'x': train_x},
    y=train_y,
    batch_size=8,
    num_epochs=None,
    shuffle=True)
</code></pre>

<p>In the documentation for the function it is said that x should be a dict of NumPy array:</p>

<blockquote>
  <p>x: dict of numpy array object.</p>
</blockquote>
",1,Documentation Replicability
101,46370159,Outputting batch/epoch training loss during `tf.train.MonitoredTrainingSession`,"<p>I would like to output my loss with <code>MonitoredTrainingSession</code> every epoch or batch.
Ideally I would love to get a flag that the epoch is ended or be able to provide a callback like in keras. I see that I can also do it by manually counting steps, but I want to use the tf functionality, which seems still poorly documented.</p>

<p>From what I could find in their documentation, one can use <code>tf.train.LoggingTensorHook</code> to print the tensors every <code>n</code> steps. </p>

<p>The problem however is that it prints with frequency different from what I request. When I run following with <code>every_n_iter=4</code> I get output every 2nd iteration:</p>

<pre><code>tf.reset_default_graph()
with g.as_default():
    loghook = tf.train.LoggingTensorHook([tf.reduce_mean(loss, name='m_loss')],
                                         every_n_iter=4,
                                         formatter=lambda x: ""LOSS\t%.4f"" % [tt for kk,tt in x.items() if kk.name.startswith('m_loss')][-1]
                                        )
    optimizer = get_optimizer(lr=lr, opt_name = opt_name)
    training_op = optimizer.minimize(loss)
    init_op = tf.global_variables_initializer()
    with tf.Session(graph=g) as sess:    
        sess.run(init_op)
    with tf.train.MonitoredTrainingSession(log_step_count_steps=1, hooks=[loghook]) as sess:
        losslist = []
        while not sess.should_stop():
            print('.')
            loss_ = sess.run(loss, feed_dict={K.learning_phase():1})
            sess.run(training_op)
            losslist.append(np.mean(loss_))
</code></pre>

<p>I am getting output like:</p>

<pre><code>.
INFO:tensorflow:LOSS    2.2416
.
.
INFO:tensorflow:LOSS    2.1547
.
.
INFO:tensorflow:LOSS    2.1186
.
.
</code></pre>

<p>etc. That is it outputs every 2nd step, not every 4th. </p>

<p>The documentation says: </p>

<pre><code>every_n_iter: `int`, print the values of `tensors` once every N local
      steps taken on the current worker.
</code></pre>

<p>I am running it on one local machine. Why one ""local step"" equals two loop python iterations? Why two and not five?</p>

<p>Looking at the Python source does not seem helping. Any Google folks aware of what it is doing?</p>
",1,Lack of Alternative Solutions/Documentation
102,46372554,When feeding a dictionary to a tensorflow function I get Why do I get TypeError: unhashable type: 'numpy.ndarray',"<p>I am working on a Tensor Flow Coursera Course and I dont understand why I am getting a type mismatch. </p>

<p>This is the function I am defining:</p>

<pre><code>def one_hot_matrix(labels, C):
    """"""
    Creates a matrix where the i-th row corresponds to the ith class number and the jth column
                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) 
                     will be 1. 

Arguments:
labels -- vector containing the labels 
C -- number of classes, the depth of the one hot dimension

Returns: 
one_hot -- one hot matrix
""""""

### START CODE HERE ###

# Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)
C = tf.constant(C, name=""C"")
#labels =tf.placeholder(labels, name=""labels"")

# Use tf.one_hot, be careful with the axis (approx. 1 line)
one_hot_matrix = tf.one_hot(indices=labels, depth=C, axis=0)

# Create the session (approx. 1 line)
sess = tf.Session()

# Run the session (approx. 1 line)
one_hot = sess.run(one_hot_matrix, feed_dict={labels:labels, C:C})

# Close the session (approx. 1 line). See method 1 above.
sess.close()

### END CODE HERE ###

return one_hot
</code></pre>

<p>And when running this: </p>

<pre><code>labels = np.array([1,2,3,0,2,1])
one_hot = one_hot_matrix(labels, C = 4)
print (""one_hot = "" + str(one_hot))
</code></pre>

<p>I get this type error:</p>

<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-113-2b9d0290645f&gt; in &lt;module&gt;()
      1 labels = np.array([1,2,3,0,2,1])
----&gt; 2 one_hot = one_hot_matrix(labels, C = 4)
      3 print (""one_hot = "" + str(one_hot))

&lt;ipython-input-112-f9f17c86d0ba&gt; in one_hot_matrix(labels, C)
     28 
     29     # Run the session (approx. 1 line)
---&gt; 30     one_hot = sess.run(one_hot_matrix, feed_dict={labels:labels, C:C})
     31 
     32     # Close the session (approx. 1 line). See method 1 above.

TypeError: unhashable type: 'numpy.ndarray'ter code here
</code></pre>

<p>I checked the Tensorflow documentation for tf.one_hot and there shouldn't be a problem with np.arrays.</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/one_hot"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/one_hot</a></p>
",1,Documentation Ambiguity
103,46381790,How does TensorFlow handle none shape?,"<p>I'm trying to implement a simple computational graph framework and test it with simple neural network, mainly by learning from TensorFlow. Now I would want to be clear how does TensorFlow handle none shape tensors.</p>

<p>In <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/multilayer_perceptron.py"" rel=""nofollow noreferrer"">this example</a>, <code>X</code> has shape <code>[None, n_input]</code>, <code>weights['h1']</code> has shape <code>[n_input, n_hidden_1]</code>, and <code>biases['b1']</code> has shape <code>[n_hidden_1]</code>. When it tries to do this: <code>layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])</code>, <code>tf.matmul(x, weights['h1'])</code> should have shape <code>[None, n_hidden_1]</code>, and how exactly does TensorFlow add it with <code>biases['b1']</code>? Based on the <a href=""https://www.tensorflow.org/api_docs/python/tf/add"" rel=""nofollow noreferrer"">documentation</a>, <code>tf.add</code> only works when the 2 operands have the same shape. If we run with a batch of size 10, <code>tf.matmul(x, weights['h1'])</code> will have shape <code>[10, n_hidden_1]</code>, and it shouldn't be able to be added with <code>biases['b1']</code>.</p>
",1,Documentation Replication on Other Examples
104,46418686,tf.nn.dynamic_rnn shape error in seq2seq,"<p>I am attempting to write my own basic seq2seq classifier. Im doing this by using <code>tf.nn.dynamic_rnn</code> and the code is shown below. However, there seems to be a problem with the shape of the tensor I'm sending to <code>tf.nn.dynamic_rnn</code>. The reason I'm doing this is because tensorflow's documentation when it comes to seq2seq is very much all over the place.</p>

<p>Running </p>

<pre><code>import numpy as np
source_batch = np.random.randint(x_letters, size=[batch_size, x_seq_length])
target_batch = np.random.randint(y_letters, size=[batch_size, y_seq_length+1])

sess.run(tf.global_variables_initializer())
loss = sess.run([loss],
            feed_dict = {inputs: source_batch, 
                         outputs: target_batch[:, :-1], 
                         targets: target_batch[:, 1:]})
</code></pre>

<p>gives me the error: <code>ValueError: Cannot feed value of shape (128, 10) for Tensor 'decoding/rnn/transpose:0', which has shape '(128, 10, 32)'</code>.</p>

<p><strong>The graph</strong> is shown below:</p>

<pre><code>import tensorflow as tf

x_seq_length = 29
y_seq_length = 10

x_letters = 60
y_letters = 13

epochs = 2
batch_size = 128
nodes = 32
embed_size = 10

####################
# Tensorflow Graph
####################
tf.reset_default_graph()
sess = tf.InteractiveSession()

inputs = tf.placeholder(tf.int32, (batch_size, x_seq_length), 'inputs')
outputs = tf.placeholder(tf.int32, (batch_size, y_seq_length), 'output')
targets = tf.placeholder(tf.int32, (batch_size, y_seq_length), 'targets')

input_embedding = tf.Variable(tf.random_uniform((x_letters, embed_size), -1, 1), name='enc_embedding')
output_embedding = tf.Variable(tf.random_uniform((y_letters, embed_size), -1, 1), name='dec_embedding')

date_input_embed = tf.nn.embedding_lookup(input_embedding, inputs)
date_output_embed = tf.nn.embedding_lookup(output_embedding, outputs)

with tf.variable_scope(""encoding"") as encoding_scope:
    lstm_enc = tf.contrib.rnn.BasicLSTMCell(nodes)
    _, last_state = tf.nn.dynamic_rnn(lstm_enc, dtype=tf.float32,inputs=date_input_embed)

with tf.variable_scope(""decoding"") as decoding_scope:
    lstm_dec = tf.contrib.rnn.BasicLSTMCell(nodes)
    outputs, _ = tf.nn.dynamic_rnn(lstm_dec, inputs=date_output_embed, initial_state=last_state)

logits = tf.contrib.layers.fully_connected(outputs, num_outputs=y_letters, activation_fn=None) 

with tf.name_scope(""optimization""):
    loss = tf.contrib.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))
    optimizer = tf.train.AdamOptimizer().minimize(loss)
</code></pre>
",1,Documentation Replicability
105,46658607,where is tf.nn.l2_loss defined?,"<p>According to this documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss</a> it says</p>

<pre><code>Defined in tensorflow/python/ops/gen_nn_ops.py.
</code></pre>

<p>But when I go to tensorflow/python/ops/gen_nn_ops.py there is no l2_loss defined.</p>

<p>I'm trying to see what would be the difference between using <code>tf.nn.l2_loss(W)</code> or just using <code>tf.reduce_sum(tf.square(W))</code>.</p>
",1,Documentation Ambiguity
106,46659101,Using `softmax_cross_entropy_with_logits()` with `seq2seq.sequence_loss()`,"<p>I have a working RNN using the default softmax loss function for <code>tf.contrib.seq2seq.sequence_loss()</code> (which I'm assuming is <code>tf.nn.softmax()</code>) but would instead like to use <code>tf.nn.softmax_cross_entropy_with_logits()</code>. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss"" rel=""nofollow noreferrer"">seq2seq.sequence_loss</a> documentation, one may use <code>softmax_loss_function=</code> to override the default loss function:</p>

<blockquote>
  <p><strong>softmax_loss_function</strong>: Function (labels, logits) -> loss-batch to be
  used instead of the standard softmax (the default if this is None).
  Note that to avoid confusion, it is required for the function to
  accept named arguments.</p>
</blockquote>

<p>Here is my code that works:</p>

<pre><code>from tensorflow.python.layers.core import Dense

# Build the graph
train_graph = tf.Graph()
# Set the graph to default to ensure that it is ready for training
with train_graph.as_default():

    # Load the model inputs    
    input_data, targets, keep_prob, lr, target_sequence_length, max_target_sequence_length, source_sequence_length \
    = get_model_inputs()

    # Create the training and inference logits
    training_decoder_output, inference_decoder_output = seq2seq_model(input_data, 
                                                                      targets, 
                                                                      lr, 
                                                                      target_sequence_length, 
                                                                      max_target_sequence_length, 
                                                                      source_sequence_length,
                                                                      len(source_letter_to_int),
                                                                      len(target_letter_to_int),
                                                                      encoding_embedding_size, 
                                                                      decoding_embedding_size, 
                                                                      rnn_size, 
                                                                      num_layers,
                                                                      keep_prob)    

    # Create tensors for the training logits and inference logits
    training_logits = tf.identity(training_decoder_output.rnn_output, 'logits')
    inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')

    # Create the weights for sequence_loss
    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')

    with tf.name_scope(""optimization""):

        # Loss function
        cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks)

        # Optimizer
        optimizer = tf.train.AdamOptimizer(lr)

        # Gradient Clipping
        gradients = optimizer.compute_gradients(cost)
        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]
        train_op = optimizer.apply_gradients(capped_gradients)

        # Add variables to collection in order to load them up when retraining a saved graph
        tf.add_to_collection(""cost"", cost)
        tf.add_to_collection(""train_op"", train_op)
</code></pre>

<p>My attempt to change the loss function is as follows (I've only indicated the code that is different):</p>

<pre><code>with tf.name_scope(""optimization""):

    # One-hot encode targets and reshape to match logits, one row per batch_size per step
    y_one_hot = tf.one_hot(targets, len(target_letter_to_int))
    y_reshaped = tf.reshape(y_one_hot, [batch_size, len(target_letter_to_int), 30])

    # Loss function
    loss = tf.nn.softmax_cross_entropy_with_logits(logits=training_logits, labels=y_reshaped)
    loss = tf.reduce_mean(loss)
    cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks, softmax_loss_function=loss)
</code></pre>

<p>The line <code>cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks, softmax_loss_function=loss)</code> is now giving me ""<strong>TypeError</strong>: 'Tensor' object is not callable."" This is one of the most opaque errors I've seen Tensorflow produce and I haven't found much of anything in the way of explanation on the internet. Any help would be appreciated.</p>
",1,Documentation Replication on Other Examples
107,46759271,Image pixel value normalized for tf.image.decode_jpeg and tf.train.shuffle_batch?,"<p>I am trying to use the tf.train.shuffle_batch function from tensorflow, then I need to first load the images using tf.image.decode_jpeg(or other similar functions to load png and jpg). But I just found out that the images are loaded as probability map, which means the max of the value of pixel is 1, and the min of the value of the pixel is 0. Below is my code updated from a github repo. I don't know why the values of pixels are normalized to [0,1], and I don't find related documentation on tensorflow. Could anyone help me? Thanks.  </p>

<pre><code>def load_examples(self, input_dir,  flip, scale_size, batch_size, min_queue_examples):
    input_paths = get_image_paths(input_dir)
    with tf.name_scope(""load_images""):
        path_queue = tf.train.string_input_producer(input_paths)
        reader = tf.WholeFileReader()
        paths, contents = reader.read(path_queue)
        # note this is important for truncated images
        raw_input = tf.image.decode_jpeg(contents,try_recover_truncated = True, acceptable_fraction=0.5)
        raw_input = tf.image.convert_image_dtype(raw_input, dtype=tf.float32)
        raw_input.set_shape([None, None, 3])

        # break apart image pair and move to range [-1, 1]
        width = tf.shape(raw_input)[1]  # [height, width, channels]
        a_images = preprocess(raw_input[:, :width // 2, :])
        b_images = raw_input[:, width // 2:, :]

    inputs, targets = [a_images, b_images]

    def transform(image):
        r = image

        r = tf.image.resize_images(r, [self.image_height, self.image_width], method=tf.image.ResizeMethod.AREA)
        return r
    def transform_gaze(image):
        r = image
        r = tf.image.resize_images(r, [self.gaze_height, self.gaze_width], method=tf.image.ResizeMethod.AREA)
        return r
    with tf.name_scope(""input_images""):
        input_images = transform(inputs)

    with tf.name_scope(""target_images""):
        target_images = transform(targets)
    total_image_count = len(input_paths)
    # target_images = tf.image.per_image_standardization(target_images)
    target_images = target_images[:,:,0]
    target_images = tf.expand_dims(target_images, 2)
    inputs_batch, targets_batch = tf.train.shuffle_batch([input_images, target_images],
                                         batch_size=batch_size,
                                         num_threads=1,
                                         capacity=min_queue_examples + 3 * batch_size,
                                         min_after_dequeue=min_queue_examples)
    # inputs_batch, targets_batch = tf.train.batch([input_images, target_images],batch_size=batch_size)
    return inputs_batch, targets_batch, total_image_count
</code></pre>
",1,Documentation Replication on Other Examples
108,46885191,tf.nn.conv2d_transpose output_shape dynamic batch_size,"<p>The documentation of tf.nn.conv2d_transpose says:</p>

<pre><code>tf.nn.conv2d_transpose(
    value,
    filter,
    output_shape,
    strides,
    padding='SAME',
    data_format='NHWC',
    name=None
)
</code></pre>

<p>The output_shape argument requires a 1D tensor specifying the shape of the tensor output by this op. Here, since my conv-net part has been built entirely on dynamic batch_length placeholders, I can't seem to device a workaround to the static <code>batch_size</code> requirement of the output_shape for this op. </p>

<p>There are many discussions around the web for this, however, I couldn't find any solid solution to this issue. Most of them are hacky ones with a <code>global_batch_size</code> variable defined. I wish to know the best possible solution to this problem. This trained model is going be shipped as a deployed service.</p>
",1,Inadequate Examples
109,46900332,How to create custom metrics for use in Tensorflow's Estimator class?,"<p>In Tensorflow's <a href=""https://www.tensorflow.org/versions/master/extend/estimators"" rel=""noreferrer"">Creating Estimators in tf.estimator</a> guide, the example used a metric that is already predefined in the <code>tf.metrics</code> module.</p>

<p>Are there any resources that describe how to define a custom metric that can be used to evaluate an Estimator? I'd like to implement the F1 metric.</p>
",1,Documentation Replication on Other Examples
110,46976226,`tf.estimator.RunConfig` vs `tf.contrib.learn.RunConfig`,"<p>I am confused regarding whether I should be using <code>tf.estimator.RunConfig</code> or <code>tf.contrib.learn.RunConfig</code> to pass a <code>RunConfig</code> to an estimator. </p>

<p>using <code>tf.contrib.learn.RunConfig</code> is straightforward:</p>

<pre><code>rc = tf.contrib.learn.RunConfig(save_checkpoints_secs=1,
                                model_dir=model_dir)
</code></pre>

<p>But <code>tf.estimator.RunConfig</code> has some odd syntax:</p>

<pre><code>rc = tf.estimator.RunConfig()
rc = rc.replace(save_checkpoints_secs=1,
                model_dir=model_dir)
</code></pre>

<p>Is there any reason to prefer one <code>RunConfig</code> over the other? The documentation is not clear on this.</p>
",1,Lack of Alternative Solutions/Documentation
111,47119604,"In tensorflow, does tf.summary record average values over multiple steps?","<p>By default, <code>RunConfig.save_summary_steps</code> is 100 in <code>tf.estimator.Estimator</code>, so it saves summaries every 100 steps. At each time it saves a summary, does it just save the current summary value computed from the current <code>step/minibatch</code>? Or it saves the average summary values computed from the recent 100 <code>steps/minibatches</code>? I cannot find a clear description for this in the official documentation.</p>
",1,Lack of Alternative Solutions/Documentation
112,47205160,Tensorflow v1.4: Layer.input not supported in Eager mode,"<p>I understand that Eager mode is a new alpha feature on the nightly builds and that it is not perfect yet, but I do not know if there are any tf.keras workarounds for this problem.</p>

<p>The error <code>Layer.input not supported in Eager mode.</code> triggers on the block</p>

<pre><code>model = tf.keras.models.Sequential()
model.add(tf.layers.Dense(2, input_shape = (None, 1)))
model.add(tf.layers.Dense(units = 1))
model.compile(optimizer = ""sgd"", loss = ""mean_squared_error"")
</code></pre>

<p>I do not know anything about keras or the keras tensorflow API and I was wondering if there was a way to avoid <code>Layer.input</code> with keras techniques so as to stay within Eager mode. Following a tutorial in the tf.Eager docs I have confirmed that <code>model = tf.layers.Dense(1)</code> works but I don't know how to add another layer.</p>

<p>Any help is very much appreciated.</p>

<p><strong>EDIT</strong>
As of tensorflow v1.10, keras is supported in eager mode.</p>
",1,Documentation Replication on Other Examples
113,47319390,Why does this TensorFlow code behave differently when inside a test case?,"<p>I have a function (<code>foo</code> below) which is behaving differently when it's run directly vs when it is run inside a <code>tf.test.TestCase</code>.</p>

<p>The code is supposed to create a dataset with elems [1..5] and shuffle it. Then it repeats 3 times: create an iterator from the data and use that to print the 5 elements.</p>

<p>When run on its own it gives output where all the lists are shuffled e.g.:</p>

<pre><code>[4, 0, 3, 2, 1]
[0, 2, 1, 3, 4]
[2, 3, 4, 0, 1]
</code></pre>

<p>but when run inside a test case they are always the same, even between runs:</p>

<pre><code>[0, 4, 2, 3, 1]
[0, 4, 2, 3, 1]
[0, 4, 2, 3, 1]
</code></pre>

<p>I imagine it's something to do with how test cases handle random seeds but I can't see anything about that in the TensorFlow docs. Thanks for any help!</p>

<hr>

<h2>Code:</h2>

<pre><code>import tensorflow as tf

def foo():
    sess = tf.Session()
    dataset = tf.data.Dataset.range(5)
    dataset = dataset.shuffle(5, reshuffle_each_iteration=False)

    for _ in range(3):
        data_iter = dataset.make_one_shot_iterator()
        next_item = data_iter.get_next()
        with sess.as_default():
            data_new = [next_item.eval() for _ in range(5)]
        print(data_new)


class DatasetTest(tf.test.TestCase):
    def testDataset(self):
        foo()

if __name__ == '__main__':
    foo()
    tf.test.main()
</code></pre>

<p>I am running it with Python 3.6 and TensorFlow 1.4. No other modules should be needed.</p>
",1,Documentation Replication on Other Examples
114,47380573,How to properly update variables in a while loop in TensorFlow?,"<p>Can someone please explain (or point me to the relevant place in the documentation that I've missed) how to properly update a <code>tf.Variable()</code> in a <code>tf.while_loop</code>? I am trying to update variables in the loop that will store some information until the next iteration of the loop using the <code>assign()</code> method. However, this isn't doing anything.</p>

<p>As the values of <code>mu_tf</code> and <code>sigma_tf</code> are being updated by the minimizer, while <code>step_mu</code> isn't, I am obviously doing something wrong, but I don't understand what it is. Specifically, I guess I should say that I know <a href=""https://stackoverflow.com/a/34220750/8931942""><code>assign()</code> does not do anything until it is executed when the graph is run</a>, so I know that I can do</p>

<p><code>sess.run(step_mu.assign(mu_tf))</code></p>

<p>and that will update <code>step_mu</code>, but I want to do this in the loop correctly. I don't understand how to add an <code>assign</code> operation to the body of the loop.</p>

<p>A simplified working example of what I'm doing follows here:</p>

<pre><code>import numpy as np
import tensorflow as tf

mu_true = 0.5
sigma_true = 1.5

n_events = 100000

# Placeholders
X = tf.placeholder(dtype=tf.float32)

# Variables
mu_tf = tf.Variable(initial_value=tf.random_normal(shape=[], mean=0., stddev=0.1,
                                                dtype=tf.float32),
                    dtype=tf.float32)
sigma_tf = tf.Variable(initial_value=tf.abs(tf.random_normal(shape=[], mean=1., stddev=0.1,
                                                dtype=tf.float32)),
                       dtype=tf.float32,
                       constraint=lambda x: tf.abs(x))

step_mu = tf.Variable(initial_value=-99999., dtype=tf.float32)   
step_loss = tf.Variable(initial_value=-99999., dtype=tf.float32)

# loss function
gaussian_dist = tf.distributions.Normal(loc=mu_tf, scale=sigma_tf)
log_prob = gaussian_dist.log_prob(value=X)
negative_log_likelihood = -1.0 * tf.reduce_sum(log_prob)

# optimizer
optimizer = tf.train.AdamOptimizer(learning_rate=0.1)

# sample data
x_sample = np.random.normal(loc=mu_true, scale=sigma_true, size=n_events)

# Construct the while loop.
def cond(step):
    return tf.less(step, 10)

def body(step):
    # gradient step
    train_op = optimizer.minimize(loss=negative_log_likelihood)

    # update step parameters
    with tf.control_dependencies([train_op]):
        step_mu.assign(mu_tf)

        return tf.add(step,1)

loop = tf.while_loop(cond, body, [tf.constant(0)])

# Execute the graph
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    step_loss = sess.run(fetches=negative_log_likelihood, feed_dict={X: x_sample})

    print('Before loop:\n')
    print('mu_tf: {}'.format(sess.run(mu_tf)))
    print('sigma_tf: {}'.format(sess.run(sigma_tf)))
    print('step_mu: {}'.format(sess.run(step_mu)))
    print('step_loss: {}\n'.format(step_loss))

    sess.run(fetches=loop, feed_dict={X: x_sample})

    print('After loop:\n')
    print('mu_tf: {}'.format(sess.run(mu_tf)))
    print('sigma_tf: {}'.format(sess.run(sigma_tf)))
    print('step_mu: {}'.format(sess.run(step_mu)))
    print('step_loss: {}'.format(step_loss))
</code></pre>
",1,Documentation Replicability
115,47568998,Tensorflow: Load data in multiple threads on cpu,"<p>I have a python class <code>SceneGenerator</code> which has multiple member functions for preprocessing and a generator function <code>generate_data()</code>. The basic structure is like this:</p>

<pre><code>class SceneGenerator(object):
    def __init__(self):
       # some inits

    def generate_data(self):
        """"""
        Generator. Yield data X and labels y after some preprocessing
        """"""
        while True:
            # opening files, selecting data
            X,y = self.preprocess(some_params, filenames, ...)            

            yield X, y
</code></pre>

<p>I used the class member function sceneGenerator.generate_data() in keras model.fit_generator() function to read the data from disk, preprocess it and yield it. In keras, this is done on multiple CPU threads, if the <code>workers</code> parameter of <code>model.fit_generator()</code> is set to something > 1.</p>

<p>I now want to use the same <code>SceneGenerator</code> class in tensorflow. My current approach is this:</p>

<pre><code>sceneGenerator = SceneGenerator(some_params)
for X, y in sceneGenerator.generate_data():

    feed_dict = {ops['data']: X,
                 ops['labels']: y,
                 ops['is_training_pl']: True
                 }
    summary, step, _, loss, prediction = sess.run([optimization_op, loss_op, pred_op],
                                                  feed_dict=feed_dict)
</code></pre>

<p>This, however, is slow and does not use multiple threads. I found the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset"" rel=""noreferrer""><code>tf.data.Dataset</code></a> api with some <a href=""https://www.tensorflow.org/versions/master/programmers_guide/datasets"" rel=""noreferrer"">documentation</a>, but I fail to implement the methods.</p>

<p><strong>Edit:</strong> Notice that I do not work with images so that the image loading mechanisms with file paths etc. do not work here.
My <code>SceneGenerator</code> loads data from hdf5 files. But not complete datasets but - depending on the initialization parameters - only parts of a dataset. I would love to keep the generator function as it is and learn how this generator can be directly used as input for tensorflow and runs on multiple threads on the CPU. Rewriting the data from the hdf5 files to csv is not a good option because it duplicated lots of data.</p>

<p><strong>Edit 2:</strong>: I think something similar to this could help: <a href=""https://stackoverflow.com/questions/47086599/parallelising-tf-data-dataset-from-generator"">parallelising tf.data.Dataset.from_generator</a></p>
",1,Documentation Replication on Other Examples
116,47644412,TensorFlow Dataset API Parsing Error,"<p>I'm using the TensorFlow Dataset API to parse a CSV file and run a logistic regression. I'm following the example from the TF documentation <a href=""https://github.com/tensorflow/models/blob/master/official/wide_deep/wide_deep.py"" rel=""nofollow noreferrer"">here</a>.</p>

<p>The following code snippet shows how I am setting up the model:</p>

<pre><code>def input_fn(path, num_epochs, batch_size):
    dataset = tf.data.TextLineDataset(path)
    dataset = dataset.map(parse_table, num_parallel_calls=12)
    dataset = dataset.repeat(num_epochs)
    dataset.batch(batch_size)

    iterator = dataset.make_one_shot_iterator()
    features, labels = iterator.get_next()
    return features, labels

def parse_table(value):
    cols = tf.decode_csv(value, record_defaults=TAB_COLUMN_DEFAULTS)
    indep_vars = dict(zip(CSV_COLS, cols))
    y = indep_vars.pop('y')
    return indep_vars, y

def build_indep_vars():
    continuous_vars = [
        tf.feature_column.numeric_column(x, shape=1) for x in CONT_COLS]
    categorical_vars = [
        tf.feature_column.categorical_column_with_hash_bucket(
            x, hash_bucket_size=100) for x in CAT_COLS]
    return categorical_vars + continuous_vars
</code></pre>

<p>When calling <code>lr.train(input_fn = lambda: input_fn(data_path, 1, 100))</code> (note: batch size is 100) I'm getting the error </p>

<pre><code>ValueError: Feature (key: V1) cannot have rank 0. Give: Tensor(""IteratorGetNext:0"", shape=(), dtype=float32, device=/device:CPU:0)
</code></pre>

<p>So I'm assuming this means one of the <code>tf.feature_column.numeric_column</code> calls is getting a scalar value which it doesn't like. However, I cannot figure out why this is the case. I've set <code>batch_size</code> to a positive integer and according to the documentation the shape of the NDarray resulting from <code>tf.feature_column.numeric_column</code> should be <code>1Xbatch_size</code> by default. Can anyone explain why TensorFlow is returning this error?</p>

<p>I'm sure this question has a simple answer that will make me feel stupid for not figuring it out, but after spending some time on this I'm still stumped.</p>
",1,Documentation Ambiguity
117,47665314,how can we get benefit from sharding the data to speed the training time?,"<p>My main issue is : I have 204 GB training tfrecords for 2 million images, and 28GB for validation tf.records files, of 302900 images. it takes 8 hour to train one epoch and this will take 33 day for training. I want to speed that by using multiple threads and shards but I am little bit confused about couple of things.</p>

<p>In <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">tf.data.Dataset API</a> there is shard function , So in the documentation they mentioned the following about shard function : </p>

<blockquote>
  <p>Creates a Dataset that includes only 1/num_shards of this dataset.</p>
  
  <p>This dataset operator is very useful when running distributed training, as it allows each worker to read a unique subset.</p>
  
  <p>When reading a single input file, you can skip elements as follows:</p>
</blockquote>

<pre><code>d = tf.data.TFRecordDataset(FLAGS.input_file)
d = d.shard(FLAGS.num_workers, FLAGS.worker_index)
d = d.repeat(FLAGS.num_epochs)
d = d.shuffle(FLAGS.shuffle_buffer_size)
d = d.map(parser_fn, num_parallel_calls=FLAGS.num_map_threads)
</code></pre>

<blockquote>
  <p>Important caveats:</p>
  
  <p>Be sure to shard before you use any randomizing operator (such as shuffle).
  Generally it is best if the shard operator is used early in the dataset pipeline. >For example, when reading from a set of TFRecord files, shard before converting >the dataset to input samples. This avoids reading every file on every worker. The >following is an example of an efficient sharding strategy within a complete >pipeline:</p>
</blockquote>

<pre><code>d = Dataset.list_files(FLAGS.pattern)
d = d.shard(FLAGS.num_workers, FLAGS.worker_index)
d = d.repeat(FLAGS.num_epochs)
d = d.shuffle(FLAGS.shuffle_buffer_size)
d = d.repeat()
d = d.interleave(tf.data.TFRecordDataset,
             cycle_length=FLAGS.num_readers, block_length=1)

d = d.map(parser_fn, num_parallel_calls=FLAGS.num_map_threads)
</code></pre>

<p>So my question regarding the code above is when I try to makes d.shards of my data using shard function, if I set the number of shards (num_workers)to 10 , I will have 10 splits of my data , then should I set the num_reader in d.interleave function to 10 to guarantee that each reader take one split from the 10 split? </p>

<p>and how I can control which split the function interleave will take? because if I set the shard_index (worker_index) in shard function to 1 it will give me the first split. Can anyone give me an idea how can I perform this distributed training using the above functions? </p>

<p>then what about the num_parallel_call . should I set it to 10 as well? </p>

<p>knowing that I have single tf.records file for training and another one for validation , I don't split the tf.records files into multiple files.</p>
",1,Documentation Replication on Other Examples
118,47768298,How to understand using tf.cond with tf.Print?,"<p>Look at the code:</p>

<pre><code>import tensorflow as tf

x = tf.constant(1.0)
y = tf.constant(2.0)
z = tf.constant(3.0)
def f1():
    return tf.Print(x, [x])

def f2():
    return tf.Print(z, [z])
op = tf.cond(x&gt;y, f1, f2)
with tf.Session() as sess:
    sess.run(op)
</code></pre>

<p>I'm very puzzled, the output of tf.Print is 3.0</p>

<p>As we know, tf.Print(z, [z]) will output the value of <code>z</code> only when <code>z</code> is evaluated, but I don't think I have evaluated <code>z</code>.</p>

<p>Another question is about <code>tf.cond</code>, how does it add node to graph, for example how does add <code>tf.Print</code> to graph, I think it should relate some tensor with the return of <code>tf.Print</code>, otherwise <code>tf.Print</code> won't be executed.</p>

<p>I'm so puzzled.</p>
",1,Documentation Replicability
119,47814401,How does tf.layers.batch_normalization calculate mean and variance during test time? (test data has machine-generated samples),"<p>I am trying to implement batch-normalization on my CNN that currently applies dropout. One problem is that I do not know how the mean and variance are calculated during test time.</p>

<p>On the documentation it says that if training=False is set then the normalization is done with moving statistics. What does this mean?</p>

<p>In addition, since my test data has lots of machine-generated samples I cannot use population mean and variance and just apply tf.nn.batch_normalization(). These samples are used to prevent hand labeling and are excluded when scoring my model</p>
",1,Documentation Completeness
120,47898147,Tensorflow Module Import error: AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'rnn_cell',"<p>When attempting to pass my RNN call, I call tf.nn.rnn_cell and I receive the following error: </p>

<pre><code>AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'rnn_cell'
</code></pre>

<p>Which is odd, because I'm sure I imported everything correctly: </p>

<pre><code>from __future__ import print_function, division
from tensorflow.contrib import rnn
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
</code></pre>

<p>But looking at the docs, things have moved around between tensorflow versions. </p>

<p>what would you all recommend to fix this?? </p>

<p>Line, I'm getting the error against: </p>

<pre><code>state_per_layer_list = tf.unstack(init_state, axis=0)
rnn_tuple_state = tuple(
    [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])
     for idx in range(num_layers)]
)
</code></pre>

<p>Specifically: </p>

<pre><code>tf.nn.rnn_cell
</code></pre>

<p>I'm using anaconda 3 to manage all of this so, the dependancies should all be taken care of. I have already tried working around a damn rank/shape error with Tensor shapes which took ages to resolve. </p>

<p>Cheers in advance. </p>
",1,Documentation Replication on Other Examples
121,47947629,"Tensorflow: Keras, Estimators and custom input function","<p>TF1.4 made Keras an integral part. 
When trying to create Estimators from Keras models with propratery input function (I.e., not using the tf.estimator.inputs.numpy_input_fn) things are not working as Tensorflow can not fuse the model with the Input function.</p>

<p>I am using tf.keras.estimator.model_to_estimator</p>

<pre><code>keras_estimator = tf.keras.estimator.model_to_estimator(
            keras_model = keras_model,
            config = run_config)

train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, 
                                    max_steps=self.train_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn,
                                  steps=None)

tf.estimator.train_and_evaluate(keras_estimator, train_spec, eval_spec)
</code></pre>

<p>and I get the following error message:</p>

<pre><code>    Cannot find %s with name ""%s"" in Keras Model. It needs to match '
              'one of the following:
</code></pre>

<p>I found some reference for this topic <a href=""https://www.tensorflow.org/versions/master/programmers_guide/estimators"" rel=""nofollow noreferrer"">here</a> (strangely enough its hidden in the TF docs in the master branch - compare to <a href=""https://www.tensorflow.org/programmers_guide/estimators"" rel=""nofollow noreferrer"">this</a>)</p>

<p>If you have the same issue - see my answer below. Might save you several hours. </p>
",1,Documentation Replicability
122,47981089,How to get TensorFlow source for canned models (Estimators),"<p>We are using the canned dnn (tf.estimator.DNNClassifier and 
 tf.estimator.DNNLinearCombinedClassifier)(and others) estimators in TensorFlow 1.4 but are interested in inspecting and perhaps reimplementing the models with variations in native TensorFlow, as well as for learning purposes. Is there any way to do this or is it available in the docs? Or is there a way to see it in the source?</p>
",1,Documentation Replicability
123,47984876,Tensorflow tf.map_fn parameters,"<p>I'm attempting to structure my parameters so that they will work properly with tf.map_fn() but most of the example documentation only discusses arrays or tensors of the same shape as function arguments.</p>

<p>Links include:</p>

<p><a href=""https://stackoverflow.com/questions/37086098/does-tensorflow-map-fn-support-taking-more-than-one-tensor"">Does tensorflow map_fn support taking more than one tensor?</a></p>

<p>My specific example is this:
I have some tensorflow function that expects [None, 2] and [x,y] as parameter tensor shapes.</p>

<p>Tensor A is of shape [batch_size, x*y, 2]</p>

<p>Tensor B is of shape [batch_size, x, y]</p>

<pre><code>lambdaData = (tensorA, tensorB)
lambdaFunc = lambda x: tensorflowFunc(x[0], x[1])
returnValues = tf.map_fn(lambdaFunc, lambdaData)
</code></pre>

<p>From the tensorflow documentation:</p>

<pre><code>If elems is a (possibly nested) list or tuple of tensors, then each of these 
tensors must have a matching first (unpack) dimension
</code></pre>

<p>Since tensorsA and B only match in dimension 0, I cannot stack or concatenate them; I have also tried creating lambdaData as:</p>

<ol>
<li>A list of two tensors</li>
<li>A tuple of two tensors</li>
<li>A list of tensor pairs</li>
</ol>

<p>All of the above result in varying dimension mismatch errors.  I would follow the recommended use as per documentation of placing all of the data into a single tensor, but because of dimension mismatching between tensorA and tensorB I am unable to.  Has anybody had any luck with tuples or lists of arguments for elems?</p>
",1,Lack of Alternative Solutions/Documentation
124,48021777,Tensorflow tf.concat,"<p>Sorry for asking a totally elementary question, but I'm trying to use the <code>tf.concat()</code> function. Just to get going, I try to run the example code on their site: <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/array_ops/slicing_and_joining"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r0.12/api_docs/python/array_ops/slicing_and_joining</a></p>

<pre><code>t1 = [[1, 2, 3], [4, 5, 6]]
t2 = [[7, 8, 9], [10, 11, 12]]
tf.concat(0, [t1, t2]) 
</code></pre>

<p>This should generate the output: <code>[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]</code>.</p>

<p>However, I get the error message, saying that </p>

<blockquote>
  <p>""Shapes (2, 2, 3) and () are incompatible"".</p>
</blockquote>
",1,Documentation Replication on Other Examples
125,48033687,How to use tf.train.shuffle_batch to train NN?,"<p>I've trained my neural built with tensorflow network and got some overfit I'd like to reduce. I hoped learning the model on batches could help ad I tried to test this idea. I found tf.train.shuffle_batch() and fought this may do the thing. So I tried and it didn't work. Tensorflow's documentation doesn't help. I've found <a href=""https://stackoverflow.com/questions/45203872/how-tf-train-shuffle-batch-works"">one topic, but the example there</a> only prints arrays out. It was promising to use it to learn NN but in my case istead of getting data divided to n-element batches I got them multiplied n-times in additional dimension. </p>

<p>Here is the code sample:</p>

<pre><code>nnInput = tf.placeholder(tf.float32, [None, input_width], ""network_input"")
nnOutput = tf.placeholder(tf.float32, [None, output_width], ""expected_labels"")

batch_readings, batch_labels = tf.train.shuffle_batch(
    [
        tf.constant(train_readings), 
        tf.constant(train_labels)
    ],
    batch_size = 15,
    num_threads = 4,
    capacity = 500,
    min_after_dequeue = 250,
    allow_smaller_final_batch = True
)

sess.run(tf.global_variables_initializer())

for epoch in range(learning_steps):
    print(""epoch:"", epoch)
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    print(""Input data shapes:"", train_readings.shape, train_labels.shape)
    for batch in range(10):
        x, y = sess.run([batch_readings, batch_labels])
        print(""Batch shapes:"", x.shape, y.shape)
        sess.run(train, feed_dict = {nnInput : x, nnOutput : y})
    coord.request_stop()
    coord.join(threads)
</code></pre>

<p>and here is the output:</p>

<pre><code>epoch: 0 
Input data shapes: (165, 60) (165, 1) 
Batch shapes: (15, 165, 60) (15, 165, 1)
</code></pre>

<p>And the error list concludes with:</p>

<pre><code>ValueError: Cannot feed value of shape (15, 165, 60) for Tensor 'network_input_1:0', which has shape '(?, 60)'
</code></pre>

<p>The conlusion is not surprising when I fed the NN with 3D array but why do I get such a batch when I expect x:(15, 60) and y:(15, 1)? Why do I get x:(15, 165, 60) y:(15, 165, 1) and how to get useful batches?</p>

<p>I'm using tensorflow-gpu but hope this should work as well, right?</p>
",1,Documentation Replication on Other Examples
126,48169791,How to change the value of a tensor which is not a tf.Variable in TensorFlow?,"<p>I know that there is a <code>tf.assign</code> function in TensorFlow, but this function is mainly aimed at mutable tensor (<code>tf.Variable</code>). How to modify the value of the tensor? For example, the following code,</p>

<pre><code>import numpy as np
import tensorflow as tf

X = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])

conv1 = tf.layers.conv2d(X, filters=64, kernel_size=(3, 3), padding='same',name='conv1')
relu1 = tf.nn.relu(conv1)

conv2 = tf.layers.conv2d(relu1, filters=64, kernel_size=(3, 3), padding='same',name='conv2')
relu2 = tf.nn.relu(conv2)

init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)

tensor = sess.graph.get_tensor_by_name(u'conv2/Conv2D:0')
feature_map = tf.reduce_mean(tensor[:,:,:,24])

image = np.random.uniform(size=(1,32,32,3))
sess.run([feature_map], feed_dict={X: image})
</code></pre>

<p>How to modify the value of <code>feature_map</code> and do not affect its derivation?</p>

<p>More specifically, when I change the value of <code>feature_map</code>, it does not affect its derivation process. 
For example, <code>y = a^2</code>, <code>y'= 2a</code>, I just need to change <code>a = 1</code> to <code>a = 2</code>. </p>

<p><code>Other_op = tf.gradients(feature_map, X)</code></p>

<p>Different <code>feature_map</code> would achieve the different values, but it does not destroy the graph structures of operation.</p>
",1,Documentation Replicability
127,48222274,tensorflow ctc_loss how to understand labels param,"<p>tensorflow document:
labels.values[i] must take on values in [0, num_labels], allow values[i] have zero value,  </p>

<p>labels is SparseTensor,<br>
indices: specifies the indices of the elements in the sparse tensor that contain nonzero values, values:which supplies the values for each element in indices</p>

<p>according to sparsetensor define, labels.values[i] is nonzero value, but tf.nn.ctc_loss labels.values allow labels.values[i] have zero value,</p>

<p>how to understand labels.values[i] allow have zero value</p>
",1,Documentation Replicability
128,48235239,The fit function from tf.contrib.learn.LinearRegressor asks to switch to tf.train.get_global_step,"<p>I am trying to get a <code>LinearRegressor</code> to work and I get an error for which there doesn't seem to be much documentation about.</p>

<p>When I do:</p>

<pre><code>regressor = tf.contrib.learn.LinearRegressor(feature_columns=linear_features)

regressor.fit(input_fn=training_input_fn, steps=10000)

regressor.evaluate(input_fn=eval_input_fn)
</code></pre>

<p>I get the error:</p>

<blockquote>
  <p>Instructions for updating: Please switch to tf.train.get_global_step</p>
</blockquote>

<p>I am not sure how to proceed.</p>

<p>I read from the docs:</p>

<blockquote>
  <p>SOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-12-01.
  Instructions for updating: Estimator is decoupled from Scikit Learn
  interface by moving into separate class SKCompat. Arguments x, y and
  batch_size are only available in the SKCompat class, Estimator will
  only accept input_fn. Example conversion: est = Estimator(...) -> est
  = SKCompat(Estimator(...))</p>
</blockquote>

<p>But I'm not sure to what I should change to, or how to switch to the global step.</p>

<p>I tried using <code>tf.estimator.LinearRegressor</code> mainly because I'm out of ideas, and did something like this:</p>

<pre><code>estimator = tf.estimator.LinearRegressor(feature_columns=linear_features)

estimator.train(input_fn=training_input_fn)
estimator.evaluate(input_fn=eval_input_fn)
estimator.predict(input_fn=eval_input_fn)
</code></pre>

<p>But got no output at all.</p>
",1,Lack of Alternative Solutions/Documentation
129,48299597,How to efficiently shuffle a large tf.data.Dataset when using tf.estimator.train_and_evaluate?,"<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer""><code>tf.estimator.train_and_evaluate</code></a> documentation makes it clear that the input dataset must be properly shuffled for the training to see all examples:</p>

<blockquote>
  <p>Overfitting: In order to avoid overfitting, it is recommended to set up the training input_fn to shuffle the training data properly. It is also recommended to train the model a little longer, say multiple epochs, before performing evaluation, as the input pipeline starts from scratch for each training. It is particularly important for local training and evaluation.</p>
</blockquote>

<p>In my application, I would like to uniformly sample examples from the full <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code></a> with arbitrary evaluation frequency and <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"" rel=""nofollow noreferrer""><code>shuffle()</code></a>'s buffer size. Otherwise, the training can at most see the first:</p>

<pre><code>(steps_per_second * eval_delay * batch_size) + buffer_size
</code></pre>

<p>elements, effectively discarding the rest. Is there an efficient way to work around that without loading the complete dataset in the system memory?</p>

<p>I considered <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shard"" rel=""nofollow noreferrer"">sharding</a> the dataset based on the buffer size, but if the evaluation does not occur frequently, it will iterate on the same shard multiple times (a <code>repeat()</code> closes the pipeline). Ideally, I would like to move to another shard after a complete iteration over the dataset, is that possible?</p>

<p>Thanks for any pointers!</p>
",1,Documentation Replicability
130,48396599,"Canonical Tensorflow ""for loop""","<p>What is the canonical way of running a Tensorflow ""for loop""? </p>

<p>Specifically, suppose we have some <code>body</code> function which does NOT depend on the loop iteration, but must be run <code>n</code> times. </p>

<p>One might think that a good method might be to run this inside of a <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/control_flow_operations#while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop</code></a> like this:</p>

<pre><code>def body(x):
    return ...

def while_body(i,x):
    return i+1, body(x) 

i, x = tf.while_loop(lambda i: tf.less(i, n), while_body, [tf.constant(0),x])
</code></pre>

<p>In fact, that is precisely what the highest rated answer in this question suggests:</p>

<p><a href=""https://stackoverflow.com/questions/35330117/how-can-i-run-a-loop-with-a-tensor-as-its-range-in-tensorflow"">How can I run a loop with a tensor as its range? (in tensorflow)</a></p>

<p>However, the <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/control_flow_operations#while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop</code> docs</a> specifically say </p>

<blockquote>
  <p>For correct programs, while_loop should return the same result for any parallel_iterations > 0.</p>
</blockquote>

<p>If you put a counter in the body, then it seems that that condition is violated. So it seems that there must be a different way of setting up a ""for loop"". </p>

<p>Furthermore, even if there is no explicit error, doing so seems like it will create a dependency between iterations meaning that I do not think they will run in parallel. </p>
",1,Lack of Alternative Solutions/Documentation
131,48427269,What's the efficient way to feed elements from Iterator (from tf.data.Dataset) into TensorFlow model?,"<p>I'm using TensrFlow's new API for importing data via <code>tf.data.Dataset</code> and iterators. It is working fine, but I'm not sure if what I do is efficient. </p>

<p>What I'm doing at the moment is evaluating an iterator's <code>get_next()</code> method, which gives me a bunch of elements like the actual image, its label, filename, etc. I then feed the image into my model using the <code>feed_dict</code>. </p>

<p>I know that <code>feed_dict</code> is very slow, so am I losing benefits of <code>Dataset</code> and Iterators and having serialised dataset in <code>TFRecord</code>s by evaluating the entries and feeding them into the graph via <code>feed_dict</code>? I haven't found any examples in TF's documentation which shows how one's expected to use Iterator's <code>get_next()</code> to feed elements into the model. Is it better to unpack <code>get_next()</code> and use the result directly in my graph? </p>
",1,Inadequate Examples
132,48445751,Keras: Constrained dictionary search with CTC decode,"<p>I'm trying to constrain the CTC decoding to a specific (external) dictionary in Keras with a the tensorflow backend. In the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_decode"" rel=""nofollow noreferrer"">tensorflow documentation for Keras' ctc_decode</a>, it is written that when <code>greedy=False</code> a dictionary will be used. Here is the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder"" rel=""nofollow noreferrer"">documentation for  tf.nn.ctc_beam_search_decoder</a>, which will be called by this option as far as I understand.</p>

<p>Since there is no way to pass an external dictionary or language model (to constrain the search), I assume that with <code>greedy=False</code> it creates its own dictionary from the training data. Is this correct? Is there a way to constrain the search to a specific (external) dictionary?</p>
",1,Documentation Replication on Other Examples
133,48471926,In Tensorflow's Dataset API how do you map one element into multiple elements?,"<p>In the tensorflow <code>Dataset</code> pipeline I'd like to define a custom map function which takes a single input element (data sample) and returns multiple elements (data samples).</p>

<p>The code below is my attempt, along with the desired results. </p>

<p>I could not follow the documentation on <code>tf.data.Dataset().flat_map()</code> well enough to understand if it was applicable here or not.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

input = [10, 20, 30]

def my_map_func(i):
  return [[i, i+1, i+2]]       # Fyi [[i], [i+1], [i+2]] throws an exception

ds = tf.data.Dataset.from_tensor_slices(input)
ds = ds.map(map_func=lambda input: tf.py_func(
  func=my_map_func, inp=[input], Tout=[tf.int64]
))
element = ds.make_one_shot_iterator().get_next()

with tf.Session() as sess:
  for _ in range(9):
    print(sess.run(element))
</code></pre>

<p>Results:</p>

<pre><code>(array([10, 11, 12]),)
(array([20, 21, 22]),)
(array([30, 31, 32]),)
</code></pre>

<p>Desired results:</p>

<pre><code>(10)
(11)
(12)
(20)
(21)
(22)
(30)
(31)
(32)
</code></pre>
",1,Documentation Replicability
134,48697799,Tensorflow feature column for variable list of values,"<p>From the TensorFlow docs it's clear how to use <code>tf.feature_column.categorical_column_with_vocabulary_list</code> to create a feature column which takes as input some string and outputs a one-hot vector. For example</p>

<pre><code>vocabulary_feature_column =
    tf.feature_column.categorical_column_with_vocabulary_list(
        key=""vocab_feature"",
        vocabulary_list=[""kitchenware"", ""electronics"", ""sports""])
</code></pre>

<p>Let's say <code>""kitchenware""</code> maps to <code>[1,0,0]</code> and <code>""electronics""</code> maps to <code>[0,1,0]</code>. My question is related to having a <strong>list of strings</strong> as a feature. For example, if the feature value was <code>[""kitchenware"",""electronics""]</code> then the desired output would be <code>[1,1,0]</code>. The input list length is not fixed but the output dimension is.</p>

<p>The use case is a straight bag-of-words type model (obviously with a much larger vocabulary list!).</p>

<p>What is the correct way to implement this?</p>
",1,Documentation Replication on Other Examples
135,48736753,"How do you load ""any"" model from disk into a TensorFlow Estimator without having the model_fn source code?","<p>In Keras you can load a model that you had previously trained by using:</p>

<p>trained_keras_model = tf.keras.models.load_model(model_name)</p>

<p>Is there any equivalent method for doing this using TensorFlow estimator API? According to the documentation, I have to use: </p>

<p>trained_estimator = tf.estimator.Estimator (model_fn,model_dir)
I want to get the trained estimator using just the files in the model directory. To be more clear my idea was to load ""any"" model from disk without having the model_fn source code. Is it possible to do it this way? </p>

<p>This feature is implemented in Keras so I am at a loss to understand why Estimator API cannot do this. </p>
",1,Documentation Replicability
136,48815906,Implement early stopping in tf.estimator.DNNRegressor using the available training hooks,"<p>I am new to tensorflow and want to implement early stopping in <code>tf.estimator.DNNRegressor</code> with  available training hooks<a href=""https://www.tensorflow.org/api_guides/python/train#Training_Hooks"" rel=""noreferrer"">Training Hooks</a> for the MNIST dataset. The early stopping hook will stop training if the loss does not improve for some specified number of steps. Tensorflow documentaton only provides example for <a href=""https://www.tensorflow.org/tutorials/layers#set_up_a_logging_hook"" rel=""noreferrer"">Logging hooks</a>. Can someone write a code snippet for implementing it?</p>
",1,Requesting (Additional) Documentation/Examples
137,48914952,num_buckets as a parameter in a tensorflow feature column,"<p>Currently Tensorflow documentation define a categorical vocabulary column this way:</p>

<pre><code>vocabulary_feature_column =
tf.feature_column.categorical_column_with_vocabulary_list(
    key=""feature_name_from_input_fn"",
    vocabulary_list=[""kitchenware"", ""electronics"", ""sports""]) 
</code></pre>

<p>However this suppose that we input manually the vocabulary list.
In case of large dataset with many columns and many unique values I would like to automate the process this way:</p>

<pre><code>for k in categorical_feature_names:
    vocabulary_feature_column =
        tf.feature_column.categorical_column_with_vocabulary_list(
        key=""feature_name_from_input_fn"",
        vocabulary_list=list_of_unique_values_in_the_column) 
</code></pre>

<p>To do so I need to retrieve the parameter <code>list_of_unique_values_in_the_column</code>.
Is there anyway to do that with Tensorflow? </p>

<p>I know there is tf.unique that could return unique values in a tensor but I don't get how I could feed the column to it so it returns the right vocabulary list.</p>
",1,Documentation Replication on Other Examples
138,49066695,How to use tf.nn.raw_rnn function in Tensorflow?,"<p>I am trying to implement LSTM based network where after hidden state computation we also apply linear + sigmoid transformation at each time step. I have found the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn"" rel=""nofollow noreferrer"">official documentation</a> and <a href=""https://hanxiao.github.io/2017/08/16/Why-I-use-raw-rnn-Instead-of-dynamic-rnn-in-Tensorflow-So-Should-You-0/"" rel=""nofollow noreferrer"">a nice article</a> that describe <code>tf.nn.raw_rnn</code> function suitable for this task however I struggle to understand why it does not work in my particular case.</p>

<h3>Input description</h3>

<p>So, let our input to LSTM be a minibatch of size <code>[num_steps x batch_size x size]</code>, concretely <code>[5, 32, 100]</code>. Let LSTM have 200 hidden units. Then the output of the LSTM is <code>[5, 32, 200]</code> tensor which we can later use for loss computation. I assume the input <code>[5, 32, 100]</code> tensor is first unstacked into an array of <code>[32, 100]</code> tensors and then stacked back if we use <code>tf.nn.dynamic_rnn</code> with <code>time_major=True</code> in Tensorflow:</p>

<pre><code>                                      tf.nn.dynamic_rnn(LSTM)
                   LSTM t=0    LSTM t=1   LSTM t=2   LSTM t=3   LSTM t=4  
[5, 32, 100] --&gt;   [[32, 100], [32, 100], [32, 100], [32, 100], [32, 100]] --&gt; [5, 32, 200]
</code></pre>

<h3>Hidden state model</h3>

<p>In addition after each LSTM cell I need to perform linear + sigmoid transformation to squash each <code>[32, 200]</code> tensor into <code>[32, 1]</code> for example. Our <code>tf.nn.dynamic_rnn</code> won't work for that since it only accepts cells. We need to use <code>tf.nn.raw_rnn</code> API. So, here is my try:</p>

<pre><code>def _get_raw_rnn_graph(self, inputs):
    time = tf.constant(0, dtype=tf.int32)
    _inputs_ta = tf.TensorArray(dtype=tf.float32, size=5)
    # our [5, 32, 100] tensor becomes [[32, 100], [32, 100], ...]
    _inputs_ta = _inputs_ta.unstack(inputs)  

    # create simple LSTM cell
    cell = tf.contrib.rnn.LSTMCell(config.hidden_size)

    # create loop_fn for raw_rnn
    def loop_fn(time, cell_output, cell_state, loop_state):
        emit_output = cell_output  # == None if time = 0

        if cell_output is None:  # time = 0
            next_cell_state = cell.zero_state(32, tf.float32)
            self._initial_state = next_cell_state
        else:
            next_cell_state = cell_state

        elements_finished = (time &gt;= 32)
        finished = tf.reduce_all(elements_finished)
        next_input = tf.cond(finished,
                             lambda: tf.zeros([32, config.input_size], dtype=tf.float32),                                                   
                             lambda: _inputs_ta.read(time))

        # apply linear + sig transform here
        next_input = self._linear_transform(next_input, activation=tf.sigmoid)

        next_loop_state = None
        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)

    outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)
    outputs = outputs_ta.stack()
    return outputs, final_state
</code></pre>

<p>This unfortunately does not work. The <code>loop_fn</code> iterates only two times instead of <code>num_steps</code> times as I expected and its output is <code>Tensor(""Train/Model/TensorArrayStack/TensorArrayGatherV3:0"", shape=(?, 32, 200), dtype=float32)</code> not <code>[5, 32, 1]</code> as we intended. What am I missing here?</p>
",1,Documentation Replication on Other Examples
139,49155119,Using TensorFlow ``grad_loss / grad_ys`` parameter to add gradients,"<p>I'm trying to use the <code>grad_loss</code> parameter in <code>optimizer.minimize(loss, grad_loss=)</code> to modify the network gradients with existing gradients.
I followed the comments here:
<a href=""https://stackoverflow.com/questions/42399401/use-of-grads-ys-parameter-in-tf-gradients-tensorflow"">Use of grads_ys parameter in tf.gradients - TensorFlow</a></p>

<p>and I would like to run a toy example, in which I recreate the default <code>1</code> values for <code>grad_ys</code>, as specified in the documentation.</p>

<p>Here's the relevant code segment:</p>

<pre><code>grads_and_vars = optimizer.compute_gradients(loss_op) 
vars_with_grad = [v for g, v in grads_and_vars if g is not None] 
grad_loss = [] 
for grad,var in grads_and_vars:
    grad_loss.append(tf.ones_like(grad))
train_op = optimizer.minimize(loss_op, grad_loss=grad_loss)
</code></pre>

<p>The first part extracts gradients using <code>compute_gradients</code>. The last line computes gradients of the loss function <code>loss_op</code> but attempts to use <code>1</code>-filled vectors for the grads. As far as I understand, this should behave similarly to funning <code>minimize</code> without the <code>grad_loss</code> parameter. </p>

<p>Unfortunately, this fails since it expects <code>grad_loss</code> to be a Tensor (and have a dtype) and not a list. Looking into <code>gradients_impl.py</code> I see that the function expected <code>grad_loss</code> to be of the same dimension as <code>loss</code> (which in this case is a scalar). </p>

<p>I would appreciate any assistance in this simple example - how do I add elements to the gradients this way? </p>

<p>EDIT: I guess the question boils down to the definition of <code>grad_loss</code>: ""A <code>Tensor</code> holding the gradient computed for <code>loss</code>."" How do I generate such a tensor from a set of gradients obtained by <code>compute_gradients</code>?</p>

<p>Thanks.</p>
",1,Documentation Replication on Other Examples
140,49201832,How to use TensorBoard and summary operations with the tf.layers module,"<p>I have followed the <a href=""https://www.tensorflow.org/tutorials/layers"" rel=""nofollow noreferrer"">TensorFlow Layers tutorial</a> to create a CNN for MNIST digit classification using TensorFlow's tf.layers module. Now I'm trying to learn how to use TensorBoard from <a href=""https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"" rel=""nofollow noreferrer"">TensorBoard: Visualizing Learning</a>. Perhaps this tutorial hasn't been updated recently, because it says its example code is a modification of that tutorial's and links to it, but the code is completely different: it manually defines a single-hidden-layer fully-connected network.</p>

<p>The TensorBoard tutorial shows how to use tf.summary to attach summaries to a layer by creating operations on the layer's weights tensor, which is directly accessible because we manually defined the layer, and attaching tf.summary objects to those operations. To do this if I'm using tf.layers and its tutorial code, I believe I'd have to:</p>

<ol>
<li>Modify the Layers tutorial's example code to use the non-functional interface (Conv2D instead of conv2d and Dense instead of dense) to create the layers</li>
<li>Use the layer objects' trainable_weights() functions to get the weight tensors and attach tf.summary objects to those</li>
</ol>

<p>Is that the best way to use TensorBoard with tf.layers, or is there a way that's more directly compatible with tf.layers and the functional interface? If so, is there an updated official TensorBoard tutorial? It would be nice if the documentation and tutorials were more unified. </p>
",1,Requesting (Additional) Documentation/Examples
141,49335184,Reuse variables and model encapsulated in class,"<p>I want to train a model in tensorflow and only define the graph and variables once. So I encapsulated that in a class as follows in this functionally non-sense minimum example:</p>

<pre><code>import tensorflow as tf
import numpy as np


class Model:
    weights = tf.get_variable(""weights"", (10, 1))
    bias = tf.get_variable(""bias"", 1)

    x = tf.placeholder(tf.float32, (100, 10), ""x"")
    y = tf.placeholder(tf.float32, 100, ""y"")

    output = tf.matmul(x, weights) + bias
    cost = tf.reduce_sum(tf.abs(output - y))
    optimizer = tf.train.MomentumOptimizer(0.5, 0.9).minimize(cost)

    def train(self, data, lbls):
        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            for i in range(10):
                _ = sess.run(self.optimizer, {self.x: data, self.y: lbls})

    def predict(self, data):
        with tf.Session() as sess:
            return sess.run(self.output, {self.x: data})


data = np.random.randint(0, 100, (100, 10))
lbls = np.random.randint(0, 1, (100, ))
mdl = Model()
mdl.train(data, lbls)
mdl.predict(data)
</code></pre>

<p>I expect the predict function to reuse the trained variables <code>self.weights</code> and <code>self.bias</code> but all I get is <code>FailedPreconditionError (see above for traceback): Attempting to use uninitialized value bias</code> in the return line of the <code>Model.predict()</code> function.</p>

<p>This sounds simple to me, but somewhere I must have a wrong assumption. The <a href=""https://www.tensorflow.org/programmers_guide/variables#sharing_variables"" rel=""nofollow noreferrer"">official Tensorflow tutorial</a> just states ""Explicitly passing tf.Variable objects around"" as one way of sharing variables. Defining variables as class variables should do that in my understanding. I have googled extensively but cannot find a simple example of tensorflow with classes like this. 
In my actual project I fiddled around with variable scope (<code>tf.variable_scope(.., reuse=True)</code>) which still raises me an uninitialized variables warning, which I can only fix by initializing but then the trained variables are reset, of course.</p>

<p>Is the whole class approach like this wrong? How can I simply reuse my variables without a saver or other more complicated structure? And: Where is my understanding of tensorflow variables, graphs and so on, wrong?</p>
",1,Inadequate Examples
142,49370940,One hot encoding characters,"<p>Is there a possibilty to one-hot encode characters of a text in Tensorflow or Keras?</p>

<ul>
<li><code>tf.one_hot</code> seem to take only integers.</li>
<li><code>tf.keras.preprocessing.text.one_hot</code> seems to one-hot encode sentences
to words, but not to characters.</li>
</ul>

<p>Beside that, <code>tf.keras.preprocessing.text.one_hot</code> works really strange, since the response does not really seem one-hot encoded, since the following code:</p>

<pre><code>text = ""ab bba bbd""
res = tf.keras.preprocessing.text.one_hot(text=text,n=3)
print(res)
</code></pre>

<p>Lead to this result:</p>

<pre><code>[1,2,2]
</code></pre>

<p>Every time I run this program, the output is a different 3d vector, sometimes it is <code>[1,1,1]</code> or <code>[2,1,1]</code>. The documentation says, that unicity is not guaranteed, but this seems really senseless to me.</p>
",1,Documentation Ambiguity
143,49405794,Why tensor_summary doesn't work?,"<p>I use <code>tf.summary.tensor_summary</code> in my code, following this: <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/tensor_summary"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/summary/tensor_summary</a></p>

<p>But I didn't see anything new in tensorboard, and tensorboard also printed some warnings:</p>

<pre><code>W0321 12:50:47.244003 Reloader tf_logging.py:121] This summary with tag 'component_3_finalize/wealth_tensor' is oddly not associated with a plugin.
</code></pre>

<p>How to make this work? Do I need install some plugin? I didn't find any docs on this.</p>

<p>UPDATE:</p>

<p>So I here is how I create my summary:</p>

<pre><code>def finalize_graph(self, graph_building_context):
    tf.summary.scalar('loss', loss)

    # the wealth tensor is of shape [B], where B is the batch size at runtime
    tf.summary.scalar('wealth', tf.reduce_mean(wealth))
    # uhmm, this tensor_summary doesn't work yet
    tf.summary.tensor_summary('wealth_tensor', wealth)
</code></pre>

<p>Then I use a <code>MonitoredTrainingSession</code>, by default it will save the summary, and I can see my <code>loss</code> and <code>wealth</code> scalar summry, but not this <code>wealth_tensor</code> summary.</p>
",1,Lack of Alternative Solutions/Documentation
144,49418325,"Use ""tf.contrib.factorization.KMeansClustering""","<p>Referring to this Link, <a href=""https://github.com/tensorflow/tensorflow/issues/17002"" rel=""nofollow noreferrer"">(the Link)</a>
I try to practice using tf.contrib.factorization.KMeansClustering for clustering. The simple codes as follow works okay:</p>

<pre><code>import numpy as np
import tensorflow as tf

# ---- Create Data Sample -----
k = 5
n = 100
variables = 5
points = np.random.uniform(0, 1000, [n, variables])

# ---- Clustering -----
input_fn=lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)
kmeans=tf.contrib.factorization.KMeansClustering(num_clusters=6)
kmeans.train(input_fn=input_fn)
centers = kmeans.cluster_centers()

# ---- Print out -----
cluster_indices = list(kmeans.predict_cluster_index(input_fn))
for i, point in enumerate(points):
  cluster_index = cluster_indices[i]
  print ('point:', point, 'is in cluster', cluster_index, 'centered at', centers[cluster_index])
</code></pre>

<p>My question is why would this ""input_fn"" code does the trick?
If I change the code to this, it will run into an infinite loop. Why??</p>

<pre><code>input_fn=lambda:tf.convert_to_tensor(points, dtype=tf.float32)
</code></pre>

<p>From the document <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeansClustering"" rel=""nofollow noreferrer"">(here)</a>, it seems that train() is expecting argument of input_fn, which is simply a A 'tf.data.Dataset' object , like Tensor(X). So, why do I have to do all these tricky things regarding lambda: tf.train.limit_epochs()?</p>

<p>Can anyone who is familiar with the fundamental of tensorflow estimators help to explain? Many Thanks!</p>
",1,Inadequate Examples
145,49472402,Tensorflow tf.nn.softmax() function performs much better than hand-written softmax,"<p>I'm writing a simple logistic regression with tensorflow. I found out that when using tf.nn.softmax, the algorithm converges much quicker, and in the end the accuracy is higher.
If switched to my own implementation of softmax, the network converges slower, and the end accuracy is not as good.</p>
<p>Here's the code:</p>
<pre><code>SEED = 1025
W = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels], seed=SEED))
b = tf.Variable(tf.zeros([num_labels]))
logits = tf.matmul(train_dataset, W) + b

# My softmax:
y_ = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis=0)
# Tensorflow softmax: 
y_ = tf.nn.softmax(logits)

y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)
loss = -tf.reduce_mean(tf.reduce_sum(train_labels * tf.log(y_clipped), axis=1))
</code></pre>
<p>Using my softmax:</p>
<pre><code>Loss at step 0: 22.213934
Training accuracy: 12.7%
Validation accuracy: 13.2%
Loss at step 100: 12.777291
Training accuracy: 45.3%
Validation accuracy: 45.5%
Loss at step 200: 11.361242
Training accuracy: 48.2%
Validation accuracy: 47.4%
Loss at step 300: 10.658278
Training accuracy: 51.4%
Validation accuracy: 49.7%
Loss at step 400: 9.297832
Training accuracy: 59.2%
Validation accuracy: 56.8%
Loss at step 500: 8.902699
Training accuracy: 62.0%
Validation accuracy: 59.2%
Loss at step 600: 8.681184
Training accuracy: 64.2%
Validation accuracy: 61.0%
Loss at step 700: 8.529438
Training accuracy: 65.8%
Validation accuracy: 62.3%
Loss at step 800: 8.416442
Training accuracy: 66.8%
Validation accuracy: 63.3%
Test accuracy: 70.4%
</code></pre>
<p>Using tensorflow's softmax:</p>
<pre><code>Loss at step 0: 13.555875
Training accuracy: 12.7%
Validation accuracy: 14.5%
Loss at step 100: 2.194562
Training accuracy: 72.5%
Validation accuracy: 72.0%
Loss at step 200: 1.808641
Training accuracy: 75.5%
Validation accuracy: 74.5%
Loss at step 300: 1.593390
Training accuracy: 76.8%
Validation accuracy: 75.0%
Loss at step 400: 1.442661
Training accuracy: 77.7%
Validation accuracy: 75.2%
Loss at step 500: 1.327751
Training accuracy: 78.2%
Validation accuracy: 75.4%
Loss at step 600: 1.236314
Training accuracy: 78.5%
Validation accuracy: 75.6%
Loss at step 700: 1.161479
Training accuracy: 78.9%
Validation accuracy: 75.6%
Loss at step 800: 1.098717
Training accuracy: 79.4%
Validation accuracy: 75.8%
Test accuracy: 83.3%
</code></pre>
<p>From the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/softmax"" rel=""nofollow noreferrer"">documentation</a>, in theory tensorflow's softmax should be exact the same as I implemented, no?</p>
<blockquote>
<p>This function performs the equivalent of</p>
<p>softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)</p>
</blockquote>
<p><strong>EDIT:</strong> I added a seed when initializing from normal distribution, now I can reproduce the accuracy results.
When setting axis value in &quot;My softmax&quot; line, only axis=0 doesn't result in error. Setting axis=1 or axis=-1 both results in this error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 10 and 10000 for 'truediv' (op: 'RealDiv') with input shapes: [10000,10], [10000].
</code></pre>
",1,Documentation Replicability
146,49494632,How can we do tf.tile with extra dimensions in the output?,"<p>Suppose I have a <code>tensor = tf.constant([1, 2])</code>, what's the best way of creating a tensor of <code>[[tensor, tensor], [tensor, tensor]]</code>, which is <code>[[[1, 2], [1, 2]], [[1, 2], [1, 2]]]</code>?</p>

<p>The use case looks similar to <code>tf.tile</code>. However, <code>tf.tile</code> does not create the extra dimensions.</p>
",1,Documentation Replicability
147,49542954,What are tf.TensorArray objects?,"<p>I am not able to get an understanding of <a href=""https://www.tensorflow.org/api_docs/python/tf/TensorArray"" rel=""nofollow noreferrer"">tf.TensorArray</a> objects. What are they and where are they needed? I have some (highly likely faulty) understanding -
 they are used in while_loops especially to write the information to the loop_state. If somehow we end up increasing the number of tensors or their dimensions across iterations it throws back an error. hence normal way to pass the loop_state across iterations collecting information from each iteration, which would be passing a list, would throw back an error. So we create tf.TensorArray objects and write the information to them at each iteration and pass these tf.TensorArray objects across loops and for some reason that way it is able to pass through</p>

<p>I couldnt find any blog or documentation explaining the working of a tf.TensorArray objects and documentation doesn't help much either</p>

<p>So, if this is not the best place to be asking this question, kindly direct me to nearest help.</p>
",1,Lack of Alternative Solutions/Documentation
148,49564318,Issue with fine-tuning inceptionv3 in slim tensorflow and tf record batches,"<p>I am trying to fine-tune inceptionv3 model using slim tensorflow library. 
I am unable to understand certain things while writing the code for it. I tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the check point. Here are the steps I followed 
 1. I created a tf.record for my training data which is fine, now I am reading the data using the below code. </p>

<pre><code>import tensorflow as tf
import tensorflow.contrib.slim.nets as nets
import tensorflow.contrib.slim as slim
import matplotlib.pyplot as plt
import numpy as np

# get the data and labels here

data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'

# Training setting
num_epochs = 100
initial_learning_rate = 0.0002
learning_rate_decay_factor = 0.7
num_epochs_before_decay = 5
num_classes = 5980

# load the checkpoint
model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'

# log directory
log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'

with tf.Session() as sess:
    feature = {'train/image': tf.FixedLenFeature([], tf.string),
               'train/label': tf.FixedLenFeature([], tf.int64)}

    # Create a list of filenames and pass it to a queue
    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)

    # Define a reader and read the next record
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)

    # Decode the record read by the reader
    features = tf.parse_single_example(serialized_example, features=feature)

    # Convert the image data from string back to the numbers
    image = tf.decode_raw(features['train/image'], tf.float32)

    # Cast label data into int32
    label = tf.cast(features['train/label'], tf.int32)

    # Reshape image data into the original shape
    image = tf.reshape(image, [128, 128, 3])

    # Creates batches by randomly shuffling tensors
    images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,
                                            min_after_dequeue=64)
</code></pre>

<p>Now I am finetuning the model using slim and this is the code. </p>

<pre><code>  init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
    sess.run(init_op)

    # Create a coordinator and run all QueueRunner objects
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    # load model

    # load the inception model from the slim library - we are using inception v3
    #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))

    img, lbl = sess.run([images, labels])
    one_hot_labels = slim.one_hot_encoding(lbl, num_classes)

    with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):
        logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,
                                                          dropout_keep_prob=.6)

    # Restore convolutional layers:

    variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])
    init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)

    # loss function
    loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)
    total_loss = tf.losses.get_total_loss()

    # train operation
    train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))

    print('Im here')
    # Start training.
    slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)
</code></pre>

<p>Now I have few questions about the code, which I am quite unable to figure out. Once, the code reaches <strong>slim.learning.train</strong> I don't see anything printing however, it's training, I can see in the log. Now, 
1. How do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.<br>
2. How do I make sure that in the code <strong>tf.train.shuffle_batch</strong> I am not repeating my images and I am training over the whole dataset? 
3. How can I print the loss values while it's training?</p>
",1,Documentation Replication on Other Examples
149,49605330,Example of tf.feature_column.indicator_column,"<p>I’m reading tensorflow’s document about <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column"" rel=""nofollow noreferrer"">tf.feature_column.indicator_column</a>.</p>

<p>In this document, there is an example.</p>

<pre><code>name = indicator_column(categorical_column_with_vocabulary_list(
       'name', ['bob', 'george', 'wanda'])
columns = [name, ...]
features = tf.parse_example(..., features=make_parse_example_spec(columns))
dense_tensor = input_layer(features, columns)

dense_tensor == [[1, 0, 0]]  # If ""name"" bytes_list is [""bob""]
dense_tensor == [[1, 0, 1]]  # If ""name"" bytes_list is [""bob"", ""wanda""]
dense_tensor == [[2, 0, 0]]  # If ""name"" bytes_list is [""bob"", ""bob”]
</code></pre>

<p>My problem is the omitted(<code>...</code>) part of this code. I just want a complete, running, simple example. And I can’t find a kind example including tf.Example and so on.</p>

<p>Can anyone make this complete?</p>

<p>Thank you for advance.</p>
",1,Documentation Completeness
150,49662470,Tensorflow global_step TypeError,"<p>I'm adding Tensorboard to an existing small Tensorflow project that I know works to practice working with Tensorboard but I get a type error that global_step must be a string or tensor, however I have assigned global_step to a <code>tf.Variable(0, name='global_step', trainable=False)</code> just like the documentation and every example I see online. Any idea of what I'm missing would be super appreciated. </p>



<p>---> 70             [summary_merge, tf.train.global_step(sess, global_step_tensor) ,update_model, weights], feed_dict)</p>

<p>TypeError: Fetch argument 0 has invalid type , must be a string or Tensor. (Can not convert a int into a Tensor or Operation.)</p>

<pre class=""lang-python prettyprint-override""><code>import gym
import numpy as np
import random
import ipdb
import matplotlib.pyplot as plt
import tensorflow as tf
%matplotlib inline

tf.reset_default_graph()
env = gym.make('FrozenLake-v0')

global_step_tensor = tf.Variable(0, name='global_step', trainable=False)
saver = tf.train.Saver()

with tf.name_scope('policy-network'):
    observations = tf.placeholder(shape=[1, env.observation_space.n], dtype=tf.float32, name='input')
    weights = tf.Variable(tf.random_uniform([16,4], 0, 0.01))
    Qout = tf.matmul(observations, weights)
    predict = tf.argmax(Qout, 1)

    nextQ = tf.placeholder(shape=[1, 4], dtype=tf.float32)
    loss = tf.reduce_sum(tf.square(nextQ - Qout))
    trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)
    update_model = trainer.minimize(loss, global_step= global_step_tensor)

with tf.name_scope('summaries'):
    summary_merge = tf.summary.merge([
        tf.summary.histogram('loss', loss),
        tf.summary.histogram('weights', weights)
    ])


init = tf.global_variables_initializer()

gamma = .99
epsilon = 0.1
num_episodes = 2000

j_list = []
r_list = []

with tf.Session() as sess:
    # Create a writer for summary data
    writer = tf.summary.FileWriter('/tmp/display', sess.graph)
    sess.run(init)
    for i in range(num_episodes):
        s = env.reset()
        reward_all = 0
        done = False
        j = 0

        while j &lt; 99:
            j+= 1

            a, allQ = sess.run([predict, Qout], feed_dict={observations:np.identity(16)[s:s+1]})
            if np.random.rand(1) &lt; epsilon:
                a[0] = env.action_space.sample()

            s1, reward, done, _ = env.step(a[0])
            Q1 = sess.run(Qout, feed_dict={observations: np.identity(16)[s1:s1+1]}) 

            maxQ1 = np.max(Q1)
            targetQ = allQ

            targetQ[0, a[0]] = reward + gamma*maxQ1
            feed_dict = {observations: np.identity(16)[s:s+1], nextQ:targetQ}

            # Run prediction operation, evaluate summary_merge and assign to summaries
            summaries, global_step_tensor, _, W1 = sess.run(
            [summary_merge, tf.train.global_step(sess, global_step_tensor) ,update_model, weights], feed_dict)

            # Write summaries to writer
            writer.add_summary(summaries, global_step)

            reward_all += reward
            s = s1

            if done == True:
                epsilon = 1./((i/50) + 10)
                break

        if (i+1) % 1000 == 0:
            # Save the graph every 1000 episodes
            saver.save(sess, '/tmp/checkpoint', global_step=global_step)

        j_list.append(j)
        r_list.append(reward_all)

print(""Percent of succesful episodes: {} %"".format((sum(r_list)/num_episodes)))
</code></pre>
",1,Lack of Alternative Solutions/Documentation
151,49686860,Side effect in tf.while_loop,"<p>I am currently having a hard time trying to understand how tensorflow works, and I feel like the python interface is somehow obscure.</p>

<p>I recently tried to run a simple print statement inside a tf.while_loop, and there are many things that remains unclear to me:</p>

<pre><code>import tensorflow as tf

nb_iter = tf.constant(value=10)
#This solution does not work at all
#nb_iter = tf.get_variable('nb_iter', shape=(1), dtype=tf.int32, trainable=False)
i = tf.get_variable('i', shape=(), trainable=False,
                     initializer=tf.zeros_initializer(), dtype=nb_iter.dtype)

loop_condition = lambda i: tf.less(i, nb_iter)
def loop_body(i):
    tf.Print(i, [i], message='Another iteration')
    return [tf.add(i, 1)]

i = tf.while_loop(loop_condition, loop_body, [i])

initializer_op = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(initializer_op)
    res = sess.run(i)
    print('res is now {}'.format(res))
</code></pre>

<p>Notice that if I initialize nb_iter with</p>

<pre><code>nb_iter = tf.get_variable('nb_iter', shape=(1), dtype=tf.int32, trainable=False)
</code></pre>

<p>I got the following error:</p>

<blockquote>
  <p>ValueError: Shape must be rank 0 but is rank 1 for 'while/LoopCond'
  (op: 'LoopCond') with input shapes: [1].</p>
</blockquote>

<p>It get even worse when I try to use the 'i' index for indexing a tensor (example not shown here), I then get the following error</p>

<blockquote>
  <p>alueError: Operation 'while/strided_slice' has been marked as not
  fetchable.</p>
</blockquote>

<p>Can someone point me to a documentation that explains how tf.while_loop works when used with tf.Variables, and if it possible to use side_effects (like print) inside the loop, as well as indexing tensor with the loop variable ?</p>

<p>Thank you in advance for your help</p>
",1,Requesting (Additional) Documentation/Examples
152,49688134,TensorFlow session inside Keras custom loss function,"<p>After going through some Stack questions and the Keras documentation, I manage to write some code trying to evaluate the gradient of the output of a neural network w.r.t its inputs, the purpose being a simple exercise of approximating a bivariate function (<code>f(x,y) = x^2+y^2</code>)  using as loss the difference between analytical and automatic differentiation.</p>

<p>Combining answers from two questions (<a href=""https://stackoverflow.com/questions/46464549"">Keras custom loss function: Accessing current input pattern
</a> and <a href=""https://stackoverflow.com/questions/39561560"">Getting gradient of model output w.r.t weights using Keras
</a>), I came up with this:</p>

<pre><code>import tensorflow as tf
from keras import backend as K
from keras.models import Model
from keras.layers import Dense, Activation, Input

def custom_loss(input_tensor):

    outputTensor = model.output       
    listOfVariableTensors = model.input      
    gradients = K.gradients(outputTensor, listOfVariableTensors)

    sess = tf.InteractiveSession()
    sess.run(tf.initialize_all_variables())
    evaluated_gradients = sess.run(gradients,feed_dict={model.input:input_tensor})

    grad_pred = K.add(evaluated_gradients[0], evaluated_gradients[1])
    grad_true = k.add(K.scalar_mul(2, model.input[0][0]), K.scalar_mul(2, model.input[0][1])) 

    return K.square(K.subtract(grad_pred, grad_true))

input_tensor = Input(shape=(2,))
hidden = Dense(10, activation='relu')(input_tensor)
out = Dense(1, activation='sigmoid')(hidden)
model = Model(input_tensor, out)
model.compile(loss=custom_loss_wrapper(input_tensor), optimizer='adam')
</code></pre>

<p>Which yields the error: <code>TypeError: The value of a feed cannot be a tf.Tensor object.</code> because of <code>feed_dict={model.input:input_tensor}</code>. I understand the error, I just don't know how to fix it. </p>

<p>From what I gathered, I can't simply pass input data into the loss function, it must be a tensor. I realized Keras would 'understand' it when I call <code>input_tensor</code>. This all just leads me to think I'm doing things the wrong way, trying to evaluate the gradient like that. Would really appreciate some enlightenment.</p>
",1,Documentation Replicability
153,49701918,tf.layers.batch_normalization parameters,"<p>I am not sure if it is only me who thinks that tensorflow documentation is a bit weak.</p>

<p>I was planing to use the tf.nn.batch_normalization function to implement batch normalization but later recognized the  tf.layers.batch_normalization function which seemingly should be the one to use for its simplicity. But the documentation is really poor if I may say it.</p>

<p>I am trying to understand how to <em>correctly</em> use it but with the information provided on the Web page is it really not easy. I am hoping that maybe some other people have experience and help me (and possibly many others) to understand it.. </p>

<p>Let me share the interface first:</p>

<pre><code>tf.layers.batch_normalization(
    inputs,
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer=tf.zeros_initializer(),
    gamma_initializer=tf.ones_initializer(),
    moving_mean_initializer=tf.zeros_initializer(),
    moving_variance_initializer=tf.ones_initializer(),
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    training=False,
    trainable=True,
    name=None,
    reuse=None,
    renorm=False,
    renorm_clipping=None,
    renorm_momentum=0.99,
    fused=None,
    virtual_batch_size=None,
    adjustment=None
)
</code></pre>

<p>Q1) beta values are initialized to zero and gamma values are initialized to 1. But it does not say why. When batch normalization used, I understand that the ordinary bias parameter of the neural network becomes obsolete and beta parameter in the batch normalization step kind of does the same thing. From that angle, setting beta to zero is understandable. But why are gamma values initialized to 1? Is that really the most efficient way?</p>

<p>Q2) I see a momentum parameter there as well. The documentation just says "" Momentum for the moving average."". I assume that this parameter is used when calculating the ""mean"" value for a certain mini batch in the corresponding hidden layer. With other words, the mean value used in batch normalization is NOT the mean of current mini batch, it is rather primarily the mean of the last 100 mini batches (since momentum = 0.99). But it is very unclear how this parameter affects the execution in testing, or if I am just validating my model on the dev set by calculating cost and accuracy. My <em>assumption</em> is that anytime I deal with test and dev sets, I set the parameter ""training"" to False so that momentum parameter becomes obsolete for that particular execution and the ""mean"" and ""variance"" values that were calculated during the training are used now instead of calculating new mean and variance values. It is how it should be if I am mistaken but I do not see anything in the documentation if it is the case. Could anyone confirm that my understanding correct? If not, I would really appreciate further explanation on this.</p>

<p>Q3) I am having difficulties to give a meaning to the trainable parameter. I assume beta and gamma params are meant here. Why would they not be trainable?</p>

<p>Q4) The ""reuse"" parameter. What is it really?</p>

<p>Q5) adjustment parameter. Another mistery..</p>

<p>Q5) A kind of summary question.. Here is my overall assumption that needs confirmation and feedback.. Important params here are:
- inputs
- axis
- momentum
- center
- scale
- training
And I assume that as long as the training=True when training, we are safe. And as long as training=False when validating dev set or test set or even when using the model in real life, we are safe too.</p>

<p>Any feedback will really be appreciated.</p>

<p>ADDENDUM:</p>

<p>Confusion continues. Help!</p>

<p>I am trying to use this function instead of implementing a batch normalizer manually. I have the following forward propagation function that loops through layers of the NN.</p>

<pre><code>def forward_propagation_with_relu(X, num_units_in_layers, parameters, 
                                  normalize_batch, training, mb_size=7):

    L = len(num_units_in_layers)

    A_temp = tf.transpose(X)

    for i in range (1, L):
        W = parameters.get(""W""+str(i))
        b = parameters.get(""b""+str(i))
        Z_temp = tf.add(tf.matmul(W, A_temp), b)

        if normalize_batch:
            if (i &lt; (L-1)):  
                with tf.variable_scope(""batch_norm_scope"", reuse=tf.AUTO_REUSE):
                    Z_temp = tf.layers.batch_normalization(Z_temp, axis=-1, 
                                                           training=training)

        A_temp = tf.nn.relu(Z_temp)

    return Z_temp   #This is the linear output of last layer
</code></pre>

<p>The tf.layers.batch_normalization(..) function wants to have static dimensions but I do not have it in my case.</p>

<p>Since I apply mini batches rather than training the entire train set each time before I run the optimizer, 1 dimension of the X appears to be unknown.</p>

<p>If I write:</p>

<pre><code>print(X.shape)
</code></pre>

<p>I get:</p>

<pre><code>(?, 5)
</code></pre>

<p>And when this is the case, when I run the whole program I get the following error below.</p>

<p>I saw in some other threads that some people say that they could solve the problem by using tf.reshape function. I try it.. Forward prop goes fine but later on it crashes in the Adam Optimizer..</p>

<p>Here is what I get when I run the code above (without using tf.reshape):</p>

<p>How do I solve this???</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-191-990fb7d7f7f6&gt; in &lt;module&gt;()
     24 parameters = nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs,
     25                       normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers,
---&gt; 26                       lambd, print_progress)
     27 
     28 print(parameters)

&lt;ipython-input-190-59594e979129&gt; in nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs, normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers, lambd, print_progress)
     34         # Forward propagation: Build the forward propagation in the tensorflow graph
     35         ZL = forward_propagation_with_relu(X_mini_batch, num_units_in_layers, 
---&gt; 36                                            parameters, normalize_batch, training)
     37 
     38     with tf.name_scope(""calc_cost""):

&lt;ipython-input-187-8012e2fb6236&gt; in forward_propagation_with_relu(X, num_units_in_layers, parameters, normalize_batch, training, mb_size)
     15                 with tf.variable_scope(""batch_norm_scope"", reuse=tf.AUTO_REUSE):
     16                     Z_temp = tf.layers.batch_normalization(Z_temp, axis=-1, 
---&gt; 17                                                            training=training)
     18 
     19         A_temp = tf.nn.relu(Z_temp)

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py in batch_normalization(inputs, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, training, trainable, name, reuse, renorm, renorm_clipping, renorm_momentum, fused, virtual_batch_size, adjustment)
    775       _reuse=reuse,
    776       _scope=name)
--&gt; 777   return layer.apply(inputs, training=training)
    778 
    779 

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)
    805       Output tensor(s).
    806     """"""
--&gt; 807     return self.__call__(inputs, *args, **kwargs)
    808 
    809   def _add_inbound_node(self,

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    676           self._defer_regularizers = True
    677           with ops.init_scope():
--&gt; 678             self.build(input_shapes)
    679           # Create any regularizers added by `build`.
    680           self._maybe_create_variable_regularizers()

~/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py in build(self, input_shape)
    251       if axis_to_dim[x] is None:
    252         raise ValueError('Input has undefined `axis` dimension. Input shape: ',
--&gt; 253                          input_shape)
    254     self.input_spec = base.InputSpec(ndim=ndims, axes=axis_to_dim)
    255 

ValueError: ('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(6), Dimension(None)]))
</code></pre>

<p>This is so hopeless.. </p>

<p>ADDENDUM(2)</p>

<p>I am adding more information:</p>

<p>The following simply means that there are 5 units in input layer, 6 units in each hidden layer, and 2 units in output layer.</p>

<pre><code>num_units_in_layers = [5,6,6,2] 
</code></pre>

<p>Here is the updated version of forward prop function with tf.reshape</p>

<pre><code>def forward_propagation_with_relu(X, num_units_in_layers, parameters, 
                                  normalize_batch, training, mb_size=7):

    L = len(num_units_in_layers)
    print(""X.shape before reshape: "", X.shape)             # ADDED LINE 1
    X = tf.reshape(X, [mb_size, num_units_in_layers[0]])   # ADDED LINE 2
    print(""X.shape after reshape: "", X.shape)              # ADDED LINE 3
    A_temp = tf.transpose(X)

    for i in range (1, L):
        W = parameters.get(""W""+str(i))
        b = parameters.get(""b""+str(i))
        Z_temp = tf.add(tf.matmul(W, A_temp), b)

        if normalize_batch:
            if (i &lt; (L-1)):  
                with tf.variable_scope(""batch_norm_scope"", reuse=tf.AUTO_REUSE):
                    Z_temp = tf.layers.batch_normalization(Z_temp, axis=-1, 
                                                           training=training)

        A_temp = tf.nn.relu(Z_temp)

    return Z_temp   #This is the linear output of last layer
</code></pre>

<p>When I do this, I can run the forward prop function. But it seems to be crashing in later execution. Here is the error that I get. (Note that I print out the shape of input X before and after reshaping in the forward prop function).</p>

<pre><code>X.shape before reshape:  (?, 5)
X.shape after reshape:  (7, 5)

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1349     try:
-&gt; 1350       return fn(*args)
   1351     except errors.OpError as e:

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1328                                    feed_dict, fetch_list, target_list,
-&gt; 1329                                    status, run_metadata)
   1330 

~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    515             compat.as_text(c_api.TF_Message(self.status.status)),
--&gt; 516             c_api.TF_GetCode(self.status.status))
    517     # Delete the underlying status object from memory otherwise it stays alive

InvalidArgumentError: Incompatible shapes: [7] vs. [2]
     [[Node: forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub = Sub[T=DT_FLOAT, _class=[""loc:@batch_norm_scope/batch_normalization/moving_mean""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](forward_prop/batch_norm_scope/batch_normalization/cond_2/Switch_1:1, forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:1)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-222-990fb7d7f7f6&gt; in &lt;module&gt;()
     24 parameters = nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs,
     25                       normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers,
---&gt; 26                       lambd, print_progress)
     27 
     28 print(parameters)

&lt;ipython-input-221-59594e979129&gt; in nn_model(train_input_paths, dev_input_paths, test_input_paths, learning_rate, num_train_epochs, normalize_batch, epoch_period_to_save_cost, minibatch_size, num_units_in_layers, lambd, print_progress)
     88                                                                         cost_mini_batch,
     89                                                                         accuracy_mini_batch],
---&gt; 90                                                                         feed_dict={training: True})
     91                       nr_of_minibatches += 1
     92                       sum_minibatch_costs += minibatch_cost

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    893     try:
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 895                          run_metadata_ptr)
    896       if run_metadata:
    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1126     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1127       results = self._do_run(handle, final_targets, final_fetches,
-&gt; 1128                              feed_dict_tensor, options, run_metadata)
   1129     else:
   1130       results = []

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1342     if handle is None:
   1343       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-&gt; 1344                            options, run_metadata)
   1345     else:
   1346       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1361         except KeyError:
   1362           pass
-&gt; 1363       raise type(e)(node_def, op, message)
   1364 
   1365   def _extend_graph(self):

InvalidArgumentError: Incompatible shapes: [7] vs. [2]
     [[Node: forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub = Sub[T=DT_FLOAT, _class=[""loc:@batch_norm_scope/batch_normalization/moving_mean""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](forward_prop/batch_norm_scope/batch_normalization/cond_2/Switch_1:1, forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:1)]]

Caused by op 'forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub', defined at:
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py"", line 16, in &lt;module&gt;
    app.launch_new_instance()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 478, in start
    self.io_loop.start()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2850, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/cesncn/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""&lt;ipython-input-222-990fb7d7f7f6&gt;"", line 26, in &lt;module&gt;
    lambd, print_progress)
  File ""&lt;ipython-input-221-59594e979129&gt;"", line 36, in nn_model
    parameters, normalize_batch, training)
  File ""&lt;ipython-input-218-62e4c6126c2c&gt;"", line 19, in forward_propagation_with_relu
    training=training)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 777, in batch_normalization
    return layer.apply(inputs, training=training)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 807, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py"", line 697, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 602, in call
    lambda: self.moving_mean)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/utils.py"", line 211, in smart_cond
    return control_flow_ops.cond(pred, true_fn=fn1, false_fn=fn2, name=name)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1985, in cond
    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1839, in BuildCondBranch
    original_result = fn()
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 601, in &lt;lambda&gt;
    lambda: _do_update(self.moving_mean, new_mean),
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/layers/normalization.py"", line 597, in _do_update
    var, value, self.momentum, zero_debias=False)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py"", line 87, in assign_moving_average
    update_delta = (variable - value) * decay
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 778, in _run_op
    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 934, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4819, in _sub
    ""Sub"", x=x, y=y, name=name)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3267, in create_op
    op_def=op_def)
  File ""/home/cesncn/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Incompatible shapes: [7] vs. [2]
     [[Node: forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub = Sub[T=DT_FLOAT, _class=[""loc:@batch_norm_scope/batch_normalization/moving_mean""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](forward_prop/batch_norm_scope/batch_normalization/cond_2/Switch_1:1, forward_prop/batch_norm_scope/batch_normalization/cond_2/AssignMovingAvg/sub/Switch_1:1)]]
</code></pre>

<p>Regarding the question why the shape of X is not static.. I don't know...
HEre is how I setup the dataset.</p>

<pre><code>with tf.name_scope(""next_train_batch""):
    filenames = tf.placeholder(tf.string, shape=[None])
    dataset = tf.data.Dataset.from_tensor_slices(filenames)
    dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(minibatch_size)
    iterator = dataset.make_initializable_iterator()
    X_mini_batch, Y_mini_batch = iterator.get_next()
</code></pre>

<p>I have 2 csv files that include the train data.</p>

<pre><code>train_path1 = ""train1.csv""
train_path2 = ""train2.csv""
train_input_paths = [train_path1, train_path2]
</code></pre>

<p>And I use the initializable iterator as following:</p>

<pre><code>sess.run(iterator.initializer, 
         feed_dict={filenames: train_input_paths})
</code></pre>

<p>During the training, I keep getting mini batches from the train set. Everything works fine when I disable batch normalization. If I enable batch norm, it requires static shape of the input X (mini batch). I reshape it but this time it crashes later in the execution as seen above. </p>

<p>ADDENDUM(3)</p>

<p>I guess I figured out where it crashes. It probably crashes when I run the optimizer after calculating the cost.</p>

<p>First the sequence of commands:
First forward prop, then compute cost, then run optimizer. First 2 seems to be working but not the optimizer.</p>

<p>HEre is how I define the optimizer:</p>

<pre><code>with tf.name_scope(""train""):
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):        
        # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.
        optimizer =  tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_mini_batch)
</code></pre>

<p>I have the update_ops there to be able to update the moving averages. If I interpret it right, it is just crashing when it tries to update moving averages. I might be misinterpreting the error msg as well.. </p>

<p>ADDENDUM(4)</p>

<p>I tried to normalize based on the known dimension and it worked! But that's not the dimension I would like to normalize, which is now confusing. Let me elaborate:</p>

<p>nr of units in input layer: 5
nr of units in layer 1 (first hidden layer): 6
so weight1 is (6, 5) matrix
Assume that mini batch size is 7.
Shape of A[0] (or X_mini_batch) in my case is: (7, 5), where 7 is the # training samples in mini batch, and 5 is the # units in input layer.</p>

<p>When calculating Z[1]...
Z[1] = weight1 * A[0].transpose
... then shape of Z[1] is (6, 7) matrix, where each column gives 6 features for each train sample.</p>

<p>The question is then which column do we want to normalize in Z[1]? What makes sense to me is that you normalize each feature from all given train samples. This means that I need to normalize each row bcz I have different feature values for different train examples in each row. And since Z[1] has the shape (6, 7), if I set axis=0, it should refer to normalization in each row. And 7 is the unknown number in my case so it doesn't hurt. Based on this logic, it works! But I am totally puzzled if axis=0 really refers to each row here... Let me show another example about this axis issue, which has bothered me for a long time now..</p>

<p>The <em>irrelevant from this topic</em> code example:</p>

<pre><code>cc = tf.constant([[1.,2.,3.], 
                  [4.,5.,6.]])

with tf.Session() as sess:
    print(sess.run(tf.reduce_mean(cc, axis=0)))
    print(sess.run(tf.reduce_mean(cc, axis=1)))  
</code></pre>

<p>This gives the following output:</p>

<pre><code>[2.5 3.5 4.5]
[2. 5.]
</code></pre>

<p>When I set axis to 0, it is giving the average of each column. And if axis=1, it is giving the average of each row.</p>

<p>(Note that cc.shape gives (2,3))</p>

<p>Now the million dollar question: In a 2 dimensional matrix, is axis 0 or 1 when I want to address each row?</p>

<p>ADDENDUM(5)
I guess I get it now correctly. Let me summarize my axis understanding here. Hopefully I am getting it right now...</p>

<p>Here is the Z[1] matrix representation with the shape (6,7):</p>

<p>t_ex :   train example
f:       feature</p>

<pre><code>t_ex1   t_ex2   t_ex3   t_ex4   t_ex5   t_ex6   t_ex7
  f1      f1      f1      f1      f1      f1      f1
  f2      f2      f2      f2      f2      f2      f2
  f3      f3      f3      f3      f3      f3      f3
  f4      f4      f4      f4      f4      f4      f4
  f5      f5      f5      f5      f5      f5      f5
  f6      f6      f6      f6      f6      f6      f6
</code></pre>

<p>In this mini batch above, there are 7 train examples and each train ex has 6 features (since there are 6 units in layer 1). When we say ""tf.layers.batch_normalization(..,axis=0)"", we mean that the normalization has to be done per row for each feature to eliminate the high variance between - say - f1 values in the first row.</p>

<p>With other words, we do NOT normalize f1,f2,f3,f4,f5,f6 with each other. We normalize f1:s with each other, and f2:s with each other, and so on..</p>
",1,Lack of Alternative Solutions/Documentation
154,49745029,How to use Distributed Tensorflow on remote machines?,"<p>I am trying to run a distributed Tensorflow script across three machines: my local machine running the parameter server and two remote machines I have access to running worker jobs. I am following <a href=""https://www.tensorflow.org/deploy/distributed#putting_it_all_together_example_trainer_program"" rel=""nofollow noreferrer"">this example</a> from the Tensorflow documentation, passing the IP addresses and unique port numbers to each worker job, and setting the <code>protocol</code> option in <code>tf.train.Server</code> to <code>'grpc'</code>. However, when I run the script, all three processes are started on my localhost, and none of the jobs are on the remote machines. Is there a step I am missing? </p>

<p>My (abridged) code:</p>

<pre><code># Define flags
tf.app.flags.DEFINE_string(""ps_hosts"", ""localhost:2223"", 
                        ""comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", 
""server1.com:2224,server2.com:2225"",
                        ""comma-separated list of hostname:port pairs"")

tf.app.flags.DEFINE_string(""job_name"", ""worker"", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

ps_hosts = FLAGS.ps_hosts.split("","")
worker_hosts = FLAGS.worker_hosts.split("","")

cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})
server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index, protocol='grpc')

if FLAGS.job_name == ""ps"":
    server.join()
elif FLAGS.job_name == ""worker"":
    # Between-graph replication
    with tf.device(tf.train.replica_device_setter(cluster=cluster, worker_device=""/job:worker/task:{}"".format(FLAGS.task_index))):
        # Create model...
        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                                 logdir=""./checkpoint"",
                                 init_op=init_op,
                                 summary_op=summary,
                                 saver=saver,
                                 global_step=global_step,
                                 save_model_secs=600)

        with sv.managed_session(server.target, 
                                 config=config_proto) as sess:
            # Train model...
</code></pre>

<p>This code causes two problems:</p>

<ol>
<li>Both of the worker jobs give errors about not getting a response from the other:</li>
</ol>

<p>From worker0:</p>

<pre><code>2018-04-09 23:48:39.749679: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
</code></pre>

<p>From worker1:</p>

<pre><code>2018-04-09 23:49:30.439166: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
</code></pre>

<ol start=""2"">
<li>I can get rid of the earlier problem by using a <code>device_filter</code>, but all jobs are started on my local machine, and not on the remote servers. </li>
</ol>

<p>How do I get the two worker jobs to run on the remote servers?</p>
",1,Documentation Replication on Other Examples
155,49746064,What is the difference between tf.nn.ctc_beam_search_decoder and tf.contrib.seq2seq.BeamSearchDecoder mechanism?,"<p>I am building a seq2seq model with tensorflow.
Can you explain the details of the two beam search functions?
Thank you.</p>

<p>tf.nn.ctc.beam_search_decoder
<a href=""https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder</a></p>

<p>tf.contrib.seq2seq.BeamSearchDecoder
<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BeamSearchDecoder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BeamSearchDecoder</a></p>
",1,Documentation Replicability
156,49765437,Tensorflow Type Error,"<p>Getting strange type error with TensorFlow code:</p>

<pre><code>curMaxAbs = tf.Variable(-1.0, tf.float32)
maxi = tf.Variable(-1, tf.int32)
for i, g in enumerate(grads):
    maxG = tf.reduce_max(tf.abs(g))            
    oCurMaxAbs = curMaxAbs            
    curMaxAbs = tf.cond(tf.greater(maxG,oCurMaxAbs),
                        lambda: maxG,
                        lambda: oCurMaxAbs)
    maxi = tf.cond(tf.greater(maxG,oCurMaxAbs),
                   lambda: maxi,
                   lambda: i)
</code></pre>

<p>Getting the error for line <code>if not tf.equal(curMaxAbs,tf.maximum(curMaxAbs, maxG))</code></p>

<blockquote>
  <p>TypeError: Input 'y' of 'Maximum' Op has type float32 that does not
  match type int32 of argument 'x'</p>
</blockquote>

<p>How in the world could <code>curMaxAbs</code> have type <code>int32</code>, when it is only reassigned with the <code>curMaxAbs = tf.maximum(curMaxAbs, maxG)</code> statement, and the <code>tf.maximum</code> function returns the same type as the first argument? (per <a href=""https://www.tensorflow.org/api_docs/python/tf/maximum"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/maximum</a>).</p>
",1,Documentation Replication on Other Examples
157,49768997,Writing TFRecords in batches,"<p>All documentations I found regarding TFRecords are generating <code>tf.train.Example()</code>s one by one, and writing them using</p>

<pre><code>writer = tf.python_io.TFRecordWrite(path)
ex = generate_example(features)  # Returns tf.train.Example() instance
writer.write(ex.SerializeToString())
</code></pre>

<p>Since I'm dealing with very big data, I know that I'll pay a high overhead price for writing examples separately</p>

<p>Is there any way to write multiple <code>tf.train.Example()</code> to a TFRecord at once?</p>
",1,Documentation Replication on Other Examples
158,49785239,TensorFlow.constant() throws TypeError with placeholder parameter (TF v1.4),"<p>Python host language. TF v1.4.</p>

<p><a href=""https://www.tensorflow.org/versions/r1.4/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.4/api_docs/python/tf/constant</a></p>

<p>Nearly just like docs example (above), I need to make a constant 2-D tensor populated with scalar value, in my case some mean value, which is mean of r, but r is a placeholder, not a variable, NOT a numpy array. As such, feed_dict needs to be used to fill-in placeholder r in my application.  Now a python ndarray or some python list was used in the docs example, which won't work in my application, so that's the difference.</p>

<p>In my application, global_bias (below) needs to be a tf.constant not a tf.variable -- because what I'm saying is, the optimizer needs to not learn it. Just leave it be, please.</p>

<p>Note: In my application, r is a placeholder not a variable.</p>

<pre><code>#global_bias_value = tf.reduce_mean(r)    # tf.constant() FAILS (below)
global_bias_value = 87. # tf.constant() runs OK (below)
global_bias = tf.constant(global_bias_value, shape=(I,J)) #TypeError: List of Tensors when single Tensor expected
rhat = global_bias + fm
</code></pre>

<p>So, as I said, what TF code would be used to make a constant 2-D tensor populated with scalar value, in my case some mean value, which is mean of r, but r is a placeholder, not a variable, NOT a numpy array?</p>

<p>Hey I tried .eval() but TF said you need a session to do that. So are you TF folks saying I need 2 sessions, run sequentially, just to do this little thing?  Or else are you saying I should bypass feed_dict to feed in my r placeholder actual data via numpy arrays in through the side door (in app memory as a python list or ndarray) plus the front door (feed_dict), which would be janky?  </p>

<p>Thanks for clues!   I need to get one.</p>
",1,Documentation Replicability
159,49899526,Tensorflow input pipeline where multiple rows correspond to a single observation?,"<p>So I've just started using Tensorflow, and I'm struggling to properly understand input pipelines. </p>

<p>The problem I'm working on is sequence classification.
I'm trying to read in a CSV file with shape (100000, 4). First 3 columns are features, 4th column is the label. BUT - the data represents sequences of length 10 i.e. rows 1-10 are sequence 1, rows 11-20 are sequence 2 etc. This also means each label is repeated 10 times.</p>

<p>So at some point in this input pipeline, I'll need to reshape my feature tensor like tf.reshape(features, [batch_size_, rows_per_ob, input_dim]). 
And only take every 10th row of my label tensor like label[::rows_per_ob]</p>

<p>Another thing I should point out is that my actual dataset is in the billions of rows so I have to think about performance.</p>

<p>I've put together the below code from documentation and other posts on here, but I don't think I fully understand this because I'm seeing the following error:</p>

<blockquote>
  <p>INFO:tensorflow:Error reported to Coordinator: , Attempting to use uninitialized value input_producer_2/limit_epochs/epochs</p>
</blockquote>

<p>There seems to be an out of range error.</p>

<p>I also can't figure out what to do with these batches once I get them working. Initially, I thought I would reshape them then just feed them into ""feed_dict"", but then I read that this is really bad, and I should be using a tf.data.Dataset object. But I'm not sure how to feed these batches into a Dataset. I'm also not entirely sure when would be the optimal time in this process to reshape my data?</p>

<p>And a final point of confusion - when you use an Iterator with a Dataset object, I see that we use the get_next() method. Does this mean that each element in the Dataset represent a full batch of data? And does this then mean that if we want to change the batch size, we need rebuild the entire Dataset object?</p>

<p>I'm really struggling to fit all the pieces together. If anyone has any pointers for me, it would be very much appreciated! Thanks!</p>

<pre><code># import
import tensorflow as tf

# constants
filename = ""tensorflow_test_data.csv""
num_rows = 100000
rows_per_ob = 10
batch_size_ = 5
num_epochs_ = 2
num_batches = int(num_rows * num_epochs_ / batch_size_ / rows_per_ob)

# read csv line
def read_from_csv(filename_queue):
    reader = tf.TextLineReader(skip_header_lines=1)
    _, value = reader.read(filename_queue)
    record_defaults = [[0.0], [0.0], [0.0], [0.0]]
    a, b, c, d = tf.decode_csv(value, record_defaults=record_defaults)
    features = tf.stack([a, b, c])
    return features, d

def input_pipeline(filename=filename, batch_size=batch_size_, num_epochs=num_epochs_):
    filename_queue = tf.train.string_input_producer([filename],
                                                    num_epochs=num_epochs,
                                                    shuffle=False)
    x, y = read_from_csv(filename_queue)
    x_batch, y_batch = tf.train.batch([x, y],
                                      batch_size = batch_size * rows_per_ob,
                                      num_threads=1,
                                      capacity=10000)
    return x_batch, y_batch

###
x, y = input_pipeline(filename, batch_size=batch_size_,
                      num_epochs = num_epochs_)

# I imagine using lists is wrong here - this was more just for me to
# see the output
x_list = []
y_list = []
with tf.Session() as sess:
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    for _ in range(num_batches):
        x_batch, y_batch = sess.run([x, y])
        x_list.append(x_batch)
        y_list.append(y_batch)
    coord.request_stop()
    coord.join(threads)
</code></pre>
",1,Documentation Replication on Other Examples
160,49987839,How to handle None in tf.clip_by_global_norm?,"<p>I have read in answers to <a href=""https://stackoverflow.com/questions/36498127/how-to-apply-gradient-clipping-in-tensorflow"">this question here</a> that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws </p>

<p>ValueError: None values not supported.</p>

<pre><code>tf.reset_default_graph()
z = tf.get_variable(name = 'z', shape = [1])
b = tf.get_variable('b', [1])
c = b*b - 2*b + 1
optimizer = tf.train.AdamOptimizer(0.1)
gradients, variables = zip(*optimizer.compute_gradients(c))
gradients = tf.clip_by_global_norm(gradients, 2.5)
train_op = optimizer.apply_gradients(zip(gradients, variables))
</code></pre>

<p>Can somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually</p>

<p>The official documentation seems to agree with @danijar's comments. see <a href=""https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/clip_by_global_norm"" rel=""nofollow noreferrer"">here</a></p>

<blockquote>
  <p>Any of the entries of t_list that are of type None are ignored.</p>
</blockquote>
",1,Documentation Replicability
161,49997294,Moving away from tf.contrib.learn: distributed training with dedicated evaluator process,"<p>In TF 1.8's upcoming release, <code>tf.contrib.learn.*</code> will be deprecated.
The <code>tf.contrib.learn.Experiment</code> class recommends switching to <code>tf.estimator.train_and_evaluate</code> instead, so I'm trying to port my code to that framework.</p>

<p>What I want to do is set up distributed training on two machines' GPUs, plus a third CPU-only process that does continuous evaluation on a small validation set.</p>

<p>Following the examples in <a href=""https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">the documentation of <code>train_and_evaluate</code></a> and the <a href=""https://www.tensorflow.org/deploy/distributed"" rel=""nofollow noreferrer"">Distributed Tensorflow</a> guide, I managed to set up the training half of my desired architecture, but I can't find a way to set up an estimator.</p>

<p>So far, what I have looks as follows:</p>

<pre><code>def input_fn(mode, num_classes, batch_size):  
  # [...] build input pipeline
  return {'input': images}, labels

def model_fn(features, labels, num_classes, mode):
  # [...] build model
  return tf.estimator.EstimatorSpec(
    mode=mode,
    predictions=predictions,
    loss=total_loss,
    train_op=train_op,
    eval_metric_ops=metrics,
    export_outputs=export_outputs)

def distributed_main_v2(unused_argv):
  """"""Expects `unused_argv` to be a list ['&lt;task_type&gt;', '&lt;task_id&gt;']""""""  
  import json
  # Set up environment variables according to the parameters passed to the process
  TF_CONFIG = {
    'cluster': {
        ""ps"": [
            ""host1:2222"",
        ],
        ""chief"": [
            ""host1:2223"",
            ],
        ""worker"": [
            ""host2:2224""
            ]
    },
    'environment': 'cluster',    
    'task': {
        'type': unused_argv[1].strip(),
        'index': unused_argv[2].strip() if len(unused_argv) &gt; 2 else 0
        }
  }
  os.environ['TF_CONFIG'] = json.dumps(TF_CONFIG)
  if unused_argv[1].strip() not in ['worker', 'chief']:
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # leave the GPU to the worker process

  # create the estimator
  # define warm start configuration
  regex = '^(?!.*final_layer*|.*aux_logits*)'
  ws_settings = tf.estimator.WarmStartSettings('checkpoint_path', regex)

  gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.95) # fix for cuDNN fatal memory error with tf.contrib.learn.Experiment (TODO: still necessary?)
  sess_conf = tf.ConfigProto(gpu_options=gpu_opts)
  run_conf = tf.estimator.RunConfig(session_config=sess_conf)

  # Create the Estimator
  estimator = tf.estimator.Estimator(
    model_fn=lambda features, labels, mode: model_fn(features, labels, NUM_CLASSES, mode),
    model_dir=model_dir,
    config=run_conf,
    warm_start_from=ws_settings)

  # Set up input functions for training and evaluation
  train_input_fn = lambda : input_fn(tf.estimator.ModeKeys.TRAIN, NUM_CLASSES, batch_size)
  eval_input_fn = lambda : input_fn(tf.estimator.ModeKeys.EVAL, NUM_CLASSES, batch_size)

  train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=steps)
  eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)

  # start distributed training
  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

if __name__ == '__main__':
  # set up globals and parse known arguments
  distributed_main_v2(unused_argv)
</code></pre>

<p>This code works, although my understanding of it is still pretty limited. I get what the PS and workers do, but from the specification of <code>chief</code> I understand this should be the ""master"" worker that also logs summaries and saves checkpoints. What I'm missing now is the periodic evaluation... and I'm at a loss. From the <code>train_and_evaluate</code> codebase I see there's some ""evaluator"" support but I don't understand how to set it up properly.</p>
",1,Documentation Replication on Other Examples
162,50029121,How to use tf.layers classes instead of functions,"<p>It seems that tf.Layer modules come in two flavours: functions and classes. I normally use the functions directly (e.g, tf.layers.dense) but I'd like to know how to use classes directly (tf.layers.<strong>D</strong>ense). I've started experimenting with the new eager execution mode in tensorflow and I think using classes are going to be useful there as well but I haven't seen good examples in the documentation. Is there any part of TF documentation that shows how these are used? </p>

<p>I guess it would make sense to use them in a class where these layers are instantiated in the <code>__init__</code> and then they're linked in the <code>__call__</code> method when the inputs and dimensions are known?</p>

<p>Are these tf.layer classes related to <code>tf.keras.Model</code>? Is there an equivalent wrapper class for using <code>tf.layers</code>?</p>

<p><strong>Update:</strong> for eager execution there's <code>tfe.Network</code> that must be inherited. There's an example <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network_eager_api.py"" rel=""noreferrer"">here</a></p>
",1,Lack of Alternative Solutions/Documentation
163,50149953,Using tf.keras within Tensorflow,"<p>What is the correct way of using the <code>tf.keras</code> API. Can <code>tf.layers.*</code> be directly replaced with <code>tf.keras.layers</code>(Similarly activations or loss functions)? Is it necessary to import <code>tf.keras.backend</code> and do <code>set_learning_phase</code>? This doesnt seem to be explained on the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras"" rel=""nofollow noreferrer"">official TF docs</a> but is mentioned in this <a href=""https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"" rel=""nofollow noreferrer"">relatively old blog post</a>. </p>
",1,Lack of Alternative Solutions/Documentation
164,50210594,the function of 'bounding_boxes' and 'min_object_covered' in tf.image.sample_distorted_bounding_box?,"<p>How parameters 'bounding_boxes' and 'min_object_covered' control the generation of a single randomly distorted bounding box for an image in tf.image.sample_distorted_bounding_box? </p>

<p>I have read the <a href=""https://www.tensorflow.org/api_docs/python/tf/image/sample_distorted_bounding_box"" rel=""nofollow noreferrer"">function</a> in tensorflow api, but I still can not understand the proplem. Maybe I need a intuitive example.</p>
",1,Requesting (Additional) Documentation/Examples
165,50222149,How to scan through tensor not at dimension 0?,"<p>The tensorflow document states that tf.scan scans on the list of tensors unpacked from elems on dimension 0.
The simplest version of scan repeatedly applies the callable fn to a sequence of elements from first to last. The elements are made of the tensors unpacked from elems on dimension 0.</p>

<p>My question is:
How to scan on the list of tensors on other dimension instead of dimension 0?
For example, 
I have a tensor, ref, defined as below.</p>

<pre><code>&gt;&gt;&gt; ref = tf.Variable(tf.ones([2,3,3],tf.int32))
....
&gt;&gt;&gt; print(ref.eval())
[[[1 1 1]
  [1 1 1]
  [1 1 1]]

 [[1 1 1]
  [1 1 1]
  [1 1 1]]]
</code></pre>

<p>I want to scan through the ref[1,0], ref[1,1], ref[1,2] and apply a function to each of the, ,say add 1.
That is to say, I want ref be after the operation</p>

<pre><code>&gt;&gt;&gt; print(ref.eval())
[[[1 1 1]
  [1 1 1]
  [1 1 1]]

 [[2 2 2]
  [2 2 2]
  [2 2 2]]]
</code></pre>

<p>Can I use tf.scan to do that? If yes, how?
If not, any how to do in other way?</p>

<p>Thanks.</p>
",1,Documentation Replication on Other Examples
166,50226274,how to explain the output of tf.rank in tensorflow,"<p>I am new in tensorflow and have a question about tf.rank method.</p>

<p>In the doc <a href=""https://www.tensorflow.org/api_docs/python/tf/rank"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/rank</a> there is a simple example about the tf.rank:</p>

<pre><code># shape of tensor 't' is [2, 2, 3]
t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])
tf.rank(t)  # 3
</code></pre>

<p>But when I run the code below:</p>

<pre><code>t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])
print(tf.rank(t))  # 3
</code></pre>

<p>I get output like:</p>

<pre><code>Tensor(""Rank:0"", shape=(), dtype=int32)
</code></pre>

<p>Why can I get the output of ""3""?</p>
",1,Documentation Replication on Other Examples
167,50243230,Unable to understand tf.nn.raw_rnn,"<p>In the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/raw_rnn"" rel=""nofollow noreferrer"">official documentation</a> of <code>tf.nn.raw_rnn</code> we have emit structure as the third output of <code>loop_fn</code> when the <code>loop_fn</code> is run for the first time.</p>

<p>Later on the emit_structure is used to copy <code>tf.zeros_like(emit_structure)</code> to the minibatch entries that are finished by <code>emit = tf.where(finished, tf.zeros_like(emit_structure), emit)</code>.</p>

<p>my lack of understanding or lousy documentation on google's part is: emit structure is <code>None</code> so <code>tf.where(finished, tf.zeros_like(emit_structure), emit)</code> is going to throw a ValueError as <code>tf.zeros_like(None)</code> does so. Can somebody please fill in what I am missing here?</p>
",1,Documentation Replication on Other Examples
168,50246535,Tensorflow estimator input function: defining each feature or not?,"<p>With <code>x</code> is a 120 x 4 feature matrix of Iris data (4 features) and <code>y</code> is a label, I can make an input function for <code>tf.estimator</code> like below </p>

<pre><code>def input_function(x, y):
    dict_x = {
        ""sepal_length"" : x[:,0],
        ""sepal_width"" :  x[:,1],
        ""petal_length"" : x[:,2],
        ""petal_width"" :  x[:,3]
    }

    dataset = tf.data.Dataset.from_tensor_slices((
        dict_x, y
    ))

    return dataset
</code></pre>

<p>then define the feature column like below:</p>

<pre><code>feature_columns = [
    tf.feature_column.numeric_column(key=""sepal_length""),
    tf.feature_column.numeric_column(key=""sepal_width""),
    tf.feature_column.numeric_column(key=""petal_length""),
    tf.feature_column.numeric_column(key=""petal_width"")
]
</code></pre>

<p>But, I found in the internet (I forget the source, still searching) that I also can define the input function like below. The difference with previous method is all four features now defined with only one key, <code>""x""</code>.</p>

<pre><code>def input_function(x, y):
    dict_x = {
        ""x"" : x,
    }

    dataset = tf.data.Dataset.from_tensor_slices((
        dict_x, y
    ))

    return dataset
</code></pre>

<p>then define the feature column like below:</p>

<pre><code>feature_columns = [
    tf.feature_column.numeric_column(key=""x"",shape=4),
]
</code></pre>

<p>I've run both method and both give almost same result. <strong>My question</strong>: I can't find any documentation that explain the difference between both method, because at a glance <code>dict_x</code> have different shape. Are they still treated equally at input layer on neural networks?</p>

<p>I'm new using <code>tf.estimator</code>, Thank You</p>

<p>My estimator code if needed:</p>

<pre><code>classifier = tf.estimator.DNNClassifier(
    feature_columns=feature_columns,
    hidden_units=[10],
    n_classes=3,
    optimizer=tf.train.GradientDescentOptimizer(0.001),
    activation_fn=tf.nn.relu
)

# Train the model
classifier.train(
    input_fn=lambda:input_function(xtrain, ytrain, True)
)
</code></pre>
",1,Lack of Alternative Solutions/Documentation
169,50252720,How to combine prefetch_to_device with make_initializer,"<p><a href=""https://github.com/tensorflow/tensorflow/releases/tag/v1.8.0"" rel=""nofollow noreferrer"">Tensorflow 1.8</a> has introduced <code>tf.contrib.data.prefetch_to_device</code>,
which can be used with <code>tf.data.Dataset.apply</code>, according to <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/data/prefetch_to_device"" rel=""nofollow noreferrer"">the official documentation</a>.</p>

<p>I have written some custom data loading, for which I would like to utilize this to prefetch to GPU. The problem is that this operation needs to be the last one in all transformations of the dataset.
I am using <code>tf.data.Iterator.make_initializer</code> and <code>tf.data.Iterator.from_structure</code> as follows.
This is a minimal example that raises the error.</p>

<pre><code>import tensorflow as tf

class MyData(object):
    def __call__(self):
         return range(100)

expected_shapes = []
expected_types = tf.int32
iterator = tf.data.Iterator.from_structure(output_types=expected_types, output_shapes=expected_shapes)
dataset = tf.data.Dataset.from_generator(MyData(), output_types=expected_types, output_shapes=expected_shapes)

prefetch_op = tf.contrib.data.prefetch_to_device(device=""/gpu:0"")
dataset = dataset.apply(prefetch_op)

# This raises NotImplementedError: `prefetch_to_device()` must be the last transformation in a dataset pipeline.
initializer = iterator.make_initializer(dataset)
</code></pre>

<p>Of course, this does not happen when I turn the order around, but then the prefetching transformation is not taken into account for the initializer.</p>

<pre><code>initializer = iterator.make_initializer(dataset)
dataset = dataset.apply(prefetch_op)
</code></pre>

<p>How can I get this to work to create the initializer after telling it to prefetch? Or is that simply not possible (currently)?
I would like to avoid having to create a new <code>Iterator</code>, unlike <a href=""https://github.com/tensorflow/tensorflow/commit/4681562607bf4001ecd61492f1e7567be9212c6f"" rel=""nofollow noreferrer"">this test case from tensorflow</a>.</p>
",1,Documentation Replication on Other Examples
170,50383462,how to randomly initialize weights in tensorflow?,"<p>in tensorflow, I learned from the tutorial that one would initialize the variables with something like
<code>
sess.run(tf.global_variables_initializer())
</code></p>

<p>however I found that every time I run this with the same input dataset, the loss value starts with the same value.</p>

<p>I presume this is due to the fact that the initialization is always setting up the variables with the same values. (probably zero)</p>

<p>I wish to randomize the values of weights. I've tried searching for this but  tensorflow docs doesn't give a clear answer if the initialization is done with zero values by default or random values.</p>

<p>How can I specify the initializaing to setup random values?</p>

<hr>

<p><strong>update</strong></p>

<p>my network is first a bunch of CNNs and pooling layers like below:
```
conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[3,3], padding=""same"", activation=tf.nn.relu, name=""conv_chad_1"")</p>

<pre><code>    pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2)

    conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3,3], padding=""same"", activation=tf.nn.relu, name=""conv_chad_2"")

    pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2, name=""pool_chad_2"")
</code></pre>

<p>```</p>

<p>AFAIK, the weights are defined inside these predefined layers. How do I specify these layers to initialize their weight variables randomly??</p>
",1,Documentation Replication on Other Examples
171,50442156,Loading a model from tensorflow SavedModel onto mutliple GPUs,"<p>Let's say someone hands me a TF SavedModel and I would like to replicate this model on the 4 GPUs I have on my machine so I can run inference in parallel on batches of data. Are there any good examples of how to do this? </p>

<p>I can load a saved model in this way:</p>

<pre><code>def load_model(self, saved_model_dirpath):
    '''Loads a model from a saved model directory - this should 
       contain a .pb file and a variables directory'''

    signature_key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY
    input_key = 'input'
    output_key = 'output'

    meta_graph_def = tf.saved_model.loader.load(self.sess, [tf.saved_model.tag_constants.SERVING],
                                                saved_model_dirpath)
    signature = meta_graph_def.signature_def

    input_tensor_name = signature[signature_key].inputs[input_key].name
    output_tensor_name = signature[signature_key].outputs[output_key].name

    self.input_tensor = self.sess.graph.get_tensor_by_name(input_tensor_name)
    self.output_tensor = self.sess.graph.get_tensor_by_name(output_tensor_name)
</code></pre>

<p>..but this would require that I have a handle to the session. For models that I have written myself, I would have access to the inference function and I could just call it and wrap it using <code>with tf.device()</code>, but in this case, I'm not sure how to extract the inference function out of a Saved Model. Should I load 4 separate sessions or is there a better way? Couldn't find much documentation on this, but apologies in advance if I missed something. Thanks!</p>
",1,Inadequate Examples
172,50454095,tf.gradients - dimensions of output,"<p>Here is my code: </p>

<pre><code>import tensorflow as tf
tf.reset_default_graph()
x = tf.placeholder(tf.float32, [None, 3],name='x')
W_1 = tf.get_variable('W_1', [3,3], dtype = tf.float32, initializer=tf.constant_initializer(1.0))
layer_out = tf.matmul(x, W_1, name = 'layer_out')
sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run([tf.gradients(layer_out, [x])], feed_dict = {x: np.array([[1,7,5]])} )
</code></pre>

<p>it returns:</p>

<pre><code>[[array([[3., 3., 3.]], dtype=float32)]]
</code></pre>

<p>I am expecting to get 3 by 3 matrix or as per <code>tf.gradients</code> docs list of dim 3 with 3 elements for each list entry.</p>

<p>What I am missing?</p>

<p><strong>UPDATE:</strong></p>

<p>I see in docs <a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">tf.gradients</a></p>

<pre><code>A list of sum(dy/dx) for each x in xs
</code></pre>

<p>but why sum and how do I get all entries of Jacobian?</p>
",1,Lack of Alternative Solutions/Documentation
173,50457247,Tensorflow finding matching strings in tensor,"<p>I'm trying to find variables that end in <code>train_step</code> from <code>tf.report_uninitialized_variables(),</code> but you can't iterate over tensors without <code>eager execution.</code> I get that you need to use <code>tf.map_fn,</code> but I do not understand it well enough.</p>

<p>This is what I have:</p>

<pre><code>variables = []
for s, t in zip(tf.report_uninitialized_variables().eval(session=sess), 
                tf.report_uninitialized_variables()):
    if 'train_step' in s:
        variables.append(t)
train_step_init = tf.variables_initializer(variables, name='train_step_init')
</code></pre>
",1,Documentation Replicability
174,50500579,what is the difference between tf.nn.max_pool() and tf.layers.max_pooling2d(),"<p>I am a beginner of tensorflow,i have met two methods about create max_pool layer these days. one is ""tf.nn.max_pool()"" and the other is ""tf.layers.max_pooling2d()"".i want to learn about its difference,and when to use them suitably.based on this ,i have read its official document and searched in google,it is not any help at all.i have searched it in stackoverflow , there is a similar answer(<a href=""https://stackoverflow.com/questions/42785026/tf-nn-conv2d-vs-tf-layers-conv2d"">tf.nn.conv2d vs tf.layers.conv2d</a>）but it didn't solve my problem.does any one can help me? thanks in advance.</p>
",1,Inadequate Examples
175,50514454,End of Sequence Error when using tf.estimator and tf.data,"<p>I am using <code>tf.estimator.train_and_evaluate</code> and <code>tf.data.Dataset</code> to feed data to the estimator:</p>

<p>Input Data function:</p>

<pre><code>    def data_fn(data_dict, batch_size, mode, num_epochs=10):
        dataset = {}
        if mode == tf.estimator.ModeKeys.TRAIN:
            dataset = tf.data.Dataset.from_tensor_slices(data_dict['train_data'].astype(np.float32))
            dataset = dataset.cache()
            dataset = dataset.shuffle(buffer_size= batch_size * 10).repeat(num_epochs).batch(batch_size)
        else:
            dataset = tf.data.Dataset.from_tensor_slices(data_dict['valid_data'].astype(np.float32))
            dataset = dataset.cache()
            dataset = dataset.batch(batch_size)

        iterator = dataset.make_one_shot_iterator()
        next_element = iterator.get_next()

    return next_element
</code></pre>

<p>Train Function:</p>

<pre><code>def train_model(data):
    tf.logging.set_verbosity(tf.logging.INFO)
    config = tf.ConfigProto(allow_soft_placement=True,
                            log_device_placement=False)
    config.gpu_options.allow_growth = True
    run_config = tf.contrib.learn.RunConfig(
        save_checkpoints_steps=10,
        keep_checkpoint_max=10,
        session_config=config
    )

    train_input = lambda: data_fn(data, 100, tf.estimator.ModeKeys.TRAIN, num_epochs=1)
    eval_input = lambda: data_fn(data, 1000, tf.estimator.ModeKeys.EVAL)
    estimator = tf.estimator.Estimator(model_fn=model_fn, params=hps, config=run_config)
    train_spec = tf.estimator.TrainSpec(train_input, max_steps=100)
    eval_spec = tf.estimator.EvalSpec(eval_input,
                                      steps=None,
                                      throttle_secs = 30)

    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</code></pre>

<p>The training goes fine, but when it comes to evaluation I get this error:</p>

<pre><code>OutOfRangeError (see above for traceback): End of sequence 
</code></pre>

<p>If I don't use <code>Dataset.batch</code> on evaluation dataset (by omitting the line <code>dataset[name] = dataset[name].batch(batch_size)</code> in <code>data_fn</code>) I get the same error but after a much longer time.</p>

<p>I can only avoid this error if I don't batch the data and use <code>steps=1</code> for evaluation, but does that perform the evaluation on the whole dataset?</p>

<p>I don't understand what causes this error as the documentation suggests I should be able to evaluate on batches too.</p>

<p>Note: I get the same error when using <code>tf.estimator.evaluate</code> on data batches.</p>
",1,Documentation Replication on Other Examples
176,50560013,"Tensorflow, multi-label confusion matrix","<p>I am trying to figure out how to the generate a confusion matrix for a multi-label classification task using neural networks. I previously managed to calculate the accuracy using the function &quot;intersection&quot;, since for that I did not care about any ordering.</p>
<pre><code>intersection = tf.sets.set_intersection(predictions, labels)
</code></pre>
<p>However, in order to calculate the confusion matrix, I do care about the indexing order of the predictions/labels. And since the labels have always the same value (<code>1,1</code> or <code>0.5,0.5</code>) there is no possible sorting according to higher/lower value.</p>
<p>I wonder:</p>
<p><strong>1) Is it possible to calculate a confusion matrix for the multi-label classification task?</strong></p>
<p><strong>2) How would that be implemented ?</strong></p>
<p><strong>3) How can you handle the case of failure in predicting both labels? Since it is not possible to know which confusion belongs to which prediction.</strong></p>
<p><strong>4) What is the logic behind the sorting of the function tf.nn.top_k()</strong></p>
<p>Below I show an example of the code that I was trying to use.</p>
<pre><code>import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

Z = np.array([[7.0, 3.0, 5.0, 1.0, 0.0, 6.0],[2.0, 3.0, 4.0, 1.0, 3.25, 2.2], [2.0 , 5.0, 1.0, 7.0, 0.0, 8.0]])
Y = np.array([[0.5, 0, 0, 0.0, 0, 0.5],[0, 0.0, 0.5, 0, 0.5, 0], [0,0,0,0.5,0,0.5]])

_, predicted_softmax = tf.nn.top_k(tf.nn.softmax(Z), k = 2, sorted = False)
_ , labels = tf.nn.top_k(Y, k = 2, sorted = False)

with tf.Session() as sess:
    # reshape to (6,1) because there is 2 correct values per sample(2*3)
    print(predicted_softmax.eval().reshape(6,1))
    print(labels.eval().reshape(6,1))
    predicted = predicted_softmax.eval().reshape(6,1)
    labels_idx = labels.eval().reshape(6,1)

class_labels = np.arange(6)
cnf_matrix_train = confusion_matrix(labels_idx, predicted, labels = class_labels)

print(cnf_matrix_train)
</code></pre>
<p>I don't really get why the output of predicted_softmax is:</p>
<pre><code>[[5] [0] [4] [2] [3] [5]] , 
</code></pre>
<p>I was expecting [5] [3] for the last two terms. There is no any logic to this output. In the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/top_k"" rel=""nofollow noreferrer"">documentation</a> they don't specify anything about the ordering in the case that <code>sorted = False</code> thought, but I was expecting some consistent behavior.</p>
<p>Thanks for any help!</p>
",1,Documentation Completeness
177,50606178,TensorFlow tf.data.Dataset and bucketing,"<p>For an LSTM network, I've seen great improvements with bucketing.</p>

<p>I've come across the <a href=""https://www.tensorflow.org/api_guides/python/contrib.training#Bucketing"" rel=""noreferrer"">bucketing section in the TensorFlow docs</a> which (tf.contrib).</p>

<p>Though in my network, I am using the <code>tf.data.Dataset</code> API, specifically I'm working with TFRecords, so my input pipeline looks something like this</p>

<pre><code>dataset = tf.data.TFRecordDataset(TFRECORDS_PATH)
dataset = dataset.map(_parse_function)
dataset = dataset.map(_scale_function)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.padded_batch(batch_size, padded_shapes={.....})
</code></pre>

<p>How can I incorporate the bucketing method into a the <code>tf.data.Dataset</code> pipeline?</p>

<p>If it matters, in every record in the TFRecords file I have the sequence length saved as an integer.</p>
",1,Documentation Replicability
178,50820781,quesion about the axis of tf.stack(),"<p>I read the doc of <code>tf.stack()</code> on <a href=""https://www.tensorflow.org/api_docs/python/tf/stack"" rel=""nofollow noreferrer"">tensorflow stack </a>. There is an example on the page:</p>

<pre><code>&gt;&gt;&gt; x = tf.constant([1, 4])
&gt;&gt;&gt; y = tf.constant([2, 5])
&gt;&gt;&gt; z = tf.constant([3, 6])
&gt;&gt;&gt; sess=tf.Session()
&gt;&gt;&gt; sess.run(tf.stack([x, y, z]))
array([[1, 4],
       [2, 5],
       [3, 6]], dtype=int32)
&gt;&gt;&gt; sess.run(tf.stack([x, y, z], axis=1))
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)
</code></pre>

<p>what I don't understand is the second example where <code>axis=1</code>.</p>

<p>From the result it seems it converts the three inputs rows to columns first </p>

<p>and then put them toghter along the <code>axis=1</code>, but </p>

<p>I think the result should be </p>

<pre><code>array([[1,4, 2, 5, 3, 6 ]] dtype=int32 )
</code></pre>

<p>can anyone help explain this?</p>

<p>Thanks!</p>
",1,Inadequate Examples
179,50825446,Restoring a trained generator network in DCGAN,"<p>I have a question regarding the saving and storing models in tensorflow. I know how to save a model with tf.train.Saver() and load it later through meta file. My problem is this:</p>

<p>I have trained a variant of DCGAN (Deep Convolution GAN), now I want to use only generator network for other tasks. Unfortunately, I do not know how to get entire generator network such that if I feed it with a new vector z, it generates an output based on the trained parameters. All the example I found in the stackoverflow, or tensorflow documentation, just mention very simple operations with two numbers. This is not I want. I want to understand if you have trained a giant network, say with 50 layers, how to load it and feed it with new input and get the output without going into the different parameters and layers in the trained network. I want to load it as a blackbox.</p>
",1,Documentation Replication on Other Examples
180,50840759,"Incorrect name returned in Tensorflow causes ""Tensor which does not exist"" error while invoking get_tensor_by_name","<p>As per the <a href=""https://www.tensorflow.org/programmers_guide/graphs#naming_operations"" rel=""nofollow noreferrer"" title=""description"">documentation</a> TensorFlow would append ""_1"", ""_2"", and so on to the name in tf.Graph namespace, in order to make it unique.  Here I define two convolutional operations.  It is expected that the first one will be named as ""conv2d"" and second one ""conv2d_1"".  But when I try to obtain the name of the second convolution it returns ""conv2d_2"".  I causes error when I try to invoke get_tensor_by_name. Here is the code:</p>

<pre><code>import numpy as np
import tensorflow as tf
import os

x = tf.constant(np.random.randn(1,2,2,1), dtype=tf.float32)
kernel_size = (1,1)
no_of_out = 20
strides = (1,1)
conv_out1 = tf.layers.conv2d(x, 10, (1,1), (1,1))
conv_out2 = tf.layers.conv2d(x, 10, (1,1), (1,1))

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print conv_out1.name # conv2d/BiasAdd:0 .  This value is correct
    print conv_out2.name # conv2d_2/BiasAdd:0 .  This value is incorrect.  It should be conv2d_1/BiasAdd:0
    conv_weights1 = tf.get_default_graph().get_tensor_by_name(os.path.split(conv_out1.name)[0] + '/kernel:0')
    conv_weights2 = tf.get_default_graph().get_tensor_by_name('conv2d_1/kernel:0')  
    conv_weights2 = tf.get_default_graph().get_tensor_by_name(os.path.split(conv_out2.name)[0] + '/kernel:0')
</code></pre>

<p>I could not understand why conv_out2.name returns ""conv2d_2"" instead of ""conv2d_1""</p>
",1,Documentation Ambiguity
181,50945733,why this Tensorflow code raises tf.errors.OutOfRangeError?,"<p>This Tensorflow code below raises a <code>tf.errors.OutofRangeError</code>:</p>



<pre><code>try:
     while not coord.should_stop():        
          vector1,vector2,vector3,vector4,vector5,labels = sess.run([train_vector1,train_vector2,train_vector3,train_vector4,train_vector5,train_labels])
          shape1 = tf.shape(vector1)
          print (sess.run(shape1))
except tf.errors.OutOfRangeError:
   print ('tf.errors.OutOfRangeError')

finally:
    coord.request_stop()
</code></pre>

<p>Why is <code>tf.errors.OutofRangeError</code> printed when all the samples are read?
It seems unreasonable.</p>
",1,Documentation Replicability
182,50967885,"tf.gradients, how can I understand `grad_ys` and use it?","<p>In <code>tf.gradients</code>,  there is a keyword argument <code>grad_ys</code></p>

<blockquote>
  <p><code>grad_ys</code> is a list of tensors of the same length as <code>ys</code> that holds the initial gradients for each <code>y</code> in <code>ys</code>. When <code>grad_ys</code> is None, we fill in a tensor of ‘1’s of the shape of <code>y</code> for each <code>y</code> in <code>ys</code>. A user can provide their own initial <code>grad_ys</code> to compute the derivatives using a different initial gradient for each y (e.g., if one wanted to weight the gradient differently for each value in each y).</p>
</blockquote>

<p>Why is <code>grads_ys</code> needed here? The docs here is implicit. Could you please give some specific purpose and code?</p>

<p>And my example code for <code>tf.gradients</code> is</p>

<pre class=""lang-py prettyprint-override""><code>In [1]: import numpy as np

In [2]: import tensorflow as tf

In [3]: sess = tf.InteractiveSession()

In [4]: X = tf.placeholder(""float"", shape=[2, 1])

In [5]: Y = tf.placeholder(""float"", shape=[2, 1])

In [6]: W = tf.Variable(np.random.randn(), name='weight')

In [7]: b = tf.Variable(np.random.randn(), name='bias')

In [8]: pred = tf.add(tf.multiply(X, W), b)

In [9]: cost = 0.5 * tf.reduce_sum(tf.pow(pred-Y, 2))

In [10]: grads = tf.gradients(cost, [W, b])

In [11]: sess.run(tf.global_variables_initializer())

In [15]: W_, b_, pred_, cost_, grads_ = sess.run([W, b, pred, cost, grads], 
                                    feed_dict={X: [[2.0], [3.]], Y: [[3.0], [2.]]})
</code></pre>
",1,Documentation Replicability
183,50988466,Using L-BFGS optimizer with Tensorflow estimator API,"<p>I am using Tensorflow Estimator API but haven't figured out how to use the L-BFGS optimizer available at <code>tf.contrib.opt.ScipyOptimizerInterface</code>.</p>

<p>It seems the estimator API expects some optimizer from the <code>tf.train</code> module but no BFGS implementation is available there. The only one defined in <code>contrib</code> does not follow the same interface.</p>

<p>To be more specific, in the <a href=""https://www.tensorflow.org/get_started/custom_estimators#train"" rel=""nofollow noreferrer"">official tutorial</a> to define custom estimators, it's shown how to use the <code>AdagradOptimizer</code>:</p>

<pre><code>optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)
train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
</code></pre>

<p>However, the API of the <code>ScipyOptimizerInterface</code> is as follows:</p>

<pre><code>optimizer = ScipyOptimizerInterface(loss, options={'maxiter': 100})

with tf.Session() as session:
    optimizer.minimize(session)
</code></pre>

<p>Taking a full example:</p>

<pre><code>from sklearn import datasets
import numpy as np


def _custom_model_fn(features, labels, mode, feature_columns):

    predictions = tf.feature_column.linear_model(features, feature_columns)
    predictions = tf.reshape(predictions, [-1])

    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {'predictions': predictions}
        return tf.estimator.EstimatorSpec(mode, predictions=predictions)

    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions,
                                        reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)

    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)

    # Create training op.
    assert mode == tf.estimator.ModeKeys.TRAIN

    # train_op = tf.contrib.opt.ScipyOptimizerInterface(loss, options={'maxiter': 10})

    optimizer = tf.train.FtrlOptimizer(learning_rate=1.)
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode,
                                      predictions=predictions,
                                      loss=loss,
                                      train_op=train_op)

class MyRegressor(tf.estimator.Estimator):
    def __init__(self, feature_columns, model_dir=None, config=None):

        def _model_fn(features, labels, mode, config):
            return _custom_model_fn(features, labels, mode, feature_columns)

        super(MyRegressor, self).__init__(model_fn=_model_fn)

# Load the diabetes dataset
diabetes = datasets.load_diabetes()
diabetes_X = diabetes.data[:, np.newaxis, 2]
diabetes_y = diabetes.target

# Create the custom estimator and train it
feature_columns = [tf.feature_column.numeric_column('x')]
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'x': np.array(diabetes.data[:, 2])},
    y=np.array(diabetes.target),
    num_epochs=None,
    shuffle=True)
myregressor = MyRegressor(feature_columns)
myregressor.train(train_input_fn, steps=10000)
</code></pre>

<p>If I un-comment the line to use the <code>ScipyOptimizer</code> instead, I obviously get an error as follows</p>

<pre><code>TypeError: train_op must be Operation or Tensor, given: &lt;tensorflow.contrib.opt.python.training.external_optimizer.ScipyOptimizerInterface object
</code></pre>

<p>Is there an easy way to use the Scipy optimizer?</p>

<p>Thanks in advance.</p>
",1,Documentation Replication on Other Examples
184,51069173,What exactly qualifies as a 'Tensor' in TensorFlow?,"<p>I am new to TensorFlow and just went through the eager execution tutorial and came across the tf.decode_csv function. Not knowing about it, I read the documentation.  <a href=""https://www.tensorflow.org/api_docs/python/tf/decode_csv"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/decode_csv</a></p>

<p>I don't really understand it. </p>

<p>The documentation says 'records: A Tensor of type string.' 
<strong>So, my question is: What qualifies as a 'Tensor'?</strong> </p>

<p>I tried the following code:</p>

<pre><code>dec_res = tf.decode_csv('0.1,0.2,0.3', [[0.0], [0.0], [0.0]])
print(dec_res, type(dec_res))



l = [[1,2,3],[4,5,6],[7,8,9]]
r = tf.reshape(l, [9,-1])
print(l, type(l))
print(r, type(r))
</code></pre>

<p>So the list <code>dec_res</code> contains tf.tensor objects. That seems reasonable to me. But is an ordinary string also a 'Tensor' according to the documentation?</p>

<p>Then I tried something else with the <code>tf.reshape</code> function. In the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/reshape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/reshape</a> it says that 'tensor: A Tensor.' So, <code>l</code> is supposed to be a tensor. But it is not of type <code>tf.tensor</code> but simply a python <code>list</code>. This is confusing.</p>

<p>Then the documentation says </p>

<blockquote>
  <p>Returns:</p>
  
  <p>A Tensor. Has the same type as tensor.</p>
</blockquote>

<p>But the type of <code>l</code> is <code>list</code> where the type of <code>r</code> is <code>tensorflow.python.framework.ops.Tensor</code>. So the types are not the same. </p>

<p>Then I thought that TensorFlow is very generous with things being a tensor. So I tried:</p>

<pre><code>class car(object):
def __init__(self, color):
    self.color = color


red_car = car('red')
#test_reshape = tf.reshape(red_car, [1, -1])
print(red_car.color) # to check, that red_car exists.
</code></pre>

<p>Now, the line in comments results in an error. </p>

<p>So, can anyone help me to find out, what qualifies as a 'Tensor'?</p>

<p>P.S.: I tried to read the source code of <code>tf.reshape</code> as given in the documentation </p>

<blockquote>
  <p>Defined in tensorflow/python/ops/gen_array_ops.py.</p>
</blockquote>

<p>But this file does not exist in the Github repo. Does anyone know how to read it?</p>
",1,Requesting (Additional) Documentation/Examples
185,51077930,tf.image.resize_bilinear()-when align_corners=False,"<p>I am using Tensorflow 1.4.0</p>

<p>The Tensorflow tf.image.resize_bilinear() has an argument called 'align_corners' and I am confused with the behavior when we set it to be False. In the <a href=""https://www.tensorflow.org/api_docs/python/tf/image/resize_bilinear"" rel=""noreferrer"">official document</a>, it says:</p>

<blockquote>
  <p>align_corners: An optional bool. Defaults to False. If true, the centers of the 4 corner pixels of the input and output tensors are aligned, preserving the values at the corner pixels. Defaults to false.</p>
</blockquote>

<p>When I use tf.image.resize_bilinear() with align_corners=True in the following program:</p>

<pre><code>import tensorflow as tf
sess = tf.Session()
x = tf.Variable(tf.Variable([[[[1],[2]],[[3],[4]]]]))
pooling_output_size = [4, 4]
pool_output = tf.image.resize_bilinear(x, pooling_output_size,align_corners=True)
sess.run(tf.global_variables_initializer())
print pool_output.eval(session=sess)
</code></pre>

<p>it outputs</p>

<pre><code>[[[[1.       ]
   [1.3333334]
   [1.6666667]
   [2.       ]]

  [[1.6666667]
   [2.       ]
   [2.3333335]
   [2.6666667]]

  [[2.3333335]
   [2.6666665]
   [3.       ]
   [3.3333335]]

  [[3.       ]
   [3.3333333]
   [3.6666667]
   [4.       ]]]]
</code></pre>

<p>which corners are correctly aligned.</p>

<p>However when I set the align_corners=False, I got the following weird outputs</p>

<pre><code>[[[[1. ]
   [1.5]
   [2. ]
   [2. ]]

  [[2. ]
   [2.5]
   [3. ]
   [3. ]]

  [[3. ]
   [3.5]
   [4. ]
   [4. ]]

  [[3. ]
   [3.5]
   [4. ]
   [4. ]]]]
</code></pre>

<p>Is there anyone who understand why Tensorflow will use this weird implementation? I didn't find any explanation anywhere.</p>

<p>Actually PyTorch's bilinear upsampling has the align_corner argument too, when you set it to True, it works well. But if you set it to False, it performs a differnet behaviour to Tensorflow's. I am totally confused with their implementations now (maybe just use align_corners=True will be fine).</p>
",1,Documentation Ambiguity
186,51248442,Behavior of the parameter 'throttle_secs' in tf.estimator.EvalSpec for use in tf.estimator.train_and_evaluate,"<p>I am using tensorflow's train_and_eval function as in the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">example</a>. Therefore i create an instance of tf.estimator.EvalSpec, according to </p>

<pre><code>eval_spec = tf.estimator.EvalSpec(input_fn=...,throttle_secs=60).
</code></pre>

<p>According to its <a href=""http://eval_spec%20=%20tf.estimator.EvalSpec(input_fn=lambda:%20tf_data_utils.monuseg_input_func(mdl_info,train=False,normalize=True),throttle_secs=60*5)"" rel=""nofollow noreferrer"">documentation</a> the explanation of the parameter throttle_secs states that </p>

<p>""Of course, evaluation does not occur if no new checkpoints are available, hence, this is the minimum.""</p>

<p>However, i observe a different behavior. If there is no new checkpoint and evaluation should be triggered according to the passed parameter a new checkpoint is created and evaluation is performed. </p>

<p>Is this a bug or am i missing something here?</p>
",1,Documentation Replicability
187,51265030,Can tf.saved_model.simple_save be used to create a SavedModel for C++?,"<p>I want to save a model for inference from C++ and I am looking into <code>SavedModel</code>s as <a href=""https://www.tensorflow.org/programmers_guide/saved_model#save_and_restore_models"" rel=""nofollow noreferrer"">suggested by the documentation</a>.</p>

<p>Now <a href=""https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save"" rel=""nofollow noreferrer""><code>tf.saved_model.simple_save</code></a> seems to be a convenience function to easily create a <code>SavedModel</code>: from within a <code>Session</code>, provide the inputs, outputs and an export dir: </p>

<pre><code>simple_save(session,
            export_dir,
            inputs={""x"": x, ""y"": y},
            outputs={""z"": z})
</code></pre>

<p>When looking at this API, the function looks rather broad in application; however the documentation warns us that </p>

<blockquote>
  <p>The <code>SavedModel</code> will load in TensorFlow Serving and supports the Predict API. To use the Classify, Regress, or MultiInference APIs, please use either <code>tf.Estimator</code> or the lower level <code>SavedModel</code> APIs.</p>
</blockquote>

<p>I am not familiar with Tensorflow serving, but it seems that these distinctions between Predict, Classify aso. relates to Tensorflow serving.</p>

<p>Actually the documentaiton on <code>tf.saved_model.simple_save</code> says that it is a</p>

<blockquote>
  <p>Convenience function to build a SavedModel <strong>suitable for serving</strong>.</p>
</blockquote>

<p>(emphasis mine).</p>

<p>So <code>tf.saved_model.simple_save</code> can create <code>SavedModel</code>s for serving, but my question is,</p>

<ul>
<li>can <code>tf.saved_model.simple_save</code> also be used to create a <code>SavedModel</code> for inference in C++,</li>
<li>if so, what are the limitation in terms of models that can be created by this function? (Given the fact that for serving, it apparently does have some restrictions.)</li>
</ul>
",1,Documentation Replicability
188,51278422,Interpreting the FLOPs profile result of tensorflow,"<p>I want to profile the FLOPs of a very simple neural network model, which is used to classify the MNIST dataset, and the batch size is 128. As I followed the official tutorials, I got the result of the following model, but I cannot understand some parts of the output.</p>

<pre><code>w1 = tf.Variable(tf.random_uniform([784, 15]), name='w1')
w2 = tf.Variable(tf.random_uniform([15, 10]), name='w2')
b1 = tf.Variable(tf.zeros([15, ]), name='b1')
b2 = tf.Variable(tf.zeros([10, ]), name='b2')

hidden_layer = tf.add(tf.matmul(images_iter, w1), b1)
logits = tf.add(tf.matmul(hidden_layer, w2), b2)

loss_op = tf.reduce_sum(\
    tf.nn.softmax_cross_entropy_with_logits(logits=logits, 
                                            labels=labels_iter))
opetimizer = tf.train.AdamOptimizer(learning_rate=0.01)
train_op = opetimizer.minimize(loss_op)
</code></pre>

<p>The <code>images_iter</code> and the <code>labels_iter</code> are the iterators of tf.data, which are similar to the placeholder. </p>

<pre><code>tf.profiler.profile(
    tf.get_default_graph(),
    options=tf.profiler.ProfileOptionBuilder.float_operation())
</code></pre>

<p>I used this code, which equals to <code>scope -min_float_ops 1 -select float_ops -account_displayed_op_only</code> in tfprof comments line tool, to profile the FLOPs and got the below result.</p>

<pre><code>Profile:
node name | # float_ops
_TFProfRoot (--/23.83k flops)
  random_uniform (11.76k/23.52k flops)
    random_uniform/mul (11.76k/11.76k flops)
    random_uniform/sub (1/1 flops)
  random_uniform_1 (150/301 flops)
    random_uniform_1/mul (150/150 flops)
    random_uniform_1/sub (1/1 flops)
  Adam/mul (1/1 flops)
  Adam/mul_1 (1/1 flops)
  softmax_cross_entropy_with_logits_sg/Sub (1/1 flops)
  softmax_cross_entropy_with_logits_sg/Sub_1 (1/1 flops)
  softmax_cross_entropy_with_logits_sg/Sub_2 (1/1 flops)
</code></pre>

<p>My questions are   </p>

<ol>
<li>What do the numbers in the parentheses mean? For example, <code>random_uniform_1 (150/301 flops)</code>, what are 150 and 301?</li>
<li>Why is the first number in the parentheses of _TFProfRoot ""--""?</li>
<li>Why are the flops of Adam/mul and softmax_cross_entropy_with_logits_sg/Sub 1?</li>
</ol>

<p>I know it is discouraging to read a question so long, but a desperate boy who cannot find relating information from the official document needs your guys to help.</p>
",1,Lack of Alternative Solutions/Documentation
189,51392594,"`ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'sparse_softmax_cross_entropy_loss' [Tensorflow]","<p>I am rather new to Tensorflow, and has been trying to pick up the basics by reading through the guides and documentation on tensorflow.org</p>

<p>I have learnt the basics of how to use the tf.data and tf.estimator APIs and is trying to get them to work together on a basic image model for MNIST.</p>

<p>I am currently following these guides: 
<a href=""https://www.tensorflow.org/tutorials/estimators/cnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/estimators/cnn</a> 
<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py</a></p>

<p>I've changed the original python script to be using <code>Dataset.from_tensor_slices</code> rather than <code>numpy_input_fn</code> but I am facing the error at the evaluation step. (though not at the training step)</p>

<p><code>ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [1,10].</code></p>

<p>My code can be found in a python notebook here (only changed the input_fn): <a href=""https://github.com/quanta0801/tf_scripts/blob/master/mnist/mnist_estimator_baseline.ipynb"" rel=""nofollow noreferrer"">https://github.com/quanta0801/tf_scripts/blob/master/mnist/mnist_estimator_baseline.ipynb</a></p>

<p>Thanks!</p>

<p>PS: any additional links to excellent guides to using tf.data &amp; tf.estimators will be great too! Official documentation cycles between these, keras and the low level APIs which is not conducive.</p>
",1,Documentation Replication on Other Examples
190,51507788,What are inputs and outputs in tf.saved_model.simple_save?,"<p>In tf.saved_model.simple_save, there are 4 params:</p>

<ul>
<li>session, the session</li>
<li>export_dir, the dir where the model will be saved</li>
<li>inputs, <strong>what it this?</strong></li>
<li>outputs, <strong>what is this?</strong></li>
</ul>

<p>I've been reading how to <a href=""https://www.tensorflow.org/guide/saved_model#simple_save"" rel=""noreferrer"">simple_save</a> but I haven't been able to figure out what to put in these two parameters (inputs and outputs). I know the model must have input values so that it can be either trained or predict. So I don't know what these two parameters should contain and wether they should map variables inside the model or what...</p>

<p>The docs aren't that great so any explaining would be much appreciated.</p>
",1,Requesting (Additional) Documentation/Examples
191,51509549,Feature importance from tf.estimator.BoostedTreeRegression,"<p>I am trying to extracted feature importance from a model built in python using <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/BoostedTreesRegressor"" rel=""nofollow noreferrer"">tf.estimator.BoostedTreeRegressor</a>.</p>

<p>It looks like a standard way to achieve it is by iterating over all trees in the forest and from the importance of each tree's coefficients to calculate some statistics.</p>

<p>Example in <a href=""http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html"" rel=""nofollow noreferrer"">sklearn</a>, <a href=""https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/"" rel=""nofollow noreferrer"">xgboost</a>. I have not found how to address this issue in tensorflow.</p>
",1,Documentation Replication on Other Examples
192,51586459,Why the false_fn in tf.cond never called?,"<p>It's so wired to use <code>tf.while_loop</code> with <code>tf.cond</code> together. why the false condition never met? </p>

<pre><code>i0 = tf.constant(1)
m0 = tf.zeros([1, 2], dtype=tf.int32)
first_set = tf.Variable(True, dtype=tf.bool)

def cond_true_fn(i, m):
    global first_set
    first_set = tf.assign(first_set, False)
    return [i + 1, tf.concat([m, [[6, 6]]], axis=0)]


def cond_false_fn(i, m):
    return [i + 1, tf.concat([m, [[3, 3]]], axis=0)]


def body(i, m):
    return tf.cond(first_set, lambda:cond_true_fn(i,m), lambda:cond_false_fn(i,m))

def condi(i, m):
    return tf.less_equal(i, 3)

_, r = tf.while_loop(condi, body, loop_vars=[i0, m0], shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])], back_prop=False)

with tf.Session() as sess:
    tf.global_variables_initializer().run()
    _r = sess.run([r])
    print(_r)
</code></pre>

<p>it always fall in true condition. give me the result unexpected as below:
<code>[[0, 0], [6, 6], [6, 6], [6, 6]]</code> </p>
",1,Documentation Replication on Other Examples
193,51586693,"Tensor has shape [?, 0] -- how to reshape to [?,]","<p>When <code>src</code> has shape <code>[?]</code>, <code>tf.gather(src, tf.where(src != 0))</code> returns a tensor with shape <code>[?, 0]</code>. I'm not sure how a dimension can have size 0, and I'm especially unsure how to change the tensor back. I didn't find anything in the documentation to explain this, either.</p>

<p>I tried to <code>tf.transpose(tensor)[0]</code>, but the first dimension of the transposed tensor has size 0 and cannot be accessed! What's wrong?</p>
",1,Documentation Replication on Other Examples
194,51612489,tensorflow tf.edit_distance explanation required?,"<p>How does tensorflow <code>tf.edit_distance</code> function works?
How it compares string stored in two different sparse matrix equivalent of 2d or 3d dense matrix. </p>

<p>Example given on tensorflow web page <a href=""https://www.tensorflow.org/api_docs/python/tf/edit_distance"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/edit_distance</a> is not so obvious. Please provide explanation using some other examples. </p>

<p>Also this example is not clear.</p>

<pre><code>#'hypothesis' is a tensor of shape [2, 1] with variable-length values:
#(0,0) = [""a""] and (1,0) = [""b""]

hypothesis = tf.SparseTensor([[0, 0, 0],[1, 0, 0]],[""a"", ""b""],(2, 1, 1))

#'truth' is a tensor of shape `[2, 2]` with variable-length values:
#(0,0) = [], (0,1) = [""a""], (1,0) = [""b"", ""c""],(1,1) = [""a""]

truth = tf.SparseTensor([[0, 1, 0],[1, 0, 0],[1, 0, 1],[1, 1, 0]],[""a"", ""b"", 
""c"", ""a""],(2, 2, 2))

normalize = True

#'output' is a tensor of shape [2, 2] with edit distances normalized by 
#'truth' lengths.

output ==&gt; [[inf, 1.0],[0.5, 1.0]],

(0,0): no truth, (0,1): no hypothesis, (1,0): addition, (1,1): no hypothesis
</code></pre>

<p>How output is of dimension [2,2]?</p>

<p>What normalization is doing here?</p>
",1,Lack of Alternative Solutions/Documentation
195,51625529,How to use tf.data's initializable iterator and reinitializable interator and feed data to estimator api?,"<p>All the official google tutorials use the one shot iterator for all the estimator api implementation, i couldnt find any documentation on how to use tf.data's initializable iterator and reinitializable interator instead of one shot iterator.</p>

<p>Can someone kindly show me how to switch between train_data and test_data using tf.data's initializable iterator and reinitializable interator. We need to run a session to use feed dict and switch the dataset in the initializable iterator, its a low level api and its confusing how to use it part of estimator api architecture</p>

<p>PS : I did find that google mentions 
""Note: Currently, one-shot iterators are the only type that is easily usable with an Estimator.""</p>

<p>But is there any work around within the community? or should we just stick with one shot iterator for some good reason</p>
",1,Lack of Alternative Solutions/Documentation
196,51687832,Probability Distribution for tf.nn.softmax_cross_entropy_with_logits_v2,"<p>I am trying to understand the Tensorflow documentation better for tf.nn.softmax_cross_entropy_with_logits_v2().</p>

<p>In the documentation, it states:
While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution. If they are not, the computation of the gradient will be incorrect.</p>

<p>Does this mean that, for my labels, I shouldn't be simply using one-hot encoding, but should also account for the number of instances of each label? For example, if I have 2 classes, and there are 90 examples for class ""A"" and only 10 examples for class ""B"", should my label for a class A be [0.9, 0.1], instead of just [1, 0]?</p>

<p>I hope this makes sense. Thanks!</p>
",1,Documentation Replication on Other Examples
197,51691199,How does tf.create_partitioned_variables work?,"<p>I am trying to figure out how to use <a href=""https://www.tensorflow.org/api_docs/python/tf/create_partitioned_variables"" rel=""nofollow noreferrer"">tf.create_partitioned_variables</a>
I am reading the documentation but I am having a hard time understanding.</p>

<p>Could anyone explain how it works and give some examples of its usage? </p>

<p>From what I understand I can use it to get a list of slices from a variable.
I just dont understand how I get the slices</p>

<p>ex:
how would i get a list of <code>[[1.],[3.]]</code> from <code>tf.Variable(np.array([[1.0],[3.0]]), dtype=tf.float32)</code></p>

<p>or list of </p>

<pre><code>[[[1 0] [3 0]], [[0 5] [0 7]]]
</code></pre>

<p>from</p>

<pre><code>[[[1 0]
  [3 0]]

 [[0 5]
  [0 7]]]
</code></pre>
",1,Inadequate Examples
198,51706848,How does tf.reshape() work internally ?,"<p>I'm trying to understand how tf.reshape works. Let's have an example:</p>

<pre><code>embeddings = tf.placeholder(tf.float32, shape=[N0,N1])
M_2D = tf.placeholder(tf.float32, shape=[N0,None])
M_3D = tf.reshape(M_2D, [-1,N0,1])
weighted_embeddings = tf.multiply(embeddings, M_3D)
</code></pre>

<p>Here I have a 2D tensor M_2D whose columns represent coefficients for the N0 embeddings of dimension N1. I want to create a 3D tensor where each column of M_2D is placed in the first dimension of M_3D, and columns are keep in the same order. My final goal is to create a 3D tensor of 2D embeddings, each weighted by the columns of M_2D. </p>

<p>How can I be sure that reshape actually place each column in the new dimension of M_3D. Is it possible that it places the rows instead ? Is there somewhere in tensorflow documentation a clear explanation on the internal working process of tf.reshape, particularly when -1 is provided ?    </p>
",1,Documentation Completeness
199,51806852,Can't save custom subclassed model,"<p>Inspired by <a href=""https://www.tensorflow.org/guide/keras#model_subclassing"" rel=""noreferrer"">tf.keras.Model subclassing</a> I created custom model.<br>
I can train it and get successfull results, but <strong>I can't save it</strong>.<br>
I use python3.6 with tensorflow v1.10 (or v1.9)  </p>

<p>Minimal complete code example here:</p>

<pre><code>import tensorflow as tf
from tensorflow.keras.datasets import mnist


class Classifier(tf.keras.Model):
    def __init__(self):
        super().__init__(name=""custom_model"")

        self.batch_norm1 = tf.layers.BatchNormalization()
        self.conv1 = tf.layers.Conv2D(32, (7, 7))
        self.pool1 = tf.layers.MaxPooling2D((2, 2), (2, 2))

        self.batch_norm2 = tf.layers.BatchNormalization()
        self.conv2 = tf.layers.Conv2D(64, (5, 5))
        self.pool2 = tf.layers.MaxPooling2D((2, 2), (2, 2))

    def call(self, inputs, training=None, mask=None):
        x = self.batch_norm1(inputs)
        x = self.conv1(x)
        x = tf.nn.relu(x)
        x = self.pool1(x)

        x = self.batch_norm2(x)
        x = self.conv2(x)
        x = tf.nn.relu(x)
        x = self.pool2(x)

        return x


if __name__ == '__main__':
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    x_train = x_train.reshape(*x_train.shape, 1)[:1000]
    y_train = y_train.reshape(*y_train.shape, 1)[:1000]

    x_test = x_test.reshape(*x_test.shape, 1)
    y_test = y_test.reshape(*y_test.shape, 1)

    y_train = tf.keras.utils.to_categorical(y_train)
    y_test = tf.keras.utils.to_categorical(y_test)

    model = Classifier()

    inputs = tf.keras.Input((28, 28, 1))

    x = model(inputs)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(10, activation=""sigmoid"")(x)

    model = tf.keras.Model(inputs=inputs, outputs=x)
    model.compile(optimizer=""adam"", loss=""binary_crossentropy"", metrics=[""accuracy""])
    model.fit(x_train, y_train, epochs=1, shuffle=True)

    model.save(""./my_model"")
</code></pre>

<p>Error message:  </p>

<pre><code>1000/1000 [==============================] - 1s 1ms/step - loss: 4.6037 - acc: 0.7025
Traceback (most recent call last):
  File ""/home/user/Data/test/python/mnist/mnist_run.py"", line 62, in &lt;module&gt;
    model.save(""./my_model"")
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1278, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py"", line 101, in save_model
    'config': model.get_config()
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1049, in get_config
    layer_config = layer.get_config()
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1028, in get_config
    raise NotImplementedError
NotImplementedError

Process finished with exit code 1
</code></pre>

<p>I looked into the error line and found out that <strong>get_config</strong> method checks <strong>self._is_graph_network</strong></p>

<p>Do anybody deal with this problem?</p>

<p>Thanks!</p>

<p><strong>Update 1:</strong><br>
On the keras 2.2.2 (not tf.keras)<br>
Found comment (for model saving)<br>
file: keras/engine/network.py<br>
Function: get_config  </p>

<blockquote>
  <p># Subclassed networks are not serializable<br>
  # (unless serialization is implemented by<br>
  # the author of the subclassed network).  </p>
</blockquote>

<p>So, obviously it won't work...<br>
I wonder, why don't they point it out in the <a href=""https://www.tensorflow.org/guide/keras"" rel=""noreferrer"">documentation</a> (Like: ""Use subclassing without ability to save!"")</p>

<p><strong>Update 2:</strong><br>
Found in <a href=""https://keras.io/models/about-keras-models/"" rel=""noreferrer"">keras documentation</a>:  </p>

<blockquote>
  <p>In subclassed models, the model's topology is defined as Python code<br>
  (rather than as a static graph of layers). That means the model's<br>
  topology cannot be inspected or serialized. As a result, the following<br>
  methods and attributes are not available for subclassed models:  </p>
  
  <p>model.inputs        and model.outputs.<br>
  model.to_yaml()     and model.to_json()<br>
  model.get_config()  and model.save().  </p>
</blockquote>

<p><strong>So, there is no way to save model by using subclassing.</strong><br>
It's possible to only use <code>Model.save_weights()</code></p>
",1,Requesting (Additional) Documentation/Examples
200,51824310,Difference between Keras and tensorflow implementation of LSTM with dropout,"<p>I was reviewing the documentation for the LSTM cell in tensorflow and Keras. In particular, I want to apply dropout as well. Here is what I have in Keras and would like to apply the same LSTM cell in tensorflow:</p>

<pre><code>cell = LSTM(num_units_2, return_sequences=True, dropout=dropout, recurrent_dropout=dropout)(net)
</code></pre>

<p>Therefore, I know that I need to use <code>tf.nn.rnn_cell.LSTMCell</code> in tensorflow with <code>num_units = num_units_2</code>. Second, I need a <code>DropoutWrapper</code> as:</p>

<pre><code>cell = tf.nn.rnn_cell.DropoutWrapper(cell)
</code></pre>

<p>Now, I want to apply <code>dropout</code> and <code>recurrent_dropout</code> similar to the Keras code. Therefore, I found that tensorflow's implementation of dropout will apply a different dropout mask at every time step unless <code>variational_recurrent</code> is set to True (Yet I'm not sure how variational_recurrent works in details). </p>

<p>Additionally, I'm not sure if the LSTM in Keras apply different Mask at each time step as well. </p>

<p>Second, I was confused about the difference between the <code>output_keep_prob</code> and the <code>state_keep_prob</code> as both mention: </p>

<p><em>output_keep_prob</em>: unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added...</p>

<p>Any help is much appreciated!!</p>
",1,Documentation Replication on Other Examples
201,51856041,Input dimension for tf.nn.in_top_k,"<p>I am following the TF documentation with respect to in_top_k: <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k</a> where it states that <code>targets</code> should be a vector of <code>batch size</code></p>

<p>Nevertheless, I'm continuously prompted with the following error:</p>

<blockquote>
  <p>InvalidArgumentError (see above for traceback): targets must be
  1-dimensional
           [[Node: in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Cas t_2/_4305, sub/_4307, in_top_k/InTopKV2/k)]]</p>
</blockquote>

<p>In my case, my <code>predictions</code> and <code>targets</code> inputs have the following shapes:</p>

<ul>
<li>predictions: <code>Tensor(""Cast_2:0"", shape=(128, 1000), dtype=float32, device=/device:GPU:0)</code></li>
<li>targets: <code>Tensor(""sub:0"", shape=(128,), dtype=int32, device=/device:GPU:0)</code></li>
</ul>

<p>From my understanding, there is still something not ok with my <code>targets</code> label, and despite using different combinations of tf.reshape or tf.squeeze I cannot seem to find where is the error. Is there any way to work around this issue?</p>
",1,Documentation Ambiguity
202,51858970,"tf.gradients() sums over ys, does it?","<p><a href=""https://www.tensorflow.org/versions/r1.6/api_docs/python/tf/gradients"" rel=""noreferrer"">https://www.tensorflow.org/versions/r1.6/api_docs/python/tf/gradients</a></p>

<p>In the documentation for tf.gradients(ys, xs) it states that </p>

<blockquote>
  <p>Constructs symbolic derivatives of sum of ys w.r.t. x in xs</p>
</blockquote>

<p>I am confused about the summing part, I have read elsewhere that this sums the derivatives dy/dx across the batch for every x in the batch. However, whenever I use this I fail to see this happening. Take the following simple example:</p>

<pre><code>x_dims = 3
batch_size = 4

x = tf.placeholder(tf.float32, (None, x_dims))

y = 2*(x**2)

grads = tf.gradients(y,x)

sess = tf.Session()

x_val = np.random.randint(0, 10, (batch_size, x_dims))
y_val, grads_val = sess.run([y, grads], {x:x_val})

print('x = \n', x_val)
print('y = \n', y_val)
print('dy/dx = \n', grads_val[0])
</code></pre>

<p>This gives the following output:</p>

<pre><code>x = 
 [[5 3 7]
 [2 2 5]
 [7 5 0]
 [3 7 6]]
y = 
 [[50. 18. 98.]
 [ 8.  8. 50.]
 [98. 50.  0.]
 [18. 98. 72.]]
dy/dx = 
 [[20. 12. 28.]
 [ 8.  8. 20.]
 [28. 20.  0.]
 [12. 28. 24.]]
</code></pre>

<p>This is the output I would expect, simply the derivative dy/dx for every element in the batch. I don't see any summing happening. I have seen in other examples that this operation is followed by dividing by the batch size to account for tf.gradients() summing the gradients over the batch (see here: <a href=""https://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html"" rel=""noreferrer"">https://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html</a>). Why is this necessary?</p>

<p>I am using Tensorflow 1.6 and Python 3.</p>
",1,Documentation Ambiguity
203,51859776,lambda layer function definition without tf.keras.backend (Python Keras Package),"<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda"" rel=""nofollow noreferrer"">tf.keras.layers.Lambda</a> documentation explains how a function can be defined in a lambda layer. That document provides the following function as an example,</p>

<pre><code>def antirectifier(x):

    x -= K.mean(x, axis=1, keepdims=True)
    x = K.l2_normalize(x, axis=1)

    pos = K.relu(x)
    neg = K.relu(-x)

    return K.concatenate([pos, neg], axis=1)

model.add(Lambda(antirectifier))
</code></pre>

<p>But according to that, <code>tf.keras.backend</code> must be used to conduct operations on the input Tensor object.</p>

<p>Is there any way we can use default python packages and user-defined function to define the steps of a lambda function.</p>

<p>If it's possible, please be kind enough to provide some examples.</p>
",1,Inadequate Examples
204,51883196,Tensorflow: tf.reverse_sequence - seq_dim and batch_dim,"<p>I am trying to learn Tensorflow and was looking at <code>tf.reverse_sequence</code>. It has two parameters <code>seq_dim</code> and <code>batch_dim</code>. From the documentation given <a href=""https://www.tensorflow.org/api_docs/python/tf/reverse_sequence"" rel=""nofollow noreferrer"">here</a> I understand that setting <code>batch_dim = 0</code> means we go through the the rows from top and setting <code>seq_dim = 1</code> means we go through columns from left to right but what do these numbers mean? I can't understand from the documentation when I should set <code>batch_dim = 1</code> or <code>2</code>. I tried <code>reverse_sequence</code> on <code>x = [[1,2,3], [4,5,6], [7,8,9]]</code> and got <code>[[3,2,1], [6,5,4], [9,8,7]]</code> with <code>batch_dim = 0</code> and <code>seq_dim = 1</code>. But I always get errors when I change <code>seq_dim</code> and <code>batch_dim</code> values from <code>1</code> and <code>0</code> respectively. Could someone explain the meaning of these values?</p>
",1,Lack of Alternative Solutions/Documentation
205,51997426,TensorFlow: alternate between datasets of different output shapes,"<p>I'm trying to use <code>tf.Dataset</code> for a 3D image CNN where the shape of the 3D image fed into it from the training set and the validation set are different (training: (64, 64, 64), validation: (176, 176, 160)). I didn't even know this was possible, but I'm recreating this network based on a paper, and using the classic <code>feed_dict</code> method the network indeed works. For performance reasons (and just to learn) I'm trying to switch the network to use <code>tf.Dataset</code> instead.</p>

<p>I have two datasets and iterators built like the following:</p>

<pre class=""lang-py prettyprint-override""><code>def _data_parser(dataset, shape):
        features = {""input"": tf.FixedLenFeature((), tf.string),
                    ""label"": tf.FixedLenFeature((), tf.string)}
        parsed_features = tf.parse_single_example(dataset, features)

        image = tf.decode_raw(parsed_features[""input""], tf.float32)
        image = tf.reshape(image, shape + (1,))

        label = tf.decode_raw(parsed_features[""label""], tf.float32)
        label = tf.reshape(label, shape + (1,))
        return image, label

train_datasets = [""train.tfrecord""]
train_dataset = tf.data.TFRecordDataset(train_datasets)
train_dataset = train_dataset.map(lambda x: _data_parser(x, (64, 64, 64)))
train_dataset = train_dataset.batch(batch_size) # batch_size = 16
train_iterator = train_dataset.make_initializable_iterator()

val_datasets = [""validation.tfrecord""]
val_dataset = tf.data.TFRecordDataset(val_datasets)
val_dataset = val_dataset.map(lambda x: _data_parser(x, (176, 176, 160)))
val_dataset = val_dataset.batch(1)
val_iterator = val_dataset.make_initializable_iterator()
</code></pre>

<p><a href=""https://www.tensorflow.org/guide/datasets#creating_an_iterator"" rel=""nofollow noreferrer"">TensorFlow documentation</a> has examples regarding switching between datasets using <code>reinitializable_iterator</code> or <code>feedable_iterator</code>, but they all switch between iterators of <strong>same</strong> output shape, which is not the case here.</p>

<p>How should I switch between training set and validation set using <code>tf.Dataset</code> and <code>tf.data.Iterator</code> in my case then?</p>
",1,Lack of Alternative Solutions/Documentation
206,52035692,Tensorflow v1.10: store images as byte strings or per channel?,"<h2>Context</h2>
<p>It is known that, at the moment, TF's Record documentation leaves something to be desired.</p>
<p>My question is in regards to what is optimal for storing:</p>
<ul>
<li>a sequence,</li>
<li>its per-element class probabilities, and</li>
<li>some (context?) information (e.g. name of the sequence)</li>
</ul>
<p>as a TF Record.</p>
<p>Namely, this questions considers storing the sequence and class probabilities as channels vs as a byte string and whether or not the meta information should go in as features of a <code>tf.train.Example</code> or as the context of a <code>tf.train.SequenceExample</code>. (see questions at the bottom).</p>
<h2>M.W.E.</h2>
<p>For example, lets assume my looks sequence like this</p>
<pre><code>seq = [ 
        # el1, el2 
        [ 0,   1   ], # channel 1
        [ 0,   1   ]  # channel 2
      ]
</code></pre>
<p>i.e. it is a 2 channel sequence of <em>fixed</em> length (in this example, 2) where the values can only be integer value.</p>
<p>and that we have three classes for which we are trying to segment the sequence into</p>
<pre><code>cls_probs = [ 
        #cls1, cls2, cls3
        [0   , 0.9 , 0.1 ], # class probabilities element 1
        [0   , 0.1 , 0.9 ]  # class probabilities element 2
      ]
</code></pre>
<p>where in effect both <code>seq</code> and <code>cls_probs</code> are <code>numpy.array</code>s.</p>
<p>The network only <em>requires</em> this information. However, I also have some meta data which I would like to keep with the sequence.</p>
<p>e.g.</p>
<pre><code>meta = {
           'name': 'my_seq',  # safer to keep this with the data rather than as file name
           'meta_val_1': 100, # not used by network, but may be useful when evaluating network's predictions for this particular sequence
           'meta_val_2': 10
       }
</code></pre>
<h1>Making TF Record</h1>
<h2>tf.train.Example</h2>
<p>Then I have several ways I could construct my <code>tf.train.Example</code>:</p>
<h3>as channels</h3>
<pre><code>example = tf.train.Example(
    features = tf.train.Features(
        feature = {
            'channel_1': tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,0])),
            'channel_2': tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,1])),
            'class_1'  : tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,0])),
            'class_2'  : tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,1])),
            'class_3'  : tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,2])),
            'name'     : tf.train.Feature(bytes_list=tf.train.BytesList(value=[f'{meta[&quot;name&quot;]}'.encode('utf-8')])), 
            # should these be FloatList even though it is just a single value?
            # should these be included here if they are not used by the network?
            'val_1'    : tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_1&quot;]}'])),
            'val_2'    : tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_2&quot;]}'])),
    })
)
</code></pre>
<p>where <code>f'{variable}'.encode('utf-8')</code> is the currently not suggested <a href=""https://www.python.org/dev/peps/pep-0498/"" rel=""nofollow noreferrer""><code>fb'&lt;string&gt;'</code></a> (note: <code>f-strings</code> only work with python3.6+).</p>
<p>This format is somewhat nice as each sequence channel is explicit. However it is also verbose and requires preprocessing when loaded to be feed into the network.</p>
<h3>as string</h3>
<p>or, I could dump my array to an string</p>
<pre><code>example = tf.train.Example(
    features = tf.train.Features(
        feature = {
            'sequence' : tf.train.Feature(bytes_list=tf.train.BytesList(value=seq.tostring())),
            'cls_probs': tf.train.Feature(bytes_list=tf.train.BytesList(value=cls_probs.tostring())),
            # ... see encoding of meta values from above
    })
)
</code></pre>
<h2>tf.train.SequenceExample</h2>
<p>TF Records also accept another form: <code>tf.train.SequenceExample</code>. <code>SequenceExample</code> expects context features and an ordered list of unnamed features.</p>
<h3>as channels</h3>
<p>So restructuring above's as <em>channels</em> example:</p>
<pre><code>example = tf.train.SequenceExample(
    context = tf.train.Features(
        feature = {
            'Name' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[f'{meta[&quot;name&quot;]}'.encode('utf-8')])), 
            'Val_1': tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_1&quot;]}'])),
            'Val_2': tf.train.Feature(float_list=tf.train.FloatList(value=[f'{meta[&quot;meta_val_2&quot;]}'])),
        }
    ),
    feature_lists = tf.train.FeatureLists(
        feature_list = {
            'sequence': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,0])),
                    tf.train.Feature(int64_list=tf.train.Int64List(value=seq[:,1])),
                ]
            ),
            'class_probabilities': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,0])),
                    tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,1])),
                    tf.train.Feature(float_list=tf.train.FloatList(value=cls_probs[:,2]))
                ]
            )
        }
    )
)
</code></pre>
<h3>as string</h3>
<p>likewise we can create the as <em>string</em> example:</p>
<pre><code>example = tf.train.SequenceExample(
    context = tf.train.Features(
        # see above
    ),
    feature_lists = tf.train.FeatureLists(
        feature_list = {
            'sequence': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(bytes_list=tf.train.BytesList(value=seq.tostring()))
                ]
            ),
            'class_probabilities': tf.train.FeatureList(
                feature = [
                    tf.train.Feature(bytes_list=tf.train.BytesList(value=cls_probs.tostring()))
                ]
            )
        }
    )
)
</code></pre>
<h1>Questions</h1>
<p>Here I gave a M.W.E. for how one could construct an example (ready to be exported to a TF Record) as both <code>tf.train.Example</code> and <code>tf.train.SequenceExample</code>. Further, I demonstrated both how to do this per channel or by dumping as a byte string. Both of these methods (as channels / as strings) include the meta information within the example.</p>
<p>Thus my questions are:</p>
<ol>
<li><p>which way (as channels / as string) of storage is more optimal (for read, write, re-use, etc) ?</p>
</li>
<li><p>given the meta information which should be kept with the example, is better to use <code>tf.train.Example</code> and store the meta information as features there? or use <code>tf.train.SequenceExample</code> and store the meta information in the context argument?</p>
</li>
</ol>
<p>Does anyone know if there are any notable advantages / disadvantages for any of four these strategies?</p>
<p>For those who would like to test this on larger less dummy like data, some functions for producing this code can be found <a href=""https://stackoverflow.com/a/52041027/5623899""><strong>below</strong></a></p>
<p>Lastly, I would like to point out this <a href=""https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564"" rel=""nofollow noreferrer"">medium post</a> which greatly elaborates on TF's docs.</p>
",1,Documentation Replication on Other Examples
207,52073782,Computations (such as tf.greater and tf.cond) on random value tensors not working as expected,"<p>I am a tensorflow beginner. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/greater"" rel=""nofollow noreferrer"">documentation</a>, <strong>tf.greater returns the truth value of (x>y) element-wise</strong></p>

<p>My code is as below:</p>

<pre><code>x = tf.random_uniform([])  # Empty array as shape creates a scalar.
y = tf.random_uniform([])
print('x: '+str(x.eval()))
print('y: ' +str(y.eval()))
out = tf.cond(tf.greater(x, y), lambda: x + y, lambda: x - y)
print(sess.run(tf.greater(x, y)))
print(sess.run(out))
</code></pre>

<p>The output I got is:</p>

<pre><code>x: 0.79379404
y: 0.30891895
False
0.3438499
</code></pre>

<p>x is bigger than y so it should return True and x+y should be 1.10271299
why is my expected output different than the actual output?</p>
",1,Documentation Replication on Other Examples
208,52134130,How to restrict the absolut value of each dimention of a sparse gradient from being too large?,"<p>Consider the code below:</p>

<pre><code>import tensorflow as tf

inputs=tf.placeholder(tf.int32, [None])
labels=tf.placeholder(tf.int32, [None])

with tf.variable_scope('embedding'):
    embedding=tf.get_variable('embedding', shape=[2000000, 300], dtype=tf.float32)

layer1=tf.nn.embedding_lookup(embedding, inputs)
logits=tf.layers.dense(layer1, 2000000)

loss=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)
cost=tf.reduce_sum(loss)

optimizer=tf.train.GradientDescentOptimizer(0.01)
grads, vars=zip(*optimizer.compute_gradients(cost))
for g in grads:
    print(0, g)

grads1=[tf.clip_by_value(g, -100, 100) for g in grads]
for g in grads1:
    print(1, g)

grads2, _=tf.clip_by_global_norm(grads, 10)
for g in grads2:
    print(2, g)
</code></pre>

<p>The output is:</p>

<pre><code>0 IndexedSlices(indices=Tensor(""gradients/embedding_lookup_grad/Reshape_1:0"", shape=(?,), dtype=int32), values=Tensor(""gradients/embedding_lookup_grad/Reshape:0"", shape=(?, 300), dtype=float32), dense_shape=Tensor(""gradients/embedding_lookup_grad/ToInt32:0"", shape=(2,), dtype=int32))
0 Tensor(""gradients/dense/MatMul_grad/tuple/control_dependency_1:0"", shape=(300, 2000000), dtype=float32)
0 Tensor(""gradients/dense/BiasAdd_grad/tuple/control_dependency_1:0"", shape=(2000000,), dtype=float32)
C:\Python\Python36\lib\site-packages\tensorflow\python\ops\gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 600000000 elements. This may consume a large amount of memory.
  num_elements)
1 Tensor(""clip_by_value:0"", shape=(?, 300), dtype=float32)
1 Tensor(""clip_by_value_1:0"", shape=(300, 2000000), dtype=float32)
1 Tensor(""clip_by_value_2:0"", shape=(2000000,), dtype=float32)
2 IndexedSlices(indices=Tensor(""gradients/embedding_lookup_grad/Reshape_1:0"", shape=(?,), dtype=int32), values=Tensor(""clip_by_global_norm/clip_by_global_norm/_0:0"", shape=(?, 300), dtype=float32), dense_shape=Tensor(""gradients/embedding_lookup_grad/ToInt32:0"", shape=(2,), dtype=int32))
2 Tensor(""clip_by_global_norm/clip_by_global_norm/_1:0"", shape=(300, 2000000), dtype=float32)
2 Tensor(""clip_by_global_norm/clip_by_global_norm/_2:0"", shape=(2000000,), dtype=float32)
</code></pre>

<p>I know there are two ways to restrict gradients from being too large. <code>tf.clip_by_value</code> to restrict each dimentions, and <code>tf.clip_by_global_norm</code> to restrict according global gradients norms.</p>

<p>However, <code>tf.clip_by_value</code> will cast a sparse gradient into a dense one, which significantly increase the memory usage and decreases the calculation efficiency, just as the warning indicates, while <code>tf.clip_by_global_norm</code> will not. Although I can understand why this is designed, how can I restrict the absolut value of each dimention of a sparse gradient from being too large without efficiency decrease?</p>

<p>Please don't tell me just use <code>tf.clip_by_global_norm</code>, I know this is ok for most cases, but is not what I want.</p>
",1,Lack of Alternative Solutions/Documentation
209,52254253,How does tf.layers.dense() interact with inputs of higher dim?,"<p>In tensorflow layers.dense(inputs, units, activation) implements a Multi-Layer Perceptron layer with arbitrary activation function. </p>

<p>Output = activation(matmul(input, weights) + bias)</p>

<p>Typically input has shape=[batch_size, input_size] and might look like this: (units = 128 and activation = tf.nn.relu are chosen arbitrarily)</p>

<pre><code>inputx = tf.placeholder(float, shape=[batch_size, input_size])
dense_layer = tf.layers.dense(inputx, 128, tf.nn.relu)
</code></pre>

<p>I have not found any documentation on what would happen, if i fed higher dimensional input, e.g. because one might have time_steps resulting in a tensor of shape=[time_step, batch_size, input_size]. What one would want here is that the layer is applied to each single input_vector for each timestep for each element of the batch. To put it a bit differently, the internal matmul of layers.dense() should simply use broadcasting in numpy style. Is the behaviour i expect here what actually happens? I.e. is: </p>

<pre><code>inputx = tf.placeholder(float, shape=[time_step, batch_size, input_size])
dense_layer = tf.layers.dense(inputx, 128, tf.nn.relu)
</code></pre>

<p>applying the dense layer to each input of size input_size for each time_step for each element in batch_size? This should then result in a tensor(in dense_layer above) of shape=[time_step, batch_size, 128]
I'm asking, as e.g. tf.matmul does not support broadcasting in the numpy style, so i'm not sure, how tensorflow handles these cases.</p>

<p>Edit: <a href=""https://stackoverflow.com/questions/46697389/reshape-3d-tensor-before-dense-layer"">This post is related, but does not finally answer my question</a></p>
",1,Lack of Alternative Solutions/Documentation
210,52319765,Swap a TensorFlow Dataset input pipeline with a placeholder after training,"<p>I'm working with the new <code>tf.data.Dataset</code> API and I can't seem to figure out how to perform inference. Ultimately, I want to convert my model to a TensorRT graph and run it on the TX2, and all of the <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/python_api/workflows/tf_to_tensorrt.html#Importing-the-UFF-Model-into-TensorRT-and-Building-an-Engine"" rel=""noreferrer"">examples I have found</a> assume you have a <code>tf.placeholder</code> for the input. Here is pseudocode for how I am training. The [...] is just meant to be a placeholder since I didn't actually run the code. Let's not debate the model, as it is just suppose to give an example:</p>

<pre><code>import tensorflow as tf

# Setup iterator
datain = tf.data.FixedLengthRecordDataset(datafiles, record_bytes1)
labels = tf.data.FixedLengthRecordDataset(labelfiles, record_bytes2)
dataset = tf.data.Dataset.zip((datain, labels))
dataset = dataset.prefetch(batch_size)
dataset = dataset.repeat(n_epoch)
iterator = dataset.make_initializable_iterator()

sess = tf.Session()
sess.run(iterator.initializer)
[batch_x, batch_y] = iterator.get_next()

# Define model function (let's not debate model except as relevant to question)
def model_fn(xin):
    x0 = tf.transpose(tf.reshape(xin, [...], name='input'))
    w = tf.Variable(tf.truncated_normal([...], stddev=0.1))
    x1 = tf.nn.conv2d(x0, w, strides=[...], padding='VALID')
    b = tf.Variable(tf.constant(0.0, shape=[...]))
    x2 = tf.nn.bias_add(x1, b)
    x3 = tf.nn.relu(x2, name='output')
    return x3

# Setup training environment
model = model_fn(batch_x)
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=batch_y))
optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)

# Train Model
while True:
    try:
        sess.run(optimizer)
    except tf.errors.OutOfRangeError:
        break

# Save model
saver = tf.train.Saver(name='saver')
saver.save(sess, 'temp/path')
</code></pre>

<p>My question is how do I get this into TensorRT without having the input be a <code>tf.placeholder</code>? All of the example I can find use a <code>tf.placeholder</code> as the input. <a href=""https://stackoverflow.com/questions/50061416/freezing-graph-in-tensorflow-when-using-tf-image-dataset/"">This example</a> suggests that I can replace the iterator with a placeholder using the <code>SavedModel</code> class, but I cannot seem to find any documentation on how to accomplish that.</p>

<p>Thanks!</p>

<p><strong>EDIT: Here is my solution thanks to the help below</strong></p>

<pre><code>from tensorflow.python.tools import optimize_for_inference_lib
import uff

# You can feed data to the IteratorGetNext node using feed_dict
input_node_name = 'iterator_scope_name/IteratorGetNext'
output_node_name = 'model_scope_name/output'

# Run inference on the trained model:
graph = tf.get_default_graph()
batch_x = graph.get_tensor_by_name(input_node_name + ':0')
networkout = graph.get_tensor_by_name(output_node_name + ':0')
testdata, testlabel = custom_data_reader_fn(data_folder)
# This will evaluate the model
label = sess.run(networkout, feed_dict={batch_x: testdata})

# Freeze model and create a UFF file:
graph_def = graph.as_graph_def() # Convert the graph to a serialized pb
frozen_graph_def = tf.graph_util.convert_variables_to_constants(sess,
    graph_def, [output_node_name])
opt_graph_def = optimize_for_inference_lib.optimize_for_inference(
    frozen_graph_def, [input_node_name], [output_node_name],
    tf.float32.as_datatype_enum)
uff.from_tensorflow(opt_graph_def, [output_node_name], quiet=False,
    output_filename='opt_model.uff')
</code></pre>

<p>that will write out a UFF file that TensorRT can utilize. The biggest issues that I encountered was:</p>

<ol>
<li>I didn't realize that the <code>optimize_for_inference_lib.optimize_for_inference</code> operation replaced the <code>iterator</code> with a <code>tf.placeholder</code></li>
<li>I did not know what node to feed data to for evaluation: you can feed data to the <code>IteratorGetNext</code> node</li>
</ol>
",1,Lack of Alternative Solutions/Documentation
211,52471921,Why there is a need of using tf.Variable?,"<p>In the following code I am unable to understand the need of using tf.Variable? I get the same value whether I use tf.Variable or omit it.</p>

<pre><code>`initial = tf.Variable(tf.truncated_normal(shape=[1,10,1], mean=0, 
stddev=0.1,seed=123))`
</code></pre>
",1,Documentation Replicability
212,52473088,How tf.Variable maintains state of the graph?,"<p>I am trying to learn tensorflow. I am really confused with the usage of tf.Variable . I know that in machine learning we have to randomly assign weights to the filter. But this can be done with tf.truncated_normal function. Then what is the role of tf.Variable here? Documentation states that tf.Variable maintains the state of graph. What does it mean? If I omit tf.Variable result is same. So what is the role of tf.Variable? Can someone please help me to understand this?  </p>

<pre><code>`def weight_variable(shape):
    initial = tf.truncated_normal(shape, mean=0, stddev=0.1)
    return tf.Variable(initial)
#function call
filter = weight_variable([1,2,2,1])`
</code></pre>
",1,Lack of Alternative Solutions/Documentation
213,52533156,Weight Initialization Tensorflow tf.estimator,"<p>Is there a way to adjust the weight initialization in the pre-built tf.estimator?
I would like to use the method after Xavier (<code>tf.contrib.layers.xavier_initializer</code>) or from He. Which method is used by default? I couldn't figure it out from the documentation. </p>

<p>I use the DNNRegressor.</p>
",1,Documentation Ambiguity
214,52572275,tensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)?,"<p>I've read the <a href=""https://www.tensorflow.org/api_docs/python/tf/manip/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_nd documentation</a> and run the example code for 1D and 3D tensors... and now I'm trying to do it for a 2D tensor.  I want to 'interleave' the columns of two tensors.  For 1D tensors, one can do this via</p>

<pre><code>'''
We want to interleave elements of 1D tensors arr1 and arr2, where
arr1 = [10, 11, 12]
arr2 = [1, 2, 3, 4, 5, 6]
such that
desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12]
'''

import tensorflow as tf

with tf.Session() as sess:

    updates1 = tf.constant([1,2,3,4,5,6])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)

    updates2 = tf.constant([10,11,12])
    indices2 = tf.constant([[2], [5], [8]])
    scatter2 = tf.scatter_nd(indices2, updates2, shape)

    result = scatter1 + scatter2

    print(sess.run(result))
</code></pre>

<p>(aside: is there a <em>better</em> way to do this?  I'm all ears.)</p>

<p>This gives the output</p>

<p><code>[ 1  2 10  3  4 11  5  6 12]</code></p>

<p>Yay! that worked!</p>

<p>Now lets' try to extend this to 2D.</p>

<pre><code>    '''
    We want to interleave the *columns* (not rows; rows would be easy!) of

    arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]
    arr2 = [[10 11 12], [10 11 12], [10 11 12]]
    such that
    desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]]
    '''

    updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([3, 9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)
</code></pre>

<p>This gives the error
<code>ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1
dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but
are 6 and 3. Shapes are [6] and [3]. for 'ScatterNd_2' (op: 'ScatterNd') with
input shapes: [6,1], [3,6], [2].</code></p>

<p>Seems like my <code>indices</code> is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean
I need to <em>explicitly</em> specify every single pair of indices for every element in <code>updates1</code>?
Or is there some kind of 'wildcard' specification I can use for the rows? (Note <code>indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]])</code> gives syntax errors, as it probably should.)</p>

<p>Would it be easier to just do a transpose, interleave the rows, then transpose back?
Because I tried that...</p>

<pre><code>scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))
print(sess.run(tf.transpose(scatter1)))
</code></pre>

<p>...and got a <em>much</em> longer error message, that I don't feel like posting unless someone requests it. </p>

<p>PS- I searched to make sure this isn't a duplicate -- I find it hard to imagine that someone else hasn't asked this before -- but turned up nothing. </p>
",1,Documentation Replication on Other Examples
215,52591291,Tensorflow Estimator: loss not decreasing when using tf.feature_column.embedding_column for a list of categorical variables,"<p>I'm very new to Tensorflow Estimator. I wonder if it's possible to pass an array of categorical variables as feature to the estimator and it automatically converts it to an array of embeddings. For example, the following is a record in a CSV file. It contains 2 lists of categorical variables(enclosed in brackets), ""country"" and ""watch"", 2 categorical variables, ""day_of_week"" and ""day_period"" and one target, ""movie_id"" in this case.</p>

<pre><code>day_of_week,day_period,country,movie_id,watched
SUNDAY,EVENING,[USA,UK],B2JO1owWbeLn,[WGdZ5qZmLw0,abcdef]
MONDAY,EVENING,[China],xxx,[abc,def,ijk]
</code></pre>

<p>According to the doc <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/feature_column</a>, ""day_of_week"" and ""day_period"" can be represented as ""categorical_column_with_vocabulary_list"". This is straightforward. However, ""country"", and ""watched"" are a list of categorical variables. I'd like to merge each categorical variable in a list to an embedding. From the same doc, a ""tf.feature_column.embedding_column"" would do the trick.</p>

<p>The following function builds columns representing the above input.</p>

<pre><code>def build_model_columns():
    day_of_week = tf.feature_column.categorical_column_with_vocabulary_list('day_of_week', day_of_weeks)
    day_period = tf.feature_column.categorical_column_with_vocabulary_list('day_period', day_periods)
    country = tf.feature_column.categorical_column_with_vocabulary_list('country', countries)
    watched = tf.feature_column.categorical_column_with_vocabulary_list('watched', movie_emb_ids)

    columns = [
        tf.feature_column.indicator_column(day_of_week),
        tf.feature_column.indicator_column(day_period),
        tf.feature_column.embedding_column(country, 8),
        tf.feature_column.embedding_column(watched, 32)
    ]
    return columns
</code></pre>

<p>The following is a function generating training dataset</p>

<pre><code>def tensor_to_array(tensor):
    length = tf.size(tf.string_split([tensor], """"))
    sub = tf.substr(tensor, 1, length-2) # remove the leading '[' and trailing ']'
    splits = tf.string_split([sub], delimiter=',')
    return splits

def train_input_fn():
    train_files = ""train.csv""
    target_files = ""target.csv""
    target_table, target_ids = read_table_lookup(target_files, ""movie"")

    def preprocess(day_of_week, day_period, country, movie_id, watched):

        features = {
            'day_of_week': day_of_week,
            'day_period': day_period,
            'country': tensor_to_array(country),
            'watched': tensor_to_array(watched)

        }
        # target_table is a lookup table converting ""movie_id"" to integer ""id""
        return features, target_table.lookup(movie_id) 

    dataset = (tf.contrib.data.CsvDataset(train_files, record_defaults, header=True)
           .map(preprocess, num_parallel_calls=5)
           .batch(batch_size=batch_size, drop_remainder=False)
           .repeat()
          )

    # iterator = dataset.make_initializable_iterator()
    # tf.add_to_collection(tf.GraphKeys.TABLE_INITIALIZERS, iterator.initializer)

    return dataset 
</code></pre>

<p>The following is a code snippet to create and train an estimator.</p>

<pre><code>hidden_units = [512, 512]
record_defaults = [[""""]] * 5
columns = build_model_columns()
estimator = tf.estimator.DNNClassifier(model_dir=""dir"",
                                   feature_columns=columns,
                                   hidden_units=hidden_units,
                                   n_classes=len(target_ids)) # length of all targets

estimator.train(input_fn=train_input_fn)
</code></pre>

<p>I got no error and it seems like everything should work as expected but the training loss is so huge and fluctuating around 3,xxx and never decreasing. See below</p>

<pre><code>INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /home/cocoza4/movie_models/deep/model.ckpt.
INFO:tensorflow:loss = 6538.0645, step = 0
INFO:tensorflow:global_step/sec: 17.353
INFO:tensorflow:loss = 3596.562, step = 100 (5.764 sec)
INFO:tensorflow:global_step/sec: 17.434
INFO:tensorflow:loss = 3504.936, step = 200 (5.736 sec)
INFO:tensorflow:global_step/sec: 17.4234
INFO:tensorflow:loss = 3500.0488, step = 300 (5.739 sec)
INFO:tensorflow:global_step/sec: 17.5321
INFO:tensorflow:loss = 3480.702, step = 400 (5.705 sec)
INFO:tensorflow:global_step/sec: 17.4534
INFO:tensorflow:loss = 3517.599, step = 500 (5.729 sec)
INFO:tensorflow:global_step/sec: 17.3421
INFO:tensorflow:loss = 3446.142, step = 600 (5.769 sec)
INFO:tensorflow:global_step/sec: 17.313
INFO:tensorflow:loss = 3281.3088, step = 700 (5.776 sec)
INFO:tensorflow:global_step/sec: 17.4421
INFO:tensorflow:loss = 3326.7336, step = 800 (5.731 sec)
INFO:tensorflow:global_step/sec: 17.3619
INFO:tensorflow:loss = 3464.902, step = 900 (5.762 sec)
INFO:tensorflow:global_step/sec: 17.2013
INFO:tensorflow:loss = 3364.2153, step = 1000 (5.813 sec)
INFO:tensorflow:global_step/sec: 17.4429
INFO:tensorflow:loss = 3410.449, step = 1100 (5.734 sec)
INFO:tensorflow:global_step/sec: 17.0483
INFO:tensorflow:loss = 3351.018, step = 1200 (5.866 sec)
INFO:tensorflow:global_step/sec: 17.4214
INFO:tensorflow:loss = 3386.995, step = 1300 (5.740 sec)
INFO:tensorflow:global_step/sec: 17.7965
INFO:tensorflow:loss = 3263.6074, step = 1400 (5.617 sec)
INFO:tensorflow:global_step/sec: 17.6944
INFO:tensorflow:loss = 3321.574, step = 1500 (5.652 sec)
INFO:tensorflow:global_step/sec: 17.3603
INFO:tensorflow:loss = 3234.7761, step = 1600 (5.760 sec)
</code></pre>

<p>I wonder if I've done something wrong when preparing the training data?</p>

<p>thanks</p>

<p>Peeranat F.</p>
",1,Documentation Replicability
216,52802359,Problem with tf.SparseTensor and tf.while_loop,"<p>I face a problem when I try to change the shape of <code>tf.SparseTensor</code> inside a <code>tf.while_loop</code>. Let's say I have this sparse tensor:</p>

<pre><code>indices = np.array([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5],
               [1, 0], [1, 1], [1, 3], [1, 4], [1, 5],
               [2, 1], [2, 2], [2, 3], [2, 4],
               [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5],
               [4, 0], [4, 2], [4, 3], [4, 4], [4, 5]], dtype=np.int64)

values = np.array([7, 6, 7, 4, 5, 4,
              6, 7, 4, 3, 4,
              3, 3, 1, 1,
              1, 2, 2, 3, 3, 4,
              1, 1, 2, 3, 3], dtype=np.float64)

dense_shape = np.array([5, 6], dtype=np.int64)

tRatings = tf.SparseTensor(indices, values, dense_shape)
</code></pre>

<p>So, I want to take a slice from the first 3 rows. I know for that purpose I can use <code>tf.sparse_slice</code> but this is an example. In my real code, I gather multiple rows from the sparse Tensor which they are not serial. The code I wrote is this:</p>

<pre><code>subTensor = tf.sparse_slice(tRatings, [0, 0], [1, 6])

i = tf.constant(1)
def condition(i, sub):
    return tf.less(i, 3)

def body(i, sub):
    tempUser = tf.sparse_slice(tRatings, [i, 0], [1, 6])
    sub = tf.sparse_concat(axis = 0, sp_inputs = [sub, tempUser])
    return [tf.add(i, 1), sub]

subTensor = tf.while_loop(condition1, body1, [i, subTensor], shape_invariants=[i.get_shape(), tf.TensorShape([2])])[1] 
</code></pre>

<p>which does't work for some reason when I run it. I get this:</p>

<pre><code>ValueError: Dimensions 1 and 2 are not compatible
</code></pre>

<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/while_loop</a> it says that:</p>

<p>The shape_invariants argument allows the caller to specify a less specific shape invariant for each loop variable, which is needed if the shape varies between iterations. The tf.Tensor.set_shape function may also be used in the body function to indicate that the output loop variable has a particular shape. The shape invariant for SparseTensor and IndexedSlices are treated specially as follows:</p>

<p>a) If a loop variable is a SparseTensor, the shape invariant must be TensorShape([r]) where r is the rank of the dense tensor represented by the sparse tensor. It means the shapes of the three tensors of the SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here is the shape of the SparseTensor.dense_shape property. It must be the shape of a vector.</p>

<p>What am I missing here?</p>
",1,Documentation Replication on Other Examples
217,52878311,How to extract rows and columns from a 3D array in Tensorflow,"<p>I wanted to do the following indexing operation on a TensorFlow tensor.
What should be the equivalent operations in TensorFlow to get <code>b</code> and <code>c</code> as output? Although <code>tf.gather_nd</code> documentation has several examples but I could not generate equivalent <code>indices</code> tensor to get these results.</p>
<pre><code>import tensorflow as tf
import numpy as np

a=np.arange(18).reshape((2,3,3))

idx=[2,0,1] #it can be any validing re-ordering index list

#These are the two numpy operations that I want to do in Tensorflow
b=a[:,idx,:]
c=a[:,:,idx] 

# TensorFlow operations

aT=tf.constant(a)
idxT=tf.constant(idx)

# what should be these two indices  
idx1T=tf.reshape(idxT, (3,1)) 
idx2T=tf.reshape(idxT, (1,1,3))

bT=tf.gather_nd(aT, idx1T ) #does not work
cT=tf.gather_nd(aT, idx2T)  #does not work

with tf.Session() as sess:
    b1,c1=sess.run([bT,cT])

print(np.allclose(b,b1))
print(np.allclose(c,c1))
</code></pre>
<p>I am not restricted to <code>tf.gather_nd</code> Any other suggestion to achieve the same operations on GPU will be helpful.</p>
<h1>Edit: I have updated the question for a typo:</h1>
<p>old statement: <code>c=a[:,idx]</code>,</p>
<p>New statement: <code>c=a[:,:,idx]</code>
What I wanted to achieve was re-ordering of columns as well.</p>
",1,Inadequate Examples
218,52956268,tf.data.Dataset: Map fails to split string,"<p>I have a <code>tf.data.Dataset</code> that I've created like this:</p>

<pre><code>dataset = tf.data.Dataset.from_tensor_slices(({""reviews"": x_train}, y_train))
</code></pre>

<p>I want to split just the reviews (strings) on whitespace.  When I do this:</p>

<pre><code>dataset = dataset.map(lambda string: tf.string_split([string]))
</code></pre>

<p>Python complains, telling me:</p>

<pre><code>TypeError: &lt;lambda&gt;() takes exactly 1 argument (2 given)
</code></pre>

<p>I've looked at the docs and it's not obvious why Python thinks I've given two arguments...any ideas?</p>

<p>Thanks!</p>
",1,Documentation Replicability
219,52969867,make tensorflow dataset from huge number of images(*.jpg) and labels(*.mat),"<p>I have a huge number of images with their labels (.mat) file (cannot use <code>tf.data.Dataset.from_tensor_slices()</code>) and I want to use <code>tf.data</code> API to make a tensorflow dataset out of it.</p>

<p>As I read in the documentation, I can use <code>tf.data.TextLineDataset</code> for large number of data(I have to have a txt file with the address of all the images and send the path of the txt file as <code>tf.data.TextLineDataset</code> argument).
Then, I can use <code>map</code> method to read txt file (<code>tf.read_file</code>) decode jpg image (<code>tf.image.decode_jpeg</code>) and do some basic transformation on the image.</p>

<p>However, I cannot use <code>scipy.io.loadmat</code> in any part of <code>map</code> method because I have no string indicating the path to the mat file. All I have is <code>tf.Tensor</code>.</p>

<p>I don't think that reading all images and making a TFRecord out of it is that much efficient in this case because then I am basically doing every thing two times. Once, reading the whole images and making TFRecord, and once again, reading TFRecord to make tensorflow dataset.</p>

<p>Any idea how I can resolve this issue?</p>

<p>This is my code:</p>

<pre><code>dataset = tf.data.TextLineDataset(txt_file).map(read_img_and_mat)
</code></pre>

<p>and then:</p>

<pre><code>def read_img_and_mat(path):
    image_string = tf.read_file(path)
    image_decoded = tf.image.decode_jpeg(image_string, channels=3)
    label = ... # get label from mat file
    return image_decoded, label
</code></pre>
",1,Documentation Replication on Other Examples
220,52976606,Global step not incrementing with batch norm and custom estimator,"<p>I have a customer estimator that has several layers that look like the following in the model function:</p>

<pre><code>natural_layer = tf.layers.dense(inputs = natural_layer, 
                                units = units, 
                                activation = None,
                                use_bias = False,
                                kernel_regularizer = params['regularizer'],
                                name = 'pre_batch_norm_layer_' + str(i + 1))

natural_layer = tf.layers.batch_normalization(natural_layer,
                                              axis = 1,
                                              center = True,
                                              scale = True,
                                              training = (mode == tf.estimator.ModeKeys.TRAIN),
                                              name = 'batch_norm_layer_' + str(i + 1))

natural_layer = params['natural_layer_activation'](natural_layer, name = 'activation_layer_' + str(i + 1))
</code></pre>

<p>Because I'm using batch norm, the training op is set up like this:</p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    optimizer = tf.contrib.opt.MultitaskOptimizerWrapper(params['optimization_algorithm'](params['training_rate']))
    train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())
</code></pre>

<p>Where the optimizer is usually tf.train.AdamOptimizer.</p>

<p>However, when I go to train the estimator the global step never increments (so training will run forever), and I get this:</p>

<p>WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.</p>

<p>I am passing tf.train.get_global_step() to minimize, so I'm not sure why it never gets updated. My hunch is that it has something to do with the batch normalization because when I remove that or replace it with dropout, everything works fine (even when keeping the update ops lines that are required for batch normalization per the documentation).</p>

<p>Anyone know what is going on? Happy to post more code if helpful. </p>
",1,Documentation Replication on Other Examples
221,53032922,TensorFlow while loop with condition dependent on body,"<p>I want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don't know how to accomplish this with <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop()</code></a>.</p>

<p>My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by</p>

<pre><code>import numpy as np
import tensorflow as tf
IMAGE_SHAPE = [960, 720]
CROP_SHAPE = [320, 240]
max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE)
crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index)
img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])
</code></pre>

<p>and the condition is</p>

<pre><code>cond = tf.count_nonzero(img_crop &gt; 0) &gt; 0.5 * tf.size(img_crop)
</code></pre>

<p>Going over the documentation and examples of <code>tf.while_loop(cond, body, loop_vars, ...)</code>, what I understand is that both <code>cond</code> and <code>body</code> should take the same arguments given in <code>loop_vars</code>.
I don't see how I can have <code>cond</code> depend on <code>img_crop</code> which would be calculated inside <code>body</code>, and isn't provided in <code>loop_vars</code>.</p>

<p>I could equivalently compute <code>cond</code> using <code>crop_begin_index</code> without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem.</p>

<p>Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use <code>tf.while_loop()</code>?</p>
",1,Documentation Replication on Other Examples
222,53053649,Tensorflow: Truncating a Tensor Seems to Have No Effect,"<p>I'm using the <code>tf.data.Dataset</code> API and am trying to truncate a bunch of tensors to length 100.  Here's what my <code>dataset</code> looks like:</p>

<pre><code>dataset = tf.data.Dataset.from_tensor_slices(({'reviews': x}, y))
</code></pre>

<p>My reviews are just movie reviews (strings), so I perform some preprocessing and map that function on my dataset:</p>

<pre><code>def preprocess(x, y):
    # split on whitespace
    x['reviews'] = tf.string_split([x['reviews']])
    # turn into integers
    x['reviews'], y = data_table.lookup(x['reviews']), labels_table.lookup(y)
    x['reviews'] = tf.sparse_tensor_to_dense(x['reviews'])
    # truncate at length 100
    x['reviews'] = x['reviews'][:100]
    x['reviews'] = x['reviews'][0]
    x['reviews'] = tf.pad(x['reviews'],
           paddings=[[100 - tf.shape(x['reviews'])[0], 0]],
           mode='CONSTANT',
           name='pad_input',
           constant_values=0)
    return x, y

dataset = dataset.map(preprocess)
</code></pre>

<p>However, my code fails with:</p>

<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Paddings must be non-negative: -140 0
</code></pre>

<p>On an input of length 240. So, it seems like my padding step calculates 100 - 240 = -140 and I get this error.</p>

<p>Here's my question: how is this possible, given that I truncate to length 100 with:</p>

<pre><code>x['reviews'] = x['reviews'][:100]
</code></pre>

<p>It seems clear that this line isn't having any effect, so I'm trying to understand why. The docs are very clear that this is acceptable syntactic sugar for <code>tf.slice</code>: </p>

<pre><code>Note that tf.Tensor.getitem is typically a more pythonic way to 

perform slices, as it allows you to write foo[3:7, :-2] instead of 

tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2]).
</code></pre>

<p>Any ideas?</p>

<p>Thanks!</p>
",1,Documentation Ambiguity
223,53079436,tensorflow Tf.cond giving unexpected output,"<p>I seem to be having a misunderstanding on how <code>tf.cond</code> works. In the tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/cond"" rel=""nofollow noreferrer"">documentation</a>, it gives the following example:</p>

<pre><code>z = tf.multiply(a, b)
result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))
</code></pre>

<p>The result of the example, if <code>x&lt;y</code> is <code>True</code> is <code>tf.add(x,z)</code> else <code>tf.square(y)</code></p>

<p>Following this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation.</p>

<p>in my example, <code>deterministic_action = 4</code>, <code>random_action = 11</code>, <code>chose_random=False</code>. The <code>stochastic_action</code> should be <code>4</code>, instead it is <code>1</code>.
Where did the value 1 come from?</p>

<pre><code>#!/usr/bin/env python3

import tensorflow as tf
import numpy as np

with tf.Graph().as_default():
    with tf.device('/cpu:0'):
        stochastic_ph = tf.placeholder(tf.bool, (), name=""stochastic"")
        eps = tf.get_variable(""eps"", (), initializer=tf.constant_initializer(0))
        with tf.variable_scope('test_cond') as sc:
            deterministic_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=0) # 4
            random_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=1) # 11
            chose_random = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32) &lt; eps # False because eps = 0
            stochastic_action = tf.cond(chose_random, lambda: random_action, lambda: deterministic_action) # S_action should be 4 but it is 1
            #output_action = tf.cond(stochastic_ph, lambda: stochastic_action, lambda: deterministic_action)


    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init, feed_dict={stochastic_ph: True})
    print (""s_ph = "", stochastic_ph)
    d_action = sess.run(deterministic_action)
    print (""det_action= "", d_action)
    r_action = sess.run(random_action)
    print (""rand_action= "", r_action)
    e = sess.run(eps)
    c_action = sess.run(chose_random)
    print (""chose_rand= "", c_action)
    s_action = sess.run(stochastic_action)
    print (""s_action= "", s_action)
    #output = sess.run(output_action)
</code></pre>

<p>here is the output:</p>

<pre><code>python random_vec.py
2018-10-31 09:46:15.028376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
</code></pre>
",1,Documentation Replication on Other Examples
224,53164055,training tensorflow data API with procedural on-the-fly data generation,"<p>My question is similar to <a href=""https://stackoverflow.com/questions/47318734/on-the-fly-generation-with-dataset-api-tensorflow"">this</a> one, in that I would like to generate batches of training data on the fly. I have a function <code>get_random_batch(batch_size, input_path, target_path, **other_kwargs)</code> which returns <code>inputs</code> and <code>targets</code>, but it is a pure vanilla python / numpy function, not tensorflow. So it returns numpy arrays, not tensors. (The function is quite a large complex one with some 3rd party libs. To port it to tensorflow is not very feasible. To preprocess everything is also not feasible as the data is huge, and I don't have the space to store it all preprocessed! In fact I don't even train a single epoch, I just take random selections for hundreds of thousands of iterations).</p>

<p>For a few years I've been using tensorflow's low level training API: generate a batch of input-target pairs, run forward pass with feed (into placeholders) and fetch, calculate loss, apply gradients, repeat etc.</p>

<p>Now I finally would like to try out the newer data API (so that I can use the Keras API for building the model and 'fitting' etc), but I can't figure out how to migrate. All of the documentation I've seen assumes that the data loading and preprocessing is part of the graph, and the output of the dataset are already tensors. </p>

<p>--</p>

<p><strong>Update</strong>: Ok this seems to work with <strong>tf.data.Dataset.from_generator</strong></p>

<pre><code>compile_kwargs = dict(
    optimizer = tf.train.AdamOptimizer(3e-4),
    loss = 'mse',
    metrics = ['accuracy', 'mse']
)

def prepare_data():
    x,t = get_random_training_pair() # this returns one training pair (each np.float32 ndarrays)
    yield (x, t)

dataset = tf.data.Dataset.from_generator(prepare_data, (tf.float32, tf.float32))
dataset = dataset.batch(128).repeat()
model = build_keras_model()
model.compile(**compile_kwargs)
model.summary()
model.fit(dataset, epochs=10, steps_per_epoch=100, shuffle=False)
</code></pre>
",1,Documentation Ambiguity
225,53167302,Does tf.keras.layers.Conv2D as first layer in model truly need input_shape?,"<p>According to <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"" rel=""nofollow noreferrer"">the official document</a> on <code>tf.keras.layers.Conv2D</code>,</p>

<blockquote>
  <p>When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=""channels_last"".</p>
</blockquote>

<p>but actually without input_shape it does work in both graph execution and eager execution environment.</p>

<p>In graph execution, </p>

<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense

class CNN(tf.keras.Model):

    def __init__(self):
        super(CNN, self).__init__()
        self.conv = Conv2D(1, 3, padding='same', data_format='channels_first')
        self.flatten = Flatten()
        self.dense = Dense(1)

    def call(self, inputs):
        x = self.conv(inputs)
        x = self.flatten(x)
        return self.dense(x)


cnn = CNN()
inputs = tf.random_uniform([2, 3, 16, 16])
outputs = cnn(inputs)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    outputs = sess.run(outputs)
    print(outputs)
</code></pre>

<p>works without any error and in eager execution,</p>

<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense
tf.enable_eager_execution()

class CNN(tf.keras.Model):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv = Conv2D(1, 3, padding='same', data_format='channels_first')
        self.flatten = Flatten()
        self.dense = Dense(1)

    def call(self, inputs):
        x = self.conv(inputs)
        x = self.flatten(x)
        return self.dense(x)


cnn = CNN()
inputs = tf.random_uniform([2, 3, 16, 16])
outputs = cnn(inputs)
print(outputs)
</code></pre>

<p>also does.</p>

<p>Q1: Does <code>tf.keras.layers.Conv2D</code> as the first layer in a model truly need to specifying <code>input_shape</code>?</p>

<p>Q2: If not, when is it needed and why is it mentioned so in the official document?</p>

<p>UPDATE1:
<a href=""https://www.tensorflow.org/tutorials/eager/custom_layers#layers_common_sets_of_useful_operations"" rel=""nofollow noreferrer"">Tutorial on tf.keras</a> says </p>

<blockquote>
  <p>The number of input dimensions is often unnecessary, as it can be inferred
  the first time the layer is used, but it can be provided if you want to 
  specify it manually, which is useful in some complex models.</p>
</blockquote>

<p>UPDATE2:
<code>git blame</code> of docstring in TensorFlow source revealed that this document is copied from Keras API (which is not TensorFlow keras API).</p>
",1,Documentation Replication on Other Examples
226,53206900,Sound way of managing multiple sessions and graphs,"<p>I'd like to manage multiple Keras models in multiple sessions. My application is constructed such that models can be live at the same time, in addition to creating, saving and loading them.</p>

<p><strong>What is the proper way of managing this situation?</strong></p>

<p>Currently one model is represented by an instance of a wrapper class. This is used in the training, saving, loading and prediction. One <code>tf.Graph</code> and <code>tf.Session</code> is created per instance, and they are used in every function requiring the actual model.</p>

<pre><code>class NN:
    def __init__(self):
        self.graph = tf.Graph()
        self.session = tf.Session(graph=self.graph)

    def predict(self, x):
        with self.graph.as_default():
            with self.session.as_default():
                return self.model.predict(x)
</code></pre>

<p>Similar functions using the <code>with</code> statements are created for compiling the network, fitting, saving (weights to .h5 and model to JSON) and loading. So whenever the model is needed, the graph and session are brought to context.</p>

<p>This resulted in a strange error (<a href=""https://stackoverflow.com/questions/53002518/poor-exit-code-when-managing-multiple-sessions"">Q</a> for further context), and I was left wondering, what is the standard way of dealing with this. I tried to release all possible resources before creating or loading a model, but it hasn't helped. This function is just a compilation of all possible routines scraped off the internet, and is purely guesswork.</p>

<pre><code>def _new_session(self):
    if self.session is not None:
        self.session.close()
    k.clear_session()
    gc.collect()
    self.graph = tf.Graph()
    self.session = tf.Session(graph=self.graph)
</code></pre>

<p>I've not found good documentation of a similar situation. So I'd very much appreciate any real insight into this.</p>

<hr>

<p>I might need to delete the old question, as it's quite all over the place. At the time of asking I had no idea what was going on. But it's there for now.</p>

<hr>

<p>Some specific questions have arisen.</p>

<ul>
<li>Loading and making predictions on a model works, compiling and fitting doesn't, although just compiling does. Do the two contexts differ in any way? Is the loaded model exactly the same?</li>
<li>At which points should a new context be created when manipulating the models? (e.g. at load, compilation, fitting, probably not with every prediction)</li>
<li>Which actions are necessary to take when releasing the resources of previous contexts? Either when a network is disposed of or when creating a new context.</li>
<li>Why exactly is the context switch needed for multiple models?</li>
<li>What are the roles of graph vs. session, given that different things are executed on the graph and session?</li>
</ul>

<h3>Updates</h3>

<ul>
<li>Compiling, fitting and saving one network works without any context trickery. Doing the same for another model in the same context works too (or at least does not produce an error).</li>
<li>In addition to above, <strong>loading the saved model and predicting works too</strong>, right after the training and for both models! Now I'm not sure whether the prediction is made correctly, but again, no error. This only begs the question I posed above even more: <em>why are the different contexts needed?</em></li>
</ul>

<hr>

<p>The underlying issue with the error has been finally (and somewhat embarassingly) <a href=""https://stackoverflow.com/questions/53002518/poor-exit-code-when-managing-multiple-sessions"">resolved</a> by updating all packages.</p>
",1,Lack of Alternative Solutions/Documentation
227,53233123,tf.data: Combining multiple from_generator() datasets to create batches padded across time windows,"<p>I am working on a timeseries problem where each timeseries is fairly long (10^3-10^4 timesteps, and each timeseries is of different length).</p>

<p>For each sequence, I can define a Python generator that yields values one timestep at a time. I am using the <code>tf.data.Dataset.from_generator()</code> constructor to wrap these generators into the tf.data API. The documentation suggests using <code>from_generator()</code> along with the <code>tf.contrib.data.parallel_interleave()</code> transformation to parallelize the extraction from my Python generators.</p>

<p>My downstream use for these data is a stateful RNN (e.g. LSTM or GRU). I want to chunk up the timeseries into smaller (~10^2) windows and use each chunk as a training example (i.e., truncated BPTT). Since my data are streaming, I think that means saving up <code>window_size</code> timesteps of each generator before passing it on through the pipeline, to be batched with the other generators' data. I also want to save the RNN state across these chunks so I can still learn long-term dependencies.</p>

<p>My issue comes with wanting to create padded batches of these generators' batched outputs. Ideally, I would want to present to my neural network windows of the generator outputs, with padding as necessary when some subset of the generators exhaust themselves before others. I know that if I consume the entire generator output for each generator, then use <code>Dataset.padded_batch()</code> I can do this (and can then slice the padded batch across the time dimension into windowed chunks as necessary). However, I want to pass each window to the neural network it becomes available. If one of the generators exhausts itself before the others, I want to pad it with the padding value until all others have, so I can reset the RNN state and begin the next batch of generators with an empty initial RNN state. I am stuck here because the dataset resulting from <code>tf.contrib.data.parallel_interleave()</code> transformation discards each generator when it becomes exhausted, and the timeseries do not maintain a consistent ordering across samples from it.</p>

<p>Here is a small example:</p>

<pre><code>import tensorflow as tf

def stepwise_generator(length):
    for i in range(length):
        yield i

lengths = list(range(1,10,2)) # [1, 3, 5, 7, 9]

window_length = 4
batch_size = 3

dataset = tf.data.Dataset.from_tensor_slices(lengths)

gen = lambda length: tf.data.Dataset.from_generator(
    stepwise_generator, tf.float32, output_shapes=[], args=(length,)
).batch(window_length) # this batching saves window_length timesteps per generator

dataset = dataset.apply(
    tf.contrib.data.parallel_interleave(gen, cycle_length=batch_size)
)

dataset = dataset.padded_batch(batch_size, (-1,), np.inf)
# batching 3 generators at once, and padding exhausted ones with inf.
# using a batch_size value no more than cycle_length above means we
# shouldn't start a new generator mid-batch (i think)

iterator = dataset.make_one_shot_iterator()
tensor = iterator.get_next()

outs = []
with tf.Session() as sess:
    while True:
        try:
            out = sess.run(tensor)
            outs.append(out)
        except tf.errors.OutOfRangeError:
            break

print(np.asarray(outs))
</code></pre>

<p>Output:</p>

<pre><code>[[[ 0. inf inf inf]   # batch 1
  [ 0.  1.  2. inf]
  [ 0.  1.  2.  3.]]

 [[ 4. inf inf inf]   # batch 2 - the generator in index -1 in the
  [ 0.  1.  2.  3.]   # previous batch gets cycled to index 0 and two
  [ 0.  1.  2.  3.]]  # new generators are initiated

 [[ 4.  5.  6. inf]   # batch 3 - more generator cycling, and the one in
  [ 4.  5.  6.  7.]   # index 1 also gets cycled to index 2 in the same
  [ 8. inf inf inf]]] # batch (because we have run out of generators in
                      # parallel_interleave)
</code></pre>

<p>My desired output would be something like</p>

<pre><code>[[[ 0. inf inf inf]   # batch 1
  [ 0.  1.  2. inf]
  [ 0.  1.  2.  3.]]

 [[inf]               # batch 2 - the leftover timestep from a padded 
  [inf]               # batch of the first 3 generators
  [4. ]]

 [[ 0.  1.  2.  3.]   # batch 3 - only two generators are left so this is 
  [ 0.  1.  2.  3.]]  # an end-of-epoch smaller batch

 [[ 4.  5.  6. inf]   # batch 4
  [ 4.  5.  6.  7.]]

 [[inf]               # batch 5
  [ 8.]]]
</code></pre>

<p>Here, the internal states of the RNNs would be reset after batch 2 and 5.</p>

<p>Again, the desired output can be simple to create if I consume the entirety of each generator's output, then pad, batch, and slice, but I want to produce batches as the generators, which may be each receiving data in real-time from e.g. a separate simulation, make them available.</p>
",1,Documentation Replication on Other Examples
228,53272508,inception v3 using tf.data?,"<p>I'm using a bit of code that is derived from inception v3 as distributed by the Google folks, but it's now complaining that the queue runners used to read the data are deprecated (tf.train.string_input_producer in image_processing.py, and similar).  Apparently I'm supposed to switch to tf.data for this kind of stuff.</p>

<p>Unfortunately, the documentation on tf.data isn't doing much to relieve my concern that I've got too much data to fit in memory, especially given that I want to batch it in a reusable way, etc. I'm confident that the tf.data stuff <em>can</em> do this; I just don't know <em>how</em> to do it. Can anyone point me to a full example of code that uses tf.data to deal with batches of data that won't all fit in memory?  Ideally, it would simply be an updated version of the inception-v3 code, but I'd be happy to try and work with anything.  Thanks!</p>
",1,Lack of Alternative Solutions/Documentation
229,53307954,TensorFlow Custom Estimator predict throwing value error,"<p>Note: this question has an accompanying, documented <a href=""https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub"" rel=""nofollow noreferrer"">Colab</a> notebook.</p>
<p>TensorFlow's documentation can, at times, leave a lot to be desired. Some of the older docs for lower level apis seem to have been expunged, and most newer documents point towards using higher level apis such as TensorFlow's subset of <code>keras</code> or <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator"" rel=""nofollow noreferrer""><code>estimators</code></a>. This would not be so problematic if the higher level apis did not so often rely closely on their lower levels. Case in point, <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator"" rel=""nofollow noreferrer""><code>estimators</code></a> (especially the <code>input_fn</code> when using TensorFlow Records).</p>
<p>Over the following Stack Overflow posts:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel"">Tensorflow v1.10: store images as byte strings or per channel?</a></li>
<li><a href=""https://stackoverflow.com/questions/52064866/tensorflow-1-10-tfrecorddataset-recovering-tfrecords"">Tensorflow 1.10 TFRecordDataset - recovering TFRecords</a></li>
<li><a href=""https://stackoverflow.com/questions/52874647/tensorflow-v1-10-why-is-an-input-serving-receiver-function-needed-when-checkpoi"">Tensorflow v1.10+ why is an input serving receiver function needed when checkpoints are made without it?</a></li>
<li><a href=""https://stackoverflow.com/questions/52641737/tensorflow-1-10-custom-estimator-early-stopping-with-train-and-evaluate"">TensorFlow 1.10+ custom estimator early stopping with train_and_evaluate</a></li>
<li><a href=""https://stackoverflow.com/questions/53226898/tensorflow-custom-estimator-stuck-when-calling-evaluate-after-training"">TensorFlow custom estimator stuck when calling evaluate after training</a></li>
</ul>
<p>and with the gracious assistance of the TensorFlow / StackOverflow community, we have moved closer to doing what the TensorFlow <a href=""https://www.tensorflow.org/guide/custom_estimators"" rel=""nofollow noreferrer"">&quot;Creating Custom Estimators&quot; guide</a> has not, demonstrating how to make an estimator one might actually use in practice (rather than toy example) e.g. one which:</p>
<ul>
<li>has a validation set for early stopping if performance worsen,</li>
<li>reads from TF Records because many datasets are larger than the TensorFlow recommend 1Gb for in memory, and</li>
<li>that saves its best version whilst training</li>
</ul>
<p>While I still have many questions regarding this (from the best way to encode data into a TF Record, to what exactly the <code>serving_input_fn</code> expects), there is one question that stands out more prominently than the rest:</p>
<p>How to predict with the custom estimator we just made?</p>
<p>Under the documentation for <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict"" rel=""nofollow noreferrer"">predict</a>, it states:</p>
<blockquote>
<p><code>input_fn</code>: A function that constructs the features. Prediction continues until <code>input_fn</code> raises an end-of-input exception (<code>tf.errors.OutOfRangeError</code> or <code>StopIteration</code>). See Premade Estimators for more information. The function should construct and return one of the following:</p>
<ul>
<li>A tf.data.Dataset object: Outputs of Dataset object must have same constraints as below.</li>
<li>features: A tf.Tensor or a dictionary of string feature name to Tensor. features are consumed by model_fn. They should satisfy the expectation of model_fn from inputs.</li>
<li>A tuple, in which case the first item is extracted as features.</li>
</ul>
</blockquote>
<p>(perhaps) Most likely, if one is using <code>estimator.predict</code>, they are using data in memory such as a dense tensor (because a held out test set would likely go through <code>evaluate</code>).</p>
<p>So I, in the accompanying <a href=""https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub"" rel=""nofollow noreferrer"">Colab</a>, create a single dense example, wrap it up in a <code>tf.data.Dataset</code>, and call <code>predict</code> to get a <code>ValueError</code>.</p>
<p>I would greatly appreciate it if someone could explain to me how I can:</p>
<ol>
<li>load my saved estimator</li>
<li>given a dense, in memory example, predict the output with the estimator</li>
</ol>
",1,Requesting (Additional) Documentation/Examples
230,53466500,Can't save and load a trained CNN model for binary image classification,"<p>I have built a Binary Image classifier using Convolutional Neural Networks using TensorFlow.It is running fine, however, each time it takes too long to train from scratch. So, I want to save the trained model and load it next time. I can't seem to understand how to implement <a href=""https://www.tensorflow.org/guide/saved_model"" rel=""nofollow noreferrer"">these</a> guides in my program as shown in the TensorFlow documentation. 
Here's the full code: </p>

<pre><code># Python program to create
# Image Classifier using CNN

# Importing the required libraries
import cv2
import os
import numpy as np
from random import shuffle
from tqdm import tqdm
from keras.models import Sequential
'''Setting up the env'''

TRAIN_DIR = 'D:\\Project\\Final_Project\\chest_xray\\train\\'
TEST_DIR = 'D:\\Project\\Final_Project\\chest_xray\\test0\\'
check_point = 'D:\\Project\\Final_Project\\chest_xray\\chkpt\\'
IMG_SIZE = 80
LR = 1e-4

'''Setting up the model which will help with tensorflow models'''
MODEL_NAME = 'NormalVsAbnormalXRays-{}-{}.model'.format(LR, '6conv-basic')

'''Labelling the dataset'''


def label_img(img):
    word_label = img.split('.')[-3]
    # DIY One hot encoder
    if word_label == 'Nor':
        return [1, 0]
    elif word_label == 'Pne':
        return [0, 1]
    else :
        return[0, 0]

'''Creating the training data'''


def create_train_data():
    # Creating an empty list where we should the store the training data
    # after a little preprocessing of the data
    training_data = []

    # tqdm is only used for interactive loading
    # loading the training data
    for img in tqdm(os.listdir(TRAIN_DIR)):
        # labeling the images
        label = label_img(img)

        path = os.path.join(TRAIN_DIR, img)

        # loading the image from the path and then converting them into
        # greyscale for easier covnet prob
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)

        # resizing the image for processing them in the covnet
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))

        # final step-forming the training data list with numpy array of the images
        training_data.append([np.array(img), np.array(label)])

        # shuffling of the training data to preserve the random state of our data
    shuffle(training_data)

    # saving our trained data for further uses if required
    np.save('train_data.npy', training_data)
    return training_data


'''Processing the given test data'''


# Almost same as processing the traning data but
# we dont have to label it.
def process_test_data():
    testing_data = []
    for img in tqdm(os.listdir(TEST_DIR)):
        path = os.path.join(TEST_DIR, img)
        img_num = img.split('.')[0]
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
        testing_data.append([np.array(img), img_num])

    shuffle(testing_data)
    np.save('test_data.npy', testing_data)
    return testing_data


'''Running the training and the testing in the dataset for our model'''
#train_data = create_train_data()
#test_data = process_test_data()

train_data = np.load('train_data.npy')
test_data = np.load('test_data.npy')
'''Creating the neural network using tensorflow'''
# Importing the required libraries
import tflearn
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.estimator import regression

import tensorflow as tf
model = Sequential()
tf.reset_default_graph()


saver = tf.train.import_meta_graph('D:\\Project\\Final_Project\\chest_xray\\check_point-78.meta')
convnet = input_data(shape=[None,IMG_SIZE, IMG_SIZE, 1], name='input')

convnet = conv_2d(convnet, 32, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)


convnet = conv_2d(convnet, 64, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)


convnet = conv_2d(convnet, 128, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)

convnet = conv_2d(convnet, 64, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)

convnet = conv_2d(convnet, 32, 4, activation='relu')
convnet = max_pool_2d(convnet, 2)

convnet = fully_connected(convnet, 1024, activation='relu')
convnet = dropout(convnet, 0.3)

convnet = fully_connected(convnet, 2, activation='softmax')
convnet = regression(convnet, optimizer='adam', learning_rate=LR,
                     loss='categorical_crossentropy', name='targets')

model = tflearn.DNN(convnet, tensorboard_dir='log', checkpoint_path='check_point',best_checkpoint_path= 'check_point',max_checkpoints= 5)

# Splitting the testing data and training data
train = train_data
test = train_data

'''Setting up the features and lables'''
# X-Features &amp; Y-Labels

X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
Y = [i[1] for i in train]
test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
test_y = [i[1] for i in test]

'''Fitting the data into our model'''
# epoch = 40 taken
model.fit({'input': X}, {'targets': Y}, n_epoch=1,
          validation_set=0.05,
          snapshot_step=500, show_metric=True, run_id=MODEL_NAME)
model.save(MODEL_NAME)

'''Testing the data'''
import matplotlib.pyplot as plt

# if you need to create the data:
# test_data = process_test_data()
# if you already have some saved:
test_data = np.load('test_data.npy')

fig = plt.figure(figsize=(80,80))

for num, data in enumerate(test_data[:1]):


    img_num = data[1]
    img_data = data[0]

    y = fig.add_subplot(1, 1, num + 1)
    orig = img_data
    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)

    # model_out = model.predict([data])[0]
    model_out = model.predict([data])[0]

    if np.argmax(model_out) == 1:
        str_label = 'Abnormal'
    else:
        str_label = 'Normal'

    y.imshow(orig, cmap='gray')
    plt.title(str_label,fontsize=20)
    y.axes.get_xaxis().set_visible(False)
    y.axes.get_yaxis().set_visible(False)
 plt.show()
</code></pre>

<p>I have tried to use saver = <code>tf.train.import_meta_graph('D:\\Project\\Final_Project\\chest_xray\\check_point-78.meta')</code> to import the graph but I get this error</p>

<pre><code>Traceback (most recent call last):
  File ""D:/Project/Final_Project/chest_xray/Final_CNN.py"", line 104, in &lt;module&gt;
    saver = tf.train.import_meta_graph('D:\\Project\\Final_Project\\chest_xray\\check_point-78.meta')
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1674, in import_meta_graph
    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1696, in _import_meta_graph_with_return_elements
    **kwargs))
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\meta_graph.py"", line 852, in import_scoped_meta_graph_with_return_elements
    ops.prepend_name_scope(value, scope_to_prepend_to_names))
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3490, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""C:\Users\waqar\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3550, in _as_graph_element_locked
    ""graph."" % repr(name))
KeyError: ""The name 'Adam' refers to an Operation not in the graph.""
</code></pre>

<p>Process finished with exit code 1</p>
",1,Documentation Replicability
231,53568337,Print accuracy when training tf.estimator.DNNClassifier,"<p>I am new to tensorflow, using <a href=""https://www.tensorflow.org/guide/custom_estimators"" rel=""nofollow noreferrer"">official tutorial</a> tf.estimator.DNNClassifier and custom estimator to build simple NN to solve classification problem.</p>

<p>While training :</p>

<pre><code>dnn_model = tf.estimator.DNNClassifier(hidden_units=[10,10,10],
                                       feature_columns = my_features_column,
                                       n_classes=5,
                                       optimizer = tf.train.AdamOptimizer()
                                      )

dnn_model.train(input_fn=train_input_func)
</code></pre>

<p>It will report loss at specific time as following:</p>

<pre><code>INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmphwkvj5le/model.ckpt-150
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 150 into /tmp/tmphwkvj5le/model.ckpt.
INFO:tensorflow:loss = 133.04277, step = 150
INFO:tensorflow:global_step/sec: 115.114
INFO:tensorflow:loss = 128.15938, step = 250 (0.872 sec)
INFO:tensorflow:global_step/sec: 134.317
INFO:tensorflow:loss = 123.093094, step = 350 (0.743 sec)
INFO:tensorflow:global_step/sec: 133.573
INFO:tensorflow:loss = 117.80729, step = 450 (0.748 sec)
INFO:tensorflow:global_step/sec: 135.081
INFO:tensorflow:loss = 114.07168, step = 550 (0.741 sec)
INFO:tensorflow:Saving checkpoints for 650 into /tmp/tmphwkvj5le/model.ckpt.
INFO:tensorflow:Loss for final step: 118.19583.
</code></pre>

<p>I want to print classification accuracy every batch or epoch, likes the log Info in keras:</p>

<pre><code>Epoch 1/20
5000/5000 [==============================] - 1s 157us/step - loss: 1.4885 - acc: 0.3276 - val_loss: 1.4397 - val_acc: 0.3620
Epoch 2/20
5000/5000 [==============================] - 0s 66us/step - loss: 1.3792 - acc: 0.3922 - val_loss: 1.4001 - val_acc: 0.3768
.
.
</code></pre>

<p>How can I find the tutorial on this problem ? All I find were talking about more lower API (tensor, session, etc.).</p>
",1,Documentation Replicability
232,53569622,Difference between tf.train.Checkpoint and tf.train.Saver,"<p>I found there are different ways to save/restore models and variables in <code>Tensorflow</code>. These ways including:</p>

<ul>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save"" rel=""nofollow noreferrer"">tf.saved_model.simple_save</a></li>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"" rel=""nofollow noreferrer"">tf.train.Checkpoint</a></li>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/train/Saver"" rel=""nofollow noreferrer"">tf.train.Saver</a></li>
</ul>

<p>In tensorflow's documentations, I found some differences between them:</p>

<ol>
<li><code>tf.saved_model</code> is a thin wrapper around <code>tf.train.Saver</code></li>
<li><code>tf.train.Checkpoint</code> support eager execution but <code>tf.train.Saver</code> <strong>not</strong>.</li>
<li><code>tf.train.Checkpoint</code> not creating <code>.meta</code> file but still can load graph structure (here is a big question! how it can do that?)</li>
</ol>

<p>How <code>tf.train.Checkpoint</code> can load graph without <code>.meta</code> file? or more generally What is the difference between <code>tf.train.Saver</code> and <code>tf.train.Checkpoint</code>?</p>
",1,Documentation Ambiguity
233,53572533,What is the second argument of TensorFlow's tf.data.filter() that I find no documentation of?,"<p>I recently had a <code>TypeError</code> when using</p>

<pre><code>def lie_filter(line):
    return tf.equal(line['lie_id'], 2)
</code></pre>

<p>in</p>

<pre><code>dataset = (
    tf.data
    .TextLineDataset('shots.csv')
    .skip(1)
    .map(decode_line)
    .filter(lie_filter)
    .cache())
</code></pre>

<p>The exact error was <code>TypeError: lie_filter() takes 1 positional argument but 2 were given</code>.</p>

<p>Simply changing the function signature to <code>lie_filter(line, x)</code> made the error go away and the filtering appears to work as intended. However, it left me wondering what is this mysterious second argument.</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#filter"" rel=""nofollow noreferrer"">TensorFlow manual for tf.data.filter()</a> only specifies one argument. There are also numerous examples by TensorFlow where filtering is done as per my attempt above. Take a look at, e.g., <a href=""https://github.com/tensorflow/tensorflow/blob/6d14dcba7225d205f2e7834551f42385802aa2cf/tensorflow/examples/get_started/regression/imports85.py#L116"" rel=""nofollow noreferrer"">imports85.py</a>.</p>

<p>Printing the <code>x</code> inside <code>lie_filter</code> yields <code>Tensor(""arg12:0"", shape=(), dtype=float32)</code>.</p>

<p>What is the second argument and where can I find documentation about it?</p>

<p>Thank you!</p>
",1,Documentation Completeness
234,53578484,tf.gather with indices of higher dimention than input data?,"<p>Reading <a href=""https://github.com/WangYueFt/dgcnn"" rel=""nofollow noreferrer"">Dynamic Graph CNN for Learning on Point Clouds</a> code, I came across this snippet:</p>

<pre><code>  idx_ = tf.range(batch_size) * num_points
  idx_ = tf.reshape(idx_, [batch_size, 1, 1]) 

  point_cloud_flat = tf.reshape(point_cloud, [-1, num_dims])
  point_cloud_neighbors = tf.gather(point_cloud_flat, nn_idx+idx_)  &lt;--- what happens here?
  point_cloud_central = tf.expand_dims(point_cloud_central, axis=-2)
</code></pre>

<p>debugging the line I made sure that the dims are</p>

<pre><code>point_cloud_flat:(32768,3) nn_idx:(32,1024,20), idx_:(32,1,1) 
// indices are (32,1024,20) after broadcasting
</code></pre>

<p>Reading the <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer"">tf.gather doc</a> I couldn't understand what the function does with dimensions higher that the input dimensions</p>
",1,Documentation Replicability
235,53583456,What problem does a reinitializable iterator solve?,"<p>From the <a href=""https://www.tensorflow.org/guide/datasets#creating_an_iterator"" rel=""nofollow noreferrer"">tf.data documentation</a>:</p>

<blockquote>
  <p>A reinitializable iterator can be initialized from multiple different
  Dataset objects. For example, you might have a training input pipeline
  that uses random perturbations to the input images to improve
  generalization, and a validation input pipeline that evaluates
  predictions on unmodified data. These pipelines will typically use
  different Dataset objects that have the same structure (i.e. the same
  types and compatible shapes for each component).</p>
</blockquote>

<p>the following example was given:</p>

<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                           training_dataset.output_shapes)
next_element = iterator.get_next()

training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

# Run 20 epochs in which the training dataset is traversed, followed by the
# validation dataset.
for _ in range(20):
  # Initialize an iterator over the training dataset.
  sess.run(training_init_op)
  for _ in range(100):
    sess.run(next_element)

  # Initialize an iterator over the validation dataset.
  sess.run(validation_init_op)
  for _ in range(50):
    sess.run(next_element)
</code></pre>

<p>It is unclear what the benefit of this complexity is.<br>
Why not simply create 2 different iterators?</p>
",1,Documentation Ambiguity
236,53612973,TensorFlow Sigmoid Cross Entropy with Logits for 1D data,"<h1>Context</h1>

<p>Suppose we have some 1D data (e.g. time series), where all series have fixed length <em>l</em>:</p>

<pre><code>        # [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11] index
example = [ 0,  1,  1,  0, 23, 22, 20, 14,  9,  2,  0,  0] # l = 12
</code></pre>

<p>and we want to perform semantic segmentation, with <em>n</em> classes:</p>

<pre><code>          # [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]    index            
labeled = [
            [ 0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0], # class 1
            [ 0,  0,  0,  0,  1,  1,  1,  1,  0,  0,  0,  0], # class 2
            [ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  0], # class 3
           #[                     ...                      ],
            [ 1,  1,  1,  0,  0,  0,  0,  0,  1,  1,  1,  1], # class n
 ]
</code></pre>

<p>then the output for a single example has shape <code>[n, l]</code> (i.e. the <code>data_format</code> is not <code>""channels_last""</code>) and the batched output has shape <code>[b, n, l]</code>, where <code>b</code> is the number of examples in the batch.</p>

<p>These classes are independent, so it is my understanding that the use <em>sigmoid</em> cross entropy is applicable here as the loss rather than softmax cross entropy.</p>

<hr>

<h1>Question</h1>

<p>I have a few small related questions in regards to the expected format for and use of <code>tf.nn.sigmoid_cross_entropy_with_logits</code>:</p>

<ol>
<li><p>since the network outputs a tensor in the same shape as the batched labels, should I train the network under the assumption that it outputs logits, or take the keras approach (see keras's <code>binary_crossentropy</code>) and assume it outputs probabilities?</p></li>
<li><p>given the 1d segmentation problem, should I call <code>tf.nn.sigmoid_cross_entropy_with_logits</code> on:</p>

<ul>
<li><code>data_format='channels_first'</code> (as shown above), or</li>
<li><code>data_format='channels_last'</code>  (example.T)</li>
</ul>

<p>if I want the labels to be assigned individually per channel?</p></li>
<li><p>should the loss operation passed to the optimizer be:</p>

<ul>
<li><code>tf.nn.sigmoid_cross_entropy_with_logits(labels, logits)</code>, </li>
<li><code>tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels, logits))</code>, or</li>
<li><code>tf.losses.sigmoid_cross_entropy</code>?</li>
</ul></li>
</ol>

<hr>

<h1>Code</h1>

<p>This <a href=""https://colab.research.google.com/drive/12EiVRy8Tdt4UyvSuuBr3wcXfCmXPVFku"" rel=""nofollow noreferrer"">Colab</a>, highlights my confusion and demonstrates that the <code>data_format</code> does in fact matter..., but the documentation does not explicitly state which is expected.</p>

<h2>Dummy data</h2>

<pre><code>c = 5  # number of channels (label classes)
p = 10 # number of positions ('pixels')


# data_format = 'channels_first', shape = [classes, pixels]
# 'logits' for 2 examples
pred_1 = np.array([[random.random() for v in range(p)]for n in range(c)]).astype(float)
pred_2 = np.array([[random.random() for v in range(p)]for n in range(c)]).astype(float)

# 'ground truth' for the above 2 examples
targ_1 = np.array([[0 if random.random() &lt; 0.8 else 1 for v in range(p)]for n in range(c)]).astype(float)
targ_2 = np.array([[0 if random.random() &lt; 0.8 else 1 for v in range(p)]for n in range(c)]).astype(float)

# batched form of the above examples
preds = np.array([pred_1, pred_2])
targs = np.array([targ_1, targ_2])


# data_format = 'channels_last', shape = [pixels, classes]
t_pred_1 = pred_1.T
t_pred_2 = pred_2.T
t_targ_1 = targ_1.T
t_targ_2 = targ_2.T

t_preds = np.array([t_pred_1, t_pred_2])
t_targs = np.array([t_targ_1, t_targ_2])
</code></pre>

<h2>losses</h2>

<h3>tf.nn</h3>

<pre><code># calculate individual losses for 'channels_first'
loss_1 = tf.nn.sigmoid_cross_entropy_with_logits(labels=targ_1, logits=pred_1)
loss_2 = tf.nn.sigmoid_cross_entropy_with_logits(labels=targ_2, logits=pred_2)
# calculate batch loss for 'channels_first'
b_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targs, logits=preds)

# calculate individual losses for 'channels_last'
t_loss_1 = tf.nn.sigmoid_cross_entropy_with_logits(labels=t_targ_1, logits=t_pred_1)
t_loss_2 = tf.nn.sigmoid_cross_entropy_with_logits(labels=t_targ_2, logits=t_pred_2)
# calculate batch loss for 'channels_last'
t_b_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=t_targs, logits=t_preds)
# get actual tensors
with tf.Session() as sess:
  # loss for 'channels_first'
  l1   = sess.run(loss_1)
  l2   = sess.run(loss_2)
  # batch loss for 'channels_first'
  bl   = sess.run(b_loss)

  # loss for 'channels_last'
  t_l1 = sess.run(t_loss_1)
  t_l2 = sess.run(t_loss_2)

  # batch loss for 'channels_last'
  t_bl = sess.run(t_b_loss)
</code></pre>

<h3>tf.reduced_mean(tf.nn)</h3>

<pre><code># calculate individual losses for 'channels_first'
rm_loss_1 = tf.reduce_mean(loss_1)
rm_loss_2 = tf.reduce_mean(loss_2)
# calculate batch loss for 'channels_first'
rm_b_loss = tf.reduce_mean(b_loss)

# calculate individual losses for 'channels_last'
rm_t_loss_1 = tf.reduce_mean(t_loss_1)
rm_t_loss_2 = tf.reduce_mean(t_loss_2)
# calculate batch loss for 'channels_last'
rm_t_b_loss = tf.reduce_mean(t_b_loss)
# get actual tensors
with tf.Session() as sess:
  # loss for 'channels_first'
  rm_l1   = sess.run(rm_loss_1)
  rm_l2   = sess.run(rm_loss_2)
  # batch loss for 'channels_first'
  rm_bl   = sess.run(rm_b_loss)

  # loss for 'channels_last'
  rm_t_l1 = sess.run(rm_t_loss_1)
  rm_t_l2 = sess.run(rm_t_loss_2)

  # batch loss for 'channels_last'
  rm_t_bl = sess.run(rm_t_b_loss)
</code></pre>

<h3>tf.losses</h3>

<pre><code># calculate individual losses for 'channels_first'
tf_loss_1 = tf.losses.sigmoid_cross_entropy(multi_class_labels=targ_1, logits=pred_1)
tf_loss_2 = tf.losses.sigmoid_cross_entropy(multi_class_labels=targ_2, logits=pred_2)
# calculate batch loss for 'channels_first'
tf_b_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=targs, logits=preds)

# calculate individual losses for 'channels_last'
tf_t_loss_1 = tf.losses.sigmoid_cross_entropy(multi_class_labels=t_targ_1, logits=t_pred_1)
tf_t_loss_2 = tf.losses.sigmoid_cross_entropy(multi_class_labels=t_targ_2, logits=t_pred_2)
# calculate batch loss for 'channels_last'
tf_t_b_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=t_targs, logits=t_preds)
# get actual tensors
with tf.Session() as sess:
  # loss for 'channels_first'
  tf_l1   = sess.run(tf_loss_1)
  tf_l2   = sess.run(tf_loss_2)
  # batch loss for 'channels_first'
  tf_bl   = sess.run(tf_b_loss)

  # loss for 'channels_last'
  tf_t_l1 = sess.run(tf_t_loss_1)
  tf_t_l2 = sess.run(tf_t_loss_2)

  # batch loss for 'channels_last'
  tf_t_bl = sess.run(tf_t_b_loss)
</code></pre>

<h2>Test equivalency</h2>

<h3>data_format equivalency</h3>

<pre><code># loss _should_(?) be the same for 'channels_first' and 'channels_last' data_format
# test example_1
e1 = (l1 == t_l1.T).all()
# test example 2
e2 = (l2 == t_l2.T).all()

# loss calculated for each example and then batched together should be the same 
# as the loss calculated on the batched examples
ea = (np.array([l1, l2]) == bl).all()
t_ea = (np.array([t_l1, t_l2]) == t_bl).all()

# loss calculated on the batched examples for 'channels_first' should be the same
# as loss calculated on the batched examples for 'channels_last'
eb = (bl == np.transpose(t_bl, (0, 2, 1))).all()


e1, e2, ea, t_ea, eb
# (True, False, False, False, True) &lt;- changes every time, so True is happenstance
</code></pre>

<h3>equivalency between tf.reduce_mean and tf.losses</h3>

<pre><code>l_e1 = tf_l1 == rm_l1
l_e2 = tf_l2 == rm_l2
l_eb = tf_bl == rm_bl

l_t_e1 = tf_t_l1 == rm_t_l1
l_t_e2 = tf_t_l2 == rm_t_l2
l_t_eb = tf_t_bl == rm_t_bl

l_e1, l_e2, l_eb, l_t_e1, l_t_e2, l_t_eb
# (False, False, False, False, False, False)
</code></pre>
",1,Lack of Alternative Solutions/Documentation
237,53649402,Disable TensorBoard logging on tf.Estimator methods,"<p>Is there a way disable the automatic TensorBoard logging when using the <code>tf.estimator.Estimator</code> class?</p>

<pre><code># Classifier
classifier = tf.estimator.Estimator(
    model_fn=lambda features, labels, mode, params: model(features, labels, mode, params, word_embeddings),
    params=params,
    model_dir=str(MODEL_DIR),
    tensorboard=Fasle)  # &lt;---- Something like that?

for _ in range(params['epochs']):
    classifier.train(input_fn=lambda: input_fn(generator, example_generator._data['train'] ,batch_size=params['batch_size']))
    classifier.evaluate(input_fn=lambda: input_fn(generator, example_generator._data['validation'], batch_size=params['batch_size']))
</code></pre>

<p>I read through the <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig"" rel=""nofollow noreferrer""><code>tf.estimator.RunConfig</code></a> and couldn't find a solution.</p>
",1,Lack of Alternative Solutions/Documentation
238,53677345,Passing >2GB data to tf.estimator,"<p>I have <code>x_train</code> and <code>y_train</code> numpy arrays, each of >2GB. I want to train model using the tf.estimator API, but I am getting the errors:</p>

<pre><code>ValueError: Cannot create a tensor proto whose content is larger than 2GB
</code></pre>

<p>I am passing the data using:</p>

<pre><code>def input_fn(features, labels=None, batch_size=None,
             shuffle=False, repeats=False):
    if labels is not None:
        inputs = (features, labels)
    else:
        inputs = features
    dataset = tf.data.Dataset.from_tensor_slices(inputs)
    if shuffle:
        dataset = dataset.shuffle(shuffle)
    if batch_size:
        dataset = dataset.batch(batch_size)
    if repeats:
        # if False, evaluate after each epoch
        dataset = dataset.repeat(repeats)
    return dataset

train_spec = tf.estimator.TrainSpec(
    lambda : input_fn(x_train, y_train,
                      batch_size=BATCH_SIZE, shuffle=50),
    max_steps=EPOCHS
)

eval_spec = tf.estimator.EvalSpec(lambda : input_fn(x_dev, y_dev))

tf.estimator.train_and_evaluate(model, train_spec, eval_spec)
</code></pre>

<p>The tf.data documentation <a href=""https://www.tensorflow.org/guide/datasets"" rel=""nofollow noreferrer"">mentions this error</a> and provides solution using traditional TenforFlow API with placeholders. Unfortunately, I don't know how this could be translated into tf.estimator API?</p>
",1,Documentation Replication on Other Examples
239,53772787,tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) in tensorflow,"<p>What is purpose of <code>tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS))</code> in tensorflow?</p>

<p>With more context:</p>

<pre><code>    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)
    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):
        train_op = optimizer.minimize(loss_fn, var_list=tf.trainable_variables())
</code></pre>
",1,Requesting (Additional) Documentation/Examples
240,53915078,"What are b, y, x and c which get flattened and returned along with the max-pooled features in tf.nn.max_pool_with_argmax?","<p>I went through the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/max_pool_with_argmax"" rel=""nofollow noreferrer"">tf.nn.max_pool_with_argmax</a> where it is written</p>

<blockquote>
  <p>Performs max pooling on the input and outputs both max values and indices.</p>
  
  <p>The indices in argmax are flattened, so that a maximum value at
  position [b, y, x, c] becomes flattened index ((b * height + y) *
  width + x) * channels + c.</p>
  
  <p>The indices returned are always in [0, height) x [0, width) before
  flattening, even if padding is involved and the mathematically correct
  answer is outside (either negative or too large). This is a bug, but
  fixing it is difficult to do in a safe backwards compatible way,
  especially due to flattening.</p>
</blockquote>

<p>The variables b, y, x and c haven't been explicitly defined hence I was having issues implementing this method. Can someone please provide the same.</p>
",1,Documentation Replicability
241,53919290,tensorflow sparse categorical cross entropy with logits,"<p>I am a novice programmer trying to follow <a href=""https://www.tensorflow.org/tutorials/sequences/text_generation"" rel=""nofollow noreferrer"">this</a> guide.
However, I ran across an issue. The guide says to define the loss function as:</p>

<pre><code>def loss(labels, logits):
    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)
</code></pre>

<p>This gives me the following error:</p>

<blockquote>
  <p>sparse_categorical_crossentropy() got an unexpected keyword argument
  'from_logits'</p>
</blockquote>

<p>which I take to mean that <code>from_logits</code> is an argument not specified in the function, which is supported by the documentation, which that <code>tf.keras.losses.sparse_categorical_crossentropy()</code> has only two possible inputs. </p>

<p>Is there a way to specify that logits are being used or is that even necesarry?</p>
",1,Documentation Replication on Other Examples
242,53922040,How does tf.keras.layers.Conv2DTranspose behave with stride and padding?,"<p>While a convolution layer in TensorFlow has a complete description <a href=""https://www.tensorflow.org/api_guides/python/nn#Convolution"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_guides/python/nn#Convolution</a>, transposed convolution does not have one.</p>

<p>Although tf.keras.layers.Conv2DTranspose has a reference to <a href=""https://arxiv.org/pdf/1603.07285.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/1603.07285.pdf</a>, it is not complete.</p>

<p>Is there any documentation that describes how tf.keras.layers.Conv2DTranspose behaves?</p>
",1,Documentation Completeness
243,53924692,Why can tf.random.truncated_normal get a shape that is not a vector even though it says it only receives shape of a vector?,"<p>I am working with TensorFlow in Python. </p>

<p>I read through the documentation of 
<a href=""https://www.tensorflow.org/api_docs/python/tf/random/truncated_normal"" rel=""nofollow noreferrer"">tf.random.truncated_normal</a>
that the input 'shape' gets 1-D tensor or python array, i.e. a vector (according to <a href=""https://www.tensorflow.org/guide/tensors"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/tensors</a>). </p>

<p>However, with the example I'm using, 'shape' is a 4-D tensor. Or is it considered a vector? Perhaps I have problem with the definition of vectors and tensors? </p>

<pre><code>def weight_variable(shape, name = 'noname'):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial, name = name)

W_conv1 = weight_variable([5, 5, 3, 32], 'W_conv1')
</code></pre>
",1,Documentation Replicability
244,54047604,How to assign custom gradient to TensorFlow op with multiple inputs,"<p>I'm trying to use TensorFlow's <code>@tf.custom_gradient</code> functionality to assign a custom gradient to a function with multiple inputs.  I can put together a working setup for only one input, but not for two or more.</p>

<p>I've based my code on <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">TensorFlow's custom_gradient documentation</a>, which works just fine for one input, as in this example:</p>

<pre><code>import tensorflow as tf
import os

# Suppress Tensorflow startup info
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

# Custom gradient decorator on a function,
# as described in documentation
@tf.custom_gradient
def my_identity(x):

    # The custom gradient
    def grad(dy):
        return dy

    # Return the result AND the gradient
    return tf.identity(x), grad

# Make a variable, run it through the custom op
x = tf.get_variable('x', initializer=1.)
y = my_identity(x)

# Calculate loss, make an optimizer, train the variable
loss = tf.abs(y)
opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)
train = opt.minimize(loss)

# Start a TensorFlow session, initialize variables, train
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(train)
</code></pre>

<p>This example runs silently, then closes.  No issues, no errors.  The variable optimizes as expected.  However, in my application, I need to do such a calculation with multiple inputs, so something of this form:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad
</code></pre>

<p>Running this in place of the example (and adding another variable input to the call of <code>my_identify</code>) results in the following error output.  Best as I can tell, the last parts of the error are from the dynamic generation of the op -- the information format matches the C++ formatting required in the op establishment (though that's about all I know about it).</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 27, in &lt;module&gt;
    train = opt.minimize(loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 400, in minimize
    grad_loss=grad_loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 519, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 630, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 821, in _GradientsHelper
    _VerifyGeneratedGradients(in_grads, op)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 323, in _VerifyGeneratedGradients
    ""inputs %d"" % (len(grads), op.node_def, len(op.inputs)))
ValueError: Num gradients 2 generated for op name: ""IdentityN""
op: ""IdentityN""
input: ""Identity""
input: ""x/read""
input: ""y/read""
attr {
  key: ""T""
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_gradient_op_type""
  value {
    s: ""CustomGradient-9""
  }
}
 do not match num inputs 3
</code></pre>

<p>Based on other custom gradient options, I surmised that the issue was a lack of supplied gradient for the second input argument.  So, I changed my function to this:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad, grad
</code></pre>

<p>This results in the following more familiar error:</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 22, in &lt;module&gt;
    y = my_identity(x, z)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 111, in decorated
    return _graph_mode_decorator(f, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 132, in _graph_mode_decorator
    result, grad_fn = f(*args)
ValueError: too many values to unpack (expected 2)
</code></pre>

<p>The <code>@custom_gradient</code> decorator is only identifying the last returned element as a gradient.  So, I tried putting the two gradients into a tuple as <code>(grad, grad)</code> such that there would only be ""two"" outputs for the function.  TensorFlow rejected this too, this time because it can't call a tuple like it would a Tensor -- entirely reasonable, in hindsight.</p>

<p>I've fussed around with the example some more, but to no avail.  No matter what I try, I can't get the custom-defined gradient to deal with multiple inputs.  I'm hoping that somebody with more knowledge than I regarding custom ops and gradients will have a better idea on this -- thanks in advance for the help!</p>
",1,Documentation Replication on Other Examples
245,54183967,Using tf.map_fn with multiple GPUs,"<p>I'm trying to extend my single-GPU TensorFlow code to multi-GPU. I have to work on 3 degrees of freedom and unfortunately I need to use tf.map_fn to parallelize over the 3rd one. I tried to use device placement as shown in the official documentation, but it looks like it is impossible to do it with <code>tf.map_fn</code>. Is there a way to run <code>tf.map_fn</code> on multiple GPUs?</p>

<p>Here the error output:</p>

<pre><code>InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'map_1/TensorArray_1': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/device:GPU:1'
Colocation Debug Info:
Colocation group had the following types and devices: 
TensorArrayGatherV3: GPU CPU 
Range: GPU CPU 
TensorArrayWriteV3: GPU CPU 
TensorArraySizeV3: GPU CPU 
MatMul: GPU CPU 
Enter: GPU CPU 
TensorArrayV3: GPU CPU 
Const: GPU CPU 

Colocation members and user-requested devices:
  map_1/TensorArrayStack/range/delta (Const) 
  map_1/TensorArrayStack/range/start (Const) 
  map_1/TensorArray_1 (TensorArrayV3) 
  map_1/while/TensorArrayWrite/TensorArrayWriteV3/Enter (Enter) /device:GPU:1
  map_1/TensorArrayStack/TensorArraySizeV3 (TensorArraySizeV3) 
  map_1/TensorArrayStack/range (Range) 
  map_1/TensorArrayStack/TensorArrayGatherV3 (TensorArrayGatherV3) 
  map_1/while/MatMul (MatMul) /device:GPU:1
  map_1/while/TensorArrayWrite/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1

         [[Node: map_1/TensorArray_1 = TensorArrayV3[clear_after_read=true, dtype=DT_FLOAT, dynamic_size=false, element_shape=&lt;unknown&gt;, identical_element_shapes=true, tensor_array_name=""""](map_1/TensorArray_1/size)]]
</code></pre>

<p>Here a simple code example to reproduce it:</p>

<pre><code>import tensorflow as tf
import numpy

rc = 1000

sess = tf.Session()

for deviceName in ['/cpu:0', '/device:GPU:0', '/device:GPU:1']:
        with tf.device(deviceName):
                matrices = tf.random_uniform([rc,rc,4],minval = 0, maxval = 1, dtype = tf.float32)

                def mult(i):
                        product = tf.matmul(matrices[:,:,i],matrices[:,:,i+1])
                        return product

                mul = tf.zeros([rc,rc,3], dtype = tf.float32)
                mul = tf.map_fn(mult, numpy.array([0,1,2]), dtype = tf.float32, parallel_iterations = 10)

m = sess.run(mul)


</code></pre>
",1,Documentation Replicability
246,54211834,how to use tf.print (not tf.Print) in high-level Estimator api,"<p>Currently, I'm using <code>tf.Print</code> to print(debug) tensor in estimator, but this api is marked deprecated, and recommend me to use tf.print instead. According to the <a href=""https://github.com/tensorflow/community/pull/14/files"" rel=""nofollow noreferrer"">RFC</a>, by using tf.print, I need to have control of the running session, but <code>Estimator</code> is designed to hide session and graph from users. So, how to use <code>tf.print</code> in Estimator?</p>
",1,Documentation Replicability
247,54509752,How to translate deprecated tf.train.QueueRunners tensorflow approach to importing data to new tf.data.Dataset approach,"<p>Altough tensorflow recommends very much to not use deprecated functions that are going to be replaced by tf.data objects, there seems to be no good documentation for cleanly replacing the deprecated for the modern approach. Moreover, Tensorflow tutorials still use the deprecated functionality to treat file processing (Reading data tutorial: <a href=""https://www.tensorflow.org/api_guides/python/reading_data"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_guides/python/reading_data</a>). </p>

<p>On the other hand, though there is good documentation for using the 'modern' approach (Importing data tutorial: <a href=""https://www.tensorflow.org/guide/datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/datasets</a>), there still exists the old tutorials which will probably lead many, as me, to use the deprecated one first. That is why one would like to cleanly translate the deprecated to the 'modern' approach, and an example for this translation would probably be very useful.</p>

<pre><code>#!/usr/bin/env python3
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import shutil
import os

if not os.path.exists('example'):
    shutil.rmTree('example');
    os.mkdir('example');

batch_sz = 10; epochs = 2; buffer_size = 30; samples = 0;
for i in range(50):
    _x = np.random.randint(0, 256, (10, 10, 3), np.uint8);
    plt.imsave(""example/image_{}.jpg"".format(i), _x)
images = tf.train.match_filenames_once('example/*.jpg')
fname_q = tf.train.string_input_producer(images,epochs, True);
reader = tf.WholeFileReader()
_, value = reader.read(fname_q)
img = tf.image.decode_image(value)
img_batch = tf.train.batch([img], batch_sz, shapes=([10, 10, 3]));
with tf.Session() as sess:
    sess.run([tf.global_variables_initializer(),
        tf.local_variables_initializer()])
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    for _ in range(epochs):
        try:
            while not coord.should_stop():
                sess.run(img_batch)
                samples += batch_sz;
                print(samples, ""samples have been seen"")
        except tf.errors.OutOfRangeError:
            print('Done training -- epoch limit reached')
        finally:
            coord.request_stop();
    coord.join(threads)
</code></pre>

<p>This code runs perfectly well for me, printing to console:</p>

<pre><code>10 samples have been seen
20 samples have been seen
30 samples have been seen
40 samples have been seen
50 samples have been seen
60 samples have been seen
70 samples have been seen
80 samples have been seen
90 samples have been seen
100 samples have been seen
110 samples have been seen
120 samples have been seen
130 samples have been seen
140 samples have been seen
150 samples have been seen
160 samples have been seen
170 samples have been seen
180 samples have been seen
190 samples have been seen
200 samples have been seen
Done training -- epoch limit reached
</code></pre>

<p>As can be seen, it uses deprecated functions and objects as tf.train.string_input_producer() and tf.WholeFileReader(). An equivalent implementation using the 'modern' tf.data.Dataset is needed.</p>

<p><strong>EDIT:</strong></p>

<p>Found already given example for importing CSV data: <a href=""https://stackoverflow.com/questions/53571432/replacing-queue-based-input-pipelines-with-tf-data"">Replacing Queue-based input pipelines with tf.data</a>. I would like to be as complete as possible here, and suppose that more examples are better, so I don't feel it as a repeated question.</p>
",1,Requesting (Additional) Documentation/Examples
248,54524992,Tensorflow serving trained model saved with saved_model,"<p>I find tf.saved_model documentation not clear, is there any valuable resources how to read trained model within other session?</p>
",1,Documentation Replication on Other Examples
249,54557468,"In tf.keras.layers.Embedding, why it is important to know the size of dictionary?","<p>Same as the title, in tf.keras.layers.Embedding, why it is important to know the size of dictionary as input dimension?</p>
",1,Documentation Replicability
250,54606302,tf.data.Dataset from tf.keras.preprocessing.image.ImageDataGenerator.flow_from_directory?,"<p>How do I create a <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""noreferrer""><code>tf.data.Dataset</code></a> from <a href=""https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory"" rel=""noreferrer""><code>tf.keras.preprocessing.image.ImageDataGenerator.flow_from_directory</code></a>?</p>

<p>I'm considering <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""noreferrer""><code>tf.data.Dataset.from_generator</code></a>, but it's unclear how to acquire the <code>output_types</code> keyword argument for it, given the return type:</p>

<blockquote>
  <p>A <code>DirectoryIterator</code> yielding tuples of <code>(x, y)</code> where <code>x</code> is a numpy array containing a batch of images with shape <code>(batch_size, *target_size, channels)</code> and <code>y</code> is a numpy array of corresponding labels.</p>
</blockquote>
",1,Documentation Replication on Other Examples
251,54686895,Tensorflow dilation behave differently than morphological dilation,"<p>As the following piece of code shows, the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dilation2d"" rel=""noreferrer"">tensorflow <code>tf.nn.dilation2D</code> function</a> doesn't behave as a <a href=""https://homepages.inf.ed.ac.uk/rbf/HIPR2/dilate.htm"" rel=""noreferrer"">conventional dilation operator</a>. </p>

<pre><code>import tensorflow as tf
tf.InteractiveSession()
A = [[0, 0, 0, 0, 0, 0, 0],
     [0, 0, 0, 0, 1, 0, 0],
     [0, 0, 0, 1, 1, 1, 0],
     [0, 0, 0, 0, 1, 0, 0],
     [0, 0, 0, 0, 0, 0, 0],
     [0, 0, 0, 0, 0, 0, 0]]
kernel = tf.ones((3,3,1))
input4D = tf.cast(tf.expand_dims(tf.expand_dims(A, -1), 0), tf.float32)
output4D = tf.nn.dilation2d(input4D, filter=kernel, strides=(1,1,1,1), rates=(1,1,1,1), padding=""SAME"")
print(tf.cast(output4D[0,:,:,0], tf.int32).eval())
</code></pre>

<p>Returns the following tensor:</p>

<pre><code>array([[1, 1, 1, 2, 2, 2, 1],
       [1, 1, 2, 2, 2, 2, 2],
       [1, 1, 2, 2, 2, 2, 2],
       [1, 1, 2, 2, 2, 2, 2],
       [1, 1, 1, 2, 2, 2, 1],
       [1, 1, 1, 1, 1, 1, 1]], dtype=int32)
</code></pre>

<p>I don't understand neither <strong>why</strong> it behaves like that, neither <strong>how</strong> I should use <code>tf.nn.dilation2d</code> to retrieve the expected output:</p>

<pre><code>array([[0, 0, 0, 1, 1, 1, 0],
       [0, 0, 1, 1, 1, 1, 1],
       [0, 0, 1, 1, 1, 1, 1],
       [0, 0, 1, 1, 1, 1, 1],
       [0, 0, 0, 1, 1, 1, 0],
       [0, 0, 0, 0, 0, 0, 0]], dtype=int32)
</code></pre>

<p>Can someone enlighten the succinct documentation of tensorflow and give an explanation of what the the <code>tf.nn.dilation2D</code> function does ?</p>
",1,Documentation Ambiguity
252,54897832,Feeding large numpy arrays into TensorFlow estimators via tf.data.Dataset,"<p>TensorFlow's <a href=""https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code> documentation on consuming numpy arrays</a> states that in order to use numpy arrays in combination with the <code>Dataset</code> API, the arrays have to be small enough (&lt;2 GB in total) to be used as tensors, or they can be fed into the dataset via placeholders.</p>

<p>However, if you use <code>Dataset</code> in conjunction with estimators (where placeholders are not available), the documentation does not provide a solution on working with large arrays without placeholders. </p>

<p>Are there other options for passing placeholder values into estimators that can be used or is the solution to provide the data in <code>tfrecord</code> or <code>csv</code> format?</p>
",1,Inadequate Examples
253,54934603,"tensorflow documentation says ""WARNING: Avoid writing code which relies on the value of a Variable..."" what does it mean?","<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">tf.Variable documentation</a> 
contains the following warning:</p>

<blockquote>
  <p>WARNING: tf.Variable objects by default have a non-intuitive memory model. A Variable is represented internally as a mutable Tensor which can non-deterministically alias other Tensors in a graph. The set of operations which consume a Variable and can lead to aliasing is undetermined and can change across TensorFlow versions. Avoid writing code which relies on the value of a Variable either changing or not changing as other operations happen. For example, using Variable objects or simple functions thereof as predicates in a tf.cond is dangerous and error-prone:</p>
</blockquote>

<pre><code>v = tf.Variable(True)
tf.cond(v, lambda: v.assign(False), my_false_fn)  # Note: this is broken.
</code></pre>

<p>I don't quite understand what time means and why the example above is broken. What does it mean that one cannot rely on the value of a Variable? Is it possible to have an example where the code above works not as expected?</p>
",1,Requesting (Additional) Documentation/Examples
254,54945641,"keras, model still setting expected input shape from training despite input_shape(None, ...)","<p>I have a simple CNN model written in the tf.keras framework, which I wish to use with variable input size.</p>

<p>According to <a href=""https://github.com/keras-team/keras/issues/1920#issuecomment-193883690"" rel=""nofollow noreferrer"">this</a> ""documentation"" I can use variable input size by setting <code>input_shape=(None, None, n_channels)</code>, and I have used a <code>GlobalMaxPooling2D</code> layer before my dense layer to standardize the input to the dense layer.</p>

<p>Yet when I train the model with one size of image and try to predict on a different size I get the error:</p>

<pre><code>  File ""multilabel_384.py"", line 180, in main
probabilities = model.predict(test_data)
File ""/usr/local/miniconda3/envs/deepchem/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py"", line 1471, in predict
x, check_steps=True, steps_name='steps', steps=steps)
File ""/usr/local/miniconda3/envs/deepchem/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py"", line 868, in _standardize_user_data
exception_prefix='input')
File ""/usr/local/miniconda3/envs/deepchem/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 191, in standardize_input_data
' but got array with shape ' + str(data_shape))
ValueError: Error when checking input: expected sequential_input to have shape (16, 24, 1) but got array with shape (32, 48, 1)
</code></pre>

<p>This is the code used to define my model:</p>

<pre><code>from tensorflow.keras import layers
import tensorflow as tf

def make_model(num_classes=8):
    # type (int) -&gt; tf.keras.model
    """"""implementation of SimpleNet in keras""""""
    model = tf.keras.Sequential()
    # conv layers
    model.add(layers.ZeroPadding2D(2))
    model.add(layers.Conv2D(input_shape=(None, None, 1),
                            filters=32, kernel_size=5, activation=""relu""))
    model.add(layers.BatchNormalization())
    model.add(layers.ZeroPadding2D(2))
    model.add(layers.Conv2D(filters=64,  kernel_size=5, activation=""relu""))
    model.add(layers.Conv2D(filters=128, kernel_size=3, activation=""relu""))
    model.add(layers.Conv2D(filters=256, kernel_size=3, activation=""relu""))
    model.add(layers.Conv2D(filters=128, kernel_size=3, activation=""relu""))
    model.add(layers.GlobalMaxPooling2D())
    # dense layers
    model.add(layers.Flatten())
    model.add(layers.Dense(128, activation=""relu""))
    model.add(layers.Dropout(0.25))
    model.add(layers.Dense(256, activation=""relu""))
    model.add(layers.Dropout(0.25))
    # use sigmoid for multiclass problems
    model.add(layers.Dense(num_classes, activation=""sigmoid""))
    return model
</code></pre>

<p>So in essence my question is why is keras <em>still</em> defining an expected input shape, and is there any way to disable this implicit <code>standardize_input_data</code> that's going on?</p>
",1,Documentation Replicability
255,54966581,tf.boolean_mask not accepting the axis argument,"<p>Here is my code:  </p>

<pre><code> 44     scores = tf.boolean_mask(box_class_scores,filtering_mask,axis=-1)
 45     boxes = tf.boolean_mask(boxes,filtering_mask,axis=-1)
 46     classes = tf.boolean_mask(box_classes,filtering_mask,axis=-1)
</code></pre>

<p>Error, I'm getting:</p>

<blockquote>
  <p>TypeError: boolean_mask() got an unexpected keyword argument 'axis'</p>
</blockquote>

<p>The <code>tf.boolean_mask()</code> is not accepting the axis argument but is a valid argument as can be seen in the documentation: <a href=""https://www.tensorflow.org/api_docs/python/tf/boolean_mask"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/boolean_mask</a></p>

<p><a href=""https://i.stack.imgur.com/bne6B.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bne6B.png"" alt=""enter image description here""></a></p>
",1,Documentation Ambiguity
256,54989442,"RNN in Tensorflow vs Keras, depreciation of tf.nn.dynamic_rnn()","<p>My question is: Are the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""noreferrer""><code>tf.nn.dynamic_rnn</code></a> and <code>keras.layers.RNN(cell)</code> truly identical as stated in docs? </p>

<p>I am planning on building an RNN, however, it seems that <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""noreferrer""><code>tf.nn.dynamic_rnn</code></a> is depricated in favour of Keras.</p>

<p>In particular, it states that:</p>

<blockquote>
  <p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future
  version. Instructions for updating: Please use keras.layers.RNN(cell),
  which is equivalent to this API</p>
</blockquote>

<p>But I don't see how the APIs are equivalent, in the case of variable sequence lengths!</p>

<p>In raw TF, we can specify a tensor of shape <code>(batch_size, seq_lengths)</code>. This way, if our sequence is <code>[0, 1, 2, 3, 4]</code> and the longest sequence in the batch is of size 10, we can pad it with 0s and <code>[0, 1, 2, 3, 4, 0, 0, 0, 0, 0]</code>, we can say <code>seq_length=5</code> to process <code>[0, 1, 2, 3, 4]</code>.</p>

<p>However, in Keras, this is not how it works! What we can do, is specify the <code>mask_zero=True</code> in previous Layers, e.g. the Embedding Layer. This will also mask the 1st zero!</p>

<p>I can go around it by adding ones to the whole vector, but then thats extra preprocessing that I need to do after processing using <code>tft.compute_vocabulary()</code>, which maps vocabulary words to 0 indexed vector.</p>
",1,Documentation Replication on Other Examples
257,55005915,How to resize image to put into tf.train.Example,"<p>I have an image (JPEG or PNG) as a byte buffer (read from the internet), and this is the way I was putting it in a <code>tf.train.Example</code> before:</p>

<pre><code>record = tf.train.Example(features=tf.train.Features(feature={
    'image/encoded': dataset_util.bytes_feature(image_bytes)
    # there are more features but they're not relevant
}))
</code></pre>

<p>However, for my usecase, the images are too big, so I'd like to resize them either before I put them in the <code>tf.train.Example</code> or just after (whichever is easiest).</p>

<p>Here's what I'm trying:</p>

<pre><code># predeclared
# - image_bytes
# - image_format
# - height
# - width

# resize image
if image_format == b'jpeg':
    image = tf.image.decode_jpeg(image_bytes, None, tf.float32)
elif image_format == b'png':
    image = tf.image.decode_png(image_bytes, None, tf.float32)

image = tf.image.resize_images(image, (int(height), int(width)))

image = tf.image.convert_image_dtype(image, tf.uint8)
record = tf.train.Example(features=tf.train.Features(feature={
    'image/encoded': dataset_util.bytes_feature(tf.image.encode_jpeg(image))
    # there are more features but they're not relevant
}))
</code></pre>

<p>I suspect this is valid right up until I actually try to put it in the <code>tf.train.Example</code>, at which point it tells me <code>TypeError: &lt;tf.Tensor 'EncodeJpeg:0' shape=() dtype=string&gt; has type Tensor, but expected one of: bytes</code>. I've tried figuring out how to get the <code>Tensor</code> into a <code>BytesList</code> or something like it, but I haven't been able to find any documentation for this. I suspect there may be a better way to approach the entire process however.</p>

<p>How can I do this the right way?</p>
",1,Lack of Alternative Solutions/Documentation
258,55044905,"Tensorflow low level api, batch normalization problem","<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">tf.layers.batch_normalization</a> documentation says it will be removed in a future version, and should be replaced by <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""nofollow noreferrer"">tf.keras.layers.BatchNormalization</a>, but i cannot find a way to replace the functionality using tensorflow low level api.</p>

<pre><code>import tensorflow as tf
bn = tf.layers.batch_normalization(tf.constant([0.0]), training=True)
print(tf.get_collection(tf.GraphKeys.UPDATE_OPS))
</code></pre>

<p>which outputs:</p>

<pre><code>[&lt;tf.Operation 'batch_normalization/AssignMovingAvg' type=AssignSub&gt;,
&lt;tf.Operation 'batch_normalization/AssignMovingAvg_1' type=AssignSub&gt;]
</code></pre>

<p>If we instead use keras as suggested in the documentation</p>

<pre><code>bn = tf.keras.layers.BatchNormalization(axis=-1)(tf.constant([0.0]), training=True)
</code></pre>

<p>we get an empty output:</p>

<pre><code>[]
</code></pre>

<p>Since UPDATE_OPS is empty, the model is unable to update the batch normalization moving_avg_mean and moving_avg_variance during training using keras (resulting in a much higer test error). Any suggestion how to solve this is greatly appreciated! </p>

<p>The example above is taken from an older post of how to use <a href=""https://stackoverflow.com/questions/48874558/tensorflow-tf-layers-batch-normalization-doesnt-add-update-ops-to-tf-graphke"">tf.layers.batch_normalization</a></p>
",1,Documentation Replication on Other Examples
259,55094952,Understanding Tensorflow control dependencies,"<p>I am trying to gain a stronger grasp of TensorFlow. I came across the concept of control dependencies. I understand that the order of ops as specified by us is not really relevant to Tensorflow during execution. In order to optimise the speed of execution TensorFlow decides its own order of calculating nodes. 
But we can customise order of execution by using tf.control_dependencies.
I am not able to understand the use cases of the function. Can anyone direct me to some resource(other than the documentation) or explain the working of this function?
An example:</p>

<pre><code>tf.reset_default_graph()
x = tf.Variable(5)
y=tf.Variable(3)
assign = tf.assign(x,x+y)
z = x+assign
with tf.Session() as sess:
   sess.run(tf.global_variables_initializer())
   with tf.control_dependencies([assign]):
        z_out = sess.run(z)

print(z_out)
</code></pre>

<p>The output of the code is 8. So I infer that since z=x+y,the assign node has not been evaluated(right?). But doesn't this mean that the result of tensorflow may be erroneous? This means we need to create new nodes during every operation to force TensorFlow to calculate all the nodes leading up to the result. But in say training a neural network with 10000 steps if each step creates a new set of 1000 weights/parameters won't the space complexity explode?</p>
",1,Inadequate Examples
260,55109696,TensorFlow - Difference between tf.keras.layers.Layer vs tf.keras.Model,"<p>Reading through the <a href=""https://www.tensorflow.org/tutorials/eager/custom_layers"" rel=""noreferrer"">documentation of implementing custom layers</a> with <code>tf.keras</code>, they specify two options to inherit from, <code>tf.keras.Layer</code> and <code>tf.keras.Model</code>.</p>

<p>Under the context of <em>creating custom layers</em>, I'm asking myself what is the difference between these two? Technically what is different?</p>

<p>If I were to implement the transformer encoder for example, which one would be more suitable? (assuming the transformer is a only a ""layer"" in my full model)</p>
",1,Documentation Replication on Other Examples
261,55141486,Unable to see keras model graph in Tensorboard when using TensorFlow 2.0 Alpha,"<p>I am trying custom training on TensorFlow 2.0 alpha and at the same time I am trying to add some metrics and my training graph to TensorBoard. Consider the following contrived example</p>

<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model


def create_model():
    inp = Input((32, ))
    net = Dense(16, activation=""relu"")(inp)
    net = Dense(8, activation=""relu"")(net)
    net = Dense(2, activation=None)(net)
    return Model(inp, net)


@tf.function
def grad(model, loss, x, y):
    with tf.GradientTape() as tape:
        y_ = model(x)
        loss_value = loss(y_true=y, y_pred=y_)
    return loss_value, tape.gradient(loss_value, model.trainable_variables)


@tf.function
def train_step(model, loss, optimizer, features, labels):
    loss_value, grads = grad(model, loss, features, labels)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss_value


def train():
    tf.summary.trace_on(graph=True, profiler=True)

    with tf.summary.create_file_writer(""model"").as_default():
        model = create_model()

        loss = tf.keras.losses.MeanSquaredError()
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

        for i in range(10):
            tf.summary.experimental.set_step(i)

            features = tf.random.normal((16, 32))
            labels = tf.random.normal((16, 2))
            loss_value = train_step(model, loss, optimizer, features, labels)
            print(loss_value)

        tf.summary.trace_export(""model"", profiler_outdir=""model"")


if __name__ == ""__main__"":
    train()
</code></pre>

<p>This, does not show the model graph properly, on doing</p>

<pre><code>tensorboard --logdir model
</code></pre>

<p>In the graphs tab I am seeing <a href=""https://i.stack.imgur.com/TRbqc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/TRbqc.png"" alt=""tensorboard""></a></p>

<p>I am getting the graph when I am training through model.fit or estimator. For example, here is the graphs section when I use <code>model_to_estimator</code> to convert a model</p>

<p><a href=""https://i.stack.imgur.com/h0rBQ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/h0rBQ.png"" alt=""model_to_estiamtor""></a></p>

<p><a href=""https://www.tensorflow.org/alpha/tutorials/eager/custom_training_walkthrough"" rel=""noreferrer"">The guide article</a> does not track metrics through tensorboard, and I did not find any sections on the new workflow for custom adding and tracking of metrics in TensorBoard on alpha (<a href=""https://www.tensorflow.org/alpha"" rel=""noreferrer"">https://www.tensorflow.org/alpha</a>). My contrived implementation is based on the API documentation of tf.summary (<a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/summary"" rel=""noreferrer"">https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/summary</a>) </p>
",1,Documentation Replication on Other Examples
262,55168906,Tensorflow - tf.nn.weighted_cross_entropy_with_logits - logits and targets must have the same shape,"<p>I've just started using tensorflow for a project I'm working on. The program aims to be a binary classifier with input being 12 features. The output is either normal patient or patient with a disease. The prevalence of the disease is quite low and so my dataset is very imbalanced, with 502 examples of normal controls and only 38 diseased patients. For this reason, I'm trying to use <code>tf.nn.weighted_cross_entropy_with_logits</code> as my cost function.</p>

<p>The code is based on the iris custom estimator from the official tensorflow documentation, and works with <code>tf.losses.sparse_softmax_cross_entropy</code> as the cost function. However, when I change to <code>weighted_cross_entropy_with_logits</code>, I get a shape error and I'm not sure how to fix this.</p>

<pre><code>ValueError: logits and targets must have the same shape ((?, 2) vs (?,))
</code></pre>

<p>I have searched and similar problems have been solved by just reshaping the labels - I have tried to do this unsuccessfully (and don't understand why <code>tf.losses.sparse_softmax_cross_entropy</code> works fine and the weighted version does not). </p>

<p>My full code is here
<a href=""https://gist.github.com/revacious/83142573700c17b8d26a4a1b84b0dff7"" rel=""nofollow noreferrer"">https://gist.github.com/revacious/83142573700c17b8d26a4a1b84b0dff7</a></p>

<p>Thanks!</p>
",1,Documentation Replication on Other Examples
263,55176818,How to support masking in custom tf.keras.layers.Layer,"<p>I'm implementing a custom <code>tf.keras.layers.Layer</code> that needs to support masking.</p>

<p>Consider the following scenario</p>

<pre class=""lang-py prettyprint-override""><code>embedded = tf.keras.layer.Embedding(input_dim=vocab_size + 1, 
                                    output_dim=n_dims, 
                                    mask_zero=True)
x = MyCustomKerasLayers(embedded)
</code></pre>

<p>Now per the documentation</p>

<blockquote>
  <p><code>mask_zero</code>: Whether or not the input value 0 is a special ""padding"" value that should be masked out. This is useful when using recurrent layers which may take variable length input. <strong>If this is True then all subsequent layers in the model need to support masking or an exception will be raised</strong>. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).</p>
</blockquote>

<p>I wonder, what does that mean? Looking through <a href=""https://www.tensorflow.org/tutorials/eager/custom_layers"" rel=""noreferrer"">TensorFlow's custom layers guide</a> and the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer"" rel=""noreferrer"">tf.keras.layer.Layer</a> documentation it is not clear what should be done to support masking</p>

<ol>
<li><p>How do I support masking?</p></li>
<li><p>How do I access the mask from the past layer? </p></li>
<li><p>Assuming input of <code>(batch, time, channels)</code> or `(batch, time) would the masks look different? What will be their shapes?</p></li>
<li><p>How do I pass it on to the next layer? </p></li>
</ol>
",1,Lack of Alternative Solutions/Documentation
264,55199181,keras v. tf.keras compile command for sequential model,"<p>I've been getting up to speed in keras, not realizing that tf.keras is also a thing (and for newbies, it's easy to get cross ways with imports in python). In trying to convert a script from keras to tf.keras, it appears that the commands are not consistent? In general, is tf.keras supposed to follow the keras documentation, or are they diverging?</p>

<p>My specific issue is that this works with keras, but not tf.keras:</p>

<pre><code>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>This gives error:</p>

<pre><code>ValueError: optimizer must be an instance of tf.train.Optimizer, not a &lt;class 'str'&gt;
</code></pre>

<p>This seems inconsistent with the tf.keras docs (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#compile"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#compile</a>).  Any idea what is going on?</p>
",1,Documentation Ambiguity
265,55264696,Tensorflow dynamic_rnn deprecation,"<p>It seems that the <code>tf.nn.dynamic_rnn</code> has been deprecated: </p>

<blockquote>
  <p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use keras.layers.RNN(cell), which is equivalent to this API</p>
</blockquote>

<p>I have checked out keras.layers.RNN(cell) and it says that it can use masking which I assume can act as a replacement for <code>dynamic_rnn</code>'s <code>sequence_length</code> parameter? </p>

<blockquote>
  <p>This layer supports masking for input data with a variable number of timesteps. To introduce masks to your data, use an Embedding layer with the mask_zero parameter set to True.</p>
</blockquote>

<p>But there is no further information even in the Embedding docs for how I can use <code>mask_zero=True</code> to accommodate variable sequence lengths. Also, if I am using an embedding layer just to add a mask, how do I prevent the Embedding from changing my input and being trained? </p>

<p>Similar to this question <a href=""https://stackoverflow.com/questions/54989442/rnn-in-tensorflow-vs-keras-depreciation-of-tf-nn-dynamic-rnn"">RNN in Tensorflow vs Keras, depreciation of tf.nn.dynamic_rnn()</a> but I want to know how to use the mask to replace <code>sequence_length</code></p>
",1,Documentation Replication on Other Examples
266,55300544,TF 2.0 @tf.function example,"<p>In the tensorflow documentation at the <a href=""https://www.tensorflow.org/alpha/guide/autograph"" rel=""nofollow noreferrer"">autograph</a> section we have the following code snippet</p>

<pre class=""lang-py prettyprint-override""><code>@tf.function
def train(model, optimizer):
  train_ds = mnist_dataset()
  step = 0
  loss = 0.0
  accuracy = 0.0
  for x, y in train_ds:
    step += 1
    loss = train_one_step(model, optimizer, x, y)
    if tf.equal(step % 10, 0):
      tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())
  return step, loss, accuracy

step, loss, accuracy = train(model, optimizer)
print('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())
</code></pre>

<p>I have a small question concerning the <code>step</code> variable, it's an integer and not a tensor, autograph supports built-in python type such as integer. Therefore the <code>tf.equal(step%10,0)</code> could be changed to simply <code>step%10 == 0</code> right ? </p>
",1,Documentation Replication on Other Examples
267,55347304,Error when applying sample/class weights to fit generator,"<p>I am using a tf.keras.Model fit_generator (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit_generator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit_generator</a>)  to feed batches of data to a model. According to TensorFlow Documentation, the fit generator should be able to accept size 2 (inputs, targets) or 3 (inputs, targets, sample_weights) tuple. We have the size 2 working, but we have unbalanced classes, so I have determined sample weights. When the fit generator returns a size 3 tuple, I get the error:
”tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got [batch_size]""</p>

<p>I am using tensorflow 1.12</p>

<p>Loss Function is tf.losses.softmax_cross_entropy</p>
",1,Documentation Replication on Other Examples
268,55379830,How do I resize image with unknown size in Tensorflow(tf.shape(input) method doesn't work),"<p>According to <a href=""https://stackoverflow.com/questions/52410154/resizing-tensorflow-images-with-unknown-size"">this post</a>, one can use tf.shape() to resize image with unknown size like placeholder. But the method doesn't seem to work for me. I have some simple code that looks like:</p>

<pre><code>import tensorflow as tf
import numpy as np

def speed_tune(x, lower_bound=0.8, upper_bound=2.0):
    speed_rate = np.random.uniform(lower_bound, upper_bound)
    newshape = tf.shape(x)[1:] # get the tensor shape except for rank 0(None)
    newshape *= speed_rate # randomly stretch or compress the signal 
    return tf.resize(x, newshape)

sess = tf.InteractiveSession()
x = tf.placeholder(tf.int16, (None, 1000)) # x is a 1D audio signal
y = speed_tune(x)
data = np.random.randint(10, size=1000)
output = sess.run(y, feed_dict={x:data})
</code></pre>

<p>Basically, my code does the following: Given an input 1D data x, the program tries to stretch or compress the sequence by some random factor and return the tuned sequence. Since I didn't find any Tensorflow function that directly performs this operation, I use tf.resize by treating the data as 1xD image where D is the length of the signal. But I got an error:</p>

<pre><code>Traceback (most recent call last):
  File ""d:\SVNRepo\Python_codes\scratch.py"", line 33, in &lt;module&gt;
    y = speed_tune(x)
  File ""d:\SVNRepo\Python_codes\scratch.py"", line 28, in speed_tune
    newshape *= speed_rate # randomly stretch or compress the signal 
TypeError: unsupported operand type(s) for *=: 'Tensor' and 'float'
</code></pre>

<p>So it seems like <code>tf.shape(x)</code> returns a Tensor rather than integer values that specify the shape of the tensor(verified by <a href=""https://www.tensorflow.org/api_docs/python/tf/shape"" rel=""nofollow noreferrer"">Tensorflow document</a>). How can I solve this?</p>
",1,Documentation Replication on Other Examples
269,55422537,Testing TF serving model fails with bytes as strings and strings as bytes confusion,"<p>I'm having a problem serving my text classification model on <code>Tensorflow 1.12</code>. I'm using <code>tf.estimator.inputs.pandas_input_fn</code> to read in my data, and <code>tf.estimator.DNNClassifier</code> to train/evaluate. I'd then like to serve my model.
(Apologies in advance, it's tough to provide a full working example here, but it's very much like the example TF provides at <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier</a>  )</p>

<p>I'm currently saving my model with ...</p>

<pre class=""lang-py prettyprint-override""><code>...
estimator.export_savedmodel(""./TEST_SERVING/"", self.serving_input_receiver_fn, strip_default_attrs=True)
...
def serving_input_receiver_fn(self):
      """"""An input receiver that expects a serialized tf.Example.""""""

      # feature spec dictionary  determines our input parameters for the model
      feature_spec = {
          'Headline': tf.VarLenFeature(dtype=tf.string),
          'Description': tf.VarLenFeature(dtype=tf.string)
      }

      # the inputs will be initially fed as strings with data serialized by
      # Google ProtoBuffers
      serialized_tf_example = tf.placeholder(
          dtype=tf.string, shape=None, name='input_example_tensor')
      receiver_tensors = {'examples': serialized_tf_example}

      # deserialize input
      features = tf.parse_example(serialized_tf_example, feature_spec)
      return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)


</code></pre>

<p>This actually fails to run with the error:</p>

<pre class=""lang-sh prettyprint-override""><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt; to Tensor. Contents: SparseTensor(indices=Tensor(""ParseExample/ParseExample:0"", shape=(?, 2), 
dtype=int64), values=Tensor(""ParseExample/ParseExample:2"", shape=(?,), dtype=string), dense_shape=Tensor(""ParseExample/ParseExample:4"", shape=(2,), dtype=int64)). Consider casting elements to a supported type.

</code></pre>

<p>I tried to save a second way doing:</p>

<pre class=""lang-py prettyprint-override""><code>def serving_input_receiver_fn(self):
  """"""Build the serving inputs.""""""
  INPUT_COLUMNS = [""Headline"",""Description""]
  inputs = {}
  for feat in INPUT_COLUMNS:
    inputs[feat] = tf.placeholder(shape=[None], dtype=tf.string, name=feat)
  return tf.estimator.export.ServingInputReceiver(inputs, inputs)
</code></pre>

<p>This actually works, until I try testing it with the <code>saved_model_cli</code>.
Some output for <code>saved_model_cli show --all --dir TEST_SERVING/1553879255/</code>:</p>

<pre class=""lang-sh prettyprint-override""><code>MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['predict']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['Description'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Description:0
    inputs['Headline'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Headline:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['class_ids'] tensor_info:
        dtype: DT_INT64
        shape: (-1, 1)
        name: dnn/head/predictions/ExpandDims:0
    outputs['classes'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: dnn/head/predictions/str_classes:0
    outputs['logits'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/logits/BiasAdd:0
    outputs['probabilities'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/head/predictions/probabilities:0
  Method name is: tensorflow/serving/predict

</code></pre>

<p>But now I can't seem to test it.</p>

<pre class=""lang-sh prettyprint-override""><code>&gt;&gt;&gt; saved_model_cli run --dir TEST_SERVING/1553879255/ --tag_set serve --signature_def predict --input_examples 'inputs=[{""Description"":[""What is going on""],""Headline"":[""Help me""]}]'
Traceback (most recent call last):
 ...
  File ""/Users/Josh/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 489, in _create_example_string
    feature_list)
TypeError: 'What is going on' has type str, but expected one of: bytes

</code></pre>

<p>Ok, lets turn it into a bytes object by changing to <code>b[""What is going on""]</code> and <code>b[""Help me""]</code>...</p>

<pre class=""lang-sh prettyprint-override""><code>ValueError: Type &lt;class 'bytes'&gt; for value b'What is going on' is not supported for tf.train.Feature.
</code></pre>

<p>Any ideas/thoughts??
Thanks!</p>
",1,Documentation Replication on Other Examples
270,55425811,Implementing Intersection over Union Loss Using Tensorflow,"<p>This may be more of a Tensorflow gradient question. I have been attempting to implement Intersection over Union (IoU) as losses and have been running into some problems. To the point, here is the snippet of my code that computes the IoU:</p>

<pre><code>def get_iou(masks, predictions):
    ious = []
    for i in range(batch_size):
        mask = masks[i]
        pred = predictions[i]
        masks_sum = tf.reduce_sum(mask)
        predictions_sum = tf.reduce_mean(pred)
        intersection = tf.reduce_sum(tf.multiply(mask, pred))
        union = masks_sum + predictions_sum - intersection
        iou = intersection / union
        ious.append(iou)
    return ious

iou = get_iou(masks, predictions)
mean_iou_loss = -tf.log(tf.reduce_sum(iou))
train_op = tf.train.AdamOptimizer(0.001).minimize(mean_iou_loss)
</code></pre>

<p>It works as predicted. However, the issue that I am having is the losses do not decrease. The model does train, though the results are less than ideal so I am wondering if I am implementing it correctly. Do I have to compute the gradients myself? I can compute the gradients for this IoU loss derived by <a href=""https://arxiv.org/pdf/1608.01471.pdf"" rel=""noreferrer"">this paper</a> using <code>tf.gradients()</code>, though I am not sure how to incorporate that with the <code>tf.train.AdamOptimizer()</code>. Reading the documentation, I feel like <code>compute_gradients</code> and <code>apply_gradients</code> are the commands that I need to use, but I can't find any examples on how to use them. My understanding is that the Tensorflow graph should be able to come up with the gradient itself via chain rule. So is a custom gradient even necessary in this problem? If the custom gradient is not necessary then I may just have an ill-posed problem and need to adjust some hyperparameters.</p>

<p><strong>Note:</strong> I have tried Tensorflow's implementation of the IoU, <code>tf.metrics.mean_iou()</code>, but it spits out <code>inf</code> every time so I have abandoned that.</p>
",1,Documentation Replication on Other Examples
271,55560676,How to use tf.while_loop with eager execution?,"<p>In the documentation, the body of a tf.while_loop needs to be a python callable.</p>

<pre><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>works but</p>

<pre><code>def b(i):
    tf.add(i,1)

i = tf.constant(0)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>throws a ValueError: Attempt to convert a value (None) with an unsupported type() to a Tensor</p>

<p>In 2.0, eager execution is default, I wonder what's the problem?!</p>
",1,Documentation Replicability
272,55573670,Unexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits,"<p>The TensorFlow documentation for <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> explicitly declares that I should not apply softmax to the inputs of this op:</p>

<blockquote>
  <p>This op expects unscaled logits, since it performs a softmax on logits
  internally for efficiency. Do not call this op with the output of
  softmax, as it will produce incorrect results.</p>
</blockquote>

<p>However if I use cross entropy without softmax it gives me unexpected results. According to <a href=""https://cs231n.github.io/neural-networks-3/#sanitycheck"" rel=""nofollow noreferrer"">CS231n course</a> the expected loss value is around 2.3 for CIFAR-10:</p>

<blockquote>
  <p>For example, for CIFAR-10 with a Softmax classifier we would expect
  the initial loss to be 2.302, because we expect a diffuse probability
  of 0.1 for each class (since there are 10 classes), and Softmax loss
  is the negative log probability of the correct class so: -ln(0.1) =
  2.302.</p>
</blockquote>

<p>However without softmax I get much bigger values, for example 108.91984.</p>

<p>What exactly am I doing wrong with <code>sparse_softmax_cross_entropy_with_logits</code>? The TF code is shown below.</p>

<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.python import keras


(_, _), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_test = np.reshape(x_test, [-1, 32, 32, 3])

y_test = np.reshape(y_test, (10000,))
y_test = y_test.astype(np.int32)

x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3))
y = tf.placeholder(dtype=tf.int32, shape=(None,))

layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x)
layer = tf.nn.relu(layer)
layer = tf.layers.Flatten()(layer)
layer = tf.layers.Dense(units=1000)(layer)
layer = tf.nn.relu(layer)
logits = tf.layers.Dense(units=10)(layer)

# If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)

loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,
                                                      logits=logits)
loss = tf.reduce_mean(loss, name='cross_entropy')

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]})
    print(""loss: "", res)
    # Expected output is value close to 2.3
    # Real outputs are 108.91984, 72.82324, etc.

</code></pre>
",1,Documentation Replication on Other Examples
273,55681290,Feeding Dataset Iterator to Tensorflow,"<p>Can i get a full example somewhere where they feed tf.data.Dataset iterator to a model? I'm trying to feed this data into a model without the help of tf.Estimators.</p>

<pre><code>def preprocess_image(image):
  image = tf.image.decode_jpeg(image, channels=1)
  image = tf.image.resize_images(image, [224, 224])
  image = tf.image.random_flip_left_right(image)
  image /= 255.0
  image = tf.cast(image, tf.float32)
  image = tf.train.shuffle_batch([image],batch_size=16, num_threads=10, capacity=100000, min_after_dequeue=15)
  return image

def load_and_preprocess_image(path):
  image = tf.read_file(path)
  return preprocess_image(image)




train_data_dx = tf.data.Dataset.from_tensor_slices(xray_data_train['full_path'].values)
train_data_dx = train_data_dx.map(load_and_preprocess_image, num_parallel_calls=8)
train_data_dy = xray_data_train['Finding_strings']
print(train_data_dx.output_shapes)
print(train_data_dx.output_types)

test_data_dx = tf.data.Dataset.from_tensor_slices(xray_data_test['full_path'].values)
test_data_dx = test_data_dx.map(load_and_preprocess_image, num_parallel_calls=8)
test_data_dy = xray_data_test['Finding_strings']
</code></pre>
",1,Lack of Alternative Solutions/Documentation
274,55703097,Training while loop in Tensorflow,"<p>I've attempted converting a Python-side training loop to Tensorflow to (hypothetically) make the code run faster - not having to pass control over to cpu constantly. However, I can't manage using <code>tf.while_loop</code>.</p>

<p>Here's the code that works:</p>

<pre><code>import numpy as np
import tensorflow as tf

from tqdm import tqdm
from sklearn.datasets import load_iris
from sklearn.preprocessing import RobustScaler

x, y = load_iris(True)
x = RobustScaler().fit_transform(x)

shape = (10, 10)
max_epochs = 1000


graph = tf.Graph()
sess = tf.Session(graph=graph)

x = x.astype(np.float64)


# Construct graph
with graph.as_default():
    weights = tf.get_variable(
        'weights', shape, initializer=tf.constant_initializer, dtype=tf.float64
    )
    curr_epoch = tf.placeholder(dtype=tf.int64, shape=())

    with tf.name_scope('data'):
        data = tf.data.Dataset.from_tensor_slices(x)
        data = data.shuffle(buffer_size=10000)
        data = data.repeat(max_epochs)
        data = data.batch(1)
        data = data.make_one_shot_iterator().get_next()

    with tf.name_scope('update'):
        update_op = make_update_op(weights)

    init = tf.global_variables_initializer()


sess.run(init)

for i in tqdm(range(max_epochs)):
    for _ in range(x.shape[0]):
        sess.run(update_op, feed_dict={
            curr_epoch: i
        })

np_weights = sess.run(weights)
print(np_weights) # Correctly prints an array of 150's.
</code></pre>

<p>Now, if I create an update function to pass <code>tf.while_loop</code>, an error is thrown.</p>

<pre><code>def make_update_op(w):
    return w.assign(
        w + 0.001
    )

# In the code above:
update_op = tf.while_loop(lambda _: True, make_update_op, (weights,), maximum_iterations=x.shape[0])

# No inner loop:
for i in tqdm(range(max_epochs)):
    sess.run(update_op, feed_dict={
        curr_epoch: i
    })
</code></pre>

<blockquote>
  <p>Line 22, in make_update_op
      <code>return w.assign(</code>
  AttributeError: 'Tensor' object has no attribute 'assign'</p>
</blockquote>

<p>I don't quite understand what is happening even after reading the documentation. <code>weights</code> is a <code>Variable</code> after all. What could be done to correctly make the training loop?</p>
",1,Documentation Replication on Other Examples
275,55711355,How to restore dangling tf.py_func within the tf.data.Dataset() with tf.saved_model API?,"<p>After doing a research for restoring the <code>tf.py_func()</code> when using saved_model API in vain, I couldn't find other information than documented in <a href=""https://www.tensorflow.org/api_docs/python/tf/py_func"" rel=""nofollow noreferrer"">tensorflow</a>:</p>

<blockquote>
  <p>The operation must run in the same address space as the Python program that calls <code>tf.py_func()</code>. If you are using distributed TensorFlow, you must run a <code>tf.train.Server</code> in the same process as the program that calls <code>tf.py_func()</code> and you must pin the created operation to a device in that server (e.g. using with <code>tf.device()</code>:)</p>
</blockquote>

<p>Two save/load snippets help to illustrate the situation. </p>

<p><strong>Save part:</strong></p>

<pre><code>def wrapper(x, y):
    with tf.name_scope('wrapper'):
        return tf.py_func(Copy, [x, y], [tf.float32, tf.float32])

def Copy(x, y):
    return x, y

x_ph = tf.placeholder(tf.float32, [None], 'x_ph')
y_ph = tf.placeholder(tf.float32, [None], 'y_ph')

with tf.name_scope('input'):
    ds = tf.data.Dataset.from_tensor_slices((x_ph, y_ph))
    ds = ds.map(wrapper)
    ds = ds.batch(1)
    it = tf.data.Iterator.from_structure(ds.output_types, ds.output_shapes)
    it_init_op = it.make_initializer(ds, name='it_init_op')

x_it, y_it = it.get_next()

# Simple operation
with tf.name_scope('add'):
    res = tf.add(x_it, y_it)

with tf.Session() as sess:
    sess.run([tf.global_variables_initializer(), it_init_op], feed_dict={y_ph: [10] * 10, x_ph: [i for i in range(10)]})
    sess.run([res])
    tf.saved_model.simple_save(sess, './dummy/test', {'x_ph': x_ph, 'y_ph': y_ph}, {'res': res})
</code></pre>

<p><strong>Load part:</strong></p>

<pre><code>graph = tf.Graph()
graph.as_default()
with tf.Session(graph=graph) as sess:
    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], './dummy/test')

    res = graph.get_tensor_by_name('add/Add:0')
    it_init_op = graph.get_operation_by_name('input/it_init_op')
    x_ph = graph.get_tensor_by_name('x_ph:0')
    y_ph = graph.get_tensor_by_name('y_ph:0')
    sess.run([it_init_op], feed_dict={x_ph: [5] * 5, y_ph: [i for i in range(5)]})

    for _ in range(5):
        sess.run([res])
</code></pre>

<p><strong>Error:</strong></p>

<blockquote>
  <p>ValueError: callback pyfunc_0 is not found</p>
</blockquote>

<p>It's well known that the function wrapped by the <code>tf.py_func()</code> isn't saved with the model. Does anybody has a solution to restore this by using the small hint given by the tf doc applying <code>tf.train.Server</code></p>
",1,Lack of Alternative Solutions/Documentation
276,55718702,How to correctly train with tf.keras.layers.BatchNormalization: Is there still a tf.GraphKeys.UPDATE_OPS dependency?,"<p>My goal is how to correctly train with batch normalizations layers in TensorFlow (TensorFlow version 1.13.1 for Python in Graph Mode) using the recommended tf.keras.layers.BatchNormalization class (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization</a>).</p>

<p>An older recommended approach was to use tf.layers.batch_normalization.  The documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization</a>) indicates that it is currently deprecating instead in favor of tf.keras.layers.BatchNormalization.  </p>

<p>While using the older class, the documentation indicates we must explicitly add dependency on the mean and variance update operations, which would otherwise be dangling nodes outside from any dependencies in training operations:</p>

<pre><code>update_ops_including_from_batch_norms  =  tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
   my_optimizer = tf.super_cool_optimizer(loss)
</code></pre>

<p>My question:  Is this explicit dependence on UPDATE_OPS still needed when training batch norms in TF 1.13 with tf.keras.layers.BatchNormalization?  I don't see this mentioned in the documentation, however, I would be much more comfortable if someone knew for sure (and even better if can point to official documentation or code) that these operation dependencies are implicitly taken care of.</p>
",1,Lack of Alternative Solutions/Documentation
277,55731549,How to use tf.keras Sequential with tf.distribute.ParameterServerStrategy and tf.train.MonitoredSession?,"<p>I'm trying to set up a really easy Minimal Working Example for the following: Use a model built with tf.keras in a tf.train.MonitoredSession using a tf.Server with a tf.distribute.ParameterServerStrategy.</p>

<p>My goal in the end is to use a tf.keras model in a distributed environment using two workers each having one GPU and a parameter server.</p>

<p>The model is built according to the example and documentation found here: <a href=""https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/keras/models/Sequential"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/keras/models/Sequential</a></p>

<p>The parameter server strategy is used according to the documentation found here: <a href=""https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/distribute/ParameterServerStrategy"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/distribute/ParameterServerStrategy</a></p>

<p>The overall setup including the device placement and the use of a MonitoredSession is taken from: <a href=""https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md"" rel=""nofollow noreferrer"">https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md</a></p>

<p>I'm already using the ""allow_soft_placement"" option and I'm ""emulating"" a distributed setup on my local machine having only a single CPU, since there are different problems in the real distributed setup which I'm trying to solve by using a MonitoredSession where the variable initialization is handled automatically.</p>

<p>This Code works with a ""normal"" (not monitored) tf.Session and variable initialization - global, local, model variables and tables etc.</p>

<p>The line which unfreezes the graph is necessary to be able to use a tf.data.Dataset in the tf.keras.Model's fit function, since an iterator has to be created - which causes an error in a frozen graph.</p>

<p>This the code I'm trying to run. I use tensorflow 1.12.0 and python 3.6.7. I've also tried python 2.7, same result.</p>

<p>The code requires no setup besides installing tensorflow.</p>

<pre class=""lang-py prettyprint-override""><code>import sys
import tensorflow as tf

def main(argv):

  # Create local cluster config for run_local_server.sh script.
  cluster = tf.train.ClusterSpec({""worker"": [""localhost:2222""], ""ps"": [""localhost:2223""]})
  task = 0
  job = str(argv[0])

  # Number of GPUs per worker
  GPU_PER_WORKER = 0

  config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
  server = tf.train.Server(cluster, job_name=job, task_index=task,config=config)

  strategy = tf.contrib.distribute.ParameterServerStrategy(num_gpus_per_worker=GPU_PER_WORKER)
  strategy.configure(session_config=config, cluster_spec=cluster,task_type=job,task_id=task)

  with strategy.scope():
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

    x_train = x_train.astype('float32') / 255
    x_test = x_test.astype('float32') / 255

    # Reshape input data from (28, 28) to (28, 28, 1)
    w, h = 28, 28
    x_train = x_train.reshape(x_train.shape[0], w, h, 1)
    x_test = x_test.reshape(x_test.shape[0], w, h, 1)

    # One-hot encode the labels
    y_train = tf.keras.utils.to_categorical(y_train, 10)
    y_test = tf.keras.utils.to_categorical(y_test, 10)

    train_ds = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_train),tf.data.Dataset.from_tensor_slices(y_train))).repeat().shuffle(60000).batch(10)
    val_ds = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_test),tf.data.Dataset.from_tensor_slices(y_test))).repeat().shuffle(10000).batch(10)

    with tf.device(tf.train.replica_device_setter(worker_device=""/job:worker/task:%d"" % task,cluster=cluster)):
      model = tf.keras.models.Sequential()

      conv0 = tf.keras.layers.Conv2D(filters=16, data_format='channels_last', padding=""valid"", kernel_size=4, strides=1, input_shape=(28,28,1), activation=tf.keras.activations.relu)
      model.add(conv0)

      flatten = tf.keras.layers.Flatten()
      model.add(flatten)

      dense1 = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)
      model.add(dense1)

      model.compile(tf.contrib.optimizer_v2.AdamOptimizer(0.001), loss=tf.keras.metrics.mean_absolute_error,metrics=['accuracy'],distribute=strategy)   

    if job == ""ps"":
      server.join()
    elif job == ""worker"":
      with tf.train.MonitoredSession(session_creator=tf.train.ChiefSessionCreator(master=server.target,config=config)) as sess:        
        sess.graph._unsafe_unfinalize()
        history = model.fit(x=train_ds, validation_data=val_ds, validation_steps=1000, steps_per_epoch=100, epochs=60)

if __name__ == ""__main__"":
  main(sys.argv[1:])
</code></pre>

<p>The code requires no extensive setup since the dataset is loaded from the web and converted to a tf.data.Dataset since this is how I want to organize my pipeline with the real data. The MNIST data setup example is taken from 
<a href=""https://www.kaggle.com/margaretmz/mnist-with-tf-keras"" rel=""nofollow noreferrer"">https://www.kaggle.com/margaretmz/mnist-with-tf-keras</a>.</p>

<p>I expect the code to not fail due to wrong variable or operation placement since I'm basically leaving all these decisions to the implementation of tensorflow by using <code>strategy.scope()</code> and <code>tf.device(tf.train.replica_device_setter(worker_device=""/job:worker/task:%d"" % task,cluster=cluster))</code></p>
",1,Documentation Replication on Other Examples
278,55764694,How to use gradient_override_map in Tensorflow 2.0?,"<p>I'm trying to use <code>gradient_override_map</code> with Tensorflow 2.0. There is an <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Graph#gradient_override_map"" rel=""noreferrer"">example in the documentation</a>, which I will use as the example here as well.</p>

<p>In 2.0, <code>GradientTape</code> can be used to compute gradients as follows:</p>

<pre><code>import tensorflow as tf
print(tf.version.VERSION)  # 2.0.0-alpha0

x = tf.Variable(5.0)
with tf.GradientTape() as tape:
    s_1 = tf.square(x)
print(tape.gradient(s_1, x))
</code></pre>

<p>There is also the <code>tf.custom_gradient</code> decorator, which can be used to define the gradient for a <em>new</em> function (again, using the <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/custom_gradient"" rel=""noreferrer"">example from the docs</a>):</p>

<pre><code>import tensorflow as tf
print(tf.version.VERSION)  # 2.0.0-alpha

@tf.custom_gradient
def log1pexp(x):
    e = tf.exp(x)

    def grad(dy):
        return dy * (1 - 1 / (1 + e))

    return tf.math.log(1 + e), grad

x = tf.Variable(100.)

with tf.GradientTape() as tape:
    y = log1pexp(x)

print(tape.gradient(y, x))
</code></pre>

<p>However, I would like to replace the gradient for standard functions such as <code>tf.square</code>. I tried to use the following code:</p>

<pre><code>@tf.RegisterGradient(""CustomSquare"")
def _custom_square_grad(op, grad):
  return tf.constant(0)

with tf.Graph().as_default() as g:
    x = tf.Variable(5.0)
    with g.gradient_override_map({""Square"": ""CustomSquare""}):
        with tf.GradientTape() as tape:
            s_2 = tf.square(x, name=""Square"")

    with tf.compat.v1.Session() as sess:
        sess.run(tf.compat.v1.global_variables_initializer())            
        print(sess.run(tape.gradient(s_2, x)))
</code></pre>

<p>However, there are two issues: The gradient replacement does not seem to work (it is evaluated to <code>10.0</code> instead of <code>0.0</code>) and I need to resort to <code>session.run()</code> to execute the graph. Is there a way to achieve this in ""native"" TensorFlow 2.0?</p>

<p>In TensorFlow 1.12.0, the following produces the desired output:</p>

<pre><code>import tensorflow as tf
print(tf.__version__)  # 1.12.0

@tf.RegisterGradient(""CustomSquare"")
def _custom_square_grad(op, grad):
  return tf.constant(0)

x = tf.Variable(5.0)

g = tf.get_default_graph()
with g.gradient_override_map({""Square"": ""CustomSquare""}):
    s_2 = tf.square(x, name=""Square"")
grad = tf.gradients(s_2, x)

with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  print(sess.run(grad))
</code></pre>
",1,Documentation Replication on Other Examples
279,55778682,fix/freeze individual kernel weights in a convolutional operation,"<p>I'm trying out a workaround for fixing individual kernel weights in a convolutional operation in TensorFlow using Python 3.7. I do it by creating </p>

<ol>
<li>a trainable variable, </li>
<li>an identical non-trainable variable and </li>
<li>a ""mask"" tensor consisting of <strong>1</strong>s and <strong>0s</strong> with the same shape as the created variables in step 1 and 2 above.</li>
</ol>

<p>A <strong>1</strong> in the ""mask"" tensor indicates that I want to fix/freeze that specific weight during training, i.e. not update it in the backward pass.</p>

<p>Now, this workaround works perfectly fine when applied to a fully connected layer but fails when applied to a convolutional layer and I can't figure out why or how to make it work.</p>

<p>Something seems to be happening in the <strong>tf.nn.conv2d()</strong> function call (see code example below) and according to the documentation this is what they do:</p>

<blockquote>
  <p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code><br>
    and a filter / kernel tensor of shape<br>
   <code>[filter_height, filter_width, in_channels, out_channels]</code>, this op<br>
    performs the following:<br>
    1. Flattens the filter to a 2-D matrix with shape<br>
       <code>[filter_height * filter_width * in_channels, output_channels]</code>.<br>
    2. Extracts image patches from the input tensor to form a <em>virtual</em><br>
       tensor of shape <code>[batch, out_height, out_width,&lt;br&gt;
       filter_height * filter_width * in_channels]</code>.<br>
    3. For each patch, right-multiplies the filter matrix and the image patch<br>
       vector.</p>
</blockquote>

<p>But since I use <strong>weights_frozen</strong> which is a tensor and depends on the trainable variable, non-trainable variable and <strong>mask_weights</strong> it should get zero-valued gradients on the positions where I have a 1 in the <strong>mask_weights</strong> tensor.</p>

<pre class=""lang-py prettyprint-override""><code>def conv(input_, layer_name...):

    weights = tf.get_variable(shape=[filter_height, filter_width, in_channels, out_channels], dtype=tf.float32, initializer=tf.glorot_uniform_initializer(), trainable=True)

    weights_fixed = tf.Variable(tf.identity(weights), trainable=False)

    mask_weights = tf.placeholder(tf.float32, weights.shape)


    weights_frozen = tf.add(tf.multiply(mask_weights, weights_fixed), tf.multiply((1 - mask_weights), weights))


    out_conv = tf.nn.conv2d(input=input_, filter=weights_frozen, strides=strides_, padding='SAME')
    out_add = tf.nn.bias_add(value=out_conv, bias=biases_frozen)

    out = tf.nn.relu(features=out_add)

    return out
</code></pre>

<p>As mentioned, I expect to get zero-valued gradients on the positions where I have a <strong>1</strong> in the <strong>mask_weights</strong> tensor, but instead they are non-zero and therefore those weights are being trained, which is not the behavior I'm trying to achieve.</p>
",1,Documentation Ambiguity
280,55788007,Unexpected results when using tfrecords loaded using tf.data.Dataset.list_files() with shuffle argument,"<p>I'm hoping to get clarification on how the <code>shuffle</code> argument in <code>tf.data.Dataset.list_files()</code> works. The documentation states that when <code>shuffle=True</code>, the filenames will be shuffled randomly. I've made model predictions using a tfrecords dataset that has been loaded using <code>tf.data.Dataset.list_files()</code>, and I would've expected the accuracy metric to be the same no matter the order of the files (i.e. whether shuffle is True or False), but am seeing otherwise. </p>

<p>Is this expected behavior or is there something wrong with my code or intepretation? I have reproducible example code below.</p>

<p>Oddly, as long as <code>tf.random.set_random_seed()</code> is set initially (and it seems it doesn't even matter what seed value is set), then the predictions results are the same no matter whether shuffle is True or False in <code>list_files()</code>.</p>

<p>tensorflow==1.13.1, keras==2.2.4</p>

<p>Thanks for any clarifications!</p>

<p>Edit: re-thinking it through and wondering if <code>Y = [y[0] for _ in range(steps) for y in sess.run(Y)]</code> is a separate and independent call?</p>

<pre><code># Fit and Save a Dummy Model
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from sklearn import datasets, metrics

seed = 7
np.random.seed(seed)
tf.random.set_random_seed(seed)

dataset = datasets.load_iris()

X = dataset.data
Y = dataset.target
dummy_Y = np_utils.to_categorical(Y)

# 150 rows
print(len(X))

model = Sequential()
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X, dummy_Y, epochs=10, batch_size=10,  verbose=2)
model.save('./iris/iris_model')

predictions = model.predict(X)
predictions = np.argmax(predictions, axis=1)

# returns accuracy = 0.3466666666666667
print(metrics.accuracy_score(y_true=Y, y_pred=predictions))
</code></pre>

<p>Split dataset into multiple tfrecords files so we can reload it with list_files() later:</p>

<pre><code>numrows = 15
for i, j in enumerate(range(0, len(X), numrows)):
    with tf.python_io.TFRecordWriter('./iris/iris{}.tfrecord'.format(i)) as writer:
        for x, y in zip(X[j:j+numrows, ], Y[j:j+numrows, ]):
            features = tf.train.Features(feature=
                {'X': tf.train.Feature(float_list=tf.train.FloatList(value=x)), 
                'Y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y]))
                })
            example = tf.train.Example(features=features)
            writer.write(example.SerializeToString())
</code></pre>

<p>At this point, I exit (ipython) and restart again:</p>

<pre><code>import numpy as np
import tensorflow as tf
from keras.models import load_model
from sklearn import metrics

model = load_model('./iris/iris_model')

batch_size = 10
steps = int(150/batch_size)
file_pattern = './iris/iris*.tfrecord'

feature_description = {
    'X': tf.FixedLenFeature([4], tf.float32),
    'Y': tf.FixedLenFeature([1], tf.int64)
}

def _parse_function(example_proto):
    return tf.parse_single_example(example_proto, feature_description)

def load_data(filenames, batch_size):
    raw_dataset = tf.data.TFRecordDataset(filenames)
    dataset = raw_dataset.map(_parse_function)
    dataset = dataset.batch(batch_size, drop_remainder=True)
    dataset = dataset.prefetch(2)
    iterator = dataset.make_one_shot_iterator()
    record = iterator.get_next()
    return record['X'], record['Y']

def get_predictions_accuracy(filenames):
    X, Y = load_data(filenames=filenames, batch_size=batch_size)

    predictions = model.predict([X], steps=steps)
    predictions = np.argmax(predictions, axis=1)
    print(len(predictions))

    with tf.Session() as sess:
        Y = [y[0] for _ in range(steps) for y in sess.run(Y)]

    print(metrics.accuracy_score(y_true=Y, y_pred=predictions))
</code></pre>

<pre><code># No shuffle results:
# Returns expected accuracy = 0.3466666666666667
filenames_noshuffle = tf.data.Dataset.list_files(file_pattern=file_pattern, shuffle=False)
get_predictions_accuracy(filenames_noshuffle)
</code></pre>

<pre><code># Shuffle results, no seed value set:
# Returns UNEXPECTED accuracy (non-deterministic value)
filenames_shuffle_noseed = tf.data.Dataset.list_files(file_pattern=file_pattern, shuffle=True)
get_predictions_accuracy(filenames_shuffle_noseed)
</code></pre>

<pre><code># Shuffle results, seed value set:
# Returns expected accuracy = 0.3466666666666667
# It seems like it doesn't even matter what seed value you set, as long as you you set it
seed = 1000
tf.random.set_random_seed(seed)
filenames_shuffle_seed = tf.data.Dataset.list_files(file_pattern=file_pattern, shuffle=True)
get_predictions_accuracy(filenames_shuffle_seed)
</code></pre>
",1,Documentation Replication on Other Examples
281,55904359,TypeError computing gradients with GradientTape.gradient,"

<p>Hello,  </p>

<p>I'm currently trying to compute gradients in <strong>Tensorflow 1.13.1</strong> and using the <code>GradientTape</code> class as explained in the <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">official documentation</a> , but I am getting a <code>TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;</code>.<br>
Below, I will include two simple cases where I get this error, using only out-of-the-box Tensorflow function, the first one being the simpler minimal working example, and the second one that I actually need to solve/get a work-around. For completeness, I am using <strong>Python 3.6.8</strong>.</p>

<h2>Simpler one</h2>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

tf.reset_default_graph()
x = tf.constant([1., 2., 3.])
with tf.GradientTape(persistent=True) as gg:
    gg.watch(x)
    f1 = tf.map_fn(lambda a: a**2, x)
    f2 = x*x

# Computes gradients
d_fx1 = gg.gradient(f1, x)     #Line that causes the error
d_fx2 = gg.gradient(f2, x)     #No error
del gg #delete persistent GradientTape

with tf.Session() as sess:
    d1, d2 = sess.run((d_fx1, d_fx2))
print(d1, d2)
</code></pre>

<p>In this code, <code>f1</code> and <code>f2</code> are computed in different ways, but give the same array. However, when trying to compute the gradients associated with them, the first line one gives the following error, whereas the second line works flawlessly. I report below the stack trace of the error</p>

<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-1-9c59a2cf2d9b&gt; in &lt;module&gt;()
     15 
     16 with tf.Session() as sess:
---&gt; 17     d1, d2 = sess.run((d_fx1, d_fx2))
     18 print(d1, d2)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    927     try:
    928       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 929                          run_metadata_ptr)
    930       if run_metadata:
    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1135     # Create a fetch handler to take care of the structure of fetches.
   1136     fetch_handler = _FetchHandler(
-&gt; 1137         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
   1138 
   1139     # Run request and get response.

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in __init__(self, graph, fetches, feeds, feed_handles)
    469     """"""
    470     with graph.as_default():
--&gt; 471       self._fetch_mapper = _FetchMapper.for_fetch(fetches)
    472     self._fetches = []
    473     self._targets = []

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in for_fetch(fetch)
    259     elif isinstance(fetch, (list, tuple)):
    260       # NOTE(touts): This is also the code path for namedtuples.
--&gt; 261       return _ListFetchMapper(fetch)
    262     elif isinstance(fetch, collections.Mapping):
    263       return _DictFetchMapper(fetch)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in __init__(self, fetches)
    368     """"""
    369     self._fetch_type = type(fetches)
--&gt; 370     self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
    371     self._unique_fetches, self._value_indices = _uniquify_fetches(self._mappers)
    372 

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in &lt;listcomp&gt;(.0)
    368     """"""
    369     self._fetch_type = type(fetches)
--&gt; 370     self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
    371     self._unique_fetches, self._value_indices = _uniquify_fetches(self._mappers)
    372 

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in for_fetch(fetch)
    256     if fetch is None:
    257       raise TypeError('Fetch argument %r has invalid type %r' % (fetch,
--&gt; 258                                                                  type(fetch)))
    259     elif isinstance(fetch, (list, tuple)):
    260       # NOTE(touts): This is also the code path for namedtuples.

TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;
</code></pre>

<p>Please note that I also tried computing only one gradient at a time, i.e with <code>persistent=False</code>, and got the same results.</p>

<h2>Actual need</h2>

<p>Below, I will include also the minimal working example to reproduce the same error I got, but trying to resolve the problem I am actually working on.</p>

<p>In this code, I'm using a <code>RNN</code> to compute an output w.r.t some inputs, and I need to compute the <code>jacobian</code> of this output w.r.t the inputs. </p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tensorflow.keras.layers import RNN, GRUCell

# Define size of variable. TODO: adapt to data
inp_dim = 2
num_units = 50
batch_size = 100
timesteps = 10

# Reset the graph, so as to avoid errors
tf.reset_default_graph()

# Building the model
inputs = tf.ones(shape=(timesteps, batch_size, inp_dim))

# Follow gradient computations
with tf.GradientTape() as g:
    g.watch(inputs)
    cells = [GRUCell(num_units), GRUCell(num_units)]
    rnn = RNN(cells, time_major=True, return_sequences=True)
    f = rnn(inputs)
d_fx = g.batch_jacobian(f, inputs)

# Run graph
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    grads = sess.run(d_fx)
grads.shape
</code></pre>

<p>Regarding the stack trace, I get the same error but with less lines (there are one <code>for_fetch</code>, <code>&lt;listcomp&gt;</code> and <code>__init</code> less in this stack trace). For completeness, I still include it below</p>

<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-5-bb2ce4eebe87&gt; in &lt;module&gt;()
     25 with tf.Session() as sess:
     26     sess.run(tf.global_variables_initializer())
---&gt; 27     grads = sess.run(d_fx)
     28 grads.shape

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    927     try:
    928       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 929                          run_metadata_ptr)
    930       if run_metadata:
    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1135     # Create a fetch handler to take care of the structure of fetches.
   1136     fetch_handler = _FetchHandler(
-&gt; 1137         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
   1138 
   1139     # Run request and get response.

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in __init__(self, graph, fetches, feeds, feed_handles)
    469     """"""
    470     with graph.as_default():
--&gt; 471       self._fetch_mapper = _FetchMapper.for_fetch(fetches)
    472     self._fetches = []
    473     self._targets = []

C:\HOMEWARE\Miniconda3-Windows-x86_64\envs\rdwsenv\lib\site-packages\tensorflow\python\client\session.py in for_fetch(fetch)
    256     if fetch is None:
    257       raise TypeError('Fetch argument %r has invalid type %r' % (fetch,
--&gt; 258                                                                  type(fetch)))
    259     elif isinstance(fetch, (list, tuple)):
    260       # NOTE(touts): This is also the code path for namedtuples.

TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;
</code></pre>

<p>I feel like there is a bug with some Tensorflow function that gets me the error, however I am not sure. At the end, what interest me is getting a <code>tensor</code> containing the <strong>jacobian</strong> of the output of my network w.r.t to the inputs. How can I achieve that using other tools, or correcting my code ?</p>

<p><strong>EDIT</strong>: Ok, so I took into account the comments by danyfang, and tried to look into the issue raised on Github he quoted about <code>tf.gradients</code> returning <code>None</code> instead of <code>0</code> due to some implementation design in low-level Tensorflow.</p>

<p>Therefore, I tried to create a simple case where I am sure that gradient are different from <code>0</code>, by computing <code>tf.matmul(tf.transpose(x), x)</code>. I am posting below a MWE.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

tf.reset_default_graph()
x = tf.constant([[1., 2., 3.]])
with tf.GradientTape(persistent=True) as gg:
    gg.watch(x)
    y = tf.matmul(x, tf.transpose(x))
    f1 = tf.map_fn(lambda a: a, y)

# Computes gradients
d_fx1 = gg.gradient(f1, x)
d_yx = gg.gradient(y, x)
del gg #delete persistent GradientTape

with tf.Session() as sess:
    #d1 = sess.run(d_fx1) # Same error None type
    d2 = sess.run(d_yx) #Works flawlessly. returns array([[2., 4., 6.]], dtype=float32)
d2
</code></pre>

<p>This shows (at least in my opinion) that the error arises not because of the behavior reported by this <a href=""https://github.com/tensorflow/tensorflow/issues/3972"" rel=""nofollow noreferrer"">issue</a>, but another thing due to lower level implementation.</p>
",1,Documentation Replication on Other Examples
282,55909188,How can I apply a TensorFlow 2D Convolution (tf.nn.conv2d) to a single (non-batch) 2D image?,"<p>I would like to use the function <code>tf.nn.conv2d()</code> on a <strong>single</strong> image example, but the TensorFlow documentation seems to only mention applying this transformation to a <strong>batch</strong> of images. </p>

<p>The docs mention that the input image must be of shape <code>[batch, in_height, in_width, in_channels]</code> and the kernel must be of shape <code>[filter_height, filter_width, in_channels, out_channels]</code>. However, what is the most straightforward way to achieve 2D convolution with input shape <code>[in_height, in_width, in_channels]</code>?</p>

<p>Here is an example of the current approach, where <code>img</code> has shape (height, width, channels):</p>

<pre><code>img = tf.random_uniform((10,10,3))  # a single image
img = tf.nn.conv2d([img], kernel)[0] # creating a batch of 1, then indexing the single example
</code></pre>

<p>I am reshaping the input as follows:</p>

<p><code>[in_height, in_width, in_channels]-&gt;[1, in_height, in_width, in_channels]-&gt;[in_height, in_width, in_channels]</code> </p>

<p>This feels like an unnecessary and costly operation when I am only interested in transforming one example.</p>

<p>Is there a simple/standard way to do this that doesn't involve reshaping?</p>
",1,Documentation Replication on Other Examples
283,55916743,How to get gradients with respect to input and change input (rather than trainable vars) to minimize loss in TF 2?,"<p>I want to use a trained model to change the input so it minimizes the loss (rather than changing the trainable variables) a la Deep Dreaming in Tensorflow 2.0 but I am not having success.</p>

<p>Say I have a basic NN as the one in the docs</p>

<pre><code>class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.conv1 = Conv2D(32, 3, activation='relu')
    self.flatten = Flatten()
    self.d1 = Dense(128, activation='relu')
    self.d2 = Dense(10, activation='softmax')

  def call(self, x):
    x = self.conv1(x)
    x = self.flatten(x)
    x = self.d1(x)
    return self.d2(x)

model = MyModel()

</code></pre>

<p>Which I train using a simple tf.GradientTape function</p>

<pre><code>@tf.function
def train_step(image, label):
  with tf.GradientTape() as tape:
    predictions = model(image)
    loss = loss_object(label, predictions)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))
</code></pre>

<p>What's the idiomatic way to create a function that will instead calculate and apply the gradients to the input - images.</p>

<p>I assumed it will be as simple as</p>

<pre><code>def train_step(image, label):
  with tf.GradientTape() as tape:
    predictions = model(image)
    loss = loss_object(label, predictions)
  gradients = tape.gradient(loss, image)
  optimizer.apply_gradients(zip(gradients, image))
</code></pre>

<p>However, that doesn't work.</p>
",1,Documentation Replication on Other Examples
284,55936016,TensorFlow 2.0 clip_by_value with dynamic bounds,"<p>It is not clear from the TensorFlow documentation whether I can have dynamic range constraints imposed on a <code>tf.Variable</code> via <code>tf.clip_by_value</code>. From my testing it doesn't seem to work, but I would like to be sure, and if it isn't then I also would like to know how to achieve this (there are certain parts of my parameter space that cause NaNs in my loss function, and these constraints can only be described in terms of combinations of parameters).</p>

<p>Here is my test scenario:</p>

<pre><code>import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd
import numpy as np

N = 2
Ntrials = 100
x = [tf.Variable(np.zeros(Ntrials,dtype='float32'), name='x{0}'.format(i)) for i in range(N)]
eta = [tf.Variable(np.zeros(Ntrials,dtype='float32'),
  constraint=lambda z: tf.clip_by_value(z, -x[i] + 0.0001, np.infty), name='eta{0}'.format(i))
   for i in range(N)]
# i.e. x[i] + eta[i] should always be positive

cov = [[1.0, 0.0],[0.0,1.0]]
mvn0 = tfd.MultivariateNormalFullCovariance([1,1],cov)

# Get samples
samples0 = mvn0.sample(Ntrials) # Ntrials)

print(""samples.shape:"", samples0.shape)

# Get pdf values for samples
etax = None
def get_loss():
   global etax
   etax = [xi + etai for xi,etai in zip(x,eta)]
   # Need to stack eta variables for broadcasting in MultivariateNormalFullCovariance
   all_etax = tf.stack(etax, axis=1, name='all_eta')
   #print(""all_eta.shape:"", all_eta.shape)
   mvnfree = tfd.MultivariateNormalFullCovariance(all_etax,cov)
   p = mvnfree.log_prob(samples0)
   #print(""p:"",p)
   return -2*tf.math.reduce_sum(p,axis=0)

# Minimise
tol = 0.01 * N
delta_loss = 1e9
prev_loss = 1e9
i = 0
print(""tol:"", tol)
opt = tf.optimizers.SGD(0.1)
while delta_loss &gt; tol:
    opt.minimize(get_loss,var_list=eta+x)
    last_loss = get_loss()  
    delta_loss = np.abs(prev_loss -last_loss)
    print(""i:"", i, "" delta_loss:"", delta_loss)
    tf.print(""  x:"", x)
    tf.print(""  eta:"", eta)
    tf.print(""  etax:"", etax)
    i+=1
    prev_loss = last_loss

print(""Finished!"")
</code></pre>

<p>Output:</p>

<pre><code>samples.shape: (100, 2)
tol: 0.02
i: 0  delta_loss: 999999400.0
  x: [[0.186258137 0.269369602 0.520818532 ... 0.354108274 0.137650698 0.25976041], [-0.149198815 0.34362933 0.128372893 ... 0.391129225 0.239100441 0.264151126]]
  eta: [[0.186258137 0.269369602 0.520818532 ... 0.354108274 0.137650698 0.25976041], [0.0001 0.34362933 0.128372893 ... 0.391129225 0.239100441 0.264151126]]
  etax: [[0.372516274 0.538739204 1.04163706 ... 0.708216548 0.275301397 0.519520819], [-0.149098814 0.687258661 0.256745785 ... 0.782258451 0.478200883 0.528302252]]
i: 1  delta_loss: 111.583984
  x: [[0.298013031 0.430991352 0.83330965 ... 0.566573262 0.220241114 0.415616632], [-0.268577874 0.549806893 0.205396622 ... 0.625806808 0.3825607 0.422641814]]
  eta: [[0.298013031 0.430991352 0.83330965 ... 0.566573262 0.220241114 0.415616632], [0.149298817 0.549806893 0.205396622 ... 0.625806808 0.3825607 0.422641814]]
  etax: [[0.596026063 0.861982703 1.6666193 ... 1.13314652 0.440482229 0.831233263], [-0.119279057 1.09961379 0.410793245 ... 1.25161362 0.7651214 0.845283628]]
</code></pre>

<p>The constraint on <code>eta</code> should enforce that <code>x + eta</code> is positive, but already we see negative values appearing in the first two loops.</p>

<p>Or is this perhaps an issue of the order of updating of variables? For example in the minimise loop I guess it is important that the <code>x</code> variables get updated first so that the constraint on the <code>eta</code> variables gets calculated correctly? I guess there is no guarantee of that, and I need to tell TensorFlow to do this? </p>

<p>Edit: I attempted to manually clip the variables in the optimisation loop, like so:</p>

<pre><code>while delta_loss &gt; tol:
    opt.minimize(get_loss,var_list=eta+x)
    # Manually clip variables
    clip_op = [eta[i].assign(tf.clip_by_value(eta[i], -x[i] + 0.0001, np.infty)) for i in range(N)]
    ...
</code></pre>

<p>and it seems to kind of work in this case, but in other test cases it seems to make the minimiser go haywire. I guess because it fights with the minimiser about what values the variables should have. So I'm not sure that this is a good solution.</p>

<p>Edit 2: Well for my specific case I realised that I could solve my problem with math, i.e. by a change of variables I can make the problem not require any explicit constraints. Which is probably the best thing to do if it is possible. But it won't always be, so I am still curious how to do it with constraints.</p>
",1,Documentation Replication on Other Examples
285,55964427,tf.keras HDF5 Model and Keras HDF5 Model,"<p>I want to convert a Keras model to Tensorflow Lite model. When I examined the documentation, it is stated that we can use tf.keras HDF5 models as input. Does it mean I can use my saved HDF5 Keras model as input to it or tf.keras HDF5 model and Keras HDF5 models are different things?</p>

<p>Documentation: <a href=""https://www.tensorflow.org/lite/convert"" rel=""nofollow noreferrer"">https://www.tensorflow.org/lite/convert</a></p>

<p>Edit: I could convert my Keras model to Tensorflow Lite model with using this API, but I didn't test it yet. My code:</p>

<pre><code>converter = tf.lite.TFLiteConverter.from_keras_model_file(path + 'plant- 
recognition-model.h5')
tflite_model = converter.convert()

with open('plant-recognition-model.tflite', 'wb') as f:
   f.write(tflite_model)
</code></pre>
",1,Documentation Replication on Other Examples
286,55986982,What is the way to use Tensor flow 2.0 object in open cv2 python and why is it so circuitous?,"<p>I load an image using tensor flow api (2.0) like so : </p>

<pre><code>def load(image_file):
  image = tf.io.read_file(image_file)
  image = tf.image.decode_jpeg(image)
</code></pre>

<p>Now that I have this object, I want to show this image, I can simply use matplotlib.pyplot, and this works. </p>

<pre><code>plt.figure()
plt.imshow(re/255.0)
plt.show()
</code></pre>

<p>However attempting this with OpenCV2 is problematic from the start, most of the examples are from 1.0 with .eval() session based suggestion for numpy conversion. One way would be to first convert tensor flow object to numpy, here is the function to do that from API documentation :</p>

<pre><code>TensorFlow
API r2.0
TensorFlow Core 2.0a
Python
tf.make_ndarray
Create a numpy ndarray from a tensor.
</code></pre>

<p>I dont understand why this does not works and I get a number of errors while all I want is to do something simple and then use some open cv2 functions like remap, resize etc.:</p>

<blockquote>
  <p>File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py"",
  line 426, in <strong>call</strong>
      self._initialize(args, kwds, add_initializers_to=initializer_map)   File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py"",
  line 370, in _initialize
      *args, **kwds))   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py"",
  line 1313, in _get_concrete_function_internal_garbage_collected
      graph_function, _, _ = self._maybe_define_function(args, kwargs)   File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py"",
  line 1580, in _maybe_define_function
      graph_function = self._create_graph_function(args, kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py"",
  line 1512, in _create_graph_function
      capture_by_value=self._capture_by_value),   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\framework\func_graph.py"",
  line 694, in func_graph_from_py_func
      func_outputs = python_func(*func_args, **func_kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py"",
  line 317, in wrapped_fn
      return weak_wrapped_fn().<strong>wrapped</strong>(*args, **kwds)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\framework\func_graph.py"",
  line 686, in wrapper
      ), args, kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\autograph\impl\api.py"",
  line 392, in converted_call
      result = converted_f(*effective_args, **kwargs)   File ""C:\Users\syeda\AppData\Local\Temp\tmpnahp3og4.py"", line 32, in
  tf__random_deform
      im2 = ag__.converted_call('make_ndarray', tf, ag__.ConversionOptions(recursive=True, verbose=0,
  strip_decorators=(tf.function, defun_9, ag__.convert,
  ag__.do_not_convert, ag__.converted_call), force_conversion=False,
  optional_features=(), internal_convert_user_code=True), (real_image,),
  {})   File
  ""C:\Python\Python37\lib\site-packages\tensorflow\python\autograph\impl\api.py"",
  line 267, in converted_call
      return _call_unconverted(f, args, kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\autograph\impl\api.py"",
  line 188, in _call_unconverted
      return f(*args, **kwargs)   File ""C:\Python\Python37\lib\site-packages\tensorflow\python\framework\tensor_util.py"",
  line 596, in MakeNdarray
      shape = [d.size for d in tensor.tensor_shape.dim] AttributeError: 'Tensor' object has no attribute 'tensor_shape'</p>
</blockquote>

<p><strong>Update 5/5/2018 :</strong> After searching more I found out that this has something to do with Tensorflow graph execution. 
I have a function </p>

<pre><code>def load_image_train(image_file):
  input_image, real_image = load(image_file)
 print(type(real_image))
  print(real_image.shape)
  some_image = Open CV operations like filtering, jitter etc performed on real_image
return some_image
</code></pre>

<p>This works nicely when called eagerly with .numpy() attribute, however when called like following code and when you try to inspect what real_image is and its type returns</p>

<blockquote>
  <p>class 'tensorflow.python.framework.ops.Tensor'   (None, None, None)</p>
</blockquote>

<p>Please advice.</p>

<pre><code># Input pipeline
train_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')
train_dataset = train_dataset.shuffle(BUFFER_SIZE)
train_dataset = train_dataset.map(load_image_train,
                               num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_dataset = train_dataset.batch(1)
</code></pre>

<p><strong>Update 5/5/2018 :</strong> I decided to do a preprocessing of the data so I don't have to worry about the using any opencv functionality during the load time of the data. However during training time I still want to do some openCV operations. Now as per the suggestion of @giser_yugang I tried using py_function, I wrap opencv operations in py_function and call that function in a wrapper tf.function. This wrapper tf.function I call in train step. However the output I get from this wrapper function is like so : </p>

<pre><code>class 'tensorflow.python.framework.ops.Tensor'
unknown
</code></pre>

<p>Then if I try to consume this tensor in the next train step operation I get a </p>

<pre><code>incompatible with the layer: its rank is undefined, but the layer requires a defined rank.
</code></pre>

<p>If I don't use this py_function wrapper in my train step and directly try the numpy operations using opencv I get another error </p>

<pre><code>AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>

<p>I guess both ways you cant win !</p>
",1,Documentation Ambiguity
287,56047272,Explicit vs implicit type definition in TensorFlow,"<p>I'm just beginning to learn TensorFlow. Quoting from the <a href=""https://www.tensorflow.org/guide/low_level_intro#graph"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p>Let's build a simple computational graph. The most basic operation is a constant. The Python function that builds the operation takes a tensor value as input. The resulting operation takes no inputs. When run, it outputs the value that was passed to the constructor. We can create two floating point constants a and b as follows:</p>
</blockquote>

<pre><code>a = tf.constant(3.0, dtype=tf.float32)
b = tf.constant(4.0) # also tf.float32 implicitly
total = a + b
print(a)
print(b)
print(total)
</code></pre>

<p>The second constant is implicitly typed as a float32. Is that based on the explicit typing of the first constant? And does that imply that the first <code>dtype</code> is required? <a href=""https://www.tensorflow.org/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">tf.constant documentation</a> would imply that it does not:</p>

<blockquote>
  <p>If the argument dtype is not specified, then the type is inferred from the type of <code>value</code>.</p>
</blockquote>

<p>But then it would be unnecessary to explicitly type the 3.0 constant above.</p>

<p>I'm just looking for some clarification on this, since, like I said, I'm just starting out.</p>
",1,Documentation Replication on Other Examples
288,56212366,TensorFlow tf.data processing dev set after each epoch,"<pre class=""lang-py prettyprint-override""><code>batch_size = 2
x_dim = 2
m = 5
m_dev = 4
epochs = 2

# Toy data
X_train = np.random.randn(m, x_dim)
Y_train = np.random.randint(0, 5, size=m).reshape(-1, 1)
X_dev = np.random.randn(m_dev, x_dim)
Y_dev = np.random.randint(0, 5, size=m_dev).reshape(-1, 1)

X = tf.placeholder(X_train.dtype, shape=[None, x_dim], name='X')
Y = tf.placeholder(Y_train.dtype, shape=[None, 1], name='Y')

# Create two separate datasets
train_dataset = tf.data.Dataset.from_tensor_slices((X, Y)).batch(batch_size)
dev_dataset = tf.data.Dataset.from_tensor_slices((X, Y)).batch(X_dev.shape[0])

# Create a generic Iterator
iterator = tf.data.Iterator.from_structure(train_dataset.output_types,
                                           train_dataset.output_shapes)

# Create two init ops
train_init_op = iterator.make_initializer(train_dataset)
dev_init_op = iterator.make_initializer(dev_dataset)

next_data = iterator.get_next()

with tf.Session() as sess:
    for epoch in range(epochs):
        # Training data
        sess.run(train_init_op, feed_dict={X: X_train, Y: Y_train})
        while True:
            try:
                X_batch, Y_batch = sess.run(next_data)
                # process training data
            except tf.errors.OutOfRangeError:
                break

        # Epoch done: process the dev data
        sess.run(dev_init_op, feed_dict={X: X_dev, Y: Y_dev})
        X_dev_all, Y_dev_all = sess.run(next_data)
</code></pre>

<p>I am using <code>tf.data</code> with reinitializable iterator to handle training and dev set data. For each epoch, I initialize the training data set. <a href=""https://www.tensorflow.org/guide/datasets#creating_an_iterator"" rel=""nofollow noreferrer"">The official documentation</a> has similar structure. I think this is not efficient especially if the training set is large. </p>

<p>Some of the resources I found online has <code>sess.run(train_init_op, feed_dict={X: X_train, Y: Y_train})</code> before the for loop to avoid this issue. But then we can't process the dev set after each epoch; we can only process it after we are done iterating over <code>epochs</code> epochs.</p>

<p>Is there a way to efficiently process the dev set after each epoch?</p>
",1,Documentation Replication on Other Examples
289,56229730,Trouble with zero-padding inputs for Steered Convolution Layer,"<p>I'm using Tensorflow's new graphics library to apply a steered convolution to a series of meshes.  In many cases, you will have a series of meshes that are not the same size and you must zero-pad the smaller ones.  According to the documentation, the ""sizes"" argument of the graph_conv.feature_steered_convolution_layer function takes in an int tensor consisting of the number of non-padded elements of each mesh.  For some reason, when this argument is set something other than ""None"", I get a warning telling me that the sparse array used in the ""neighbors"" argument is being converted to a dense matrix.  This causes my program to run absurdly slowly.  </p>

<p>The issue seems to be tied to the way that it calculates gradients.  If the optimizer is commented out, the error does not come up.  </p>

<p>I read about a similar problem (link below) where the solution to the problem was to use tf.dynamic_partition rather than tf.gather.  However, the tf.gather functions, in this case are located within the graph_convolution library.  I attempted to make some edits in my copy of the library, but to no avail.</p>

<p><a href=""https://stackoverflow.com/questions/45882401/how-to-deal-with-userwarning-converting-sparse-indexedslices-to-a-dense-tensor/45917500#45917500"">How to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape</a></p>

<pre class=""lang-py prettyprint-override""><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl.testing import parameterized
import numpy as np
import tensorflow as tf

from tensorflow_graphics.nn.layer import graph_convolution as graph_conv

#Number of meshes
N = 2
#Number of spatial dimensions
d = 2

#################################
#Data consists of the vertices of two meshes.  The first mesh has 5 vertices and the second has 4.
    #Shape of data is (numberOfMeshes,maxNumberofVertices,numberofSpatialDimensions)

#An array containing the actual size of each non-padded mesh
sz = np.array([5,4],dtype=np.int64)
#The maximum number of vertices in a mesh
datav = 5

#Input placeholder for input data (vertices)
V0 = tf.placeholder(dtype=tf.float64,name=""V0"",shape=(N,datav,d)) 
#Input Placeholder for labels for classification (For now, I'm just using throw-away data as my labels)
L = tf.placeholder(shape=(N,5,1),dtype=tf.float64)
SZ = tf.placeholder(shape=(N),dtype=tf.int64)
#Input placeholder for the sparse array representing the adjacency matrix shape:(numberOfMeshes,datav,datav)
    #The warning is not raised if ""SZ"" is changed to ""None
adj_sp = tf.sparse_placeholder(shape=(SZ.shape[0],datav,datav),dtype=tf.float64,name='SPP')



#The steered graph convolution that is included in Tensorflow's new graphics package
output = graph_conv.feature_steered_convolution_layer(data=V0,neighbors=adj_sp,sizes=SZ,translation_invariant=False,num_weight_matrices=1,num_output_channels=1)

loss = tf.losses.softmax_cross_entropy(L,output, weights=1.0)
optimizer = tf.train.AdamOptimizer(learning_rate=.001).minimize(loss) #Warning not raised if this is commented out
</code></pre>

<p>When the above code is run, I get the following warning:</p>

<pre><code>C:\Python37\lib\site-packages\tensorflow\python\ops\gradients_impl.py:110: 
UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown 
shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
</code></pre>

<p>I am starting to think that this might have more to do with the library itself than with this piece of code.  I have referenced this posed in GitHub in case it requires updates (or additional documentation) to the library.
<a href=""https://github.com/tensorflow/graphics/issues/13"" rel=""nofollow noreferrer"">https://github.com/tensorflow/graphics/issues/13</a></p>
",1,Requesting (Additional) Documentation/Examples
290,56231695,When should tf.losses.add_loss() be used in TensorFlow?,"<p>I cannot find an answer to this question in the TensorFlow documentation. I once read that one should add losses from <code>tf.nn</code> functions but it isn't necessary for functions from <code>tf.losses</code>. Therefore:</p>

<p>When should I use <code>tf.losses.add_loss()</code>?</p>

<p>Example:</p>

<pre><code>loss = tf.reduce_mean(tf.nn.sparse_softmax_corss_entropy_with_logits
                       (labels=ground_truth, logits=predictions))

tf.losses.add_loss(loss) &lt;-- when is this required?
</code></pre>

<p>Thank yoou.</p>
",1,Lack of Alternative Solutions/Documentation
291,56284927,tf.keras equivalent code block written in tf.contrib.slim,"<p>I'm trying to re-implement a research paper code in tf.keras, in init block it was written as:</p>

<pre><code>with slim.arg_scope([slim.conv2d,separable_conv],activation_fn=tf.nn.relu6, normalizer_fn=slim.batch_norm):
    with slim.arg_scope([slim.batch_norm], is_training=is_training, activation_fn=None):
        with tf.variable_scope(name):
            net = slim.conv2d(inputs, num_outputs=depth, kernel_size=3, stride=2, scope=""conv"") #padding same
</code></pre>

<p>I didn't find a equivalent in tf.keras.layer.Conv2D arguments for normalizer_fn=slim.batch_norm. How to achieve this in keras?</p>

<p>I tried:</p>

<pre><code>model.add(Conv2D(""some arguments"") #0
model.add(BatchNormalization())
</code></pre>

<p>Is this a valid equivalent to the above tf.contrib.slim code. With limited documentation of tf.contrib.slim, I'm really confused.</p>
",1,Documentation Replication on Other Examples
292,56286350,tf.keras.metrics.SpecificityAtSensitivity num_thresholds interpretation,"<p>I'm trying to get my head around <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/metrics/SensitivityAtSpecificity"" rel=""nofollow noreferrer"">tf.keras.metrics.SensitivityAtSpecificity</a>. I'm fine with the concept of sensity and specificity in isolation, but I'm unsure how the two are related in this single metric.</p>

<p>More specifically, I'm unsure how to interpret the <code>num_thresholds</code> argument. The example in documentation has <code>num_thresholds=1</code>. Setting <code>num_thresholds</code> greater than 1 with the same input data seems to always return a metric value of 1.0.</p>

<pre class=""lang-py prettyprint-override""><code>def print_metric_value(num_thresholds):
    # other values based on docs example
    m = tf.keras.metrics.SensitivityAtSpecificity(
        0.4, num_thresholds=num_thresholds)
    m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])
    print('Result with num_thresholds = %d: %.1f' %
          (num_thresholds, m.result().numpy()))

print_metric_value(1)    # 0.5 - same as docs
print_metric_value(2)    # 1.0
print_metric_value(200)  # 1.0
</code></pre>
",1,Documentation Replication on Other Examples
293,56289685,TensorflowJS predict asynchronously,"<p>I have been trying to figure out how to perform predictions using tensorflowJS in an asynchronous fashion. All my attempts resulted in the predict function blocking my code.</p>

<p>Looking at the <a href=""https://js.tensorflow.org/api/latest/#model"" rel=""nofollow noreferrer"">docs</a>, I see that most of the functions are defined as async functions and return a promise like for example <code>tf.loadLayersModel</code>, which also works for me asynchronously without any blocking.</p>

<p>However, <a href=""https://js.tensorflow.org/api/latest/#tf.LayersModel.predict"" rel=""nofollow noreferrer"">predict</a> doesn't return a promise but directly a <code>tf.Tensor</code>. I tried wrapping the predictions in a customly defined async function like:</p>

<pre class=""lang-javascript prettyprint-override""><code>compute = async(data) =&gt; {
  var tensor = tf.tensor(data, [1, 100])
  var prediction = this.model.predict(tensor)
  return prediction.data()
}
</code></pre>

<p>But still predict is blocking the execution of my code.</p>

<p>What is the right approach to use TensorflowJS for asynchronous inference?</p>
",1,Documentation Replicability
294,56344827,"in TF2, how do you save models/weights when not using the tf.keras API?","<p>In the documentation it seems they focus on how to save and restore tf.keras.models, but i was wondering how do you save and restore models trained customly through some basic iteration loop?</p>

<p>Now that there isnt a graph or a session, how do we save structure defined in a tf function that is customly built without using layer abstractions?</p>
",1,Lack of Alternative Solutions/Documentation
295,56386901,Example for tf. group_by_reducer?,"<p>Can someone show me an example of tf.data.experimental.group_by_reducer? I find the documentation tricky and couldn't understand fully.</p>

<p>How can I use it for calculating average?</p>
",1,Documentation Replicability
296,56436701,tf.data.Dataset.window example from the documentation fails,"<p>I'm trying to use an example from the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"" rel=""nofollow noreferrer"">TF documentation</a> for <code>tf.data.Dataset.window</code> and the example from the documentation is failing.</p>

<p>Code derived from the documentation:</p>

<pre><code>import tensorflow as tf

ds = tf.data.Dataset.range(7).window(2)
next_element = ds.make_one_shot_iterator().get_next()

with tf.Session() as sess:
    print(sess.run(next_element))
</code></pre>

<p>Produces this error (trace removed):</p>

<pre><code>TypeError: Can not convert a _VariantDataset into a Tensor or Operation.
During handling of the above exception, another exception occurred:
TypeError: Fetch argument &lt;_VariantDataset shapes: (), types: tf.int64&gt; has invalid type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;, must be a string or Tensor. (Can not convert a _VariantDataset into a Tensor or Operation.)
</code></pre>

<p>So <code>iterator.get_next()</code> is returning a <code>VariantDataset</code> rather than the usual tensor.</p>

<p><strong>TF Version: 1.13.1</strong></p>
",1,Documentation Replication on Other Examples
297,56491633,What is the difference between tf.scatter_add and tf.scatter_nd when indices is a matrix?,"<p>Both <a href=""https://www.tensorflow.org/api_docs/python/tf/scatter_add"" rel=""nofollow noreferrer"">tf.scatter_add</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_nd</a> allow <code>indices</code> to be a matrix. It is clear from the documentation of tf.scatter_nd that the last dimension of <code>indices</code> contains values that are used to index a tensor of shape <code>shape</code>. The other dimensions of <code>indices</code> define the number of elements/slices to be scattered. Suppose <code>updates</code> has a rank <code>N</code>. First <code>k</code> dimensions of <code>indices</code> (except the last dimension) should match with first <code>k</code> dimensions of <code>updates</code>.  The last <code>(N-k)</code> dimensions of <code>updates</code> should match with the last <code>(N-k)</code> dimensions of <code>shape</code>.</p>

<p>This implies that <code>tf.scatter_nd</code> can be used to perform an <code>N</code>-dimensional scatter. However, <code>tf.scatter_add</code> also takes matrices as <code>indices</code>. But, its not clear which dimensions of <code>indices</code> correspond to the number of scatters to be performed and how do these dimensions align with <code>updates</code>. Can someone provide a clear explanation possibly with examples?</p>
",1,Inadequate Examples
298,56553579,How to export Estimator's best model?,"<p>I am training a simple CNN based on a Custom Estimator with TF Records.
I am trying to export the best model in terms of validation loss during the <code>train_and_evaluate</code> phase. </p>

<p>According to the documentation of the <code>tf.estimator.BestExporter</code>, I should feed a function that returns a <code>ServingInputReceiver</code> but after doing so, the <code>train_and_evaluate</code> phase crashes with a <code>NotFoundError: model/m01/eval; No such file or directory</code>.</p>

<p>Seems like if the BestExporter does not permit saving the evaluation results as it would do without the exporter. I tried with different <code>ServingInputReceiver</code> but I keep getting the same error.</p>

<p>As defined <a href=""https://www.tensorflow.org/guide/saved_model#using_savedmodel_with_estimators"" rel=""nofollow noreferrer"">here</a>:</p>

<pre><code>feature_spec = {
        'shape': tf.VarLenFeature(tf.int64),
        'image_raw': tf.FixedLenFeature((), tf.string),
        'label_raw': tf.FixedLenFeature((43), tf.int64)
    }

def serving_input_receiver_fn():
  serialized_tf_example = tf.placeholder(dtype=tf.string,
                                         shape=[120, 120, 3],
                                         name='input_example_tensor')
  receiver_tensors = {'image': serialized_tf_example}
  features = tf.parse_example(serialized_tf_example, feature_spec)
  return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)
</code></pre>

<p>and <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/BestExporter#__init__"" rel=""nofollow noreferrer"">here</a></p>

<pre><code>def serving_input_receiver_fn():
    feature_spec = {
            'image': tf.FixedLenFeature((), tf.string)
        }
    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)
</code></pre>

<p>Here are my exporter and training procedure:</p>

<pre><code>exporter = tf.estimator.BestExporter(
    name=""best_exporter"",
    serving_input_receiver_fn=serving_input_receiver_fn,
    exports_to_keep=5)

train_spec = tf.estimator.TrainSpec(
    input_fn=lambda: imgs_input_fn(train_path, True, epochs, batch_size))

eval_spec = tf.estimator.EvalSpec(
    input_fn=lambda: imgs_input_fn(eval_path, perform_shuffle=False, batch_size=1),
    exporters=exporter)

tf.estimator.train_and_evaluate(ben_classifier, train_spec, eval_spec)
</code></pre>

<p><a href=""https://gist.github.com/hichameyessou/f2710391066f6ed5786693892ac93dbe"" rel=""nofollow noreferrer"">This is a gist</a> with the output.
What's the correct way to define a <code>ServingInputReceiver</code> for the <code>BestExporter</code>?</p>
",1,Documentation Ambiguity
299,56606757,Tensorflow: output of multi-step decay function returns a TypeError,"<p>We are trying to write a multi-step decay function in Tensorflow using tf.train.piecewise_constant() as suggested <a href=""https://stackoverflow.com/a/47174243/5079359"">here</a>. Tensorflow documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/train/piecewise_constant_decay"" rel=""nofollow noreferrer"">here</a> states that:</p>

<p>""When eager execution is enabled, this function returns a function which in turn returns the decayed learning rate Tensor""</p>

<p>However, when we tried running the code, it returned a  TypeError. 
It returns the same error even when lr() is used.</p>

<pre><code>import tensorflow as tf
tf.enable_eager_execution()
import numpy as np

def conv3x3(out_planes, data_format ='channels_last',  stride=1, padding='same', dilation=1, name = None,use_bias = False):
    """"""3x3 convolution with padding""""""
    return  tf.keras.layers.Conv2D(filters = out_planes, kernel_size = 3,data_format= data_format,
                                   strides=(stride, stride), padding='same', use_bias=use_bias,
                                   dilation_rate = (dilation,dilation) , kernel_initializer=tf.initializers.he_normal(),name = name)


def conv1x1(out_planes,data_format ='channels_last', padding = 'same', stride=1):
    """"""1x1 convolution""""""
    return tf.keras.layers.Conv2D(filters = out_planes, kernel_size = 1, strides=(stride, stride),data_format= data_format,
                                  padding=padding, use_bias=False, kernel_initializer=tf.initializers.he_normal())

class BasicBlock(tf.keras.Model):
    expansion = 1

    def __init__(self, planes=1, stride=1, data_format= 'channels_last', downsample=None,  dilation=(1, 1), residual=True, key=None, stage = None):
        super(BasicBlock, self).__init__()
        self.data_format = data_format
        bn_axis = 1 if self.data_format == 'channels_first' else 3
        self.conv1 = conv3x3(out_planes= planes, stride = stride, padding='same' ,
                             data_format = self.data_format, dilation=dilation[0], name = '{}_{}_conv0'.format(key,stage))

        self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis, name = '{}_{}_BN0'.format(key,stage))

        self.conv2 = conv3x3(out_planes =planes, padding='same',
                             data_format = self.data_format, dilation=dilation[0],name = '{}_{}_conv1'.format(key,stage))

        self.bn2 = tf.keras.layers.BatchNormalization(axis=bn_axis,name = '{}_{}_BN1'.format(key,stage))

        self.downsample = downsample
        self.relu = tf.keras.layers.ReLU(name = '{}_{}_Relu'.format(key,stage))
        self.stride = stride
        self.residual = residual

    def get_config(self):
        base_config = {}
        base_config['conv1'] = self.conv1.get_config()
        base_config['bn1'] = self.bn1.get_config()
        base_config['conv2'] = self.conv2.get_config()
        base_config['bn2'] = self.bn2.get_config()
        if self.downsample is not None:
            base_config['downsample'] = self.downsample.get_config()
        return base_config


    def call(self, inputs, training=None):
        residual = inputs
        out = self.conv1(inputs)
        out = self.bn1(out,training = training)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(inputs)
        if self.residual:
            out += residual
        out = self.relu(out)
        return out


class Bottleneck(tf.keras.Model):
    expansion = 4

    def __init__(self, planes, stride=1, data_format = 'channels_last',downsample=None,dilation=(1, 1)):
        super(Bottleneck, self).__init__()

        bn_axis = 1 if data_format == 'channels_first' else 3
        self.conv1 = conv1x1(planes, data_format = data_format)
        self.bn1 = tf.keras.layers.BatchNormalization(axis=bn_axis)
        self.relu = tf.keras.layers.ReLU()
        self.conv2 = conv3x3(planes, stride, padding= 'same', bias=False,  data_format = data_format, dilation=dilation[1])
        self.bn2 = tf.keras.layers.BatchNormalization(axis=bn_axis)
        self.conv3 =conv1x1( planes * 4, data_format = data_format, )
        self.bn3 =  tf.keras.layers.BatchNormalization(axis=bn_axis) # nn.BatchNorm2d(planes * self.expansion)
        self.downsample = downsample
        self.stride = stride

    def get_config(self):
        base_config = {}
        base_config['conv1'] = self.conv1.get_config()
        base_config['bn1'] = self.bn1.get_config()
        base_config['conv2'] = self.conv2.get_config()
        base_config['bn2'] = self.bn2.get_config()
        base_config['conv3'] = self.conv3.get_config()
        base_config['bn3'] = self.bn3.get_config()
        if self.downsample is not None:
            base_config['downsample'] = self.downsample.get_config()
        return base_config



    def call(self, inputs, training=None):
        identity = inputs
        out = self.conv1(inputs)
        out = self.bn1(out,training = training)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out,training = training)
        out = tf.nn.relu(out)
        out = self.conv3(out)
        out = self.bn3(out,training = training)
        if self.downsample is not None:
            identity = self.downsample(inputs)
        out += identity
        out = self.relu(out)
        return out

class pooling (tf.keras.Model):
    def __init__(self, pool_size, stride = None, data_format='channels_last'):
        super(pooling, self).__init__()
        self.pool_size = pool_size
        self.data_format = data_format
        if stride is None:
            self.stride =self.pool_size
        else:
            self.stride = stride


    def call(self, inputs):
        return tf.layers.average_pooling2d(inputs, strides =self.stride, pool_size = self.pool_size, data_format = self.data_format)


class DRN(tf.keras.Model):
    def __init__(self, block, layers, data_format='channels_last', num_classes=7,channels=(16, 32, 64, 128, 256, 512, 512, 512),
                 out_map=False, out_middle=False, pool_size=28, arch='D'):
        super(DRN, self).__init__()
        self.inplanes = channels[0]
        self.out_map = out_map
        self.out_dim = channels[-1]
        self.out_middle = out_middle
        self.arch = arch
        self.poolsize = pool_size
        self.data_format = data_format
        self.bn_axis = 1 if data_format == 'channels_first' else 3

        self.conv0 = tf.keras.layers.Conv2D(filters=channels[0], kernel_size=7, strides=1,  padding='same',
                                               use_bias=False, data_format = self.data_format, kernel_initializer=tf.initializers.he_normal(), name ='L0_conv0' )
        self.bn0 = tf.keras.layers.BatchNormalization(axis=self.bn_axis,name ='L0_BN0')
        self.relu0 = tf.keras.layers.ReLU(name ='L0_Relu0')


        if arch == 'C':
            self.layer1 = self._make_layer(block = BasicBlock, planes = channels[0], blocks = layers[0], stride=1, data_format = self.data_format, key='CL1')
            self.layer2 = self._make_layer(block = BasicBlock, planes =  channels[1], blocks = layers[1], stride=2, data_format = self.data_format, key='CL2')
        elif arch == 'D':
            self.layer1 = self._make_conv_layers(channels = channels[0],convs = layers[0], stride=1, data_format = self.data_format, key='DL1')
            self.layer2 = self._make_conv_layers(channels = channels[1],convs = layers[1], stride=2, data_format = self.data_format, key='DL2')


        self.layer3 = self._make_layer(block = block, planes = channels[2], blocks = layers[2], stride=2, data_format = self.data_format, key='L3')
        self.layer4 = self._make_layer(block = block, planes = channels[3], blocks = layers[3], stride=2, data_format = self.data_format, key='L4')
        self.layer5 = self._make_layer(block = block, planes = channels[4], blocks = layers[4], dilation=2, new_level=False, data_format = self.data_format, key='L5')
        self.layer6 = None if layers[5] == 0 else self._make_layer(block, channels[5], layers[5], dilation=4, new_level=False, data_format = self.data_format, key='L6')

        if arch == 'C':
            self.layer7 = None if layers[6] == 0 else self._make_layer(BasicBlock, channels[6], layers[6], dilation=2, new_level=False, residual=False, data_format = self.data_format, key='CL7')
            self.layer8 = None if layers[7] == 0 else self._make_layer(BasicBlock, channels[7], layers[7], dilation=1, new_level=False, residual=False, data_format = self.data_format, key='CL8')
        elif arch == 'D':
            self.layer7 = None if layers[6] == 0 else self._make_conv_layers(channels[6], layers[6], dilation=2, data_format = self.data_format, key='DL7')
            self.layer8 = None if layers[7] == 0 else self._make_conv_layers(channels[7], layers[7], dilation=1, data_format = self.data_format, key='DL8')

        if num_classes &gt; 0:
            self.avgpool = tf.keras.layers.GlobalAveragePooling2D(data_format = self.data_format)
            self.fc = tf.keras.layers.Dense(units=num_classes)


    def _make_layer(self, block, planes, blocks, stride=1,dilation=1, new_level=True, data_format = 'channels_last', residual=True, key=None):
        assert dilation == 1 or dilation % 2 == 0
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = tf.keras.Sequential([conv1x1(out_planes = planes * block.expansion,stride = stride, data_format = data_format),
                      tf.keras.layers.BatchNormalization(axis=self.bn_axis)], name = 'downsample')

#
        layers = []
        layers.append(block(planes= planes, stride =  stride, downsample = downsample, dilation=(1, 1) if dilation == 1 else (
                dilation // 2 if new_level else dilation, dilation), data_format=data_format, residual=residual, key = key, stage = '0'))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(planes, residual=residual,dilation=(dilation, dilation), data_format=data_format, key = key, stage = i))
        return tf.keras.Sequential(layers, name = key)


    def _make_conv_layers(self, channels, convs, stride=1, dilation=1 ,data_format = 'channels_last', key = None):
        modules = []
        for i in range(convs):
            modules.extend([
                conv3x3(out_planes= channels, stride=stride if i == 0 else 1,
                          padding= 'same' , use_bias=False, dilation=dilation,  data_format = data_format,name ='{}_{}_Conv'.format(key,i)),
                tf.keras.layers.BatchNormalization(axis=self.bn_axis,name ='{}_{}_BN'.format(key,i)),
                tf.keras.layers.ReLU(name ='{}_{}_Relu'.format(key,i))])
            self.inplanes = channels
        return tf.keras.Sequential(modules,name=key)


    def call(self, x, training=None):
        x = self.conv0(x)
        x = self.bn0(x,training = training)
        x = self.relu0(x)
        x = self.layer1(x,training = training)
        x = self.layer2(x,training = training)
        x = self.layer3(x,training = training)
        x = self.layer4(x,training = training)
        x = self.layer5(x,training = training)

        if self.layer6 is not None:
            x = self.layer6(x,training = training)

        if self.layer7 is not None:
            x = self.layer7(x)
        if self.layer8 is not None:
            x = self.layer8(x)
        if self.out_map:
            x = self.fc(x)
        else:
            x = self.avgpool(x)
            x = self.fc(x)
        return x

def loss(logits, labels):
  return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))

def make_scheduler(policy, init_lr, n_step_epoch, global_step):
    total_steps= n_step_epoch * 10 #10 epochs
    milestones = policy.split('_')
    milestones.pop(0)
    milestones = list(map(lambda x: int(x), milestones))
    boundaries = np.multiply(milestones,n_step_epoch)
    values = [init_lr] + [init_lr/(0.1**-i) for i in  range(1,len(milestones)+1)]
    learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)
    return learning_rate


def train(model, optimizer, step_counter ):
  """"""Trains model on `dataset` using `optimizer`.""""""

  for (batch, i) in enumerate(range(10)):
      print('Training Loop {}'.format(i))
      images = tf.random.uniform((4, 224, 224,3))
      labels = tf.constant(np.random.randint(4, size=4))
      with tf.contrib.summary.record_summaries_every_n_global_steps(10, global_step=step_counter):
          with tf.GradientTape() as tape:
            logits = model(images, training=True)
            loss_value = loss(logits, labels)
          grads = tape.gradient(loss_value, model.variables)
          optimizer.apply_gradients(zip(grads, model.variables), global_step=step_counter)


def test(model):
  """"""Perform an evaluation of `model` on the examples from `dataset`.""""""
  for  i in (range(10)):
    images = tf.random.uniform((4, 225, 225,3))
    logits = model(images, training=False)
    print(logits)

def main():
    model =  DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], arch='C',num_classes = 4)
    device = '/gpu:0'
    step_counter = tf.train.get_or_create_global_step()
    lr = make_scheduler(policy='multistep_2_5',init_lr=0.1,n_step_epoch = 10,global_step= step_counter)
    optimizer = tf.train.MomentumOptimizer(lr,momentum=0.5)

    with tf.device(device):
        for _ in range(10):
           train(model, optimizer,step_counter)
           print(optimizer._lr_t)
           test(model)

if __name__ == '__main__':
  main()

</code></pre>

<blockquote>
  <p>File """", line 1, in 
      runfile('/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py', wdir='/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug')</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 709, in runfile
      execfile(filename, namespace)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/spyder_kernels/customize/spydercustomize.py"", line 108, in execfile
      exec(compile(f.read(), filename, 'exec'), namespace)</p>
  
  <p>File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 311, in 
      main()</p>
  
  <p>File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 305, in main
      train(model, optimizer,step_counter)</p>
  
  <p>File ""/home/srijith/work/Tensorflow/SkinCaner_tensorflow/debug/stackoverflow.py"", line 284, in train
      optimizer.apply_gradients(zip(grads, model.variables), global_step=step_counter)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py"", line 598, in apply_gradients
      self._prepare()</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/momentum.py"", line 87, in _prepare
      learning_rate = learning_rate()</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py"", line 171, in decayed_lr
      boundaries = ops.convert_n_to_tensor(boundaries)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1273, in convert_n_to_tensor
      as_ref=False)</p>
  
  <p>File ""/home/srijith/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in internal_convert_n_to_tensor
      raise TypeError(""values must be a list."")</p>
  
  <p>TypeError: values must be a list.</p>
</blockquote>

<p>The code works as expected when we provide a constant learning rate. Is there something that we are missing?</p>
",1,Documentation Ambiguity
300,56621039,Understanding the graph of tf.cond,"<p>I am trying to understand the inner workings of tf.cond by looking at the graph of low-level ops that are used to build it.</p>

<p>This is the code in question</p>

<pre><code>x = tf.constant(1, name='x')
y = tf.constant(2, name='y')
z = tf.constant(3, name='z')

result = tf.cond(tf.less(x, y), lambda: tf.add(x, z), lambda: tf.square(y))
</code></pre>

<p>And the resulting <a href=""https://i.stack.imgur.com/cIJSx.jpg"" rel=""nofollow noreferrer"">graph</a>.</p>

<p>What I am wondering is the following.</p>

<ul>
<li>What is the separate switch op leading to switch_t and switch_f doing there?</li>
<li>Why does Less output connect to pred_id and Switch Ops? I would expect it to output one predicate (Boolean tensor) leading into all Switch-es for all the inputs into tf.cond.</li>
<li>What is pred_id? Is it just an identity that forks the predicate into three branches?</li>
<li><p>I am trying to understand how does tf.cond evaluate only one branch during runtime. </p>

<p>I understand that when we evaluate the result of tf.cond we are evaluating the tensor coming out of the merge op. Merge must take in (I assume) four tensors as input (two from Add branch and two from Square branch) and three of which much be dead. But we only can know the ""deadness"" of the tensors if we eval them back down the graph, no?</p></li>
<li><p>For the Square branch, for example, I understand that switch takes in as input the y tensor and the predicate and outputs two tensors, y and dead, on the appropriate branches of the switch statement. But this branch is kind of guaranteed already to be for the false branch. So what happens to both T and F outputs of the switch branch? They both go into Square Op? And then into the merge?</p></li>
</ul>

<p>Thank you,</p>

<p>S</p>
",1,Documentation Replicability
301,56635027,Feeding array (shape with rank 1) to TensorFlow tf.case,"<p>Following this example from the <code>tf.case</code> documentation:</p>

<pre><code>def f1(): return tf.constant(17)
def f2(): return tf.constant(23)
def f3(): return tf.constant(-1)
r = tf.case({tf.less(x, y): f1, tf.greater(x, z): f2},
            default=f3, exclusive=True)
</code></pre>

<p>I want to do the same, but allow to use a feed_dict as input, illustrated by this snipped:</p>

<pre><code>x = tf.placeholder(tf.float32, shape=[None])
y = tf.placeholder(tf.float32, shape=[None])
z = tf.placeholder(tf.float32, shape=[None])
def f1(): return tf.constant(17)
def f2(): return tf.constant(23)
def f3(): return tf.constant(-1)
r = tf.case({tf.less(x, y): f1, tf.greater(x, z): f2},
            default=f3, exclusive=True)
print(sess.run(r, feed_dict={x: [0, 1, 2, 3], y: [1, 1, 1, 1], z: [2, 2, 2, 2]}))
# result should be [17, -1, -1, 23]
</code></pre>

<p>So, basically I want to feed three <code>int</code>-arrays of equal length and receive an array of <code>int</code>-values containing either 17, 23, or -1. Unfortunately, there code above gives and error:</p>

<blockquote>
  <p>ValueError: Shape must be rank 0 but is rank 1 for 'case/cond/Switch' (op: 'Switch') with input shapes: [?], [?].</p>
</blockquote>

<p>I understand, that <code>tf.case</code> requires boolean scalar tensor input values but is there any way to achieve what I want? I also tried <code>tf.cond</code> without success.</p>
",1,Documentation Replicability
302,56693863,Why does model.losses return regularization losses?,"<p>I have met a snippet of code of tensorflow 2.0, which is used for calculating the loss. The total loss is composed of two parts: 1) regularization loss, 2) prediction loss. My question is why <code>model.losses</code> is regularization loss? <code>model</code> here is an instance of <code>tf.keras.Model</code>. I'm kind of confused by the tensorflow official API documentation. <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#losses"" rel=""noreferrer"">tf.keras.Model</a>, it says</p>
<blockquote>
<p>Losses which are associated with this Layer.</p>
<p>Variable regularization tensors are created when this property is accessed, so it is eager safe: accessing losses under a <code>tf.GradientTape</code> will propagate gradients back to the corresponding variables.</p>
</blockquote>
<p>Why could we get regularization loss via accessing <code>losses</code> property? Also, what is eager safe? If <code>losses</code> property is returning regularization loss, why is it named <code>losses</code> instead of <code>regularization_loss</code>?</p>
<pre class=""lang-py prettyprint-override""><code>with tf.GradientTape() as tape:
  outputs = model(images, training=True)
  regularization_loss = tf.reduce_sum(model.losses)
  pred_loss = ...
  total_loss = pred_loss + regularization_loss
</code></pre>
",1,Documentation Ambiguity
303,56754293,TensorflowServing on a trained native Keras model with a preprocessing function for the input,"<p>My final goal is to use the What-If-Tool on tensorboard. In order to do that, I need to serve my Keras model on TensorflowServing, and the data in a TFRecordFile. So the data has to be transformed into tf.Examples.
The tool is supposed to grab the network to run inference on the data.
however, the network cannot handle tf.Examples as an input. So the served model needs to have a preprocessing function.</p>

<p>According to the tensorflow documentation, one way is to create a tensorflow Estimator, and to use ""serving_input_receiver_fn"" to preprocess the data. 
This would have been perfect except for the case that I can't make an already trained native Keras model into an Estimator. It seems that the only way it to create it from a tf.keras model (and not a native keras model like I have), and to train it directly with the estimator.</p>

<p>Another way would be to use the tf.saved_model.simple_save function, and then use TensorflowServing, but I did not find a way to preprocess the tf.Examples to make a correct input for the network.</p>

<p>Since this is not working, I have no clue on how to resolve this.</p>

<p><strong>Edit:</strong> I tried to transform my native keras into a tf.keras model. My model is really big, so I build this function: </p>

<pre><code>def create_tf_keras_model_from_native_keras(native_model):
    list_layers = []
    for i, layer in enumerate(native_model.layers):
        type_layer = str(layer).split('.')[2]
        second_type_layer = str(layer).split('.')[3].split(' ')[0]
        if type_layer == 'input_layer':
            new_layer = tf.keras.layers.InputLayer(**layer.get_config())
        elif type_layer == 'convolutional':
            new_layer = tf.keras.layers.Conv2D(**layer.get_config())
        elif type_layer == 'normalization':
            new_layer = tf.keras.layers.BatchNormalization(**layer.get_config())
        elif type_layer == 'core':
            if second_type_layer == 'Activation':
                new_layer = tf.keras.layers.Activation(**layer.get_config())
            elif second_type_layer == 'Dense':
                new_layer = tf.keras.layers.Dense(**layer.get_config())
            elif second_type_layer == 'Dropout':
                new_layer = tf.keras.layers.Dropout(**layer.get_config())
            elif second_type_layer == 'Lambda':
                config_lambda = layer.get_config()
                print(config_lambda)
                del config_lambda['function_type']
                del config_lambda['output_shape_type']
                new_layer = tf.keras.layers.Lambda(**config_lambda)
        elif type_layer == 'pooling':
            if second_type_layer == 'MaxPooling2D':
                new_layer = tf.keras.layers.MaxPooling2D(**layer.get_config())
            elif second_type_layer == 'AveragePooling2D':
                new_layer = tf.keras.layers.AveragePooling2D(**layer.get_config())
            elif second_type_layer == 'GlobalMaxPooling2D':
                new_layer = tf.keras.layers.GlobalMaxPooling2D(**layer.get_config())
        if new_layer == 'merge':
            new_layer = tf.keras.layers.Concatenate(**layer.get_config())
        list_layers.append(new_layer)
    model = tf.keras.Sequential(list_layers)
    return model
</code></pre>

<p>However, this is not working because of Lambda layer. In the config layer, the function is now written in the form of: </p>

<pre><code>'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQC8ARQAFwBTACkDTukAAAAA6QEA\nAACpACkC2gZpbaBXNjYWxlcgMAAAByAwAAAPp/L2dwZnMvaGFpZmEtcDYvMDMvbXNpZXZl\nX2RldjMvdXNyL3BhdWxkYS9naXRfcmVwb0hJLUltYWdlQW5hbHl0aWNzL3Jlc291cmNlcy9y\ndW5fMTE3NC9jdXN0b21fcHJldHJhaW5lZF9JbmNlcHRpb25SZXNOZXRWMi5wedoIPGxhbWJkYT6d\nAAAA8wAAAAA=\n', None, None)
</code></pre>

<p>Hence, I gave up this method hoping something else would allow to pre-process the input of my serving model.</p>
",1,Documentation Replication on Other Examples
304,56802840,What exactly tensorflow.gather() does?,"<p>I saw code for triplet loss that contains the function tf.gather(). What this function does?</p>

<p>I have gone through the tensorflow's official website for definition but still unable to get it.</p>

<pre><code>def margin_triplet_loss(y_true, y_pred, margin, batch_size):
    anchor = tf.gather(y_pred, tf.range(0, batch_size, 3))
    positive = tf.gather(y_pred, tf.range(1, batch_size, 3))
    negative = tf.gather(y_pred, tf.range(2, batch_size, 3))

    loss = K.maximum(margin
                 + K.sum(K.square(anchor-positive), axis=1)
                 - K.sum(K.square(anchor-negative), axis=1),
                 0.0)
    return K.mean(loss)
</code></pre>
",1,Lack of Alternative Solutions/Documentation
305,56905939,Effective way to read images from a csv file and return a tf.data.Dataset object,"<p>I have a csv file that contains two columns:</p>

<ol>
<li>the file path of the image which is stored as <code>numpy</code> arrays</li>
<li>the label of the image</li>
</ol>

<p>Each row in the csv corresponds to one item (sample).</p>

<p>I want to create a <code>tf.data</code> pipeline that reads the file path and loads the numpy array and the label associated with it. How would I go about doing so so that I can return a <code>tf.data.Dataset</code> object?</p>

<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data"" rel=""nofollow noreferrer"">documentation</a> on the website is not very informative and I cannot figure out where to start from.</p>
",1,Lack of Alternative Solutions/Documentation
306,56939282,How do you feed a tf.data.Dataset dynamically in eager execution mode where initializable_iterator isn't available?,"<p>What is the new approach (under eager execution) to feeding data through a dataset pipeline in a dynamic fashion, when we need to feed it sample by sample? </p>

<p>I have a <code>tf.data.Dataset</code> which performs some preprocessing steps and reads data from a generator, drawing from a large dataset during training. </p>

<p>Let's say that dataset is represented as:</p>

<pre><code>ds = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])
ds = ds.map(tf.square).shuffle(2).batch(2)
iterator = tf.data.make_one_shot_iterator(ds)
</code></pre>

<p>After training I want to produce various visualizations which require that I feed one sample at a time through the network for inference. I've now got this dataset preprocessing pipeline that I need to feed my raw sample through to be sized and shaped appropriately for the network input.</p>

<p>This seems like a use case for the initializable iterator:</p>

<pre><code>placeholder = tf.placeholder(tf.float32, shape=None)
ds = tf.data.Dataset.from_tensor_slices(placeholder)
ds = ds.map(tf.square).shuffle(2).batch(2)
iterator = tf.data.make_initializable_iterator(ds) 
# now re-initialize for each sample
</code></pre>

<blockquote>
  <p>Keep in mind that the map operation in this example represents a long sequence of preprocessing operations that can't be duplicated for each new data sample being feed in.</p>
</blockquote>

<p><strong>This doesn't work with eager execution</strong>, you can't use the placeholder. The documentation examples all seem to assume a static input such as in the first example here.</p>

<p>The only way I can think of doing this is with a queue and <code>tf.data.Dataset.from_generator(...)</code> which reads from the queue that I push to before predicting on the data. But this feels both hacky, and appears prone to deadlocks that I've yet to solve.</p>

<p>TF 1.14.0</p>
",1,Documentation Replication on Other Examples
307,56969703,How to use `tf.scatter_nd` with multi-dimensional tensors,"<p>I'm trying to create a new tensor (<code>output</code>) with the values of another tensor (<code>updates</code>) placed according to <code>idx</code> tensor. The shape of <code>output</code> should be <code>[batch_size, 1, 4, 4]</code> (like an image of 2x2 pixels and one channel) and <code>update</code> has shape <code>[batch_size, 3]</code>.</p>

<p>I've read Tensorflow documentation (I'm working with gpu version 1.13.1) and found <code>tf.scatter_nd</code> should work for my problem. The issue is that I cannot make it work, I think I'm having problems understanding how I have to arange <code>idx</code>. </p>

<p>Let's consider <code>batch_size = 2</code>, so what I'm doing is:</p>

<pre class=""lang-py prettyprint-override""><code>updates = tf.constant([[1, 2, 3], [4, 5, 6]])  # shape [2, 3]
output_shape = tf.constant([2, 1, 4, 4])
idx = tf.constant([[[1, 0], [1, 1], [1, 0]], [[0, 0], [0, 1], [0, 2]]])  # shape [2, 3, 2]
idx_expanded = tf.expand_dims(idx, 1)  # so I have shape [2, 1, 3, 2]
output = tf.scatter_nd(idx_expanded, updates, output_shape)
</code></pre>

<p>I expect it to work, but it doesn't, it gives me this error:</p>

<p><code>ValueError: The outer 3 dimensions of indices.shape=[2,1,3,2] must match the outer 3 dimensions of updates.shape=[2,3]: Shapes must be equal rank, but are 3 and 2 for 'ScatterNd_7' (op: 'ScatterNd') with input shapes: [2,1,3,2], [2,3], [4]</code></p>

<p>I don't understand why it's expecting <code>updates</code> to have dimension 3. I thought <code>idx</code> has to make sense with <code>output_shape</code> (that's why I used <code>expand_dims</code>) and also with <code>updates</code> (specify the two indices for the three points), but it's obvious I'm missing something here.</p>

<p>Any help would be appreciated.</p>
",1,Documentation Replication on Other Examples
308,56970612,Fitted values and weights in tensorflow (tesorflow DNNRegressor),"<p>I am using tensorflow version 2.0.0-beta1. I have created the input function to feed into tf.estimator.DNNRegressor.</p>

<pre><code>input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,
                                                y=y_train,
                                                batch_size=10,
                                                num_epochs=1000,
                                                shuffle=True)
</code></pre>

<p>Below is the model that I am creating using DNNRegressor. </p>

<pre><code>model = tf.estimator.DNNRegressor(feature_columns=feature_col, hidden_units=[1024, 800, 512, 256])
model.train(input_fn=input_func, steps=10000)
</code></pre>

<p>Now I want to identify </p>

<p><strong>1) Fitted values of my model on training data.</strong></p>

<p><strong>2) Weights associated with each variable in model(i.e. tf.estimator.DNNRegressor)</strong></p>

<p>I have search through the documentation of tensorflow and other sources but didn't get this information. </p>
",1,Lack of Alternative Solutions/Documentation
309,57014236,How to use the Embedding Projector in Tensorflow 2.0,"<p>With the tf.contrib module gone from Tensorflow, and with tf.train.Saver() also gone, I cannot find a way to store a set of embeddings and their corresponding thumbnails, so that the Tensorboard Projector can read them.</p>

<p>The <a href=""https://www.tensorflow.org/tensorboard/r2/get_started"" rel=""noreferrer"">Tensorboard documentation</a> for Tensorflow 2.0 explains how to create plots and summaries, and how to use the summary tool in general, but nothing about the projector tool. Has anyone found how to store datasets for visualization?</p>

<p>If possible, I would appreciate a (minimal) code example.</p>
",1,Documentation Replication on Other Examples
310,57056756,Prepare a tensorflow dataset with *.jpeg in a directory with corresponding labels in a .csv file,"<p>Indeed this question is similar to prior but for me attempting prior answers tossed a errors I cannot scale probably due to deprecated functions  and thus update is requested (pleading on my knees really)-- maybe windows 10 is the problem</p>

<p>In the Google tensorflow documentation they trumpet the ease of tensorflow and they of course make it seem easy by having a dataset prepped and ready 
to go such as <code>mnist = tf.keras.datasets.mnist</code></p>

<p>But for people doing real work with new data they are not going to have data so neatly prepared. Instead they (i.e. me) are going to take many pictures of different similar things (say 64 nuclei of cancer cells from 64 patient cases-- 250 by 250 pixels each with RGB) and they will  store the 64 jpegs in a single directory lets say <code>C:\\Users\\dalton\\Desktop\\breast\\nuclei\\*.jpg</code>
There are no other jpgs in the directory other than those of interest</p>

<p>Then in a csv text file (essentially a spreadsheet with one column saved as csv file or could be txt) they record the label corresponding to each picture -- this text file has 64 entries of a 1 or 0 whereby 1= very bad cancer cell and 0= not so bad. Lets say this txt file is located at:
 <code>C:\\Users\\dalton\\Desktop\\breast\\nuclei\\n_labels.txt</code></p>

<p>They (me) will use 32 of the pictures and corresponding labels for train and 32 for test.</p>

<p>So from this basic data of 64 jpegs and 64 labels (as 64 entries in a single text file)how does one get to the same point as given in the loading of an easy example. Or does one need a single <code>spreadsheet</code> with the jpeg filenames in one column and the labels in another so as to prepare a list or tuple?</p>

<p>In essence how does</p>

<p>Real world work join final common pathway same as
 <code>mnist = tf.keras.datasets.mnist</code></p>

<p>I think an answer to this will help many many people besides me. I have tried innumerable examples in <code>GitHub</code>, here, and tried R versions and total frustration.</p>

<p>Sincere thanks to an answer.
LD</p>

<p>attempted solutions used examples as per:</p>

<p><a href=""https://www.tensorflow.org/datasets/datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/datasets/datasets</a></p>

<p><a href=""https://gist.github.com/eerwitt/518b0c9564e500b4b50f"" rel=""nofollow noreferrer"">https://gist.github.com/eerwitt/518b0c9564e500b4b50f</a></p>
",1,Documentation Replication on Other Examples
311,57081006,Create a Keras Layer Subclass using Conv Layers,"<p>I would like to create a custom <code>tf.keras.layers.Layer</code> resembling the below function:</p>

<pre><code>def conv_block(inputs, filters, kernel_size, strides=(1, 1, 1),
                 padding='valid', activation=True, block_name='conv3d'):

    with tf.name_scope(block_name):
      conv = Conv3D(filters=filters, kernel_size=kernel_size, strides=strides,
                    padding=padding, activation=None,
                    name='{}_conv'.format(block_name))(inputs)
      batch_norm = BatchNormalization(
          name='{}_batch_norm'.format(block_name))(conv)

      if activation:
        relu = ReLU(max_value=6, name='{}_relu'.format(block_name))(batch_norm)
        res_layer = relu
      else:
        res_layer = batch_norm
    return res_layer
</code></pre>

<p>I went through the documentation available <a href=""https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models#the_layer_class"" rel=""nofollow noreferrer"">here</a> and <a href=""https://www.tensorflow.org/guide/keras#custom_layers"" rel=""nofollow noreferrer"">here</a> and subsequently I created the below class:</p>

<pre><code>class ConvBlock(tf.keras.layers.Layer):

    def __init__(self, filters, kernel_size, strides=(1, 1, 1), padding='valid', activation=True, **kwargs):
        super(ConvBlock, self).__init__()
        self.filters = filters
        self.kernel_size = kernel_size
        self.strides = strides
        self.padding = padding
        self.activation = activation

        self.conv_1 = Conv3D(filters=self.filters, 
                             kernel_size=self.kernel_size, 
                             strides=self.strides, 
                             padding=self.padding, 
                             activation=None)

        self.batch_norm_1 = BatchNormalization()
        self.relu_1 = ReLU(max_value=6)

    def call(self, inputs):
        conv = self.conv_1(inputs)
        batch_norm = self.batch_norm_1(conv)

        if self.activation:
            relu = self.relu_1(batch_norm)
            return relu
        else:
            return batch_norm
</code></pre>

<p>I want to use this <code>Layer</code> several times throughout my model. I have several questions around this:</p>

<ol>
<li>The documentation mentions using <code>add_weights()</code> in the <code>build()</code> method. However would it be necessary in this case?</li>
<li>Do I need to include a <code>build()</code>method at all? </li>
<li><p>How do I get the output shape of the layer? The documentation mentions using the below function:</p>

<p>def compute_output_shape(self, input_shape):
    shape = tf.TensorShape(input_shape).as_list()
    shape[-1] = self.output_dim
    return tf.TensorShape(shape)</p></li>
</ol>

<p>How can I use this function to compute the shape of the output layer?</p>
",1,Documentation Replicability
312,57083881,Tensorflow 2.0 Saving trained parameters to be restored in a new file,"<p>I need to save trained variables of a TensorFlow 2.0 model using one of TF's built in functions like tf.train.Checkpoint or any other, and want to call them in a new file. I am not using tf.Keras.Sequantial and don't want to use something like model.save_weights()</p>

<p>I have tried tf.train.Checkpoint to save variables, but not sure how to restore them. I used to work with tf.train.Saver() in TF 1.0 to save variables using sessions and restore them using tf.train.import_meta_graph and tf.train.latest_checkpoint. However, I haven't been able to find equivalent functionalities in TF 2.0 documentation so far. </p>

<h1>try checkpoint saver in tensorflow 2.0 format to save trained parameters W, b_v, b_h</h1>

<p>saver = tf.train.Checkpoint()</p>

<p>saver.listed = [W, b_v, b_h]</p>

<p>saver.mapped = {'W':saver.listed[0],'b_v':saver.listed[1],
 'b_h':saver.listed[2]}</p>

<p>save_path = saver.save('trained_parameters')</p>

<h1>in a new file:</h1>

<p>restorer = tf.train.Checkpoint()</p>

<p>restorer.restore('trained_parameters')</p>

<h1>calling the parameters by their previously mapped names doesn't work, not sure how to go about this</h1>
",1,Documentation Replication on Other Examples
313,57120680,Deep copy of tensor in tensorflow python,"<p>In some of my code, I have created a neural network using tensorflow and have access to a tensor representing that network's output. I want to make a copy of this tensor so that even if I train the neural network more, I can access the original value of the tensor.</p>

<p>Following other answers and tensorflow documentation, I have tried the tf.identity() function, but it does not seem to be doing what I need. Some other links suggested the use of tf.tile(), but this did not help either. I do not wish to use sess.run(), evaluate the tensor, and store it elsewhere.</p>

<p>Here is a toy example that describes what I need to do:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

t1 = tf.placeholder(tf.float32, [None, 1])
t2 = tf.layers.dense(t1, 1, activation=tf.nn.relu)
expected_out = tf.placeholder(tf.float32, [None, 1])

loss = tf.reduce_mean(tf.square(expected_out - t2))
train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)

sess = tf.Session()

sess.run(tf.global_variables_initializer())

print(sess.run(t2, feed_dict={t1: np.array([1]).reshape(-1,1)}))
t3 = tf.identity(t2) # Need to make copy here
print(sess.run(t3, feed_dict={t1: np.array([1]).reshape(-1,1)}))

print(""\nTraining \n"")

for i in range(1000):
    sess.run(train_op, feed_dict={t1: np.array([1]).reshape(-1,1), expected_out: np.array([1]).reshape(-1,1)})

print(sess.run(t2, feed_dict={t1: np.array([1]).reshape(-1,1)}))
print(sess.run(t3, feed_dict={t1: np.array([1]).reshape(-1,1)}))
</code></pre>

<p>The result of the above code is that <code>t2</code> and <code>t3</code> have the same value. </p>

<pre><code>[[1.5078927]]
[[1.5078927]]

Training

[[1.3262703]]
[[1.3262703]]
</code></pre>

<p>What I want is for <code>t3</code> to keep its value from being copied.</p>

<pre><code>[[1.5078927]]
[[1.5078927]]

Training

[[1.3262703]]
[[1.5078927]]
</code></pre>

<p>Thanks in advance for your help.</p>
",1,Documentation Ambiguity
314,57134808,tf.keras.optimizers.Adam with tf.estimator model in Tensorflow 2.0.beta is crashing,"<p>I am using <code>Tensorflow 2.0.beta</code> with <code>Python 3.6.6</code> on <code>Mac OS</code> (nightly: <code>tf-nightly-2.0-preview</code> <code>2.0.0.dev20190721</code> but I never managed to have it working with compat module in <code>Tensorflow 2.0</code>).</p>

<p>I am traying to migrate a <code>tf.estimator</code> model from <code>Tensorflow 1.12</code> (fully working) to <code>Tensorflow 2.0</code>. Here is the code:</p>

<pre><code># estimator model
def baseline_estimator_model(features, labels, mode, params):
    """"""
    Model function for Estimator
    """"""
    print('model based on keras layer but return an estimator model')

    # gettings the bulding blocks
    model = keras_building_blocks(params['dim_input'], params['num_classes'])

    dense_inpout = features['dense_input']

    # Logits layer
    if mode == tf.estimator.ModeKeys.TRAIN:
        logits = model(dense_inpout, training=True)
    else:
        logits = model(dense_inpout, training=False)


    # Compute predictions
    probabilities = tf.nn.softmax(logits)
    classes = tf.argmax(input=probabilities, axis=1, )

    # made prediction
    predictions = {
        'classes': classes,
        'probabilities': probabilities,
    }

    # to be tested
    predictions_output = tf.estimator.export.PredictOutput(predictions)

    # Provide an estimator spec for `ModeKeys.PREDICT`
    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode,
                                          predictions=predictions,
                                          export_outputs={tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: predictions_output})

    # Compute loss for both TRAIN and EVAL modes
    # old -&gt; loss = tf.compat.v1.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)
    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, logits)

    # Generate necessary evaluation metrics
    # old -&gt; accuracy = tf.compat.v1.metrics.accuracy(labels=tf.argmax(input=labels, axis=1), predictions=classes, name='accuracy')
    accuracy = tf.keras.metrics.CategoricalAccuracy()
    accuracy.update_state(labels, logits)

    eval_metrics = {'accuracy': accuracy}

    tf.summary.scalar('accuracy', accuracy.result())

    # Provide an estimator spec for `ModeKeys.EVAL`
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          eval_metric_ops=eval_metrics)

    # Provide an estimator spec for `ModeKeys.TRAIN`
    if mode == tf.estimator.ModeKeys.TRAIN:

        # old but working -&gt; optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta1=0.9)
        # crashing
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, epsilon=1e-07)

        # old -&gt; train_op = optimizer.minimize(loss, tf.compat.v1.train.get_or_create_global_step())
        train_op = optimizer.minimize(loss,var_list=model.weights)

        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          train_op=train_op)
</code></pre>

<p>predictions=predictions, loss=loss, train_op=train_op, export_outputs=predictions_output)</p>

<p>If I keep the compat.v1 module it is working:</p>

<pre><code>optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta1=0.9)
</code></pre>

<p>If I try to use something without compat.v1 it is crashing:</p>

<pre><code>optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9,epsilon=1e-07)
</code></pre>

<p>with the following error (I am running the code locally for the moment, not on <code>GCP</code>):</p>

<pre><code>I0721 17:33:04.812453 4526515648 estimator.py:209] Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/v3/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x1c37b11b70&gt;, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0721 17:33:04.815697 4526515648 estimator_training.py:186] Not using Distribute Coordinator.
I0721 17:33:04.817899 4526515648 training.py:612] Running training and evaluation locally (non-distributed).
I0721 17:33:04.818665 4526515648 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10 or save_checkpoints_secs None.
I0721 17:33:04.834385 4526515648 model.py:211] input_dataset_fn: TRAIN, train

using keras layer and estimator (recommended way)
exporter &lt;tensorflow_estimator.python.estimator.exporter.LatestExporter object at 0x1c37b115f8&gt;

I0721 17:33:05.117963 4526515648 estimator.py:1145] Calling model_fn.

model based on keras layer but return an estimator model

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;timed exec&gt; in &lt;module&gt;

~/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/src/model_mnist_2_0_v1/trainer/model.py in train_and_evaluate(FLAGS, use_keras)
    589                                       exporters=exporter)
    590 
--&gt; 591     tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
    592 
    593 def train_and_evaluate_old(FLAGS, use_keras):

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    471         '(with task id 0).  Given task id {}'.format(config.task_id))
    472 
--&gt; 473   return executor.run()
    474 
    475 

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in run(self)
    611         config.task_type != run_config_lib.TaskType.EVALUATOR):
    612       logging.info('Running training and evaluation locally (non-distributed).')
--&gt; 613       return self.run_local()
    614 
    615     # Distributed case.

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in run_local(self)
    712         max_steps=self._train_spec.max_steps,
    713         hooks=train_hooks,
--&gt; 714         saving_listeners=saving_listeners)
    715 
    716     eval_result = listener_for_eval.eval_result or _EvalResult(

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    365 
    366       saving_listeners = _check_listeners_type(saving_listeners)
--&gt; 367       loss = self._train_model(input_fn, hooks, saving_listeners)
    368       logging.info('Loss for final step: %s.', loss)
    369       return self

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1156       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1157     else:
-&gt; 1158       return self._train_model_default(input_fn, hooks, saving_listeners)
   1159 
   1160   def _train_model_default(self, input_fn, hooks, saving_listeners):

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
   1186       worker_hooks.extend(input_hooks)
   1187       estimator_spec = self._call_model_fn(
-&gt; 1188           features, labels, ModeKeys.TRAIN, self.config)
   1189       global_step_tensor = training_util.get_global_step(g)
   1190       return self._train_with_estimator_spec(estimator_spec, worker_hooks,

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
   1144 
   1145     logging.info('Calling model_fn.')
-&gt; 1146     model_fn_results = self._model_fn(features=features, **kwargs)
   1147     logging.info('Done calling model_fn.')
   1148 

~/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/src/model_mnist_2_0_v1/trainer/model.py in baseline_estimator_model(features, labels, mode, params)
    442         #train_op = optimizer.minimize(loss, tf.compat.v1.train.get_or_create_global_step())
    443         #train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())
--&gt; 444         train_op = optimizer.minimize(loss,var_list=model.weights)
    445 
    446         print('step 8')

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in minimize(self, loss, var_list, grad_loss, name)
    315     """"""
    316     grads_and_vars = self._compute_gradients(
--&gt; 317         loss, var_list=var_list, grad_loss=grad_loss)
    318 
    319     return self.apply_gradients(grads_and_vars, name=name)

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in _compute_gradients(self, loss, var_list, grad_loss)
    349       if not callable(var_list):
    350         tape.watch(var_list)
--&gt; 351       loss_value = loss()
    352     if callable(var_list):
    353       var_list = var_list()

TypeError: 'Tensor' object is not callable
</code></pre>

<p>Any idea how to fix that ? The error messages was changing over time since <code>Tensorflow 2.0 alpha</code>.</p>

<p>I am also looking for a full working example of tf.estimator working with <code>Tensorflow 2.0</code>. I have issue to export the model as well. In the official documentation of <code>Tensorflow 2.0</code> they only use in their example <code>compat.v1</code> and don't export the model. All the online course on tf.estimator from GCP are using  older version of Tensorflow (1.12 - 1.14).</p>
",1,Inadequate Examples
315,57155780,tf.function uses all CPU RAM,"<p>I cannot understand why the function I have posted below uses up all of my RAM. I could understand if I were running it eagerly, but I thought the point of a tf.function was to create a graph that is reused, much like creating an operation and running it in tf 1.x. I am new to tensorflow 2.0 so I might have the wrong idea about what tf.function is doing.</p>

<pre><code>@tf.function
def clip_w(self, weight):
    return tf.clip_by_value(weight, -0.01, 0.01)
</code></pre>

<p>Could anyone help me understand this? Thanks</p>

<p>EDIT: Here is the code where I use this function</p>

<pre><code>def clip_weights(self):
        for l in self.C.layers:
            weights = l.get_weights()
            weights = [self.clip_w(w) for w in weights]
            l.set_weights(weights)
</code></pre>
",1,Documentation Replication on Other Examples
316,57170737,Cannot run tflite model on GPU (Jetson Nano) using Python,"<p>I have a quantized tflite model that I'd like to benchmark for inference on a Nvidia Jetson Nano. I use tf.lite.Interpreter() method for inference. The process doesn't seem to run on the GPU as the inference times on both CPU and GPU are the same.</p>
<p>Is there any way to run a tflite model on GPU using Python?</p>
<p>I tried to force GPU usage by setting tf.device() method but still doesn't work. The official documentation has something called delegates for GPU acceleration but I can't seem to find anything for Python.</p>
<pre><code>with tf.device('/device:GPU:0'):

    interpreter = tf.lite.Interpreter(model_path=&quot;model.tflite&quot;)

    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    input_shape = input_details[0]['shape']
    input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)
    interpreter.set_tensor(input_details[0]['index'], input_data)

    start_time = time.time()

    interpreter.invoke()

    elapsed_time = time.time() - start_time
    print(elapsed_time)

    output_data = interpreter.get_tensor(output_details[0]['index'])
</code></pre>
",1,Documentation Replication on Other Examples
317,57175343,Multiple inputs of keras model with tf.data.Dataset.from_generator in Tensorflow 2,"<p>I am trying to implement a model in keras that will have multiple inputs:</p>

<ul>
<li>image (200x200)</li>
<li>some numbers (1x50)</li>
<li>three 1d signals (1x50000, 2x100000)</li>
</ul>

<p>To feed that model, I want to write a generator to use with <code>tf.data.Dataset.from_generator</code>. From the <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#from_generator"" rel=""noreferrer"">docs of from_generator</a>, its not clear to me how I should provide its parameters <code>output_types</code>, <code>output_shapes</code>. Can anyone help me with this?</p>
",1,Inadequate Examples
318,57246091,How to cast int32 tensor to float32,"<p>How can I cast an <code>int32</code> tensor to <code>float32</code> in tensorflow. I don't understand what <code>tf.cast</code> does. It does not seem to do anything.</p>

<pre><code>import tensorflow as tf
import numpy as np

tf.enable_eager_execution()

a = tf.constant([[1, 2, 3, 4], [1, 2, 3, 4]])
b = tf.cast(a, dtype=tf.float32)

print(tf.shape(a))
print(tf.shape(b))
</code></pre>

<p>outputs;</p>

<pre><code>tf.Tensor([2 4], shape=(2,), dtype=int32) #a   
tf.Tensor([2 4], shape=(2,), dtype=int32) #b
</code></pre>
",1,Documentation Replicability
319,57277926,Can Keras' model.predict return a dictionary?,"<p>The documentation <a href=""https://keras.io/models/model/#predict"" rel=""noreferrer"">https://keras.io/models/model/#predict</a> says that  <code>model.predict</code> returns Numpy array(s) of predictions.  <strong>In the Keras API, is there is a way to distinguishing which of these arrays are which?</strong>  How about in the TF implementation?</p>

<p>At the top of the same page of documentation, they say that ""models can specify multiple inputs and outputs using lists"".  It seems that nothing breaks if instead, one passes dictionaries:  </p>

<pre><code>my_model = tf.keras.models.Model(inputs=my_inputs_dict, outputs=my_outputs_dict)
</code></pre>

<p>When calling <code>model.fit</code> the same documentation says ""If input layers in the model are named, you can also pass a dictionary mapping input names to Numpy arrays.""</p>

<p>It would be nice if either the keys from <code>my_output_dict</code> or the names of the dictionary values (layers) in <code>my_output_dict</code> were attached to the outputs of <code>my_model.predict(...)</code> </p>

<p>If I save the model to TensorFlow's saved_model format protobuf using 
 <code>tf.keras.model.save</code> the tf.serving API works this way-- with named inputs and outputs... </p>
",1,Lack of Alternative Solutions/Documentation
320,57296471,How can one use TensorFlow.js tf.data.generator for remote data sources since generators can't use callbacks,"<p>When introducing the tf.data.Dataset API, the <a href=""https://www.manning.com/books/deep-learning-with-javascript"" rel=""nofollow noreferrer"">Deep Learning with JavaScript book</a> says:</p>

<blockquote>
  <p>Large applications require technology for accessing data from a remote source, piece by piece, on demand.</p>
</blockquote>

<p>But the documentation I've read about generators says a generator can't produce values via callbacks. But how else can one access remote sources? I don't see how one can use <a href=""https://js.tensorflow.org/api/latest/#data.generator"" rel=""nofollow noreferrer"">tf.data.generator</a> in such cases. <a href=""https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/yield"" rel=""nofollow noreferrer"">MDN documentation on yield</a> states:</p>

<blockquote>
  <p>yield can only be called directly from the generator function that contains it. It can't be called from nested functions or from callbacks.</p>
</blockquote>
",1,Documentation Ambiguity
321,57349824,"Recurrent neural network, time series prediction with newer Tensorflow 1.14","<p>How to use new tf.keras API with recurrent neural network? I have checked the documentation but there is no example of such a situation.
There is this great book Hands on machine learning from 2017. Since that year the API of tensorflow has evolved and I am trying to rewrite recurrent neural network for time series prediction with using version <code>1.14</code> code.
The code from the book is using older <code>tf.nn.dynamic_rnn</code> and <code>tf.nn.rnn_cell.BasicRNNCell</code>:</p>

<pre><code>n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1
learning_rate = 0.001

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])
cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)
rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)
stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])
stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
loss = tf.reduce_mean(tf.square(outputs - y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()
n_iterations = 500
batch_size = 50

with tf.Session() as sess:
    init.run()
        for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})
</code></pre>

<p>And this code works just fine (except that it throws warnings about deprecation left and right). I wanted to use <code>tf.keras</code> API as suggested in warning. My code is the same except:</p>

<pre><code>cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)  
rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

<p>But this yields following exception:</p>

<pre><code>InvalidArgumentError: Input to reshape is a tensor with 50 values, but the requested shape requires a multiple of 20
 [[node Reshape_1 (defined at &lt;ipython-input-9-879361be49dd&gt;:3) ]]
</code></pre>

<p>so I understand that the problematic line is</p>

<pre><code>outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
</code></pre>

<p>After checking and comparing documentation for both cells <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a> and 
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN</a> I can't find the culprit.</p>

<p><strong>What is the difference with these two cells? How to use tf.keras API with time series?</strong></p>

<p>Full old code: <a href=""https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb"" rel=""nofollow noreferrer"">https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb</a></p>

<p>Full ""my"" code:</p>

<pre><code>import numpy as np
import tensorflow as tf
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd
from utils import shuffle_batch, variable_summaries
import os


dir_path = os.getcwd()

now = datetime.utcnow().strftime(""%Y%m%d%H%M%S"")
root_logdir = ""tf_logs""
logdir = ""{}/run-{}/"".format(root_logdir, now)
print(dir_path)


t_min, t_max = -5, 5
section_start = (t_max + t_min) / 2
resolution = 0.1
n_steps = 20

def time_series(t):
    return np.sin(t)

def next_batch(batch_size, n_steps):
    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)
    Ts = t0 + np.arange(0., n_steps + 1) * resolution
    ys = time_series(Ts)
    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)


t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))

t_instance = np.linspace(start = section_start, stop = section_start + resolution * (n_steps + 1),num = n_steps + 1)

plt.figure(figsize=(11,4))
plt.subplot(121)
plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"")
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)
#plt.axis([-10, 10, -17, 13])
plt.xlabel(""Time"")
plt.ylabel(""Value"")

plt.subplot(122)
plt.title(""A training instance"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""c*"", markersize=10, label=""target"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")


# In[6]:


n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])


# In[7]:


cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)                        


rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
print(rnn_outputs.get_shape())


stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons], name='reshape1')
stacked_outputs = tf.keras.layers.Dense(n_outputs,name=""hidden2"")(stacked_rnn_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs], name='reshape2')


learning_rate = 0.001

loss = tf.reduce_mean(tf.square(outputs - y)) # MSE
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()

n_iterations = 1500
batch_size = 50
save_path =os.path.join(dir_path,""model"",""recurrent_sinus_model"")

with tf.Session() as sess:
    init.run()
    for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    saver.save(sess, save_path)


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})


plt.title(""Testing the model"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""w*"", markersize=10, label=""target"")
plt.plot(t_instance[1:], y_pred[0,:,0], ""r."", markersize=10, label=""prediction"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")

plt.show()


# In[ ]:


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t.reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})



plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"",linewidth=5,c='r')
plt.plot(t[:-1], time_series(t[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)

plt.xlabel(""Time"")
plt.ylabel(""Value"")
</code></pre>
",1,Documentation Replication on Other Examples
322,57392510,TensorFlow simple example help - custom gradient,"<p>How do you pass a custom gradient into a gradient optimization function in TensorFlow.</p>

<p>I have illustrated what I am trying to do, with a simple example (trying to minimize z = 2x^2 + y^2 + 2).</p>

<p>I have been looking at:
<a href=""https://www.tensorflow.org/api_docs/python/tf/train/Optimizer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/Optimizer</a></p>

<p>The problem seems to work if you pass in <code>optimizer = tf.train.GradientDescentOptimizer(0.55)</code> and <code>train = optimizer.minimize(z)</code></p>

<p>This code works:</p>

<pre><code>import tensorflow as tf

x = tf.Variable(11, name='x', dtype=tf.float32)
y = tf.Variable(11, name='x', dtype=tf.float32)
const = tf.constant(2.0, dtype=tf.float32)

z = x**2 + y**2 + const


optimizer = tf.train.GradientDescentOptimizer(0.55)
train = optimizer.minimize(z)

init = tf.global_variables_initializer()

def optimize():
  with tf.Session() as session:
    session.run(init)
    print(""starting at"", ""x:"", session.run(x), ""y:"", session.run(y), ""z:"", session.run(z))
    for step in range(10):  
      session.run(train)
      print(""step"", step, ""x:"", session.run(x), ""y:"", session.run(y), ""z:"", session.run(z))


optimize()
</code></pre>

<p>But I want to specify the gradient in the problem.
aka I am trying to do this:</p>

<pre><code>def function_to_minimize(x,y, const):
    # z = 2x^2 + y^2 + constant
    z = 2*x**2 + y**2 + const
    return z

def calc_grad(x,y):
    # z = 2x^2 + y^2 + constant
    dz_dx = 4*x
    dz_dy = 2*y
    return [(dz_dx, x), (dz_dy, y)]

x = tf.Variable(3, name='x', dtype=tf.float32)
y = tf.Variable(3, name='y', dtype=tf.float32)
const = tf.constant(2.0, dtype=tf.float32)


z = function_to_minimize(x,y, const)
grad = calc_grad(x,y)


init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
print(sess.run(z))
print(sess.run(grad))


optimizer = tf.train.GradientDescentOptimizer(0.5)

grads_and_vars = calc_grad(x,y)

optimizer.apply_gradients(grads_and_vars)

# minimize() takes care of both computing the gradients and applying them to the variables.
#If you want to process the gradients before applying them you can instead use the optimizer in three steps:
#     1. Compute the gradients with compute_gradients().
#     2. Process the gradients as you wish.
#     3. Apply the processed gradients with apply_gradients()
</code></pre>

<p>How do you do this properly?</p>
",1,Documentation Replication on Other Examples
323,57403472,How do I add a new feature column to a tf.data.Dataset object?,"<p>I am building an input pipeline for proprietary data using Tensorflow 2.0's data module and using the tf.data.Dataset object to store my features. Here is my issue - the data source is a CSV file that has only 3 columns, a label column and then two columns which just hold strings referring to JSON files where that data is stored. I have developed functions that access all the data I need, and am able to use Dataset's map function on the columns to get the data, but I don't see how I can add a new column to my tf.data.Dataset object to hold the new data. So if anyone could help with the following questions, it would really help:</p>

<ol>
<li>How can a new feature be appended to a tf.data.Dataset object?</li>
<li>Should this process be done on the entire Dataset before iterating through it, or during (I think during iteration would allow utilization of the performance boost, but I don't know how this functionality works)?</li>
</ol>

<p>I have all the methods for taking the input as the elements from the columns and performing everything required to get the features for each element, I just don't understand how to get this data into the dataset. I could do ""hacky"" workarounds, using a Pandas Dataframe as a  ""mediator"" or something along those lines, but I want to keep everything within the Tensorflow Dataset and pipeline process, for both performance gains and higher quality code.</p>

<p>I have looked through the Tensorflow 2.0 documentation for the Dataset class (<a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset"" rel=""noreferrer"">https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset</a>), but haven't been able to find a method that can manipulate the structure of the object.</p>

<p>Here is the function I use to load the original dataset:</p>

<pre><code>def load_dataset(self):
    # TODO: Function to get max number of available CPU threads
    dataset = tf.data.experimental.make_csv_dataset(self.dataset_path,
                                                    self.batch_size,
                                                    label_name='score',
                                                    shuffle_buffer_size=self.get_dataset_size(),
                                                    shuffle_seed=self.seed,
                                                    num_parallel_reads=1)
    return dataset
</code></pre>

<p>Then, I have methods which allow me to take a string input (column element) and return the actual feature data. And I am able to access the elements from the Dataset using a function like "".map"". But how do I add that as a column?</p>
",1,Inadequate Examples
324,57414387,Meaning of tf.keras.layers.LSTM parameters,"<p>I am having trouble understanding some of the parameters of <code>LSTM</code> layers in the <code>tf.keras.layers</code> API. </p>

<p>I am investigating using <code>CuDNNLSTM</code> layers instead of <code>LSTM</code> layers (to speed up training), but before I commit to <code>CuDNN</code> layers, I would like to have a full understanding of the parameters that I lose by using a <code>CuDNNLSTM</code> instead of a <code>LSTM</code> layer. I have read the docs, but they seem to assume some prior knowledge of <code>LSTM</code>s that I do not have.</p>

<p>I have listed the pararameters that <code>CuDNNLSTM</code> does not have (that <code>LSTM</code> has) and interspersed with my questions about them, respectively.</p>

<ul>
<li><code>activation</code></li>
<li><code>recurrent_activation</code>

<ol>
<li>What is the difference between <code>activation</code> and <code>recurrent_activation</code>? I am assuming it has something to do with the activation for a cell vs. the activation for the full <code>LSTM</code> layer, but am unsure.</li>
</ol></li>
<li><code>use_bias</code>

<ol start=""2"">
<li>If <code>use_bias</code> is True, where is this bias applied?</li>
</ol></li>
<li><code>dropout</code></li>
<li><code>recurrent_dropout</code>

<ol start=""3"">
<li>Again, what is the difference between <code>dropout</code> and <code>recurrent_dropout</code>? If <code>recurrent_dropout</code> is dropout between the LSTM cells, that does not make sense to me, because you would be ignoring the previous output, which I thought would defeat the purpose of having an RNN.</li>
<li>Can either of these dropout parameters be substituted with a dropout layer before/after the LSTM layer (i.e. <code>tf.keras.models.sequential([Input(...), LSTM(...), Dropout(0.5)])</code> or <code>tf.keras.models.sequential([Input(...), Dropout(0.5), LSTM(...)])</code> instead of <code>tf.keras.models.sequential([Input(...), LSTM(..., dropout=0.5)])</code>)</li>
</ol></li>
<li><code>implementation</code>

<ol start=""5"">
<li>I understand why this parameter is not in <code>CuDNN</code> layers, since it would probably make it harder to parallelize. However, in <code>LSTM</code>s, does this impact the result (i.e. with the same seed, will <code>implementation=1</code> converge to the same or different result as <code>implementation=2</code>)?</li>
</ol></li>
<li><code>unroll</code></li>
</ul>

<p>I've read a lot about <code>LSTM</code>s, and am at a point where I've decided to start training things, otherwise I won't absorb much more hypothetical knowledge. I've tried a lot of things in modeling, too, but the network I'm training is really simple so nothing seems to impact the results.</p>
",1,Documentation Replicability
325,57449484,What is trainable parameter in tensorflow?,"<p>tf.compat.v1.layers.batch_normalization takes <code>trainable</code> as an input. The documentation says:</p>

<blockquote>
  <p>Boolean, if True also add variables to the graph collection GraphKeys.TRAINABLE_VARIABLES (see tf.Variable).</p>
</blockquote>

<p>I think only scaling factor (gamma) and offset (beta) should be added to trainable variables and I am skeptical if even moving averages will get added to GraphKeys.TRAINABLE_VARIABLES. Can somebody tell me how trainable input is influencing the behavior of batch_normalization</p>
",1,Documentation Replicability
326,57460127,Tensorflow 2 creating custom dataset,"<p>I am trying to build a custom dataset-loader, which laods <a href=""https://rrc.cvc.uab.es/?ch=4"" rel=""nofollow noreferrer"">ICDAR</a>-Dataset.
My frist step was to embed a dataset inside my loader as suggested also
<a href=""https://stackoverflow.com/questions/54373780/create-tensorflow-dataset-with-custom-file-format"">here</a> in this post, but the problem is that you have to implement all the nice features that the tenfsoflow-2 class ""Dataset"" offers manually.</p>

<p>My second try was to subclass the Dataset-Class, something like:</p>

<pre><code>class MyDataset(tf.data.Dataset):
  def __init__(self):
    super(MyDataset, self).init()

  def preprocess_images(self):
    pass
</code></pre>

<p>But the problem is i did not find any documentation what dataset-class internally really does, the only implementation i found was <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L2349"" rel=""nofollow noreferrer"">this one</a>.</p>

<p>So question is does anybody know how to build a custom ""dataset"" in tf2 by subclassing tf.data.Dataset.</p>

<p>By the way i also tried tensorflow_datasets, bit it does not really worked, shince it will downlaod the dataset, and split them manually which is in this is alreay seperated by train and test and also ICDAr can not be downlaoded without registration.</p>

<p><strong>The content of the ICDAR-Dataset is as following:</strong></p>

<blockquote>
  <p>An Image </p>
  
  <p>A List of all texts in each image </p>
  
  <p>A List of Bouding-boxes for each text in each image</p>
</blockquote>

<p><strong>Image:</strong> 
@<a href=""https://rrc.cvc.uab.es/?ch=4"" rel=""nofollow noreferrer"">https://rrc.cvc.uab.es/?ch=4</a> owns the copyrights of this image.
<a href=""https://i.stack.imgur.com/YCVX2.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YCVX2.jpg"" alt=""enter image description here""></a></p>

<p>Words and bounding boxes for the above image:</p>

<pre><code>377,117,463,117,465,130,378,130,Genaxis Theatre
493,115,519,115,519,131,493,131,[06]
374,155,409,155,409,170,374,170,###
492,151,551,151,551,170,492,170,62-03
376,198,422,198,422,212,376,212,Carpark
494,190,539,189,539,205,494,206,###
374,1,494,0,492,85,372,86,###
</code></pre>

<p>Thanks
does anyone know how to </p>
",1,Lack of Alternative Solutions/Documentation
327,57570385,"How to generate custom mini-batches using Tensorflow 2.0, such as those in the paper ""In defense of the triplet loss""?","<p>I want to implement a custom mini-batch generator in Tensorflow 2.0 using tf.data.Dataset API. Concretely, I have image data, 100 classes with ~200 examples each. For each mini-batch, I want to randomly sample P classes, and K images from each class, for a total of P*K examples in a mini-batch (as described in the paper <a href=""https://arxiv.org/pdf/1703.07737.pdf"" rel=""nofollow noreferrer"">In Defense of the Triplet Loss for Person Re-Identification</a>]).</p>

<p>I've been searching through documentation for <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">tf.data.Dataset</a>, but can't seem to find the right method. I've looked into the <code>from_generator</code> method, but it doesn't seem suitable for this, since it generates a whole dataset from scratch as I understood.</p>

<p>It seems to me that one way to do it would be to make a new class similar to <code>BatchDataset</code> which can be found in <a href=""https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/data/ops/dataset_ops.py#L90-L1536"" rel=""nofollow noreferrer"">tf.data.Dataset source code</a>, where I would somehow implement the logic, but I'm hoping for an easier solution to be honest.</p>
",1,Requesting (Additional) Documentation/Examples
328,57651287,How to swap tensor axes efficiently in tensorflow?,"<p>I have to swap tensor's axes using <code>tf.transpose</code> to do the batch matrix multiplication (as the code shown below). </p>

<p>tensor input_a: shape [10000, 10000] </p>

<p>tensor input_b: shape [batch_size, 10000, 10] </p>

<p>tensor output:  shape [batch_size, 10000, 10] </p>

<pre><code># reshape_input_b: shape [10000, batch_size, 10]
transpose_input_b = tf.transpose(input_b, [1, 0, 2])

# transpose_input_b : shape [10000, batch_size * 10]
reshape_input_b = tf.reshape(transpose_input_b , [10000, -1])

# ret: shape [10000, batch_size * 10]
ret = tf.matmul(input_a, reshape_input_b, a_is_sparse = True)

# reshape_ret: [10000, batch_size, 10]
reshape_ret = tf.reshape(ret, [10000, -1, 10])

# output : [batch_size, 10000, 10]
output = tf.transpose(reshape_ret, [1, 0, 2])
</code></pre>

<p>However, it seems very slow. I noticed this in the document page of <code>tf.transpose</code>:</p>

<blockquote>
  <p>In numpy transposes are memory-efficient constant time operations as they simply return a new view of the same data with adjusted strides.</p>
  
  <p>TensorFlow does not support strides, <b>so transpose returns a new tensor with the items permuted</b>.</p>
</blockquote>

<p>So, I think it might be the reason why my code run slowly? Is there any way to swap tensor's axes, or do the batch matrix multiplication efficiently?</p>
",1,Inadequate Examples
329,57717004,Tensorflow: Modern way to load large data,"<p>I want to train a convolutional neural network (using tf.keras from Tensorflow version 1.13) using numpy arrays as input data. The training data (which I currently store in a single &gt;30GB '.npz' file) does not fit in RAM all at once. <strong>What is the best way to save and load large data-sets into a neural network for training?</strong> Since I didn't manage to find a good answer to this (surely ubiquitous?) problem, I'm hoping to hear one here. Thank you very much in advance for any help!</p>
<h3>Sources</h3>
<p>Similar questions seem to have been asked many times (e.g. <a href=""https://stackoverflow.com/questions/49169016/training-classifier-from-tfrecords-in-tensorflow"">training-classifier-from-tfrecords-in-tensorflow</a>, <a href=""https://stackoverflow.com/questions/40467990/tensorflow-synchronize-readings-from-tfrecord"">tensorflow-synchronize-readings-from-tfrecord</a>, <a href=""https://stackoverflow.com/questions/51357223/how-to-load-data-parallelly-in-tensorflow"">how-to-load-data-parallelly-in-tensorflow</a>) but are several years old and usually contain no conclusive answer.</p>
<p>My current understanding is that using TFRecord files is a good way to approach this problem. The most promising tutorial I found so far explaining how to use TFRecord files with keras is <a href=""https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36"" rel=""noreferrer"">medium.com</a>. Other helpful sources were <a href=""http://machinelearninguru.com/deep_learning/data_preparation/tfrecord/tfrecord.html"" rel=""noreferrer"">machinelearninguru.com</a> and <a href=""https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564"" rel=""noreferrer"">medium.com_source2</a> and sources therin.</p>
<p>The official tensorflow documentation and tutorials (on <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""noreferrer"">tf.data.Dataset</a>, <a href=""https://www.tensorflow.org/guide/datasets"" rel=""noreferrer"">Importing Data</a>, <a href=""https://www.tensorflow.org/tutorials/load_data/tf_records"" rel=""noreferrer"">tf_records</a> etc.) did not help me. In particular, several of the examples given there didn't work for me even without modifications.</p>
<h3>My Attempt at using TFRecord files</h3>
<p>I'm assuming TFRecords are a good way to solve my problem but I'm having a hard time using them. Here is an example I made based on the tutorial <a href=""https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36"" rel=""noreferrer"">medium.com</a>. I stripped down the code as much as I could.</p>
<pre><code># python 3.6, tensorflow 1.13.
# Adapted from https://medium.com/@moritzkrger/speeding-up-keras-with-tfrecord-datasets-5464f9836c36
import tensorflow as tf
import numpy as np
from tensorflow.python import keras as keras


# Helper functions (see also https://www.tensorflow.org/tutorials/load_data/tf_records)
def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))


def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))


def writeTFRecords():
    number_of_samples = 100  # create some random data to play with
    images, labels = (np.random.sample((number_of_samples, 256, 256, 1)), np.random.randint(0, 30, number_of_samples))

    writer = tf.python_io.TFRecordWriter(&quot;bla.tfrecord&quot;)

    for index in range(images.shape[0]):
        image = images[index]
        label = labels[index]

        feature = {'image':  _bytes_feature(tf.compat.as_bytes(image.tostring())),
                   'label':  _int64_feature(int(label))}

        example = tf.train.Example(features=tf.train.Features(feature=feature))
        writer.write(example.SerializeToString())
    writer.close()


def loadTFRecord(data_path):
    with tf.Session() as sess:
        feature = {'train/image': tf.FixedLenFeature([], tf.string),
                   'train/label': tf.FixedLenFeature([], tf.int64)}
        # Create a list of filenames and pass it to a queue
        filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)
        # Define a reader and read the next record
        reader = tf.TFRecordReader()
        _, serialized_example = reader.read(filename_queue)
        # Decode the record read by the reader
        features = tf.parse_single_example(serialized_example, features=feature)
        # Convert the image data from string back to the numbers
        image = tf.decode_raw(features['train/image'], tf.float32)

        # Cast label data into int32
        label = tf.cast(features['train/label'], tf.int32)
        # Reshape image data into the original shape
        image = tf.reshape(image, [256, 256, 1])

        return image, label  # I'm not 100% sure that's how this works...


# ######### generate a TFRecords file in the working directory containing random data. #################################
writeTFRecords()
# ######## Load the TFRecords file and use it to train a simple example neural network. ################################
image, label = loadTFRecord(&quot;bla.tfrecord&quot;)

model_input = keras.layers.Input(tensor=image)
model_output = keras.layers.Flatten(input_shape=(-1, 256, 256, 1))(model_input)
model_output = keras.layers.Dense(16, activation='relu')(model_output)

train_model = keras.models.Model(inputs=model_input, outputs=model_output)
train_model.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001),  
                    loss='mean_squared_error',
                    target_tensors=[label])

print(&quot;\n \n start training \n \n&quot;) # Execution gets stuck on fitting
train_model.fit(epochs=1, steps_per_epoch=10)  # no output or error messages.

</code></pre>
<p>The code creates a TFRecord file and starts fitting, then just gets stuck with no output or error messages. I don't know what the problem is or how I could try to fix it.</p>
",1,Documentation Replication on Other Examples
330,57719398,Unable to save model with tensorflow 2.0.0 beta1,"<p>I have tried all the options described in the documentation but none of them allowed me to save my model in tensorflow 2.0.0 beta1. I've also tried to upgrade to the (also unstable) TF2-RC but that ruined even the code I had working in beta so I quickly rolled back for now to beta.</p>

<p>See a minimal reproduction code below.</p>

<p>What I have tried: </p>

<ol>
<li><pre><code>model.save(""mymodel.h5"") 
</code></pre></li>
</ol>

<blockquote>
  <p>NotImplementedError: Saving the model to HDF5 format requires the
  model to be a Functional model or a Sequential model. It does not work
  for subclassed models, because such models are defined via the body of
  a Python method, which isn't safely serializable. Consider saving to
  the Tensorflow SavedModel format (by setting save_format=""tf"") or
  using <code>save_weights</code>.</p>
</blockquote>

<ol start=""2"">
<li><pre><code>model.save(""mymodel"", format='tf')
</code></pre></li>
</ol>

<blockquote>
  <p>ValueError: Model &lt;<strong>main</strong>.CVAE object at 0x7f1cac2e7c50> cannot be
  saved because the input shapes have not been set. Usually, input
  shapes are automatically determined from calling .fit() or .predict().
  To manually set the shapes, call model._set_inputs(inputs).</p>
</blockquote>

<p>3.</p>

<pre><code>model._set_input(input_sample)
model.save(""mymodel"", format='tf') 
</code></pre>

<blockquote>
  <p>AssertionError: tf.saved_model.save is not supported inside a traced
  @tf.function. Move the call to the outer eagerly-executed context.</p>
</blockquote>

<p>And this is where I am stuck now because it gives me no reasonable hint whatsoever. That's because I am NOT calling the save() function from a @tf.function, I'm already calling it from the outermost scope possible. In fact, I have no @tf.function at all in this minimal reproduction script below and still getting the same error.</p>

<p>So I really have no idea how to save my model, I've tried every options and they all throw errors and provide no hints.</p>

<p>The minimal reproduction example below works fine if you set save_model=False and it reproduces the error when save_model=True. </p>

<p>It may seem unnecessary in this simplified auto-encoder code example to use a subclassed model but I have lots of custom functions added to it in my original VAE code that I need it for.</p>

<p>Code:</p>

<pre><code>import tensorflow as tf

save_model = True

learning_rate = 1e-4
BATCH_SIZE = 100
TEST_BATCH_SIZE = 10
color_channels = 1
imsize = 28

(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()

train_images = train_images[:5000, ::]
test_images = train_images[:1000, ::]
train_images = train_images.reshape(-1, imsize, imsize, 1).astype('float32')
test_images = test_images.reshape(-1, imsize, imsize, 1).astype('float32')
train_images /= 255.
test_images /= 255.
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE)
test_dataset = tf.data.Dataset.from_tensor_slices(test_images).batch(TEST_BATCH_SIZE)

class AE(tf.keras.Model):
    def __init__(self):
        super(AE, self).__init__()
        self.network = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=(imsize, imsize, color_channels)),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(50),
            tf.keras.layers.Dense(imsize**2 * color_channels),
            tf.keras.layers.Reshape(target_shape=(imsize, imsize, color_channels)),
        ])
    def decode(self, input):
        logits = self.network(input)
        return logits

optimizer = tf.keras.optimizers.Adam(learning_rate)
model = AE()

def compute_loss(data):
    logits = model.decode(data)
    loss = tf.reduce_mean(tf.losses.mean_squared_error(logits, data))
    return loss

def train_step(data):
    with tf.GradientTape() as tape:
        loss = compute_loss(data)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss, 0

def test_step(data):
    loss = compute_loss(data)
    return loss

input_shape_set = False
epoch = 0
epochs = 20
for epoch in range(epochs):
    for train_x in train_dataset:
        train_step(train_x)
    if epoch % 1 == 0:
        loss = 0.0
        num_batches = 0
        for test_x in test_dataset:
            loss += test_step(test_x)
            num_batches += 1
        loss /= num_batches
        print(""Epoch: {}, Loss: {}"".format(epoch, loss))

        if save_model:
            print(""Saving model..."")
            if not input_shape_set:
                # Note: Why set input shape manually and why here:
                # 1. If I do not set input shape manually: ValueError: Model &lt;main.CVAE object at 0x7f1cac2e7c50&gt; cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).
                # 2. If I set input shape manually BEFORE the first actual train step, I get: RuntimeError: Attempting to capture an EagerTensor without building a function.
                model._set_inputs(train_dataset.__iter__().next())
                input_shape_set = True
            # Note: Why choose tf format: model.save('MNIST/Models/model.h5') will return NotImplementedError: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=""tf"") or using save_weights.
            model.save('MNIST/Models/model', save_format='tf')
</code></pre>
",1,Documentation Replicability
331,57731214,What tf.keras.backend.clear_session actually do?,"<p>What is <code>tf.keras.backend.clear_session</code> actually do?</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session</a></p>

<p>How it's related to <code>tf.reset_default_graph()</code> and  <code>sess.close()</code> ?</p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/reset_default_graph"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/reset_default_graph</a></p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/Session#close"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/Session#close</a></p>
",1,Lack of Alternative Solutions/Documentation
332,57813806,Apply feature columns without tf.Estimator (Tensorflow 2.0.0-rc0),"<p>In the Tensorflow tf.Estimator and tf.feature_column docs it is well documented, how to use feature columns together with an Estimator e.g. in order to one-hot encode the categorical features in the dataset being used.</p>

<p>However, I want to ""apply"" my feature columns directly to a tf.dataset which I create from a .csv file (with two columns: UserID, MovieID), without even defining a model or an Estimator. (Reason: I want to check what's happening exactly in my datapipeline, i.e. I'd like to be able to run a batch of samples through my the pipeline, and then see in the output how the features got encoded.)</p>

<p>This is what I have tried so far:</p>

<pre><code>column_names = ['UserID', 'MovieID']

user_col = tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000)
movie_col = tf.feature_column.categorical_column_with_hash_bucket(key='MovieID', hash_bucket_size=1000)
feature_columns = [tf.feature_column.indicator_column(user_col), tf.feature_column.indicator_column(movie_col)]

feature_layer = tf.keras.layers.DenseFeatures(feature_columns=feature_columns)

def process_csv(line):
  fields = tf.io.decode_csv(line, record_defaults=[tf.constant([], dtype=tf.int32)]*2, field_delim="";"")
  features = dict(zip(column_names, fields))

  return features 

ds = tf.data.TextLineDataset(csv_filepath)
ds = ds.map(process_csv, num_parallel_calls=4)
ds = ds.batch(10)
ds.map(lambda x: feature_layer(x))
</code></pre>

<p>However the last line with the map call raises the following error:</p>

<blockquote>
  <p>ValueError: Column dtype and SparseTensors dtype must be compatible.
  key: MovieID, column dtype: , tensor dtype: </p>
</blockquote>

<p>I'm not sure what this error means...
I also tried to define a tf.keras model with only the feature_layer I defined, and then run .predict() on my dataset - instead of using ds.map(lambda x: feature_layer(x)):</p>

<pre><code>model = tf.keras.Sequential([feature_layer])
model.compile()
model.predict(ds)
</code></pre>

<p>However, this results exactly in the same error as above.
Does anybody have an idea what is going wrong? Is there maybe an easier way to achieve this?</p>
",1,Documentation Replication on Other Examples
333,57872334,parallel inference in tensorflow (CPUs),"<p>this is a really basic question, but I can't get the answer anywhere.</p>

<p>Using tensorflow, can I do inference (<code>tf.keras.Model.predict()</code>) on multiple CPUs in parallel? I am using <code>tf.data.Dataset</code> to represent my data, but from the <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict"" rel=""nofollow noreferrer"">documentation</a> it seems multiprocessing can be used only with generators or tf.keras.Sequence objects. Why is that? Am I supposed to somehow create an ordinary python generator from the <code>Dataset</code> or to manage the parallelism on my own with <code>multiprocessing</code> package? What would be the standard way of doing this?</p>

<p>Thanks for any hints.</p>
",1,Documentation Replication on Other Examples
334,57881799,How to define custom gradient for keras layer with tensorflow 1.14,"<p>I am trying to implement gradient reversal layer in tf.keras (tf ver 1.14). I defined a custom gradient using tf.custom_gradient but the grad function is never called and the result is wrong.</p>

<p>I am using the following to test the layer</p>

<pre><code>from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras import backend as k
import tensorflow as tf
tf.enable_eager_execution()
import numpy as np

@tf.custom_gradient
def custom_op(x):
    result = x
    def custom_grad(dy):
        grad = tf.negative(dy)
        return grad
    return result, custom_grad

class GradientReversal(tf.keras.layers.Layer):
  def __init__(self):
    super(GradientReversal, self).__init__()

  def call(self, inputs):
    return custom_op(inputs)


a = Input(shape=(2,))
b = GradientReversal()(a)
c = Dense(1)(b)
model = Model(inputs=a, outputs=c)
model.compile(loss='binary_crossentropy', optimizer='sgd')

@tf.function
def test():  
  with tf.GradientTape() as tape:
    out = model(np.ones((1, 2)))
  gradients = tape.gradient(out, model.trainable_variables)
  return gradients

print(test())
</code></pre>
",1,Documentation Replicability
335,57921463,How tf.data.experimental.group_by_window() operates in Tensorflow 2.0,"<p>I am trying to understand the tf.data.experimental.group_by_window() method in Tensorflow 2 but I have some difficulties.</p>

<p>For a reproducible example I use the one presented in the documentation:</p>

<pre><code>components = np.arange(100).astype(np.int64)
dataset20 = tf.data.Dataset.from_tensor_slices(components)
dataset20 = dataset.apply(tf.data.experimental.group_by_window(key_func=lambda x: x%2, reduce_func=lambda _,\
                                                          els: els.batch(10), window_size=100))

i = 0

for elem in dataset20:

    print('i is {0}\n'.format(i))

    print('elem is {0}'.format(elem.numpy()))

    i += 1

    print('\n--------------------------------\n')

i is 0

elem is [0 2 4 6 8]

--------------------------------

i is 1

elem is [1 3 5 7 9]

--------------------------------
</code></pre>
",1,Documentation Ambiguity
336,57929803,What is the proper way to convert Tracing Code using RunOptions to Tensorflow 2.0?,"<p>I'm having difficulty finding any documentation on how to migrate tracing code from 1.x to 2.0.</p>

<p>In tensorflow 1.x you could do the following:</p>

<pre><code>run_options = tf.compat.v1.RunOptions(trace_level=tf.compat.v1.RunOptions.FULL_TRACE)
run_metadata = tf.compat.v1.RunMetadata()
final_result = sess.run(result, feed_dict={...},
                        options=run_options,
                        run_metadata=run_metadata)

trace = fetched_timeline = timeline.Timeline(run_metadata.step_stats)
chrome_trace = fetched_timeline.generate_chrome_trace_format()
with open('timeline.json', 'w') as f:
    f.write(chrome_trace)
</code></pre>

<p>How can you do a similar thing with a @tf.function call?</p>

<pre><code>@tf.function
def predict(x1, x2):
    ...
#=============
# Set run options and RunMetadata variables
#=============
#=============
final_result = predict(x1_val, x2_val)

#=============
# Dump Trace (assuming run_metadata is the RunMetaData object we configured previously)
#=============
trace = fetched_timeline = timeline.Timeline(run_metadata.step_stats)
chrome_trace = fetched_timeline.generate_chrome_trace_format()
with open('timeline.json', 'w') as f:
    f.write(chrome_trace)
#=============

</code></pre>
",1,Inadequate Examples
337,57970717,Using pretrained convolutional network as a GAN discriminator,"<p>I've pulled some code from TF2.0 documentation to generate images from a custom dataset. The code is <a href=""https://www.tensorflow.org/beta/tutorials/generative/dcgan"" rel=""nofollow noreferrer"">here</a> </p>

<p>Since the documentation uses Keras i figured i might change the discriminator network to a pretrained network e.g InceptionV3, and only train the top layers. I've found <a href=""https://keras.io/applications/"" rel=""nofollow noreferrer"">this</a> code (Fine-tune InceptionV3 on a new set of classes). I cant seem to figure out how to replace the the one with the other. I understand that im trying to replace Sequential mode with the Functional API. But i guess they are somehow interconnected. However, im not a frequent Keras user.</p>

<p>My questions is: How do i replace a custom CNN in Sequential mode with a pretrained one from the Functional API to use as a discriminator?</p>

<p>EDIT: I would be happy if anyone has examples of doing it with the GANEstimator instead as im more used to TF.</p>

<p><strong>Use the generator to generate a random image</strong></p>

<pre><code>def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 3)

    return model

generator = make_generator_model()
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
</code></pre>

<p><strong>The current discriminator and helpers (Outputs tf.Tensor([[-0.0003378]], shape=(1, 1), dtype=float32))</strong></p>

<pre><code>def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))

    return model

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
</code></pre>

<p><strong>The desired discriminator</strong></p>

<pre><code>def make_discriminator_model():
    # create the base pre-trained model
    model = InceptionV3(weights='imagenet', include_top=False)

    # ADD TOP LAYERS

    # FREEZE ALL LAYERS EXCEPT TOP LAYERS

    return model

# COMPILE

def discriminator_loss(real_output, fake_output):
    real_loss = ??? # Real Loss
    fake_loss = ??? # Fake loss
    total_loss = real_loss + fake_loss
    return total_loss

noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
</code></pre>

<p><strong>All imports</strong></p>

<pre><code>  from __future__ import absolute_import, division, print_function, unicode_literals

try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf
print('TF version: {}'.format(tf.__version__))

import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from PIL import Image
from tensorflow.keras import layers
import time

from IPython import display
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import vgg16
import os.path
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras import backend as K
</code></pre>

<p><strong>EDIT:
This was the discriminator i ended up with! Thanks to @pandrey</strong></p>

<pre><code>def make_discriminator_model():
    pre_trained = tf.keras.applications.InceptionV3(
        weights='imagenet', include_top=False, input_shape=IMG_SHAPE
    )
    pre_trained.trainable = False  # mark all weights as non-trainable
    model = tf.keras.Sequential([pre_trained])
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(1))   
    return model
</code></pre>
",1,Requesting (Additional) Documentation/Examples
338,57995171,Need a clear simple approach to distributed learning in Tensorflow/Keras,"<p>I have multiple machines, some with GPUs and some others not. I also have a keras model that works fine on a single machine but I want to train it in a distributed mode because I want to test it with a huge dataset and with a bigger number of layers.
There is quite a lot of pages discussing the distribution strategy in tf.distribute, but at the same time there are a lot other pages showing how to do it with encapsulating keras model with an estimator, setting up the TF_CONFIG parameter and then call <code>tf.estimator.train_and_evaluate</code>.
I used the second approach personally as it was more straightforward and am struggling to tune and debug it. It works anyway, but I am very confused what is the point in all of strategy-related stuff as I don't see any use them in the second approach, and the documentation is not helping to clear it.</p>

<p>I also have some doubt if my file setting environment is correct: My understanding is that the PS server is going to hold the model parameters and the chief server is going to administer the whole training process, distributing data, and saving summaries and checkpoints. So I assume that:</p>

<p>0- I need only one chief server, at least one PS server, possibly some workers, and one evaluator. The data and parameter sharing and communication between all of these servers is done by system and I am not engaged in it.</p>

<p>1- The main python code for all machines should be exactly the same, except in TF_CONFIG definition that defines the task and index for that specific machine.</p>

<p>2- I should have one shared copy of data in a folder available to all chief and workers.</p>

<p>3- I should have one shared log directory accessible by all machines as defined in tf.estimator.RunConfig.</p>

<p>4- Having this setting then a piece of code such as below will do the job (assuming the <code>model</code> has been defined elsewhere and the <code>read_datasets</code> function returns features and labels for running the model):</p>

<pre><code>runConfig = tf.estimator.RunConfig(
        session_config=config,
        model_dir=log_dir,
        save_summary_steps=1,
        save_checkpoints_steps=train_steps
        )
estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig)
train_spec = tf.estimator.TrainSpec(input_fn=lambda: read_datasets(...), max_steps=epochs*train_steps)
eval_spec = tf.estimator.EvalSpec(input_fn=lambda: read_datasets(...), start_delay_secs=1, throttle_secs=1)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
</code></pre>

<p>Although the above approach seems to work fine, I still have some difficulties understanding how the chief is partitioning the dataset among the workers and how to set the train_step and batch_size in this approach. Also I don't know how can I report accuracy and other metrics such as precision/recall/F1 in addition to loss when running the <code>tf.estimator.evaluate</code> without writing a custom model_fn for my encapsulated keras estimator.</p>
",1,Documentation Replication on Other Examples
339,58069572,Workaround for lack of broadcast in TFLite,"<p>I would like to run a TFLite model that requires me to produce a 3d output (the sample code is a minimum example generating the error). Is there a tensorflow equivalent to gather_nd that does not reduce the dimension by one?</p>

<p>I've tried looking through the documentation for related functions that I can think of and haven't found a good option.</p>

<pre><code>import tensorflow.compat.v1 as tf
import numpy as np

tf.disable_v2_behavior()
initial_input = tf.placeholder(dtype=tf.float32, shape=(None,5,1024))
cap_i = tf.gather_nd(initial_input, [[0,1]]) #[0,2],[0,3],[0,4],[0,5]
cap_i_broadcast = tf.broadcast_to(cap_i, [1,5,1024])
cap_iT = tf.transpose(cap_i_broadcast, perm=[0,2,1])

sess = tf.Session()
sess.run(tf.global_variables_initializer())
tf.io.write_graph(sess.graph_def, '', 'train.pbtxt')
converter = tf.lite.TFLiteConverter.from_session(sess, [initial_input], [cap_iT])
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
open('converted_model.tflite', ""wb"").write(tflite_model)
sess.close()
</code></pre>

<p>Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: GATHER_ND, TRANSPOSE. Here is a list of operators for which you will need custom implementations: BroadcastTo.</p>
",1,Documentation Replication on Other Examples
340,58112355,"What, exactly, is eager execution from a programming point of view?","<p>I am trying to understand eager execution. Pages returned by Google describe what it does for you, and I'm ok with that. I am trying to understand it from the point of view of program code. Here is an example from <a href=""https://towardsdatascience.com/eager-execution-tensorflow-8042128ca7be"" rel=""nofollow noreferrer"">this article</a>.</p>

<pre><code>a = tf.constant([[1,2],[3,4]])
</code></pre>

<p>The article says this statement does something different depending on whether you are in eager mode or not. Without eager mode, print(a) gives:</p>

<pre><code>Tensor(""Const:0"", shape=(2, 2), dtype=int32)
</code></pre>

<p>With eager mode, print(a) gives:</p>

<pre><code>tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32)
</code></pre>

<p>Please could someone explain what these two return values are. If they are two different object types, a Tensor and a tf.Tensor, what is the difference between these objects?</p>

<p>I have searched the TensorFlow documentation and can't see anything that addresses this distinction. Any pointers gratefully received.</p>

<p>Thanks,</p>

<p>Julian</p>
",1,Inadequate Examples
341,58126494,How to Translate CSV Data into TFRecord Files,"<p>Currently I am working on a system that can take data from a CSV file and import it into a TFRecord file, However I have a few questions.</p>

<p>For starters, I need to know what type a TFRecord file can take, when using CSV types are removed.</p>

<p>Secondly, How can I convert data type:object into a type that a TFRecord can take?</p>

<p>I have two columns (will post example below) of two objects types that are strings, How can I convert that data to the correct type for TFRecords?</p>

<p>When importing Im hoping to append data from each row at a time into the TFRecord file, any advice or documentation would be great, I have been looking for some time at this problem and it seems there can only be ints,floats inputted into a TFRecord but what about a list/array of Integers?</p>

<p>Thankyou for reading!</p>

<p>Quick Note, I am using PANDAS to create a dataframe of the CSV file</p>

<p>Some Example Code Im using </p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
from ast import literal_eval
import numpy as np
import tensorflow as tf


tf.compat.v1.enable_eager_execution()


def Start():
    db = pd.read_csv(""I:\Github\ClubKeno\Keno Project\Database\..\LotteryDatabase.csv"")

    pd.DataFrame = db
    print(db['Winning_Numbers'])
    print(db.dtypes)

    training_dataset = (
        tf.data.Dataset.from_tensor_slices(
            (
                tf.cast(db['Draw_Number'].values, tf.int64),
                tf.cast(db['Winning_Numbers'].values, tf.int64),
                tf.cast(db['Extra_Numbers'].values, tf.int64),
                tf.cast(db['Kicker'].values, tf.int64)
            )
        )
    )

    for features_tensor, target_tensor in training_dataset:
        print(f'features:{features_tensor} target:{target_tensor}')
</code></pre>

<p>Error Message:</p>

<p><img src=""https://cdn.discordapp.com/attachments/279786369902051328/626967249395122213/Capture.PNG"" alt=""Error Message""></p>

<p><a href=""https://cdn.discordapp.com/attachments/502661247809093673/626946732239880194/LotteryDatabase.csv"" rel=""nofollow noreferrer"">CSV Data</a></p>

<p>Update:
Got Two Columns of dating working using the following function...</p>

<pre class=""lang-py prettyprint-override""><code>dataset = tf.data.experimental.make_csv_dataset(
        file_pattern=databasefile,
        column_names=['Draw_Number', 'Kicker'],
        column_defaults=[tf.int64, tf.int64],
    )
</code></pre>

<p>However when trying to include my two other column object types
(What data looks like in both those columns)
<code>""3,9,11,16,25,26,28,29,36,40,41,46,63,66,67,69,72,73,78,80""</code></p>

<p>I get an error, here is the function I tried for that</p>

<pre class=""lang-py prettyprint-override""><code>    dataset = tf.data.experimental.make_csv_dataset(
        file_pattern=databasefile,
        column_names=['Draw_Number', 'Winning_Numbers', 'Extra_Numbers', 'Kicker'],
        column_defaults=[tf.int64, tf.compat.as_bytes, tf.compat.as_bytes, tf.int64],
        header=True,
        batch_size=100,
        field_delim=',',
        na_value='NA'
    )
</code></pre>

<p>This Error Appears:</p>

<pre><code>TypeError: Failed to convert object of type &lt;class 'function'&gt; to Tensor. Contents: &lt;function as_bytes at 0x000000EA530908C8&gt;. Consider casting elements to a supported type.
</code></pre>

<p>Should I try to Cast those two types outside the function and try combining it later into the TFRecord file alongside the tf.data from the <code>make_csv_dataset</code> function? </p>
",1,Requesting (Additional) Documentation/Examples
342,58176215,Tensorflow difference between tf.stop_gradient and feed variables to optimizer?,"<p>I'm trying to train a model in <strong>self-supervised learning</strong>. The flow chart is something like the following:
<a href=""https://i.stack.imgur.com/g2yMn.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/g2yMn.jpg"" alt=""enter image description here""></a></p>

<p>Let's assume that <code>N1</code> is already trained and we want to train just <code>N2</code>. This is my current implementation:</p>

<pre><code>x_1 = tf.placeholder(tf.float32, [None, 128, 128, 1])
x_2 = tf.placeholder(tf.float32, [None, 128, 128, 1])

s_t1 = tf.stop_gradient(N1(x_1))  # treat s_t1 as a constant
s_t2_pred = N2(s_t1)) 
s_t2 = tf.stop_gradient(N1(x_2))  # treat s_t2 as a constant

loss = some_loss_function(s_t2, s_t2_pred)
train_op = tf.train.AdamOptimizer(lr).minimize(loss)
</code></pre>

<p>In this way, I should be optimizing only <code>N2</code>. What makes me confused is the fact that if I were to use the following code I would obtain very different results (much better than the above): </p>

<pre><code># treat everything as a variable:
s_t1 = N1(x_1)
s_t2_pred = N2(s_t1)
s_t2 = N1(x_2)

loss = some_loss_function(s_t2, s_t2_pred)
var_list = take_all_variables_in_N2()
train_op = tf.train.AdamOptimizer(lr).minimize(loss, var_list)
</code></pre>

<p>I wonder what is the problem with the first implementation. What is exactly the behaviour of <code>tf.stop_gradient</code> (the documentation is a bit poor)? How does this differ from the second approach?</p>

<p>From a practical perspective in semi-supervised learning: what is the difference between the two? Which one is the correct approach?</p>

<p>Thank you :) </p>

<hr>

<hr>

<p><strong>I added a possible solution to the problem in the comments below. I would still be happy to receive any feedback from more experienced users and to share some opinions on the best approach to structure a self-supervised learning problem in tensorflow.</strong></p>

<p>Bye, G.</p>
",1,Documentation Replication on Other Examples
343,58186564,TensorFlow multi class training and prediction,"<p>The following code (working), train a model to recognize cats and make a prediction on the selected picture. (Code TensorFlowJS but the question is generally TensorFlow)<br>
So far it is only predicting one class (""cat""), so that a car or a dog would be for example 80% a cat. 
<br><br>
Question:<br>
How do i add other classes (like ""dog"") ? <br>
Should it look like that (abstracted): model.fit([img1, img2, img3], [label1, label2, label3] ...) ?<br>
<br>
I don't get it:<br>
What is the relation between the labels and the training set.<br></p>

<p>Here is the code (please ignore the ""Predict"" part for now):</p>

<pre><code>&lt;head&gt;
    &lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2.7""&gt; &lt;/script&gt;
    &lt;script src=""https://unpkg.com/@tensorflow-models/mobilenet""&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class=""container mt-5""&gt;
        &lt;div class=""row""&gt;
            &lt;input id =""image-selector"" class=""form-control border-0"" type=""file""/&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col""&gt;
                &lt;h2&gt;Prediction&lt;/h2&gt;
                &lt;ol id=""prediction-list""&gt;&lt;/ol&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-12""&gt;
                &lt;h2 class=""ml-3""&gt;Image&lt;/h2&gt;
                &lt;canvas id=""canvas"" width=""400"" height=""300"" style=""border:1px solid #000000;""&gt;&lt;/canvas&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div  id=""training-images""&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat.jpg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat3.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat4.jpeg"" /&gt;

        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog3.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog4.jpeg"" /&gt;
    &lt;/div&gt;
&lt;/body&gt;

&lt;script&gt;
    const modelType = ""mobilenet"";
    const model = tf.sequential();
    const label = ['cat'];
    var ys, setLabel, input, canvas, context;
    input = document.getElementById(""image-selector"");
    canvas = document.getElementById(""canvas"");
    context = canvas.getContext('2d');

    //-------------------------- Training: --------------------------------
    window.addEventListener('load', (event) =&gt; {
        // Labels
        setLabel = Array.from(new Set(label));
        ys = tf.oneHot(tf.tensor1d(label.map((a) =&gt; setLabel.findIndex(e =&gt; e === a)), 'int32'), 10);
        console.log('ys:::'+ys);

        // Prepare model :
        model.add(tf.layers.conv2d({
            inputShape: [224, 224 , 3],
            kernelSize: 5,
            filters: 8,
            strides: 2,
            activation: 'relu',
            kernelInitializer: 'VarianceScaling'
        }));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.flatten({}));
        model.add(tf.layers.dense({units: 64, activation: 'relu'}));
        model.add(tf.layers.dense({units: 10, activation: 'softmax'}));
        model.compile({
            loss: 'meanSquaredError',
            optimizer : 'sgd'
        });

        // Prepare training images
        var images = [];
        for(var i = 0; i &lt; 40; i++) {
            let img = preprocessImage(document.getElementsByClassName(""cat"")[i], modelType);
            images.push(tf.reshape(img, [1, 224, 224, 3],'resize'));
        }
        console.log(""processed images : "");
        console.log(images);
        trainModel(images);
    });

    async function trainModel(images) {
        for(var i = 0; i &lt; images.length; i++) {
            await model.fit(images[i], ys, {epochs: 100, batchSize: 32}).then((loss) =&gt; {
            const t = model.predict(images[i]);
            console.log('Prediction:::'+t);
            pred = t.argMax(1).dataSync(); // get the class of highest probability
            const labelsPred = Array.from(pred).map(e =&gt; setLabel[e]);
            console.log('labelsPred:::'+labelsPred);
            }).catch((e) =&gt; {
                console.log(e.message);
            })
        }
        console.log(""Training done!"");
    }

    //-------------------------- Predict: --------------------------------
    input.addEventListener(""change"", function() {
        var reader = new FileReader();
        reader.addEventListener(""loadend"", function(arg) {
            var src_image = new Image();
            src_image.onload = function() {
                canvas.height = src_image.height;
                canvas.width = src_image.width;
                context.drawImage(src_image, 0, 0);
                var imageData = canvas.toDataURL(""image/png""); 
                runPrediction(src_image)
            }
            src_image.src = this.result;
        });
        var res = reader.readAsDataURL(this.files[0]);
    });

    async function runPrediction(imageData){
        let tensor = preprocessImage(imageData, ""mobilenet"");
        const resize_image = tf.reshape(tensor, [1, 224, 224, 3],'resize');
        let prediction = await model.predict(tensor).data();
        console.log('prediction:::'+ prediction);

        let top5 = Array.from(prediction)
        .map(function(p,i){
            return {
                probability: p,
                className: prediction[i]
            };
        }).sort(function(a,b){
            return b.probability-a.probability;
        }).slice(0,1);

        $(""#prediction-list"").empty();
        top5.forEach(function(p){
            $(""#prediction-list"").append(`&lt;li&gt;${p.className}:${p.probability.toFixed(6)}&lt;/li&gt;`);
        });
    }

    //-------------------------- Helpers: --------------------------------
    function preprocessImage(image, modelName)
    {
        let tensor = tf.browser.fromPixels(image)
        .resizeNearestNeighbor([224,224])
        .toFloat();

        let offset=tf.scalar(127.5);

        return tensor.sub(offset)
        .div(offset)
        .expandDims();
    }
&lt;/script&gt;
</code></pre>

<p>The code is based on the TFJS documentation and a comment on the github : <a href=""https://github.com/tensorflow/tfjs/issues/1288"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tfjs/issues/1288</a></p>

<p><strong>UPDATE :</strong>
So I need X and Y to be the same length for X:images and Y:labels, with Y1 being the label for X1 and so on...
<br><br>
I tried:</p>

<pre><code>ys:::Tensor (with only 2 classes represented in the training data set) :
    [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]
</code></pre>

<p><br><br>
One image + all labels -> with ""model.fit(images[i], ys, {epochs: 100})..."", I get:
<br>Error: ""Input Tensors should have the same number of samples as target Tensors. Found 1 input sample(s) and 10 target sample(s).""
<br><br>
One image + one label -> with ""model.fit(images[i], ys[i], {epochs: 100})..."", I get:
<br>Error: ""Cannot read property 'shape' of null"", i guess ys is a tensor but y[i] is not.
<br><br>
All images + all labels -> with ""model.fit(images, ys, {epochs: 100})..."", I get:
<br>Error: ""when checking model input: the Array of Tensors that you are passing to your model is not the size the model expected. 
Expected to see 1 Tensor(s), but instead got the following list of Tensor(s): Tensor ...""
<br><br>
Guess: I need to put all images in one tensor with the same structure as ys.</p>

<p><strong>SOLVED :</strong>
<br>
After solving the problem with the labels thanks to Rishabh Sahrawat, I had to merge all tensor(images) in to one with the help of tf.concat(...).</p>

<pre><code>[tensorImg1, tensorImg2, tensorImg3, tensorImg4, ...] x tensor[label1, label2, label3, label4, ...]
-&gt; 
tensor[dataImg1, dataImg2, dataImg3, dataImg4, ...] x tensor[label1, label2, label3, label4, ...]
</code></pre>

<p>Updated code :</p>

<pre><code>&lt;head&gt;
    &lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2.7""&gt; &lt;/script&gt;
    &lt;script src=""https://unpkg.com/@tensorflow-models/mobilenet""&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class=""container mt-5""&gt;
        &lt;div class=""row""&gt;
            &lt;input id =""image-selector"" class=""form-control border-0"" type=""file""/&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col""&gt;
                &lt;h2&gt;Prediction&lt;/h2&gt;
                &lt;ol id=""prediction-list""&gt;&lt;/ol&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=""row""&gt;
            &lt;div class=""col-12""&gt;
                &lt;h2 class=""ml-3""&gt;Image&lt;/h2&gt;
                &lt;canvas id=""canvas"" width=""400"" height=""300"" style=""border:1px solid #000000;""&gt;&lt;/canvas&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div  id=""training-images""&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat.jpg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image cat"" src=""training-images/cat3.jpeg"" /&gt;

        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog2.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog3.jpeg"" /&gt;
        &lt;img width=""400"" height=""300"" class=""train-image dog"" src=""training-images/dog4.jpeg"" /&gt;
    &lt;/div&gt;
&lt;/body&gt;

&lt;script&gt;
    const modelType = ""mobilenet"";
    const model = tf.sequential();
    var labels = ['cat', 'dog'];
    var ys, setLabel, input, canvas, context;
    input = document.getElementById(""image-selector"");
    canvas = document.getElementById(""canvas"");
    context = canvas.getContext('2d');

    //-------------------------- Training: --------------------------------
    window.addEventListener('load', (event) =&gt; {        
        // Prepare model :
        prepareModel();

        // Prepare training images
        var images = [];
        var trainLabels = []
        for(var i = 0; i &lt; document.getElementsByClassName('train-image').length; i++) {
            let img = preprocessImage(document.getElementsByClassName('train-image')[i], modelType);
            //images.push(tf.reshape(img, [1, 224, 224, 3],'resize'));
            images.push(img);
            if (document.getElementsByClassName('train-image')[i].classList.contains(""cat"")){
                trainLabels.push(0)
            } else {
                trainLabels.push(1)
            }
        }

        console.log(labels)
        setLabel = Array.from(labels);
        ys = tf.oneHot(trainLabels, 2);
        console.log('ys:::'+ys);
        console.log(images);
        trainModel(images);
    });

    async function trainModel(images) {
        for(var i = 0; i &lt; images.length; i++) {
            await model.fit(tf.concat(images, 0), ys, {epochs: 100}).then((loss) =&gt; {
            const t = model.predict(images[i]);
            console.log('Prediction:::'+t);
            pred = t.argMax().dataSync(); // get the class of highest probability
            //const labelsPred = Array.from(pred).map(e =&gt; setLabel[e]);
            //console.log('labelsPred:::'+labelsPred);
            }).catch((e) =&gt; {
                console.log(e.message);
            })

        }
        console.log(""Training done!"");
    }

    //-------------------------- Predict: --------------------------------
    input.addEventListener(""change"", function() {
        var reader = new FileReader();
        reader.addEventListener(""loadend"", function(arg) {
            var src_image = new Image();
            src_image.onload = function() {
                canvas.height = src_image.height;
                canvas.width = src_image.width;
                context.drawImage(src_image, 0, 0);
                var imageData = canvas.toDataURL(""image/png""); 
                runPrediction(src_image)
            }
            src_image.src = this.result;
        });
        var res = reader.readAsDataURL(this.files[0]);
    });

    async function runPrediction(imageData){
        let tensor = preprocessImage(imageData, ""mobilenet"");
        const resize_image = tf.reshape(tensor, [1, 224, 224, 3],'resize');
        let prediction = await model.predict(tensor).data();
        console.log('prediction:::'+ prediction);

        let top5 = Array.from(prediction)
        .map(function(p,i){
            return {
                probability: p,
                className: prediction[i]
            };
        }).sort(function(a,b){
            return b.probability-a.probability;
        }).slice(0,1);

        $(""#prediction-list"").empty();
        top5.forEach(function(p){
            $(""#prediction-list"").append(`&lt;li&gt;${p.className}:${p.probability.toFixed(6)}&lt;/li&gt;`);
        });
    }

    //-------------------------- Helpers: --------------------------------

    function prepareModel(){
        model.add(tf.layers.conv2d({
            inputShape: [224, 224 , 3],
            kernelSize: 5,
            filters: 8,
            strides: 2,
            activation: 'relu',
            kernelInitializer: 'VarianceScaling'
        }));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.maxPooling2d({poolSize: 2, strides: 2}));
        model.add(tf.layers.flatten({}));
        model.add(tf.layers.dense({units: 64, activation: 'relu'}));
        model.add(tf.layers.dense({units: 2, activation: 'softmax'}));
        model.compile({
            loss: 'meanSquaredError',
            optimizer : 'sgd'
        });
        model.summary()
    }

    function preprocessImage(image, modelName)
    {
        let tensor = tf.browser.fromPixels(image)
        .resizeNearestNeighbor([224,224])
        .toFloat();

        let offset=tf.scalar(127.5);

        return tensor.sub(offset)
        .div(offset)
        .expandDims();
    }
&lt;/script&gt;
</code></pre>
",1,Documentation Replication on Other Examples
344,58225926,Tensorflow Gradient Tape returning None,"<p>I'm using TensorFlow 1.14.0 with Python(3.6.8). I'm trying to use tensorflow_probability's lbfgs optimizer implementation(<a href=""https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer/lbfgs_minimize"" rel=""nofollow noreferrer"">documentation/example</a>).</p>

<p>If I run the example code provided in the documentation it works fine. I tried to follow the same procedure for my own code which uses the <code>tf.GradientTape()</code> approach for computing the objective function. When doing it that way, the gradients come back as <code>None</code> type.</p>

<p>I'm not seeing why one is working, but the other is not.</p>

<p>Edit: I realized that running eager execution using the gradients wouldn't work, so I adjusted the example to be able to be run with eager execution.</p>

<p>Non-working example(using GradientTape) with eager execution</p>

<pre><code>import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp

tf.enable_eager_execution()

# A high-dimensional quadratic bowl.
ndims = 3
minimum = np.ones([ndims], dtype='float64')
scales = np.arange(ndims, dtype='float64') + 1.0

# The objective function and the gradient.
def quadratic(x):
    with tf.GradientTape() as g:
        value = tf.reduce_sum(scales * (x - minimum) ** 2)
    grads = g.gradient(value, x)
    print('Gradients: ')
    print(grads)
    return value, grads

start = np.arange(ndims, 0, -1, dtype='float64')
optim_results = tfp.optimizer.lbfgs_minimize(quadratic, initial_position=start, num_correction_pairs=10,tolerance=1e-8)

print('results')
print(optim_results)
# Check that the search converged
assert(optim_results.converged)
# Check that the argmin is close to the actual value.
np.testing.assert_allclose(optim_results.position, minimum)
</code></pre>
",1,Documentation Replication on Other Examples
345,58338310,Predefined layers inside Custom layers,"<p>I want to use predefined layers from tf.keras.layers inside a custom layer. I want to create a custom layer that is a combination of dense and 1D Convolution layers.
Is it possible to do something like that? I could not find an example in the tensorflow pages.</p>
",1,Lack of Alternative Solutions/Documentation
346,58384884,'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction',"<p>I am using Huber loss implementation in tf.keras in tensorflow 1.14.0 as follows:</p>

<pre><code>huber_keras_loss = tf.keras.losses.Huber(
        delta=delta,
        reduction=tf.keras.losses.Reduction.SUM,
        name='huber_loss'
    )
</code></pre>

<p>I am getting the error 
AttributeError: module 'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction'</p>

<p>I have tried using tf.losses.Reduction, tf.compat.v2.losses.Reduction nothing seems to work.</p>

<p>Did tensorflow remove Reduction from tf.keras.losses, it is strange if they did so because their documentation still shows:
<a href=""https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/losses/Huber#args"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/losses/Huber#args</a></p>
",1,Documentation Ambiguity
347,58520594,"tf.Data.Dataset - On each Epoch, only train with a sub sample of the full dataset","<p>I have an image dataset with a large imbalance of positive and negatives samples (many more negatives). I would like to create a tf.data.Dataset where each epoch it will train with all of the positive samples but only (ratio * len(positive) ) of the negative samples. </p>

<p>I am currently using a datagen inherited from keras.util.Sequence to achieve this and using this subsampling policy is performing much better than training on all data.</p>

<p>However reading the docs on Dataset, I cannot seem to find a way to do it, is it possible?</p>

<p>In my existing data generator, I am doing this:</p>

<pre class=""lang-py prettyprint-override""><code># List if indicies of the positive and negative samples
positives = np.where(self.labels == 1)[0]
negatives = np.where(self.labels == 0)[0]
# How many of the negatives do we want to use?
n_negatives = np.clip(int(len(positives) * self.config.DATASET_NEGSUBSAMPLE_RATIO), 1, len(negatives))
# Choose random negatives
subsampled_negatives = np.random.choice(negatives, n_negatives, replace=False)
# Create the incidies array from the positive and subsamples negative indicies
self.indexes = np.concatenate((positives, subsampled_negatives))
# Shuffle them together
np.random.shuffle(self.indexes)
</code></pre>
",1,Lack of Alternative Solutions/Documentation
348,58550146,How to use the tf.keras.layers.BatchNormalization() in custom training loop?,"<p>I went back to tensorflow after quite a while and it seems the landscape is completely changed.</p>

<p>However, previously I used to use <code>tf.contrib....batch_normalization</code> with the following in the training loop:</p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    train_op = optimizer.minimize(cnn.loss, global_step=global_step)
</code></pre>

<p>But it seems, <code>contrib</code> is nowhere to be found and <code>tf.keras.layers.BatchNormalization</code> does not work the same way. Also, I couldn't find any training instruction in their <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""nofollow noreferrer"">documentation</a>.</p>

<p>So, any information of help is appreciated.</p>
",1,Lack of Alternative Solutions/Documentation
349,58631390,What is the purpose of tf.compat?,"<p>What's the purpose of tf.compat module? It looks like just the entire Tensorflow API is replicated inside this module.
The documentation states</p>

<blockquote>
  <p>Functions for Python 2 vs. 3 compatibility.</p>
</blockquote>

<p>So why there is a ""v1"" and a ""v2"" submodule? What are the compatibility problems address by tf.compat specifically?</p>
",1,Documentation Completeness
350,58730460,Freeze sublayers in tensorflow 2,"<p>I have a model which is composed of custom layers. Each custom layer contains many tf.keras.layers. The problem is that if I want to freeze those layers after defining my model, the loop:</p>

<pre><code>for i, layer in enumerate(model.layers):
    print(i, layer.name)
</code></pre>

<p>only prints the ""outer"" custom layers and not those who exist inside. Is there any way to access the inner layers so I can freeze them?</p>

<p>an example of a custom layer from the <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">official tf docs</a>:</p>

<pre><code>class MLPBlock(layers.Layer):

  def __init__(self):
    super(MLPBlock, self).__init__()
    self.linear_1 = Linear(32)
    self.linear_2 = Linear(32)
    self.linear_3 = Linear(1)

  def call(self, inputs):
    x = self.linear_1(inputs)
    x = tf.nn.relu(x)
    x = self.linear_2(x)
    x = tf.nn.relu(x)
    return self.linear_3(x)
</code></pre>
",1,Documentation Replication on Other Examples
351,58748202,Difference between feature_column.embedding_column and keras.layers.Embedding in TensorFlow,"<p>I have been using <strong>keras.layers.Embedding</strong> for almost all of my projects. But, recently I wanted to fiddle around with tf.data and found <strong>feature_column.embedding_column</strong>.</p>

<p>From the documentation:</p>

<p><strong>feature_column.embedding_column</strong> - 
<code>DenseColumn</code> that converts from sparse, categorical input.
  Use this when your inputs are sparse, but you want to convert them to a dense
  representation (e.g., to feed to a DNN).</p>

<p><strong>keras.layers.Embedding</strong> - Turns positive integers (indexes) into dense vectors of fixed size.
  e.g. <code>[[4], [20]] -&gt; [[0.25, 0.1], [0.6, -0.2]]</code>
  This layer can only be used as the first layer in a model.</p>

<p>My question is, is both of the api doing similar thing on different type of input data(for ex. input - [0,1,2] for keras.layers.Embedding and its one-hot-encoded rep. [[1,0,0],[0,1,0],[0,0,1] for feature_column.embedding_column)?</p>
",1,Documentation Replication on Other Examples
352,58818679,Why a model using tf.py_function can not be serialized?,"<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer"">documentation</a> of ty.py_function a model using it can't be serialized.</p>

<blockquote>
  <p>The body of the function (i.e. func) will not be serialized in a GraphDef. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.</p>
</blockquote>

<p>Why is serialization not possible?</p>

<p>I was looking for an explanation to why this is the case and alternatives to using tf.py_function but did not find helpful ones.</p>

<p>In my specific case I want to use the Keras Tokenizer and its methods expect numpy arrays - so I am calling it using tf.py_function.</p>
",1,Lack of Alternative Solutions/Documentation
353,58822319,How to use tfa.seq2seq.BahdanauAttention with tf.keras functional API?,"<p>I want to use <a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/BahdanauAttention"" rel=""nofollow noreferrer""><code>tfa.seq2seq.BahdanauAttention</code></a> with functional API of <code>tf.keras</code>. I have looked at the example given at <a href=""https://github.com/tensorflow/nmt/blob/master/nmt/attention_model.py"" rel=""nofollow noreferrer"">tensorflow/nmt/attention_model.py</a>. But I couldn't figure out how to use it with <code>tf.keras</code>'s functional API.</p>

<p>So I would like to use <code>tfa.seq2seq.BahdanauAttention</code> for a lipreading task, something like this:</p>

<pre class=""lang-py prettyprint-override""><code>
    # Using tf.keras functional API
    encoder_out = a tensor of shape (batch_size, time_steps, units)
    decoder_out = a tensor of shape (batch_size, time_steps, units)
    attn_out = attention_mechanism()(encoder_out, decoder_out)  # Need help figuring this out

</code></pre>

<p>Thanks in advance.</p>
",1,Documentation Ambiguity
354,58842107,How do I update a model using a pre-release version of Tensorflow to run in a Google Colab instance?,"<p>I'm trying to use the <a href=""https://github.com/google-research-datasets/wiki-reading"" rel=""nofollow noreferrer"">WikiReading</a> dataset and model in a project and train it using a Google Colaboratory instance. For that purpose, I'm adapting the code to a Jupyter Notebook, which also uses a more recent version of Tensorflow than the provided baseline Bag of Words model did. The original paper and accompanying baseline model was published in August 2016, which predates Tensorflow 1.0.0.</p>

<p>I've gone some way towards the process of updating the model to Tensorflow v1.x, but I appear to have hit a roadblock. From my (fairly limited) understanding, the last step in the model is to apply a softmax function on the results. In the original model, this was done using the following function call:</p>

<pre><code>softmax, loss = tf.contrib.learn.ops.softmax_classifier(
        joint_enc, answers, answer_embeddings, answer_biases)
</code></pre>

<p>This is then used in this statement for the optimization:</p>

<pre><code>train_op = tf.contrib.layers.optimize_loss(
        loss, tf.contrib.framework.get_global_step(),
        learning_rate=LEARNING_RATE,
        optimizer='Adam')
</code></pre>

<p>I can't seem to find any documentation relating to the <code>tf.contrib.learn.ops.softmax_classifier()</code> function online. I'm assuming it takes in 4 tensors in some order, most likely something like the first holds the batch to classify, the second one holds a list of the answers to predict with the 3rd and 4th holding the embedding and biases for each answer.</p>

<p>My problem is that I cannot find a function that maps neatly to that format with the same output and I'm not sure what transformations to apply to my tensors to get a similar result using something like <code>tf.nn.softmax()</code> without access to the documentation of <code>tf.contrib.learn.ops.softmax_classifier()</code>. How should I go about tackling this problem? Should I just rewrite the model_fcn()?</p>

<h2>Original model_fn()</h2>

<pre class=""lang-py prettyprint-override""><code>def bow_model(features, target):
    document = utils.prune_out_of_vocab_ids(features['document_sequence'], VOCAB_SIZE)
    question = utils.prune_out_of_vocab_ids(features['question_sequence'], VOCAB_SIZE)
    answers = tf.squeeze(tf.one_hot(target, ANSWER_NUM, 1.0, 0.0),
                         squeeze_dims=[1])
    embeddings = tf.get_variable('embeddings', [VOCAB_SIZE, EMBED_DIM])
    doc_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], document, None, combiner='sum')
    question_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], question, None, combiner='sum')
    joint_enc = tf.concat(1, [doc_enc, question_enc])
    answer_embeddings = tf.get_variable(
        'answer_embeddings', [ANSWER_DIM, ANSWER_NUM])
    answer_biases = tf.get_variable('answer_biases', [ANSWER_NUM])
    softmax, loss = learn.ops.softmax_classifier(
        joint_enc, answers, answer_embeddings, answer_biases)
    train_op = layers.optimize_loss(
        loss, tf.contrib.framework.get_global_step(),
        learning_rate=LEARNING_RATE,
        optimizer='Adam')
    return softmax, loss, train_op
</code></pre>

<h2>Partially updated model_fn():</h2>

<pre class=""lang-py prettyprint-override""><code>def bow_model(features, labels, mode):
    document = prune_out_of_vocab_ids(features['document_sequence'], VOCAB_SIZE)
    question = prune_out_of_vocab_ids(features['question_sequence'], VOCAB_SIZE)

    answers = tf.squeeze(tf.one_hot(labels, ANSWER_NUM, 1.0, 0.0))

    embeddings = tf.get_variable('embeddings',
                                 [VOCAB_SIZE, EMBED_DIM])
    answer_embeddings = tf.get_variable('answer_embeddings',
                                        [ANSWER_DIM, ANSWER_NUM])
    answer_biases = tf.get_variable('answer_biases',
                                    [ANSWER_NUM])

    doc_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], document, None, combiner='sum')
    question_enc = layers.safe_embedding_lookup_sparse(
        [embeddings], question, None, combiner='sum')
    joint_enc = tf.concat(axis=1, values=[doc_enc, question_enc])

    # softmax, loss = tf.contrib.learn.ops.softmax_classifier(
    #     joint_enc, answers, answer_embeddings, answer_biases)
    # replaced by:
    logits = tf.nn.xw_plus_b(doc_enc, answer_embeddings, answer_biases)
    softmax = tf.nn.softmax(logits)
    loss = tf.losses.softmax_cross_entropy(onehot_labels=answers,
                                           logits=logits,
                                           weights=answer_embeddings)

    train_op = layers.optimize_loss(
        loss, tf.train.get_global_step(),
        learning_rate=LEARNING_RATE,
        optimizer='Adam')

    return learn.EstimatorSpec(mode=mode,
                               predictions=softmax,
                               loss=loss,
                               train_op=train_op)
</code></pre>

<h2>Original input_fn():</h2>

<pre class=""lang-py prettyprint-override""><code>def get_wikireading_input():
    filename = ""../train-*""
    feature_info = {k: tf.VarLenFeature(dtype=tf.int64) for k in SPARSE_FEATURES}
    feature_info['answer_ids'] = tf.VarLenFeature(dtype=tf.int64)
    def input_fn():
        features = learn.read_batch_features(
            filename, BATCH_SIZE, feature_info,
            reader=tf.TFRecordReader)
        target = features.pop('answer_ids')
        target = utils.resize_axis(tf.sparse_tensor_to_dense(target), 1, 1)
        return features, target
    return input_fn
</code></pre>

<h2>Updated input_fn()</h2>

<pre class=""lang-py prettyprint-override""><code>def input_fn():
    features = {'document_sequence': tf.VarLenFeature(dtype=tf.int64),
                'question_sequence': tf.VarLenFeature(dtype=tf.int64),
                'answer_ids': tf.VarLenFeature(dtype=tf.int64)}

    files = tf.data.Dataset.list_files(file_pattern=filename)
    dataset = files.interleave(tf.data.TFRecordDataset,
                          cycle_length=AUTOTUNE,
                          num_parallel_calls=AUTOTUNE)

    def parse_fn(serialized):
        example = tf.io.parse_single_sequence_example(serialized=serialized,
                                                      sequence_features=features)[1]
        labels = example.pop('answer_ids')
        labels = resize_axis(tf.sparse_tensor_to_dense(labels), 1, 1)
        return example, labels

    dataset = dataset.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)
    dataset = dataset.batch(batch_size=BATCH_SIZE)
    dataset = dataset.shuffle(buffer_size=BATCH_SIZE)
    dataset = dataset.prefetch(buffer_size=AUTOTUNE)
    return dataset
</code></pre>

<p>The full Jupyter notebook can be accessed <a href=""https://github.com/ThierrySt-Arnaud/wiki-reading/blob/colab-conversion/colab/wiki_reading_training_en.ipynb"" rel=""nofollow noreferrer"">here</a></p>

<h2>Edit:</h2>

<p>I have found the source for the mentioned function <a href=""https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/contrib/learn/python/learn/ops/losses_ops.py"" rel=""nofollow noreferrer"">here</a>. The deprecation warning  says this about updating this function:</p>

<blockquote>
  <p>'Use <code>tf.losses.softmax_cross_entropy</code> and explicit logits computation.'</p>
</blockquote>

<p>Now, I'm replicating the operations of this function as follows:</p>

<pre class=""lang-py prettyprint-override""><code>  logits = tf.nn.xw_plus_b(doc_enc, answer_embeddings, answer_biases)
  softmax = tf.nn.softmax(logits)
  loss = tf.losses.softmax_cross_entropy(answers, logits, answer_embeddings)
</code></pre>

<p>but this gives me:</p>

<blockquote>
  <p>ValueError Dimensions must be equal, but are 20 and 40 for 'xw_plus_b/MatMul' (op: 'BatchMatMulV2') with input shapes: [?,?,20], [40,5000].</p>
</blockquote>

<p>This makes perfect sense when I look at the constant definitions:</p>

<pre class=""lang-py prettyprint-override""><code>VOCAB_SIZE = 10000
EMBED_DIM = 20
ANSWER_DIM = 2 * EMBED_DIM
ANSWER_NUM = 5000
BATCH_SIZE = 128
LEARNING_RATE = 0.01
HIDDEN_SIZE = 128
</code></pre>

<p>I guess my questions now are:</p>

<ul>
<li>Why is ANSWER_NUM and ANSWER_DIM not equal to VOCAB_SIZE and EMBED_DIM, respectively? Shouldn't they have the same size?</li>
<li>How could this have worked before?</li>
</ul>

<h3>Edit 2:</h3>

<p>As I try to update and train this model, I have grown more and more confused by the way it is defined. This is largely due to my inexperience with machine learning in general and TensorFlow in particular, but there are some things that don't make sense, at least to me. I have adjusted the ANSWER_NUM and ANSWER_DIM as I mention above and updated other functions and parameters (seen in the updated model_fn above) which gives me a valid data graph but the following error when trying to fit:</p>

<blockquote>
  <p>(0) Invalid argument: assertion failed: [weights can not be broadcast to values.] [weights.shape=] [answer_embeddings/read:0] [20 10000] [values.shape=] [softmax_cross_entropy_loss/xentropy/Reshape_2:0] [128 0] [is_scalar=] [0]</p>
</blockquote>

<p>This probably just requires a formatting step (that I'm not entirely sure of yet) before feeding running softmax_cross_entropy(). However, I also noticed that there is no definition of the hidden layers anywhere in the original model and HIDDEN_SIZE is unused. Is there an implicit definition of those layers somewhere in the model that I'm missing?</p>

<p>At this point, I feel like it will be easier to just use a Keras functional model in TensorFlow 2.x to get as close as possible to the <em>perceived</em> original model.</p>
",1,Lack of Alternative Solutions/Documentation
355,58867494,"tf2.0: tf.image.resize_with_pad fails with ""using a `tf.Tensor` as a Python `bool"" with tf.keras.Input","<p>With <code>tensorflow 2.0</code>, <code>resize_with_pad</code> does not seem to work when <code>tf.keras.Input</code> is given as an input, but <code>resize</code> works nicely. For example,</p>

<pre><code>import tensorflow as tf

# with tensorflow constant
img_arr = tf.zeros([1,100,100,3])
tf.image.resize(img_arr, [224, 224]) # works
tf.image.resize_with_pad(img_arr, 224, 224) # works

# with keras input
img_arr = tf.keras.Input(shape = (100,100,3))
tf.image.resize(img_arr, [224, 224]) # works
tf.image.resize_with_pad(img_arr, 224, 224) # doesn't work
</code></pre>

<p>throws an error</p>

<pre><code>---------------------------------------------------------------------------
OperatorNotAllowedInGraphError            Traceback (most recent call last)
&lt;ipython-input-29-aee2cbd13944&gt; in &lt;module&gt;
      9 img_arr = tf.keras.Input(shape = (100,100,3))
     10 tf.image.resize(img_arr, [224, 224]) # works
---&gt; 11 tf.image.resize_with_pad(img_arr, 224, 224) # doesn't work

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in resize_image_with_pad_v2(image, target_height, target_width, method, antialias)
   1472 
   1473   return _resize_image_with_pad_common(image, target_height, target_width,
-&gt; 1474                                        _resize_fn)
   1475 
   1476 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _resize_image_with_pad_common(image, target_height, target_width, resize_fn)
   1337       raise ValueError('\'image\' must have either 3 or 4 dimensions.')
   1338 
-&gt; 1339     assert_ops = _CheckAtLeast3DImage(image, require_static=False)
   1340     assert_ops += _assert(target_width &gt; 0, ValueError,
   1341                           'target_width must be &gt; 0.')

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _CheckAtLeast3DImage(image, require_static)
    226         check_ops.assert_positive(
    227             array_ops.shape(image),
--&gt; 228             [""all dims of 'image.shape' ""
    229              'must be &gt; 0.']),
    230         check_ops.assert_greater_equal(

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_positive(x, data, summarize, message, name)
    266           'x (%s) = ' % name, x]
    267     zero = ops.convert_to_tensor(0, dtype=x.dtype)
--&gt; 268     return assert_less(zero, x, data=data, summarize=summarize)
    269 
    270 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_less(x, y, data, summarize, message, name)
    865       ]
    866     condition = math_ops.reduce_all(math_ops.less(x, y))
--&gt; 867     return control_flow_ops.Assert(condition, data, summarize=summarize)
    868 
    869 

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/util/tf_should_use.py in wrapped(*args, **kwargs)
    196   """"""
    197   def wrapped(*args, **kwargs):
--&gt; 198     return _add_should_use_warning(fn(*args, **kwargs))
    199   return tf_decorator.make_decorator(
    200       fn, wrapped, 'should_use_result',

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py in Assert(condition, data, summarize, name)
    147   """"""
    148   if context.executing_eagerly():
--&gt; 149     if not condition:
    150       xs = ops.convert_n_to_tensor(data)
    151       data_str = [_summarize_eager(x, summarize) for x in xs]

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in __bool__(self)
    763       `TypeError`.
    764     """"""
--&gt; 765     self._disallow_bool_casting()
    766 
    767   def __nonzero__(self):

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_bool_casting(self)
    532     else:
    533       # Default: V1-style Graph execution.
--&gt; 534       self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
    535 
    536   def _disallow_iteration(self):

/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_in_graph_mode(self, task)
    521     raise errors.OperatorNotAllowedInGraphError(
    522         ""{} is not allowed in Graph execution. Use Eager execution or decorate""
--&gt; 523         "" this function with @tf.function."".format(task))
    524 
    525   def _disallow_bool_casting(self):

OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
</code></pre>
",1,Documentation Replicability
356,58963793,ValueError: Shapes must be equal rank in assign_add(),"<p>I am reading <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">tf.Variable in Tensorflow r2.0</a> in TF2: </p>

<pre><code>import tensorflow as tf

# Create a variable.
w = tf.constant([1, 2, 3, 4], tf.float32, shape=[2, 2])

# Use the variable in the graph like any Tensor.
y = tf.matmul(w,tf.constant([7, 8, 9, 10], tf.float32, shape=[2, 2]))
v= tf.Variable(w)
# The overloaded operators are available too.
z = tf.sigmoid(w + y)
tf.shape(z)
# Assign a new value to the variable with `assign()` or a related method.
v.assign(w + 1)
v.assign_add(tf.constant([1.0, 21]))
</code></pre>

<blockquote>
  <p>ValueError: Shapes must be equal rank, but are 2 and 1 for
  'AssignAddVariableOp_4' (op: 'AssignAddVariableOp') with input shapes:
  [], <a href=""https://youtu.be/Up9CvRLIIIw?t=113"" rel=""nofollow noreferrer"">2</a>.</p>
</blockquote>

<p>And also how come the following returns false?</p>

<pre><code>tf.shape(v) == tf.shape(tf.constant([1.0, 21],tf.float32))
</code></pre>

<p>My other question is that when we are in TF 2, we should not use tf.Session() anymore, correct? It seems <a href=""https://youtu.be/Up9CvRLIIIw?t=113"" rel=""nofollow noreferrer"">we should never run session.run()</a>, but the API document keys doing it with tf.compat.v1, etc. So why they are using it in TF2 docs?</p>

<p>Any help would be appreciated.</p>

<p>CS</p>
",1,Documentation Completeness
357,59056872,Why class name change after saving a keras model?,"<p>i wrote a basic keras model (tf.keras.__version = 2.2.4-tf) using tensorflow (2.0.0) :</p>

<pre><code>import tensorflow as tf

model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(1, activation='linear',input_shape=(1,),name='equation'))
model.compile(optimizer='RMSprop', loss='mean_squared_error')
model.save('c:\\tmp\\oneneuron')
print(""Model saved type : "", type(model))
loaded_model = tf.keras.models.load_model('c:\\tmp\\oneneuron')
print(""Model loaded type : "", type(loaded_model))
print(""compare object model with loaded_model type : "",isinstance(model,type(loaded_model)))
print(""compare object loaded_model with model type : "",isinstance(loaded_model,type(model)))
print(""compare sublclass loaded_model and model type : "",issubclass(type(loaded_model),type(model)))
</code></pre>

<p>Results are </p>

<pre><code>Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; exec(open(r'C:\tmp\myPython\test_type_model.py').read())
2019-11-26 18:49:39.071088: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-11-26 18:49:39.574113: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING: Logging before flag parsing goes to stderr.
W1126 18:49:39.627490 11772 deprecation.py:506] From F:\Program Files\Python\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model saved type :  &lt;class 'tensorflow.python.keras.engine.sequential.Sequential'&gt;
Model loaded type :  &lt;class 'tensorflow.python.keras.saving.saved_model.load.Sequential'&gt;
compare object model with loaded_model type :  False
compare object loaded_model with model type :  True
compare sublclass loaded_model and model type :  True
</code></pre>

<p>Where can I find the difference between tensorflow.python.keras.saving.saved_model.load.Sequential and tensorflow.python.keras.engine.sequential.Sequential in tensorflow or keras documentation?</p>
",1,Lack of Alternative Solutions/Documentation
358,59074659,Best practice for allocating GPU and CPU resources in TensorFlow,"<p>I'm wondering what is the correct way to set devices for creating/training a model in order to optimize resource usage for speedy training in TensorFlow with the Keras API? I have 1 CPU and 2 GPUs at my disposal. I was initially using a <code>tf.device</code> context to create my model and train on GPUs only, but then I saw in the TensorFlow documentation for <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/multi_gpu_model"" rel=""nofollow noreferrer""><code>tf.keras.utils.multi_gpu_model</code></a>, they suggest explicitly instantiating the model on the CPU:</p>

<pre><code># Instantiate the base model (or ""template"" model).
# We recommend doing this with under a CPU device scope,
# so that the model's weights are hosted on CPU memory.
# Otherwise they may end up hosted on a GPU, which would
# complicate weight sharing.
with tf.device('/cpu:0'):
    model = Xception(weights=None,
                     input_shape=(height, width, 3),
                     classes=num_classes)

# Replicates the model on 8 GPUs.
# This assumes that your machine has 8 available GPUs.
parallel_model = multi_gpu_model(model, gpus=8)
parallel_model.compile(loss='categorical_crossentropy',
                       optimizer='rmsprop')
</code></pre>

<p>I did this, and now when I train I see my CPU usage go way up with all 8 cores at about 70% usage each, and my GPU memory is maxed out. Would things go faster if the model were created on one of the GPUs? Even if I have just 1 GPU, is it still better to create model on CPU and use <code>tf.device</code> context to train the model on the GPU?</p>
",1,Documentation Replication on Other Examples
359,59174710,default tf.gradients in TensorFlow - total or partial derivatives?,"<p>so I'm reading about tf.gradients() in the documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/gradients</a>) and I'm a bit confused.</p>

<p>I've seen people stating that the results of tf.gradients() are </p>

<blockquote>
  <p>symbolic partial derivatives of sum of ys w.r.t. x in xs.</p>
</blockquote>

<p>This is also what I was thinking first. But then the documentation describes one optional arguments of this function as follows:</p>

<blockquote>
  <p>stop_gradients is a Tensor or a list of tensors to be considered constant with respect to all xs. These tensors will not be backpropagated through, as though they had been explicitly disconnected using stop_gradient. Among other things, this allows computation of partial derivatives as opposed to total derivatives. </p>
</blockquote>

<p>So is it only possible to calculate the partial derivatives if I use 'stop_gradient' and otherwise the default values returned in a vector with len(xs) are total derivatives? Probably it's just my misunderstanding, it would be much appreciated if someone could elaborate on this a bit.</p>

<p>Thanks a lot!</p>
",1,Requesting (Additional) Documentation/Examples
360,59177677,Custom aggregation for tf.GradientTape().gradient? (TF2.0),"<p>As far as I know, the tf.gradients function provides option to choose the aggregation method for summarizing the gradients from multiple sources.
<a href=""https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/gradients</a></p>

<p>However according to the Tensorflow API documentation, the tf.GradientTape().gradient method has no such option.
<a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/GradientTape</a></p>

<p>So my questions are as follows:</p>

<ol>
<li><p>Is there any way to change the aggregation method in tf.GradientTape().gradient?</p></li>
<li><p>If not, is there any way to obtain the gradient with a custom aggregation method which is compatible with eager execution?</p></li>
</ol>
",1,Documentation Ambiguity
361,59299060,TF 2.0 while_loop and parallel_iterations,"<p>I am trying to use <code>tf.while_loop</code> to run loops in parallel. However, in the following toy examples,loops don't appear to be running in parallel. </p>

<pre><code>iteration = tf.constant(0)
c = lambda i: tf.less(i, 1000)
def print_fun(iteration):
    print(f""This is iteration {iteration}"")
    iteration+=1
    return (iteration,)
r = tf.while_loop(c, print_fun, [iteration], parallel_iterations=10)
</code></pre>

<p>Or</p>

<pre><code>i = tf.constant(0)
c = lambda i: tf.less(i, 1000)
b = lambda i: (tf.add(i, 1),)
r = tf.while_loop(c, b, [i])
</code></pre>

<p>What is preventing the <code>tf.while_loop</code> from parallelizing the loop?</p>

<p>In addition, if anyone who maintain the Tensorflow documentation see this page, he/she should fix the bug in the first example. See the discussion <a href=""https://github.com/tensorflow/tensorflow/issues/18257"" rel=""nofollow noreferrer"">here</a>.</p>

<p>Thanks.</p>
",1,Requesting (Additional) Documentation/Examples
362,59361689,Redundancies in tf.keras.backend and tensorflow libraries,"<p>I have been working in TensorFlow for about a year now, and I am transitioning from TF 1.x to TF 2.0, and I am looking for some guidance on how to use the <code>tf.keras.backend</code> library in TF 2.0. I understand that the transition to TF 2.0 is supposed to remove a lot of redundancies in modeling and building graphs, since there were many ways to create equivalent layers in earlier TensorFlow versions (and I'm insanely grateful for that change!), but I'm getting stuck on understanding when to use <code>tf.keras.backend</code>, because the operations appear redundant with other TensorFlow libraries. </p>

<p>I see that some of the functions in <code>tf.keras.backend</code> are redundant with other TensorFlow libraries. For instance, <code>tf.keras.backend.abs</code> and <code>tf.math.abs</code> are not aliases (or at least, they're not listed as aliases in the documentation), but both take the absolute value of a tensor. After examining the source code, it looks like <code>tf.keras.backend.abs</code> calls the <code>tf.math.abs</code> function, and so I really do not understand why they are not aliases. Other <code>tf.keras.backend</code> operations don't appear to be duplicated in TensorFlow libraries, but it looks like there are TensorFlow functions that can do equivalent things. For instance, <code>tf.keras.backend.cast_to_floatx</code> can be substituted with <code>tf.dtypes.cast</code> as long as you explicitly specify the dtype. I am wondering two things:</p>

<ol>
<li>when is it best to use the <code>tf.keras.backend</code> library instead of the equivalent TensorFlow functions?</li>
<li>is there a difference in these functions (and other equivalent <code>tf.keras.backend</code> functions) that I am missing?</li>
</ol>
",1,Documentation Replication on Other Examples
363,59458980,How to print the tensorflow objects?,"<pre class=""lang-py prettyprint-override""><code>def model_fn_builder(num_labels, learning_rate, num_train_steps,
                     num_warmup_steps):
  """"""Returns `model_fn` closure for TPUEstimator.""""""
  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument
    """"""The `model_fn` for TPUEstimator.""""""

    input_ids = features[""input_ids""]
    input_mask = features[""input_mask""]
    segment_ids = features[""segment_ids""]
    label_ids = features[""label_ids""]

    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)         

    # TRAIN and EVAL
    if not is_predicting:
      (loss, predicted_labels, log_probs) = create_model(
        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)



      train_op = bert.optimization.create_optimizer(
          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)


  # Return the actual model function in the closure
  return model_fn
</code></pre>

<p>I want to print <code>label_ids</code>, <code>predicted_labels</code> and <code>log_probs</code> but I am not able achieve it using <code>tf.print</code>. </p>

<p>My model is having a very poor accuracy so i need to check it step by step. Hence I want to print the tensor objects step by step when I cal the function.
I am using <code>tf 1.15</code>.</p>
",1,Documentation Replicability
364,59497372,Is there an alternative to tf.py_function() for custom Python code?,"<p>I have started using TensorFlow 2.0 and have a little uncertainty with regard to one aspect.</p>

<p>Suppose I have this use case: while ingesting data with the <code>tf.data.Dataset</code> I want to apply some specific augmentation operations upon some images. However, the external libraries that I am using <strong>require</strong> that the <strong>image is a numpy array</strong>, <strong>not a tensor</strong>.</p>

<p>When using <code>tf.data.Dataset.from_tensor_slices()</code>, the flowing data needs to be of type Tensor. Concrete example:</p>

<pre><code>def my_function(tensor_image):
   print(tensor_image.numpy()
   return


data = tf.data.Dataset.from_tensor_slices(tensor_images).map(my_function)
</code></pre>

<p>The code above does not work yielding an </p>

<blockquote>
  <p>'Tensor' object has no attribute 'numpy' error.</p>
</blockquote>

<p>I have read the documentation on TensorFlow 2.0 stating that if one wants to use an arbitrary python logic, one should use <code>tf.py_function</code> <strong>or only TensorFlow primitives</strong> according to:
<a href=""https://stackoverflow.com/questions/56075037/how-to-convert-tensor-to-numpy-array-in-tensorflow"">How to convert &quot;tensor&quot; to &quot;numpy&quot; array in tensorflow?</a> </p>

<p><strong>My question is the following</strong>: Is there another way to use arbitrary python code in a function with a custom decorator/an easier way than to use <code>tf.py_function</code>?</p>

<p>To me honestly it seems that there must be a more elegant way than passing to a <code>tf.py_function</code>, transforming to a numpy array, perform operations A,B,C,D and then retransform to a tensor and yield the result. </p>
",1,Lack of Alternative Solutions/Documentation
365,59531864,Why does TensorFlow calculate 2D convolutions when 1D convolution is called?,"<p>In the documentation of tf.nn.conv1d, it is stated that</p>

<blockquote>
  <p>Internally, this op reshapes the input tensors and invokes tf.nn.conv2d. For example, if data_format does not start with ""NC"", a tensor of shape [batch, in_width, in_channels] is reshaped to [batch, 1, in_width, in_channels], and the filter is reshaped to [1, filter_width, in_channels, out_channels]. The result is then reshaped back to [batch, out_width, out_channels] (where out_width is a function of the stride and padding as in conv2d) and returned to the caller.</p>
</blockquote>

<p>I get that the operations are equivalent, but I am a bit confused about the implications of this implementation detail. </p>

<p>Does the reshaping create some computational overhead? 
The 3D convolution has its own implementation, so why not the 1D convolution?</p>

<p>Thanks for any explanation that helps me and others to understand this implementation detail of TensorFlow!</p>
",1,Documentation Replicability
366,59555206,keras to tf.keras Conversion: Dense layer dimensions not defined?,"<p>So I've built a convnet using pure <code>keras</code>. It compiles and operates exactly as intended, but I need to convert it to use <code>tf.keras</code> so that I can make use of <code>tfmot</code>. Having read documentation, I attempted to convert it, only to get the following error:</p>

<p><code>The last dimension of the inputs to Dense should be defined. Found None.</code> </p>

<p>Any idea what I'm doing wrong?</p>

<p>Thanks!</p>

<p>Original <code>keras</code> model:</p>

<pre><code>input_layer = keras.layers.Input(shape=(100,))
reshape_layer = keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = keras.layers.Flatten()(conv_layer_5)
label_layer = keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = keras.layers.Dense(1, activation=""linear"")(label_layer)

model = keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>Converted <code>tf.keras</code> model:</p>

<pre><code>input_layer = tf.keras.layers.InputLayer(input_shape=(100,))
reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>EDIT 1:</p>

<p>I thought maybe I could get around the issue by saving the <code>keras</code> model after creation and loading it as a <code>tf.keras</code> model immediately before compilation / training. That throws the same error! </p>
",1,Documentation Replication on Other Examples
367,59607363,Tensorflow 2.0 dataset batching not working properly,"<p>Tensorflow 2.0 dataset api's batch is not working as I expected it to work.</p>

<p>I've made a dataset like this.</p>

<pre><code>self.train_dataset = tf.data.Dataset.from_generator(generator=train_generator, output_types=(tf.float32, tf.float32), output_shapes=(tf.TensorShape([6]), tf.TensorShape([])))
</code></pre>

<p>This yields DatasetV1Adapter shapes: ((6,), ()), types: (tf.float32, tf.float32),
and to this dataset I applied batch function from tf.data.Dataset.</p>

<pre><code>self.train_dataset.batch(1024)
</code></pre>

<p>yields DatasetV1Adapter shapes: ((None, 6), (None,)), types: (tf.float32, tf.float32), and changing the batch size doesn't help at all. </p>

<p>From official description of the batch, </p>

<blockquote>
  <p>The components of the resulting element will have an additional outer dimension, which will be batch_size (or N % batch_size for the last element if batch_size does not divide the number of input elements N evenly and drop_remainder is False). If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to True to prevent the smaller batch from being produced.</p>
</blockquote>

<p>The way I thought this function would work, was to make [batch, 6], [batch,] but didn't work out well. </p>

<p>I originally used pytorch, and started using TF 2.0 recently, and need some help on proper batching. Thanks in advance.</p>
",1,Documentation Replication on Other Examples
368,59723003,From .tfrecord to tf.data.Dataset to tf.keras.model.fit,"<p>I am attemping to use Tensorflow (v2.0)'s Datasets API to pass large amounts of data to a <code>tf.keras.model</code>.  Here is a simplified version of my dataset:</p>

<pre><code>for rec in my_dataset:
    print(repr(rec))

$ {'feature0': &lt;tf.Tensor: id=528, shape=(), dtype=float32, numpy=0.2963&gt;,
'feature1': &lt;tf.Tensor: id=618, shape=(), dtype=int64, numpy=0&gt;,
'feature2': &lt;tf.Tensor: id=620, shape=(), dtype=string, numpy=b'Inst1'&gt;,
'target': &lt;tf.Tensor: id=621, shape=(), dtype=int64, numpy=2&gt;}
{'feature0': &lt;tf.Tensor: id=528, shape=(), dtype=float32, numpy=0.4633&gt;,
'feature1': &lt;tf.Tensor: id=618, shape=(), dtype=int64, numpy=1&gt;,
'feature2': &lt;tf.Tensor: id=620, shape=(), dtype=string, numpy=b'Inst4'&gt;,
'target': &lt;tf.Tensor: id=621, shape=(), dtype=int64, numpy=0&gt;}
</code></pre>

<p>...and so on.  Each record in the <code>my_dataset</code> object is a dictionary with the features' (and target's) names as the keys and associated tensors as the values.  I created the dataset from several .tfrecord files, so I'm constrained in the sense that each tensor corresponds to a <code>tf.train.Example</code> (wrapper) object.  The dataset precisely matches the format seen in tensorflow documentation (see, for example, the last code example in <a href=""https://www.tensorflow.org/tutorials/load_data/tfrecord#reading_a_tfrecord_file"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/load_data/tfrecord#reading_a_tfrecord_file</a>).</p>

<p>I would like to use this dataset with keras.  The <code>tf.keras.model</code> objects I'm working with all seem, for their <code>fit</code> function, to take as input a tuple representing the feature vector (X) and the target (y).  I think I could figure out how to transform the tensors from my dataset into numpy arrays and pass them into the model that way, or iterate over the dataset using an iterator, but if I understand correctly that seems to defeat the whole purpose of using the Datasets API to begin with (see, for example, <a href=""https://www.tensorflow.org/guide/keras/overview#train_from_tfdata_datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/overview#train_from_tfdata_datasets</a>).</p>

<p>My question:  what is the appropriate way to transform <code>my_dataset</code> into some form that <code>tf.keras.model.fit()</code> will receive?  Or if this is the wrong question, what fundamental concepts am I missing that keep me from asking the right one?  (For example, should the .tfrecord Examples be structured differently?  Or, am I required to use an iterator instead of directly passing <code>my_dataset</code> to the model as I'd prefer?)</p>
",1,Documentation Replicability
369,59743351,Tensorflow 2.0.0: AttributeError: 'TensorSliceDataset' object has no attribute 'as_numpy_iterator',"<p>I am testing tensorflow <code>tf.data.Dataset</code> method <code>as_numpy_iterator</code> using <code>tensorflow 2.0.0</code>. According to the official documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#as_numpy_iterator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#as_numpy_iterator</a>, this function allows directly inspecting the content of a tensorflow dataset. But when I try the given example:</p>

<pre><code>dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) 
for element in dataset.as_numpy_iterator(): 
  print(element) 
</code></pre>

<p>There occurs an error: <code>AttributeError: 'TensorSliceDataset' object has no attribute 'as_numpy_iteractor'</code>. I am wondering if this method is just newly added, beyond the support of tensorflow 2.0.0. If so, is there an alternative to checking the dataset content as the <code>as_numpy_iterator()</code>?</p>
",1,Documentation Replicability
370,59870349,"tf.data for keras model with multiple inputs, one ctc output, ValueError","<p>I'm using tf.version '2.1.0-rc2'</p>

<p>My model has 2 inputs and 1 output and I am struggling to feed it data.</p>

<p>Example <a href=""https://keras.io/examples/image_ocr/"" rel=""nofollow noreferrer"">https://keras.io/examples/image_ocr/</a> uses a generator that output 
a dictionary of numpy arrays.</p>

<pre><code>inputs = {'the_input': X_data,
          'the_labels': labels,
          'input_length': input_length,
          'label_length': label_length,
          'source_str': source_str  # used for visualization only
          }
outputs = {'ctc': np.zeros([size])} 
return (inputs, outputs)
</code></pre>

<p>and fit_generator</p>

<pre><code>   model.fit_generator(
        generator=img_gen.next_train(),
        steps_per_epoch=(words_per_epoch - val_words) // minibatch_size,
        epochs=stop_epoch,
        validation_data=img_gen.next_val(),
        validation_steps=val_words // minibatch_size,
        callbacks=[viz_cb, img_gen],
        initial_epoch=start_epoch)
</code></pre>

<p>but <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Model</a> indicates</p>

<blockquote>
  <p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future
  version. Instructions for updating: Please use Model.fit, which
  supports generators.</p>
</blockquote>

<p>I believe td.data is the recommended way to feed data into tf.keras.
So I would like to figure this out.</p>

<p>First, a simplified dummy model</p>

<pre><code>def why_fail(input_size, one_hot_output_size, model_output_shape):
    ''' A dummy model, to focus on issue of multiple inputs '''

    a = Input(name=""the_image_input"", shape=(320, 128, 1))
    b = Input(name=""the_book_id_input"", shape=(20,))
    print(f""the_image_input.shape = {a.shape}, the_book_id_input.shape = {b.shape}"")
    # the_image_input.shape = (None, 320, 128, 1), the_book_id_input.shape = (None, 20)

    c = Flatten()(a)
    d = Concatenate()([b, c]) # ([b, c])

    # reduce dimension to something we can make 40*xxx
    e = Dense(units=model_output_shape[1]*2)(d )
    f = Reshape( (model_output_shape[1],2) )(e)

    output_data = Dense(units=one_hot_output_size, activation=""softmax"")(f )

    print(f""into ctc output.shape = {output_data.shape}"")
    # into ctc output.shape = (None, 40, 72)

    return Model(inputs=[a,b],  outputs=output_data)
</code></pre>

<p>My generator based on tf.data</p>

<pre><code>def get_tf_dataset(height, width, batch_size, alphabet, record_limit = 10000000, partition_name=""train"", max_string_length=128, angle_in_radians=30/180*math.pi, min_percent_of_target=0.95, dataset=None, full_word_only=True, expensive_safety_checks=False, debug_dir_path=None, sample_output_path=None):

    # my data fits in memory (for now at least)
    my_data = read_dataset(alphabet, record_limit=record_limit, partition_names=[partition_name], max_string_length=max_string_length, expensive_safety_checks=expensive_safety_checks, debug_dir_path=debug_dir_path)

    def generator():
        i = 0
        while True:
            i = (i + 1) % len(my_data[partition_name][""image""])

            img = my_data[partition_name][""image""][i]
            img = kiss_image.phase_2_img_rnd_rot_rnd_size_rnd_position_rnd_noise(image=img, id=id, height=height, width=width, angle_in_radians=angle_in_radians, min_percent_of_target=min_percent_of_target, expensive_safety_checks=expensive_safety_checks, debug_dir_path=debug_dir_path )

            book_id = my_data[partition_name][""book_id""][i]
            text_as_alphabet_index = my_data[partition_name][""text_as_alphabet_index""][i]

            if len(text_as_alphabet_index) &lt;= max_string_length:

                text_as_alphabet_index_array = pad_sequences([text_as_alphabet_index], maxlen=max_string_length, padding=""post"")
                text_as_alphabet_index_array = text_as_alphabet_index_array[0]

                print(f""the_image_input.shape = {img.shape}"")
                print(f""the_book_id_input.shape = {book_id.shape}"")
                print(f""text_as_alphabet_index_array.shape = {text_as_alphabet_index_array.shape}"")

                # the_image_input.shape = (320, 128)
                # the_book_id_input.shape = (20,)
                # text_as_alphabet_index_array.shape = (18,)

                yield {""the_image_input"": img, ""the_book_id_input"": book_id}, text_as_alphabet_index_array


    dataset = tf.data.Dataset.from_generator(generator, output_types=({""the_image_input"": tf.float64, ""the_book_id_input"": tf.float64}, tf.int64))
    dataset = dataset.batch(batch_size)
    return dataset
</code></pre>

<p>Instantiate a train and validation generator from the above</p>

<pre><code>g_train = kiss_grabner.get_tf_dataset(partition_name=""train"", record_limit=1000*2*1, height=height, width=width, batch_size=batch_size, max_string_length=max_string_length, alphabet=alphabet, angle_in_radians=15/180*math.pi, full_word_only=full_word_only, min_percent_of_target=0.95, sample_output_path=sample_output_path)
g_valid = kiss_grabner.get_tf_dataset(partition_name=""valid"", record_limit=1000*2*1, height=height, width=width, batch_size=batch_size, max_string_length=max_string_length, alphabet=alphabet, angle_in_radians=15/180*math.pi, full_word_only=full_word_only, min_percent_of_target=0.95, sample_output_path=sample_output_path)
</code></pre>

<p>Call fit with the td.data generators</p>

<pre><code>model.fit(  x= g_train, #generator.next_train_batch_with_book_id(),
            steps_per_epoch=steps_per_epoch,
            epochs=1000,
            validation_data=g_valid, #generator.next_valid_batch(), #validation_data=generator.next_valid_batch_with_book_id(),
            validation_steps=1000,
            callbacks=callbacks
        )
</code></pre>

<p>The error</p>

<pre><code>Traceback (most recent call last):
  File ""kiss_run_model_on_grabner.py"", line 371, in &lt;module&gt;
    callbacks=callbacks
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 593, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 706, in _process_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 702, in __init__
    x = standardize_function(x)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 684, in standardize_function
    return dataset.map(map_fn, num_parallel_calls=dataset_ops.AUTOTUNE)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1591, in map
    self, map_func, num_parallel_calls, preserve_cardinality=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3926, in __init__
    use_legacy_function=use_legacy_function)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3147, in __init__
    self._function = wrapper_fn._get_concrete_function_internal()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2395, in _get_concrete_function_internal
    *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3140, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3082, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn
        batch_size=None)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors
        exception_prefix='input')
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:526 standardize_input_data
        standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:526 &lt;listcomp&gt;
        standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:451 standardize_single_array
        if (x.shape is not None and len(x.shape) == 1 and
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py:822 __len__
        raise ValueError(""Cannot take the length of shape with unknown rank."")

    ValueError: Cannot take the length of shape with unknown rank.
</code></pre>

<p>I also tried the dictionary approach</p>

<pre><code> def next_train_batch_with_book_id(self):

train = self.dataset[""train""]
while True:
    xy = self.get_batch(train, return_ids_and_text_too=True, angle_in_radians=self.angle_in_radians, min_percent_of_target=self.min_percent_of_target, full_word_only=self.full_word_only)

    an_array_of_images = xy[""image""]
    an_array_of_book_ids = xy[""book_id""]
    an_array_of_1_hot  = xy[""text_as_alphabet_index""]

    print(f""an_array_of_images.shape = {an_array_of_images.shape}"")
    print(f""an_array_of_book_ids.shape = {an_array_of_book_ids.shape}"")
    print(f""an_array_of_1_hot.shape = {an_array_of_1_hot.shape}"")
    # an_array_of_images.shape = (32, 320, 128, 1)
    # an_array_of_book_ids.shape = (32, 20)
    #an_array_of_1_hot.shape = (32, 18)

    # dictionary based input/output to model
    inputs  = { 'the_image_input': an_array_of_images, ""the_book_id_input"": an_array_of_book_ids} 
    outputs = { 'the_text_as_alphabet_index_input' : an_array_of_1_hot }

    # just the data as input
    #inputs = an_array_of_images 
    outputs =  an_array_of_1_hot 

    xy = (inputs, outputs, [])

    yield xy
</code></pre>

<p>...</p>

<p>with model.fit calling as recommended</p>

<pre><code>model.fit(  x=generator.next_train_batch_with_book_id(),
            steps_per_epoch=steps_per_epoch,
            epochs=1000,
            validation_data=generator.next_valid_batch(), #validation_data=generator.next_valid_batch_with_book_id(),
            validation_steps=1000,
            callbacks=callbacks
        )
</code></pre>

<p>But this gives me the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""kiss_run_model_on_grabner.py"", line 371, in &lt;module&gt;
    callbacks=callbacks
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 614, in _process_training_inputs
    distribution_strategy=distribution_strategy)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 706, in _process_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 767, in __init__
    dataset = standardize_function(dataset)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 684, in standardize_function
    return dataset.map(map_fn, num_parallel_calls=dataset_ops.AUTOTUNE)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1591, in map
    self, map_func, num_parallel_calls, preserve_cardinality=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3926, in __init__
    use_legacy_function=use_legacy_function)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3147, in __init__
    self._function = wrapper_fn._get_concrete_function_internal()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2395, in _get_concrete_function_internal
    *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3140, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3082, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn
        batch_size=None)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors
        exception_prefix='input')
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py:539 standardize_input_data
        str(data)[:200] + '...')

    ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), for inputs ['the_image_input', 'the_book_id_input'] but instead got the following list of 1 arrays: [&lt;tf.Tensor 'args_0:0' shape=(None, None, None, None) dtype=float32&gt;]...
</code></pre>
",1,Documentation Replicability
371,59998335,Constantly update tf.cond based on bool value,"<p>I am using <code>tf.cond</code> for controlling the flow of the Tensorflow graph. I went through the documentation and was able to implement <code>tf.cond</code> based branching successfully. But my concern is that while the graph is being loaded the value of the <code>bool</code> variable is checked and the branching decision is made at the initialization step itself. Any further changes in the <code>bool</code> is not tracked. Following is the MWE that better describes the problem:</p>

<pre class=""lang-py prettyprint-override""><code>def funa():
    return tf.constant(32)

def funb():
    return tf.constant(25)

foo = True
x = tf.cond(tf.convert_to_tensor(foo), lambda: funa(), lambda: funb())
for i in range(20):
    global foo
    if i &gt; 10:
        foo = False
    print(sess.run(x))    
</code></pre>

<p>This prints only <code>32</code>s. </p>

<p>I tried with <code>eager_execution</code> too with the following code:</p>

<pre class=""lang-py prettyprint-override""><code>tf.enable_eager_execution()
def funa():
    return tf.constant(32)

def funb():
    return tf.constant(21)

foo = True
x = tf.cond(tf.convert_to_tensor(foo), lambda: funa(), lambda: funb())
for i in range(20):
    if i &gt; 10:
        foo = False
    print(x)
</code></pre>

<p>Still the same result.</p>

<p>So my question is how can I write code such that one part of the graph is chosen dynamically, based on the updates to the <code>bool</code> variable (if possible)? Thanks. I am using Tensorflow v1.14.</p>
",1,Documentation Replication on Other Examples
372,60013980,tf.nn.embedding_lookup_sparse 3D sparse tensor input,"<p>I have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse"" rel=""nofollow noreferrer""><code>tf.nn.embedding_lookup_sparse</code></a> I found it only supports 2D sparse tensors,</p>

<blockquote>
  <p>sp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary.</p>
</blockquote>

<p>My example code here</p>

<pre><code>import numpy as np
import tensorflow as tf
tf.enable_eager_execution()

# [feature number, embedding dim] 
w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer())

z = np.array(
     [
      [
        [0, 1, 2, 3],   # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum
        [2, 3]
      ],

      [
        [1, 3],
        [2]
      ],

      [
        [0, 1, 3],
        [1, 2]
      ]
     ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2],
                              [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0],
                              [2,0,1],[2,0,3],[2,1,1],[2,1,2]],
                     dense_shape=[3, 2, 4])

tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')
# the outputs
&lt;tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy=
array([[-5.8729677 , -1.3900641 ,  0.8126096 , -3.1223912 ],
       [-1.0788026 , -1.1324122 ,  0.34160078,  0.23714277],
       [-2.497394  , -2.7855003 ,  3.0201516 , -1.8009453 ]],
      dtype=float32)&gt;

print(w)
&lt;tf.Variable 'w:0' shape=(4, 4) dtype=float32, numpy=
array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)&gt;
</code></pre>

<p>But the expected output is a matrix with a dimension of <code>3x2x4</code>, not <code>3x4</code>. Does <code>tf.nn.embedding_lookup_sparse</code> support this operation?</p>
",1,Documentation Replicability
373,60047705,Repeated use of GradientTape for multiple Jacobian calculations,"<p>I am attempting to compute the Jacobian of a TensorFlow neural network's outputs with respect to its inputs. This is easily achieved with the <code>tf.GradientTape.jacobian</code> method. The trivial example provided in the TensorFlow documentation is as follows:</p>

<pre><code>with tf.GradientTape() as g:
  x  = tf.constant([1.0, 2.0])
  g.watch(x)
  y = x * x
jacobian = g.jacobian(y, x)
</code></pre>

<p>This is fine if I want only want to compute the Jacobian of a single instance of the input tensor <code>x</code>. However, I need to repeatedly evaluate this Jacobian many, many times for various instances of <code>x</code>. For a non-trivial Jacobian calculation (e.g. for a deep convolutional neural network with non-linear activation functions), this is incredibly expensive to repeatedly rerun the GradientTape calculation and evaluate the <code>jacobian</code> method. I know from the <a href=""https://www.tensorflow.org/tutorials/customization/autodiff"" rel=""nofollow noreferrer"">TensorFlow documentation</a> that the gradients (and hence the Jacobian) are computed via automatic differentiation.  I have to imagine there is some internal storage of the analytical gradient of the network (computed by automatic differentiation) which is evaluated at the given inputs. </p>

<p>My question: am I correct in assuming that TensorFlow builds and stores (at least parts of) the analytical gradients needed to compute the Jacobian? And if so, is there a way to save this analytical gradient and re-evaluate the Jacobian with new inputs without having to reconstruct it via the GradientTape method?</p>

<p>A ""persistent"" GradientTape does not seem to solve this issue: it only allows for the repeated evaluation of a single GradientTape instance with respect to multiple internal arguments of the computation.</p>
",1,Documentation Replication on Other Examples
374,60213882,Using Tensorflow Interleave to Improve Performance,"<p>I have an input pipe that is performing poorly with low CPU, GPU, and disk utilization. I've been reading the tensorflow ""Better performance with tf.data API"" doc and the Dataset docs, but I don't understand what's going on well enough to apply it to my situation. Here's my current setup:</p>

<pre><code>img_files = sorted(tf.io.gfile.glob(...))
imgd = tf.data.FixedLengthRecordDataset(img_files, inrez*inrez)
#POINT1A
imgd = imgd.map(lambda s: tf.reshape(tf.io.decode_raw(s, tf.int8), (inrez,inrez,1)))
imgd = imgd.map(lambda x: tf.cast(x, dtype=tf.float32))

out_files = sorted(tf.io.gfile.glob(...))
outd = tf.data.FixedLengthRecordDataset(out_files, 4, compression_type=""GZIP"")
#POINT1B
outd = outd.map(lambda s: tf.io.decode_raw(s, tf.float32))

xsrc = tf.data.Dataset.zip((imgd, outd)).batch(batchsize)
xsrc = xsrc.repeat()        # indefinitely
#POINT2
xsrc = xsrc.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
</code></pre>

<p>Should I interleave the whole pipe right at the end (POINT2), before the prefetch? Or interleave imgd and outd separately, after each FixedLengthRecordDataset (POINT1A, POINT1B), and parallelize the maps? (need to keep the imgd and outd synced up!) What's up with Dataset.range(rvalue)---seems it's necessary but not obvious what rvalue to use? Is there a better overall plan?</p>

<p>Note that the datasets are very large and do not fit in RAM.</p>
",1,Documentation Replicability
375,60215970,What's the cleanest and most efficient way to pass two stereo images to a loss function in Keras?,"<p>First off, why am I using Keras? I'm trying to stay as high level as possible, which doesn't mean I'm scared of low-level Tensorflow; I just want to see how far I can go while keeping my code as simple and readable as possible.</p>

<p>I need my Keras model (custom-built using the Keras functional API) to read the left image from a stereo pair and minimize a loss function that needs to access both the right and left images. I want to store the data in a <code>tf.data.Dataset</code>.</p>

<p>What I tried:</p>

<ol>
<li>Reading the dataset as <code>(left image, right image)</code>, i.e. as tensors with shape <code>((W, H, 3), (W, H, 3))</code>, then use function closure: define a <code>keras_loss(left_images)</code> that returns a <code>loss(y_true, y_pred)</code>, with <code>y_true</code> being a <code>tf.Tensor</code> that holds the right image. The problem with this approach is that <code>left_images</code> is a <code>tf.data.Dataset</code> and Tensorflow complains (rightly so) that I'm trying to operate on a dataset instead of a tensor. </li>
<li><p>Reading the dataset as <code>(left image, (left image, right image))</code>, which should make <code>y_true</code> a <code>tf.Tensor</code> with shape <code>((W, H, 3), (W, H, 3))</code> that holds both the right and left images. The problem with this approach is that it...does not work and raises the following error:</p>

<pre><code>ValueError: Error when checking model target: the list of Numpy arrays 
that you are passing to your model is not the size the model expected. 
Expected to see 1 array(s), for inputs ['tf_op_layer_resize/ResizeBilinear'] 
but instead got the following list of 2 arrays: [&lt;tf.Tensor 'args_1:0' 
shape=(None, 512, 256, 3) dtype=float32&gt;, &lt;tf.Tensor 'args_2:0' 
shape=(None, 512, 256, 3) dtype=float32&gt;]...
</code></pre></li>
</ol>

<p>So, is there anything I did not consider? I read the documentation and found nothing about what gets considered as <code>y_pred</code> and what as <code>y_true</code>, nor about how to convert a dataset into a tensor smartly and without loading it all in memory. </p>

<p>My model is designed as such:</p>

<pre><code> def my_model(input_shape):
     width = input_shape[0]
     height = input_shape[1]
     inputs = tf.keras.Input(shape=input_shape)
     # &lt; a few more layers &gt;
     outputs = tf.image.resize(tf.nn.sigmoid(tf.slice(disp6, [0, 0, 0, 0], [-1, -1, -1, 2])), tf.Variable([width, height]))
     model = tf.keras.Model(inputs=inputs, outputs=outputs)
     return model
</code></pre>

<p>And my dataset is built as such (in case 2, while in case 1 only the function <code>read_stereo_pair_from_line()</code> changes):</p>

<pre><code>def read_img_from_file(file_name):
    img = tf.io.read_file(file_name)
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_png(img, channels=3)
    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)
    # resize the image to the desired size.
    return tf.image.resize(img, [args.input_width, args.input_height])


def read_stereo_pair_from_line(line):
    split_line = tf.strings.split(line, ' ')
    return read_img_from_file(split_line[0]), (read_img_from_file(split_line[0]), read_img_from_file(split_line[1]))

# Dataset loading
list_ds = tf.data.TextLineDataset('test/files.txt')
images_ds = list_ds.map(lambda x: read_stereo_pair_from_line(x))
images_ds = images_ds.batch(1)
</code></pre>
",1,Lack of Alternative Solutions/Documentation
376,60311184,how to loop over a tensor object until a condition met,"<p>I have a tensor like this:</p>

<pre><code>masked_bad_col = [[False  True  True False  True  True  True  True  True  True  True False]]
</code></pre>

<p>I want to loop through this tensor untill all elements get <code>True</code>.
So I have another function, which will update this tensor, lets call it <code>uniqueness</code>.</p>

<pre><code>def uniqueness():

   'blah blah blha'
   return tensor1, updated_masked_bad_col
</code></pre>

<p>I looked at the documentation and got to know that I can do that using <code>tf.while_loop</code>. Although, I could not find any example working on boolean stuff.
This is what I have done so far:</p>

<pre><code>tensor1, _ = tf.while_loop(masked_bad_col != True, uniqueness)
</code></pre>

<p>It is obviously incorrect, but don't know how to use each element of <code>masked_bad_col</code> as a condition to continue looping through <code>uniqueness</code> function.</p>

<p><strong>Update 1</strong>
This is the method I am trying to call in the loop:</p>

<pre><code>corpus = load_corpus('path_to_corpus/train.corpus')
topics = []
vocab, docs = corpus['vocab'], corpus['docs']
number_of_topics = 0
encoder_model = load_keras_model(
    'path_to_model/encoder_model',
    custom_objects={""KCompetitive"": KCompetitive})
weights = encoder_model.get_weights()[0]
for idx in range(encoder_model.output_shape[1]):
    token_idx = np.argsort(weights[:, idx])[::-1][:20]
    topics.append([(revdict(vocab)[x]) for x in token_idx])
    number_of_topics += 1

nparr = np.asarray(topics)
# print nparr.shape

unique, indices, count = np.unique(nparr, return_inverse=True, return_counts=True)

tensor1 = (np.sum(count[indices].reshape(nparr.shape), axis=1).reshape(1, nparr.shape[0]) / (
        number_of_topics * 20))

def uniqueness_score():
    corpus = load_corpus('path_to_corpus/train.corpus')
    topics = []
    vocab, docs = corpus['vocab'], corpus['docs']
    number_of_topics = 0
    encoder_model = load_keras_model(
        'path_to_model/encoder_model',
        custom_objects={""KCompetitive"": KCompetitive})
    weights = encoder_model.get_weights()[0]
    for idx in range(encoder_model.output_shape[1]):
        token_idx = np.argsort(weights[:, idx])[::-1][:20]
        topics.append([(revdict(vocab)[x]) for x in token_idx])
        number_of_topics += 1

    nparr = np.asarray(topics)

    unique, indices, count = np.unique(nparr, return_inverse=True, return_counts=True)

    tensor1 = (np.sum(count[indices].reshape(nparr.shape), axis=1).reshape(1, nparr.shape[0]) / (
            number_of_topics * 20))
    return tensor1
</code></pre>

<p>And this is the way I called this method in the <code>while_loop</code></p>

<pre><code>with tf.Session() as sess:

        tensor2, _ = tf.while_loop(
            # Loop condition (negated goal condition)
            lambda tensor1: ~tf.math.reduce_all(tensor1 &gt; tf.reduce_mean(tensor1)),
            # Loop body
            lambda tensor1: uniqueness_score(),
            # Loop variables
            [tensor1])
        # Returned loop value
        print(tensor2.eval())
</code></pre>
",1,Inadequate Examples
377,60314717,How does shuffle and batch work in tf.data.dataset?,"<p>I'm working on a large dataset with around 10million datapoints so I've decided to use tf.data.dataset api for fetching dataset.</p>

<pre><code>train_dataset = tf.data.Dataset.from_tensor_slices((data))
train = train_dataset.shuffle(100000).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)
</code></pre>

<p>I've few doubts which isn't clear from tensorflow docs. I hope someone can address them.</p>

<p>How does the shuffle work in my case? Because I have 10 million datapoints should I shuffle all 10 million (or) will 100k be enough? Will it have any performance impact choosing a large shuffle? </p>

<p>Will the batch is considered only from shuffled dataset (or) the original dataset?</p>
",1,Documentation Replication on Other Examples
378,60384790,Difference - tf.gradients vs tf.keras.backend.gradients,"<p>Being new to Tensorflow, I am trying to understand the difference between underlying functionality of tf.gradients and tf.keras.backend.gradients.</p>

<p>The latter finds the gradient of input feature values w.r.t cost function. </p>

<p>But I couldn't get a clear idea on the former whether it computes the gradient over cost function or output probabilities (For example, consider the case of binary classification using a simple feed forward network. Output probability here is referred to the Sigmoid activation outcome of final layer with single neuron. Cost is given by Binary cross entropy)</p>

<p>I have referred the official documentation for tf.gradients, but it is short and vague (for me), and I did not get a clear picture - The documentation mentions it as just 'y' - is it cost or output probability? </p>

<p>Why I need the gradients? 
To implement a basic gradient based feature attribution. </p>
",1,Requesting (Additional) Documentation/Examples
379,60398554,"Should we apply repeat, batch shuffle to tf.data.Dataset when passing it to fit function?","<p>I still don't after having read documentation about <code>tf.keras.Model.fit</code> and <code>tf.data.Dataset</code>, when passing <code>tf.data.Dataset</code> to fit function, should I call <code>repeat</code> and <code>batch</code> on the dataset object or should I provide the <code>batch_size</code> and <code>epochs</code> arguments to fit instead? or both? Should I apply the same treatment to the validation set?</p>

<p>And while I'm here, can I <code>shuffle</code> the dataset before the <code>fit</code>? (seems like it's an obvious yes)
If so, before, after calling <code>Dataset.batch</code> and <code>Dataset.repeat</code> (if calling them)?</p>

<p><strong>Edit:</strong> When using <code>batch_size</code> argument, and without having called <code>Dataset.batch(batch_size)</code> previously, I am getting the following error:</p>

<pre><code>ValueError: The `batch_size` argument must not be specified for the given input type.
Received input: &lt;MapDataset shapes: ((&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;), (&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;)), 
types: ((tf.float32, tf.float32, tf.float32, tf.float32), (tf.float32, tf.float32, tf.float32))&gt;, 
batch_size: 1
</code></pre>

<p>Thanks</p>
",1,Documentation Replication on Other Examples
380,60453533,Tensorflow what is the tf.contrib.nccl.allsum in new version?,"<p>It seems that from tensorflow 1.13, there is no api such as tf.contrib.nccl.allsum. However, in the Nvidia official GitHub <a href=""https://github.com/tkarras/progressive_growing_of_gans"" rel=""nofollow noreferrer"">https://github.com/tkarras/progressive_growing_of_gans</a>, which uses this old API to reduce sum from different gpu devices as the following. </p>

<pre><code># Sum gradients across devices.
            if len(devices) &gt; 1:
                with tf.name_scope('SumAcrossGPUs'), tf.device(None):
                    for var_idx, grad_shape in enumerate(self._grad_shapes):
                        g = [dev_grads[dev][var_idx][0] for dev in devices]
                        if np.prod(grad_shape): # nccl does not support zero-sized tensors
                            g = tf.contrib.nccl.all_sum(g)
                        for dev, gg in zip(devices, g):
                            dev_grads[dev][var_idx] = (gg, dev_grads[dev][var_idx][1])
</code></pre>

<p>I am not sure if there is similar api which can achieve the same collective operation cross different devices. I have checked the Tensorflow official website and it seems that programmers prefer to use <code>tf.distribute.MirroredStrategy</code> which hides the raw operation of <code>NCCL</code>. Thanks a lot.</p>
",1,Documentation Replication on Other Examples
381,60469970,How does tf.function compile a python function with autograph?,"<p>How does <code>tf.function</code> compile a python function operating on tensors into a graph, especially wrt autograph? The <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer"">docs</a> don't go into detail</p>

<blockquote>
  <p><code>tf.function</code> constructs a callable that executes a TensorFlow graph (<code>tf.Graph</code>) created by trace-compiling the TensorFlow operations in <code>func</code>, effectively executing <code>func</code> as a TensorFlow graph.</p>
</blockquote>

<p>Does it use the special methods called by conditionals (<code>__bool__</code>) and loops (<code>__iter__</code>) to 'trace' the function's implementation? For example</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

@tf.function
def op(t: tf.Tensor) -&gt; tf.Tensor:
    if tf.reduce_sum(t) == 0:
        for _ in t:
            ...
</code></pre>

<p>could use the fact that the <code>if</code> results in <code>Tensor.__bool__(...)</code> and <code>for _ in t</code> results in <code>Tensor.__iter__(...)</code></p>
",1,Documentation Replicability
382,60516977,Difficulties in understanding higher order derivatives for tf.custom_gradient(),"<p>Based on the example as quoted in tensorflow's website here: <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/custom_gradient</a></p>

<pre><code>@tf.custom_gradient
def op_with_fused_backprop(x):
     y, x_grad = fused_op(x)

     def first_order_gradient(dy):
         @tf.custom_gradient
         def first_order_custom(unused_x):
             def second_order_and_transpose(ddy):
                 return second_order_for_x(...), gradient_wrt_dy(...)
             return x_grad, second_order_and_transpose
         return dy * first_order_custom(x)
     return y, first_order_gradient
</code></pre>

<p>There is a lack of details on why <code>second_order_and_transpose(ddy)</code> returns two objects. Based on the documentation of tf.custom_gradient, the <code>grad_fn</code> (<em>i.e.</em> <code>second_order_and_transpose()</code>) should return a list of Tensors which are the derivatives of dy w.r.t. <code>unused_x</code>. It is also not even clear why did they name it <code>unused_x</code>. Anyone has any idea on this example or in general create custom gradients for higher order derivatives?</p>
",1,Documentation Completeness
383,60525257,How to apply Non max suppression on batch of images in tensorflow 1.14?,"<p>I have batch of cropped images from original image on which I have to perform object detection, I am trying to apply tensorflow NMS operation. </p>

<p>I looked into tensorflow api docs, and found <code>tf.image.combined_non_max_suppression()</code>, but I am unable to understand it properly.</p>

<p>The flow in my pipeline is of two step.</p>

<ol>
<li>I get some image and apply object detection to get desired region of interests.</li>
<li>On each of these ROIs I have to apply object detection again, so I am passing it as batch.</li>
</ol>

<p>For the first step, I use simple <code>tf.image.non_max_suppression()</code> followed by <code>tf.gather()</code>, but I am not able to understand, how to do it for second step. </p>

<p>Please refer to code snippets below:</p>

<pre><code>with tf.Session(graph = self.detection_graph) as sess:

    # input image tensor
    image_tensor1 = self.detection_graph.get_tensor_by_name('import/image_tensor:0')

    # boxes, scores and classes for first step
    boxesop1 = self.detection_graph.get_tensor_by_name('import/detection_boxes:0')
    scoresop1 = self.detection_graph.get_tensor_by_name('import/detection_scores:0')
    classesop1 = self.detection_graph.get_tensor_by_name('import/detection_classes:0')

    # getting first values, since we are predicting on single image
    boxesop1 = boxesop1[0]
    classesop1 = classesop1[0]
    scoresop1 = scoresop1[0]

    # applying NMS for the first step
    selected_indices1 = tf.image.non_max_suppression(
        boxesop1, scoresop1, 20, iou_threshold = 0.5
    )

    boxesop1 = tf.gather(boxesop1, selected_indices1)
    classesop1 = tf.gather(classesop1, selected_indices1)
    scoresop1 = tf.gather(scoresop1, selected_indices1)


    # boxes, scores and classes for second step
    boxesop2 = self.detection_graph.get_tensor_by_name('import_1/detection_boxes:0')
    scoresop2 = self.detection_graph.get_tensor_by_name('import_1/detection_scores:0')
    classesop2 = self.detection_graph.get_tensor_by_name('import_1/detection_classes:0')

    # applying NMS for the second step
    boxesop2, scoresop2, classesop2, valid_detections = tf.image.combined_non_max_suppression(
        boxesop2, scoresop2, max_output_size_per_class = 10, max_total_size = 30,
        iou_threshold = 0.5
    )

    # predicting for each images
    for imgPath, imgID in img_files:

        # reading image data
        img = cv2.imread(imgPath)
        imageHeight, imageWidth = img.shape[:2]

        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
        image_np_expanded = np.expand_dims(img, axis=0)

        # Run inference
        (boxes1, scores1, classes1, boxes2, scores2, classes2) = sess.run(
            [boxesop1, scoresop1, classesop1, boxesop2, scoresop2, classesop2],
            feed_dict={image_tensor1: image_np_expanded}
        )
</code></pre>

<p>But I got following error, when tried running above:</p>

<pre><code>Traceback (most recent call last):
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: boxes must be 4-D[20,300,4]
         [[{{node combined_non_max_suppression/CombinedNonMaxSuppression}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/prediction.py"", line 159, in predict
    feed_dict={image_tensor1: image_np_expanded}
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: boxes must be 4-D[20,300,4]
         [[node combined_non_max_suppression/CombinedNonMaxSuppression (defined at /home/prediction.py:130) ]]

Errors may have originated from an input operation.
Input Source operations connected to node combined_non_max_suppression/CombinedNonMaxSuppression:
 import_1/detection_boxes (defined at /home/prediction.py:94)

Original stack trace for 'combined_non_max_suppression/CombinedNonMaxSuppression':
  File ""/home/prediction.py"", line 130, in predict
    iou_threshold = 0.5
  File ""../env/lib/python3.5/site-packages/tensorflow/python/ops/image_ops_impl.py"", line 3707, in combined_non_max_suppression
    score_threshold, pad_per_class, clip_boxes)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/ops/gen_image_ops.py"", line 431, in combined_non_max_suppression
    clip_boxes=clip_boxes, name=name)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""../env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
</code></pre>

<p><strong>How to solve it and apply NMS for batch of images in tensorflow ?</strong></p>
",1,Documentation Replicability
384,60590333,Increasing each element of a tensor by the predecessor in Tensorflow 2.0,"<p>I'm new to <em>tensorflow 2.0</em>, and haven't done much except designing and training some artificial neural networks from boilerplate code. I'm trying to solve an <em>exercise for newcomers</em> into the new tensorflow. I created some code, but it doesn't work. Below is the <strong><em>problem definition</em></strong>:</p>

<hr>

<p>Assuming we have tensor <code>M</code> of rational numbers in shape of <code>(a, b, c)</code> and scalar <code>p ∈ (0, 1)</code> (memory factor), let’s create a function that will return tensor <code>N</code> in shape of <code>(a, b, c)</code>. Each element of <code>N</code> tensors moving along axis <em>c</em> should be increased by the value of predecessor multiplied by <code>p</code>.</p>

<p>Assuming we have tensor:</p>

<pre><code>T = [x1, x2, x3, x4]
</code></pre>

<p>in shape of <code>(1, 1, 4)</code>, we would like to get vector:</p>

<pre><code>[x1, x2+x1·p, x3+(x2+x1·p)·p, x4+(x3+(x2+x1·p)·p)*p] 
</code></pre>

<p>Solution should be created in <em>Tensorflow 2.0</em> and should be focused on delivering the shortest execution time on CPU. Created graph should allow to efficiently calculate derivative both on tensor <code>M</code> and value <code>p</code>.</p>

<hr>

<p>This is the <strong>code I created till now</strong>:</p>

<pre><code>import tensorflow as tf

@tf.function
def vectorize_predec(t, p):
    last_elem = 0
    result = []
    for el in t:
        result.append(el + (p * last_elem))
        last_elem = el + (p * last_elem)
    return result

p = tf.Variable(0.5, dtype='double')

m = tf.constant([[0, 1, 2, 3, 4],
          [1, 3, 5, 7, 10],
          [1, 1, 1, -1, 0]])

vectorize_predec(m, p)
</code></pre>

<p>But it throws a <code>TypeError</code>.</p>

<p>I looked around documentation, I've seen functions like <code>cumsum</code> and <code>polyeval</code>, but I'm not sure they fit my needs. To my understanding, I need to write my own customer function annotated with <code>@tf.function</code>. I'm also not sure how to handle 3-dimension tensors properly according to the problem definition (adding the predecessor should happen on the last (<em>""c""</em>) axis). </p>

<p>I've seen in documentation (here: <a href=""https://www.tensorflow.org/tutorials/customization/performance"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/customization/performance</a>) that there are ways to measure size of the produced graph. Although, I'm not sure how ""graph"" allows to efficiently calculate <em>derivative</em> both on tensor <code>M</code> and value <code>p</code>. ELI5 answers appreciated, or at least some materials I can read to educate myself better.</p>

<p>Thanks a lot! </p>
",1,Lack of Alternative Solutions/Documentation
385,60708695,"How can I make ""element wise"" comparsion inside of the tf.function?","<p>I try to make my own activation function in TensorFlow 2 and the function looks like this:</p>

<pre><code>@tf.function
def f(x):
  r = 2
  if x&gt;=0:
    return (r**2 * x + 1)**(1/r) - 1/r
  else:
    return K.exp(r*x) - 1/r
</code></pre>

<p>The problem is that it cant take as argument <code>tf.constant([2.0, 3.0])</code>because there is an issue with conditions. I have tried <code>tf.math.qreater_equal(x, 0)</code> which lead to same output also <code>tf.cond()</code>. I have had no luck with documentation examples either.
It returns error:</p>

<pre><code>InvalidArgumentError:  The second input must be a scalar, but it has shape [2]
     [[{{node cond/switch_pred/_2}}]] [Op:__inference_f_7469065]
</code></pre>

<p>Thanks!</p>
",1,Documentation Ambiguity
386,60761888,Chaining custom Keras layers in functional style,"<p>I want to build a model using <code>tf.keras</code>' functional API. My model is quite large, hence I would like to create custom layers by inheriting from <code>tf.keras.layers.Layer</code>. Below is my attempt, inspired by <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_layer_class"" rel=""nofollow noreferrer"">TensorFlow's documentation</a>.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

class Conv2D(tf.keras.layers.Layer):
    def __init__(self):
        super().__init__()

        input_layer = tf.keras.layers.Input(
            shape=(256, 256, 3)
        )
        self.conv = tf.keras.layers.Conv2D(
            filters=16,
            kernel_size=3,
            strides=(1, 1),
            padding=""same""
        )(input_layer)

    def call(self, inputs):
        return self.conv(inputs)

outer_input_layer = tf.keras.layers.Input(
    shape=(256, 256, 3)
)
x = Conv2D()(outer_input_layer)
</code></pre>

<p>This code crashes with the following error.</p>

<pre class=""lang-none prettyprint-override""><code>Traceback (most recent call last):
  File ""c:\Users\user\.vscode\extensions\ms-python.python-2020.2.64397\pythonFiles\ptvsd_launcher.py"", line 48, in &lt;module&gt;
    main(ptvsdArgs)
  File ""c:\Users\user\.vscode\extensions\ms-python.python-2020.2.64397\pythonFiles\lib\python\old_ptvsd\ptvsd\__main__.py"", line 432, in main
    run()
  File ""c:\Users\user\.vscode\extensions\ms-python.python-2020.2.64397\pythonFiles\lib\python\old_ptvsd\ptvsd\__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""C:\Users\user\code\.env\lib\runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""C:\Users\user\code\.env\lib\runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""C:\Users\user\code\.env\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""c:\Users\user\code\tests.py"", line 23, in &lt;module&gt;
    x = Conv2D()(outer_input_layer)
  File ""C:\Users\user\code\.env\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 773, in __call__        
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""C:\Users\user\code\.env\lib\site-packages\tensorflow_core\python\autograph\impl\api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in converted code:

    c:\Users\user\code\tests.py:18 call  *
        return self.conv(inputs)
    C:\Users\user\code\.env\lib\site-packages\tensorflow_core\python\autograph\impl\api.py:447 converted_call
        f in m.__dict__.values() for m in (collections, pdb, copy, inspect, re)):
    C:\Users\user\code\.env\lib\site-packages\tensorflow_core\python\autograph\impl\api.py:447 &lt;genexpr&gt;
        f in m.__dict__.values() for m in (collections, pdb, copy, inspect, re)):
    C:\Users\user\code\.env\lib\site-packages\tensorflow_core\python\ops\math_ops.py:1351 tensor_equals
        return gen_math_ops.equal(self, other, incompatible_shape_error=False)
    C:\Users\user\code\.env\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py:3240 equal
        name=name)
    C:\Users\user\code\.env\lib\site-packages\tensorflow_core\python\framework\op_def_library.py:477 _apply_op_helper
        repr(values), type(values).__name__, err))

    TypeError: Expected float32 passed to parameter 'y' of op 'Equal', got 'collections' of type 'str' instead. Error: Expected float32, got 'collections' 
of type 'str' instead.
</code></pre>

<p>What's wrong with my approach?</p>
",1,Documentation Replication on Other Examples
387,60782077,How do you use tensorflow ctc_batch_cost function with keras?,"<p>I have been trying to implement a CTC loss function in keras for several days now.</p>
<p>Unfortunately, I have yet to find a simple way to do this that fits well with keras. I found tensorflow's <code>tf.keras.backend.ctc_batch_cost</code> function but there is not much documentation on it. I am confused about a few things. First, what are the <code>input_length</code> and <code>label_length</code> parameters? I am trying to make a handwriting recognition model and my images are 32x128, my RNN has 32 time steps, and my character list has a length of 80. I have tried to use 32 for both parameters and this gives me the error below.</p>
<p>Shouldn't the function already know the <code>input_length</code> and <code>label_length</code> from the shape of the first two parameters (<code>y_true</code> and <code>y_pred</code>)?</p>
<p>Secondly, do I need to encode my training data? Is this all done automatically?</p>
<p>I know tensorflow also has a function called <code>tf.keras.backend.ctc_decode</code>. Is this only used when making predictions?</p>
<pre><code>def ctc_cost(y_true, y_pred):
    return tf.keras.backend.ctc_batch_cost(
        y_true, y_pred, 32, 32)


model = tf.keras.Sequential([
    layers.Conv2D(32, 5, padding=&quot;SAME&quot;, input_shape=(32, 128, 1)),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D(2, 2),
    layers.Conv2D(64, 5, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D(2, 2),
    layers.Conv2D(128, 3, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D((1, 2), (1, 2)),
    layers.Conv2D(128, 3, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D((1, 2), (1, 2)),
    layers.Conv2D(256, 3, padding=&quot;SAME&quot;),
    layers.BatchNormalization(),
    layers.Activation(&quot;relu&quot;),
    layers.MaxPool2D((1, 2), (1, 2)),
    layers.Reshape((32, 256)),
    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),
    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),
    layers.Reshape((-1, 32, 512)),
    layers.Conv2D(80, 1, padding=&quot;SAME&quot;),
    layers.Softmax(-1)
])

print(model.summary())

model.compile(tf.optimizers.RMSprop(0.001), ctc_cost)
</code></pre>
<p><strong>Error:</strong></p>
<p><em>tensorflow.python.framework.errors_impl.InvalidArgumentError: squeeze_dims[0] not in [0,0). for 'loss/softmax_loss/Squeeze' (op: 'Squeeze') with input shapes: []</em></p>
<p><strong>Model:</strong></p>
<pre><code>Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 32, 128, 32)       832
batch_normalization (BatchNo (None, 32, 128, 32)       128
activation (Activation)      (None, 32, 128, 32)       0
max_pooling2d (MaxPooling2D) (None, 16, 64, 32)        0
conv2d_1 (Conv2D)            (None, 16, 64, 64)        51264
batch_normalization_1 (Batch (None, 16, 64, 64)        256
activation_1 (Activation)    (None, 16, 64, 64)        0
max_pooling2d_1 (MaxPooling2 (None, 8, 32, 64)         0
conv2d_2 (Conv2D)            (None, 8, 32, 128)        73856
batch_normalization_2 (Batch (None, 8, 32, 128)        512
activation_2 (Activation)    (None, 8, 32, 128)        0
max_pooling2d_2 (MaxPooling2 (None, 8, 16, 128)        0
conv2d_3 (Conv2D)            (None, 8, 16, 128)        147584
batch_normalization_3 (Batch (None, 8, 16, 128)        512
activation_3 (Activation)    (None, 8, 16, 128)        0
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0
conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168
batch_normalization_4 (Batch (None, 8, 8, 256)         1024
activation_4 (Activation)    (None, 8, 8, 256)         0
max_pooling2d_4 (MaxPooling2 (None, 8, 4, 256)         0
reshape (Reshape)            (None, 32, 256)           0
bidirectional (Bidirectional (None, 32, 512)           1050624
bidirectional_1 (Bidirection (None, 32, 512)           1574912
reshape_1 (Reshape)          (None, None, 32, 512)     0
conv2d_5 (Conv2D)            (None, None, 32, 80)      41040     
softmax (Softmax)            (None, None, 32, 80)      0
</code></pre>
<p><strong>Here is the tensorflow documentation I was referencing:</strong></p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_batch_cost"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_batch_cost</a></p>
",1,Documentation Ambiguity
388,60919434,String to one_hot tensor in Tensorflow,"<p>I have found in tensorflow doc the following function to compute and apply a vocabulary onto a string tensor but it was still using <code>tf.session</code> and I can't make it work with <code>tf.function</code>:</p>

<pre><code>import tensorflow as tf
import tensorflow_transform as tft


@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.string),))
def string_to_one_hot(labels):
    codes = tft.compute_and_apply_vocabulary(labels)
    return tf.one_hot(codes, depth=tf.cast(tf.reduce_max(codes), tf.int32))


test_labels = tf.constant(['a', 'b', 'a', 'c'])
test_one_hot = string_to_one_hot(test_labels)

&gt; tensorflow.python.framework.errors_impl.InvalidArgumentError:  You must feed a value for placeholder tensor 'compute_and_apply_vocabulary/vocabulary/Placeholder' with dtype string
     [[node compute_and_apply_vocabulary/vocabulary/Placeholder (defined at /Users/clementwalter/.pyenv/versions/keras_fsl/lib/python3.6/site-packages/tensorflow_transform/analyzer_nodes.py:102) ]] [Op:__inference_string_to_one_hot_52]

</code></pre>

<h2>EDIT</h2>

<p>I have been able to build such a function with direct use of the hash facilities. However I have had to use a hard-coded bucket_size/depth param. Any ideas?</p>

<pre><code>@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.string),))
def string_to_one_hot(labels):
    one_hot = tf.one_hot(tf.strings.to_hash_bucket_fast(labels, 1024), depth=1024)
    return tf.boolean_mask(one_hot, tf.reduce_sum(one_hot, axis=0) &gt; 0, axis=1)
</code></pre>
",1,Documentation Replicability
389,61059725,Why does tf.constant give a dtype error if we pass in a tensor?,"<p>The following code</p>

<pre><code>a = tf.range(10)
b = tf.constant(a, dtype=tf.float32)
</code></pre>

<p>gives the following error:</p>

<pre><code>TypeError: Expected tensor with type tf.float32 not tf.int32
</code></pre>

<p>Although from the <a href=""https://www.tensorflow.org/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">documentation</a>, setting <code>dtype</code> means that <code>tf.constant</code> is supposed to cast <code>a</code> to the specified data type. So I don't see why this should give a type error.</p>

<p>I also know that:</p>

<pre><code>a = np.arange(10)
b = tf.constant(a, dtype=tf.float32)
</code></pre>

<p>does not give an error.</p>

<p>So actually, I'm mainly wondering about what's happening under the hood here.</p>
",1,Documentation Ambiguity
390,61175291,Why is optimizer.minimize not working if we pass loss as tf.constant?,"<p>I simply have <code>train = optimizer.minimize(loss = tf.constant(4,dtype=""float32""))</code> Line of code that i change before everything is working. <br/></p>

<p>Why it is giving error ? Because documentation say it can be tensor <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam#minimize"" rel=""nofollow noreferrer"">Here is Docs</a> </p>

<pre><code>W = tf.Variable([0.5],tf.float32)
b = tf.Variable([0.1],tf.float32)
x = tf.placeholder(tf.float32)
y= tf.placeholder(tf.float32)
discounted_reward = tf.placeholder(tf.float32,shape=[4,], name=""discounted_reward"")
linear_model = W*x + b

squared_delta = tf.square(linear_model - y)
print(squared_delta)
loss = tf.reduce_sum(squared_delta*discounted_reward)
print(loss)
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss = tf.constant(4,dtype=""float32""))
init = tf.global_variables_initializer()
sess = tf.Session()

sess.run(init)

for i in range(3):
    sess.run(train,{x:[1,2,3,4],y:[0,-1,-2,-3],discounted_reward:[1,2,3,4]})

print(sess.run([W,b]))
</code></pre>

<hr>

<p>I really need this thing to work. In this particular example we can have other ways to solve it but i need it to work as my actual code can do this only </p>

<p><hr/> Error is</p>

<pre><code>&gt; ValueError: No gradients provided for any variable, check your graph
&gt; for ops that do not support gradients, between variables
&gt; [""&lt;tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_2:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_3:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_4:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_5:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_6:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_7:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_8:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_9:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_10:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_11:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_12:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_13:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_14:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_15:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_16:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_17:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_18:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_19:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_20:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_21:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_22:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_23:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_24:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_25:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_26:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_27:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_28:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_29:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_30:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_31:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_32:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_33:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_34:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_35:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_36:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_37:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_38:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_39:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_40:0' shape=(1,) dtype=float32_ref&gt;"",
&gt; ""&lt;tf.Variable 'Variable_41:0' shape=(1,) dtype=float32_ref&gt;""] and loss
&gt; Tensor(""Const_4:0"", shape=(), dtype=float32).
</code></pre>
",1,Documentation Replication on Other Examples
391,61219907,Failed to create control dependencies with tf.control_dependencies(),"<p>I tried to understand <code>tf.control_dependencies()</code>, and wanted to verify it does create control dependencies. Here is the code</p>

<pre><code>import tensorflow as tf

a = tf.get_variable('a', shape = [2, 3])
b = tf.get_variable('b', shape = [2, 3])
c = tf.scalar_mul(2, a)
d = tf.scalar_mul(3, b)

with tf.control_dependencies([d, c]):
  f = d-c

print (f.op.control_inputs)
</code></pre>

<p>It returned <code>[]</code>, which was not what I expected. If I added the control dependencies in the following way</p>

<pre><code>f = d-c
f.op._add_control_inputs([c.op, d.op])
print (f.op.control_inputs)
</code></pre>

<p>It gave back what I expected <code>[&lt;tf.Operation 'Mul' type=Mul&gt;, &lt;tf.Operation 'Mul_1' type=Mul&gt;]</code>. </p>

<p>So my question is, does <code>tf.control_dependencies()</code> really add control dependencies? Or does <code>f.op.control_inputs</code> return all the control inputs?</p>
",1,Documentation Replication on Other Examples
392,61273445,Tensorflow MapDataset iterator fails,"<p>I am trying to implement the method suggested by the tensorflow documentation over here (<a href=""https://www.tensorflow.org/tutorials/load_data/images"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/load_data/images</a>) to load images from local directory as a tensorflow dataset. Especially I am interested in loading using tf.data as a tf.data.Dataset object as it is suggested that the performance is better that way. I pretty much took the exact code from the documentation page and also made sure that the tensorflow version matches to the one in the documentation</p>

<p>The problem happens when I try to iterate over the MapDataset object using take().</p>

<pre><code>import os
import sys
import pathlib

import IPython.display as display
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf

AUTOTUNE = tf.data.experimental.AUTOTUNE

BATCH_SIZE = 32
IMG_HEIGHT = 224
IMG_WIDTH = 224
STEPS_PER_EPOCH = np.ceil(3670/BATCH_SIZE)
CLASS_NAMES = None

#https://www.tensorflow.org/tutorials/load_data/images

def get_label(file_path):
    # convert the path to a list of path components
    #parts = tf.strings.split(file_path, result_type = 'RaggedTensor')
    parts = tf.strings.split(file_path)

    # The second to last is the class-directory
    return parts[-2] == CLASS_NAMES

def decode_img(img):
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_jpeg(img, channels=3)

    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)

    # resize the image to the desired size.
    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])

def process_path(file_path):
    label = get_label(file_path)

    # load the raw data from the file as a string
    img = tf.io.read_file(file_path)
    img = decode_img(img)

    return img, label

def test():

    data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
                                         fname='flower_photos', untar=True)

    data_dir = pathlib.Path(data_dir)

    global CLASS_NAMES
    CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != ""LICENSE.txt""])

    list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))

    labeled_ds = list_ds.map(process_path)
    print('type: ', type(labeled_ds))

    for image, label in labeled_ds.take(1):
        print(""Image shape: "", image.numpy().shape)
        print(""Label: "", label.numpy())

def main():
    test()  

if __name__ == '__main__':
    main()

</code></pre>

<p>I get the following error and have no idea how to go about resolving this</p>

<pre><code>2020-04-17 09:47:53.816123: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.
2020-04-17 09:47:53.820082: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at iterator_ops.cc:941 : Invalid argument: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
Traceback (most recent call last):
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\eager\context.py"", line 1897, in execution_mode
    yield
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 659, in _next_internal
    output_shapes=self._flat_output_shapes)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_dataset_ops.py"", line 2478, in iterator_get_next_sync
    _ops.raise_from_not_ok_status(e, name)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 6606, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""&lt;string&gt;"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]] [Op:IteratorGetNextSync]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "".\img_sub_model.py"", line 150, in &lt;module&gt;
    main()
  File "".\img_sub_model.py"", line 145, in main
    test()
  File "".\img_sub_model.py"", line 136, in test
    for image, label in labeled_ds.take(1):
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 630, in __next__
    return self.next()
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 674, in next
    return self._next_internal()
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py"", line 665, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\eager\context.py"", line 1900, in execution_mode
    executor_new.wait()
  File ""C:\Users\VVJ3281\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\eager\executor.py"", line 67, in wait
    pywrap_tensorflow.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]
</code></pre>

<p>By some random coincidence I found that when CLASS_NAMES is set to None, the code runs and the lebel object of labeled_ds has a value 'False'</p>

<p>See output below</p>

<pre><code>type:  &lt;class 'tensorflow.python.data.ops.dataset_ops.MapDataset'&gt;
Image shape:  (224, 224, 3)
Label:  False
</code></pre>
",1,Documentation Replication on Other Examples
393,61280184,Model with multiple outputs and custom loss function,"<p>I'm trying to train a model that has multiple outputs and a custom loss function using keras, but I'm getting some error <code>tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: iterating over ``tf.Tensor`` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.</code></p>

<p>It's hard to debug it because I'm doing <code>model.compile</code> and <code>model.fit</code>. I think it has something to do with how models are supposed to be defined when having multiple outputs, but I can't find good documentation on this. The guide specifies how to have models with multiple outputs suing the functional API, and has an example for this, but it doesn't clarify how custom loss functions should work when subclassing the <code>Model</code> API. My code is as follows:</p>

<pre><code>class DeepEnsembles(Model):

    def __init__(self, **kwargs):
        super(DeepEnsembles, self).__init__()

        self.num_models = kwargs.get('num_models')
        model = kwargs.get('model')

        self.mean = [model(**dict(**kwargs)) for _ in range(self.num_models)]

        self.variance = [model(**dict(**kwargs)) for _ in range(self.num_models)]

    def call(self, inputs, training=None, mask=None):
        mean_predictions = []
        variance_predictions = []
        for idx in range(self.num_models):
            mean_predictions.append(self.mean[idx](inputs, training=training))
            variance_predictions.append(self.variance[idx](inputs, training=training))
        mean_stack = tf.stack(mean_predictions)
        variance_stack = tf.stack(variance_predictions)

        return mean_stack, variance_stack
</code></pre>

<p>And where MLP is the following:</p>

<pre><code>class MLP(Model):
    def __init__(self, **kwargs):
        super(MLP, self).__init__()

        # Initialization parameters
        self.num_inputs = kwargs.get('num_inputs', 779)
        self.num_outputs = kwargs.get('num_outputs', 1)
        self.hidden_size = kwargs.get('hidden_size', 256)
        self.activation = kwargs.get('activation', 'relu')

        # Optional parameters
        self.p = kwargs.get('p', 0.05)

        self.model = tf.keras.Sequential([
            layers.Dense(self.hidden_size, activation=self.activation, input_shape=(self.num_inputs,)),
            layers.Dropout(self.p),
            layers.Dense(self.hidden_size, activation=self.activation),
            layers.Dropout(self.p),
            layers.Dense(self.num_outputs)
         ])

    def call(self, inputs, training=None, mask=None):
        output = self.model(inputs, training=training)
        return output

</code></pre>

<p>I'm trying to minimize a custom loss function </p>

<pre><code>class GaussianNLL(Loss):

    def __init__(self):
        super(GaussianNLL, self).__init__()

    def call(self, y_true, y_pred):

        mean, variance = y_pred
        variance = variance + 0.0001
        nll = (tf.math.log(variance) / 2 + ((y_true - mean) ** 2) / (2 * variance))
        nll = tf.math.reduce_mean(nll)
        return nll

</code></pre>

<p>Finally, this is how I try to train it:</p>

<pre><code>    ensembles_params = {'num_models': 5, 'model': MLP, 'p': 0}
    model = DeepEnsembles(**ensembles_params)
    loss_fn = GaussianNLL()
    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)
    epochs = 10000

    model.compile(optimizer='adam',
                  loss=loss_fn,
                  metrics=['mse', 'mae'])
    history = model.fit(x_train, y_train,
                        batch_size=2048,
                        epochs=10000,
                        verbose=0,
                        validation_data=(x_val, y_val))
</code></pre>

<p>Which results in the above error. Any pointers? In particular, the whole stack trace is </p>

<pre><code>Traceback (most recent call last):
  File ""/home/emilio/anaconda3/lib/python3.7/contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py"", line 2803, in variable_creator_scope
    yield
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 593, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 646, in _process_inputs
    x, y, sample_weight=sample_weights)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2360, in _standardize_user_data
    self._compile_from_inputs(all_inputs, y_input, x, y)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2618, in _compile_from_inputs
    experimental_run_tf_function=self._experimental_run_tf_function)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 446, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1592, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1652, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File ""/home/emilio/fault_detection/tensorflow_code/tf_utils/loss.py"", line 13, in call
    mean, variance = y_pred
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 539, in __iter__
    self._disallow_iteration()
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 535, in _disallow_iteration
    self._disallow_in_graph_mode(""iterating over `tf.Tensor`"")
  File ""/home/emilio/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 515, in _disallow_in_graph_mode
    "" this function with @tf.function."".format(task))
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.


</code></pre>

<p>So it's clearly related to the loss function. But the model's forward pass outputs a tuple, which I unpack in the loss function, so I don't know why is this an issue.</p>
",1,Lack of Alternative Solutions/Documentation
394,61305781,Using Tensorflow embedded columns raises All feature_columns must be _FeatureColumn instances error,"<p>I am new to tensorflow and I was trying to follow the official documentation where I came across 
tf.feature_column.categorical_column_with_vocabulary_list</p>

<p>The code I tested is: </p>

<pre><code>key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), default_value=0)
columns = [[tfc.embedding_column(colors, 3)], ...]
features = tf.io.parse_example(..., features=tfc.make_parse_example_spec(columns))
dense_tensor = tfc.input_layer(features, columns)
</code></pre>

<p>However , when I run this sample code I get the following error : 
 ValueError: All feature_columns must be _FeatureColumn instances. Given: [EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), dtype=tf.string, default_value=0, num_oov_buckets=0), dimension=3, combiner='mean', initializer=, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]</p>

<p>What I am doing wrong?  </p>
",1,Documentation Replication on Other Examples
395,61355289,When will tf.print ACTUALLY WORK as expected (i.e. print the values of tensors and variables)?,"<p>First of all, I am using TensorFlow 2.0 and I only care about this version or higher (and I am already caring too much for such a piece of software that only produces headaches).</p>

<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/print"" rel=""nofollow noreferrer"">TensorFlow documentation</a> of <code>tf.print</code> says </p>

<blockquote>
  <p>Print the specified inputs.</p>
</blockquote>

<p>and then</p>

<blockquote>
  <p>A TensorFlow operator that prints the specified inputs to a desired output stream or logging level. The inputs may be </p>
  
  <ul>
  <li><strong>dense</strong> or </li>
  <li><strong>sparse Tensors</strong>, </li>
  <li><strong>primitive python objects</strong>, </li>
  <li><strong>data structures that contain tensors</strong>, and </li>
  <li><strong>printable Python objects</strong>. </li>
  </ul>
  
  <p>Printed tensors will recursively show the first and last elements of each dimension to summarize. </p>
</blockquote>

<p>This is all very nice, but I still don't get where <code>tf.print</code> will ACTUALLY WORK (i.e. print the VALUES of variables and tensors) in my code. Of course, needless to say, I couldn't care less about the symbolic representations of tensors, variables or whatever. Whenever I try to use <code>tf.print</code>, I want to see the VALUES (real numbers, vectors or matrices). </p>

<p>I've tried to use <code>tf.print</code> in multiple cases and in multiple places, e.g. </p>

<ul>
<li><p>in a method that is called from the <code>__init__</code> method of a custom layer that is called during model building (so before compiling the model) in order to print the value of a tensor (at least, this is what the <code>type(my_var)</code> returns, i.e. it returns <code>&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;</code>), but nothing is printed. If I try to add <code>@tf.function</code> (I still don't get the usage of this function!), nothing changes. According to the documentation above <code>tf.print</code> is supposed to print tensors, my variable is a tensor and TensorFlow decides to ignore my call, and then one wonders why did I decide to use TF? Why? </p>

<p>Also, I am using TF 2.0 and, even if I don't use the decorator <code>@tf.function</code>, <code>print(tf.executing_eagerly())</code> prints False, which is really what I was expecting.</p></li>
<li><p>in a custom loss function, where a similar behaviour happens (i.e. sometimes something is printed, sometimes it is not, sometimes I try to add the decorator <code>@tf.function</code> to the custom loss function and see if something changes, but nothing changes, or maybe yes).</p></li>
</ul>

<p>Ok, so, as you can see, I have no idea where <code>tf.print</code> will do what I want, i.e. I want to see the values of tensors. If something is a tensor, it must have a value. Similarly for variables.</p>

<p>So, when will <code>tf.print</code> ACTUALLY PRINT THE VALUES OF TENSORS? </p>

<p>I am looking for answers that say e.g., ""<code>tf.print</code> will NEVER work"" or ""it will only work if you are dreaming"". Apart from the jokes and sarcasm, I am really looking for answers that tell me exactly in which places of my code or which stages of developing a model with TF <code>tf.print</code>  will actually do what it is supposed to do. Please, don't tell me that <code>tf.print</code> will work when the input is a tensor!! </p>
",1,Documentation Ambiguity
396,61355474,Why does tf.executing_eagerly() return False in TensorFlow 2?,"<p>Let me explain my set up. I am using TensorFlow 2.1, the Keras version shipped with TF, and TensorFlow Probability 0.9.</p>

<p>I have a function <code>get_model</code> that creates (with the functional API) and returns a model using Keras and custom layers. In the <code>__init__</code> method of these custom layers <code>A</code>, I call a method <code>A.m</code>, which executes the statement <code>print(tf.executing_eagerly())</code>, but it returns <code>False</code>. Why?</p>

<p>To be more precise, this is roughly my setup</p>

<pre><code>def get_model():
    inp = Input(...)
    x = A(...)(inp) 
    x = A(...)(x)
    ...
    model = Model(inp, out)
    model.compile(...)
    return model

class A(tfp.layers.DenseFlipout): # TensorFlow Probability
    def __init__(...):
        self.m()

    def m(self): 
        print(tf.executing_eagerly()) # Prints False
</code></pre>

<p>The documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/executing_eagerly"" rel=""nofollow noreferrer""><code>tf.executing_eagerly</code></a> says</p>

<blockquote>
  <p>Eager execution is enabled by default and this API returns True in most of cases. However, this API might return False in the following use cases.</p>
  
  <ul>
  <li>Executing inside <code>tf.function</code>, unless under <code>tf.init_scope</code> or <code>tf.config.experimental_run_functions_eagerly(True)</code> is previously called.</li>
  <li>Executing inside a transformation function for <code>tf.dataset</code>.</li>
  <li><code>tf.compat.v1.disable_eager_execution()</code> is called.</li>
  </ul>
</blockquote>

<p>But these cases are not my case, so <code>tf.executing_eagerly()</code> should return <code>True</code> in my case, but no. Why?</p>

<p>Here's a simple complete example (in TF 2.1) that illustrates the problem.</p>

<pre><code>import tensorflow as tf


class MyLayer(tf.keras.layers.Layer):
    def call(self, inputs):
        tf.print(""tf.executing_eagerly() ="", tf.executing_eagerly())
        return inputs


def get_model():
    inp = tf.keras.layers.Input(shape=(1,))
    out = MyLayer(8)(inp)
    model = tf.keras.Model(inputs=inp, outputs=out)
    model.summary()
    return model


def train():
    model = get_model()
    model.compile(optimizer=""adam"", loss=""mae"")
    x_train = [2, 3, 4, 1, 2, 6]
    y_train = [1, 0, 1, 0, 1, 1]
    model.fit(x_train, y_train)


if __name__ == '__main__':
    train()
</code></pre>

<p>This example prints <code>tf.executing_eagerly() = False</code>.</p>

<p>See <a href=""https://github.com/tensorflow/tensorflow/issues/38775"" rel=""nofollow noreferrer"">the related Github issue</a>.</p>
",1,Documentation Replicability
397,61428918,tensorflow2: keras: model.fit() callbacks and eager mode,"<p>I am running Tensorflow 2.1 with keras API. I am following the following coding style:</p>

<pre><code>    model = tf.keras.Sequential()
    ...
    model.fit(..., callbacks=callbacks)
</code></pre>

<p>Now, I would like to save some intermediate layer tensor value as image summary (as a sample what is happening at n-th training step). In order to do this, I've implemented my own callback class. I've also learned how <code>keras.callbacks.TensorBoard</code> is implemented, since it can save layer weights as image summaries.
I do the following in my <code>on_epoch_end</code>:</p>

<pre><code>tensor = self.model.get_layer(layer_name).output

with context.eager_mode():
    with ops.init_scope():
        tensor = tf.keras.backend.get_value(tensor)
    tf.summary.image(layer_name, tensor, step=step, max_outputs=1)
</code></pre>

<p>Unfortunately, I am still getting issue related to eager/graph modes:</p>

<pre><code>    tensor = tf.keras.backend.get_value(tensor)
  File ""/home/matwey/lab/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py"", line 3241, in get_value
    return x.numpy()
AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>

<p>Unfortunately, there is a little to no documentation on how to correctly combine keras callbacks and <code>tf.summary.image</code>. How could I overcome this issue?</p>

<p><strong>upd:</strong> tf_nightly-2.2.0.dev20200427 has the same behaviour.</p>
",1,Lack of Alternative Solutions/Documentation
398,61522019,Is it still necessary to implement `compute_output_shape()` when defining a custom tf.keras Layer?,"<p>I have implemented a custom <code>Layer</code> in <code>tf.keras</code>, using TensorFlow 2.1.0.</p>

<p>In the past, when using the stand-alone Keras, it was important to define the <code>compute_output_shape(input_shape)</code> method in any custom layer so that the computational graph could be created. </p>

<p>Now, having moved to TF2, I found out that even if I remove that method from my custom implementation the layer still works as expected. Apparently, it works both in eager and graph mode.
This is an example of what I mean: </p>

<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras.layers import Layer, Input
from tensorflow.keras.models import Sequential
import numpy as np


class MyLayer(Layer):
    def call(self, inputs):
        return inputs[:, :-1]  # Do something that changes the shape


m = Sequential([MyLayer(), MyLayer()])
m.predict(np.ones((10, 3)))  # This would not have worked in the past
</code></pre>

<p>Is it safe to say that <code>compute_output_shape()</code> is not necessary anymore? Am I missing something important?</p>

<p>In the documentation there's no explicit mention of removing <code>compute_output_shape()</code>, although none of the examples implements it explicitly. </p>

<p>Thanks</p>
",1,Inadequate Examples
399,61526556,Serializing a tensor and writing to tfrecord from within a graph,"<p>I would like to write tensorflow example records to a TFRecordWriter from inside an AutoGraph generated graph.</p>

<p>The documentation for tensorflow 2.0 states the following:</p>

<blockquote>
  <p>The simplest way to handle non-scalar features is to use tf.serialize_tensor to convert tensors to binary-strings. Strings are scalars in tensorflow.</p>
</blockquote>

<p>However, <code>tf.io.serialize_tensor</code> returns a tensor of byte-string. Creating an Example proto requires a bytes list, not a tensor. </p>

<p>How do I write a tf.train.Example to a tf record from inside a graph?</p>

<p>Code to reproduce:</p>

<pre><code>%tensorflow_version 2.x
import tensorflow as tf

@tf.function
def example_write():
  writer = tf.io.TFRecordWriter(""test.tfr"")
  x = tf.constant([[0, 1], [2, 3]])
  x = tf.io.serialize_tensor(x)
  feature = {
      ""data"": tf.train.Features(
        bytes_list=tf.train.BytesList(value=[x]))
  }
  ex = tf.train.Example(features=tf.train.Features(
      feature=feature))
  writer.write(ex.SerializeToString())

example_write()
</code></pre>

<p>and the error</p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-df8a97eb17c9&gt; in &lt;module&gt;()
     12   writer.write(ex.SerializeToString())
     13 
---&gt; 14 example_write()

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

TypeError: in user code:

    &lt;ipython-input-6-df8a97eb17c9&gt;:6 example_write  *
        feature = {

    TypeError: &lt;tf.Tensor 'SerializeTensor:0' shape=() dtype=string&gt; has type Tensor, but expected one of: bytes
</code></pre>
",1,Documentation Replication on Other Examples
400,61628845,Alternative to tf.compat.v1,"<p>I was trying to migrate my tf1 codes into tf2.</p>

<p>For this purpose, I changed the following functions as follows:</p>

<p><code>tf.losses.softmax_cross_entropy()</code>into<code>tf.compat.v1.losses.softmax_cross_entropy()</code>
<code>tf.train.MomentumOptimizer()</code>into<code>tf.compat.v1.train.MomentumOptimizer()</code>
<code>tf.train.get_or_create_global_step()</code>
into  <code>tf.compat.v1.train.get_or_create_global_step()</code></p>

<p>However, I want to rewrite my codes in tf2 directly without using <code>tf.compat.v1</code></p>

<p>How is it?</p>
",1,Documentation Replication on Other Examples
401,61720708,How do you save a Tensorflow dataset to a file?,"<p>There are at least two more questions like this on SO but not a single one has been answered.</p>

<p>I have a dataset of the form:</p>

<pre><code>&lt;TensorSliceDataset shapes: ((512,), (512,), (512,), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;
</code></pre>

<p>and another of the form:</p>

<pre><code>&lt;BatchDataset shapes: ((None, 512), (None, 512), (None, 512), (None,)), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;
</code></pre>

<p>I have looked and looked but I can't find the code to save these datasets to files that can be loaded later. The closest I got was <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/TFRecordWriter"" rel=""noreferrer"">this page in the TensorFlow docs</a>, which suggests serializing the tensors using <code>tf.io.serialize_tensor</code> and then writing them to a file using <code>tf.data.experimental.TFRecordWriter</code>.</p>

<p>However, when I tried this using the code:</p>

<pre><code>dataset.map(tf.io.serialize_tensor)
writer = tf.data.experimental.TFRecordWriter('mydata.tfrecord')
writer.write(dataset)
</code></pre>

<p>I get an error on the first line:</p>

<blockquote>
  <p>TypeError: serialize_tensor() takes from 1 to 2 positional arguments but 4 were given</p>
</blockquote>

<p>How can I modify the above (or do something else) to accomplish my goal?</p>
",1,Documentation Replication on Other Examples
402,61743921,can we build object detection model using Tensorflow or it is only possible with the help f tf.keras,"<p>Is there any way to build object detection model using Tensorflow without any help of tf.keras module?</p>

<p>From Tensorflow documentation I'm  not able to find any example which helps to create model without Keras.</p>
",1,Lack of Alternative Solutions/Documentation
403,61762324,why tf.divide does not return a tensor,"<p>If I run the following code using tf2</p>

<pre><code>import tensorflow as tf
import math as m

print(tf.add(5, 2))
print(tf.multiply(5, 2))
print(tf.divide(5, 2))
print(tf.multiply(tf.add(3, 2), tf.add(14, 32)))
print(tf.multiply(2.54, tf.divide(8, 2.6)))
print(tf.subtract(6.3, 2.1045))
print(tf.pow(3.6, 2))
print(tf.add(1, tf.pow(2, 2)))
print(tf.sqrt(5.0))
print(tf.cos(m.pi))
</code></pre>

<p>I get this as an ouput </p>

<pre><code>tf.Tensor(7, shape=(), dtype=int32)
tf.Tensor(10, shape=(), dtype=int32)
2.5
tf.Tensor(230, shape=(), dtype=int32)
tf.Tensor(7.815385, shape=(), dtype=float32)
tf.Tensor(4.1955004, shape=(), dtype=float32)
tf.Tensor(12.959999, shape=(), dtype=float32)
tf.Tensor(5, shape=(), dtype=int32)
tf.Tensor(2.236068, shape=(), dtype=float32)
tf.Tensor(-1.0, shape=(), dtype=float32)
</code></pre>

<p>Why only tf.divide does not return a tensor?</p>
",1,Documentation Replicability
404,61767803,Tensorflow 1.x to Tensorflow 2.1.0,"<p>I am trying to update code written in Tensorflow 1.x to code in Tensorflow 2.1.0. I have been converting codes using Tensorflow 2.1.0 documentation, and I had no problems until this code.</p>

<pre><code>loss = tf.losses.softmax_cross_entropy(one_hot_labels, logits)
</code></pre>

<p>Above code is Tensorflow 1.x version, and I think, according to Tensorflow 2.1.0 documentation, the properly updated code is </p>

<pre><code>loss = tf.nn.softmax_cross_entropy_with_logits(one_hot_labels, logits)
</code></pre>

<p>Then, when I run</p>

<pre><code>return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)
</code></pre>

<p>I get the following error.</p>

<pre><code>Loss must be scalar, given: Tensor(""softmax_cross_entropy_with_logits/Reshape_2:0"", shape=(512,), dtype=float32)**
</code></pre>

<p>So, I am guessing in Tensorflow 1.x version, the loss was passed as 'tensor' to tf.estimator.EstimatorSpec, but in Tensorflow 2.1.0, the loss has to be passed as <code>scalar</code> to <code>tf.estimator.EstimatorSpec</code>? Loss (the way it is defined here) in both Tensorflow 1.x and 2.1.0 is tensor if I remember it correctly.</p>

<p>So, does anyone know how to convert tensor to scalar (which I don't think will be sufficient nor efficient in building the CNN model) or better yet, how to solve this dilemma?</p>

<p>Or did I convert the original code the wrong way?</p>

<p>I would very much appreciate if compat.v1. is not used unless absolutely necessary (i.e. no other way to use the code in Tensorflow 2.1.0 than compat.v1.)</p>
",1,Documentation Replication on Other Examples
405,61885570,Reading a tfrecord: DecodeError: Error parsing message,"<p>I am using colab to run a <a href=""https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/handling_sparse_features.ipynb"" rel=""nofollow noreferrer"">tutorial</a> on tensorflow ranking. It uses wget to fetch the tfrecord:</p>

<pre><code>!wget -O ""/tmp/train.tfrecords"" ""http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/ELWC/train.tfrecords""
</code></pre>

<p>I am using this code to try to look at the structure of the tfrecord:</p>

<pre><code>for example in tf.compat.v1.python_io.tf_record_iterator(""/tmp/train.tfrecords""):
    print(tf.train.Example.FromString(example))
    break
</code></pre>

<p>And I am getting:</p>

<pre><code>DecodeError: Error parsing message
</code></pre>

<p>How to generally look at the structure of tfrecords instead?</p>

<p>A second question: Where to find documentation on classes like <code>tf.train.Example</code>? I just find this <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Example"" rel=""nofollow noreferrer"">empty page</a>.</p>
",1,Requesting (Additional) Documentation/Examples
406,61988657,Why does tensorflow.rank always return shape with null value,"<p>Being a beginner to TensorFlow <strong>I couldn't get why does tensorflow.rank always return shape with null value?</strong></p>

<p><strong>This is what I am working on:</strong></p>

<pre><code>import tensorflow as tf
%tensorflow_version 2.x

list_2d = [[1,2,3,4],
             [5,6,7,8],
             [9,10,11,12]
]
tensor_2d = tf.Variable(list_2d)

print(tensor_2d.shape)
print(tf.rank(tensor_2d))
</code></pre>

<p><strong>and the output is</strong> </p>

<pre><code>(3, 4)
tf.Tensor(2, shape=(), dtype=int32)
</code></pre>

<p>So <strong>my question is what is this <code>shape=()</code> from <code>tf.rank</code> output</strong>?</p>

<p>I couldn't get much from here - <a href=""https://www.tensorflow.org/api_docs/python/tf/rank"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/rank</a></p>
",1,Documentation Replicability
407,61994285,TensorFlow: Error using weighted_categorical_column,"<p>I work on a binary classification problem containing a field STREET. In a first step I used the Tokenization to the get a word list (frequency of how often one word appears in the different datasets). Then I used this information to create two columns in my Dataframe describing the word and how often it was used:</p>

<pre><code>def buildWeightList(indexes, tokenizer):
    weights = []
    for index in indexes:
        if index == 0:
            weights.append(0)
        else:
            weights.append(tokenizer.index_docs.get(index))
    return weights
</code></pre>

<pre><code>street_tokenized = ts.texts_to_sequences(data['STREETPRO'])
data['STREETPRO'] = tf.keras.preprocessing.sequence.pad_sequences(street_tokenized, maxlen=1)
data['STREETFREQ']  = buildWeightList(data['STREETPRO'], ts)
</code></pre>

<p>After I converted the Dataframe to a TensorFlow Dataset I have used the following code to add it to my future columns:</p>

<pre><code>vocabulary_list = np.arange(0, street_num_words + 1, 1).tolist()
street_voc = tf.feature_column.categorical_column_with_vocabulary_list(
    key='STREETPRO', vocabulary_list=vocabulary_list, dtype=tf.dtypes.int64)

weighted_street = tf.feature_column.weighted_categorical_column(categorical_column=street_voc, weight_feature_key='STREETFREQ', dtype=tf.dtypes.int64)
street_one_hot = feature_column.indicator_column(weighted_street)

feature_columns.append(street_one_hot)
</code></pre>

<p>As you can see I used the function tf.feature_column.weighted_categorical_column. Unfortunately I get the following error when I try to train my model:</p>

<pre><code>InvalidArgumentError:  indices and values rows (indexing dimension) must match. (indices = 5, values = 1)
     [[node sequential/dense_features_2/STREETPRO_weighted_by_STREETFREQ_indicator/SparseMerge/SparseReorder (defined at &lt;ipython-input-40-964101dd1dc8&gt;:3) ]] [Op:__inference_train_function_986]
</code></pre>

<p>Furthermore I get the following warning:</p>

<pre><code>WARNING:tensorflow:From ...\feature_column\feature_column_v2.py:4366: sparse_merge (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
</code></pre>

<p>Now I have two questions:</p>

<p><strong>First</strong>: does it make sense to use this function for my described problem? Unfortunately, I couldn’t find a detailed description how this function works (only this short documentations: <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/weighted_categorical_column"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/feature_column/weighted_categorical_column</a>) </p>

<p><strong>Second</strong>: How can I fix the described error?</p>
",1,Lack of Alternative Solutions/Documentation
408,62039068,Advice on how to create a custom tf.keras optimizer (optimizer_v2),"<p>I want to make an <em>accumulated SGD optimizer</em> for <code>tf.keras</code> (not <code>keras</code> standalone). I have found a couple of implementations of standalone <code>keras</code> accumulated SGD optimizers including this <a href=""https://pypi.org/project/runai/"" rel=""nofollow noreferrer"">one</a> on pypi. Nevertheless, I am using a project which make use of <code>tf.keras</code>. And as I have seen it's not a good idea to mix them together. </p>

<p>The problem is that the documentation for achieving this custom optimizer is not really straight forward. The base class (which I should inherit from) is <a href=""https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"" rel=""nofollow noreferrer"">Optimizer_v2.py</a> which contains some information in the comment section about the task.</p>

<p>The required methods that should be overridden are:
    - <code>resource_apply_dense</code> (update variable given gradient tensor is dense)
    - <code>resource_apply_sparse</code> (update variable given gradient tensor is sparse)
    - <code>create_slots</code> (if your optimizer algorithm requires additional variables)
    - <code>get_config</code> (serialization of the optimizer, include all hyper parameters)</p>

<p>Of course of these ones only <code>get_config()</code> actually exists in the base class. <code>resource_apply_dense</code> is actually <code>_resource_apply_dense</code>, <code>resource_apply_sparse</code> is <code>_resource_apply_sparse</code> and <code>create_slots</code> does not even exist in base class. In subclasses as <code>SGD</code> in <code>gradient_decent.py</code>, <code>create_slots</code> also exists as <code>_create_slots</code>. </p>

<p>Anyway, apparently the documentation is not updated (there is also an issue regarding this in git but I don't remember the link which pointed this lack of consistency with the documentation) but this makes the whole procedure difficult. For example in <code>SGD</code> I have to override the <code>_resource_apply_dense()</code> method but I cannot understand where the gradients are being calculated and where they are updated.</p>

<p>The actual code is given below:</p>

<pre><code>def _resource_apply_dense(self, grad, var, apply_state=None):
        var_device, var_dtype = var.device, var.dtype.base_dtype
        coefficients = ((apply_state or {}).get((var_device, var_dtype))
                        or self._fallback_apply_state(var_device, var_dtype))

        if self._momentum:
          momentum_var = self.get_slot(var, ""momentum"")
          return training_ops.resource_apply_keras_momentum(
              var.handle,
            momentum_var.handle,
            coefficients[""lr_t""],
            grad,
            coefficients[""momentum""],
            use_locking=self._use_locking,
            use_nesterov=self.nesterov)
        else:
            return training_ops.resource_apply_gradient_descent(
                var.handle, coefficients[""lr_t""], grad, use_locking=self._use_locking)
</code></pre>

<p>which obviously rely on <code>training_ops.resource_apply_keras_momentum</code> and <code>training_ops.resource_apply_gradient_descent</code> to do the actual job. How can I split the 2 parts mentioned in the <code>minimize()</code> method in <code>OptimizerV2</code> from the above code? The 2 parts are:
<code>_compute_gradients()</code> and <code>apply_gradients()</code>.</p>

<p>There are a lot of parts that are confusing in this comments like for example in the base class:</p>

<blockquote>
  <p>Many optimizer subclasses, such as <code>Adam</code> and <code>Adagrad</code> allocate and
  manage   additional variables associated with the variables to train. 
  These are called   <i>Slots</i>.  Slots have names and you can ask the
  optimizer for the names of   the slots that it uses.</p>
</blockquote>

<p>although if I declare an Adam optimizer and ask for slot names I get an empty list (?).</p>

<pre><code>optimizer = Adam(lr=1e-3)    
optimizer.get_slot_names()

[]
</code></pre>

<p>Another confusing issue is the use of private methods which is not clear when they are called and what's their purpose. For example <code>_prepare_local()</code> is contained within <code>SGD</code> and includes a line:</p>

<pre><code>apply_state[(var_device, var_dtype)][""momentum""] = array_ops.identity(self._get_hyper(""momentum"", var_dtype))
</code></pre>

<p>Anyway, the problem here is that I do not know which exactly approach to follow to create a custom <code>tf.keras</code> optimizer. Instructions included in comments seem to contradict with the actual implemented subclasses, and the latter also seem to assign the dirty work to the actual C++ function without being clear how this is done or how (in my case) to separate the actions (like the gradient calculation and application). So, is there any advice someone can provide on how to proceed and steps to follow to accomplish this (relatively) simple task?</p>

<p>I am using tf 1.15 by the way (so the links are from there).</p>
",1,Documentation Replication on Other Examples
409,62211822,TF2 Keras - Feature Engineering in Keras saved model via Tensorflow Serving,"<p>The Tensorflow 2 documentation for preprocessing / feature engineering over a Keras model seems to be quite confusing and isn't very friendly.</p>

<p>Currently I have a simple Keras N-layer model with TF feature columns feeding as dense layer. For training I have CSV files read using <code>tf.dataset</code> API and I have written a feature engineering function that creates new features using <code>dataset.map</code> function.</p>

<pre><code>def feature_engg_features(features):
  #Add new features
  features['nodlgrbyvpatd'] = features['NODLGR'] / features['VPATD']

  return(features)
</code></pre>

<p>I can save the model easily using <code>tf.keras.models.save_model</code> method. However I am having trouble figuring out how to attach the <code>feature_engineering</code> steps in the serving function.</p>

<p><strong>Requirement</strong>: Now I want to take the same feature engineering function above and attach it to my <code>serving function</code> so that in JSON input via <code>tensorflow_model_server</code> the same feature engineering steps are applied. I know about the lambda Layer option in Keras but I want to do this via <code>saved_model</code> method but there are a lot of difficulties here.</p>

<p>For Example, below code gives error:</p>

<pre><code>def feature_engg_features(features):
  #Add new features
  features['nodlgrbyvpatd'] = features['NODLGR'] / features['VPATD']
  return(features)

@tf.function
def serving(data):
    data = tf.map_fn(feature_engg_features, data, dtype=tf.float32)

    # Predict
    predictions = m_(data)

version = ""1""
tf.keras.models.save_model(
    m_,
    ""./exported_model/"" + version,
    overwrite=True,
    include_optimizer=True,
    save_format=None,
    signatures=serving,
    options=None
)
</code></pre>

<p>Error:</p>

<pre><code>Only `tf.functions` with an input signature or concrete functions can be used as a signature.
</code></pre>

<p>The above error is because I have not provided InputSignature of my Keras model but I am not able to understand that I have 13 input fields, what is expected as input signature.</p>

<p>So I wanted to know if anyone knows the shortest way of solving this out. This is a very basic requirement and Tensorflow seems to have kept this quite complicated for Keras Tensorflow model serving.</p>

<p>GIST: <a href=""https://colab.research.google.com/gist/rafiqhasan/6abe93ac454e942317005febef59a459/copy-of-dl-e2e-structured-mixed-data-tf-2-keras-estimator.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/gist/rafiqhasan/6abe93ac454e942317005febef59a459/copy-of-dl-e2e-structured-mixed-data-tf-2-keras-estimator.ipynb</a></p>

<p><strong>EDIT:</strong>
I fixed it, so TensorSpec has to be generated and passed for each feature and also model( ) has to be called in serving function.</p>

<pre><code>@tf.function
def serving(WERKS, DIFGRIRD, SCENARIO, TOTIRQTY, VSTATU, EKGRP, TOTGRQTY, VPATD, EKORG, NODLGR, DIFGRIRV, NODLIR, KTOKK):
    ##Feature engineering
    nodlgrbyvpatd = tf.cast(NODLGR / VPATD, tf.float32)

    payload = {
        'WERKS': WERKS,
        'DIFGRIRD': DIFGRIRD,
        'SCENARIO': SCENARIO,
        'TOTIRQTY': TOTIRQTY,
        'VSTATU': VSTATU,
        'EKGRP': EKGRP,
        'TOTGRQTY': TOTGRQTY,
        'VPATD': VPATD,
        'EKORG': EKORG,
        'NODLGR': NODLGR,
        'DIFGRIRV': DIFGRIRV,
        'NODLIR': NODLIR,
        'KTOKK': KTOKK,
        'nodlgrbyvpatd': nodlgrbyvpatd,        
    }

    ## Predict
    ##IF THERE IS AN ERROR IN NUMBER OF PARAMS PASSED HERE OR DATA TYPE THEN IT GIVES ERROR, ""COULDN'T COMPUTE OUTPUT TENSOR""
    predictions = m_(payload)
    return predictions

serving = serving.get_concrete_function(WERKS=tf.TensorSpec([None,], dtype= tf.string, name='WERKS'), 
                                        DIFGRIRD=tf.TensorSpec([None,], name='DIFGRIRD'),
                                        SCENARIO=tf.TensorSpec([None,], dtype= tf.string, name='SCENARIO'), 
                                        TOTIRQTY=tf.TensorSpec([None,], name='TOTIRQTY'),
                                        VSTATU=tf.TensorSpec([None,], dtype= tf.string, name='VSTATU'), 
                                        EKGRP=tf.TensorSpec([None,], dtype= tf.string, name='EKGRP'),
                                        TOTGRQTY=tf.TensorSpec([None,], name='TOTGRQTY'), 
                                        VPATD=tf.TensorSpec([None,], name='VPATD'),
                                        EKORG=tf.TensorSpec([None,], dtype= tf.string, name='EKORG'), 
                                        NODLGR=tf.TensorSpec([None,], name='NODLGR'),
                                        DIFGRIRV=tf.TensorSpec([None,], name='DIFGRIRV'),
                                        NODLIR=tf.TensorSpec([None,], name='NODLIR'),
                                        KTOKK=tf.TensorSpec([None,], dtype= tf.string, name='KTOKK')
                                        )

version = ""1""
tf.saved_model.save(
    m_,
    ""./exported_model/"" + version,
    signatures=serving
)
</code></pre>
",1,Documentation Replication on Other Examples
410,62223016,Single Prediction Image doesn't need to be rescaled?,"<p>I followed a tutorial to make my first Convolutional Neural Network using Keras and I have a small question regarding the rescaling step.</p>

<p>So when we are importing the training set and test set, we create an instance of  the <code>tf.keras.preprocessing.image.ImageDataGenerator</code> class and use it as:</p>

<pre class=""lang-py prettyprint-override""><code>train_datagen = ImageDataGenerator(rescale=1/255)
</code></pre>

<p>Along with some other augmentation parameters. My understanding is that we use the <code>rescale</code> parameter to normalize the pixel values of the images imported.</p>

<p>But when we load up a single image to run through the CNN, we write something like (code from keras docs):</p>

<pre class=""lang-py prettyprint-override""><code>image = tf.keras.preprocessing.image.load_img(image_path)
input_arr = keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr])  # Convert single image to a batch.
predictions = model.predict(input_arr)
</code></pre>

<p>My question is, I cannot see the single input image being <code>rescaled</code> anywhere. Is it being done implicitly, or is there no need to actually perform rescaling? If the latter, then why is it so?</p>

<p>Thanks!</p>
",1,Documentation Replicability
411,62236460,How to set bounds and constraints on Tensorflow Variables (tf.Variable),"<p>I am using Tensorflow to minimize a function. The function takes about 10 parameters. Every single parameter has bounds, e.g. a minimum and a maximum value the parameter is allowed to take. For example, the parameter x1 needs to be between 1 and 10.</p>

<p>I also have a pair of parameters that need to have the following constraint x2 > x3. In other words, x2 must always be bigger than x3. (In addition to this, x2 and x3 also have bounds, similarly to the example of x1 above.)</p>

<p>I know that tf.Variable has a ""constraint"" argument, however I can't really find any examples or documentation on how to use this to achieve the bounds and constraints as mentioned above.</p>

<p>Thank you!</p>
",1,Documentation Replicability
412,62249084,What is the numpy equivalent of TensorFlow Xavier initializer for CNN?,"<p>I would like to re-create the Xavier initialization in NumPy (using basic functions) in the same way that TensorFlow2 does for CNN. 
Here is how I learned to do Xavier initialization in NumPy:</p>

<pre><code># weights.shape = (2,2)
np.random.seed(0)
nodes_in = 2*2
weights = np.random.rand(2,2) * np.sqrt(1/nodes_in)

&gt;&gt;&gt;array([[0.27440675, 0.35759468],
          [0.30138169, 0.27244159]])
</code></pre>

<p>This is the way I learned Xavier initialization for the logistic regression model. It seems that for Convolution Neural Network it should be different but I don't know how.</p>

<pre><code>initializer = tf.initializers.GlorotUniform(seed=0)
tf.Variable(initializer(shape=[2,2],dtype=tf.float32))

&gt;&gt;&gt;&lt;tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=
   array([[-0.7078647 ,  0.50461936],
          [ 0.73500216,  0.6633029 ]], dtype=float32)&gt;
</code></pre>

<p>I'm confused by the TensorFlow <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform"" rel=""noreferrer"">documentation</a> when they explain the ""fan_in"" and ""fan_out"". I'm guessing this is where the problem is. Can somebody dumb it down for me, please? </p>

<p>Much appreciate it!</p>

<p><em>[UPDATE]:</em></p>

<p>When I follow the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform"" rel=""noreferrer"">tf.keras.initializers.GlorotUniform</a> documentation I still don't come to the same results:</p>

<pre><code># weights.shape = (2,2)
np.random.seed(0)
fan_in = 2*2
fan_out = 2*2
limit = np.sqrt(6/(fan_in + fan_out))
np.random.uniform(-limit,limit,size=(2,2))
&gt;&gt;&gt;array([[0.08454747, 0.37271892],
          [0.17799139, 0.07773995]])
</code></pre>
",1,Documentation Replication on Other Examples
413,62284095,What are the parameters to tf.GradientTape()'s __exit__ function?,"<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">documentation</a> for <code>tf.GradientTape</code>, its <code>__exit__()</code> method takes three positional arguments: <code>typ, value, traceback</code>.</p>

<p><strong>What exactly are these parameters?</strong> </p>

<p>How does the <code>with</code> statement infer them? </p>

<p>What values should I give them in the code below (where I'm <em>not</em> using a <code>with</code> statement):</p>

<pre><code>x = tf.Variable(5)

gt = tf.GradientTape()
gt.__enter__()
y = x ** 2
gt.__exit__(typ = __, value = __, traceback = __)
</code></pre>
",1,Documentation Replicability
414,62476015,TF 2.2 Saved_model from keras with custom signatures and preprocessing,"<p>I am trying to use the <code>tf.saved_model.save</code> after a training a Transformer Model in order to deploy it.
My model has multiple inputs and outputs. If I am using the saved_model function for serving, I add some issue about the input shape with the first input, and the second input is not visible when I am using the <code>saved_model_cli show</code> function. I found a way to solve that issue by wrapping the main transformer block by a model module and then save the model.</p>
<pre><code>def build_model(MAX_LEN, transformer_layer):
    inp = Input(shape=(MAX_LEN,), dtype=tf.int32, name=&quot;input_word_ids&quot;)
    inp2 = Input(shape=(MAX_LEN,), dtype=tf.int32, name=&quot;attention_mask&quot;)
    sequence_output, pooled_output = transformer_layer(inp, attention_mask = inp2)
    out = Dense(1, activation='sigmoid', name='outputs')(pooled_output)
    model = Model(inputs=[inp], outputs=[out])
    return model
</code></pre>
<p>But, I see in the documentation there is another way which consist in using signatures to indicate the inputs/outputs during the  <code>tf.saved_model.save</code>. To do that, we need to use the <code>tf.Module</code> class but I haven't understood how to use it in the case we have multiple inputs/outputs exactly (how to make understand the module that inputs tensor should be related to that inputs for the model?) .
Does anyone know how to do that with the second method ?  Morever can we do preprocessing of the data through the signature ?https://www.tensorflow.org/guide/saved_model</p>
<pre><code>class CustomModule(tf.Module):

  def __init__(self):
    super(CustomModule, self).__init__()
    self.v = tf.Variable(1.)

  @tf.function
  def __call__(self, x):
    print('Tracing with', x)
    return x * self.v

  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])
  def mutate(self, new_v):
    self.v.assign(new_v)

module = CustomModule()
</code></pre>
",1,Documentation Replication on Other Examples
415,62611459,How to support mixed precision in custom Tensorflow layers?,"<p><strong>When developing my own custom layers for <code>tf.keras</code>: how am I supposed to support mixed precision?</strong></p>
<p>The <a href=""https://www.tensorflow.org/guide/mixed_precision"" rel=""nofollow noreferrer"">documentation of mixed precision</a> - a feature which is currently marked as experimental in Tensorflow 2.2 - only explains how to use it from a consumers perspective with predefined layers such as the <code>tf.keras.layers.Dense</code> one.</p>
<p>I already tried to guess it myself and found two - maybe relevant - details:</p>
<ul>
<li><p>The <code>dtype</code> property stays as <code>float32</code> by default when using 16-bit mixed precision.</p>
</li>
<li><p>There is a <code>mixed_precision.get_layer_policy(layer)</code> method (see <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/get_layer_policy"" rel=""nofollow noreferrer"">docs</a>) and a <code>mixed_precision.global_policy()</code> method (see <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/global_policy"" rel=""nofollow noreferrer"">docs</a>) which could be used to retrieve the configured <code>compute_dtype</code> and <code>variable_dtype</code>.</p>
</li>
</ul>
<p>Am I supposed to use the above <code>get_layer_policy</code>-method and just cast my variables into <code>compute_dtype</code> within the <code>call(...)</code> method of my layer? (And pass <code>variable_dtype</code> in my layers <code>build(...)</code> method to <code>add_weight(...)</code> when creating variables?)</p>
<p>For example, here is naive sample implementation of a standard dense neuron layer:</p>
<pre class=""lang-py prettyprint-override""><code>  def call(self, input):
    policy = mixed_precision.get_layer_policy(self)
    bias = tf.cast(self._bias, policy.compute_dtype)
    weights = tf.cast(self._weights, policy.compute_dtype)
    y = tf.nn.bias_add(tf.matmul(input, weights), bias)
    outputs = self._activation(y)
    return outputs
</code></pre>
<p>Sure, nobody would implement such basic stuff themselves, that one is just for demonstration. But, would this be the way the Tensorflow team expects us to implement the <code>call(...)</code> methods of our custom layers?</p>
",1,Documentation Replication on Other Examples
416,62620694,What is difference between tf.keras.models.sequential vs tf.keras.sequential?,"<p>What is difference between <code>tf.keras.models.Sequential()</code> vs <code>tf.keras.Sequential()</code>? I don't understand differences between them quite well. Can somebody explain it to me? I am new to TensorFlow but have some basic understanding on machine learning.</p>
",1,Documentation Ambiguity
417,62670041,batch_size in tf model.fit() vs. batch_size in tf.data.Dataset,"<p>I have a large dataset that can fit in host memory. However, when I use tf.keras to train the model, it yields GPU out-of-memory problem. Then I look into tf.data.Dataset and want to use its batch() method to batch the training dataset so that it can execute the model.fit() in GPU. According to its documentation, an example is as follows:</p>
<pre><code>train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))
test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))

BATCH_SIZE = 64
SHUFFLE_BUFFER_SIZE = 100

train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)
</code></pre>
<p>Is the BATCH_SIZE in dataset.from_tensor_slices().batch() the same as the batch_size in the tf.keras modelt.fit()?</p>
<p>How should I choose BATCH_SIZE so that GPU has sufficient data to run efficiently and yet its memory is not overflown?</p>
",1,Documentation Replication on Other Examples
418,62752605,Loss function in tf.nn.sampled_softmax_loss,"<p>I have a question regarding Tensorflow:</p>
<p>Which loss function is used in <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""nofollow noreferrer""><code>tf.nn.sampled_softmax_loss</code></a>?</p>
<p>I believe it's <em><strong>cross-entropy</strong></em>, but it is not written on the official website. Can anyone confirm my guess?</p>
",1,Documentation Replicability
419,62786629,how model info is sent to keras model,"<p>below is the code in tensorflow document.
(<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Model</a>)</p>
<pre><code>inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
</code></pre>
<p>in tf.keras.Model, input and output tensor related info is sent.</p>
<p>But there is no info about modeling( two dense layer and activation funtion)</p>
<p>How modeling info is sent to tf.keras.Model??</p>
<p>thanks.</p>
",1,Inadequate Examples
420,62877768,Input shape of tf.data.Dataset not accepted by model.fit(),"<p>I would like to feed with data my model by applying a <code>tf.data.Dataset</code>.</p>
<p>Having checked the documentation of TF 2.0 I found that the <code>.fit()</code> function (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit</a>) accepts:</p>
<blockquote>
<p>x - A tf.data dataset. Should return a tuple of either (inputs, targets)
or (inputs, targets, sample_weights).</p>
</blockquote>
<p>So, I wrote the following minial proof of concept code:</p>
<pre><code>from sklearn.datasets import make_blobs
import tensorflow as tf
from tensorflow.keras import Model, Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.metrics import Accuracy, AUC

X, Y = make_blobs(n_samples=500, n_features=2, cluster_std=3.0, random_state=1)

def define_model():
    model = Sequential()
    model.add(Dense(units=1, activation=&quot;sigmoid&quot;, input_shape=(2,)))
    model.compile(optimizer=&quot;adam&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[AUC(), Accuracy()])
    return model

model = define_model()

X_ds = tf.data.Dataset.from_tensor_slices(X)
Y_ds = tf.data.Dataset.from_tensor_slices(Y)
dataset = tf.data.Dataset.zip((X_ds, Y_ds))

for elem in dataset.take(1):
    print(type(elem))
    print(elem)

model.fit(x=dataset) #&lt;-- does not work
#model.fit(x=X, y=Y) &lt;-- does work without any problems....
</code></pre>
<p>As mentioned in the second comment, the code that does not apply a <code>tf.data.Dataset</code> works fine.</p>
<p>However, when applying the Dataset object I get the following error message:</p>
<pre><code>&lt;class 'tuple'&gt;
(&lt;tf.Tensor: shape=(2,), dtype=float64, numpy=array([-10.42729974,  -0.85439721])&gt;, &lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;)
... other output here...
ValueError: Error when checking input: expected dense_19_input to have
shape (2,) but got array with shape (1,)
</code></pre>
<p>From my understanding of the documentation, the dataset I have constructed should be exactly the tuple object the fit method expects.</p>
<p>I do not understand this error message.</p>
<p>What am I doing wrong here?</p>
",1,Documentation Ambiguity
421,62956096,Is it possible to extract trained class names from tflite model?,"<p>I have tried to search everywhere, tried everything in <code>tflite_interpreter = tf.lite.Interpreter(model_path='model.tflite')</code>, read tflite documentation but I cannot find the method to extract the class names from the model.</p>
<p>Is it possible?</p>
",1,Lack of Alternative Solutions/Documentation
422,62962147,TensorFlow - Fashion MNIST Steps Per Epoch,"<p>I'm working with the Kera's Fashion MNIST dataset. When I fit my model, I noticed to complete one epoch it would have to go through 1500 steps.</p>
<pre><code>history = model.fit(x_train, y_train, epochs=30, validation_split=0.2)

Epoch 3/30
1500/1500 [==============================] - 3s 2ms/step - loss: 0.4494 - sparse_categorical_accuracy: 0.8438 - val_loss: 0.4691 - val_sparse_categorical_accuracy: 0.8308
Epoch 4/30
964/1500 [==================&gt;...........] - ETA: 0s - loss: 0.4294 - sparse_categorical_accuracy: 0.8504
</code></pre>
<p>I was looking at the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">docs</a> for the fit function, but couldn't understand why the default steps were set to 1500. I understand when the <code>steps_per_epoch</code> is <code>None</code> the behavior is dependent on the data type of the dataset, but how can I check if the data type is a tensor or tf.data?</p>
",1,Documentation Replication on Other Examples
423,62994289,Saving TFrecords with TPU,"<p>I'm trying to use <code>tf.data.experimental.TFRecordWriter</code> to save dataset on Google cloud bucket using TPU. The code from the example in documentation works:</p>
<pre><code>dataset = tf.data.Dataset.range(3)
dataset = dataset.map(tf.io.serialize_tensor)
writer = tf.data.experimental.TFRecordWriter(&quot;gs://oleg-zyablov/test.tfrec&quot;)
writer.write(dataset)
</code></pre>
<p>But I have dataset of tuples (string, int64), where first is jpg-encoded image and second is label. When I pass it to writer.write() method, it says: 'tuple' object has no attribute 'is_compatible_with'.</p>
<p>I guess I have to pack image and label into tf.train.Example to make it work. I use the following code:</p>
<pre><code>def serialize(image, class_idx):
  tfrecord = tf.train.Example(features = tf.train.Features(feature = {
    'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image.numpy()])),
    'class': tf.train.Feature(int64_list = tf.train.Int64List(value = [class_idx.numpy()]))
  }))
  return tfrecord.SerializeToString()

#saving_pipeline is a dataset of (string, int64) tuples
saving_pipeline_serialized = saving_pipeline.map(serialize)

writer = tf.data.experimental.TFRecordWriter(&quot;gs://oleg-zyablov/car-classification/train_tfrecords/test.tfrecord&quot;)
writer.write(saving_pipeline_serialized)
</code></pre>
<p>But I get the following error:</p>
<pre><code>'Tensor' object has no attribute 'numpy'
</code></pre>
<p>Although I didn't turn off eager mode and this code <code>tf.constant([], dtype = float).numpy()</code> works. Maybe TPU works not in eager mode? Ok, I changed .numpy() to .eval() in the code above. Then I get the foloowing error:</p>
<pre><code>Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`
</code></pre>
<p>What session does TPU use and how do I specify it? When I run the code below:</p>
<pre><code>with tf.compat.v1.Session():
  saving_pipeline_serialized = saving_pipeline.map(serialize)
</code></pre>
<p>I get an error:</p>
<pre><code>Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`.
</code></pre>
<p>But I don't know how to get the current graph and pass it to tf.compat.v1.Session(). When I go another way and type:</p>
<pre><code>image.eval(session = tf.compat.v1.get_default_session())
</code></pre>
<p>It says:</p>
<pre><code>Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`
</code></pre>
<p>Is it possible to use .eval() on TPU? Or how do I perform my task another way?</p>
",1,Documentation Replication on Other Examples
424,63004540,How to pad 1 dimensinal vector in tensorflow? Getting InvalidArgumentError: paddings must be a matrix with 2 columns with tf.pad,"<p>I am trying to use tf.pad. Here is my attempt to pad the tensor to length 20, with values 10.</p>
<pre><code>tf.pad(tf.constant([1, 2, 3, 45]), paddings=20, constant_values=10)
</code></pre>
<p>I get this error message</p>
<pre><code>InvalidArgumentError: paddings must be a matrix with 2 columns: [2,1] [Op:PadV2]
</code></pre>
<p>I am looking at the documentation</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/pad"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/pad</a></p>
<blockquote>
<p>paddings is an integer tensor with shape [n, 2], where n is the rank of tensor. For each dimension D of input, paddings[D, 0] indicates how many values to add before the contents of tensor in that dimension, and paddings[D, 1] indicates how many values to add after the contents of tensor in that dimension</p>
</blockquote>
<p>But I am unable to figure out how to shape the pad value</p>
",1,Documentation Replicability
425,63020800,"Understanding Tensorflow Object-Detection API, kwargs for Checkpoint class, what is `_base_tower_layers_for_heads`?","<p>Currently, I've been learning how to use Object-Detection API from Tensorflow. I follow a quick start tutorial for training with custom data with <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb"" rel=""nofollow noreferrer"">this notebook</a> as suggested by them. In the effort to understanding each line of the code, I stumbled upon this snippet code in the &quot;Create Model and Restore Weight&quot; part.</p>
<pre><code>fake_box_predictor = tf.compat.v2.train.Checkpoint(
    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,
    # _prediction_heads=detection_model._box_predictor._prediction_heads,
    #    (i.e., the classification head that we *will not* restore)
    _box_prediction_head=detection_model._box_predictor._box_prediction_head,
    )
</code></pre>
<p>I don't really understand what are the keyword arguments that are available for the <code>Checkpoint</code> class in that particular snippet code. My question is; is there any documentation out there that shows the list of the keyword arguments? or at least explain what are <code>_base_tower_layers_for_heads</code> and<code>_box_prediction_head</code>?</p>
<p>I've read the <code>tf.train.Checkpoint</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"" rel=""nofollow noreferrer"">documentation</a>. It says that we can provide <code>models</code> or <code>optimizers</code> for the constructor's keyword argument. I am already familiar with this class to restore the weights to my model, however, I find it is alien to see <code>_base_tower_layers_for_heads</code> or <code>_box_prediction_head</code> for the keyword argument.</p>
<p>I do know about 'heads' and different types of 'heads' in the object detection architecture and their relation to transfer learning, what I don't understand is in the context of their data structure. How do I know, these keyword arguments exist? and is there any other else? I would really appreciate it if somebody could give me insights or at least tell me where can I find documentation that I can read to understand it more.</p>
",1,Requesting (Additional) Documentation/Examples
426,63146831,What is the analytic interpretation for Tensorflow custom gradient?,"<p>In the official <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">tf.custom_gradient</a> documentation it shows how to define custom gradients for <code>log(1 + exp(x))</code></p>
<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient
def log1pexp(x):
  e = tf.exp(x)
  def grad(dy):
    return dy * (1 - 1 / (1 + e))
  return tf.math.log(1 + e), grad
</code></pre>
<p>When <code>y = log(1 + exp(x))</code>, analytically the derivative comes out to be <code>dy/dx = (1 - 1 / (1 + exp(x)))</code>.</p>
<p>However in the code <code>def grad</code> says its <code>dy * (1 - 1 / (1 + exp(x)))</code>.
<code>dy/dx = dy * (1 - 1 / (1 + exp(x)))</code> is not a valid equation. While <code>dx = dy * (1 - 1 / (1 + exp(x)))</code> is wrong as it should be the reciprocal.</p>
<p>What does the <code>grad</code> function equate to?</p>
",1,Documentation Replication on Other Examples
427,63158314,Tensorflow 2.3.0 - Warning: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version,"<p>I've just updated to TF-2.3. In a model using <code>tf.data.Dataset.from_tensor_slices</code> as data source, I get the folowing warning:</p>
<pre><code>WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Iterator.get_next_as_optional()` instead.
</code></pre>
<p>I didn't find the instructions on the documentation on how to use the updated methods.</p>
<pre><code>train_dataset = tf.data.Dataset.from_tensor_slices(
    (
        {&quot;input_1&quot;: x1_train, 
         &quot;input_2&quot;: x2_train}, 
        {&quot;output&quot;: y_train},
    )
)

train_batches = train_dataset.batch(GLOBAL_BATCH_SIZE)
</code></pre>
<p>Training:</p>
<pre><code>history = model.fit(
    x = train_batches,
    epochs=30,
    verbose = 1,
)
</code></pre>
<p>Thanks in advance.</p>
",1,Lack of Alternative Solutions/Documentation
428,63379008,How to make a diagonal tensor and why doesn't Tensorflow linalg.tensor_diag do that?,"<p>What I would consider a diagonal tensor is a tensor t of shape (d1, ..., dr) which is all zero except when the components are equal.
So t[i,j,k,l] = 0 unless i == j == k == l.
A function to create such a tensor should take in a shape (d1, ..., dr) and a vector [a1, ..., ak] of length min(d1, ..., dr), placing these values along the diagonal.</p>
<p>I would like to do this in Tensorflow, and the most relevant function I could find was <a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/tensor_diag"" rel=""nofollow noreferrer"">tf.linalg.tensor_diag</a>, but it doesn't do what I want. For instance, the diagonal input is a tensor, and the output tensor always has twice the rank, and so it can never output tensors of odd rank.</p>
<p>The documentation says &quot;Given a diagonal, this operation returns a tensor with the diagonal and everything else padded with zeros&quot;, but I don't know how to square that with its actual behavior.</p>
<p>My question is two parts:</p>
<ol>
<li><p>What is the best way in TF to do create what I am calling a diagonal tensor. Is there another name for this?</p>
</li>
<li><p>Why does linalg.tensor_diag work like this? What is the intended use?</p>
</li>
</ol>
<p>Here is an example output:</p>
<pre><code>&gt;&gt;&gt; tf.linalg.tensor_diag([1,2],[3,4]])

&lt;tf.Tensor: shape=(2, 2, 2, 2), dtype=int32, numpy=
array([[[[1, 0],
         [0, 0]],

        [[0, 2],
         [0, 0]]],


       [[[0, 0],
         [3, 0]],

        [[0, 0],
         [0, 4]]]], dtype=int32)&gt;```
</code></pre>
",1,Documentation Ambiguity
429,63383594,How does Tensorflow build() work from tf.keras.layers.Layer,"<p>I was wondering if anyone knew how the <code>build()</code> function works from the <code>tf.keras.layers.Layer</code> class under the hood. According to the <a href=""https://www.tensorflow.org/tutorials/customization/custom_layers"" rel=""noreferrer"">documentation</a>:</p>
<blockquote>
<p><em>build is called when you know the shapes of the input tensors and can
do the rest of the initialization</em></p>
</blockquote>
<p>so to me it seems like the class is behaving similar to this:</p>
<pre><code>class MyDenseLayer:
  def __init__(self, num_outputs):
    self.num_outputs = num_outputs

  def build(self, input_shape):
    self.kernel = self.add_weight(&quot;kernel&quot;,
                                  shape=[int(input_shape[-1]), self.num_outputs])

  def __call__(self, input):
    self.build(input.shape) ## build is called here when input shape is known
    return tf.matmul(input, self.kernel)
</code></pre>
<p>I can't imagine <code>build()</code> would be called for ever <code>__call__</code>, but it is the only place where the input is passed in. Does anyone know how exactly this works under the hood?</p>
",1,Documentation Replication on Other Examples
430,63482945,How does tf.nn.dilation2d compute gradient and learn its filters,"<p>I want to understand how the tf.nn.dilation2d is working and how the &quot;filters&quot;, which refers to a structural element are learned.</p>
<p>The official documentation is available here : <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dilation2d"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dilation2d</a></p>
<p>The documentation didn't reference a scientific paper, and I found a lot of different idea in scientific literature, about morphological filters in deep learnign. Here just some examples :</p>
<ul>
<li><a href=""https://arxiv.org/abs/1906.01751"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1906.01751</a></li>
<li><a href=""https://arxiv.org/abs/1909.01532"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1909.01532</a></li>
<li><a href=""https://doi.org/10.1109/TNNLS.2018.2890334"" rel=""nofollow noreferrer"">https://doi.org/10.1109/TNNLS.2018.2890334</a></li>
<li><a href=""https://doi.org/10.1142/S0218001419540247"" rel=""nofollow noreferrer"">https://doi.org/10.1142/S0218001419540247</a></li>
</ul>
<p>I searched into the code (<a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/nn_ops.py#L327-L392"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/nn_ops.py#L327-L392</a>), but the tf.nn.dilation2d only call gen_nn_ops.dilation2d</p>
<pre><code>@tf_export(&quot;nn.dilation2d&quot;, v1=[])
@dispatch.add_dispatch_support
def dilation2d_v2(input, filters, strides, padding, data_format, dilations, name=None):
  if data_format != &quot;NHWC&quot;:
    raise ValueError(&quot;Data formats other than NHWC are not yet supported&quot;)
  return gen_nn_ops.dilation2d(input=input,
                               filter=filters,
                               strides=strides,
                               rates=dilations,
                               padding=padding,
                               name=name)
</code></pre>
<p>I searched into gen_nn_ops.py (which I found inside my python lib folder, probably because it's generated from somewhere else) but I didn't understand what the code is doing.</p>
<pre><code>def dilation2d(input, filter, strides, rates, padding, name=None):
  r&quot;&quot;&quot;Computes the grayscale dilation of 4-D `input` and 3-D `filter` tensors.

  The `input` tensor has shape `[batch, in_height, in_width, depth]` and the
  `filter` tensor has shape `[filter_height, filter_width, depth]`, i.e., each
  input channel is processed independently of the others with its own structuring
  function. The `output` tensor has shape
  `[batch, out_height, out_width, depth]`. The spatial dimensions of the output
  tensor depend on the `padding` algorithm. We currently only support the default
  &quot;NHWC&quot; `data_format`.

  In detail, the grayscale morphological 2-D dilation is the max-sum correlation
  (for consistency with `conv2d`, we use unmirrored filters):

      output[b, y, x, c] =
         max_{dy, dx} input[b,
                            strides[1] * y + rates[1] * dy,
                            strides[2] * x + rates[2] * dx,
                            c] +
                      filter[dy, dx, c]

  Max-pooling is a special case when the filter has size equal to the pooling
  kernel size and contains all zeros.

  Note on duality: The dilation of `input` by the `filter` is equal to the
  negation of the erosion of `-input` by the reflected `filter`.

  Args:
    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
      4-D with shape `[batch, in_height, in_width, depth]`.
    filter: A `Tensor`. Must have the same type as `input`.
      3-D with shape `[filter_height, filter_width, depth]`.
    strides: A list of `ints` that has length `&gt;= 4`.
      The stride of the sliding window for each dimension of the input
      tensor. Must be: `[1, stride_height, stride_width, 1]`.
    rates: A list of `ints` that has length `&gt;= 4`.
      The input stride for atrous morphological dilation. Must be:
      `[1, rate_height, rate_width, 1]`.
    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.
      The type of padding algorithm to use.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `input`.
  &quot;&quot;&quot;
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = pywrap_tfe.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, &quot;Dilation2D&quot;, name,
        tld.op_callbacks, input, filter, &quot;strides&quot;, strides, &quot;rates&quot;, rates,
        &quot;padding&quot;, padding)
      return _result
    except _core._FallbackException:
      try:
        return dilation2d_eager_fallback(
            input, filter, strides=strides, rates=rates, padding=padding,
            name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _, _, _op, _outputs = _op_def_library._apply_op_helper(
        &quot;Dilation2D&quot;, input=input, filter=filter, strides=strides,
                      rates=rates, padding=padding, name=name)
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = (&quot;T&quot;, _op._get_attr_type(&quot;T&quot;), &quot;strides&quot;,
              _op.get_attr(&quot;strides&quot;), &quot;rates&quot;, _op.get_attr(&quot;rates&quot;),
              &quot;padding&quot;, _op.get_attr(&quot;padding&quot;))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        &quot;Dilation2D&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Dilation2D = tf_export(&quot;raw_ops.Dilation2D&quot;)(_ops.to_raw_op(dilation2d))


def dilation2d_eager_fallback(input, filter, strides, rates, padding, name, ctx):
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter], ctx)
  (input, filter) = _inputs_T
  _inputs_flat = [input, filter]
  _attrs = (&quot;T&quot;, _attr_T, &quot;strides&quot;, strides, &quot;rates&quot;, rates, &quot;padding&quot;,
  padding)
  _result = _execute.execute(b&quot;Dilation2D&quot;, 1, inputs=_inputs_flat,
                             attrs=_attrs, ctx=ctx, name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        &quot;Dilation2D&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


def dilation2d_backprop_filter(input, filter, out_backprop, strides, rates, padding, name=None):
  r&quot;&quot;&quot;Computes the gradient of morphological 2-D dilation with respect to the filter.

  Args:
    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
      4-D with shape `[batch, in_height, in_width, depth]`.
    filter: A `Tensor`. Must have the same type as `input`.
      3-D with shape `[filter_height, filter_width, depth]`.
    out_backprop: A `Tensor`. Must have the same type as `input`.
      4-D with shape `[batch, out_height, out_width, depth]`.
    strides: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The stride of the sliding window for each dimension of
      the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
    rates: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The input stride for atrous morphological dilation.
      Must be: `[1, rate_height, rate_width, 1]`.
    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.
      The type of padding algorithm to use.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `input`.
  &quot;&quot;&quot;
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = pywrap_tfe.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, &quot;Dilation2DBackpropFilter&quot;,
        name, tld.op_callbacks, input, filter, out_backprop, &quot;strides&quot;,
        strides, &quot;rates&quot;, rates, &quot;padding&quot;, padding)
      return _result
    except _core._FallbackException:
      try:
        return dilation2d_backprop_filter_eager_fallback(
            input, filter, out_backprop, strides=strides, rates=rates,
            padding=padding, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _, _, _op, _outputs = _op_def_library._apply_op_helper(
        &quot;Dilation2DBackpropFilter&quot;, input=input, filter=filter,
                                    out_backprop=out_backprop,
                                    strides=strides, rates=rates,
                                    padding=padding, name=name)
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = (&quot;T&quot;, _op._get_attr_type(&quot;T&quot;), &quot;strides&quot;,
              _op.get_attr(&quot;strides&quot;), &quot;rates&quot;, _op.get_attr(&quot;rates&quot;),
              &quot;padding&quot;, _op.get_attr(&quot;padding&quot;))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        &quot;Dilation2DBackpropFilter&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Dilation2DBackpropFilter = tf_export(&quot;raw_ops.Dilation2DBackpropFilter&quot;)(_ops.to_raw_op(dilation2d_backprop_filter))


def dilation2d_backprop_filter_eager_fallback(input, filter, out_backprop, strides, rates, padding, name, ctx):
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_filter' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter, out_backprop], ctx)
  (input, filter, out_backprop) = _inputs_T
  _inputs_flat = [input, filter, out_backprop]
  _attrs = (&quot;T&quot;, _attr_T, &quot;strides&quot;, strides, &quot;rates&quot;, rates, &quot;padding&quot;,
  padding)
  _result = _execute.execute(b&quot;Dilation2DBackpropFilter&quot;, 1,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        &quot;Dilation2DBackpropFilter&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result


def dilation2d_backprop_input(input, filter, out_backprop, strides, rates, padding, name=None):
  r&quot;&quot;&quot;Computes the gradient of morphological 2-D dilation with respect to the input.

  Args:
    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
      4-D with shape `[batch, in_height, in_width, depth]`.
    filter: A `Tensor`. Must have the same type as `input`.
      3-D with shape `[filter_height, filter_width, depth]`.
    out_backprop: A `Tensor`. Must have the same type as `input`.
      4-D with shape `[batch, out_height, out_width, depth]`.
    strides: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The stride of the sliding window for each dimension of
      the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
    rates: A list of `ints` that has length `&gt;= 4`.
      1-D of length 4. The input stride for atrous morphological dilation.
      Must be: `[1, rate_height, rate_width, 1]`.
    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.
      The type of padding algorithm to use.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `input`.
  &quot;&quot;&quot;
  _ctx = _context._context or _context.context()
  tld = _ctx._thread_local_data
  if tld.is_eager:
    try:
      _result = pywrap_tfe.TFE_Py_FastPathExecute(
        _ctx._context_handle, tld.device_name, &quot;Dilation2DBackpropInput&quot;,
        name, tld.op_callbacks, input, filter, out_backprop, &quot;strides&quot;,
        strides, &quot;rates&quot;, rates, &quot;padding&quot;, padding)
      return _result
    except _core._FallbackException:
      try:
        return dilation2d_backprop_input_eager_fallback(
            input, filter, out_backprop, strides=strides, rates=rates,
            padding=padding, name=name, ctx=_ctx)
      except _core._SymbolicException:
        pass  # Add nodes to the TensorFlow graph.
    except _core._NotOkStatusException as e:
      _ops.raise_from_not_ok_status(e, name)
  # Add nodes to the TensorFlow graph.
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _, _, _op, _outputs = _op_def_library._apply_op_helper(
        &quot;Dilation2DBackpropInput&quot;, input=input, filter=filter,
                                   out_backprop=out_backprop, strides=strides,
                                   rates=rates, padding=padding, name=name)
  _result = _outputs[:]
  if _execute.must_record_gradient():
    _attrs = (&quot;T&quot;, _op._get_attr_type(&quot;T&quot;), &quot;strides&quot;,
              _op.get_attr(&quot;strides&quot;), &quot;rates&quot;, _op.get_attr(&quot;rates&quot;),
              &quot;padding&quot;, _op.get_attr(&quot;padding&quot;))
    _inputs_flat = _op.inputs
    _execute.record_gradient(
        &quot;Dilation2DBackpropInput&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result

Dilation2DBackpropInput = tf_export(&quot;raw_ops.Dilation2DBackpropInput&quot;)(_ops.to_raw_op(dilation2d_backprop_input))


def dilation2d_backprop_input_eager_fallback(input, filter, out_backprop, strides, rates, padding, name, ctx):
  if not isinstance(strides, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'strides' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % strides)
  strides = [_execute.make_int(_i, &quot;strides&quot;) for _i in strides]
  if not isinstance(rates, (list, tuple)):
    raise TypeError(
        &quot;Expected list for 'rates' argument to &quot;
        &quot;'dilation2d_backprop_input' Op, not %r.&quot; % rates)
  rates = [_execute.make_int(_i, &quot;rates&quot;) for _i in rates]
  padding = _execute.make_str(padding, &quot;padding&quot;)
  _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter, out_backprop], ctx)
  (input, filter, out_backprop) = _inputs_T
  _inputs_flat = [input, filter, out_backprop]
  _attrs = (&quot;T&quot;, _attr_T, &quot;strides&quot;, strides, &quot;rates&quot;, rates, &quot;padding&quot;,
  padding)
  _result = _execute.execute(b&quot;Dilation2DBackpropInput&quot;, 1,
                             inputs=_inputs_flat, attrs=_attrs, ctx=ctx,
                             name=name)
  if _execute.must_record_gradient():
    _execute.record_gradient(
        &quot;Dilation2DBackpropInput&quot;, _inputs_flat, _attrs, _result)
  _result, = _result
  return _result
</code></pre>
<p>Thank you for your time.</p>
",1,Documentation Replicability
431,63715707,Does image_dataset_from_directory load all the images into memory at once?,"<p>I'm new to machine learning, and I am trying to create an image classifier, I want to load the dataset, but I want to do it in a way such that it does not take up all of my memory. Reading the tensorflow documentation, it says that iteration of a dataset happens in streaming fashion, and I am wondering if tf.keras.preprocessing.image_dataset_from_directory will load the images at once or &quot;stream&quot; it a batch at a time. If not I was thinking of making a generator to read file names one at a time and load them when the batches are ready with keras.utils.Sequence.</p>
",1,Documentation Replication on Other Examples
432,63851431,How to Augment the Training Set using the tf.keras.utils.Sequence API?,"<p>TensorFlow documentation have the following example that can illustrate how to create a batch generator to feed a training set in batches to a model when the training set is too large to fit in memory:</p>
<pre class=""lang-py prettyprint-override""><code>from skimage.io import imread
from skimage.transform import resize
import tensorflow as tf
import numpy as np
import math

# Here, `x_set` is list of path to the images
# and `y_set` are the associated classes.

class CIFAR10Sequence(tf.keras.utils.Sequence):

    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        return np.array([
            resize(imread(file_name), (200, 200))
               for file_name in batch_x]), np.array(batch_y)
</code></pre>
<p>My intention is to further increase the diversity of the training set by rotating each image 3x by 90º. In each Epoch of the training process, the model would first be fed with the &quot;0º training set&quot; and next with the 90º, 180º and 270º rotating sets, respectively.</p>
<p>How can I modify the previous piece of code to perform this operation inside the <code>CIFAR10Sequence()</code> data generator?</p>
<p>Please don't use <code>tf.keras.preprocessing.image.ImageDataGenerator()</code> so that the answer does not lose its generality for another type of similar problems that are of a different nature.</p>
<p>NB: The idea would be to create the new data &quot;in real time&quot; as the model is fed instead of creating (in advance) and storing on disk a new and augmented training set bigger than the original one to be used later (also in batches) during the training process of the model.</p>
<p>Thx in advance</p>
",1,Documentation Replication on Other Examples
433,63894153,TypeError: 'Tensor' object cannot be interpreted as an integer when using tf.map_fn(),"<p>I am trying to construct label-dependent convolutional filters in keras/tensorflow. Therefore, the convolutional filter(s) depend on each example in the batch.</p>
<pre><code># function used for tf.map_fn
def single_conv(tupl):
    x, kernel = tupl
    return tf.nn.conv2d(x, kernel, strides=(1, 1, 1, 1), padding='SAME')

# first dimension is None (batch size)
input_img = tf.keras.layers.Input(shape=(28,28,1), dtype=tf.float32)
label = tf.keras.layers.Input(shape=(10,), dtype=tf.float32) 

# the network is learning a mapping for the label
label_encoded = tf.keras.layers.Dense(9, activation='relu')(label) 
# turn mapping into conv filter 
kernels = tf.keras.layers.Reshape((3,3,1,1))(label_encoded) 

# class dependent filter(s)
conditional_conv = tf.map_fn(single_conv, (tf.expand_dims(input_img, 1), kernels), fn_output_signature=tf.float32) 
</code></pre>
<p>When I run this code snippet, I get a <code>TypeError: 'Tensor' object cannot be interpreted as an integer</code> for the last line. Since the last line uses <code>tf.map_fn</code>, I saw that  tf.map_fn results in a TypeError if either the function used (single_conv in this case) is not callable or the structure of the output of function and fn_output_signature do not match: <a href=""https://www.tensorflow.org/api_docs/python/tf/map_fn#raises"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/map_fn#raises</a>.</p>
<p>However, I'm still not sure why this is happening? I feel like both of those reasons should not be an issue?</p>
",1,Documentation Replication on Other Examples
434,63919438,TensorFlow keras model fit() parameters steps_per_epoch and epochs behavior on train set,"<p>I'm using a tf.data dataset containing my training data consisting of (lets say) 100k images.
I'm also using a tf.data dataset containing my validation set.
Since an epoch of all 100k images takes quite long (in my case approximately one hour) before I get any feedback on performance on the validation set, I set the <code>steps_per_epoch</code> parameter in tf.keras.Model <code>fit()</code> to <code>10000</code>.
Using a batch size of 1 this results into having 10 validation scores when reaching 100k of images.
In order to complete one epoch of 100k images of my entire training dataset, I set the <code>epochs</code> parameter to <code>10</code></p>
<p>However, I'm not sure if using <code>steps_per_epoch</code> and <code>epochs</code> this way has any other consequences. Is it correct to use these parameters in order to get more frequent feedback on performance?
And also a more specific question, does it use all 100k images or does it use the same first 10k images of my training set at every 'epoch'?
I already dug into the <a href=""https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">TensorFlow docs</a> and read several different stack overflow questions, but I couldn't find anything conclusive to answer my own question. Hope you can help!</p>
<p>Tensorflow version I'm using is 2.2.0.</p>
",1,Inadequate Examples
435,64081367,Slicing a tensor with a tensor of indices and tf.gather,"<p>I am trying to slice a tensor with a indices tensor. For this purpose I am trying to use <code>tf.gather</code>.
However, I am having a hard time understanding the <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer"">documentation</a> and don't get it to work as I would expect it to:</p>
<p>I have two tensors. An <code>activations</code> tensor with a shape of <code>[1,240,4]</code> and an <code>ids</code> tensor with the shape <code>[1,1,120]</code>. I want to slice the second dimension of the <code>activations</code> tensor with the indices provided in the third dimension of the <code>ids</code> tensor:</p>
<pre><code>downsampled_activations = tf.gather(activations, ids, axis=1)
</code></pre>
<p>I have given it the <code>axis=1</code> option since that is the axis in the <code>activations</code> tensor I want to slice.</p>
<p>However, this does not render the expected result and only gives me the following error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0,0,1] = 1 is not in [0, 1)
</code></pre>
<p>I have tried various combinations of the <code>axis</code> and <code>batch_dims</code> options, but to no avail so far and the documentation doesn't really help me on my path. Anybody care to explain the parameters in more detail or on the example above would be very helpful!</p>
<p><strong>Edit:</strong>
The IDs are precomputed before runtime and come in through an input pipeline as such:</p>
<pre><code>features = tf.io.parse_single_example(
            serialized_example,
            features={ 'featureIDs': tf.io.FixedLenFeature([], tf.string)}
</code></pre>
<p>They are then reshaped into the previous format:</p>
<pre><code>feature_ids_raw = tf.decode_raw(features['featureIDs'], tf.int32)
feature_ids_shape = tf.stack([batch_size, (num_neighbours * 4)])
feature_ids = tf.reshape(feature_ids_raw, feature_ids_shape)
feature_ids = tf.expand_dims(feature_ids, 0)
</code></pre>
<p>Afterwards they have the previously mentioned shape (<code>batch_size = 1</code> and <code>num_neighbours = 30</code> -&gt; <code>[1,1,120]</code>) and I want to use them to slice the <code>activations</code> tensor.</p>
<p><strong>Edit2:</strong> I would like the output to be <code>[1,120,4]</code>. (So I would like to gather the entries along the second dimension of the <code>activations</code> tensor in accordance with the IDs stored in my <code>ids</code> tensor.)</p>
",1,Documentation Ambiguity
436,64093750,Example of inferencing a Tensorflow lite model with parsing_serving_input_receiver_fn using C++ API,"<p>I have followed the Tensorflow2 documentation to convert my trained tf.estimator model to tflite model; in order to convert my model, first I had to save my model in saved_model format with an input_receiver_fn and then convert it with SELECT_OPS flag:</p>
<pre><code>classifier = tf.estimator.LinearClassifier(n_classes=2, model_dir = classifier_dir, feature_columns=features)
classifier.train(input_fn = lambda: trian_fn(features = train_datas, labels = trian_labels))

serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(tf.feature_column.make_parse_example_spec(features))

classifier.export_saved_model(classifier_dir+&quot;\saved_model&quot;, serving_input_fn)

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir = saved_model_dir , signature_keys=['serving_default']) 
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
</code></pre>
<p>I wanted to run my tflite model on an ARM device without python support so I built the C++ interpreter shared libs with Bazel as it is explained in the documentation :</p>
<p><a href=""https://www.tensorflow.org/lite/guide/ops_select#c"" rel=""nofollow noreferrer"">Cross-compile for armhf with Bazel</a></p>
<p><a href=""https://www.tensorflow.org/lite/guide/ops_select#c"" rel=""nofollow noreferrer"">Select TensorFlow operators C++</a></p>
<p>My model has 3 input features but when I try to use the following <a href=""https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_c"" rel=""nofollow noreferrer"">guide</a> for inferencing I get a segmentation fault.
I used the following code to extract my model details:</p>
<pre><code>interpreter = tf.lite.Interpreter(model_path=&quot;./model.tflite&quot;)
interpreter.allocate_tensors()
print(&quot;all ok&quot;)
# Print input shape and type
inputs = interpreter.get_input_details()
print('{} input(s):'.format(len(inputs)))
for i in range(0, len(inputs)):
    print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))

# Print output shape and type
outputs = interpreter.get_output_details()
print('\n{} output(s):'.format(len(outputs)))
for i in range(0, len(outputs)):
    print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))
</code></pre>
<p>I got the following output:</p>
<pre><code>all ok
1 input(s):
[1] &lt;class 'numpy.bytes_'&gt;

2 output(s):
[1 2] &lt;class 'numpy.bytes_'&gt;
[1 2] &lt;class 'numpy.float32'&gt;
</code></pre>
<p>first few lines of the output of tflite::PrintInterpreterState(interpreter.get()) are:</p>
<pre><code>INFO: Created TensorFlow Lite delegate for select TF ops.
INFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 25 nodes with 1 partitions.

Interpreter has 54 tensors and 26 nodes
Inputs: 0
Outputs: 38 34

Tensor   0 input_example_tensor kTfLiteString  kTfLiteDynamic          0 bytes ( 0.0 MB)  1
</code></pre>
<p>The output illustrates that the input shape is not the same as the original model, also the input type is &lt;class 'numpy.bytes_'&gt; but the Tensorflow 2 model inputs are [numpy.float32, numpy.float32, numpy.float32].
my input dictionary for prediction in TF2 model is something like : {'feature0' : data0, 'feature1' : data1, 'feature2' : data2}</p>
<p>here is the Google Colab <a href=""https://colab.research.google.com/drive/1fkj8zM2FM-xd6cajWkStcasmzliZWF9s?usp=sharing"" rel=""nofollow noreferrer"">link</a> to the Tensorflow model
I didn't have previous experience with inferencing TensorFlow Lite models so I searched first and found out these related questions that helped me write below C++ code:</p>
<p><a href=""https://stackoverflow.com/questions/56837288/tensorflow-lite-c-api-example-for-inference"">TensorFlow Lite C++ API example for inference</a></p>
<p><a href=""https://stackoverflow.com/questions/59424842/how-to-give-multi-dimensional-inputs-to-tflite-via-c-api"">How to give multi-dimensional inputs to tflite via C++ API</a></p>
<p>I tried to fill the input buffer with a vector of zeros but it was without success. Here is my C++ code to load a tflite model and feed it inputs for prediction. can someone please point me to the right direction since I could not find any examples or related documentation for feeding inputs to converted tf.estimator with a serving_input_fn.</p>
<pre><code>#include &lt;cstdio&gt;
#include &quot;tensorflow/lite/interpreter.h&quot;
#include &quot;tensorflow/lite/kernels/register.h&quot;
#include &quot;tensorflow/lite/model.h&quot;
#include &quot;tensorflow/lite/optional_debug_tools.h&quot;

int main()
{
  // Load model
      std::unique_ptr&lt;tflite::FlatBufferModel&gt; model = tflite::FlatBufferModel::BuildFromFile(&quot;model.tflite&quot;);
      
  // Build the interpreter with the InterpreterBuilder.
  tflite::ops::builtin::BuiltinOpResolver resolver;
  tflite::InterpreterBuilder builder(*model, resolver);
  std::unique_ptr&lt;tflite::Interpreter&gt; interpreter;
  builder(&amp;interpreter);
  tflite::PrintInterpreterState(interpreter.get());
  
  // Allocate tensor buffers.
  interpreter-&gt;AllocateTensors();
  printf(&quot;=== Pre-invoke Interpreter State ===\n&quot;);
  tflite::PrintInterpreterState(interpreter.get());

  // Fill input buffers
  std::vector&lt;float&gt; tensor(3, 0);  //Vector of zeros
  int input = interpreter-&gt;inputs()[0];
  float* input_data_ptr = interpreter-&gt;typed_input_tensor&lt;float&gt;(input);
  for(int i = 0; i &lt; 3; ++i)
  {
    *(input_data_ptr) = (float)tensor[i];
    input_data_ptr++;
  }
  // Run inference
  interpreter-&gt;Invoke();
  printf(&quot;\n\n=== Post-invoke Interpreter State ===\n&quot;);
  
  return 0;
}
</code></pre>
<h1><strong>EDIT 1:</strong></h1>
<p>I also asked this question in Tensorflow's GitHub and got a comment mentioning that I have to feed my inputs in the form of an &quot;example proto&quot;, now the problem is reduced to what is an &quot;example proto&quot; and how can one feed inputs to a tflite model in from of an example proto?</p>
<p><a href=""https://github.com/tensorflow/tensorflow/issues/43607"" rel=""nofollow noreferrer"">Github issue link</a></p>
",1,Inadequate Examples
437,64326029,Load tensorflow images and create patches,"<p>I am using <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer"">image_dataset_from_directory</a> to load a very large RGB imagery dataset from disk into a <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">Dataset</a>. For example,</p>
<pre><code>dataset = tf.keras.preprocessing.image_dataset_from_directory(
    &lt;directory&gt;,
    label_mode=None,
    seed=1,
    subset='training',
    validation_split=0.1)
</code></pre>
<p>The Dataset has, say, 100000 images grouped into batches of size 32 yielding a <code>tf.data.Dataset</code> with spec <code>(batch=32, width=256, height=256, channels=3)</code></p>
<p>I would like to extract patches from the images to create a new <code>tf.data.Dataset</code> with image spatial dimensions of, say, 64x64.</p>
<p>Therefore, I would like to create a new Dataset with 400000 patches still in batches of 32 with a <code>tf.data.Dataset</code> with spec <code>(batch=32, width=64, height=64, channels=3)</code></p>
<p>I've looked at the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"" rel=""nofollow noreferrer"">window</a> method and the <a href=""https://www.tensorflow.org/api_docs/python/tf/image/extract_patches"" rel=""nofollow noreferrer"">extract_patches</a> function but it's not clear from the documentation how to use them to create a new Dataset I need to start training on the patches. The <code>window</code> seems to be geared toward 1D tensors and the <code>extract_patches</code> seems to work with arrays and not with Datasets.</p>
<p>Any suggestions on how to accomplish this?</p>
<p>UPDATE:</p>
<p>Just to clarify my needs. I am trying to avoid manually creating the patches on disk. One, that would be untenable disk wise. Two, the patch size is not fixed. The experiments will be conducted over several patch sizes. So, I do not want to manually perform the patch creation either on disk or manually load the images in memory and perform the patching. I would prefer to have tensorflow handle the patch creation as part of the pipeline workflow to minimize disk and memory usage.</p>
",1,Documentation Replication on Other Examples
438,64356209,How does Model.fit() method's shuffle deals with Batches when using a tf.data.Dataset?,"<p>I am using tensorflow 2.</p>
<p>When using the <code>Model.fit()</code> method with a <code>tf.data.Dataset</code>, the argument '<code>batch_size</code>' is ignored. Thus to train my model on batches, I have to first change my dataset of samples into a dataset of batches of samples by calling <code>tf.data.Dataset.batch(batch_size)</code>.</p>
<p>Then, after reading the documentation, I don't understand clearly how the <code>.fit()</code> method will shuffle my dataset at each epoch.</p>
<p><strong>Since my dataset is a dataset of batches, will it shuffle the batches among each other</strong> (the batches remain unchanged) <strong>? Or will it shuffle all the samples and then regroup them into new batches</strong> (which is the desired behaviour) <strong>?</strong></p>
<p>Thanks a lot for your help.</p>
",1,Documentation Replicability
439,64380057,TF 2.3.0 training keras model using tf dataset with sample weights does not apply to metrics,"<p>I am passing in sample_weight as the 3rd tuple in tf.data.Dataset (using it in the context of mask, so my sample_weight are either 0, or 1. The problem is that this sample_weight doesn't seem to get applied to metrics calculation. (Ref: <a href=""https://www.tensorflow.org/guide/keras/train_and_evaluate#sample_weights"" rel=""noreferrer"">https://www.tensorflow.org/guide/keras/train_and_evaluate#sample_weights</a>)</p>
<p>Here's code snippet:</p>
<pre><code>train_ds = tf.data.Dataset.from_tensor_slices((imgs, labels, masks))
train_ds = train_ds.shuffle(1024).repeat().batch(32).prefetch(buffer_size=AUTO)

model.compile(optimizer = Adam(learning_rate=1e-4),
             loss = SparseCategoricalCrossentropy(),
             metrics = ['sparse_categorical_accuracy'])

model.fit(train_ds, steps_per_epoch = len(imgs)//32, epochs = 20)
</code></pre>
<p>The loss after training is very close to zero, but sparse_categorical_accuracy is not (about 0.89). So I highly suspect whatever sample_weight (masks) that's passed in to construct the tf.dataset, does NOT get applied when the metrics is reported during training, while loss seems to be correct. I further confirmed by running prediction on the subset that are not masked separately, and confirmed the accuracy is 1.0</p>
<p>Also, according to documentation:</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy</a></p>
<p>the metric has 3 args: y_true, y_pred, sample_weight</p>
<p>So how does one pass the sample_weight during metric computation? Is this the responsibility of model.fit(...) within the keras framework? I can't find any example googling around so far.</p>
",1,Inadequate Examples
440,64424397,Keras - Custom layer with multiple inputs,"<p>I would like to implement a custom <code>tf.keras</code> layer called <code>MyLayer</code> which has three inputs and contains a sub layer which in turn has three inputs, like in the figure below:</p>
<p><a href=""https://i.stack.imgur.com/Um7yn.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Um7yn.jpg"" alt=""MyLayer"" /></a></p>
<p>I assume that the right thing to do would be to create a <code>MyLayer</code> class that extends <code>tf.keras.layers.Layer</code> and implement the <code>__init__</code>, <code>build</code> and <code>call</code> methods, as mentioned in the <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">official documentation</a>.</p>
<p>Now, the examples provided in the documentation are relative to pretty simple layers that are composed of several sublayers connected in a sequential manner, that is one after the other. For instance, the <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models#layers_are_recursively_composable"" rel=""nofollow noreferrer""><code>MLPBlock</code></a> layer consists of 3 linear layers ordered sequentially.</p>
<p>In general, however, sublayers are not ordered sequentially, but can form branches. This suggests that those layers could be run in parallel, since they are not connected to one another.
Going back to the custom layer I would like to implement, you can see that <code>Layer1</code>, <code>Layer2</code> and <code>Layer3</code> could be run in parallel. Once their outputs are computed, they can be fed to <code>Layer4</code>. The point is: how do I run them in parallel? I couldn't find any &quot;ParallelCombinator&quot; or things like that among the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers"" rel=""nofollow noreferrer"">available Keras layers</a>.</p>
<p>If I were to follow the examples provided in the documentation, I would write something along these lines:</p>
<pre class=""lang-py prettyprint-override""><code>class MyLayer(keras.layers.Layer):
    def __init__(self, ...):
        super(MyLayer, self).__init__()
        self.layer_1 = Layer1(...)
        self.layer_2 = Layer2(...)
        self.layer_3 = Layer3(...)
        self.layer_4 = Layer4(...)

    def call(self, inputs):
        tmp_1 = self.layer_1(inputs[0])
        tmp_2 = self.layer_2(inputs[1])
        tmp_3 = self.layer_3(inputs[2])
        return self.layer4([tmp_1, tmp_2, tmp_3])
</code></pre>
<p>This, however, would imply that <code>Layer1</code>, <code>Layer2</code> and <code>Layer3</code> are run sequentially, not in parallel.</p>
<p>One possible solution that I came up with involves structuring <code>MyLayer</code> as a <code>tf.keras.Model</code> built with Keras's functional API rather than as a subclass of <code>tf.keras.Layer</code>, like so:</p>
<pre class=""lang-py prettyprint-override""><code>def MyLayer(...):
    input_1 = tf.keras.layers.Input(...)
    input_2 = tf.keras.layers.Input(...)
    input_3 = tf.keras.layers.Input(...)

    layer_1 = Layer1(...)(input_1)
    layer_2 = Layer2(...)(input_2)
    layer_3 = Layer3(...)(input_3)
    output_1 = Layer4(...)([layer_1, layer_2, layer_3])

    return tf.keras.Model(inputs=[input_1, input_2, input_3], outputs=output_1)

if __name__ == '__main__':
    my_layer = MyLayer(...)
    input_1 = ...
    input_2 = ...
    input_3 = ...
    output = my_layer([input_1, input_2, input_3])
</code></pre>
<p>The reason why I think this would work is that I assume that when I feed some inputs to a <code>tf.keras.Model</code>, as in <code>output = my_layer([input_1, input_2, input_3])</code>, the layers that <em>can</em> be run in parallel are effectively run in parallel (or are they?). This solution, however, feels like a hack to me, as <code>MyLayer</code> is supposed to be a layer, <em>not</em> a model. In fact, a <code>tf.keras.Model</code> instance exposes methods like <code>fit(...)</code> that aren't meant to be called on a layer.</p>
<p>Does anybody know what's the best approach to implement <code>MyLayer</code>?</p>
",1,Documentation Replication on Other Examples
441,64552543,Tensorflow 2.2.0 :- WARNING:tensorflow:Gradients do not exist for variables when minimizing the loss,"<p>After implementing Custom Loss class as per the tensorflow api documentation and when invoking model.fit , facing this warning alongwith below error:- This is reference link on github and they have asked to raise here in stack overflow.https://github.com/tensorflow/tensorflow/issues/42542# TypeError: An op outside of the function building code is being passed a &quot;Graph&quot; tensor. It is possible to have Graph tensors leak out of the function building context by including a tf.init_scope in your function building code. For example, the following function will fail:</p>
<hr />
<blockquote>
<p>@tf.function   def has_init_scope():
my_constant = tf.constant(1.)
with tf.init_scope():
added = my_constant * 2 The graph tensor has name: ident33/Relu_5:0</p>
</blockquote>
",1,Documentation Replication on Other Examples
442,64611137,port TensorFlow 1 code to TensorFlow 2 (model learning process without sess.run),"<p>I have this piece of tf1 code, which was taken from nice book &quot;Deep Learning&quot; by S. Nikolenko.</p>
<p>It's a simple linear regression that learns <code>k</code> and <code>b</code> to 2 and 1 respectively.</p>
<pre><code>%tensorflow_version 1.x

import numpy as np,tensorflow as tf
import pandas as pd

n_samples, batch_size, num_steps = 1000, 100, 20000 #set learning constants
X_data = np.random.uniform(1, 10, (n_samples, 1)) #generate array x from 1 to 10 of shape (1000,1)
print(X_data.shape)
y_data = 2 * X_data + 1 + np.random.normal(0, 2, (n_samples, 1)) #generate right answer and add noise to it (to make it scatter)

X = tf.placeholder(tf.float32, shape=(batch_size, 1)) #defining placeholders to put into session.run
y = tf.placeholder(tf.float32, shape=(batch_size, 1))

with tf.variable_scope('linear-regression'):
  k = tf.Variable(tf.random_normal((1, 1)), name='slope') #defining 2 variables with shape (1,1)
  b = tf.Variable(tf.zeros((1,)), name='bias') # and (1,)
  print(k.shape,b.shape)

y_pred = tf.matmul(X, k) + b # all predicted y in batch, represents linear formula k*x + b
loss = tf.reduce_sum((y - y_pred) ** 2)  # mean square
optimizer = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)
display_step = 100

with tf.Session() as sess:
  sess.run(tf.initialize_variables([k,b]))
  for i in range(num_steps):
    indices = np.random.choice(n_samples, batch_size) # taking random indices
    X_batch, y_batch = X_data[indices], y_data[indices] # taking x and y from generated examples
    _, loss_val, k_val, b_val = sess.run([optimizer, loss, k, b ],
      feed_dict = { X : X_batch, y : y_batch })
    if (i+1) % display_step == 0:
      print('Epoch %d: %.8f, k=%.4f, b=%.4f' %
        (i+1, loss_val, k_val, b_val))

</code></pre>
<p>I'm striving to port it on TensorFlow 2</p>
<p>And for long time I can't wrap my head what should I use instead of <code>sess.run()</code> and <code>feed_dict</code>, which doing magic behind the scenes, official documentation go into to details with writing model class and so on, but I'm want to keep this as flat as possible.</p>
<p>Also it's suggested to calculate derivatives with <code>tf.GradientTape</code>, but I'm struggling with applying it right to my example</p>
<pre><code>%tensorflow_version 2.x

import numpy as np,tensorflow as tf
import pandas as pd

n_samples, batch_size, num_steps = 1000, 100, 200
X_data = np.random.uniform(1, 10, (n_samples, 1))
y_data = 2 * X_data + 1 + np.random.normal(0, 2, (n_samples, 1))

X = tf.Variable(tf.zeros((batch_size, 1)), dtype=tf.float32, shape=(batch_size, 1))
y = tf.Variable(tf.zeros((batch_size, 1)), dtype=tf.float32, shape=(batch_size, 1))

k = tf.Variable(tf.random.normal((1, 1)), name='slope')
b = tf.Variable(tf.zeros((1,)), name='bias')

loss = lambda: tf.reduce_sum((y - (tf.matmul(X, k) + b)) ** 2)
optimizer = tf.keras.optimizers.SGD(0.01).minimize(loss, [k, b, X, y])
display_step = 100


for i in range(num_steps):
  indices = np.random.choice(n_samples, batch_size)
  X_batch, y_batch = X_data[indices], y_data[indices]
  
</code></pre>
<p>I need SGD optimizer minimize that given loss function and learn k and b values, how can I achieve it from this point?</p>
",1,Documentation Replicability
443,64642944,Steps of tf.summary.* operations in TensorBoard are always 0,"<p>When I'm training my model with TensorFlow 2.3, I want to visualize some intermediate tensors calculated using the weight in the computation graph of my customized <code>tf.keras.layers.Layer</code>.</p>
<p>So I use <code>tf.summary.image()</code> to record these tensors and visualize them as images like this:</p>
<pre><code>class CustomizedLayer(tf.keras.layers.Layer):
    def call(self, inputs, training=None):
        # ... some code ...
        tf.summary.image(name=&quot;some_weight_map&quot;, data=some_weight_map)
        # ... some code ...
</code></pre>
<p>But in TensorBoard, no matter how many steps passed, there is only one image of step 0 shown.</p>
<p>And I tried to set the parameter <em><strong>step</strong></em> of <code>tf.summary.image()</code> to the value obtained from <code>tf.summary.experimental.get_step()</code>:</p>
<pre><code>tf.summary.image(name=&quot;weight_map&quot;, data=weight_map, step=tf.summary.experimental.get_step())
</code></pre>
<p>And update the step by calling <strong>tf.summary.experimental.set_step</strong> from a customized Callback using a tf.Variable like codes shown below:</p>
<pre><code>class SummaryCallback(tf.keras.callbacks.Callback):
def __init__(self, step_per_epoch):
    super().__init__()
    self.global_step = tf.Variable(initial_value=0, trainable=False, name=&quot;global_step&quot;)
    self.global_epoch = 0
    self.step_per_epoch = step_per_epoch
    tf.summary.experimental.set_step(self.global_step)

def on_batch_end(self, batch, logs=None):
    self.global_step = batch + self.step_per_epoch * self.global_epoch
    tf.summary.experimental.set_step(self.global_step)  
    # whether the line above is commented, calling tf.summary.experimental.get_step() in computation graph code always returns 0.
    # tf.print(self.global_step)

def on_epoch_end(self, epoch, logs=None):
    self.global_epoch += 1
</code></pre>
<p>This Callback's instance is passed in the argument <em><strong>callbacks</strong></em> in <code>model.fit()</code> function.</p>
<p>But the value <code>tf.summary.experimental.get_step()</code> returned is still 0.</p>
<p>The TensorFlow document of &quot;<code>tf.summary.experimental.set_step()</code>&quot; says:</p>
<blockquote>
<p>when using this with @tf.functions, the step value will be captured at the time the function is traced, so changes to the step outside the function will not be reflected inside the function unless using a tf.Variable step.</p>
</blockquote>
<p>Accroding to the document, I am already using a Variable to store the steps, but it's changes are still not reflected inside the function (or keras.Model).</p>
<p>Note: My code produces expected results in TensorFlow 1.x with just a simple line of <code>tf.summary.image()</code> before I migrate it to TensorFlow 2.</p>
<p>So I want to know if my approach is wrong in TensorFlow 2?</p>
<p>In TF2, how can I <strong>get training steps inside the computation graph</strong>?</p>
<p>Or there is other solution to <strong>summarize tensors (as scalar, image, etc.) inside a model in TensorFlow 2</strong>?</p>
",1,Documentation Replication on Other Examples
444,64687375,Get labels from dataset when using tensorflow image_dataset_from_directory,"<p>I wrote a simple CNN using tensorflow (v2.4) + keras in python (v3.8.3). I am trying to optimize the network, and I want more info on what it is failing to predict. I am trying to add a confusion matrix, and I need to feed tensorflow.math.confusion_matrix() the test labels.</p>
<p>My problem is that I cannot figure out how to access the labels from the dataset object created by tf.keras.preprocessing.image_dataset_from_directory()</p>
<p>My images are organized in directories having the label as the name. The documentation says the function returns a tf.data.Dataset object.</p>
<blockquote>
<pre><code>If label_mode is None, it yields float32 tensors of shape (batch_size, image_size[0], image_size[1], num_channels), encoding
</code></pre>
<p>images (see below for rules regarding num_channels).
Otherwise, it yields a tuple (images, labels), where images has shape (batch_size, image_size[0], image_size[1], num_channels), and
labels follows the format described below.</p>
</blockquote>
<p>Here is the code:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras import layers
#import matplotlib.pyplot as plt
import numpy as np
import random

import PIL
import PIL.Image

import os
import pathlib

#load the IMAGES
dataDirectory = '/p/home/username/tensorflow/newBirds'

dataDirectory = pathlib.Path(dataDirectory)
imageCount = len(list(dataDirectory.glob('*/*.jpg')))
print('Image count: {0}\n'.format(imageCount))

#test display an image
# osprey = list(dataDirectory.glob('OSPREY/*'))
# ospreyImage = PIL.Image.open(str(osprey[random.randint(1,100)]))
# ospreyImage.show()

# nFlicker = list(dataDirectory.glob('NORTHERN FLICKER/*'))
# nFlickerImage = PIL.Image.open(str(nFlicker[random.randint(1,100)]))
# nFlickerImage.show()

#set parameters
batchSize = 32
height=224
width=224

(trainData, trainLabels) = tf.keras.preprocessing.image_dataset_from_directory(
    dataDirectory,
    labels='inferred',
    label_mode='categorical',
    validation_split=0.2,
    subset='training',
    seed=324893,
    image_size=(height,width),
    batch_size=batchSize)

testData = tf.keras.preprocessing.image_dataset_from_directory(
    dataDirectory,
    labels='inferred',
    label_mode='categorical',
    validation_split=0.2,
    subset='validation',
    seed=324893,
    image_size=(height,width),
    batch_size=batchSize)

#class names and sampling a few images
classes = trainData.class_names
testClasses = testData.class_names
#plt.figure(figsize=(10,10))
# for images, labels in trainData.take(1):
#     for i in range(9):
#         ax = plt.subplot(3, 3, i+1)
#         plt.imshow(images[i].numpy().astype(&quot;uint8&quot;))
#         plt.title(classes[labels[i]])
#         plt.axis(&quot;off&quot;)
# plt.show()

#buffer to hold the data in memory for faster performance
autotune = tf.data.experimental.AUTOTUNE
trainData = trainData.cache().shuffle(1000).prefetch(buffer_size=autotune)
testData = testData.cache().prefetch(buffer_size=autotune)

#augment the dataset with zoomed and rotated images
#use convolutional layers to maintain spatial information about the images
#use max pool layers to reduce
#flatten and then apply a dense layer to predict classes
model = tf.keras.Sequential([
    #layers.experimental.preprocessing.RandomFlip('horizontal', input_shape=(height, width, 3)),
    #layers.experimental.preprocessing.RandomRotation(0.1),
    #layers.experimental.preprocessing.RandomZoom(0.1),
    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(height, width, 3)),
    layers.Conv2D(16, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(256, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    # layers.Conv2D(512, 3, padding='same', activation='relu'),
    # layers.MaxPooling2D(),
    #layers.Conv2D(1024, 3, padding='same', activation='relu'),
    #layers.MaxPooling2D(),
    #dropout prevents overtraining by not allowing each node to see each datapoint
    #layers.Dropout(0.5),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dense(len(classes))
    ])

model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.summary()
    
epochs=2
history = model.fit(
    trainData,
    validation_data=testData,
    epochs=epochs
    )

#create confusion matrix
predictions = model.predict_classes(testData)
confusionMatrix = tf.math.confusion_matrix(labels=testClasses, predictions=predictions).numpy()
</code></pre>
<p>I have tried using (foo, foo1) = tf.keras.preprocessing.image_dataset_from_directory(dataDirectory, etc), but I get
(trainData, trainLabels) = tf.keras.preprocessing.image_dataset_from_directory(
ValueError: too many values to unpack (expected 2)</p>
<p>And if I try to return as one variable and then split it as so:</p>
<pre><code>train = tf.keras.preprocessing.image_dataset_from_directory(
    dataDirectory,
    labels='inferred',
    label_mode='categorical',
    validation_split=0.2,
    subset='training',
    seed=324893,
    image_size=(height,width),
    batch_size=batchSize)
trainData = train[0]
trainLabels = train[1]
</code></pre>
<p>I get TypeError: 'BatchDataset' object is not subscriptable</p>
<p>I can access the labels via testClasses = testData.class_names, but I get:</p>
<blockquote>
<p>2020-11-03 14:15:14.643300: W
tensorflow/core/framework/op_kernel.cc:1740] OP_REQUIRES failed at
cast_op.cc:121 : Unimplemented: Cast string to int64 is not supported
Traceback (most recent call last):   File &quot;birdFake.py&quot;, line 115, in

confusionMatrix = tf.math.confusion_matrix(labels=testClasses, predictions=predictions).numpy()   File
&quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py&quot;,
line 201, in wrapper
return target(*args, **kwargs)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/confusion_matrix.py&quot;,
line 159, in confusion_matrix
labels = math_ops.cast(labels, dtypes.int64)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py&quot;,
line 201, in wrapper
return target(*args, **kwargs)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py&quot;,
line 966, in cast
x = gen_math_ops.cast(x, base_type, name=name)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py&quot;,
line 1827, in cast
_ops.raise_from_not_ok_status(e, name)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py&quot;,
line 6862, in raise_from_not_ok_status
six.raise_from(core._status_to_exception(e.code, message), None)   File &quot;&quot;, line 3, in raise_from
tensorflow.python.framework.errors_impl.UnimplementedError: Cast
string to int64 is not supported [Op:Cast]</p>
</blockquote>
<p>I am open to any method to get those labels into the confusion matrix. Any ideas as to why what I am doing is not working would also be appreciated.</p>
<p>UPDATE: I tried the method proposed by Alexandre Catalano, and I get the following error</p>
<blockquote>
<p>Traceback (most recent call last):   File &quot;./birdFake.py&quot;, line 118,
in 
labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])   File &quot;&lt;<strong>array_function</strong> internals&gt;&quot;, line 5, in concatenate
ValueError: all the input arrays must have same number of dimensions,
but the array at index 0 has 1 dimension(s) and the array at index 1
has 0 dimension(s)</p>
</blockquote>
<p>I printed the first element of the labels array, and it is zero</p>
",1,Documentation Replication on Other Examples
445,64759627,TensorFlow custom training step with different loss functions,"<h1>Background</h1>
<p>According to the <a href=""https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch"" rel=""nofollow noreferrer"">TensorFlow documentation</a>, a custom training step can be performed with the following</p>
<pre><code># Fake sample data for testing
x_batch_train = tf.zeros([32, 3, 1], dtype=&quot;float32&quot;)
y_batch_train = tf.zeros([32], dtype=&quot;float32&quot;)
</code></pre>
<pre><code>loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
with tf.GradientTape() as tape:
    logits = model(x_batch_train, training=True)
    loss_value = loss_fn(y_batch_train, logits)

grads = tape.gradient(loss_value, model.trainable_weights)
optimizer.apply_gradients(zip(grads, model.trainable_weights))
</code></pre>
<br>
<p>But if I want to use a different loss function like categorical cross-entropy I would need to argmax the logits created in the gradient tape:</p>
<pre><code>loss_fn = tf.keras.lossees.get(&quot;categorical_crossentropy&quot;)
with tf.GradientTape() as tape:
    logits = model(x_batch_train, training=True)
    prediction = tf.cast(tf.argmax(logits, axis=-1), y_batch_train.dtype)
    loss_value = loss_fn(y_batch_train, prediction)

grads = tape.gradient(loss_value, model.trainable_weights)
optimizer.apply_gradients(zip(grads, model.trainable_weights))
</code></pre>
<hr>
<h1>Problem</h1>
<p>The problem with this is that the <code>tf.argmax</code> function is not differentiable, so TensorFlow wouldn't be able to compute the gradients and you would get the error:</p>
<pre><code>ValueError: No gradients provided for any variable: [...]
</code></pre>
<hr>
<p><strong>My question:</strong> Without changing the loss function how could I make the second example work?</p>
",1,Documentation Replication on Other Examples
446,64769187,"Tensorflow - Interpreting the tf.estimator.ProfilerHook ""_Send"" op","<p>I have a deep CNN/RNN that I train on Google AI platform. I distribute the training on 8 GPUs using the <code>tf.distribute.MirroredStrategy</code>. I recently upgraded my runtime version from 1.13 to 1.15 and my training is more than 2x slower than before. I read that <code>tf.estimator.ProfilerHook</code> can be used to identify performance bottlenecks. So I collected the profiling information and rendered it at <code>chrome://tracing</code>. I got this</p>
<p><a href=""https://i.stack.imgur.com/l5hDZ.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/l5hDZ.jpg"" alt=""profiling screenshot"" /></a></p>
<p>A training step spends an entire 1 second on these <code>_Send</code> ops. What is this? I can't find any documentation on the op or why it's in my graph. What does this mean?</p>
",1,Lack of Alternative Solutions/Documentation
447,64826405,Tensorflow: 'axis' argument in dot product,"<p>Can someone show me the way I should use the <code>axis</code> argument in <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""nofollow noreferrer""><code>tf.tensordot</code></a>?</p>
<p>I read the documentation but it was complicated and I'm still confused. I saw <a href=""https://stackoverflow.com/questions/48082900/in-tensorflow-what-is-the-argument-axis-in-the-function-tf-one-hot"">another question</a> that asks about <code>axis</code> in <code>tf.one_hot</code> and in the answers were some good insights about the matter, but that didn't help me with <code>tf.tensordot</code>. I thought you can give me some insights on this too.</p>
<p>For example, I know I can dot product a vector and a tensor like this:</p>
<pre><code>my_vector = tf.random.uniform(shape=[n])
my_tensor = tf.random.uniform(shape=[m, n])

dp = tf.tensordot(my_tensor, my_vector, 1)
</code></pre>
<p>But when I <em><strong>batch</strong></em> them and add one dimension to them to be of the shape <code>(b, n)</code> and <code>(b, m, n)</code> to obtain a <code>(b, m, 1)</code>, now I don't know how to dot product every batch.</p>
",1,Documentation Ambiguity
448,65157852,How to mix tensorflow keras model and transformers,"<p>I am trying to import a pretrained model from Huggingface's transformers library and extend it with a few layers for classification using tensorflow keras. When I directly use transformers model (Method 1), the model trains well and reaches a validation accuracy of 0.93 after 1 epoch. However, when trying to use the model as a layer within a tf.keras model (Method 2), the model can't get above 0.32 accuracy. As far as I can tell based on the documentation, the two approaches should be equivalent. My goal is to get Method 2 working so that I can add more layers to it instead of directly using the logits produced by Huggingface's classifier head but I'm stuck at this stage.</p>
<pre><code>import tensorflow as tf

from transformers import TFRobertaForSequenceClassification
</code></pre>
<p>Method 1:</p>
<pre><code>model = TFRobertaForSequenceClassification.from_pretrained(&quot;roberta-base&quot;, num_labels=6)
</code></pre>
<p>Method 2:</p>
<pre><code>input_ids = tf.keras.Input(shape=(128,), dtype='int32')

attention_mask = tf.keras.Input(shape=(128, ), dtype='int32')

transformer = TFRobertaForSequenceClassification.from_pretrained(&quot;roberta-base&quot;, num_labels=6)

encoded = transformer([input_ids, attention_mask])

logits = encoded[0]

model = tf.keras.models.Model(inputs = [input_ids, attention_mask], outputs = logits)

</code></pre>
<p>Rest of the code for either method is identical,</p>
<pre><code>model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), 
              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])
</code></pre>
<p>I am using Tensorflow 2.3.0 and have tried with transformers versions 3.5.0 and 4.0.0.</p>
",1,Documentation Replication on Other Examples
449,65277703,image normalization and TPU,"<p>I'm trying to incorporate image normalization in my keras model to run on Google's cloud TPU. Therefore I inserted a line into my code:</p>
<pre><code>with strategy.scope():
     input_shape=(128,128,3)
     image_0 = Input(shape=input_shape)
     **image_1 = tf.image.per_image_standardization(image_0)**
     ...
</code></pre>
<p>There was nor error thrown, but according the documentation of google tf.image.per_image_standardization
is not a supported function. Does anybody know if it works anyhow, or does anybody have an idea how to check if it works?</p>
",1,Documentation Replicability
450,65436819,Keras: How to use `image_dataset_from_directory` to load test set?,"<p>I am using <code>tf.keras.preprocessing.image_dataset_from_directory</code> to load dataset as follows,</p>
<pre><code>train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir, 
                                                                    labels='inferred', 
                                                                    label_mode='categorical',
                                                                    batch_size=32,
                                                                    image_size=(224, 224))


val_dataset = tf.keras.preprocessing.image_dataset_from_directory(val_dir, 
                                                                  labels='inferred', 
                                                                  label_mode='categorical',
                                                                  batch_size=32,
                                                                  image_size=(224, 224))

</code></pre>
<p>However, when I check the document looks like this argument <code>labels</code> seem to be a must-have one,  but my test data has no labels, so how can I load test data? Is there a convenient and unified way to do this?</p>
",1,Documentation Replicability
451,65437493,convert string to float array in csv using tf.data,"<p>I have a csv like this :</p>
<pre><code>kw_text,kw_text_weight
amazon google,0.5 0.5
google facebook microsoft,0.5 0.3 0.2
</code></pre>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>kw_text</th>
<th>kw_text_weight</th>
</tr>
</thead>
<tbody>
<tr>
<td>amazon google</td>
<td>0.5 0.5</td>
</tr>
<tr>
<td>google facebook microsoft</td>
<td>0.5 0.3 0.2</td>
</tr>
</tbody>
</table>
</div>
<p>I want to convert column <code>text_weight</code> to <code>tf.data</code> . But I find nothing about it in tensorflow document website .</p>
",1,Lack of Alternative Solutions/Documentation
452,65464181,An alternative to tf.distribute.cluster_resolver.TPUClusterResolver( tpu_name) to be used in Sagemaker?,"<ol>
<li><p>task : object_detection</p>
</li>
<li><p>environment: AWS sagemaker</p>
</li>
<li><p>instance type: 'ml.p2.xlarge' | num_instances = 1</p>
</li>
<li><p>Main file to be run: <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py"" rel=""nofollow noreferrer"">original</a></p>
</li>
<li><p>Problematic code segment from the main file:</p>
<pre><code>    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
    FLAGS.tpu_name)
    tf.config.experimental_connect_to_cluster(resolver)
    tf.tpu.experimental.initialize_tpu_system(resolver)
    strategy = tf.distribute.experimental.TPUStrategy(resolver)
    elif FLAGS.num_workers &gt; 1:
        strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    else:
        strategy = tf.compat.v2.distribute.MirroredStrategy()
</code></pre>
</li>
<li><p>Problem : Can't find the proper value to be given as <code>tpu_name</code> argument.</p>
</li>
<li><p>My research on the problem:</p>
</li>
</ol>
<p>According to the tensorflow documentation in <a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/TPUClusterResolver"" rel=""nofollow noreferrer"">tf.distribute.cluster_resolver.TPUClusterResolver</a>, it says that this resolver works only on Google Cloud platform.</p>
<blockquote>
<p>This is an implementation of cluster resolvers for the Google Cloud
TPU service.</p>
<p>TPUClusterResolver supports the following distinct environments:
Google Compute Engine Google Kubernetes Engine Google internal</p>
<p>It can be passed into tf.distribute.TPUStrategy to support TF2
training on Cloud TPUs.</p>
</blockquote>
<p>But from <a href=""https://github.com/tensorflow/tensorflow/issues/39721"" rel=""nofollow noreferrer"">this issue in github</a>, I found out that a similar code also works in Azure.</p>
<ol start=""8"">
<li>My question :</li>
</ol>
<p>Is there a way I can bypass this resolver and initialize my tpu in <strong>sagemaker</strong> ?</p>
<p>Even better, if I can find a way to insert the name or url of sagemaker gpu to the resolver and initiate it from there ?</p>
",1,Documentation Replicability
453,65481591,Keras Generator to tf.data.Dataset,"<p>I am working with the Mask RCNN keras implementation but the data generator hard locks on my systems when using <code>use_multiprocessing=True</code>. The data generator runs fine in single thread. I am trying to convert the data generator to a <code>tf.data.Dataset</code> as recommended by tensorflow. I have no idea how to do this and have been unable to find any documentation on this.</p>
<p>Mask RCNN data generator:</p>
<pre><code>class DataGenerator(KU.Sequence):
    &quot;&quot;&quot;An iterable that returns images and corresponding target class ids,
        bounding box deltas, and masks. It inherits from keras.utils.Sequence to avoid data redundancy
        when multiprocessing=True.

        dataset: The Dataset object to pick data from
        config: The model config object
        shuffle: If True, shuffles the samples before every epoch
        augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.
            For example, passing imgaug.augmenters.Fliplr(0.5) flips images
            right/left 50% of the time.
        random_rois: If &gt; 0 then generate proposals to be used to train the
                     network classifier and mask heads. Useful if training
                     the Mask RCNN part without the RPN.
        detection_targets: If True, generate detection targets (class IDs, bbox
            deltas, and masks). Typically for debugging or visualizations because
            in trainig detection targets are generated by DetectionTargetLayer.

        Returns a Python iterable. Upon calling __getitem__() on it, the
        iterable returns two lists, inputs and outputs. The contents
        of the lists differ depending on the received arguments:
        inputs list:
        - images: [batch, H, W, C]
        - image_meta: [batch, (meta data)] Image details. See compose_image_meta()
        - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)
        - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.
        - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs
        - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]
        - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width
                    are those of the image unless use_mini_mask is True, in which
                    case they are defined in MINI_MASK_SHAPE.

        outputs list: Usually empty in regular training. But if detection_targets
            is True then the outputs list contains target class_ids, bbox deltas,
            and masks.
        &quot;&quot;&quot;

    def __init__(self, dataset, config, shuffle=True, augmentation=None,
                 random_rois=0, detection_targets=False):

        self.image_ids = np.copy(dataset.image_ids)
        self.dataset = dataset
        self.config = config

        # Anchors
        # [anchor_count, (y1, x1, y2, x2)]
        self.backbone_shapes = compute_backbone_shapes(config, config.IMAGE_SHAPE)
        self.anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,
                                                      config.RPN_ANCHOR_RATIOS,
                                                      self.backbone_shapes,
                                                      config.BACKBONE_STRIDES,
                                                      config.RPN_ANCHOR_STRIDE)

        self.shuffle = shuffle
        self.augmentation = augmentation
        self.random_rois = random_rois
        self.batch_size = self.config.BATCH_SIZE
        self.detection_targets = detection_targets

    def __len__(self):
        return int(np.ceil(len(self.image_ids) / float(self.batch_size)))

    def __getitem__(self, idx):
        b = 0
        image_index = -1
        while b &lt; self.batch_size:
            
            # Increment index to pick next image. Shuffle if at the start of an epoch.
            image_index = (image_index + 1) % len(self.image_ids)

            if self.shuffle and image_index == 0:
                np.random.shuffle(self.image_ids)

            # Get GT bounding boxes and masks for image.
            image_id = self.image_ids[image_index]
            image, image_meta, gt_class_ids, gt_boxes, gt_masks = \
                load_image_gt(self.dataset, self.config, image_id,
                              augmentation=self.augmentation)

            # Skip images that have no instances. This can happen in cases
            # where we train on a subset of classes and the image doesn't
            # have any of the classes we care about.
            if not np.any(gt_class_ids &gt; 0):
                continue

            # RPN Targets
            rpn_match, rpn_bbox = build_rpn_targets(image.shape, self.anchors,
                                                    gt_class_ids, gt_boxes, self.config)

            # Mask R-CNN Targets
            if self.random_rois:
                rpn_rois = generate_random_rois(
                    image.shape, self.random_rois, gt_class_ids, gt_boxes)
                if self.detection_targets:
                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask = \
                        build_detection_targets(
                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, self.config)

            # Init batch arrays
            if b == 0:
                batch_image_meta = np.zeros((self.batch_size,) + image_meta.shape, dtype=image_meta.dtype)
                batch_rpn_match = np.zeros([self.batch_size, self.anchors.shape[0], 1], dtype=rpn_match.dtype)
                batch_rpn_bbox = np.zeros([self.batch_size, self.config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4], dtype=rpn_bbox.dtype)
                batch_images = np.zeros((self.batch_size,) + image.shape, dtype=np.float32)
                batch_gt_class_ids = np.zeros((self.batch_size, self.config.MAX_GT_INSTANCES), dtype=np.int32)
                batch_gt_boxes = np.zeros((self.batch_size, self.config.MAX_GT_INSTANCES, 4), dtype=np.int32)
                batch_gt_masks = np.zeros((self.batch_size, gt_masks.shape[0], gt_masks.shape[1],self.config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)
                if self.random_rois:
                    batch_rpn_rois = np.zeros((self.batch_size, rpn_rois.shape[0], 4), dtype=rpn_rois.dtype)
                    if self.detection_targets:
                        batch_rois = np.zeros((self.batch_size,) + rois.shape, dtype=rois.dtype)
                        batch_mrcnn_class_ids = np.zeros((self.batch_size,) + mrcnn_class_ids.shape, dtype=mrcnn_class_ids.dtype)
                        batch_mrcnn_bbox = np.zeros((self.batch_size,) + mrcnn_bbox.shape, dtype=mrcnn_bbox.dtype)
                        batch_mrcnn_mask = np.zeros((self.batch_size,) + mrcnn_mask.shape, dtype=mrcnn_mask.dtype)

            # If more instances than fits in the array, sub-sample from them.
            if gt_boxes.shape[0] &gt; self.config.MAX_GT_INSTANCES:
                ids = np.random.choice(
                    np.arange(gt_boxes.shape[0]), self.config.MAX_GT_INSTANCES, replace=False)
                gt_class_ids = gt_class_ids[ids]
                gt_boxes = gt_boxes[ids]
                gt_masks = gt_masks[:, :, ids]

            # Add to batch
            batch_image_meta[b] = image_meta
            batch_rpn_match[b] = rpn_match[:, np.newaxis]
            batch_rpn_bbox[b] = rpn_bbox
            batch_images[b] = mold_image(image.astype(np.float32), self.config)
            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids
            batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes
            batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks
            if self.random_rois:
                batch_rpn_rois[b] = rpn_rois
                if self.detection_targets:
                    batch_rois[b] = rois
                    batch_mrcnn_class_ids[b] = mrcnn_class_ids
                    batch_mrcnn_bbox[b] = mrcnn_bbox
                    batch_mrcnn_mask[b] = mrcnn_mask
            b += 1

        inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,
                  batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]
        outputs = []

        if self.random_rois:
            inputs.extend([batch_rpn_rois])
            if self.detection_targets:
                inputs.extend([batch_rois])
                # Keras requires that output and targets have the same number of dimensions
                batch_mrcnn_class_ids = np.expand_dims(
                    batch_mrcnn_class_ids, -1)
                outputs.extend(
                    [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])

        return inputs, outputs
</code></pre>
<p>I have tried to use the <code>tf.data.Dataset.from_generator()</code> however it requires the <code>output_types=</code> argument and the Mask RCNN outputs a number of lists, I can not figure out how to define <code>output_types=</code>.</p>
<p>I am using <code>python3.7</code>, <code>keras==2.2.5</code>, <code>tensorflow==2.2.0</code></p>
",1,Documentation Replication on Other Examples
454,65640885,CRNN tf.keras.backend.ctc_decode. What is log probability?,"<p>Based on <a href=""https://docs.w3cub.com/tensorflow%7Epython/tf/keras/backend/ctc_decode"" rel=""nofollow noreferrer"">the documentation</a>, the function <code>tf.keras.backend.ctc_decode</code> is supposed to return a <code>Tuple</code>. Its first field contains the best path (let's assume we use greedy search), whereas the second one contains its <code>log probability</code>.</p>
<p>Is this probability actually the accuracy of the prediction?</p>
<p>If not how am I supposed to calculate it?</p>
<p>I've tried on some test images and this was my output:</p>
<pre><code>True value: test0, prediction: test0, acc: 1.841524362564087
True value: test1, prediction: test1, acc: 0.9661365151405334
True value: test2, prediction: test2, acc: 1.0634151697158813
True value: test3, prediction: test3, acc: 2.471940755844116
True value: test4, prediction: test4, acc: 1.4866207838058472
True value: test5, prediction: test5, acc: 0.7630811333656311
True value: test6, prediction: test6, acc: 0.35642576217651367
True value: test7, prediction: test7, acc: 1.5693446397781372
True value: test8, prediction: test8, acc: 0.9700028896331787
True value: test9, prediction: test9, acc: 1.4783780574798584
</code></pre>
<p>During the training part, the final CTC loss was around 0.1 and the prediction is always correct. However what I think it's the probability seems not to be what I expect. They looks like completely random numbers, even grater than 1 or 2! What am I doing wrong?</p>
",1,Documentation Replication on Other Examples
455,65745053,Tensorflow softmax does not ignore masking value,"<p>I am reviving this github <a href=""https://github.com/tensorflow/tensorflow/issues/27010"" rel=""nofollow noreferrer"">issue</a> because I believe it is valid and needs to be explained. tf.keras has a masking layer with docs that reads</p>
<blockquote>
<p>For each timestep in the input tensor (dimension #1 in the tensor), if
all values in the input tensor at that timestep are equal to
mask_value, then the timestep will be masked (skipped) in all
downstream layers (as long as they support masking).</p>
<p>If any downstream layer does not support masking yet receives such an
input mask, an exception will be raised.</p>
</blockquote>
<pre><code>
# create padded zeros and change two valid entries.
inputs = np.zeros([1,5])
inputs[0,1] = 0.5
inputs[0,2] = 0.1
inputs = tf.Variable(inputs)
masked_inputs = tf.keras.layers.Masking(mask_value=0.0)(inputs)
with_masking = tf.keras.layers.Softmax()(masked_inputs)
without_masking = tf.keras.layers.Softmax()(inputs)
</code></pre>
<p>The two results are virtually identical</p>
<pre><code>with_masking
&lt;tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0.1737954 , 0.28654018, 0.19207363, 0.1737954 , 0.1737954 ]],
      dtype=float32)&gt;
without_masking
&lt;tf.Tensor: shape=(1, 5), dtype=float64, numpy=array([[0.1737954 , 0.28654017, 0.19207362, 0.1737954 , 0.1737954 ]])&gt;
</code></pre>
<h1>Expected behavior</h1>
<p>I expected to just take softmax of the valid entries, similiar to</p>
<pre><code>#Assign one large value 
inputs = np.zeros([1,2])
inputs[0,0] = 0.5
inputs[0,1] = 0.1
inputs = tf.Variable(inputs)
without_masking = tf.keras.layers.Softmax()(inputs)

without_masking
&lt;tf.Tensor: shape=(1, 2), dtype=float64, numpy=array([[0.59868766, 0.40131234]])&gt;
</code></pre>
<p>padded at the correct positions</p>
<pre><code>with_masking
&lt;tf.Tensor: shape=(1, 5), dtype=float32, numpy=
array([[0 , 0.59868766, 0.40131234, 0, 0 ]],
      dtype=float32)&gt;
</code></pre>
<p>To ignore 0's in a softmax function, we could switch out massively negative numbers?</p>
<p>Related: <a href=""https://stackoverflow.com/questions/39091432/tensorflow-softmax-ignore-negative-labels-just-like-caffe"">tensorflow - softmax ignore negative labels (just like caffe)</a></p>
<pre><code>from tensorflow import __version__
__version__
'2.3.1'
</code></pre>
",1,Documentation Replication on Other Examples
456,65779087,How to use tf.gradients within a model and still use a custom training loop?,"<p>I would like to make a TensorFlow model where the outputs respect a mathematical condition, namely that output 0 is a scalar function and all subsequent outputs are its partial derivatives w.r.t. the input. This is because my observations are the scalar function and its partials, and not using the partials for training would be a waste of information.</p>
<p>For now, using simply tf.gradients works if I don't build a custom training loop, i.e. when I don't utilize eager execution. The model is built like this, and training works as expected:</p>
<pre><code>import tensorflow as tf


from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras import callbacks

# Creating a model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Dense,
    Dropout,
    Flatten,
    Concatenate,
    Input,
    Lambda,
)

# Custom activation function
from tensorflow.keras.layers import Activation
from tensorflow.keras import backend as K

import numpy
import matplotlib.pyplot as plt

import tensorboard

layer_width = 200
dense_layer_number = 3

def lambda_gradient(args):
    layer = args[0]
    inputs = args[1]
    return tf.gradients(layer, inputs)[0]

# Input is a 2 dimensional vector
inputs = tf.keras.Input(shape=(2,), name=&quot;coordinate_input&quot;)

# Build `dense_layer_number` times a dense layers of width `layer_width`
stream = inputs
for i in range(dense_layer_number):
    stream = Dense(
        layer_width, activation=&quot;relu&quot;, name=f&quot;dense_layer_{i}&quot;
    )(stream)

# Build one dense layer that reduces the 200 nodes to a scalar output
scalar = Dense(1, name=&quot;network_to_scalar&quot;, activation=custom_activation)(stream)

# Take the gradient of the scalar w.r.t. the model input
gradient = Lambda(lambda_gradient, name=&quot;gradient_layer&quot;)([scalar, inputs])

# Combine them to form the model output
concat = Concatenate(name=&quot;concat_scalar_gradient&quot;)([scalar, gradient])

# Wrap everything in a model
model = tf.keras.Model(inputs=inputs, outputs=concat)

loss = &quot;MSE&quot;
optimizer = &quot;Adam&quot;

# And compile
model.compile(loss=loss, optimizer=optimizer)
</code></pre>
<p>However, them problem now comes when I want to do online training (i.e. with an incremental dataset). In this case, I wouldn't compile my model at the very end. Instead, I write a loop as such (before calling model.compile):</p>
<pre><code># ... continue from previous minus model.compile

loss_fn = tf.keras.losses.MeanSquaredError()
optimizer = tf.keras.optimizers.Adam()

# Iterate over the batches of a dataset and train.
for i_batch in range(number_of_batches):

    with tf.GradientTape() as tape:
        # Predict w.r.t. the inputs X
        prediction_Y = model(batches_X[i_batch])
        
        # Compare batch prediction to batch observation
        loss_value = loss_fn(batches_Y[i_batch], prediction_Y)

    gradients = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(gradients, model.trainable_weights))
</code></pre>
<p>This however gives the following exception at <code>prediction_Y = model(batches_X[i_batch])</code>:</p>
<pre><code>RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
</code></pre>
<p>As most examples, tutorials and documentation solely deal with using gradients to do training, and not within the model, I can't find any good resources how to deal with this. I tried to find how to use gradient tape, but I can't figure out how to use it in the model design phase. Any pointers would be appreciated!</p>
<p>Versions used:</p>
<pre><code>$ python --version                                         
Python 3.8.5
$ python -c &quot;import tensorflow as tf;print(tf.__version__);print(tf.keras.__version__)&quot;
2.2.0
2.3.0-tf
</code></pre>
",1,Inadequate Examples
457,65794527,"Example of output_signature , output_types & output_shapes for complex object called by tf.data.Dataset.from_generator","<p>I've a generator function that yields the following tuple: <code>yield (transformed_input_array, set_y)</code></p>
<p><em>transformed_input_array</em> is a list of ndarrays with the following shape: <em>(1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140)</em>  and the following types: <em>tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64</em>
<em>set_y</em> is a ndarray of shape <em>1024</em> and type of <em>int64</em></p>
<p>I've wrapped my generator with tf.data.Dataset.from_generator function, here is the code:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
    generator,
    # output_signature=(
    #     tf.TensorSpec(shape=(), dtype=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64)),
    #     tf.TensorSpec(shape=1024, dtype=tf.int64))
    output_types=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64, tf.int64),
    output_shapes=((1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140), 1024)
)
</code></pre>
<p>But when I run the training, I get the following error:</p>
<blockquote>
<p>ValueError: Data is expected to be in format <code>x</code>, <code>(x,)</code>, <code>(x, y)</code>,
or <code>(x, y, sample_weight)</code>, found: (&lt;tf.Tensor 'IteratorGetNext:0'
shape=(1024, 104) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:1'
shape=(1024, 142) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:2'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'It eratorGetNext:3'
shape=(1024, 1) dtype=int16&gt;, &lt;tf.Tensor 'IteratorGetNext:4'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:5'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:6'
shape=(1024, 140) dtype=float64&gt;, &lt;tf.Tensor 'ExpandDims:0'
shape=(1024, 1) dtype=int64&gt;)</p>
</blockquote>
<p>If I try to run with output_signature param (commented out code), I get the following error:</p>
<blockquote>
<p>TypeError: Cannot convert value (tf.float64, tf.float64, tf.int8,
tf.int16, tf.int8, tf.int8, tf.float64) to a TensorFlow DType.</p>
</blockquote>
<p><strong>Can someone provide an example, of how I should treat complex type (list of ndarrays)?</strong> Couldn't find any example in TF documentation..</p>
",1,Inadequate Examples
458,65835387,ValueError: too many values to unpack (expected 2) when using tf.keras.preprocessing.image_dataset_from_directory,"<p>I want to create a dataset-variable as well as a labels-variable using the function tf.keras.preprocessing.image_dataset_from_directory (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory</a>).
The documentation states:</p>
<blockquote>
<p>Returns:
A tf.data.Dataset object.
If label_mode is None, it yields
float32 tensors of shape (batch_size, image_size[0], image_size[1],
num_channels), encoding images (see below for rules regarding
num_channels).
Otherwise, it yields a tuple (images, labels), where
images has shape (batch_size, image_size[0], image_size[1],
num_channels), and labels follows the format described below.</p>
</blockquote>
<p>My code is the following:</p>
<pre><code>train_ds, labels = tf.keras.preprocessing.image_dataset_from_directory(
  directory = data_dir,
  labels='inferred',
  label_mode = &quot;int&quot;,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
</code></pre>
<p>I expect to get a tuple as return values, but instead I get the error message:</p>
<pre><code>Found 2160 files belonging to 2160 classes.
Using 1728 files for training.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-168-ed9d42ed2ab9&gt; in &lt;module&gt;
      7   seed=123,
      8   image_size=(img_height, img_width),
----&gt; 9   batch_size=batch_size)

ValueError: too many values to unpack (expected 2)
</code></pre>
<p>When I save the output in one variable (just train_ds) and I inspect the variable, I get the following output:</p>
<pre><code>&lt;BatchDataset shapes: ((None, 120, 30, 3), (None,)), types: (tf.float32, tf.int32)&gt;
</code></pre>
<p>How can I access the two tuples inside seperatly?</p>
",1,Documentation Ambiguity
459,65863738,Changing order of Input Image in 3D convolutions,"<p>According to the official documentation of tf.keras.layers.Conv3D</p>
<blockquote>
<p>5+D tensor with shape: batch_shape + (channels, conv_dim1, conv_dim2,
conv_dim3) if data_format='channels_first' or 5+D tensor with shape:
batch_shape + (conv_dim1, conv_dim2, conv_dim3, channels) if
data_format='channels_last'</p>
</blockquote>
<p>. Now the whole idea around channels and batch shape makes sense, but will changing the general order of (conv_dim1, conv_dim2,conv_dim2) as (x,y,z) to say (z,x,y) affect the performance.</p>
<p>Does Conv3D worry about order of x-y-z dimension ?</p>
<p>I was training a U-net segmentation model and upon changing the order of axis I saw difference in performance. (x,y,z) order converges faster as compared to (y,x,z).</p>
<p>I just wanted to make sure what's the correct way..</p>
",1,Documentation Ambiguity
460,65953591,Which format should have time series input for LSTM-Model in Tensorflow?,"<p>I have a problem with the input for the fit-function of an LSTM-Model in TensorFlow. I have an input with the following shape:<br />
(5, 128, 78, 80)<br />
The fields are: (number of samples, timesteps, feature1, feature2)</p>
<p>The output has the shape: (5, 128, 78, 2)</p>
<p>This is my model:</p>
<pre><code>from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation

batch_size=5

time_model = tf.keras.Sequential()
time_model.add(tf.keras.layers.LSTM(512,return_sequences=True,input_shape=(128,2)))
time_model.add(Activation('sigmoid'))
time_model.add(Dense(2,name=&quot;dense&quot;))
time_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')


time_model.fit(x=time_input,y=time_output, epochs=10, batch_size=batch_size)
</code></pre>
<p>I get the following error:<br />
<code>ValueError: Input 0 of layer sequential_38 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (5, 128, 78, 80)</code></p>
<p>So I think, I have to change the shape of my data, but I don't know how. I tried already different values for input and  input_shape-attribute.<br />
I read in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM</a> that the input has to be a tensor with shape <code>[batch, timesteps, feature]</code>. So I put the two features in a nested array, and gave <code>[batch, timesteps, array of the features]</code> to the fit-function. But it told me that the data could not be converted to a tensor. Also explicit converting with <code>tf.convert_to_tensor</code> did not work.</p>
<p>I would be really glad, if someone could explain me, how I can pass input data with two features to an LSTM-model.</p>
",1,Documentation Ambiguity
461,66019998,"How to get a processed dataset, if the processing steps are not tensor operations?","<p>I have an instance of <code>tf.data.Dataset()</code>, of images, basically, acquired this way:</p>
<pre><code>import tensorflow as tf

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_directory,
    image_size = (image_height, image_width),
    batch_size = batch_size
)
</code></pre>
<p>So, this dataset has <code>(data, label)</code> where the data is a tensor of shape <code>(batch_size, image_height, image_width, channels)</code> [I don't really need the labels it assigns]. So far so good. The problem is, I need to process this dataset, applying certain operations to the images, and, this dataset is too big to load everything in memory (that's why <code>batch_size</code> is there). According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">tensorflow documentation</a>, <code>tf.data.Dataset.map()</code> is the function I need (or so I assume....).</p>
<pre><code>def image_processing(data):
    print(data.shape)
    
    # Do some operations.
    # Do some copies [because np.arrays help me more...].
    copy = np.array(data, copy=True)

    # Change some pixels, like, zero out a square in this image
    # It sad that TensorFlow can't do this assignment if it were a tf.Tensor:
    copy[10:80,10:80] = np.array([0,0,0])

    # Do more things, and when done return.
    return something


processed_dataset = dataset.map(lambda image, label: (image_processing(image), label))
</code></pre>
<p>First of all, the shape returned by the print: <code>(None, 200, 200, 3)</code> instead of <code>(32, 200, 200, 3)</code>, or, instead of <code>(200, 200, 3)</code> [which is what I'd expect from reading the documentation] [let's assume batch of 32, and images 200x200], and this is messing my code, because, I need to do assigments, like, take the ith image, and change a couple pixels: <code>data[i][12:15,40:50] = np.array([1,2,3])</code> and things like that.</p>
<p>Basically, that's the error message: <code>TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'</code>.</p>
<hr />
<p><strong>In summary, my question:</strong> How can I get a <code>processed_dataset</code>, where the processing steps will not be whole tensor operations, but instead, will be changing individual values in the data (say, individual pixels), for certain images (say, the ith image, jth image, etc)?</p>
<hr />
<p>If you must know, I am running this in Ubuntu. Tensorflow version is:</p>
<pre><code>&gt;&gt;&gt; tf.__version__
'2.4.0'
</code></pre>
",1,Documentation Replication on Other Examples
462,66030439,TensorFlow profiler using tf.profiler.experimental.client.trace gives empty trace data,"<p>I'm unable to collect trace data using <code>tf.profiler.experimental.client.trace</code> Please can someone help? I'm following the (CPU/GPU) example usage here <a href=""https://www.tensorflow.org/api_docs/python/tf/profiler/experimental/client/trace"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/profiler/experimental/client/trace</a> which looks simple enough.</p>
<p>I have a very simple model, and I'm able to collect trace data from it using <code>tf.profiler.experimental.start</code> and <code>tf.profiler.experimental.stop</code>.</p>
<p>But <code>tf.profiler.experimental.client.trace</code> gives me empty trace data.</p>
<p>My code is as follows:</p>
<pre><code>import tensorflow as tf
import numpy as np
                                                                                                    
def mnist_dataset(batch_size):
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()                                              
    x_train = x_train / np.float32(255)
    y_train = y_train.astype(np.int64)
    train_dataset = tf.data.Dataset.from_tensor_slices(
        (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)
    return train_dataset

batch_size = 64
dataset = mnist_dataset(batch_size)

model = tf.keras.Sequential([
    tf.keras.Input(shape=(28, 28)),
    tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
    metrics=['accuracy'])
                                                                                           
#tf.profiler.experimental.start('./logs/tb_log')                                                                        
tf.profiler.experimental.server.start(6009)

model.fit(dataset, epochs=10, steps_per_epoch=70)

tf.profiler.experimental.client.trace('grpc://localhost:6009', './logs/tbc_log', 20000)
#tf.profiler.experimental.stop()         
</code></pre>
<p>The code runs through the epochs, and then outputs</p>
<pre><code>2021-02-02 17:49:44.943933: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288184943887718 [2021-02-02T17:49:44.943887718+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 2
2021-02-02 17:49:44.944037: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:49:44.944197: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:49:44.944316: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:49:44.944340: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:49:44.946274: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:49:44.947547: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:49:44.946338176+00:00) for the scheduled start (2021-02-02T17:49:44.943887718+00:00) and will start immediately.
2021-02-02 17:49:44.947582: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:49:44.947660: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 2 GPUs
2021-02-02 17:49:44.949656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.11.0
2021-02-02 17:50:08.435260: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-02-02 17:50:08.435591: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-02-02 17:50:08.635192: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. 
2021-02-02 17:50:08.648616: I tensorflow/core/profiler/rpc/profiler_service_impl.cc:67] Collecting XSpace to repository: ./logs/tbc_log/plugins/profile/2021_02_02_17_49_44/localhost_6009.xplane.pb
2021-02-02 17:50:08.650309: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-02-02 17:50:08.650676: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
No trace event is collected. Automatically retrying.

2021-02-02 17:50:08.651046: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288208651017638 [2021-02-02T17:50:08.651017638+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 1
2021-02-02 17:50:08.651123: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:50:08.651274: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:50:08.651391: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:50:08.651420: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:50:08.652492: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:50:08.652570: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:50:08.652539729+00:00) for the scheduled start (2021-02-02T17:50:08.651017638+00:00) and will start immediately.
2021-02-02 17:50:08.652591: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:50:31.280828: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-02-02 17:50:31.281134: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-02-02 17:50:31.510697: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. 
2021-02-02 17:50:31.515475: I tensorflow/core/profiler/rpc/profiler_service_impl.cc:67] Collecting XSpace to repository: ./logs/tbc_log/plugins/profile/2021_02_02_17_49_44/localhost_6009.xplane.pb
2021-02-02 17:50:31.518037: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-02-02 17:50:31.518440: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
No trace event is collected. Automatically retrying.

2021-02-02 17:50:31.518819: I tensorflow/core/profiler/rpc/client/capture_profile.cc:198] Profiler delay_ms was 0, start_timestamp_ns set to 1612288231518793164 [2021-02-02T17:50:31.518793164+00:00]
Starting to trace for 20000 ms. Remaining attempt(s): 0
2021-02-02 17:50:31.518889: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:75] Deadline set to 2021-02-02T17:50:44.890124419+00:00 because max_session_duration_ms was 60000 and session_creation_timestamp_ns was 1612288184890124419 [2021-02-02T17:49:44.890124419+00:00]
2021-02-02 17:50:31.519021: I tensorflow/core/profiler/rpc/client/profiler_client.cc:113] Asynchronous gRPC Profile() to localhost:6009
2021-02-02 17:50:31.519124: I tensorflow/core/profiler/rpc/client/remote_profiler_session_manager.cc:96] Issued Profile gRPC to 1 clients
2021-02-02 17:50:31.519147: I tensorflow/core/profiler/rpc/client/profiler_client.cc:131] Waiting for completion.
2021-02-02 17:50:31.520067: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-02-02 17:50:31.520136: W tensorflow/core/profiler/lib/profiler_session.cc:144] Profiling is late (2021-02-02T17:50:31.520095781+00:00) for the scheduled start (2021-02-02T17:50:31.518793164+00:00) and will start immediately.
2021-02-02 17:50:31.520152: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-02-02 17:50:44.891412: W tensorflow/core/profiler/rpc/client/profiler_client.cc:152] Deadline exceeded: Deadline Exceeded
2021-02-02 17:50:44.891501: W tensorflow/core/profiler/rpc/client/capture_profile.cc:133] No trace event is collected from localhost:6009
2021-02-02 17:50:44.891526: W tensorflow/core/profiler/rpc/client/capture_profile.cc:145] localhost:6009 returned Deadline exceeded: Deadline Exceeded
No trace event is collected after 3 attempt(s). Perhaps, you want to try again (with more attempts?).
Tip: increase number of attempts with --num_tracing_attempts.
2021-02-02 17:50:44.891848: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
Traceback (most recent call last):
  File &quot;keras_singleworker_2.py&quot;, line 37, in &lt;module&gt;
2021-02-02 17:50:44.893228: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
    tf.profiler.experimental.client.trace('grpc://localhost:6009', './logs/tbc_log', 20000)
  File &quot;/fserver/jonathanb/miniconda3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/profiler/profiler_client.py&quot;, line 131, in trace
    _pywrap_profiler.trace(
tensorflow.python.framework.errors_impl.UnavailableError: No trace event was collected because there were no responses from clients or the responses did not have trace data.
</code></pre>
<p>I've tried locating tf.profiler.experimental.server.start and tf.profiler.experimental.client.trace in other locations in the code, but with no success.</p>
",1,Documentation Ambiguity
463,66038861,Why are both branches in tf.cond being executed? And why does tf.while_loop finish the loop even though the condition still true?,"<p>I am using keras for a while now, but usually I don't have to use customized layers or perform some more complex flow control, so I'm struggling trying to understand somethings.</p>
<p>I am modeling a neural network with a customized layer on the top. This customized layer calls another function (<code>search_sigma</code>)  and inside this function I execute <code>tf.while_loop</code> and inside of <code>tf.while_loop</code> I execute <code>tf.cond</code>.</p>
<p>I cannot understand why the conditions are not working.</p>
<ul>
<li><code>tf.while_loop</code> stops even though the condition (<code>l1</code>) still true</li>
<li><code>tf.cond executes</code> both <code>f1</code> and <code>f2</code> (callables <code>true_fn</code> and <code>false_fn</code>)</li>
</ul>
<p>Could someone help me understand what I am missing?</p>
<p>I already tried to change both tf.cond and tf.while_loop conditions for true tensors, just to see what would happen. The behavior (exactly same errors) remained the same.</p>
<p>I also tried to write this code without implementing a class (using just functions). Nothing changed.</p>
<p>I tried to find solutions looking at tensorflow documentation, other stack overflow doubts and websites talking about tf.while_loop and tf.cond.</p>
<p>I left some <code>print()</code>s in the body of the code to try to track what was happening.</p>
<pre><code>class find_sigma:
    
    def __init__ (self, t_inputs,  inputs,  expected_perp=10. ):       
        self.sigma, self.cluster = t_inputs
        self.inputs = inputs
        self.expected_perp = expected_perp
        self.min_sigma=tf.constant([0.01],tf.float32)
        self.max_sigma=tf.constant([50.],tf.float32)
 

    def search_sigma(self):

        
        def cond(s,sigma_not_found): return sigma_not_found


        def body(s,sigma_not_found):   

            print('loop')
            pi = K.exp( - K.sum( (K.expand_dims(self.inputs, axis=1) - self.cluster)**2, axis=2  )/(2*s**2) )        
            pi = pi / K.sum(pi)
            MACHINE_EPSILON = np.finfo(np.double).eps
            pi = K.maximum(pi, MACHINE_EPSILON)
            H = - K.sum ( pi*(K.log(pi)/K.log(2.)) , axis=0 )
            perp = 2**H

            print('0')

            l1 = tf.logical_and (tf.less(perp , self.expected_perp), tf.less(0.01, self.max_sigma-s))
            l2 = tf.logical_and (tf.less(  self.expected_perp , perp) , tf.less(0.01, s-self.min_sigma) )
    
            def f1():
                print('f1')
                self.min_sigma = s 
                s2 = (s+self.max_sigma)/2 
                return  [s2, tf.constant([True])]
                

            def f2(l2): 
                tf.cond( l2, true_fn=f3 , false_fn = f4)

            def f3(): 
                print('f3')
                self.max_sigma = s 
                s2 = (s+self.min_sigma)/2
                return [s2, tf.constant([True])]

            def f4(): 
                print('f4')
                return [s, tf.constant([False])]
            
            output = tf.cond( l1, f1 ,  f4 ) #colocar f2 no lugar de f4

            s, sigma_not_found = output
            
            print('sigma_not_found = ',sigma_not_found)
            return [s,sigma_not_found]

        print('01')

        sigma_not_found = tf.constant([True])

        new_sigma,sigma_not_found=sigma_not_found = tf.while_loop(
            cond , body, loop_vars=[self.sigma,sigma_not_found]
        )

        print('saiu')
        
        print(new_sigma)

        return new_sigma
</code></pre>
<p>The piece of code that calls the above code is:</p>
<pre><code>self.sigma = tf.map_fn(fn=lambda t: find_sigma(t,  inputs).search_sigma() , elems=(self.sigma,self.clusters), dtype=tf.float32)
</code></pre>
<p>'inputs' is a <code>(None, 10)</code> size tensor</p>
<p>'self.sigma' is a <code>(10,)</code> size tensor</p>
<p>'self.clusters' is a <code>(N, 10)</code> size tensor</p>
",1,Inadequate Examples
464,66049816,Custom layer in sequential model tensorflow,"<p>I'm trying to create a custom layer for my model, which can be used the classic Dense layer of Keras. Here my custom layer:</p>
<pre><code>class MyDenseLayer(tf.keras.layers.Layer):
    def __init__(self, num_outputs):
        super(MyDenseLayer, self).__init__()
        self.num_outputs = num_outputs
    def build(self, input_shape):
        self.kernel = self.add_weight(&quot;kernel&quot;, 
                                      shape=[int(input_shape[-1]),
                                      self.num_outputs])
    def call(self, input):
        return tf.matmul(input, self.kernel)
</code></pre>
<p>It does not do anything 'custom' for now.</p>
<p>But when I add it to my model</p>
<pre><code>def build_model():
    model = keras.Sequential([
        MyDenseLayer(10)(normed_x_train),
        layers.Activation(tf.nn.relu),
        layers.Dense(1, activation=tf.nn.relu)
        ])
    return model
</code></pre>
<p>I get this:</p>
<pre><code>The added layer must be an instance of class Layer. Found: tf.Tensor(
[....])
</code></pre>
<p>Because probably I'm creating directly the object of class Custom Layer. But I do not find in the tf documentation how to add other properties to make it work as a normal layer, i.e. as something like <code>layers.Dense(100, activation=tf.nn.relu)</code></p>
<p>Is there a way to make it work like that ?</p>
",1,Lack of Alternative Solutions/Documentation
465,66062973,TensorFlow custom loss function error: No gradients provided for any variable,"<p>I am creating a custom loss function using <em>tf.raw_ops</em> namespace to train my model using keras. Here is my loss function:</p>
<p><strong>Loss(pred,label)= { 0.0 if pred−label&lt;=0.1, 1.0 elsewhere</strong></p>
<pre><code>comparing_tensor = tf.convert_to_tensor([0.1, 0.1, 0.1])
def custom_loss(y_pred, y_true):
    loss_tensor = tf.raw_ops.Abs(x=y_pred - y_true) # get the abs diff between y_true and y_pred
    boolean_tensor = tf.raw_ops.Greater(x=loss_tensor, y=comparing_tensor) # get a boolean tensor based on Greater operation. Example: [True, False, True] 
    binary_tensor = tf.raw_ops.Cast(x=boolean_tensor, DstT=tf.float32) # convert boolean to bianry tensor Example: [1.0, 0.0, 1.0]
    mean_tensor= tf.raw_ops.Mean(input=binary_tensor, axis=-1) # get mean of binary tensor, 2/3=0.66 
    loss = tf.raw_ops.Reshape(tensor=mean_tensor, shape=(1,1), name=None) # reshape mean tensor to get desired shape
    return loss
</code></pre>
<p>And then I am using this in my</p>
<pre><code>Keras.model.compile(opt=SDG, loss=custom_loss, metrics=['mse])
</code></pre>
<p>I am getting an error</p>
<blockquote>
<p>ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'dense/kernel:0', 'dense/bias:0', 'x/kernel:0', 'x/bias:0'].**</p>
</blockquote>
<p>I know this may be because some of the <code>tf.operations</code> that I am using are not differentiable, or doesn't have a gradient. However, I have checked this page <strong><a href=""https://docs.w3cub.com/tensorflow%7E2.3/raw_ops"" rel=""nofollow noreferrer"">https://docs.w3cub.com/tensorflow~2.3/raw_ops</a></strong> It shows which operations are differentiable and which are not. All of my operations are differentiable. I am not sure what am I missing. Any help is appreciated.</p>
",1,Documentation Ambiguity
466,66231467,How to set a minimum number of epoch in Optuna SuccessiveHalvingPruner()?,"<p>I'm using Optuna 2.5 to optimize a couple of hyperparameters on a tf.keras CNN model. I want to use pruning so that the optimization skips the less promising corners of the hyperparameters space. I'm using something like this:</p>
<pre><code>study0 = optuna.create_study(study_name=study_name,
                             storage=storage_name,
                             direction='minimize', 
                             sampler=TPESampler(n_startup_trials=25, multivariate=True, seed=123),
                             pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource='auto',
                             reduction_factor=4, min_early_stopping_rate=0),
                             load_if_exists=True)
</code></pre>
<p>Sometimes the model stops after 2 epochs, some other times it stops after 12 epochs, 48 and so forth. What I want is to ensure that the model always trains at least 30 epochs before being pruned. I guess that the parameter <code>min_early_stopping_rate</code> might have some control on this but I've tried to change it from 0 to 30 and then  the models never get pruned. Can someone explain me a bit better than the Optuna documentation, what these parameters in the  <code>SuccessiveHalvingPruner()</code> really do (specially <code>min_early_stopping_rate</code>)?
Thanks</p>
",1,Requesting (Additional) Documentation/Examples
467,66546321,Proper way to input a scalar into a Tensorflow 2 model,"<p>In my Tensorflow 2 model, I want my batch size to be parametric, such that I can build tensors which have appropriate batch size dynamically. I have the following code:</p>
<pre><code>batch_size_param = 128

tf_batch_size = tf.keras.Input(shape=(), name=&quot;tf_batch_size&quot;, dtype=tf.int32)
batch_indices = tf.range(0, tf_batch_size, 1)

md = tf.keras.Model(inputs={&quot;tf_batch_size&quot;: tf_batch_size}, outputs=[batch_indices])
res = md(inputs={&quot;tf_batch_size&quot;: batch_size_param})
</code></pre>
<p>The code throws an error in <code>tf.range</code>:</p>
<pre><code>ValueError: Shape must be rank 0 but is rank 1
 for 'limit' for '{{node Range}} = Range[Tidx=DT_INT32](Range/start, tf_batch_size, Range/delta)' with input shapes: [], [?], []
</code></pre>
<p>I think the problem is with the fact that <code>tf.keras.Input</code> automatically tries to expand the input array at the first dimension, since it expects the partial shape of the input without the batch size and will attach the batch size according to the shape of the input array, which in my case a scalar. I can just feed the scalar value as a constant integer into <code>tf.range</code> but this time, I won't be able to change it after the model graph has been compiled.</p>
<p>Interestingly, I failed to find a proper way to input only a scalar into a TF-2 model even though I checked the documentation, too. So, what would be the best way to handle such a case?</p>
",1,Documentation Replication on Other Examples
468,66570237,TensorFlow model to Keras functional API?,"<p>I want to have this model as a functional model that uses Keras API, but not sure how. I want my model to be in the form of <code>model = tf.keras.model.Model(....)</code> so I can just evaluate or export the model by calling <code>model</code>. But I don't know how to do this with attention layers in the model. The <a href=""https://keras.io/api/layers/attention_layers/attention/"" rel=""nofollow noreferrer"">Keras attention layer documentation</a> stops at that very step and leave it to the user to figure it out.</p>
<p>FYI, my model uses IMDB reviews for sentiment analysis.</p>
<pre class=""lang-py prettyprint-override""><code>query_layer = tf.keras.layers.Conv1D(filters=100, kernel_size=4, padding='same')
value_layer = tf.keras.layers.Conv1D(filters=100, kernel_size=4, padding='same')

attention = tf.keras.layers.Attention()
concat = tf.keras.layers.Concatenate()

cells = [tf.keras.layers.LSTMCell(256), tf.keras.layers.LSTMCell(64)]
rnn = tf.keras.layers.RNN(cells)
output_layer = tf.keras.layers.Dense(1)

for batch in ds['train'].batch(32):
    text = batch['text']
    embeddings = embedding_layer(vectorize_layer(text))
    query = query_layer(embeddings)
    value = value_layer(embeddings)
    query_value_attention = attention([query, value])
    attended_values = concat([query, query_value_attention])
    logits = output_layer(rnn(attended_values))
    loss = binary_crossentropy(tf.expand_dims(batch['label'], -1),
                                               logits, from_logits=True)
</code></pre>
",1,Documentation Replicability
469,66874943,Why iterations over the same tf.data.Dataset give different data each iteration?,"<p>I'm trying to understand how <strong>tf.data.Dataset</strong> works.</p>
<p>It says on the documentation that <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take"" rel=""nofollow noreferrer"">take</a> returns a dataset with a certain amount of elements from that dataset. You can then iterate over a single sample (in this case a batch):</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow.compat.v2 as tf
import tensorflow_datasets as tfds

# Construct a tf.data.Dataset
ds = tfds.load('mnist', split='train', shuffle_files=True)

# Build your input pipeline
ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)

single_batch_dataset = ds.take(1)

for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)
# ...
</code></pre>
<p>Outputs:</p>
<pre><code>tf.Tensor([2 0 6 6 8 8 6 0 3 4 8 7 5 2 5 7 8 7 1 1 1 8 6 4 0 4 3 2 4 2 1 9], shape=(32,), dtype=int64)
</code></pre>
<p>However, iterating over it again, gives different labels: (continuation of last code)</p>
<pre class=""lang-py prettyprint-override""><code>for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)

for example in single_batch_dataset:
  image, label = example[&quot;image&quot;], example[&quot;label&quot;]
  print(label)

</code></pre>
<p>Outputs:</p>
<pre><code>tf.Tensor([7 3 5 6 3 1 7 9 6 1 9 3 9 8 6 7 7 1 9 7 5 2 0 7 8 1 7 8 7 0 5 0], shape=(32,), dtype=int64)
tf.Tensor([1 3 6 1 8 8 0 4 1 3 2 9 5 3 8 7 4 2 1 8 1 0 8 5 4 5 6 7 3 4 4 1], shape=(32,), dtype=int64)
</code></pre>
<p>Shouldn't the labels be the same, given that the dataset is the same?</p>
",1,Documentation Replicability
470,66879748,What is the difference between tf.keras.model and tf.keras.sequential?,"<p>In some <code>tf. keras</code> tutorials, I've seen them instantiated their model class like this:</p>
<p><code>model = tf.keras.Sequential()</code></p>
<p>While in some places, they use something like this:</p>
<p><code>model = tf.keras.Model(inputs=input, outputs=output)</code></p>
<p>But seeing here in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""noreferrer"">docs</a>, they do seem the same, but I am not sure nor is it explicitly mentioned. What are the differences between the two?</p>
",1,Documentation Ambiguity
471,67066760,Configuring labels in TensorFlow BinaryCrossentropy loss function,"<p>I want to compute cross-entropy loss using <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy"" rel=""nofollow noreferrer"">tf.keras.losses.BinaryCrossentropy</a>. The documentation has the following example, and specifies that true labels and predicted labels should have the shape <code>[batch_size]</code>:</p>
<pre><code>y_true = [[0., 1.], [0., 0.]]
y_pred = [[0.6, 0.4], [0.4, 0.6]]

bce = tf.keras.losses.BinaryCrossentropy()
bce(y_true, y_pred).numpy()
</code></pre>
<p>From the example, it is inferred that each sample's label should be formatted as [probability of belonging to Class 0, probability of belonging to Class 1]. Is it correct? If it is, why <code>y_true[1]</code> probabilities do not add up to 1?</p>
",1,Documentation Ambiguity
472,67197448,How to extract multiple rows from tensor at the same time?,"<p>TL;DR:
TensorFlow tensor is of shape <code>(50, 50, 6)</code>, want these indices (:, :, (0, 2, 3)). How to extract them?</p>
<p>Here is an example array I am working with:</p>
<pre><code>import numpy as np

a = np.random.randint(0,10, (50, 50, 6))
</code></pre>
<p>I want to extract the the first, third, and fourth row; in other words I need all these entries <code>(:, :, (1, 3))</code>, which works for numpy arrays:</p>
<pre><code>out = a[:,:, [0, 2, 3]]
out.shape #(50, 50, 3)

</code></pre>
<p>Working with a tensor <code>t = tf.convert_to_tensor(a)</code> and then calling the index like</p>
<pre><code>t[:,:, [0, 2, 3]]
</code></pre>
<p>throws an error:</p>
<pre><code>TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got [0, 1, 3]
</code></pre>
<p>For numpy I have found the following relevant questions, but they naturally focus on numpy arrays:</p>
<p><a href=""https://stackoverflow.com/questions/46227095/how-to-slice-a-2d-array-non-consecutively-in-python?noredirect=1&amp;lq=1"">How to slice a 2D array non-consecutively in Python</a></p>
<p><a href=""https://stackoverflow.com/questions/24398708/slicing-a-numpy-array-along-a-dynamically-specified-axis"">Slicing a numpy array along a dynamically specified axis</a></p>
<p>Looking at the TF documentation I found <code>gather_nd</code> and <code>boolean_mask</code>, which I feel are helpful, but I must freely admit that I have not understood the docs at this part. On SO I found this question <a href=""https://stackoverflow.com/questions/58052967/how-to-select-elements-of-a-tensor-along-a-specific-axis-in-tensorflow"">How to select elements of a tensor along a specific axis in TensorFlow</a>, which focuses on single elements; I am looking for complete dimensions (if that's the right wording here).</p>
<p>How can I do the numpy thing in TensorFlow?</p>
",1,Documentation Replication on Other Examples
473,67211152,Tensorlow - please decipher what the tf.where document says,"<p>Please decipher what the <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer"">tf.where</a> documentation says about what it does when both x and y are provided.</p>
<p>I suppose it tries to say it will produce a result by:</p>
<ol>
<li>Broadcast y to the result shape.</li>
<li>Broadcast x to the result shape.</li>
<li>Update y with x elements where the condition is true.</li>
</ol>
<p>Is this correct?</p>
<blockquote>
<p>If x and y are provided (both have non-None values):
tf.where will choose an output shape from the shapes of condition, x, and y that all three shapes are broadcastable to.</p>
<p><strong>Returns</strong>
If x and y are provided: A Tensor with the same type as x and y, and shape that is broadcast from condition, x, and y. Otherwise, a Tensor with shape (num_true, dim_size(condition)).</p>
</blockquote>
",1,Documentation Replicability
474,67361081,Tensorflow 2 - what is 'index depth' in tensor_scatter_nd_update?,"<p>Please explain what is index depth of <a href=""https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update"" rel=""nofollow noreferrer"">tf.tensor_scatter_nd_update</a>.</p>
<pre><code>tf.tensor_scatter_nd_update(
    tensor, indices, updates, name=None
)
</code></pre>
<p>Why indices is 2D for 1D tensor?</p>
<blockquote>
<p>indices has at least two axes, the last axis is the depth of the index vectors.
For a higher rank input tensor scalar updates can be inserted by using an index_depth that matches tf.rank(tensor):</p>
</blockquote>
<pre><code>tensor = [0, 0, 0, 0, 0, 0, 0, 0]    # tf.rank(tensor) == 1
indices = [[1], [3], [4], [7]]       # num_updates == 4, index_depth == 1   # &lt;--- what is depth and why 2D for 1D tensor?
updates = [9, 10, 11, 12]            # num_updates == 4
print(tf.tensor_scatter_nd_update(tensor, indices, updates))
</code></pre>
<p><a href=""https://i.stack.imgur.com/eNdogl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eNdogl.png"" alt=""enter image description here"" /></a></p>
<pre><code>tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2
indices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2
updates = [5, 10]                    # num_updates == 2
print(tf.tensor_scatter_nd_update(tensor, indices, updates))
</code></pre>
",1,Documentation Replicability
475,67523944,"Tensorflow2 - Use ""tf.data.experimental.make_csv_dataset"" with ""tf.keras.preprocessing.timeseries_dataset_from_array""","<p>I am trying to get TensorFlow to read +100 CSV files that <em><strong>don't</strong></em> fit in memory (+1GB size each). The files contain time series data (EEG signals), with the labels in the first column. From the TensorFlow documentation it seems like I should be able to use the <em>tf.data</em> API to load my data off-disk.</p>
<p>For the sake of simplicity and reproducibility, let's consider the following &quot;<em>sample_data.csv</em>&quot; dataset:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Label</th>
<th>Feature 1</th>
<th>Feature 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Apple</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>Banana</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>Coconut</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>Durian</td>
<td>7</td>
<td>8</td>
</tr>
</tbody>
</table>
</div>
<p>I've tried using <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset"" rel=""nofollow noreferrer"">tf.data.experimental.make_csv_dataset</a> to load the CSV files into <em>tf.data.Dataset</em> objects, and then <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array"" rel=""nofollow noreferrer"">tf.keras.preprocessing.timeseries_dataset_from_array</a> to process the data into sliding windows with overlap. For the dataset above, I would do:</p>
<pre><code>import tensorflow as tf

input_data = tf.data.experimental.make_csv_dataset(
    'sample_data.csv',
    batch_size=1,
    column_names=['Label', 'Feature 1', 'Feature 2']
    label_name='Label',
    num_epochs=1,
    shuffle=False
)
</code></pre>
<p>Which we can check works correctly by looking at the output from <code>list(input_data.as_numpy_iterator())</code>. We can then feed <code>input_data</code> to the next function:</p>
<pre><code>my_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(
    input_data,
    targets=None,
    sequence_length=3,
    sequence_stride=2,
    sampling_rate=1,  
    batch_size=1,
    shuffle=False
)
</code></pre>
<p>Which unfortunately <strong>throws this error</strong>:</p>
<blockquote>
<p>TypeError: dataset length is unknown.</p>
</blockquote>
<p>I also tried using <code>my_dataset = input_data.window(3, shift=2)</code> (see the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window"" rel=""nofollow noreferrer"">tf.data.Dataset.window</a> documentation) and it didn't throw an error, but
it seems to be returning an <strong>empty dataset</strong>? See &quot;<em>_VariantDataset shapes: (None,)</em>&quot; in the output:</p>
<pre><code>list(input_data.window(3, shift=2))

[344]:
[(OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;),
 (OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;),
 (OrderedDict([('Feature 1',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;),
               ('Feature 2',
                &lt;_VariantDataset shapes: (None,), types: tf.int32&gt;)]),
  &lt;_VariantDataset shapes: (None,), types: tf.string&gt;)]
</code></pre>
<p>If I load the &quot;<em>sample_data.csv</em>&quot; in memory using pandas and then feed the <em>timeseries_dataset_from_array</em> function a numpy array instead, it works correctly.</p>
<p>Any ideas on how to solve this? <strong>What's the best method to input overlapping windows from off-memory time-series data into TensorFlow</strong>?</p>
<p>Thank you!</p>
",1,Documentation Replication on Other Examples
476,67563475,How to convert a tensorflow model and load as tfds,"<p>I need help converting my dataset from how I usually make it using
<code>tf.keras.preprocessing.image_dataset_from_directory</code>
To be used to replace this in an example</p>
<pre><code>dataset, info = tfds.load(name='mnist', split=split, with_info=True,

as_supervised=True, try_gcs=True)
</code></pre>
<p>How can I do so? I am unable to find related documentation so if you can link that it would be amazing.
Thanks</p>
<p>This is how the dataset is used in the example</p>
<pre><code>  split = 'train' if is_training else 'test'
  dataset, info = tfds.load(name='mnist', split=split, with_info=True,
                            as_supervised=True, try_gcs=True)


  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255.0

    return image, label

  dataset = dataset.map(scale)
</code></pre>
",1,Documentation Ambiguity
477,67698111,Show version of tensorflow 2.4.1 in python 3.7,"<p>Using python 3.7, how do you print the version of tensorflow if you have tensorflow 2.4.1. None of the documented styles: 'tf. __ version__', tf.version, nor tf.version.VERSION seem to work.</p>
",1,Documentation Ambiguity
478,67723809,Memory leak when using tf.data Datasets with shuffle,"<p>I have a memory leak somehow when I create my tf.data.dataset pipeline, but I don't know where.
My code works fine with ImageDataGenerator but is really slow.
Reading a lot of documentation I thought it might be albumentations.</p>
<p>However I now switched my transform to be entirely in tensorflow:</p>
<pre><code>def map_data(inputs, outputs):
image = inputs['image_input']
image = parse_image(image)
image = tf.cast(image, tf.float32) / 255.0
image = tf.image.resize(image, size = [224, 224])
image = tf.image.random_flip_left_right(image)
image = tf.image.random_flip_up_down(image)
image = tf.image.random_brightness(image, max_delta = 0.5)
#image = tf.expand_dims(image, axis=3)
other = parse_image(inputs['other_input'])
other = tf.cast(other, tf.float32) / 255.0
other = tf.image.resize(other, size = [224, 224])
other = tf.image.random_flip_left_right(other)
other = tf.image.random_flip_up_down(other)
other = tf.image.random_brightness(other, max_delta = 0.5)


return {'image_input': image, 'other_input': other}, outputs
</code></pre>
<p>And I made the shuffle buffer extremely small:</p>
<pre><code>        #dataset = dataset.prefetch(tf.data.AUTOTUNE)
    AUTOTUNE = tf.data.AUTOTUNE
    dataset = (dataset
        .shuffle(32)
        .map(map_data, num_parallel_calls=AUTOTUNE)
        .cache()
        .batch(32)
        .prefetch(AUTOTUNE)
    )
</code></pre>
<p>Could autotune cause this?
On Colab I usually hit the RAM restart at 500 batches</p>
<p>I would like to use tf.data.datasets because it's really much faster if possible.</p>
<p>Thank you for anyone who can point me to the flaw in my code, I have always used generators and only recently made the switch.</p>
",1,Documentation Replication on Other Examples
479,67747314,Finding precision and recall for the tutorial federated learning model on MNIST,"<p>I'm using this tutorial to try to learn how federated models work through TensorFlow's tutorial here: <a href=""https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb</a></p>
<p>Currently, the model is defined like this which uses accuracy as its metric.</p>
<pre><code>def model_fn():
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec = preprocessed_example_dataset.element_spec,
      loss = tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy()]
  )
</code></pre>
<p>I want to either use precision and recall as metrics, or find them after the model is trained, but I can't figure out how to do so.</p>
<p>I tried adding precision to metrics like this <code>metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(), tf.keras.metrics.Precision()]</code> and run this code but it gives me an error.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01),
    server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.5))
</code></pre>
<p>Error output:</p>
<pre><code>ValueError                                Traceback (most recent call last)

&lt;ipython-input-13-f8ac3534e325&gt; in &lt;module&gt;()
      2     model_fn,
      3     client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01),
----&gt; 4     server_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=1.5))

ValueError: Shapes (None, 10) and (None, 1) are incompatible
</code></pre>
<p>Previously, I asked a similar question for a regular <a href=""https://stackoverflow.com/questions/67729973/finding-precision-and-recall-for-mnist-dataset-using-tensorflow/67730576#67730576"">centralized model here</a>, but I don't think I can use that same method since you can't get the results of the predictions back in the same way from what I've found.
I've also tried looking at other documentation <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression#training_the_model_and_outputting_training_metrics"" rel=""nofollow noreferrer"">such as this</a>, but it also uses accuracy as the metric, so that wasn't helpful. How can I get the precision and recall of this federated model?</p>
",1,Lack of Alternative Solutions/Documentation
480,67759756,"How do I use ""text_dataset_from_directory"" to do binary text classification from tf.dataset object?","<p>Sorry, I am still relatively new to text classification and Tensorflow, so this may look like a very dumb question.</p>
<p>I have the song lyrics of two different singers. What I am trying to achieve is to build a binary text classification model to predict whether a song fits to the style of singer A or singer B more.
I have the training data (the lyrics text files) of both classes in sub-directories. The directory structure is similar to,</p>
<pre><code>Classification/
...Singer_A/
......A_song_1.txt
......A_song_2.txt
...Singer_B/
......B_song_1.txt
......B_song_2.txt
</code></pre>
<p>And from what I read on the Tensorflow documentation, I could easily construct a dataset by using the
<code>text_dataset_from_directory</code> method. So something like,</p>
<pre><code>dataset = text_dataset_from_directory(
    'Classification', labels='inferred', label_mode='int',
    batch_size=32
)
</code></pre>
<p>However, I don't know how I could go on from there. I would suppose that the created <code>tf.data.Dataset</code> object would still need Tokenization in the texts component, and the tokenized text would then need padding and embedding before feeding it into a logistic model. But I don't know how to further process it in the <code>tf.data.Dataset</code> object.</p>
<p>I saw <a href=""https://www.tensorflow.org/text/guide/word_embeddings"" rel=""nofollow noreferrer"">Tensorflow's Text Embedding Tutorial</a>, but don't really see how it could be changed to become a binary model.</p>
",1,Documentation Replicability
481,67760450,How to achieve Tensorflow Python model() (__call__) performance in C(++) API for small inputs?,"<p><strong>The problem</strong></p>
<p>I have a (very) small and fast model saved in the SavedModel format which I can load and run with the following code:</p>
<pre><code>model = tf.keras.models.load_model(&quot;./&lt;SavedModelDir&gt;&quot;)
outputs = model(inputs, training=False)
</code></pre>
<p>The predict function runs in 0.05 seconds with a batch of 5 inputs (on a Nvidia GPU).
If however I use <code>model.predict_on_batch(inputs)</code> or <code>model.predict(inputs)</code> the performance drops significantly to 0.65 - 0.80 seconds for a batch of 5. This is consistent with the documentation that states that using <code>model() (__call__)</code> is usually faster for smaller inputs.</p>
<p>The problem I am having is the fact that I am trying to port my model to a C(++) program. And using <code>TF_SessionRun()</code> for the C api and <code>model_bundle.GetSession()-&gt;Run()</code> I am getting performance similar to &quot;slow&quot; Python inference methods.</p>
<p><strong>What I have tried</strong></p>
<p>Another (very) small model with small batch, same result.</p>
<p>I tried disabling optimizations with <code>tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': False})</code> to make sure this does not negatively impact performance but this made things even slower.</p>
<p>I also tried converting the SavedModel to a TensorRT SavedModel. This increases the performance of the <code>model() (__call__)</code> method even further but all the other methods stop working in Python and in the downloaded precompiled Tensorflow C GPU api (2.5.0) and the C++ API compiled with Tensorflow_CC I get an error about the operation not being found (TensorRT does not seem to work).</p>
<p>All the performance numbers given were run after a few warmup runs.
Performance measured both with Tensorflow profiler and Python's time.time</p>
<p>I checked if <code>model() (__call__)</code> is working correctly by checking the output and it is.</p>
<p><strong>My question(s)</strong></p>
<p>Is there a way to get <code>model() (__call__)</code> performance with the Tensorflow C(++) API?</p>
<p>The problem seems to be somewhere in Tensorflows optimization for larger batch sizes which decreases the performance of smaller batch sizes. Is there another API that allows faster inference on small batches out of the box (TensorRT C++ API?)?</p>
",1,Documentation Replication on Other Examples
482,67940962,How to convert this tensor flow code into pytorch code?,"<p>I am trying to implement an Image Denoising Gan which is written in tensorflow to pytorch and I am unable to understand what is <code>tf.variable_scope</code> and <code>tf.Variable</code> similar in pytorch. please help.</p>
<pre><code>def conv_layer(input_image, ksize, in_channels, out_channels, stride, scope_name, activation_function=lrelu, reuse=False):
    with tf.variable_scope(scope_name):
        filter = tf.Variable(tf.random_normal([ksize, ksize, in_channels, out_channels], stddev=0.03))
        output = tf.nn.conv2d(input_image, filter, strides=[1, stride, stride, 1], padding='SAME')
        output = slim.batch_norm(output)
        if activation_function:
            output = activation_function(output)
        return output, filter
</code></pre>
<pre><code>def residual_layer(input_image, ksize, in_channels, out_channels, stride, scope_name):
    with tf.variable_scope(scope_name):
        output, filter = conv_layer(input_image, ksize, in_channels, out_channels, stride, scope_name+&quot;_conv1&quot;)
        output, filter = conv_layer(output, ksize, out_channels, out_channels, stride, scope_name+&quot;_conv2&quot;)
        output = tf.add(output, tf.identity(input_image))
        return output, filter

def transpose_deconvolution_layer(input_tensor, used_weights, new_shape, stride, scope_name):
    with tf.varaible_scope(scope_name):
        output = tf.nn.conv2d_transpose(input_tensor, used_weights, output_shape=new_shape, strides=[1, stride, stride, 1], padding='SAME')
        output = tf.nn.relu(output)
        return output

def resize_deconvolution_layer(input_tensor, new_shape, scope_name):
    with tf.variable_scope(scope_name):
        output = tf.image.resize_images(input_tensor, (new_shape[1], new_shape[2]), method=1)
        output, unused_weights = conv_layer(output, 3, new_shape[3]*2, new_shape[3], 1, scope_name+&quot;_deconv&quot;)
        return output

</code></pre>
",1,Documentation Replicability
483,67947583,"Defining a callable ""loss"" function","<p>I am trying to optimize a loss function (defined using evidence lower bound) with <code>tf.train.AdamOptimizer.minimize()</code> on Tensorflow version <code>1.15.2</code> with eager execution enabled. I tried the following:</p>
<pre><code>learning_rate = 0.01
optim = tf.train.AdamOptimizer(learning_rate=learning_rate)
train_op = optim.minimize(loss)
</code></pre>
<p>and got the following : <code>RuntimeError: &quot;loss&quot; passed to Optimizer.compute_gradients should be a function when eager execution is enabled.</code></p>
<p>This works fine if I disable eager execution but since I need to save a tensorflow variable as a <code>numpy</code> array so I need eager execution enabled. The documentation mentions that when eager execution is enabled, the loss must be a <strong>callable</strong>. So the loss function should be defined in a way that it takes no inputs but gives out loss. I am not exactly sure how do I achieve such a thing.</p>
<p>I tried <code>train_op = optim.minimize(lambda: loss)</code> but got <code>ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [] and loss &lt;function &lt;lambda&gt; at 0x7f3c67a93b00&gt;</code></p>
",1,Documentation Replication on Other Examples
484,68354367,Getting an error when using tf.keras.metrics.Mean in functional Keras API,"<p>I'm trying to add a Mean metric to a Keras functional model (Tensorflow 2.5), and am getting the following error:</p>
<pre><code>ValueError: Expected a symbolic Tensor for the metric value, received: tf.Tensor(0.0, shape=(), dtype=float32)
</code></pre>
<p>Here is the code:</p>
<pre><code>x = [1, 2, 3, 4, 5, 6, 7, 8]
y = [5 + i * 3 for i in x]
a = Input(shape=(1,))
output = Dense(1)(a)
model = Model(inputs=a,outputs=output)
model.add_metric(tf.keras.metrics.Mean()(output))
model.compile(loss='mse')
model.fit(x=x, y=y, epochs=100)
</code></pre>
<p>If I remove the following line (from which the exception is thrown):</p>
<pre><code>model.add_metric(tf.keras.metrics.Mean()(output))
</code></pre>
<p>the code works as expected.
<br><br>I Tried disabling eager execution, but I get the following error instead:</p>
<pre><code>ValueError: Using the result of calling a `Metric` object when calling `add_metric` on a Functional Model is not supported. Please pass the Tensor to monitor directly.
</code></pre>
<p>The above usage was pretty much copied from the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Mean"" rel=""nofollow noreferrer"">tf.keras.metrics.Mean</a> documentation (see <em>Usage with compile() API</em>)</p>
",1,Lack of Alternative Solutions/Documentation
485,68367159,Adding inputs to a `tf.data.generator` in tensorflow.js,"<p>I'm trying to create a data generator, which I verified was working by itself in pure js. TFJS documentation for it is here, with two examples:
<a href=""https://js.tensorflow.org/api/latest/#data.generator"" rel=""nofollow noreferrer"">https://js.tensorflow.org/api/latest/#data.generator</a></p>
<p>I'd like to use a <code>tf.data.generator</code> as this datasets requires elaborate preprocessing. A minimal example is as follows:</p>
<pre class=""lang-js prettyprint-override""><code>const tf = require('@tensorflow/tfjs-node');
class dataGeneratorGenerator {
    constructor(test) {
        this.test = test
    }
    * dataGenerator() {
        let len = this.test.length
        let idx = 0
        while (idx &lt; len) {
            idx++
            console.log(idx)
            yield this.test[idx]
        }
    }
}
let dgg = new dataGeneratorGenerator(['hi', 'hi2', 'hi3'])
let trainDs = tf.data.generator(dgg.dataGenerator);
trainDs.forEachAsync(e =&gt; console.log(e));
</code></pre>
<p>The error is as follows:</p>
<pre><code>TypeError: Error thrown while iterating through a dataset: Cannot read property 'test' of undefined
</code></pre>
<p>Iterating through our datagenerator in pure javascript works:</p>
<pre class=""lang-js prettyprint-override""><code>let dgg = new dataGeneratorGenerator(['hi', 'hi2', 'hi3'])
let dg = dgg.dataGenerator()
console.log(dgg.next())
console.log(dgg.next())
console.log(dgg.next())
</code></pre>
<p>My understanding is that we are only passing <code>dataGenerator</code> into <code>tf.data.generator</code> instead of the entire class. Then, how is it possible to input variables into <code>tf.data.generator</code>? Thanks.</p>
",1,Documentation Ambiguity
486,68431633,tf.image.stateless_random_crop VS. tf.image.random_crop. Shouldn't these be the same thing?,"<p>In tf 2.5, there are two functions for cropping an image: <code>tf.image.stateless_random_crop</code>, and <code>tf.image.random_crop</code>. The documentation states that <code>stateless_random_crop</code> is deterministic (always returns the same crop given one seed). However, <code>random_crop</code> has a seed parameter and is also deterministic, one would think. What is the actual difference between these two functions? I cannot find information about statelessness in Tensorflow anywhere.</p>
<p>The differences between <code>tf.image.stateless_random_crop</code>, and <code>tf.image.random_crop</code> are one line where stateless_random_uniform is used instead of a random_uniform:
stateless_random_crop: <a href=""https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L415-L465"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L415-L465</a>
random_crop: <a href=""https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L360-L412"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/ops/random_ops.py#L360-L412</a></p>
<p>I always thought that <code>random_crop</code> would always return the same crop given a seed, but it looks like maybe that wasn't always true? Any enlightenment about statelessness in Tensorflow is greatly appreciated!</p>
",1,Documentation Ambiguity
487,68878231,tf.gradients() vs tf.gradientTape.gradient() in graph mode,"<p>I had a question regarding the behavior of tf.gradients() as opposed tf.gradientTape.gradient() in graph mode.</p>
<p>Given a differentiable function y = f(x), where x and y are each single tensorflow tensors, is there any difference between the behavior of tf.gradient(y, x) vs tape.gradient(y, x) where tape is an instance of tf.gradientTape (assuming the use of graph mode) ?</p>
<p>Not sure why tensorflow has two different gradient methods which can be used with graph mode - maybe there are some subtle differences in the implementations? I’ve looked at the documentation for gradientTape and tf.gradients but it’s not clear whether there is any difference between the behavior of these methods for a single (x, y) pair, or whether it’s just that tf.gradients() can be used in this case for a speedup when using graph mode.</p>
<p>Thank you so much for your help!</p>
",1,Documentation Replication on Other Examples
488,68984841,How can I understand the kernel of tf.keras.layers.Dense for rank >2?,"<p>How can I understand the kernel of <code>tf.keras.layers.Dense</code> for rank &gt;2?</p>
<p>The official API doc states that:</p>
<blockquote>
<p>Note: If the input to the layer has a rank greater than 2, then Dense
computes the dot product between the inputs and the kernel along the
last axis of the inputs and axis 0 of the kernel (using tf.tensordot).
For example, if input has dimensions (batch_size, d0, d1), then we
create a kernel with shape (d1, units), and the kernel operates along
axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there
are batch_size * d0 such sub-tensors). The output in this case will
have shape (batch_size, d0, units).</p>
</blockquote>
<p>My understanding is that for a rank larger than 2 (for example rank 3) only <strong>one</strong> kernel is created and thus the same kernel is applied on all slices of the second dimension, like above.
That would consequently mean that the outputs for different indices of the second dimension are <strong>not independent</strong> of each other (especially during training).</p>
<p>Is my understanding correct? And if yes, is there a simple way to use a stack of kernels instead or do I have to implement the tensor multiplication?</p>
",1,Documentation Replicability
489,69458522,What does tf.squeeze does to the audio and how can I load an mp3?,"<p>I'm using TensorFlow and I would like to be able to load audio and generate a spectrogram from it. I have little knowledge of how audio internally works.
Currently, this is the code I'm using:</p>
<pre><code>import pathlib
import tensorflow as tf
import tensorflow_io as tfio
import matplotlib.pyplot as plt

from IPython.display import Audio

data_dir = pathlib.Path('recordings')
sample_file = data_dir/'testA.mp3'
audio = tfio.audio.AudioIOTensor(str(sample_file))

# remove last dimension
audio_slice = audio[100:]
audio_tensor = tf.squeeze(audio_slice, axis=[-1])
#audio_tensor = audio.to_tensor()
tensor = tf.cast(audio_tensor, tf.float32) / 32768.0

print(&quot;Audio Tensor: &quot; + str(tensor))

plt.figure()
plt.plot(tensor.numpy())
plt.show()

# Convert to spectrogram
spectrogram = tfio.audio.spectrogram(tensor, nfft=512, window=512, stride=256)
    
plt.figure()
plt.imshow(tf.math.log(spectrogram).numpy())
plt.show()
</code></pre>
<p>I have been reading the documentation and in order to create a tensor I need to either use the tf.squeeze method or audio.to_tensor(). I have no clue what the tf.squeeze method does, but when I use it I get the error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 2 [Op:Squeeze]
</code></pre>
<p>If I instead use the method audio.to_tensor(), I'm unable to display the created spectrogram on the plt and instead I get the following error:</p>
<pre><code>TypeError: Invalid shape (28224, 1, 257) for image data
</code></pre>
",1,Documentation Replication on Other Examples
490,69509388,TF BERT input packer on more than two inputs,"<p>Some of the TensorFlow examples using BERT models show a use of the BERT preprocessor to &quot;pack&quot; inputs. E.g. in <a href=""https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/bert_glue.ipynb"" rel=""nofollow noreferrer"">this example</a>,</p>
<p><code>text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok], tf.constant(20))</code></p>
<p>The documentation implies that this works equally well with more than two input sentences, such that (I would expect) one can do something like:</p>
<p><code>text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok, tok], tf.constant(20))</code></p>
<p>However, so doing causes the error at the bottom[1] of this post.</p>
<p>I get that there isn't a matching signature; if I read this correctly (and I may not!), there's a signature for a single input and one for two. But what's the recommended way to pack more than two sentences into input suitable for a classification task, as suggested in the above colab?</p>
<p>1.</p>
<pre><code>ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (2 total):
    * [tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(&quot;inputs:0&quot;, shape=(None,), dtype=int32), row_splits=Tensor(&quot;inputs_2:0&quot;, shape=(None,), dtype=int64)), row_splits=Tensor(&quot;inputs_1:0&quot;, shape=(2,), dtype=int64)), tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(&quot;inputs_3:0&quot;, shape=(None,), dtype=int32), row_splits=Tensor(&quot;inputs_5:0&quot;, shape=(None,), dtype=int64)), row_splits=Tensor(&quot;inputs_4:0&quot;, shape=(2,), dtype=int64)), tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(&quot;inputs_6:0&quot;, shape=(None,), dtype=int32), row_splits=Tensor(&quot;inputs_8:0&quot;, shape=(None,), dtype=int64)), row_splits=Tensor(&quot;inputs_7:0&quot;, shape=(2,), dtype=int64))]
    * Tensor(&quot;seq_length:0&quot;, shape=(), dtype=int32)
  Keyword arguments: {}

Expected these arguments to match one of the following 4 option(s):

Option 1:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}

Option 2:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}

Option 3:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64), RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}

Option 4:
  Positional arguments (2 total):
    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]
    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')
  Keyword arguments: {}```
</code></pre>
",1,Inadequate Examples
491,69672777,Compute Hessian of lossfunction in Tensorflow,"<p>I would like to compute the hessian of a loss function of a neural network in Tensorflow with respect to all the parameters (or trainable variables). By modifying the example code from the Tensorflow documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/GradientTape</a>) I managed to compute the hessian w.r.t the weight matrix for the first layer (if I'm not mistaken):</p>
<pre><code>with tf.GradientTape(persistent=True) as tape:
    loss = tf.reduce_mean(model(x,training=True)**2)
    g = tape.gradient(loss,model.trainable_variables[0]) 
    h=tape.jacobian(g,model.trainable_variables[0])
</code></pre>
<p>If I try to compute it w.r.t model.trainable_variables instead the tape.jacobian complains that 'list object has no attribute shape'. I instead tried to flatten the model.trainable_variables and compute it w.r.t the flattened vector:</p>
<pre><code>with tf.GradientTape(persistent=True) as tape:
    loss = tf.reduce_mean(model(x,training=True)**2)
    source = tf.concat([tf.reshape(x,[-1]) for x in model.trainable_variables],axis=0)
    g = tape.gradient(loss,source) 
    h=tape.jacobian(g,source)
   
</code></pre>
<p>The problem now is that g is empty (NoneType) for some reason. I noticed that source is tf.Tensor-type but model.trainable_variables[0] was of type tf.ResourceVariable so I tried changing this by declaring source as</p>
<pre><code>source = resource_variable_ops.ResourceVariable(tf.concat([tf.reshape(x,[-1]) for x in model.trainable_variables],axis=0))
</code></pre>
<p>This didn't change anything though, so I'm guessing that this is not the issue. I also thought that the problem might be that the source-variable is not watched, but it seems that it is set to trainable and even if i do tape.watch(source), g is still empty.</p>
<p>Does anybody know how I can solve this?</p>
",1,Documentation Replication on Other Examples
492,69792031,Explanation of tf.keras.layers.CategoryEncoding output_mode='multi_hot' behavior,"<h1>Question</h1>
<p>Please help understand the definition of <strong>multi hot encoding</strong> of tf.keras.layers.CategoryEncoding and the behavior of <code>output_mode='multi_hot'</code>.</p>
<h1>Background</h1>
<p>According to <a href=""https://stats.stackexchange.com/a/467672"">What exactly is multi-hot encoding and how is it different from one-hot?</a>:</p>
<blockquote>
<p>If you would use multi-hot-encoding you would first label-encode your classes, thus having only a single number which represents the presence of a class (e.g. 1 for 'dog') and then convert the numerical labels to binary vectors of size log2(5)=3.<br />
Examples:</p>
<pre><code>'cat'  = [0,0,0]  
'dog'  = [0,0,1]  
'fish' = [0,1,0]  
'bird' = [0,1,1]  
'ant'  = [1,0,0]   
</code></pre>
</blockquote>
<h1>Behaviour of <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding"" rel=""nofollow noreferrer"">tf.keras.layers.CategoryEncoding</a></h1>
<p>The document says <code>num_tokens</code> is the total number of tokens the layer should support.</p>
<blockquote>
<h3>args</h3>
<h4>num_tokens</h4>
<p>The total number of tokens the layer should support. All inputs to the layer must integers in the range 0 &lt;= value &lt; num_tokens, or an error will be thrown.</p>
<h4>output_mode</h4>
<ul>
<li>&quot;one_hot&quot;: Encodes each individual element in the input into an array of num_tokens size, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output.</li>
<li>&quot;multi_hot&quot;: Encodes each sample in the input into <strong>a single array of num_tokens size, containing a 1 for each vocabulary term present in the sample</strong>. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens).</li>
</ul>
</blockquote>
<p>According to the definitions of multi hot encoding above, I expected <code>tf.keras.layers.CategoryEncoding(num_tokens=5, output_mode=&quot;multi_hot&quot;)</code> encodes 5 tokens into an array of size 3.</p>
<p>However, the document says &quot;multi_hot&quot; encodes each sample into <strong>a single array of num_tokens size</strong>, containing a 1 for each vocabulary term present in the sample, and behaves as such.</p>
<pre><code>dataset = tf.data.Dataset.from_tensor_slices(tf.constant(['cat', 'dog', 'fish', 'bird']))

lookup = tf.keras.layers.StringLookup(max_tokens=5, oov_token='[UNK]')
lookup.adapt(dataset)
lookup.get_vocabulary()
---
['[UNK]', 'fish', 'dog', 'cat', 'bird']

mhe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=&quot;multi_hot&quot;)
print(f&quot;cat: {mhe(lookup(tf.constant('cat'))).numpy()}&quot;)
print(f&quot;dog: {mhe(lookup(tf.constant('dog'))).numpy()}&quot;)
---
cat: [0. 0. 0. 1. 0.]
dog: [0. 0. 1. 0. 0.]
</code></pre>
<p>Which has no difference from One Hot Encoding.</p>
<pre><code>ohe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=&quot;one_hot&quot;)
print(f&quot;cat: {ohe(lookup(tf.constant('cat'))).numpy()}&quot;)
print(f&quot;dog: {ohe(lookup(tf.constant('dog'))).numpy()}&quot;)
---
cat: [0. 0. 0. 1. 0.]
dog: [0. 0. 1. 0. 0.]
</code></pre>
<p>For multi value inputs, multi_hot only handles the first value.</p>
<pre><code>print(ohe(lookup(tf.constant(['cat', 'dog']))).numpy())
---
[[0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0.]]

print(mhe(lookup(tf.constant(['cat', 'dog']))).numpy())
---
[0. 0. 1. 1. 0.]
</code></pre>
<p>To handle multiple inputs, need to be 2D array.</p>
<pre><code>print(mhe(lookup(tf.constant([['cat'], ['dog']]))).numpy())
---
[[0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0.]]
</code></pre>
<p>Apparently the definition of <strong>multi hot encoding</strong> of <code>tf.keras.layers.CategoryEncoding</code> is not the same with the one in <a href=""https://stats.stackexchange.com/a/467672"">What exactly is multi-hot encoding and how is it different from one-hot?</a>.</p>
<h1>Related</h1>
<ul>
<li><a href=""https://github.com/tensorflow/tensorflow/issues/52892"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/52892</a></li>
</ul>
",1,Lack of Alternative Solutions/Documentation
493,69843239,How does tf.keras.util.array_to_image() work with regards to memory?,"<p>I have image data that I want to use in a TensorFlow model, but I have to retrieve the image as an (Numpy) array of pixel values. From what I've read, TensorFlow has to read an image in as some image format and from some location. I know that <code>tf.keras.util.array_to_image()</code> can convert an array to a PIL instance of an image, and I know that there are several other libraries that have similar functionality, such as <code>PIL.Image.fromarray()</code>.</p>
<p>My problem is that I don't want to duplicate the image data by copying it to a new format. The API documentation for the <code>tf.keras.util.array_to_image()</code> says that it returns a &quot;PIL image instance&quot;. Does that mean that it is copying all array values to a new data structure and returning that, or is it creating an image data structure that references the original array pixel values?</p>
<p>As a follow-up question, if the keras method does duplicate the data (by having both the original array and the image instance have independent values), is there a way to have TensorFlow accept an array representation of an image without needing to duplicate it as a separate image file?</p>
",1,Documentation Replication on Other Examples
494,70363340,Question about tensorflow.tile with a tensor of 5 dimensions,"<p>I'm trying to understand the following thing from an implementation of a paper I'm currently reading:</p>
<p>In <code>tensorflow</code>, if I have a tensor <code>x</code> of shape <code>(4,64,5,5)</code></p>
<ul>
<li><p>Then I create a new dimension by doing</p>
<pre><code>x = x[:,:,tf.newaxis]
</code></pre>
<p>ending with a new tensor of <code>shape</code> <code>(4,64,1,5,5)</code></p>
</li>
<li><p>Then I do</p>
<pre><code>x = tf.tile(x, (1, 1, 5, 1, 1))
</code></pre>
</li>
</ul>
<p>ending up with something of shape <code>(4,64,5,5,5)</code></p>
<p>Reading the documentation for <code>tf.tile</code>, I still don't understand what is it exactly doing in this case. Am I replicating the new dimension for 5 times? And if yes, what is exactly placed in the new dimension by tensorflow? What am I exactly replicating?</p>
",1,Documentation Ambiguity
495,70747499,Using tf.map_fn when the function has multiple outputs,"<p>I can easily use tf.map_fn when the function has one output:</p>
<pre><code>import tensorflow as tf
tensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]])

def my_fun(x):
    return x[0]

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<p><strong>output:</strong></p>
<pre><code>tf.Tensor([1. 4.], shape=(2,), dtype=float32)
</code></pre>
<p>But, when the function has two outputs:</p>
<pre><code>def my_fun(x):
    return [x[0],x[1]]

print(tf.map_fn(my_fun,tensaki))
</code></pre>
<p>I get an error. Not sure what is going on. I read the information about tf.map_fn in here <a href=""https://www.tensorflow.org/api_docs/python/tf/map_fn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/map_fn</a>, but not sure how to fix this:</p>
<p>map_fn also supports functions with multi-arity inputs and outputs:</p>
<p><em>If elems is a tuple (or nested structure) of tensors, then those tensors must all have the same outer-dimension size (num_elems); and fn is used to transform each tuple (or structure) of corresponding slices from elems. E.g., if elems is a tuple (t1, t2, t3), then fn is used to transform each tuple of slices (t1[i], t2[i], t3[i]) (where 0 &lt;= i &lt; num_elems).
If fn returns a tuple (or nested structure) of tensors, then the result is formed by stacking corresponding elements from those structures.</em></p>
<p><strong>Output:</strong></p>
<pre><code>~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\util\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites)
    317     _pywrap_tensorflow.AssertSameStructure(nest1, nest2, check_types,
--&gt; 318                                            expand_composites)
    319   except (ValueError, TypeError) as e:

ValueError: The two structures don't have the same nested structure.

First structure: type=DType str=&lt;dtype: 'float32'&gt;

Second structure: type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]

More specifically: Substructure &quot;type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]&quot; is a sequence, while substructure &quot;type=DType str=&lt;dtype: 'float32'&gt;&quot; is not

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
&lt;ipython-input-36-5b11c7fef461&gt; in &lt;module&gt;
      5     return [x[0],x[1]]
      6 
----&gt; 7 print(tf.map_fn(my_fun,tensaki))

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)
    266         back_prop=back_prop,
    267         swap_memory=swap_memory,
--&gt; 268         maximum_iterations=n)
    269     results_flat = [r.stack() for r in r_a]
    270 

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)
   2712                                               list(loop_vars))
   2713       while cond(*loop_vars):
-&gt; 2714         loop_vars = body(*loop_vars)
   2715         if try_to_pack and not isinstance(loop_vars, (list, _basetuple)):
   2716           packed = True

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\control_flow_ops.py in &lt;lambda&gt;(i, lv)
   2703         cond = lambda i, lv: (  # pylint: disable=g-long-lambda
   2704             math_ops.logical_and(i &lt; maximum_iterations, orig_cond(*lv)))
-&gt; 2705         body = lambda i, lv: (i + 1, orig_body(*lv))
   2706       try_to_pack = False
   2707 

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\map_fn.py in compute(i, tas)
    256       packed_values = input_pack([elem_ta.read(i) for elem_ta in elems_ta])
    257       packed_fn_values = fn(packed_values)
--&gt; 258       nest.assert_same_structure(dtype or elems, packed_fn_values)
    259       flat_fn_values = output_flatten(packed_fn_values)
    260       tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]

~Users\user2\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\util\nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites)
    323                   &quot;Entire first structure:\n%s\n&quot;
    324                   &quot;Entire second structure:\n%s&quot;
--&gt; 325                   % (str(e), str1, str2))
    326 
    327 

ValueError: The two structures don't have the same nested structure.

First structure: type=DType str=&lt;dtype: 'float32'&gt;

Second structure: type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]

More specifically: Substructure &quot;type=list str=[&lt;tf.Tensor: id=203, shape=(), dtype=float32, numpy=1.0&gt;, &lt;tf.Tensor: id=207, shape=(), dtype=float32, numpy=2.0&gt;]&quot; is a sequence, while substructure &quot;type=DType str=&lt;dtype: 'float32'&gt;&quot; is not
Entire first structure:
.
Entire second structure:
[., .]```
</code></pre>
",1,Documentation Replication on Other Examples
496,70880589,what does cardinality mean in relation to an image dataset?,"<p>After successfully creating a tensorflow image <code>Dataset</code> with:</p>
<p><code>dataset = tf.keras.utils.image_dataset_from_directory(...)</code></p>
<p>which returns</p>
<p><em>Found 21397 files belonging to 5 classes.
Using 17118 files for training.</em></p>
<p>There is the cardinality method:</p>
<p><code>dataset.cardinality()</code></p>
<p>which returns a tensor containing the single value</p>
<p><em>tf.Tensor(535, shape=(), dtype=int64)</em></p>
<p>I've read the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/cardinality"" rel=""nofollow noreferrer"">docs here</a> but I don't understand what 535 represents or why its different to the number of files?</p>
<p>I ask, because I would like to understand how cardinality plays into this equation:</p>
<p><code>steps_per_epoch = dataset.cardinality().numpy() // batch_size</code></p>
",1,Lack of Alternative Solutions/Documentation
497,71019644,Equivalent tensorflow expression to numpy mask,"<p>I have a numpy array named PixelData of unknown shape, and I am using the following condition to filter values in the array greater than some value x using a mask:</p>
<pre><code>PixelData[PixelData&gt;=x] = PixelData[PixelData&gt;=x] - x
</code></pre>
<p>When I convert this numpy array to a tensor, I cannot perform the same masking operation. I have tried using tf.where as follows:</p>
<pre><code>PixelData = tf.where(PixelData&gt;=x, PixelData - x, PixelData)
</code></pre>
<p>In the official documentation, they always seem to define the mask dimensions in advance to equal the dimensions of the tensor being masked, but then they talk about the dimensions being broadcasted automatically, so I am a bit confused. Are these two functions equivalent? Are there any situations where they may produce different outputs?</p>
",1,Documentation Ambiguity
498,71090570,How do I create a tf.Tensor from a pandas DataFrame containing arrays?,"<p>I have a pandas DataFrame like below.</p>
<pre><code>import pandas as pd
import numpy as np
import tensorflow as tf  # Version 2.8.0
df = pd.DataFrame({&quot;id&quot;: 
                   [&quot;i123&quot;, &quot;i456&quot;],  
                   &quot;col&quot;: [np.array([&quot;igh&quot;, &quot;ghdd&quot;, &quot;yu&quot;]),
                           np.array([&quot;uh&quot;, &quot;lkk&quot;, &quot;nj&quot;])]})
print(df)
</code></pre>
<p>Output:</p>
<pre><code>    id      col
0   i123    [igh, ghdd, yu]
1   i456    [uh, lkk, nj]
</code></pre>
<p>I would to create a <code>Tensor</code> from the values of the <code>col</code> column, in order to use them in a specific use case. I have tried converting the values like</p>
<pre><code>values = df[&quot;col&quot;].to_numpy()
values
</code></pre>
<p>Which looks like:</p>
<pre><code>array([array(['igh', 'ghdd', 'yu'], dtype='&lt;U4'),
       array(['uh', 'lkk', 'nj'], dtype='&lt;U3')], dtype=object)
</code></pre>
<p>When I try to convert this to a Tensor, by</p>
<pre><code>tf.constant(values)
</code></pre>
<p>I get an exception:</p>
<pre><code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).
</code></pre>
<p>I can see from the <a href=""https://www.tensorflow.org/api_docs/python/tf/constant"" rel=""nofollow noreferrer"">documentation</a> that the tf.constant method should work on a very similar array
<a href=""https://i.stack.imgur.com/zscVM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zscVM.png"" alt=""TF docs"" /></a></p>
<p>The <code>values</code> variable I create have <code>.shape</code> like <code>(2,)</code> while the image below have <code>(2, 3)</code>, which might be the problem.
I can't seem to get the dtype and/or shape to match exactly, and I'm unsure how to get it to work. Any ideas?</p>
",1,Documentation Replicability
499,71129505,"Is it possible to split a tensorflow dataset into train, validation AND test datasets when using image_dataset_from_directory?","<p>I am using <code>tf.keras.utils.image_dataset_from_directory</code> to load a dataset of 4575 images. While this function allows to split the data into two subsets (with the <code>validation_split</code> parameter), I want to split it into training, testing, and validation subsets.</p>
<p>I have tried using <code>dataset.skip()</code> and <code>dataset.take()</code> to further split one of the resulting subsets, but these functions return a <code>SkipDataset</code> and a <code>TakeDataset</code> respectively (by the way, contrary to <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#take"" rel=""nofollow noreferrer"">the documentation</a>, where it is claimed that these functions return a <code>Dataset</code>). This leads to problems when fitting the model - the metrics calculated on validation sets (val_loss, val_accuracy) disappear from model history.</p>
<p>So, my question is: is there a way to split a <code>Dataset</code> into three subsets for training, validation and testing, so that all three subsets are also <code>Dataset</code> objects?</p>
<p><strong>Code used to load the data</strong></p>
<pre><code>def load_data_tf(data_path: str, img_shape=(256,256), batch_size: int=8):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.2,
        subset=&quot;training&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    val_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.3,
        subset=&quot;validation&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    return train_ds, val_ds

train_dataset, test_val_ds = load_data_tf('data_folder', img_shape = (256,256), batch_size=8)
test_dataset = test_val_ds.take(686)
val_dataset = test_val_ds.skip(686)
</code></pre>
<p><strong>Model compilation and fitting</strong></p>
<pre><code>model.compile(optimizer='sgd',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])
history = model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=1)
</code></pre>
<p><strong>When using a normal <code>Dataset</code>, <code>val_accuracy</code> and <code>val_loss</code> are present in the history of the model:</strong></p>
<p><a href=""https://i.stack.imgur.com/Qn1Yf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qn1Yf.png"" alt=""Expected behaviour: when using a Dataset, validation metrics are calculated"" /></a></p>
<p><strong>But when using a <code>SkipDataset</code>, they are not:</strong></p>
<p><a href=""https://i.stack.imgur.com/GMnBM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GMnBM.png"" alt=""Using the SkipDataset produced by test_val_ds.take() leads to validation metrics disappearing from model history"" /></a></p>
<p><a href=""https://i.stack.imgur.com/omU5U.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/omU5U.png"" alt=""val_accuracy and val_loss are not present in history keys when using a SkipDataset or a TakeDataset"" /></a></p>
",1,Documentation Replication on Other Examples
500,71130645,Correct axes to use dot product to evaluate the final output of a listwise learning to rank model,"<p>I'm not being able to find the correct configuration to pass to a tf.keras.layers.Dot to make a pairwise dot product when the entries each have lists of values, like from a listwise learning to rank model. For instance, suppose:</p>
<pre><code>repeated_query_vector = [
  [[1, 2], [1, 2]],
  [[3, 4], [3, 4]]
]

document_vectors = [
  [[5, 6], [7, 8]],
  [[9, 10], [11, 12]],
]
</code></pre>
<p>Calling tf.keras.layers.Dot(axes=??)([repeated_query_vector, document_vectors]) I want the output to be like:</p>
<pre><code>[
  [1*5 + 2*6, 1*7 + 2*8]
  [3*9 + 4*10, 3*11 + 4*12]
]
</code></pre>
<p>All examples I found in the documentation have one dimension less than my use case. What would be the correct value of axes for this call?</p>
",1,Inadequate Examples
501,71149271,"How to remove single feature from tensorflow dataset, how to use apply on single feture?","<p>I created dataset from csv file with dataset = tf.data.experimental.make_csv_dataset() function but My dataset has categorical and numeric features.</p>
<pre><code>dataset=
color  price weight
red    120    1.2
blue    80     2.0
green   90     3
</code></pre>
<p>Question 1:
The question is how can I  modify  only single feature, for example weight +2, to:</p>
<pre><code>dataset=
color  price weight
red    120    3.2
blue    80     4.0
green   90     5
</code></pre>
<p>I try to do something like:</p>
<pre><code>dataset = dataset.apply(lambda x: x['weight']+2)
</code></pre>
<p>but the error is: &quot;TypeError: 'FilterDataset' object is not subscriptable&quot;</p>
<p>Example from the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply</a> doesn't show it.</p>
<p>Question 2:
How can I remove single feature ? Is there any equivalent to pandas drop column?</p>
",1,Documentation Replication on Other Examples
502,71294464,@tf_gradient peculiar implementation in StyleGan,"<p>I've been reading the source code for the StyleGAN implementation, and I cannot understand the peculiar use of the <code>@tf_gradient</code> decorator. Let us take the concrete example of their implementation of <code>Leaky_Relu</code>. The way I would do it is as follows :</p>
<pre><code>def myLRelu(x,alpha=0.2):
    alpha = tf.constant(alpha, dtype=x.dtype, name='alpha')
    @tf.custom_gradient
    def func(x):
        y = tf.maximum(x, x * alpha)
        def grad(dy):
            dx = tf.where(y &gt;= 0, dy, dy * alpha)
            return dx
        return y, grad
    return func(x)
</code></pre>
<p>Which follows the tf documentation for the use of tf.custom_gradient. But in the styleGan paper, they implement it as follows (I removed the &quot;variable_scope&quot; in my implementation as I'm not sure what it does):</p>
<pre><code>def leaky_relu(x, alpha=0.2):
    with tf.variable_scope('LeakyReLU'):
        alpha = tf.constant(alpha, dtype=x.dtype, name='alpha')
        @tf.custom_gradient
        def func(x):
            y = tf.maximum(x, x * alpha)
            @tf.custom_gradient
            def grad(dy):
                dx = tf.where(y &gt;= 0, dy, dy * alpha)
                return dx, lambda ddx: tf.where(y &gt;= 0, ddx, ddx * alpha)
            return y, grad
        return func(x)
</code></pre>
<p>There are two <code>@tf.custom_gradient</code> decorators used, and I don't understand why since there clearly aren't any second order derivatives being computed (as they are identically 0 anyway for LRelu). Is this a trick to somehow speed up computations ? If so, how does it work ?</p>
<p>EDIT : To clarify why I think this is somehow a &quot;trick&quot; to make computations of gradients faster, the authors make the following comment in the code :</p>
<pre><code># High-level ops for manipulating 4D activation tensors.
# The gradients of these are meant to be as efficient as possible.
</code></pre>
<p>And for completeness, here is the <a href=""https://github.com/NVlabs/stylegan/"" rel=""nofollow noreferrer"">repo</a> from which I took the code from</p>
",1,Documentation Replication on Other Examples
503,71335830,What is the difference between tf.keras.layers.Input() and tf.keras.layers.Flatten(),"<p>I have seen multiple uses of both <code>tf.keras.layers.Flatten()</code> (ex. <a href=""https://www.tensorflow.org/tutorials/generative/autoencoder#first_example_basic_autoencoder"" rel=""nofollow noreferrer"">here</a>) and <code>tf.keras.layers.Input()</code> (ex. <a href=""https://www.tensorflow.org/tutorials/generative/autoencoder#define_a_convolutional_autoencoder"" rel=""nofollow noreferrer"">here</a>). After reading the documentation, it is not clear to me</p>
<ol>
<li>whether either of them uses the other</li>
<li>whether both can be used interchangeably when introducing to a model an input layer (let's say with dimensions <code>(64, 64)</code>)</li>
</ol>
",1,Documentation Ambiguity
504,71588962,Solving a set of linear systems in tensorflow,"<p>I'm having a problem understanding the working mechanism of tensorflow's function: tf.linalg.solve.
I want to solve a set of linear systems (AX = Y), where the linear coefficients (A) were shared but there are multiple batches of Y, which are different.
Using numpy, I can simply do it via:</p>
<pre><code>np.random.seed(0)
mtx = np.random.uniform(size= (1,4,4))
vec = np.random.uniform(size= (100,4,1))
solution = np.linalg.solve(mtx,vec)
print(abs(np.matmul(mtx,solution) - vec).max())
# 5.551115123125783e-16
</code></pre>
<p>which gives me a quite consistent solution.
But when I switch to tensorflow, it gives me the results:</p>
<pre><code>mtx = tf.random.uniform(shape = (1,4,4))
vec = tf.random.uniform(shape = (100,4,1))
solution = tf.linalg.solve(mtx,vec)
print(tf.math.reduce_max(abs(tf.matmul(mtx,solution) - vec))) 
# tf.Tensor(1.3136615, shape=(), dtype=float32)
</code></pre>
<p>According to the document, I assume the solution should be solved according to the corresponding vec. But it does not seem to give me the expected results in tensorflow. Since I'm a new user, I could have messed up something.
It would be appreciated if any information could be offered.</p>
",1,Documentation Ambiguity
505,71619495,Image normalization by tf.image.convert_image_dtype function,"<p>According to documentation <code>tf.image.convert_image_dtype</code> &quot;Images that are represented using floating point values are expected to have values in the range [0,1).&quot;</p>
<p>But in the keras tutorial(<a href=""https://keras.io/examples/vision/cutmix/"" rel=""nofollow noreferrer"">https://keras.io/examples/vision/cutmix/</a>) i have seen the following preprocessing function:</p>
<pre><code>def preprocess_image(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0
    return image, label
</code></pre>
<p>My question is: why did they divide by 255, when <code>tf.image.convert_image_dtype</code> already did that job?</p>
",1,Documentation Ambiguity
506,71791115,Nan Loss when training Deep neural Recommender model using tensorflow,"<p>I am trying to follow <a href=""https://www.tensorflow.org/recommenders/examples/deep_recommenders"" rel=""nofollow noreferrer"">tensorflow documentation</a> and applying same technique to one of toy dataset.</p>
<p>During training I am getting all loss as Nan. I have tried to debug the same using Debugger V2 and I could see that <code>tf.keras.layers.GlobalAveragePooling1D</code> is giving Nan due to division by 0, which is causing all values to be Nan during backpropagation. But what is not clear from the debugger V2 GUI why the sum is becoming 0. I did try to reduce the number of features and the size of the dataset, but each of this activity is giving me new error (probably I shall start a separate question thread for each issues at a later point ).</p>
<p>Below is the code for reference. I am providing the dataset as well <a href=""https://drive.google.com/file/d/1z954Djz8IntSzMP6velSdMGWTW_yBUAn/view?usp=sharing"" rel=""nofollow noreferrer"">here</a>. I had tried below code on Google Colab.</p>
<pre><code>import os
import pprint
import tempfile

from typing import Dict, Text

import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_datasets as tfds

tf.debugging.experimental.enable_dump_debug_info(
    &quot;./tfdbg2_logdir&quot;,
    tensor_debug_mode=&quot;FULL_HEALTH&quot;,
    circular_buffer_size=-1)

!pip install -q tensorflow-recommenders
import tensorflow_recommenders as tfrs  
</code></pre>
<p>Preparing Data</p>
<pre><code>ds=pd.read_csv('train_recom.csv')
ds['year'].replace(0,1,inplace=True)
ds_song=ds.groupby(['song_id','title','release','artist_name','year']).size().reset_index().rename(columns={0:'count'})
ds_song.to_csv('songs_details.csv')
ds.to_csv('train_recom_transformed.csv')
</code></pre>
<p>Reading data to tensorflow dataset</p>
<pre><code>ratings = tf.data.experimental.make_csv_dataset(
    &quot;./train_recom_transformed.csv&quot;,
    batch_size=5,
    select_columns=['user_id', 'song_id', 'listen_count', 'title', 'release', 'artist_name',
       'year'],
    header=True,
    num_epochs=1,
    ignore_errors=False,)
songs = tf.data.experimental.make_csv_dataset(
    &quot;./songs_details.csv&quot;,
    batch_size=128,
    select_columns=['song_id','title','release','artist_name','year'],
    num_epochs=1,
    ignore_errors=True,)
ratings = ratings.unbatch().map(lambda x: {
    &quot;song_id&quot;: x[&quot;song_id&quot;],
    &quot;user_id&quot;: x[&quot;user_id&quot;],
    &quot;release&quot; : x[&quot;release&quot;],
    &quot;artist_name&quot; : x[&quot;artist_name&quot;],
    &quot;title&quot; : x[&quot;title&quot;],
    &quot;year&quot; : x[&quot;year&quot;],
    &quot;listen_count&quot;: x[&quot;listen_count&quot;]
})
songs = songs.unbatch().map(lambda x: x[&quot;song_id&quot;]) 
</code></pre>
<p>Preparing train and test dataset</p>
<pre><code>tf.random.set_seed(42)
shuffled = ratings.shuffle(16000, seed=42, reshuffle_each_iteration=False)

train = shuffled.take(12000)
test = shuffled.skip(12000).take(4000)
cached_train = train.shuffle(100_000).batch(1200).cache()
cached_test = test.batch(400).cache()

title = songs.batch(1000)
user_ids = ratings.batch(1_000_000).map(lambda x: x[&quot;user_id&quot;])
unique_song_titles = np.unique(np.concatenate(list(title)))
unique_user_ids = np.unique(np.concatenate(list(user_ids)))
year_data=np.concatenate(list(ratings.map(lambda x: x['year']).batch(4000)))
</code></pre>
<p>User model class</p>
<pre><code>class UserModel(tf.keras.Model):

    def __init__(self):
        super().__init__()

        max_tokens = 1_000_000

        embedding_dimension = 32
        self.user_embedding = tf.keras.Sequential([
            tf.keras.layers.StringLookup(
                vocabulary=unique_user_ids, mask_token=None),
            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)
          ])

        self.release_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(
            max_tokens=max_tokens)
        
        self.release_text_embedding = tf.keras.Sequential([
          self.release_vectorizer,
          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True,input_length=144),
          tf.keras.layers.GlobalAveragePooling1D(),
        ])

        self.release_vectorizer.adapt(np.concatenate(list(ratings.map(lambda x: x['release']).batch(4000))))

        self.artist_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(
            max_tokens=max_tokens)
        self.artist_text_embedding = tf.keras.Sequential([
          self.artist_vectorizer,
          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),
          tf.keras.layers.GlobalAveragePooling1D(),
        ])
        self.artist_vectorizer.adapt(np.concatenate(list(ratings.map(lambda x: x['artist_name']).batch(4000))))
        
        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(
            max_tokens=max_tokens)
        self.title_text_embedding = tf.keras.Sequential([
          self.title_vectorizer,
          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),
          tf.keras.layers.GlobalAveragePooling1D(),
        ])
        self.title_vectorizer.adapt(np.concatenate(list(ratings.map(lambda x: x['title']).batch(4000))))
        
        self.year_embedding = tf.keras.Sequential([
              tf.keras.layers.Embedding(len(year_data) + 1, 32),
            ])

    def call(self, inputs):
      return tf.concat([
          self.user_embedding(inputs['user_id']),
          self.release_text_embedding(inputs['release'])
          ,
          self.year_embedding(inputs['year']), 
          self.artist_text_embedding(inputs['artist_name']),
          self.title_text_embedding(inputs['title']),
             ], axis=1)
</code></pre>
<p>Item model</p>
<pre><code>class ItemModel(tf.keras.Model):

    def __init__(self):
        super().__init__()

        max_tokens = 10_000

        embedding_dimension = 32

        ## embed title from unique_song_titles
        self.title_embedding = tf.keras.Sequential([
        tf.keras.layers.StringLookup(
            vocabulary=unique_song_titles, mask_token=None),
        tf.keras.layers.Embedding(len(unique_song_titles) + 1, embedding_dimension)
      ])

    def call(self, inputs):
      return self.title_embedding(inputs)
</code></pre>
<p>Query model . Creating Deep model</p>
<pre><code>class QueryModel(tf.keras.Model):
  &quot;&quot;&quot;Model for encoding user queries.&quot;&quot;&quot;

  def __init__(self, layer_sizes):
    &quot;&quot;&quot;Model for encoding user queries.

    Args:
      layer_sizes:
        A list of integers where the i-th entry represents the number of units
        the i-th layer contains.
    &quot;&quot;&quot;
    super().__init__()

    # We first use the user model for generating embeddings.
    self.embedding_model = UserModel()

    # Then construct the layers.
    self.dense_layers = tf.keras.Sequential()

    # Use the ReLU activation for all but the last layer.
    for layer_size in layer_sizes[:-1]:
      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=&quot;relu&quot;))

    # No activation for the last layer.
    for layer_size in layer_sizes[-1:]:
      self.dense_layers.add(tf.keras.layers.Dense(layer_size))

  def call(self, inputs):
    feature_embedding = self.embedding_model(inputs)
    return self.dense_layers(feature_embedding)
</code></pre>
<p>Creating deep model for the Item model</p>
<pre><code>class CandidateModel(tf.keras.Model):
  &quot;&quot;&quot;Model for encoding movies.&quot;&quot;&quot;

  def __init__(self, layer_sizes):
    &quot;&quot;&quot;Model for encoding movies.

    Args:
      layer_sizes:
        A list of integers where the i-th entry represents the number of units
        the i-th layer contains.
    &quot;&quot;&quot;
    super().__init__()

    self.embedding_model = ItemModel()

    # Then construct the layers.
    self.dense_layers = tf.keras.Sequential()

    # Use the ReLU activation for all but the last layer.
    for layer_size in layer_sizes[:-1]:
      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=&quot;relu&quot;))

    # No activation for the last layer.
    for layer_size in layer_sizes[-1:]:
      self.dense_layers.add(tf.keras.layers.Dense(layer_size))

  def call(self, inputs):
    feature_embedding = self.embedding_model(inputs)
    return self.dense_layers(feature_embedding)
</code></pre>
<p>Combining both query and candidate model</p>
<pre><code>class SongModel(tfrs.models.Model):

    def __init__(self, layer_sizes):
        super().__init__()
        self.query_model = QueryModel(layer_sizes)
        self.candidate_model = CandidateModel(layer_sizes)
        self.task = tfrs.tasks.Retrieval(
          metrics=tfrs.metrics.FactorizedTopK(
              candidates=songs.batch(128).map(self.candidate_model),
          ),
      )

    def compute_loss(self, features, training=False):
        print('type of feature ----',type(features))

        query_embeddings = self.query_model({
            &quot;user_id&quot;: features[&quot;user_id&quot;]
            ,
                &quot;release&quot; : features[&quot;release&quot;]
                ,
                &quot;artist_name&quot; : features[&quot;artist_name&quot;],
                &quot;title&quot;: features[&quot;title&quot;],
                &quot;year&quot; : features[&quot;year&quot;],
        })

        item_embeddings = self.candidate_model(features[&quot;song_id&quot;])

        return self.task(query_embeddings, item_embeddings)
</code></pre>
<p>training the model</p>
<pre><code>model = SongModel([32])
model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))
model_hist = model.fit(cached_train, epochs=9)
</code></pre>
<p>Below id the outout that I got</p>
<pre><code>WARNING:tensorflow:Failed to read source code from path: /content/&lt;ipython-input-26-fdc864fc30cf&gt;. Reason: Source path neither exists nor can be loaded as a .par file: /content/&lt;ipython-input-26-fdc864fc30cf&gt;
WARNING:tensorflow:Failed to read source code from path: /content/&lt;ipython-input-25-e3009db55439&gt;. Reason: Source path neither exists nor can be loaded as a .par file: /content/&lt;ipython-input-25-e3009db55439&gt;
Epoch 1/9
type of feature ---- &lt;class 'dict'&gt;
WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_10_input'), name='embedding_10_input', description=&quot;created by layer 'embedding_10_input'&quot;), but it was called on an input with incompatible shape (None,).
type of feature ---- &lt;class 'dict'&gt;
WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_10_input'), name='embedding_10_input', description=&quot;created by layer 'embedding_10_input'&quot;), but it was called on an input with incompatible shape (None,).
10/10 [==============================] - 63s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0022 - factorized_top_k/top_10_categorical_accuracy: 0.0033 - factorized_top_k/top_50_categorical_accuracy: 0.0073 - factorized_top_k/top_100_categorical_accuracy: 0.0103 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 2/9
10/10 [==============================] - 9s 945ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 3/9
10/10 [==============================] - 10s 953ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 4/9
10/10 [==============================] - 9s 948ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 5/9
10/10 [==============================] - 10s 966ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 6/9
10/10 [==============================] - 10s 955ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 7/9
10/10 [==============================] - 10s 955ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 8/9
10/10 [==============================] - 10s 958ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
Epoch 9/9
10/10 [==============================] - 10s 971ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: nan - regularization_loss: 0.0000e+00 - total_loss: nan
</code></pre>
",1,Documentation Replication on Other Examples
507,71813366,How to add loss function with activity regularizer in distributed training,"<p>I have an deep autoencoder with an activity_regularizer <strong>in the bottleneck layer</strong>:</p>
<pre class=""lang-py prettyprint-override""><code>keras.layers.Dense(input_dim, ...)
...
keras.layers.Dense(2, activity_regularizer=keras.regularizers.l1())
...
outputs = keras.layers.Dense(input_dim, ...)
...
model.compile(loss='mse')
</code></pre>
<p>I then added some <a href=""https://www.tensorflow.org/guide/migrate/migrating_feature_columns#feature_column_equivalence_table"" rel=""nofollow noreferrer"">tf2 preprocessing feature layers</a>:</p>
<pre class=""lang-py prettyprint-override""><code>inputs = {
  'a': keras.Input(shape=()),
  'b': keras.Input(shape=()), # some other preprocessing applied afterwards
}
preprocessed = keras.layers.Concatenate()(inputs.values())

keras.layers.Dense(input_dim, ...)(preprocessed)
...
keras.layers.Dense(2, activity_regularizer=keras.regularizers.l1())
...
outputs = keras.layers.Dense(input_dim, ...)
...
model.compile(loss='mse')
</code></pre>
<p>So now I can't just add a loss function like <code>model.compile(loss='mse')</code> since the input are raw features and the outputs are scalars. I need to compute the loss based on the output of <code>preprocessed</code> and the final <code>outputs</code>.</p>
<p>This <a href=""https://stackoverflow.com/a/71614473/7242490"">answer</a> suggested I use the <code>model.add_loss()</code> function like:</p>
<pre class=""lang-py prettyprint-override""><code>model.add_loss(keras.losses.MeanSquaredError()(preprocessed, outputs))
</code></pre>
<p>This worked but when I tried training this using <code>tf.distribute.MultiWorkerMirroredStrategy()</code> I got the error:</p>
<pre><code>ValueError: Please use `tf.keras.losses.Reduction.SUM` or `tf.keras.losses.Reduction.NONE` for loss reduction when losses are used with `tf.distribute.Strategy` outside of the built-in training loops. You can implement `tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE` using global batch size like:

with strategy.scope():
    loss_obj = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)
    ....
    loss = tf.reduce_sum(loss_obj(labels, predictions)) * (1. / global_batch_size)

Please see https://www.tensorflow.org/tutorials/distribute/custom_training for more details.
</code></pre>
<p>Reading <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/distribute/custom_training</a> the documentation states:</p>
<blockquote>
<p>If you are using regularization losses in your model then you need to scale the loss value by number of replicas. You can do this by using the tf.nn.scale_regularization_loss function.</p>
</blockquote>
<p>So I'm now a bit confused. Does the above statement apply to the <code>activity_regularizer</code> I added? How does this work with the <code>global_batch_size</code>?</p>
<p>How can I solve this in distributed training?</p>
<hr />
<p><strong>TLDR: Do I need to &quot;scale the loss value by number of replicas&quot; when using hidden layer <code>activity_regularizer</code> in distributed training?</strong></p>
",1,Documentation Ambiguity
508,71933464,How to make true_fn of tf.cond skip a for loop in tensorflow v1.0/python?,"<p>I want to use <code>tf.cond</code> to mimic the python <code>if-else</code> logic in the <code>_preprocessing_fn</code> of <code>transform.py</code>.</p>
<p>Specifically, if the condition of <code>tf.cond</code> is true, I want to skip the current iteration of the for loop.</p>
<p>This seems problematic because <code>true_fn</code> and <code>false_fn</code> parameters of <code>tf.cond</code> are expected to return Tensors according to the documentation.</p>
<p>However, in my case, I want <code>true_fn</code> (aka <code>skip_feature_fn</code>)to simply &quot;continue&quot; to the next for loop iteration. Also, I want <code>false_fn</code> to take in two inputs (<code>feature</code> and <code>sp</code>) and simply feed them to some other API (e.g. <code>tft.vocabulary</code>).
I don't expect either of <code>true_fn</code> or <code>false_fn</code> to return anything.</p>
<p>Could someone help me accomplish my goal?</p>
<p>Here is the code snippet I'm working with:</p>
<pre><code>def _preprocessing_fn(inputs, category_features=features.STRING_FEATURES):
  outputs = transform_lib.preprocessing_helper_fn(
      inputs, used_features=category_features)

  for feature in category_features:
    if feature:
      sp = outputs[feature]
      tf.cond(
          tf.equal(sp.dense_shape[1], 0), skip_feature_fn, lambda: process_feature_further(
              feature,
              sp,
          ))

  return outputs
</code></pre>
<p>Thank you.</p>
",1,Documentation Replication on Other Examples
509,72184958,Pydantic: Type hinting tensorflow tensor,"<p>any idea of how to type-hint tf tensors using pydantic??. Tried default tf.Tensor</p>
<pre><code>RuntimeError: no validator found for &lt;class 'tensorflow.python.framework.ops.Tensor'&gt;, see `arbitrary_types_allowed` in Config
</code></pre>
<p>and tf.flaot32</p>
<pre><code>RuntimeError: error checking inheritance of tf.float32 (type: DType)
</code></pre>
<p>Looking at documentation in pydantic, i believe something like this arbitrary class need to be defined...</p>
<pre><code>class Tensor:
    def __init__(self, Tensor):

        self.Tensor = Union[
            tensorflow.python.framework.ops.Tensor,
            tensorflow.python.framework.sparse_tensor.SparseTensor,
            tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor,
            tensorflow.python.framework.ops.EagerTensor,
        ]
</code></pre>
<p>with following in main..</p>
<pre><code> class Main(BaseModel):
     tensor : Tensor


 class Config:
    arbitary_types_allowed = True
</code></pre>
",1,Documentation Replicability
510,72329108,Is there a simple way to know which Tensorflow ops have a registered GPU kernel?,"<p>I have been trying to optimize some Tensorflow code that was pretty memory inefficient (use of large dense tensors containing very sparse information), and would thus limit batch size and scalability, by trying to make use of SparseTensors.
After some struggle I finally come up with a decent solution with satisfactory speedup on CPU and very low memory usage, and when the time comes to use a GPU I realize that the previous memory inefficient is orders of magnitude faster...</p>
<p>Using tensorboard profiling I've discovered that two of the operations I have used in my &quot;&quot;optimized&quot;&quot; version only run on CPU (namely UniqueV2 and sparse_dense_matmul), but I could not see any hint of that in the documentation.</p>
<p>The only related piece of <a href=""https://www.tensorflow.org/guide/gpu#overview"" rel=""nofollow noreferrer"">documentation</a> states:</p>
<blockquote>
<p>If a TensorFlow operation has no corresponding GPU implementation,
then the operation falls back to the CPU device. For example, since
tf.cast only has a CPU kernel, on a system with devices CPU:0 and
GPU:0, the CPU:0 device is selected to run tf.cast, even if requested
to run on the GPU:0 device.</p>
</blockquote>
<p>In turn there is nothing in the tf.cast documentation hinting that the op has no GPU kernel.</p>
<p>Thus, is there a simple way to know whether a TF ops has a registered GPU kernel, without having to use a GPU to find it out?</p>
<p>The <a href=""https://www.tensorflow.org/guide/create_op#gpu_support"" rel=""nofollow noreferrer"">custom ops</a> guide suggest that this could be seen by looking at the ops C files, but this seems a rather cumbersome way to do it...</p>
<p>I'm using TF v2.8</p>
<p>Thanks!</p>
",1,Inadequate Examples
511,72707453,How to save a tensorflow dataset to multiple shards without using enumerate,"<p>I have a tensorflow dataset with some elements in it, and I want to save it with <code>tf.data.Dataset.save</code> such that each element gets its own shard. Thus if the dataset contains 2,000 elements, it would be saved to 2,000 shards.</p>
<p>The documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#save"" rel=""nofollow noreferrer"">here</a> specifies how to create 1 shard only, but not how to make a shard for each element.</p>
<p>Below, I am able to do it with enumerate, but is there another way to do it without also saving the index from <code>enumerate</code>?</p>
<pre><code>tuple_data = np.array([3, 4])
data = tf.data.Dataset.from_tensor_slices(tuple_data)
data = data.enumerate()
print(list(data.as_numpy_iterator()))
# [(0, 3), (1, 4)]

data.save(path='~/Desktop/1', shard_func=lambda i, x: i)
</code></pre>
",1,Documentation Replicability
512,72720129,Understanding tf.keras.metrics.Precision and Recall for multiclass classification,"<p>I am building a model for a multiclass classification problem. So I want to evaluate the model performance using the Recall and Precision.
I have 4 classes in the dataset and it is provided in <code>one hot</code> representation.</p>
<p>I was reading the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision"" rel=""nofollow noreferrer"">Precision</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall"" rel=""nofollow noreferrer"">Recall</a> <code>tf.keras</code> documentation, and have some questions:</p>
<ol>
<li>When it calculating the Precision and Recall for the multi-class classification, how can we take the average of all of the labels, meaning the global precision &amp; Recall? is it calculated with <code>macro</code> or <code>micro</code> since it is not specified in the documentation as in the <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html"" rel=""nofollow noreferrer"">Sikit learn</a>.</li>
<li>If I want to calculate the precision &amp; Recall for each label separately, can I use the argument <code>class_id</code> for each label to do  <code>one_vs_rest</code> or <code>binary</code> classification. Like what I have done in the code below?</li>
<li>can I use the argument <code>top_k</code> with the value <code>top_k=2</code> would be helpful here or it is not suitable for my classification of 4 classes only?</li>
<li>While I am measuring the performance of each class, What could be the difference, when I set the <code>top_k=1</code> and not setting <code>top_k</code>overall?</li>
</ol>
<pre><code>model.compile(
      optimizer='sgd',
      loss=tf.keras.losses.CategoricalCrossentropy(),
      metrics=[tf.keras.metrics.CategoricalAccuracy(),
               ##class 0
               tf.keras.metrics.Precision(class_id=0,top_k=2), 
               tf.keras.metrics.Recall(class_id=0,top_k=2),
              ##class 1
               tf.keras.metrics.Precision(class_id=1,top_k=2), 
               tf.keras.metrics.Recall(class_id=1,top_k=2),
              ##class 2
               tf.keras.metrics.Precision(class_id=2,top_k=2), 
               tf.keras.metrics.Recall(class_id=2,top_k=2),
              ##class 3
               tf.keras.metrics.Precision(class_id=3,top_k=2), 
               tf.keras.metrics.Recall(class_id=3,top_k=2),
])
</code></pre>
<p>Any clarification of this function will be appreciated.
Thanks in advance</p>
",1,Documentation Replicability
513,72749893,Optimizer.apply_gradients creating variables in tf.function,"<p>I have created a neural style transfer with Eager Execution, but it does not work when I  try to turn it into a tf.function.
The error message says:</p>
<pre><code>ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
</code></pre>
<p>However, no variable is being created inside the function. Here is a simplified version of the code, which is just a neural style transfer with one image (the goal is to make the generated image look exactly like the content image):</p>
<pre><code>import tensorflow as tf
import numpy as np
from PIL import Image

#Get and process the images
image = np.array(Image.open(&quot;frame7766.jpg&quot;)).reshape(1, 720, 1280, 3)/255
content_image = tf.convert_to_tensor(image, dtype = tf.float32)
# variable is defined outside of tf.function
generated_image = tf.Variable(np.random.rand(1, 720, 1280, 3)/2 + content_image/2, dtype = tf.float32)

def clip_0_1(image): # keeps image values between 0 and 1
    return tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)

@ tf.function
def train_step(generated_image, content_image): #turn generated image into tf variable
    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)
    with tf.GradientTape() as tape:
        cost = tf.reduce_sum(tf.square(generated_image - content_image))
    grad = tape.gradient(cost, generated_image) 
    optimizer.apply_gradients([(grad, generated_image)]) # More information below
    generated_image.assign(clip_0_1(generated_image))
    return generated_image

generated_image = train_step(generated_image, content_image)
</code></pre>
<p>The error message points to the line</p>
<pre><code>optimizer.apply_gradients([(grad, generated_image)]) 
</code></pre>
<p>I have tried to change the input of <code> optimizer.apply_gradients</code> to <code>zip([grad], [generated_image])</code>, and every combination of lists and tuples I can think of, but the error still remains. I have also looked through <a href=""https://www.tensorflow.org/guide/function#creating_tfvariables"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/function#creating_tfvariables</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer</a>, but neither of them shows examples where the variable is not explicitly defined.
The only conclusion that I can come to is that one of my commands (most likely <code>optimizer.apply_gradients</code>) creates a variable because of an issue in my earlier code. Is that correct?</p>
",1,Documentation Replication on Other Examples
514,72850120,"Keras - Specifying from_logits=False when using tf.keras.layers.Dense(1,activation='sigmoid')(x)","<p>I am working on a binary classification problem, using transfer learning and image inputs and have a question regarding the</p>
<p>I have been working through using the correct activation layers (e.g. Softmax or Sigmoid - sigmoid for binary softmax for multiclass) and noticed when I specify 'sigmoid' as part of the <code>Dense()</code> output layer, I no longer need to specify <code>from_logits=True</code> during <code>model.compile()</code>.</p>
<p>This means when I am obtaining predictions, I don't use the <code>tf.nn.sigmoid()</code> function and instead simply check if the value is greater than 0.5, then 1, else 0. Is this correct? Here is my code:</p>
<pre><code>i = keras.Input(shape=(150, 150, 3))
                scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)
                mt = scale_layer(i)
                mt = base_model(model_top, training=False)
                mt = keras.layers.GlobalAveragePooling2D()(mt)
                mt = keras.layers.Dropout(dropout)(mt)  # Regularize with dropout
                o = keras.layers.Dense(1,activation='sigmoid')(mt)
                model = keras.Model(i, o)

....

model.compile(optimizer=keras.optimizers.Adam(lr),loss=keras.losses.BinaryCrossentropy(from_logits=False)
                )
</code></pre>
<p>And then when I obtain predictions, I have the following:</p>
<pre><code>                pred = model.predict(test)
                pred = tf.where(pred &lt; 0.5, 0, 1)
                pred = pred.numpy()
</code></pre>
<p>My intuition is that as I am specifying the sigmoid activation function during the Dense layer build, I no longer work with 'logits' and therefore do not need to apply the sigmoid function later on. In the documentation, I've seen both examples used but it's quite sparse on information when working with <code>model.predict()</code>, would appreciate any guidance.</p>
",1,Documentation Replicability
515,72928149,Difference between Experimental Preprocessing layers and normal preprocessing layers in Tensorflow,"<pre><code>import tensorflow as tf
import keras
import tensorflow.keras.layers as tfl
from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation
</code></pre>
<p>I am trying to figure out which I should use for Data Augmentation. In the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers"" rel=""nofollow noreferrer"">documentation</a>, there is:</p>
<p>tf.keras.layers.RandomFlip and RandomRotation</p>
<p>Then we have in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing"" rel=""nofollow noreferrer"">tf.keras.layers.experimental.preprocessing</a> the same things, randomFlip and RandomRotation.</p>
<p>Which should I use? I've seen <a href=""https://www.tensorflow.org/guide/keras/preprocessing_layers"" rel=""nofollow noreferrer"">guides</a> that use both.</p>
<p>This is my current code:</p>
<pre><code>def data_augmenter():
data_augmentation = tf.keras.Sequential([
    tfl.RandomFlip(),
    tfl.RandomRotation(0.2)
])
return data_augmentation
</code></pre>
<p>and this is a part of my model:</p>
<pre><code>def ResNet50(image_shape = IMG_SIZE, data_augmentation=data_augmenter()):

input_shape = image_shape + (3,)

# Remove top layer in order to put mine with the correct classification labels, get weights for imageNet
base_model = tf.keras.applications.resnet_v2.ResNet50V2(input_shape=input_shape, include_top=False, weights='imagenet')

# Freeze base model
base_model.trainable = False

# Define input layer
inputs = tf.keras.Input(shape=input_shape)

# Apply Data Augmentation
x = data_augmentation(inputs)
</code></pre>
<p>I am a bit confused here..</p>
",1,Documentation Replication on Other Examples
516,73049510,How to dynamically set pool size for AveragePooling2D layer/ How to pass external value to an sequential layer,"<p>Trying to understand <a href=""https://www.tensorflow.org/recommenders/examples/listwise_ranking"" rel=""nofollow noreferrer"">listwise documentation</a></p>
<p>while trying to replicate by mixing <a href=""https://www.tensorflow.org/recommenders/examples/deep_recommenders"" rel=""nofollow noreferrer"">deep model</a> to listwise I am stuck at point where I am not able to set the pool size inside the sequential layer in an dynamic manner. For example consider below code</p>
<pre><code>!pip install -q tensorflow-recommenders
!pip install -q --upgrade tensorflow-datasets
!pip install -q tensorflow-ranking
import pprint

import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_ranking as tfr
import tensorflow_recommenders as tfrs
from typing import Dict, Text
import os
import tempfile
import datetime
ratings = tfds.load(&quot;movielens/100k-ratings&quot;, split=&quot;train&quot;)
movies = tfds.load(&quot;movielens/100k-movies&quot;, split=&quot;train&quot;)

ratings = ratings.map(lambda x: {
    &quot;movie_title&quot;: x[&quot;movie_title&quot;],
    &quot;user_id&quot;: x[&quot;user_id&quot;],
    &quot;user_rating&quot;: x[&quot;user_rating&quot;],
    # &quot;timestamp&quot;: x[&quot;timestamp&quot;],
})
movies = movies.map(lambda x: x[&quot;movie_title&quot;])

unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))
unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(
    lambda x: x[&quot;user_id&quot;]))))


class MovieModel(tf.keras.Model):

  def __init__(self):
    super().__init__()

    max_tokens = 10_000_00

    self.title_vectorizer = tf.keras.layers.TextVectorization(
        max_tokens=max_tokens)

    self.title_text_embedding = tf.keras.Sequential([
      # tf.keras.layers.Flatten(),
      self.title_vectorizer,
      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),
      tf.keras.layers.AveragePooling2D(pool_size=(1,4),strides=1,    padding='valid',),
    ])
    self.title_vectorizer.adapt(movies)

  def call(self, titles):
    return self.title_text_embedding(titles)
</code></pre>
<p>After we create movie model lets try to test it before we can use it on proper movie data</p>
<p>below is the test code</p>
<pre><code>test_movie_titles = [[&quot;M*A*S*H (1970)&quot;, &quot;Dances with Wolves (1990)&quot;, &quot;Speed (1994)&quot;,&quot;Dances with Wolves (1990)&quot;, &quot;Speed (1994)&quot;]]
md = MovieModel()
test_ratings = md(tf.constant(tf.reshape(test_movie_titles,[1,5,1])) )  
test_ratings
</code></pre>
<p>This now works perfect and I will get an output as below</p>
<pre><code>&lt;tf.Tensor: shape=(1, 5, 1, 32), dtype=float32, numpy=
array([[[[ 0.00778975, -0.00899004,  0.02926993, -0.00527342,
           0.00706512,  0.02012717,  0.03438753,  0.01971687,
          -0.00543808, -0.00754605, -0.02241766,  0.00045748,
          -0.00785657, -0.00291913,  0.00670988,  0.01176082,
          -0.02052191, -0.00751739, -0.01433057,  0.008
-----
----
</code></pre>
<p>Now if you notice in the code above I have hardcoded the pool_size as 1,4 ( <code>tf.keras.layers.AveragePooling2D(pool_size=(1,4),strides=1,    padding='valid',),</code>) because the test sample I had used above only have maximum 4 words, so the vectorization will produce vector of size 4, now problem is how to I ensure the right pool size when I pass the whole dataset (movies) to the model. How can I pass such external value (pool_size) to an sequential layer from outside?</p>
<p>The above code was run on google colab using tensorflow version 2.9.1</p>
",1,Documentation Replication on Other Examples
517,73179836,tensorflow.py_function fails to temporarily switch to eager execution while in graph mode,"<p>I'm not sure if this is a Tensorflow bug or my misunderstanding about what this function is supposed to do, but I can't get <code>tf.py_function</code> to return an <code>EagerTensor</code> <em>while in graph mode</em>. Consequently, calling <code>.numpy()</code> on the output of this function fails.</p>
<p>The issue can be reproduced using the exact example given in the official documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/py_function</a>):</p>
<pre><code>import tensorflow as tf

tf.compat.v1.disable_eager_execution()

def log_huber(x, m):
  if tf.abs(x) &lt;= m:
    return x**2
  else:
    return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))

x = tf.constant(1.0)
m = tf.constant(2.0)

with tf.GradientTape() as t:
  t.watch([x, m])
  y = tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32)

dy_dx = t.gradient(y, x)
assert dy_dx.numpy() == 2.0

</code></pre>
<p>This generates the following error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;&lt;input&gt;&quot;, line 17, in &lt;module&gt;
  File &quot;C:\Users\...\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\framework\ops.py&quot;, line 446, in __getattr__
    self.__getattribute__(name)
AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>
<h3>About version</h3>
<p>I am running Python 3.8 and Tensorflow v2.9.1.</p>
<p>Any help would be greatly appreciated!</p>
",1,Documentation Replicability
518,73213159,How to apply tf.data transformations to a DataFrame,"<p>I want to apply tf.data transformations to a panda  dataframe. According to the tensorflow docs <a href=""https://www.tensorflow.org/tutorials/load_data/pandas_dataframe"" rel=""nofollow noreferrer"">HERE</a> I can apply tf.data to a dataframe directly but the dtype of the dataframe should be uniform.</p>
<p>When I apply tf.data to my dataframe like below</p>
<pre><code>tf.data.Dataset.from_tensor_slices(df['reports'])
</code></pre>
<p>it generates this error</p>
<pre><code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).
</code></pre>
<p>When I print <code>df['reports'].dtype</code> it is <code>dtype('O')</code> which seems to be not uniformed, if this is the case then how can I convert this dataframe to uniform <code>dtype</code>.</p>
",1,Documentation Replicability
519,73279782,Tensorboard profiling a predict call using Cloud TPU Node,"<p>I've been trying to profile a predict call of a custom NN model using a Cloud TPU v2-8 Node.</p>
<p>It is important to say that my prediction call takes about 2 minutes to finish and I do it using data divided in TFRecord batches.</p>
<p>I followed the official documentation &quot;<a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools"" rel=""nofollow noreferrer"">Profile your model with Cloud TPU Tools</a>&quot; and I tryied to capture a profile:</p>
<ol>
<li>Using <a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_a_profile_using_tensorboard"" rel=""nofollow noreferrer"">Tensorboard UI</a> and</li>
<li>The &quot;<a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_a_profile_programmatically"" rel=""nofollow noreferrer"">programatic way</a>&quot; with a tf.profiler.experimental.start() and tf.profilier.experimental.stop() wrapping the predict call, but I had no success in both cases.</li>
</ol>
<pre><code># TPU Node connection is done before...

# TPU at this point is already running
logdir_path = &quot;logs/predict&quot;
tf.profiler.experimental.start(logdir_path)
# Tensorflow predict call here
tf.profiler.experimental.stop()
</code></pre>
<p>I could generate some data in both cases (Tensorboard UI and profiler call), but when I try to open it in Tensorboard pointing the logdir path, I received a &quot;No dashboard are active for the current data set&quot; message.</p>
<p><strong>Is there any way to profile a Tensorflow/Keras prediction call with a model running in a Cloud TPU Node?</strong>
<br>
<br>
<br>
<br>
<strong>Curious fact</strong> - There seems to be an inconsistency in the Tensorflow docs and Cloud TPU docs: in <a href=""https://www.tensorflow.org/guide/profiler#profiling_use_cases"" rel=""nofollow noreferrer"">Tensorflow Optimization Docs</a> we can see that tf.profiler.experimental.start/stop calls are not supported by TPU hardware, but in <a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools#capture_a_profile_programmatically"" rel=""nofollow noreferrer"">Google Cloud docs</a> this is the recommended method to capture a profile in TPU.</p>
<p>Config:</p>
<ul>
<li>Tensorflow 2.6.1</li>
<li>Tensorboard 2.9.1</li>
<li>Python 3.8</li>
<li>Cloud TPU Node v2-8</li>
</ul>
",1,Documentation Replication on Other Examples
520,73328337,Tensorflow 2 SSD MobileNet model breaks during conversion to tflite,"<p>I've been trying to follow this process to run an object detector (SSD MobileNet) on the Google Coral Edge TPU:
<a href=""https://i.stack.imgur.com/Hm22L.png"" rel=""nofollow noreferrer"">Edge TPU model workflow</a></p>
<p>I've successfully trained and evaluated my model with the Object Detection API. I have the model both in checkpoint format as well as tf SavedModel format. As per the documentation, the next step is to convert to .tflite format using post-training quantization.</p>
<p>I am to attempting to follow <a href=""https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/convert_odt_model_to_TFLite.ipynb"" rel=""nofollow noreferrer"">this</a> example. The export_tflite_graph_tf2.py script and the conversion code that comes after run without errors, but I see some weird behavior when I try to actually use the model to run inference.</p>
<ol>
<li>I am unable to use the saved_model generated by export_tflite_graph_tf2.py. When running the following code, I get an error:</li>
</ol>
<pre><code>print('loading model...')
model = tf.saved_model.load(tflite_base)
print('model loaded!')
results = model(image_np)
</code></pre>
<blockquote>
<p>TypeError: '_UserObject' object is not callable --&gt; results = model(image_np)</p>
</blockquote>
<p>As a result, I have no way to tell if the script broke my model or not before I even convert it to tflite. Why would model not be callable in this way? I have even verified that the type returned by tf.saved_model.load() is the same when I pass in a saved_model before it went through the export_tflite_graph_tf2.py script and after. The only possible explanation I can think of is that the script alters the object in some way that causes it to break.</p>
<ol start=""2"">
<li>I convert to tflite with post-training quantization with the following code:</li>
</ol>
<pre><code>def representative_data_gen():
  dataset_list = tf.data.Dataset.list_files(images_dir + '/*')
  for i in range(100):
    image = next(iter(dataset_list))
    image = tf.io.read_file(image)
    # supports PNG as well
    image = tf.io.decode_image(image, channels=3)
    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
    image = tf.cast(image / 255., tf.float32) 
    image = tf.expand_dims(image, 0)
    if i == 0:
      print(image.dtype)
    yield [image]

# This enables quantization
# This sets the representative dataset for quantization
converter = tf.lite.TFLiteConverter.from_saved_model(base_saved_model)
# converter = tf.lite.TFLiteConverter.from_keras(model)

converter.optimizations = [tf.lite.Optimize.DEFAULT] # issue here?
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [
  # tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  # tf.lite.OpsSet.SELECT_TF_OPS, # enable TensorFlow ops.
  tf.lite.OpsSet.TFLITE_BUILTINS_INT8 # This ensures that if any ops can't be quantized, the converter throws an error
]

# This ensures that if any ops can't be quantized, the converter throws an error
# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.
converter.target_spec.supported_types = [tf.int8]
converter.target_spec.supported_ops += [tf.lite.OpsSet.TFLITE_BUILTINS]
# These set the input and output tensors to uint8 (added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_model_quantized = converter.convert()
</code></pre>
<p>Everything runs with no errors, but when I try to actually run an image through the model, it returns garbage. I tried removing the quantization to see if that was the issue, but even without quantization it returns seemingly random bounding boxes that are completely off from the model's performance prior to conversion. The shape of the output tensors look fine, it's just the content is all wrong.</p>
<p>What's the right way to get this model converted to a quantized tflite form? I should note that I can't use the tflite_convert utility because I need to quantize the model, and it appears according to the source code that the quantize_weights flag is deprecated? There are a bunch of conflicting resources I see from TF1 and TF2 about this conversion process so I'm pretty confused.</p>
<p>Note: I'm using a retrained SSD MobileNet from the model zoo. I have not made any changes to the architecture in my training workflow. I've confirmed that the errors persist even on the base model pulled directly from the object detection model zoo.</p>
",1,Documentation Ambiguity
521,73645574,Why keras AUC returns zero when multi-label is set?,"<p>I'm trying to understand how <code>tf.keras.metrics.AUC(multi_label=True)</code> works. From the docs, I'm led to understand that when working with multi-label vectors, each class is computed individually, then averaged.</p>
<p>However, I can't seem to get the following trivial case to compute correctly. That is, if the prediction is the same as the expected vector, why is the output not <code>1.0</code>?</p>
<pre><code>y_true = [
    [1, 0, 0, 0, 1],
]

acc = tf.keras.metrics.AUC(multi_label=True, num_labels=5)

acc.reset_state()
acc.update_state(tf.constant(y_true), tf.constant(y_true))
acc.result().numpy()

&gt;&gt;&gt; 0.0
</code></pre>
",1,Documentation Ambiguity
522,73794766,what is the meaning of axis=-1 in tf.keras.layers.Normalization?,"<p>I'm trying to learn deep learning using keras and tensorflow and I came across a code explaining linear regression at <a href=""https://www.tensorflow.org/tutorials/keras/regression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/keras/regression</a> wherein they have created a normalization layer using normalizer = tf.keras.layers.Normalization(axis=-1). Someone please explain the meaning of axis =-1 . I tried looking at the API documentation but I couldnt understand the explanation from there?I know that axis=0 represent rows and axis=1 columns, right?
Thanks in advance</p>
",1,Documentation Completeness
523,74005009,How to create output_signature for tensorflow.dataset.from_generator,"<p>I have a generator yielding data and labels <code>yield data, labels</code> where the data is
an <code>numpy.ndarray</code> with variable rows and 500 columns of type <code>dtype=float32</code> and the labels are integers of <code>numpy.int64</code>.</p>
<p>I'm trying to pass this data into TensorFlow from_generator function to create a TensorFlow dataset: <code>tf.data.Dataset.from_generator</code></p>
<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">docs</a> say that the from_generator function needs a parameter <code>output_signature</code> as an input. But I'm having trouble understanding how to build this output_signature.</p>
<p>How can I make the output_signature for the generator I described?</p>
<p>Thank you!</p>
<p>Edit:
I used <code>tf.type_spec_from_value</code> to get this:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
   datagen_row,
   output_signature=(
      tf.TensorSpec(shape=(None, 512), dtype=tf.float32, name=None),
      tf.TensorSpec(shape=(), dtype=tf.int64, name=None)
   )
)
</code></pre>
<p>But is it correct to use None when the number of rows is varying for the first data type?</p>
",1,Documentation Replicability
524,74029376,Tensorflow custom reduction function with axis support,"<p>I would like to get the value with the maximum absolute value in a tensor, with respect to an axis. Note that I don't want the maximum absolute value, I want the <em>value that has the maximum absolute value</em> (so I need to keep the sign).</p>
<p>Ideally, I would like something similar to <code>reduce_max</code> or <code>reduce_min</code>:</p>
<pre class=""lang-py prettyprint-override""><code>tensor = tf.constant(
  [
    [[ 1,  5, -3],
     [ 2, -3,  1],
     [ 3, -6,  2]],

    [[-2,  3, -5],
     [-1,  4,  2],
     [ 4, -1,  0]]
   ]
)
# tensor.shape = (2, 3, 3)

tensor.reduce_maxamplitude(tensor, axis=0)
# Tensor(
#  [[-2,  5, -5],
#   [ 2,  4,  2],
#   [ 4, -6,  2]]
# )
# shape: (3, 3)

tensor.reduce_maxamplitude(tensor, axis=1)
# Tensor(
#  [[3, -6, -3],
#   [4,  4, -5]]
# )
# shape: (2, 3)

tensor.reduce_maxamplitude(tensor, axis=2)
# Tensor(
#  [[5, -3, -6],
#   [-5,  4, 4]]
# )
# shape: (2, 3)
</code></pre>
<p>but I did not find anything useful in tensorflow documentation.</p>
<p>With a flat tensor, I know that I could use <code>tf.foldl</code> or <code>tf.foldr</code>:</p>
<pre class=""lang-py prettyprint-override""><code>flat = tf.reshape(tensor, -1)
tf.foldr(lambda a, x: x if tf.abs(x) &gt; tf.abs(a) else a, flat)
# -6
</code></pre>
<p>However, I don't know how to handle an axis parameter in the case of multidimensional tensors.</p>
",1,Lack of Alternative Solutions/Documentation
525,74060508,How to Save a Tensorflow Dataset,"<p>As the title says I'm trying to save a <code>TensorSliceDataset</code> object to file. Viewing tensorflow's <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">website</a> it seems that the <code>tf.data.Dataset</code> class has a save function but it is not implemented for <code>TensorSliceDataset</code> objects. Pickling also did not work for me.</p>
<p>Example code</p>
<pre><code>import tensorflow as tf
t = tf.range(10)
ds = tf.data.Dataset.from_tensor_slices(t)
ds.save()
</code></pre>
<p>returns error: <code>AttributeError: 'TensorSliceDataset' object has no attribute 'save'</code></p>
",1,Documentation Replicability
526,74088086,Seed in tensorflow initializer (tf.keras.initializers) doesn't guarantees reproducible results,"<p>looking at tensorflow documentation (see, e.g., <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal</a>) a seed should guarantee that &quot;multiple initializers will produce the same sequence when constructed with the same seed value&quot;</p>
<p>The following easy experiment says otherwise</p>
<pre><code>import tensorflow as tf
initializer = tf.keras.initializers.GlorotNormal(seed=123)
values = initializer(shape=(2, 2))
print(values)

initializer1 = tf.keras.initializers.GlorotNormal(seed=123)
values1 = initializer1(shape=(2, 2))
print(values1)
</code></pre>
<p>Giving the output</p>
<pre><code>tf.Tensor(
[[-0.58071285 -0.06369764]
 [ 0.06184607 -1.2040431 ]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[ 0.76186    -0.11021858]
 [-1.1184257  -1.430372  ]], shape=(2, 2), dtype=float32)
</code></pre>
<p>Interesting fact, if I run the python script multiple times I always get the same overall results. So the first seed somehow works, but when it is called a second time in the script it 'keeps advancing', although it should be fixed.</p>
<p>Any opinion about that? Do you think it is a bug? Do you think it is the intended behaviour (if yes could you explain me why)? It may be a problem of my TF installation? I have python 3.7.9 on Windows and Tensorflow version is 2.7.0</p>
<p>Of course, the same behaviour applies when inserting an initializer in a tf.keras.layer</p>
<pre><code>x = tf.constant(6, shape=(2,3))
dense = tf.keras.layers.Dense(units=3, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=123))
dense1 = tf.keras.layers.Dense(units=3, kernel_initializer=tf.keras.initializers.GlorotNormal(seed=123))
print(dense(x), '\n', dense1(x))
</code></pre>
<p>giving</p>
<pre><code>tf.Tensor(
[[14.365635   3.3581433 -1.2498709]
 [14.365635   3.3581433 -1.2498709]], shape=(2, 3), dtype=float32)
 tf.Tensor(
[[10.644517  8.859441  5.136632]
 [10.644517  8.859441  5.136632]], shape=(2, 3), dtype=float32)
</code></pre>
<p>Thanks in advance for your time!</p>
",1,Documentation Replication on Other Examples
527,74182037,"How to ""update"" from module tf.keras.preprocessing.image to tf.keras.utils.image_dataset_from_directory for features extraction","<p>This code part is common to both &quot;problematic&quot; codes below:</p>
<pre><code>BATCH_SIZE = 32
IM_DIR = '/content/drive/My Drive/101_ObjectCategories/'
IM_HEIGHT = 224
IM_WIDTH = 224
NUM_IM = 8686
NUM_EPOCHS = int(math.ceil(NUM_IM / BATCH_SIZE))

#load pre-trained base model
model = ResNet50(weights='imagenet',
                 include_top=False,
                 input_shape=(IM_WIDTH, IM_HEIGHT, CH),
                 pooling='max')
</code></pre>
<p>The following code I successfully use to extract features of a set of images using module <code>tf.keras.preprocessing.image</code>.</p>
<pre><code>datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)
dataset = datagen.flow_from_directory(IM_DIR,
                                      target_size=(IM_HEIGHT, IM_WIDTH),
                                      class_mode=None,
                                      shuffle=False)

feature_list = []
feature_list = model.predict(dataset, num_epochs)
</code></pre>
<p>Thereafter I train a simple nearest-neighbor model using brute-force algorithm and I'm able to find three other images that are really similar to the query image as you can see below:</p>
<p><a href=""https://i.stack.imgur.com/qPi7q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qPi7q.png"" alt=""Right results"" /></a></p>
<p>But as pointed in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image"" rel=""nofollow noreferrer"">documentation</a> this preprocessing module is deprecated.<br />
So, I would like to &quot;update&quot; the code as suggested in the documentation: &quot;Prefer loading data with <code>tf.keras.utils.image_dataset_from_directory</code>, and then transforming the output <code>tf.data.Dataset</code> with preprocessing layers&quot;.<br />
For that I'm trying the following:</p>
<pre><code>#load images
dataset = tf.keras.utils.image_dataset_from_directory(
  IM_DIR,
  labels='inferred', #'inferred', None
  label_mode='categorical',  #'int', 'categorical', 'binary' or None
  class_names=None,
  color_mode='rgb',  #'grayscale', 'rgb' or 'rgba'
  batch_size=BATCH_SIZE,
  image_size=(IM_HEIGHT, IM_WIDTH),
  shuffle=True,
  seed=51719,
  validation_split=None,
  subset=None,                #'training', 'validation' or 'both'
  interpolation='bilinear',   #'bilinear', 'nearest', 'bicubic', 'area', 'lanczos3', 'lanczos5', 'gaussian' or 'mitchellcubic'
  follow_links=False,
  crop_to_aspect_ratio=False
)

#&quot;transforming the output with preprocessing layers&quot;
#rescale (normalize) dataset
rescale_layer = tf.keras.layers.Rescaling(1./255)

rescaled_dataset = dataset.map(lambda x, y: (rescale_layer(x), y))
im_batch, labels_batch = next(iter(rescaled_dataset))


#configure dataset for performance
#https://www.tensorflow.org/tutorials/load_data/images#configure_the_dataset_for_performance

AUTOTUNE = tf.data.AUTOTUNE
tuned_dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)
</code></pre>
<p>And now I begin with the features extraction</p>
<pre><code>#features extraction
#https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict
feature_list = []

feature_list = model.predict(
    tuned_dataset,
    batch_size=None,
    verbose='auto',
    steps=None,
    callbacks=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False
)

#save features
pickle.dump(
    feature_list,
    open(DATA_DIR + 'features.pickle', 'wb'))
</code></pre>
<p>After that I do the same and train the nearest neighbor model with this features, but the results are catastrophic as you can see below:</p>
<p><a href=""https://i.stack.imgur.com/18Wsa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/18Wsa.png"" alt=""Bad results"" /></a></p>
<p>What I'm doing so wrong that I have such different results?</p>
<p><strong>== EDIT 1 ==</strong></p>
<p>Answering @DWKOT using the same image we have following results:</p>
<pre><code>#Query image with first code
im_idx = 75
distances, indices = neighbors.kneighbors([feature_list[im_idx]])
plt.imshow(mpimg.imread(filenames[im_idx]), interpolation='lanczos')
</code></pre>
<p><a href=""https://i.stack.imgur.com/V7EdQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/V7EdQ.png"" alt=""Query image"" /></a></p>
<pre><code>#Similar image
plt.imshow(mpimg.imread(filenames[indices[0][1]]), interpolation='lanczos')
</code></pre>
<p><a href=""https://i.stack.imgur.com/UfUG8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UfUG8.png"" alt=""Similar image"" /></a></p>
<p>And the code that give us the distance to the 5 nearest neighbors:</p>
<pre><code>for i in range(5):
    print(distances[0][i])
</code></pre>
<p>With the following results:</p>
<pre><code>0.0
185.60701
185.75049
195.71657
196.4056
</code></pre>
<p>With the second code we have following result for query / similar image:</p>
<p><a href=""https://i.stack.imgur.com/V7EdQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/V7EdQ.png"" alt=""Query image"" /></a> / <a href=""https://i.stack.imgur.com/lW4n1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lW4n1.png"" alt=""Similar image 2"" /></a></p>
<p>And following results for the first five &quot;similar&quot; images:</p>
<pre><code>0.0
0.81401
0.88622
0.92734
0.9346
</code></pre>
<p>What is also strange as I would expect similar images having values next to zero and different ones far from zero...</p>
",1,Documentation Replication on Other Examples
528,74434308,Setting only global level seed gives same output in consecutive iterations of loop in Tensorflow,"<p>I am testing out the <code>tf.random.set_seed</code> according to the rules given at - <a href=""https://www.tensorflow.org/api_docs/python/tf/random/set_seed"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/random/set_seed</a></p>
<p>In particular I am testing the second rule - where we set only global level seed and no operation level seed.</p>
<p>According to the documentation (the link is mentioned above), the second rule is:</p>
<blockquote>
<p>If the global seed is set, but the operation seed is not: The system deterministically picks an operation seed in conjunction with the global seed so that it gets a unique random sequence.</p>
</blockquote>
<p>To explain the second rule, the documentation uses the following snippet:</p>
<pre><code>tf.random.set_seed(1234)
print(tf.random.uniform([1]))  # generates 'A1'
print(tf.random.uniform([1]))  # generates 'A2'
</code></pre>
<p>and states that</p>
<blockquote>
<p>The reason we get 'A2' instead 'A1' on the second call of tf.random.uniform above is because the second call uses a different operation seed.</p>
</blockquote>
<p>Now, I tested this rule on a 1D tensor of shape (3,) to check if the output of shuffling the tensor does not give the same sequence within consecutive iterations of the loop as follows:</p>
<pre><code>import tensorflow as tf


&quot;&quot;&quot;
Only global level seed
&quot;&quot;&quot;

tf.random.set_seed(1234)
   
constant_tensor = tf.constant([1,2,3])

for i in range(1, 15):
    shuffled_tensor = tf.random.shuffle(constant_tensor)
    print(shuffled_tensor)
</code></pre>
<p>I got the following output:</p>
<pre><code>tf.Tensor([3 1 2], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([1 3 2], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([2 3 1], shape=(3,), dtype=int32)
tf.Tensor([2 1 3], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([1 2 3], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
tf.Tensor([3 2 1], shape=(3,), dtype=int32)
</code></pre>
<p>From the output you can see that the sequence on line number 7 and 8 match.
Also the sequence on line number 13 and 14 match.</p>
<p>According to the documentation, tensorflow should not output the same sequence in a consecutive iteration.</p>
<p>Then why am I getting this kind of output? Have I misunderstood the concept?</p>
<p>To test this further, I also tested to following snippet which I used to generate 14 1-D tensors and check if any tensor is repeated within consecutive runs as follows:</p>
<pre><code>import tensorflow as tf
tf.random.set_seed(1234)
for i in range(1, 15):
    print(tf.random.uniform(shape=[1], minval=1, maxval=15, dtype=tf.int32))
</code></pre>
<p>And I got the following output:</p>
<pre><code>tf.Tensor([12], shape=(1,), dtype=int32)
tf.Tensor([8], shape=(1,), dtype=int32)
tf.Tensor([1], shape=(1,), dtype=int32)
tf.Tensor([2], shape=(1,), dtype=int32)
tf.Tensor([4], shape=(1,), dtype=int32)
tf.Tensor([3], shape=(1,), dtype=int32)
tf.Tensor([2], shape=(1,), dtype=int32)
tf.Tensor([7], shape=(1,), dtype=int32)
tf.Tensor([13], shape=(1,), dtype=int32)
tf.Tensor([11], shape=(1,), dtype=int32)
tf.Tensor([8], shape=(1,), dtype=int32)
tf.Tensor([3], shape=(1,), dtype=int32)
tf.Tensor([1], shape=(1,), dtype=int32)
tf.Tensor([4], shape=(1,), dtype=int32)
</code></pre>
<p>You can see that no two consecutive tensors are repeated. Why didn't I see this behaviour for my first snippet?</p>
",1,Documentation Ambiguity
529,74545053,Is there an equivalent of tf.gradients function in tensorflow C or C++ API?,"<p>I want to implement a tensorflows function <a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""nofollow noreferrer"">tf.gradients</a> in C or C++ API? Tensorflow C++ has the <a href=""https://www.tensorflow.org/api_docs/cc"" rel=""nofollow noreferrer"">worst documentation</a> in the world and C API aren't documented at all. Can you suggest if there is an implementation or which API parts should I use to develop this myself.</p>
",1,Documentation Completeness
530,75136950,How to visualize tf.compat.v1 static graph in tensorboard?,"<p>For a given graph, how can we visualize the graph using tensorboard for tf.compat.v1 ?
Sharing this here after searching everywhere. Most of the documentations explains tf.keras and not for tf.compat.v1 static graphs</p>
",1,Documentation Replication on Other Examples
531,75371111,"when trying to load external tfrecord with TFDS, given tf.train.Example, how to get tfds.features?","<p><strong>What I need help with / What I was wondering</strong></p>
<p>Hi, I am trying to load external tfrecord files with TFDS. I have read the official doc <a href=""https://www.tensorflow.org/datasets/external_tfrecord"" rel=""nofollow noreferrer"">here</a>, and find I need to define the feature structure using <code>tfds.features</code>. However, since the tfrecords files are alreay generated, I do not have control the generation pipeline. I do, however, know the <code>tf.train.Example</code> structre used in <code>TFRecordWriter</code> during generation, shown as follows.</p>
<pre><code>from tensorflow.python.training.training import BytesList, Example, Feature, Features, Int64List

dict(Example=Features({
'image': Feature(bytes_list=BytesList(value=[img_str])), # img_str is jpg encoded image raw bytes
'caption': Feature(bytes_list=BytesList(value=[caption])), # caption is a string
'height': Feature(bytes_list=Int64List(value=[caption])), 
'width': Feature(bytes_list=Int64List(value=[caption])), 
})
</code></pre>
<p>The doc only describes how to translate <a href=""https://www.tensorflow.org/datasets/api_docs/python/tfds/features"" rel=""nofollow noreferrer"">tfds.features</a> into the human readable structure of the <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Example"" rel=""nofollow noreferrer"">tf.train.Example</a>. But nowhere does it mention how to translate a tf.train.Example into tfds.features, which is needed to automatically add the proper metadata fileswith <a href=""https://www.tensorflow.org/datasets/api_docs/python/tfds/folder_dataset/write_metadata"" rel=""nofollow noreferrer"">tfds.folder_dataset.write_metadata</a>.</p>
<p>I wonder how to translate the above tf.train.Example into tfds.features? Thanks a lot!</p>
<p>BTW, while I understand that it is possible to directly read the data as it is in TFRecord with <code>tf.data.TFRecordDataset</code> and then use <code>map(decode_fn)</code> for decoding as suggested <a href=""https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset"" rel=""nofollow noreferrer"">here</a>, it seems to me this approach lacks necessary metadata like <code>num_shards</code> or <code>shard_lengths</code>. In this case, I am not sure if it is still ok to use common operations like <code>cache/repeat/shuffle/map/batch</code> on that <code>tf.data.TFRecordDataset</code>. So I think it is better to stick to the tfds approach.</p>
<p><strong>What I've tried so far</strong></p>
<p>I have searched the official doc for quite some time but cannot find the answer. There is a <code>Scalar</code> class in <code>tfds.features</code>, which I assume could be used to decode <code>Int64List</code>. But How can I decode the <code>BytesList</code>?</p>
<p><strong>Environment information</strong></p>
<ul>
<li><code>tensorflow-datasets</code> version: 4.8.2</li>
<li><code>tensorflow</code> version: 2.11.0</li>
</ul>
",1,Documentation Completeness
532,75572543,What to look out for when passing a generator into model.fit in tensorflow?,"<p>I want to replace the x and y training data parameters in tf.keras.Model.fit with a generator. However, some subtlety seems to escape me, as the model accuracy doesn't improve with the generator when training.</p>
<p>As far as I understand the documentation, the generator is supposed to yield tuples <code>(x_vals,y_vals)</code>, such that <code>x_vals</code> is a concatenation of <code>batch_size</code>-many training samples along a new 0th dimension, and 'v_vals' is the concatenation of their corresponding labels.</p>
<p>As long as the generator fulfills this, as I understand it, we can just replace the x parameter in tf.keras.Model.fit with the generator and omit the y parameter, though to define an epoch, we also need to specify 'steps_per_epoch' in fit.</p>
<p>There however seems to be something here I misunderstood or forgot, because starting with a model and input data that trains (i.e. its accuracy improves) and replacing the training data array with a generator as discussed, results in a model that doesn't train (i.e. its accuracy instead goes up a little, then however goes back down till its equal to chance).</p>
<p>The corresponding code:</p>
<pre><code>import numpy as np
import tensorflow as tf

BATCH_SIZE = 32

#Loading training data:
def load_cifar():
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
    assert x_train.shape == (50000, 32, 32, 3)
    assert x_test.shape == (10000, 32, 32, 3)
    assert y_train.shape == (50000, 1)
    assert y_test.shape == (10000, 1)

    #Normalize the data &amp; cast to fp32:
    x_train = np.true_divide(x_train,255,dtype=np.single)
    x_test =  np.true_divide(x_test,255,dtype=np.single)
    y_train = y_train.astype(np.single)
    y_test =  y_test.astype(np.single)

    return (x_train,y_train), (x_test,y_test)


(train_x, train_y) , (validation_x, validation_y) = load_cifar()
   


# Defining the generator:
def data_generator_dummy(input_data_x:np.ndarray,
                          input_data_y:np.ndarray,
                          batch_size=BATCH_SIZE,
                          ):
    &quot;&quot;&quot;
    Given the input_data's, generate infinitely by:
     1. Drawing batch_size-many vectors from input_data_x and input_data_y
     2. Turn the drawn vectors into a mini-batch (with shape  [None]+input_data.shape)

    :param batch_size:
    :param input_data_x, input_data_y: The data on which noise shall be added
    :return: A generator for the input data.
    &quot;&quot;&quot;
    index =0
    while True:
        # We start with a zero-vector of expected size and fill the drawn samples into it:
        samples_x = np.zeros( [batch_size] + list(input_data_x.shape[1:]),dtype=np.single)
        samples_y = np.zeros( [batch_size] + list(input_data_y.shape[1:]),dtype=np.single)
        for i in range(batch_size):
            samples_x[i] = input_data_x[index%50_000]
            samples_y[i] = input_data_y[index%50_000]
            index +=1

        yield samples_x,samples_y

# Basically a linear classifier:
def make_model():
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(10,tf.nn.softmax))
    model.build([None] +list(train_x[0,:,:,:].shape))
    return model


#Training:
generator = data_generator_dummy(train_x,train_y,batch_size=BATCH_SIZE)
model = make_model()
model.summary()
optimizer_adam=tf.keras.optimizers.Adam(learning_rate=0.0005/32,beta_1=0.9,beta_2=0.999,epsilon=1e-07)
model.compile(optimizer_adam,loss=&quot;sparse_categorical_crossentropy&quot;,metrics=&quot;accuracy&quot;)
model.fit(generator, validation_data=(validation_x,validation_y),epochs=10,
          steps_per_epoch=train_x.shape[0]//BATCH_SIZE,
          )

# This one however works:
# model.fit(train_x, train_y, validation_data=(validation_x,validation_y),epochs=30,
#           steps_per_epoch=train_x.shape[0]//BATCH_SIZE,
#           shuffle=True
#           )
</code></pre>
<hr />
<p>The model also trains if one first let's the generator generate a long list of samples and then passes those into <code>fit</code> as <code>x</code>and <code>y</code>:</p>
<pre><code>#Training:
generator = data_generator_dummy(train_x,train_y,batch_size=50000)
model = make_model()
model.summary()
optimizer_adam=tf.keras.optimizers.Adam(learning_rate=0.0005/32,beta_1=0.9,beta_2=0.999,epsilon=1e-07)
model.compile(optimizer_adam,loss=&quot;sparse_categorical_crossentropy&quot;,metrics=&quot;accuracy&quot;)
while True:
    samples_x,samples_y = next(generator)
    model.fit(samples_x,samples_y, validation_data=(validation_x,validation_y),epochs=10,batch_size=BATCH_SIZE
          )
</code></pre>
",1,Documentation Replication on Other Examples
533,75639137,TF1 to TF2 migration,"<p>Hello I am new to tensorflow and I am working on a code that I would like to migrate from tensorflow 1 to 2. I have this line of code:</p>
<pre><code>x1 = tf.compat.v1.placeholder(tf.float32, [], name=&quot;x1&quot;)
</code></pre>
<p>As mentioned in <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder</a>, I should use <code>keras.Input</code>. But even when specifying the shape, I can't have the same tensor as with compat.v1:</p>
<pre><code>x2 = tf.keras.Input(shape=[], dtype=tf.float32, name=&quot;x2&quot;)
</code></pre>
<p>To check the shape I use <code>tf.shape(x1)</code> or <code>tf.shape(x2)</code>, but the shapes are not the same. Could anyone explain to me how to have, in TF2, the same shape as in TF1 ?
Thanks and regards</p>
",1,Documentation Replicability
534,75851842,tensorflow map function to mulitple tensors,"<p>I am using the following function in a custom layer in TensorFlow to rearrange query, key values:</p>
<pre><code>q, k, v = map(lambda t: rearrange(t, 'b n (h d) -&gt; b h n d', h = self.heads), (q, k, v)) 
</code></pre>
<p>and it throws this warning:</p>
<p><code>WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating: Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089</code></p>
<p>Is there a more TensorFlowic way of doing this?</p>
<p>I tried using map_fn as follows and it throws the the same warning and an error:</p>
<pre><code>import tensorflow as tf
from einops import rearrange
a = tf.random.uniform((1, 196, 196))
b, c, d = tf.map_fn(lambda t: rearrange(t, 'b (h n) d -&gt; b h n d', h=14), [a, a, a])
</code></pre>
<p>From documentation, it seems <code>tf.map_fn</code> but it seems to work on a stack of tensors. Will it be better to stack the tensors?</p>
",1,Documentation Replication on Other Examples
535,75996642,Is there a good equivalent of pandas' `apply` for TensorFlow datasets?,"<p><strong>BACKGROUND</strong></p>
<p>The use of <a href=""https://www.tensorflow.org/guide/data"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code></a> is promoted by TensorFlow as the best practice for implementing input pipelines due to their efficient implementation of common operations such as batching, shuffling, as well as their seamless integration with the Keras API.</p>
<p>I may just be lousy at looking up the documentation on the matter, but it seems to me that the major drawback of TensorFlow datasets is that they are quite unwieldy, if not impossible to work with, when trying to implement feature engineering tasks whereby a new column is created via the application of some generic Python function. This is in contrast to pandas' very nifty <a href=""https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html"" rel=""nofollow noreferrer""><code>apply()</code></a> function which can produce new columns from preexisting ones both efficiently (i.e., via vectorization) and in a pythonic manner.</p>
<p>To the best of my understanding, the closest thing to pandas' <code>apply()</code> is TensorFlow dataset's <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer""><code>map()</code></a>. However, one can't simply use it with arbitrary Python functions since they'd first need to be converted to tensors. This becomes very difficult as one has to have arcane knowledge of the miscellaneous tensor analogues of arbitrary Python functions (e.g., <code>tf.strings.length()</code> instead of Python's <code>len()</code>). Even when one finds such functions, the idiosyncracies of tensor operations makes them very un-pythonic and prone to obscure dimensionality or type errors.</p>
<p>I've read about TensorFlow's <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer""><code>py_function</code></a> as some sort of wrapper that magically converts Pythonic code into a tensor representation, but judging from the documentation, it became clear to me that this is far from the case.</p>
<p><strong>QUESTION</strong></p>
<p>Is TensorFlow's <code>tf.data</code> just not mature yet to be able to handle feature engineering in the same way that pandas <code>apply()</code> does? If not, what am I missing in my understanding?</p>
<p><strong>MINIMUM WORKING EXAMPLE</strong></p>
<p>In the code below, I compare a pandas DataFrame <code>df</code> with the equivalent TensorFlow dataset <code>ds</code>. My goal is to engineer two extra features, namely</p>
<ol>
<li>adding a suffix to the string feature <code>my_string</code>, and</li>
<li>counting the number of time a certain letter appears in any given instance of <code>my_string</code>.</li>
</ol>
<p>As you can see for yourself, the first operation works intuitively for both pandas and TensorFlow, but the second only works easily for pandas. Getting it to work with TensorFlow is either extremely complex, or just plain impossible.</p>
<pre><code>from collections import Counter
import numpy as np
import pandas as pd
import tensorflow as tf

# Create the pandas DataFrame.
df = pd.DataFrame(
    {'index': list(range(5)),
     'my_string': ['Alondra', 'Spaanbiuk', 'Ibinth', 'Liefelle', 'Yoanda'], 
     'some_other_column': np.random.rand(5),
     }).set_index('index')
print('Original pandas DataFrame:')
print(df, '\n')

# Create the TensorFlow dataset and define a function to view it 
# as a pandas DataFrame.
ds = tf.data.Dataset.from_tensors(df.to_dict(orient='list'))
def view_ds(ds):
    data = pd.concat([pd.DataFrame(k) for k in ds.take(5)], axis=0)
    # Convert byte strings to Python strings.
    object_cols = data.select_dtypes([object])
    data[object_cols.columns] = object_cols.stack().str.decode('utf-8').unstack()
    print('TensorFlow dataset:')
    print(data, '\n')
view_ds(ds)

#### Add a suffix to `my_string` as `my_string_with_suffix`.
def add_a_suffix(x):
    x['my_string_with_suffix'] = x['my_string']+'.suffix'
    return x

# Apply to the pandas DataFrame.
print('DataFrame with the suffix:')
df = df.apply(add_a_suffix, axis=1)
print(df, '\n')

# Apply to the TensorFlow dataset.
print('TensorFlow dataset with the suffix:')
ds = ds.map(lambda x: add_a_suffix(x))
view_ds(ds)

#### Count they the number of `a`'s in `my_string`:
def count_letters(x, letter='a'):
    counter = Counter(x['my_string'].lower())
    x[f'{letter}_counts'] = counter[letter]
    return x

# Apply to the pandas DataFrame.
print('DataFrame with the letter count:')
df = df.apply(count_letters, axis=1)
print(df, '\n')
    
# Apply to the TensorFlow dataset.
# HOW BUT HOW?!!
# print('TensorFlow dataset with the letter count:')
# ds = ds.apply(lambda x: count_letters(x))
# view_ds(ds)
</code></pre>
<p>The output is of the above is as follows.</p>
<pre><code>Original pandas DataFrame:
       my_string  some_other_column
index                              
0        Alondra           0.209685
1      Spaanbiuk           0.972315
2         Ibinth           0.933700
3       Liefelle           0.186369
4         Yoanda           0.667436 

TensorFlow dataset:
   my_string  some_other_column
0    Alondra           0.209685
1  Spaanbiuk           0.972315
2     Ibinth           0.933700
3   Liefelle           0.186369
4     Yoanda           0.667436 

DataFrame with the suffix:
       my_string  some_other_column my_string_with_suffix
index                                                    
0        Alondra           0.209685        Alondra.suffix
1      Spaanbiuk           0.972315      Spaanbiuk.suffix
2         Ibinth           0.933700         Ibinth.suffix
3       Liefelle           0.186369       Liefelle.suffix
4         Yoanda           0.667436         Yoanda.suffix 

TensorFlow dataset with the suffix:
TensorFlow dataset:
   my_string  some_other_column my_string_with_suffix
0    Alondra           0.209685        Alondra.suffix
1  Spaanbiuk           0.972315      Spaanbiuk.suffix
2     Ibinth           0.933700         Ibinth.suffix
3   Liefelle           0.186369       Liefelle.suffix
4     Yoanda           0.667436         Yoanda.suffix 

DataFrame with the letter count:
       my_string  some_other_column my_string_with_suffix  a_counts
index                                                              
0        Alondra           0.209685        Alondra.suffix         2
1      Spaanbiuk           0.972315      Spaanbiuk.suffix         2
2         Ibinth           0.933700         Ibinth.suffix         0
3       Liefelle           0.186369       Liefelle.suffix         0
4         Yoanda           0.667436         Yoanda.suffix         2 
</code></pre>
",1,Documentation Ambiguity
536,76012810,Unable to extract output probability array using Tensorflow for JS,"<p>New to Javascript/Typescript + ML libs. Created a quick TS code snippet to test out the TensorFlow lib. I am stuck at a point where I am not able to extract the probability array and then choose the max from the output.</p>
<p>In the last iteration I have here, I am using data() function but it does not compile giving this error:</p>
<pre><code>Property 'data' does not exist on type 'Tensor&lt;Rank&gt; | Tensor&lt;Rank&gt;[]'.
  Property 'data' does not exist on type 'Tensor&lt;Rank&gt;[]'.ts(2339)
</code></pre>
<p>Even though input is of the type tf.Tensor and according to the docs <a href=""https://js.tensorflow.org/api/latest/#tf.Tensor.data"" rel=""nofollow noreferrer"">here</a>, it should work.</p>
<p>I am definitely missing some thing here. I am tried going through other examples, but it seems like TensorFlow has a lot to offer and I did not come across anything that would be useful in my case.</p>
<p>I feel I need help with these 3 lines here:</p>
<pre><code>const output = await net.predict(input).data();  
  const predictedPortfolio = Object.keys(portfolios)[output.indexOf(Math.max(...output))];
  return predictedPortfolio;
</code></pre>
<p>Code snippet</p>
<pre><code>import * as tf from '@tensorflow/tfjs';

interface FinancialInformation {
  age: number;
  riskTolerance: number;
  currentNetWorth: number;
  annualIncome: number;
  debt: number;
}

interface Portfolios {
  [key: string]: string[];
}

// Define the investment portfolios
const portfolios: Portfolios = {
  conservative: ['bonds', 'real estate'],
  balanced: ['stocks', 'bonds', 'real estate', 'commodities'],
  aggressive: ['stocks', 'commodities', 'crypto'],
};

export async function generateSuggestion(financialInfo: FinancialInformation): Promise&lt;string&gt; {
  // Define the neural network
  const net = tf.sequential({
    layers: [
      tf.layers.dense({ inputShape: [5], units: 10, activation: 'sigmoid' }),
      tf.layers.dense({ units: 10, activation: 'sigmoid' }),
      tf.layers.dense({ units: 3, activation: 'softmax' }),
    ],
  });

  // Train the neural network
  const trainingData = tf.tensor2d([
    [25, 2, 100000, 60000, 0],
    [30, 4, 150000, 80000, 20000],
    [40, 6, 200000, 100000, 50000],
    [50, 8, 300000, 120000, 100000],
    [60, 10, 400000, 150000, 150000],
  ]);

  const outputData = tf.tensor2d([
    [1, 0, 0],
    [0, 1, 0],
    [0, 0, 1],
    [0, 0, 1],
    [0, 0, 1],
  ]);

  const options = {
    epochs: 500,
    learningRate: 0.3,
  };

  net.compile({ optimizer: tf.train.adam(), loss: 'categoricalCrossentropy' });

  await net.fit(trainingData, outputData, options);

  // Use the neural network to generate a suggestion
  const input = tf.tensor2d([
    [financialInfo.age, financialInfo.riskTolerance, financialInfo.currentNetWorth, financialInfo.annualIncome, financialInfo.debt],
  ]) as tf.Tensor;

  const output = await net.predict(input).data();  
  const predictedPortfolio = Object.keys(portfolios)[output.indexOf(Math.max(...output))];
  return predictedPortfolio;
}
</code></pre>
",1,Lack of Alternative Solutions/Documentation
537,76040030,Problem using Huggingface imagenet-1k dataset in Keras / Tensorflow,"<p>I'm having a problem using the imagenet-1k dataset from Huggingface with a Keras model. I'm just experimenting with simple models, but am stuck trying to get the dataset to work with the model fit function.</p>
<p>Here is how I load the dataset:</p>
<pre><code>ds = load_dataset('imagenet-1k')  # loads a DatasetDict
ds_train = ds['train']  # get a Dataset
ds_train.set_format(type='tensorflow', columns=['image'])  # convert to tf tensor
ds_val = ds['validation']  # get a Dataset
ds_val.set_format(type='tensorflow', columns=['image'])  # convert to tf tensor
</code></pre>
<p>Here is the fit invocation:</p>
<pre><code># train the autoencoder
autoencoder.fit(ds_train, ds_train,
                epochs=10,
                shuffle=True,
                validation_data=(ds_val, ds_val))
</code></pre>
<p>I get the following error:</p>
<pre><code>ValueError: Failed to find data adapter that can handle input: &lt;class 'datasets.arrow_dataset.Dataset'&gt;, &lt;class 'datasets.arrow_dataset.Dataset'&gt;
</code></pre>
<p>When I inspect one of the elements of the datasets it looks like a tf.Tensor, so I don't understand why it can't be passed directly. None of the examples or docs I can find make it clear how to do this. Huggingface <a href=""https://huggingface.co/docs/datasets/v2.11.0/en/use_with_tensorflow"" rel=""nofollow noreferrer"">examples</a> for images produce the same format that I'm getting, but apparently there is a step I'm missing before it can be used with model.fit()</p>
",1,Documentation Replication on Other Examples
538,76153107,Difference between tf.Module and tf.keras.Model,"<p>I know both <code>tf.Module</code> and <code>tf.keras.Model</code> are used for building custom models.
But what's the difference between both of them?
Which one should be used when becuase there usage looks similar as shown in tensorflow docs?</p>
",1,Documentation Ambiguity
539,76244268,Tensorflow: Build new model from input and middle layers of another model,"<p>I'm trying to build <code>new_model</code> from another model layers for class activation mapping purposes.</p>
<pre class=""lang-py prettyprint-override""><code>def vgg_sequential():
    input_shape = IMG_SIZE + (3,)
    model = Sequential()
    model.add(tf.keras.applications.vgg16.VGG16(input_shape=input_shape, include_top=False, weights='imagenet'))
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(1))
    return model
</code></pre>
<pre class=""lang-py prettyprint-override""><code>cam_model = tf.keras.Model(inputs=seq_vgg.layers[0].input, outputs=(seq_vgg.layers[-3].output, seq_vgg.layers[-1].output))
</code></pre>
<p>And with this code i get the following error:</p>
<pre><code>ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 480, 480, 3), dtype=tf.float32, name='vgg16_input'), name='vgg16_input', description=&quot;created by layer 'vgg16_input'&quot;) at layer &quot;vgg16&quot;. The following previous layers were accessed without issue: ['block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1']
</code></pre>
<p>Already tried functional model API, providing <code>Input()</code> layer inside <code>vgg_sequential()</code> with the same error that my Input layer is disconected from the rest of my model. Beside this when using <code>tf.keras.applications.efficientnet_v2</code> that provides input layers for rescaling and resizing images i don't have any problem.</p>
<p>Any help, information, tips or links to docs that getas me to a solution will be very much appreciated.</p>
<p>Thanks in advance.</p>
",1,Inadequate Examples
540,76324368,Understanding tf.keras.layers.Dense(),"<p>I am trying to understand why there is a difference between calculating a dense layer operation directly and using the <code>keras</code> implementation.</p>
<p>Following the documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense</a>) <code>tf.keras.layers.Dense()</code> should implement the operation <code>output = activation(dot(input, kernel) + bias)</code> but <code>result</code> and <code>result1</code> below are not the same.</p>
<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(5,10)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<p>output</p>
<pre class=""lang-py prettyprint-override""><code>
[[2.87080455]
 [3.25458574]
 [3.28776264]
 [3.14319134]
 [2.04760242]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]

</code></pre>
<p>Using <code>test.get_weights()</code> I can see that the kernel and bias (<code>b</code>) are getting set to the correct values. I am using TF version 2.12.0.</p>
",1,Documentation Replication on Other Examples
541,76380927,Tensorflow decode image,"<p>I am a beginner in tensorflow and I am training a small cnn, I am using the tf.io.decode_image function but I can't figure out if this function does preprocess.
The tensorflow documentation about it doesn't say anything.
When I open images with this function the values are between 0 and 1.
The images are single channel grayscale.
This is the code.</p>
<pre><code>def decode_img(self, imgs, channels):
        # Convert the compressed string to a 3D uint8 tensor
        images = []
        for element in imgs:

            dec_image = tf.io.decode_image(element, channels=channels, dtype=tf.float32)
            try:
                img = keras.utils.img_to_array(dec_image)
            except AttributeError:
                img = keras.preprocessing.image.img_to_array(dec_image)
            images.append(img)
        images = np.array(images)
        return images
</code></pre>
<p>I would like to have more explanations</p>
",1,Requesting (Additional) Documentation/Examples
542,76391276,Custom gradient for broadcasting operation,"<p>I have an operation for which I want to define a custom gradient with <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer""><code>tf.custom_gradient</code></a>. The operation takes two broadcastable arguments and produces a result with the broadcasted shape. The problem is how to handle the broadcasting rules &quot;backwards&quot; in the custom gradient. Let's take the example for a multiplication operation from the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer""><code>tf.custom_gradient</code></a>:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

@tf.custom_gradient
def bar(x, y):
  def grad(upstream):
    dz_dx = y
    dz_dy = x
    return upstream * dz_dx, upstream * dz_dy
  z = x * y
  return z, grad
</code></pre>
<p>I can use this gradient alright for the non-broadcasting case:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.GradientTape() as tape:
    a = tf.ones([5])
    b = tf.ones([5])
    tape.watch([a, b])
    c = bar(a, b)
# Works fine
grad_a, grad_b = tape.gradient(c, [a, b])
</code></pre>
<p>However, when the inputs are broadcasted, the result is not correct:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.GradientTape() as tape:
    a = tf.ones([10, 1])
    b = tf.ones([5])
    tape.watch([a, b])
    c = bar(a, b)
grad_a, grad_b = tape.gradient(c, [a, b])
print(grad_a.shape, grad_b.shape)
# (10, 5) (10, 5)
</code></pre>
<p>In fact, trying to use it in graph mode fails:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

with tf.Graph().as_default():
    a = tf.ones([10, 1])
    b = tf.ones([5])
    c = bar(a, b)
    grad_a, grad_b = tf.gradients(c, [a, b])
# ValueError: Incompatible shapes between op input and calculated input gradient.
</code></pre>
<p>Is there a way to handle this &quot;unbroadcasting&quot; of the input gradients automatically?</p>
",1,Documentation Ambiguity
543,76396532,"Ragged tensors in dataset, tensorflow, how do I train the model","<p>I have</p>
<pre><code>def call (self, inputs):
    context, x = inputs
</code></pre>
<p>in my model, for fitting,
and my dataset contains ragged tensors, basically context and x are ragged tensor, of variable length, everything I try gives me some sort of error, for example<br> first I tried <code>[ [ context, x], ...]</code> where all the arrays were <code>np.ndarray</code>, but it said something along the lines that <code>np.ndarray</code> is an unrecognised datatype and cannot be converted to a <code>tf.Tensor</code>.<br>Then when I tried putting this in a tf.data.Dataset, it says <code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor).</code><br>
I am totally lost on how to train my model</p>
<p>I tried several different data types from list, to tf.data.Dataset, but none of them were working, and now I am totally in the dark. Consulting the documentation has not helped me figure out how does the fit function actually treat data</p>
",1,Documentation Replicability
544,76444107,Are 'validation_steps' used if the validation_dataset is 'DirectoryIterator'?,"<p>I was trying to use the Keras API to train a given model by using its <a href=""https://keras.io/api/models/model_training_apis/"" rel=""nofollow noreferrer"">fit</a> function. In its documentation we can see the following:</p>
<blockquote>
<p>validation_steps: Only relevant if validation_data is provided and is
a tf.data dataset. Total number of steps (batches of samples) to draw
before stopping when performing validation at the end of every epoch.
If 'validation_steps' is None, validation will run until the
validation_data dataset is exhausted. In the case of an infinitely
repeated dataset, it will run into an infinite loop. If
'validation_steps' is specified and only part of the dataset will be
consumed, the evaluation will start from the beginning of the dataset
at each epoch. This ensures that the same validation samples are used
every time.</p>
</blockquote>
<p>By reading the above text I understand that if the <code>validation_data</code> is not a tf.data dataset the validation_steps is ignored. However I am not sure if in my case this principle is applied. I am using an <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"" rel=""nofollow noreferrer"">ImageDataGenerator</a> to then use its <code>flow_from_directory</code> function that returns a DirectoryIterator. In its documentation we can see the following:</p>
<blockquote>
<p>A DirectoryIterator yielding tuples of (x, y) where x is a numpy array
containing a batch of images with shape (batch_size, *target_size,
channels) and y is a numpy array of corresponding labels.</p>
</blockquote>
<p>So, by reading this I am convinced that the whole validation dataset is going to be used despite the fact that validation_steps might be set to a given number. Is there a way I can check whether it is using the whole dataset or only the given <code>validation_steps</code>? Does it simply ignore the <code>validation_steps</code> because the <code>validation_data</code> is not a tf.data and therefore there is no need to check it?</p>
<p>Thanks!</p>
<p>Code example of usage:</p>
<pre><code># model building and whatnot
# (...)
img_val = r'/content/drive/MyDrive/validation'
validation = ImageDataGenerator()
val_dataset = validation.flow_from_directory(img_val,
                                          target_size=(224, 224),
                                          batch_size=32,
                                          class_mode='categorical')

model.fit(train_dataset, validation_data=val_dataset, epochs=1000, steps_per_epoch=1875, validation_steps=375  
</code></pre>
<p>PS: I know that we can let <code>validation_steps</code> be <code>None</code> to use it fully for validating the model in each epoch. My question is especifically if the <code>validation_steps</code> parameter is ignored or not if provided while using data from a ImageDataGenerator.</p>
",1,Documentation Replication on Other Examples
545,76447508,How to retrain a model that was saved using the tf.saved_model.save() function in Tensorflow,"<p>I am building a Neural Machine Translator for English to Konkani (a local language) language using the Transformer architecture proposed by (Vaswani et, al. 2017). I am following the tutorial code from <a href=""https://www.tensorflow.org/text/tutorials/transformer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/text/tutorials/transformer</a>. I have trained the model and used the <code>tf.saved_model.save()</code> method to save the model files locally.</p>
<p>I now want to retrain that saved model on a new dataset that I have gathered recently, but I've realised that after loading the model using the <code>tf.saved_model.load()</code> method, I am not able to train it again as the loaded model now lacks the necessary method <code>model.fit()</code> .</p>
<p>Here is a part of the model training code:</p>
<pre class=""lang-py prettyprint-override""><code>class Transformer(tf.keras.Model):
  def __init__(self, *, num_layers, d_model, num_heads, dff,
               input_vocab_size, target_vocab_size, dropout_rate=0.1):
    super().__init__()
    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=input_vocab_size,
                           dropout_rate=dropout_rate)

    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=target_vocab_size,
                           dropout_rate=dropout_rate)

    self.final_layer = tf.keras.layers.Dense(target_vocab_size)

  def call(self, inputs):
    # To use a Keras model with `.fit` you must pass all your inputs in the
    # first argument.
    context, x  = inputs

    context = self.encoder(context)  # (batch_size, context_len, d_model)

    x = self.decoder(x, context)  # (batch_size, target_len, d_model)

    # Final linear layer output.
    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)

    try:
      # Drop the keras mask, so it doesn't scale the losses/metrics.
      # b/250038731
      del logits._keras_mask
    except AttributeError:
      pass

    # Return the final output and the attention weights.
    return logits
#-----------------------------------------------------------------------

#...&lt;code to define optimizers and loss functions&gt;...

# This Class acts as an interface for the Transformer
class Translator(tf.Module):
  def __init__(self, context_tokenizers, target_tokenizers, transformer):
    self.context_tokenizers = context_tokenizers
    self.target_tokenizers = target_tokenizers
    self.transformer = transformer

  def __call__(self, sentence, max_length=MAX_TOKENS): #max_length=MAX_TOKENS
    assert isinstance(sentence, tf.Tensor)
    if len(sentence.shape) == 0:
      sentence = sentence[tf.newaxis]

    sentence = tokenize(sentence,self.context_tokenizers).to_tensor()

    encoder_input = sentence

    # As the output language is English, initialize the output with the
    # English `[START]` token.

    start_end = tokenize('',self.target_tokenizers)[0]
    start = start_end[0][tf.newaxis]
    end = start_end[-1][tf.newaxis]

    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)
    output_array = output_array.write(0, start)

    for i in tf.range(max_length):
      output = tf.transpose(output_array.stack())
      predictions = self.transformer([encoder_input, output], training=False)

      # Select the last token from the `seq_len` dimension.
      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.

      predicted_id = tf.argmax(predictions, axis=-1)

      # Concatenate the `predicted_id` to the output which is given to the
      # decoder as its input.
      output_array = output_array.write(i+1, predicted_id[0])

      if predicted_id == end:
        break

    output = tf.transpose(output_array.stack())
    # The output shape is `(1, tokens)`.

    text = self.target_tokenizers.detokenize(output)

    tokens = tf.gather(target_vocab, output)

    # `tf.function` prevents us from using the attention_weights that were
    # calculated on the last iteration of the loop.
    # So, recalculate them outside the loop.
    self.transformer([encoder_input, output[:,:-1]], training=False)
    attention_weights = self.transformer.decoder.last_attn_scores

    joined_text = tf.strings.reduce_join(text[0][1:-1], separator=' ', axis=-1)
    return joined_text, tokens, attention_weights
#-----------------------------------------------------------------------

class ExportTranslator(tf.Module):
  def __init__(self, translator):
    self.translator = translator

  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
  def __call__(self, sentence):
    (result,
     tokens,
     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)

    return result
#-----------------------------------------------------------------------

transformer = Transformer(
    num_layers=num_layers,
    d_model=d_model,
    num_heads=num_heads,
    dff=dff,
    input_vocab_size=context_vocab_size,
    target_vocab_size=target_vocab_size,
    dropout_rate=dropout_rate)

transformer.compile(
    loss=masked_loss,
    optimizer=optimizer,
    metrics=[masked_accuracy])

# training the model on the training data for some epochs
transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )

translator = Translator(context_tokenizer, target_tokenizer, transformer)

exp_translator = ExportTranslator(translator)

#saving the model
tf.saved_model.save(exp_translator, export_dir=MODEL_SAVED_FILES)

#-----------------------------------------------------------------------

#loading a saved model
reloaded = tf.saved_model.load(MODEL_SAVED_FILES)
</code></pre>
<p>Here's the error I get when I try to retrain the model using the following code:</p>
<pre class=""lang-py prettyprint-override""><code>reloaded = tf.saved_model.load(MODEL_SAVED_FILES)

#retraing the model on new dataset
reloaded.translator.transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )
</code></pre>
<p>The error:</p>
<pre class=""lang-py prettyprint-override""><code>
---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

&lt;ipython-input-41-ad1b625ff6c0&gt; in &lt;cell line: 2&gt;()
      1 #retraing the model on new dataset
----&gt; 2 reloaded.translator.transformer.fit(train_batches,
      3                 epochs=20,
      4                 validation_data=val_batches,
      5                 callbacks=[

AttributeError: '_UserObject' object has no attribute 'fit'
</code></pre>
<p>After reading the documentation I've realised that when saving the model in the above method, the <code>model.fit()</code> and other methods are not saved hence they are not callable.</p>
<p>I need help in finding a way to retrain my saved model, It is not feasible for me to train a new model on a combined dataset as It will take up lot of time and I have very limited resources. I have been looking up on the web for days but couldn't find a solution. Any help in this regards will be appreciated!</p>
",1,Inadequate Examples
