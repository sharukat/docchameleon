QuestionId,QuestionAPI,IssueType,Title,Question,GroundTruth,GT_Explain,GT_Code,yt_queries,so_queries,yt_urls,yt_transcripts,so_urls,contexts,generated_explanation
51586693,tf.gather,example required,"Tensor has shape [?, 0] -- how to reshape to [?,]","<p>When <code>src</code> has shape <code>[?]</code>, <code>tf.gather(src, tf.where(src != 0))</code> returns a tensor with shape <code>[?, 0]</code>. I'm not sure how a dimension can have size 0, and I'm especially unsure how to change the tensor back. I didn't find anything in the documentation to explain this, either.</p>

<p>I tried to <code>tf.transpose(tensor)[0]</code>, but the first dimension of the transposed tensor has size 0 and cannot be accessed! What's wrong?</p>
","<p>I think you should use <a href=""https://www.tensorflow.org/api_docs/python/tf/not_equal"" rel=""nofollow noreferrer""><code>tf.not_equal</code></a> to perform elementwise comparison on the tensor.</p>

<pre><code>src = tf.constant([0, 1, 1, 0], dtype=tf.int8)
tf.gather(src, tf.where(tf.not_equal(src, 0))).eval(session=tf.Session())

array([[1],
       [1]], dtype=int8)
</code></pre>

<p>You can also shorten this a bit and use <a href=""https://www.tensorflow.org/api_docs/python/tf/boolean_mask"" rel=""nofollow noreferrer""><code>tf.boolean_mask</code></a> instead of <code>tf.where</code> and <code>tf.gather</code>:</p>

<pre><code>tf.boolean_mask(src, tf.not_equal(src, 0)).eval(session=tf.Session())
array([1, 1], dtype=int8)
</code></pre>

<p>Note the difference in the shape of the outputs.</p>
",,"<pre><code>src = tf.constant([0, 1, 1, 0], dtype=tf.int8)
tf.gather(src, tf.where(tf.not_equal(src, 0))).eval(session=tf.Session())

array([[1],
       [1]], dtype=int8)
</code></pre>","['Understanding tf.gather and tf.where in TensorFlow', 'Handling tensors with zero dimensions in TensorFlow', 'How to reshape tensors in TensorFlow', 'Common issues with tf.gather and tf.where in TensorFlow', 'TensorFlow: Working with sparse tensors and zero values', 'TensorFlow: Reshaping and manipulating tensor dimensions', 'TensorFlow: Dealing with unexpected tensor shapes', 'TensorFlow: Practical examples of tf.gather and tf.where']","['Why does tf.gather(src, tf.where(src != 0)) return a tensor with shape [?, 0]?', 'How can I reshape a tensor with shape [?, 0] to a valid shape in TensorFlow?', 'What is the correct way to filter out zero elements from a tensor in TensorFlow?', 'How to use tf.where and tf.gather correctly to avoid getting a tensor with shape [?, 0]?', 'What are the best practices for handling tensors with dynamic shapes in TensorFlow?']","{'https://www.youtube.com/watch?v=WLtkPIrCs9Y', 'https://www.youtube.com/watch?v=ukBG9ALd8T8'}","['""""""[Document(page_content=""JASON MAYES: So\\nbefore you move on to using the second\\ntype of pre-made model, you need to understand a\\nvery important concept known as a tensor. TensorFlow is, after\\nall, named after it. So as you may have guessed,\\nit\'s pretty key to a subject. So let\'s find out some more. Now, the very first\\nthing you\'ll find, if you look at the TensorFlow.js\\nAPI as shown on this slide, is this thing called a tensor. And tensors are the\\nprimary data structure in TensorFlow programs. Machine-learning\\nmodels literally take tensors as inputs,\\nmanipulate them in some way, and then spit out\\ntensors as outputs. You can think of them as\\nbeing similar in structure to an array. And just like arrays, they\\ncan have multiple dimensions. But tensors almost always\\nonly contain numerical data, unlike regular\\nJavaScript arrays, that could contain a\\nwhole mix of objects that you might use or invent. Furthermore, the\\ntensor class, itself, has a whole bunch\\nof useful functions that can assist in transforming\\nthem into different sizes or dimensions, or doing math\\nupon the numbers contained inside them, and much more. Basically, an array\\nextended with super powers. Now, this flow of tensors for a\\nmachine-learning model is where TensorFlow gets its name from-- essentially, the flow of\\ntensors through the model. Now, I mentioned tensors\\ncan have multiple dimensions just like arrays. Let\'s quickly recap\\nwhat this looks like, and the slightly different\\nterms you might hear when speaking about tensors. First, the most\\nsimple is some data that has no dimensions, a\\nsingle value, if you will, also known as a scalar value in\\nmathematics-- like the number six. Here, you can see\\na little bucket of memory shown in orange\\ncontaining the single number all by itself. Now, machine-learning folk\\nlike to describe dimensionality in terms of a word called rank. So here, the tensor\\nhas a rank of zero-- which simply means it has\\nzero dimensions, or axes, if you prefer. In JavaScript code,\\nyou\'ve used scalar values like this over time. For example, when you\\ncreate a variable, and assign it a single\\nnumber as a value-- like let value equals 6,\\nas shown on this slide. Using the TensorFlow.js\\nAPI, you can instead call tf.scalar, and pass\\nit the number directly to return a tensor\\nholding that number. Next, you can have a\\none-dimensional tensor. You can think of this\\nas a list of numbers, just like a\\none-dimensional array. And mathematicians would\\ncall this collection of numbers a vector. And when constructed\\nas a tensor, TensorFlow folk would call\\nthis a rank one tensor, as it uses a\\none-dimensional array to store those three numbers. It should be noted,\\nhowever, that in this case, the vector data stored\\nis three dimensional-- it has three numbers in the array. Those numbers could\\nrepresent a single coordinate in 3D space-- in x, y,\\nand z, respectively. So in that sense, the data,\\nitself, is three dimensional. Now, do not confuse a 3D\\nvector with a 3D tensor. In the prior example,\\nthe vector is 3D as it contained three numbers. But for tensor holding that\\ndata was one-dimensional, or 1D. If you had four numbers in the\\narray, the vector would be 4D, but the tensor would still be\\none dimensional with rank one. So for term of\\ndimensionality can represent one of two things,\\nas you just saw. It can either denote\\nthe number of elements along a specific\\naxes of a tensor-- like the 3D vector\\nthat you just saw-- or the number of\\naxes in a tensor. In this case, it was one,\\nas the container is just a standard\\none-dimensional array. Here, you can\\nvisualize the array as a list of numbers\\nin memory, all going in one dimension,\\nas shown on the right. In JavaScript code, you probably\\nused a one-dimensional array over time to store\\nvalues as shown. Using the TensorFlow.js API, you\\ncan instead call tf.tensor1d, and pass it to one-dimensional\\narray of numbers instead, to return a tensor of\\nrank one holding those numbers. Up next is two\\ndimensional tensors. Imagine you had a\\ngrayscale image. Every pixel in the image would\\nhave a value from zero to 255, representing different shades\\nof gray the computer could draw. Now, each pixel has\\nan x and y location somewhere on that 2D image. So to store those\\nvalues whilst retaining the correct positions,\\nyou might choose to store this data as\\na two-dimensional array in your code. Now, mathematicians\\ncall this a matrix. And TensorFlow folk would\\ncall this a rank 2 tensor. Here, you can\\nvisualize the array as a rectangle or square of\\nnumbers as shown on the right. In JavaScript code, you may have\\nalready used 2D arrays already, like the code shown, to\\nstore some data for an image, or maybe even a\\nboard game state, for example, to keep\\ntrack of what pieces is in what location of the board. Now, using the\\nTensorFlow.js API, you can call\\ntf.tensor2d and pass it with two-dimensional\\narray of numbers to return a tensor of rank\\n2, holding those numbers. And in a similar manner,\\nthree-dimensional tensors also exist. A great example of this is a\\nregular, full-color RGB image. You may think images\\nare two-dimensional, which, for the purposes\\nof grayscale images, that\'s pretty true. However, a color image is\\nmade of red, green, and blue channels. Each pixel, therefore,\\nneeds three numbers to produce the color that\\nyou see on your screen with the correct mixture\\nof red, green, and blue. So to store the data\\nfor a color image, you actually need a\\nrank 3 tensor, as shown. This example essentially\\nshows a 3 by 3 pixel RGB image stored in memory, where one\\nlayer could be the red values, layer two of green, and\\nlayer three the blue. To visualize this, you can\\nthink of many 2D layers stacked together to create a 3D\\nshape, like this cube on the right-hand side, with\\neach sub-cube containing a number in this case. Hopefully by now, you\\ncan see the pattern in the code, where\\nas you increase the number of dimensions,\\nyou\'re essentially nesting more arrays inside each other. And the TensorFlow.js code\\njust calls tf.tensorxd, where x is the\\nnumber of dimensions that you have, up\\nto a maximum of six. You then pass\\nthrough that function the multidimensional\\narray of numbers, which will return a\\ntensor whose rank is the same as the\\ndimensions required. Visualizing beyond\\n3D is sort of tricky. So I\'ve tried my best here\\nto draw some visualizations to help you see how\\nthis works in terms of the nesting of\\narrays in a visual way. A rank 4 tensor\\nstructure is simply an array of three-dimensional\\narrays that you just saw. Here, you can see a light\\nblue container representing the fourth dimension,\\nwhich itself contains a collection of\\n3D arrays like the ones you saw on the previous slide. Now I\'ve not written\\nthe code for this, as it\'s hard to fit\\non a single slide, but the principle is the\\nsame as you previously saw. Hopefully, this\\nvisualization helps illustrate what\'s going on. And a common use case\\nfor this sort of data would be video data that\\ncontains a time element. Here, you can see that\\na video after all, is just an ordered set\\nof RGB images over time. And in the example\\nshown here, you can see that you have\\nthree, 3 by 3 pixel RGB images stored over time. Each with a red, green, and blue\\nchannel, one after each other, and all contained\\nwithin the new array. And yes, you can go further. A rank 5 tensor is\\nshown here, building upon the previous\\nexample, which is like having a batch of videos. Here, you can see how each\\nvideo from the prior slide is now stacked inside a new\\narray containing them all. And it should be noted\\nthat there are also some real-world scenarios\\nthat might need a rank 5 tensor to store their\\ndata from sensors that are more advanced\\nthan regular webcams, or when using very specific data\\ntypes, say, in the 3D industry. One potential example\\nwould be storing voxels, which simply is\\na fancy word for saying three-dimensional pixels. Lets look into this deeper. In the image on\\nthe right, you can see a screenshot of the popular\\ncomputer game called Minecraft. This digital world\\nis represented by a whole bunch of cubes that\\nare essentially the smallest subdivision of the 3D world\\nspace that you can have, which is known as a voxel. Just like the smallest\\nsubdivision of a 2D space is known as a pixel\\nfor regular images. Now, each one of these voxels\\nhas a specific color value, representing different\\nobjects in the game. But the users can manipulate\\nto create and build whatever they want. Now, if you were to store a\\nportion of this Minecraft world in the form of a\\ntensor, each voxel may need to store the RGB\\ncolor value it represents. As free values would\\nneed to be stored in a one-dimensional array, this\\nwould be the first dimension-- the color of the voxel. This voxel now needs to be\\nassigned a location in the game world, for example\\nin x, y, and z. Which means you need a second,\\nthird, and fourth dimension, respectively, so you can\\ntrack the coordinates of where that voxel is\\nlocated in three dimensions. And finally, if you were\\ncoding these values over time, you would even need\\nthe fifth dimension to store frames of this data. You can think of\\nthis as an animation that records changes\\nto the voxels, but you can then play back\\nover some time interval. And last but not least, you\\nmight summon a rank 6 tensor-- this is the highest rank tensor\\nthat TensorFlow supports. Realistically, you\\nprobably won\'t ever need to use it for\\nmost situations, but know that it exists. Continuing the\\nprevious rank 5 example for recording voxel\\nstates over time, you might find\\nyou need to record a batch of voxel animations to\\nsend to your model in parallel. In this case, you\'d need\\nthat sixth dimension here to do that. All right, that\'s\\nquite a bit to digest, especially as you\\ntypically only work up to three dimensions\\nin your mind. So feel free to rewind and\\nunderstand the examples provided before continuing. Now, when working\\nwith tensors, there\'s some common vocabulary you\'ll\\nhear folk often referring to. Most importantly,\\nall tensors have two fundamental properties--\\ndata type and shape. So let\'s dive into the details. Data type is the type of data\\nthat the tensor will store. For example, integers\\nwhich are just whole numbers, or floating\\npoint numbers, which are just fractional numbers\\nwith a decimal point, like 0.2. The amount of memory used\\nto store these numbers defines the range of\\nvalues that they can store. So as you can see on\\nthis slide, int-8 stores a smaller range of\\nnumbers than int-16. Now, as a JavaScript programmer\\nin the web.dev world, you may not have had to\\ndeal with specifying numbers to this level of detail before. Typically, you would\\njust say, let x equal 2, and be done with it. But in the\\nmachine-learning world, it\'s important to do so,\\nas using the wrong type could eat a ton more memory,\\nas often larger networks are dealing with millions\\nof numbers in the model. For this reason,\\nyou\'ll see typed arrays being used a lot in\\nTensorFlow.js that JavaScript also supports, even\\nthough few people need to use them normally. This not only helps\\nwith memory efficiency, but also for performance. If an array only\\nstores one type, then it can be accessed\\nmore efficiently, too, making a program as\\nfast as possible. Next, shape is the\\nlength of a number of elements, if you will, of\\neach of the axes of the tensor. In this example, you have\\nthree-dimensional tensors, as you saw before. The shape for the tense on\\nthe left would be 3 by 3 by 3. And on the one on the\\nright, which is also a three-dimensional tensor, its\\nshape might be described as 3 by 3 by 6, using\\nthe same convention. Now, rank, as you\\nsaw before, is simply the number of axes\\nthat the tensor has, or the dimensions, if you\\nprefer to think of it like that. This tensor has three axes,\\nso it has a rank of three. Axes or dimensions can be\\nindividually called up to. For example, axes two\\nin this visualization runs along the cube from the\\nleft to the right, as shown. Finally, size is just the total\\nnumber of items in the tensor. If you know the\\nshape of a tensor, you can multiply the\\nnumbers to get its size. This 3 by 3 by 3 tensor has a\\nsize of 27 on the left there, and the 3 by 3 by 6\\ntensor has a size of 54. Now, once you\'ve got\\nyour data in tensor form, you can now make use of all\\nthe powerful functions provided by the TensorFlow.js library. A few simple examples\\nare shown here. In the first line\\nof code, you can see it just creates\\na new 2D tensor and assigns it to a\\nvariable, called tensor. In a similar manner,\\nthe second line of code creates a scalar tensor\\nwith the value of 2, and assigns it to a\\nvariable called scalar. But next line shows you\\nhow you can multiply all values in the first tensor\\nwith the scalar value you just created by calling tensor.mul,\\nand passing it the scalar tensor you want to multiply by. Next, if you put the contents\\nof a new tensor just created by doing that, you can\\nsee all of the values are now double what they\\nwere in the first tensor that you created at the start. Now, you might wonder, why not\\njust use regular JavaScript to multiply all\\nthe numbers by 2? Well, simply put,\\nusing tensors means you can take advantage\\nof the faster execution on the graphics\\ncard, or other back ends, that TensorFlow.js\\nsupports, which can do many of these operations\\nin parallel or much faster than vanilla JavaScript. This means your program\\nis going to run super fast when doing these\\nsorts of operations on huge arrays of numbers. Which when you\'re\\ndealing with things like images that contain\\nmillions of numbers, that performance difference\\ncan make a huge difference in execution time. Finally, on the\\nlast line, you can see how you can even change\\nthe shape of tensors. In this case, it takes the\\n2D tensor from the first line and reshapes it into a\\none-dimensional tensor with six elements. Pretty neat. Now, these examples may not mean\\nmuch on their own right now, but later in this course, you\'ll\\nsee more useful use cases, for which these sorts of\\ntransformations-- for example, when working with image data-- and converting back\\nto being tensor form, will be input into a\\nmodel more efficiently. Now, the beauty of having these\\nstandard ways to represent data is that the library knows\\nhow it can use such data on different hardware types. As it now can rely\\nupon the fact that data will always be consistent in\\nthis well-defined tensor form. But TensorFlow.js library\\nworks on several backends, as you saw before, like\\nWebGL for the graphics card, or WebAssembly for the CPU. And this means that the library\\ncan accelerate the tensor operations that you perform\\non the desired hardware for you, without you having to\\nworry about what the tensor is actually executing on\\nyourself, saving you a lot of time and complexity\\nof writing all that code, yourself. Now, one final point I\'d like\\nto share for consideration, is that tensors need to\\nbe manually destroyed, and are not disposed of like\\nmost things in JavaScript. In regular JavaScript, if you\\ndeclare a variable-- let\'s say, x equal 1-- and then stop using\\nthe variable, x, the browser will\\nautomatically clean up the memory it used with\\nits garbage collector, freeing up the RAM and\\nresources for the computer. For a tensor, you\\nmust dispose of memory yourself manually using a\\nspecial dispose function or the convenient tf.tidy,\\nwhich will automatically dispose of any tensors created\\nwithin a given function. Now, this might come as\\na bit of a shock to you, if you\'re not used to writing\\nin other languages, like C, you have to remember to\\ndispose of variables that you create but you no\\nlonger need as standard. You\'ll learn more\\nabout putting this into practice later\\nin the course. So for now, just realize this\\nis something you\'ll need to do. Otherwise, you could\\ncause a memory leak if you keep creating\\ntensors, say, in a loop, and never dispose\\nof the old ones. Great, so with that, you now\\nhave the 101 of what tensors are, it\'s time to\\nhead back to learning how to use slightly more\\nadvanced premade models well you\'ll need to work\\nat the tensor level to pass data in and retrieve\\noutputs from such models. See you in the next section."", metadata={\'source\': \'WLtkPIrCs9Y\'})]""""""', '""""""[Document(page_content=""we start by importing tensorflow as tf then we print the version of tensorflow that we are using we\'re using tensorflow 1.5.0 in this video we\'re going to use tensorflow reshape to change the shape of a tensorflow tensor as long as the number of elements stay the same we will do three examples to show how reshape works let\'s start out with an initial tensorflow constant tensor shaped two by three by four with numerical integer values between 1 and 24 all of whom have the data type of n32 so we use tensorflow.constant we have our two by three by four tensor we have the data type as n32 and we see the numbers are one two three four all the way through 24 and we assign it to the python variable tf underscore initial underscore tensor underscore constant now that we have it let\'s print out the tf initial tensor constant python variable to see what we have we see that it\'s a tensorflow constant the shape is two by three by four the data type is n32 because we haven\'t run it in a tensorflow session yet it doesn\'t seem to have values even though we just defined it as a constant the same will apply to the other reshapes we\'re about to create for the first example let\'s go from a tensor whose shape is two by three by four to a tensor whose shape is two by twelve so we\'re going to use tensorflow.reshape we pass in the initial tensor constant and then we pass in the specifics of what we want the new shape to be so it\'ll be 2 comma 12 and we assign the whole thing to the python variable tf x 1 reshape tensor 2 by 12. note that the number of elements will stay the same as 2 times 3 times 4 is 24 and 2 times 12 is 24. let\'s print out the tfx one reshaped tensor 2 by 12 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 2 by 12 and we see that the data type is in 32. it\'s not showing any values yet because we\'re still building the tensorflow graph and we haven\'t run at any tensorflow session for the second example let\'s change a tensor whose shape is two by three by four to a tensor whose shape is two by three by two by two so we use tensorflow.reshape we pass in our initial tensor and then we specify what the shape is going to be so we pass in two comma three comma two comma 2 and we assign it to the python variable tf x 2 reshape tensor 2 by 3 by 2 by 2. note that the number of elements will stay the same as 2 times 3 times 4 is 24 and 2 times 3 times 2 times 2 is 24 as well let\'s print out the tf x to reshape tensor 2 by 3 by 2 by 2 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 2 by 3 by 2 by 2 which is what we would expect and the data type is in 32 for the third example we\'re going to change a tensorflow tensor whose shape is 2 by 3 by 4 to a vector of 24 elements and the way we do that is we use the tensorflow.reshape operation we pass in our initial tensor and here we\'re going to use a negative one so what that\'s going to do is it\'s just going to flatten the tensor so that\'s just going to be a list of 24 elements we assign it to the python variable tf x tree reshape tensor one by 24. let\'s print out the tf x tree reshape tensor one by 24 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 24 comma that means it\'s going to be a vector the data type is n32 now that we have created our tensorflow tensors it\'s time to run the computational graph first we launch the graph in a session then we initialize all the global variables in the graph in our case it\'s going to be all the tensors we\'ve created next we\'re going to print out the four tensors to see how tensorflow\'s reshape works let\'s print out our initial tensor constant so we do a print session run tf initial tensor constant we see that it\'s a two by three by four tensor the numbers go from one to twenty four and none of them have decimal points so we know that they\'re in 32 numbers let\'s now print our first reshaped tensor so we use the print session run tfx1 reshape tensor2 by 12. we see that it\'s a tensor that has two matrices inside of it the first matrix has one row and 12 columns the second matrix has one row and 12 columns so all of our elements are there one through 24. let\'s now print our second reshaped tensor python variable tf x2 reshaped tensor two by three by two by two awesome we see that it\'s a tensor that has two interior tensors each of which has three matrices that are two by two perfect so two rows two columns two rows two columns two rows two columns and then two rows two columns two rows two columns two rows two columns so overall we can see that the shape is two by three by two by two and all our numbers are there finally let\'s print our third reshape tensorflow example this is the python variable tfx tree reshape tensor 1 by 24 awesome we see that it\'s a vector that\'s 24 elements long so we see the number 1 all the way to 24. so all our numbers are there perfect we were able to use tensorflow reshape to change the shape of a tensorflow tensor as long as the number of elements stayed the same"", metadata={\'source\': \'ukBG9ALd8T8\'})]""""""']","{'https://stackoverflow.com/questions/37868935/tensorflow-reshape-tensor', 'https://stackoverflow.com/questions/62092075/tensorflow-2-0-shape-inference-with-reshape-returns-none-dimension', 'https://stackoverflow.com/questions/36764791/in-tensorflow-how-to-use-tf-gather-for-the-last-dimension', 'https://stackoverflow.com/questions/42194051/filter-out-non-zero-values-in-a-tensor'}","['""""""Filter out non-zero values in a tensor\n\nSuppose I have an array: input = np.array([[1,0,3,5,0,8,6]]), and I want to filter out [1,3,5,8,6]. I know that you can use tf.where with a condition but the returned value still has 0\'s in it.""""""', '"""""" In Tensorflow, how to use tf.gather() for the last dimension? n\nI am trying to gather slices of a tensor in terms of the last dimension for partial connection between layers. Because the output tensor\'s shape is [batch_size, h, w, depth], I want to select slices based on the last dimension, such as\n\n# L is intermediate tensor partL = L[:, :, :, [0,2,3,8]]\n\nHowever, tf.gather(L, [0, 2,3,8]) seems to only work for the first dimension (right?) Can anyone tell me how to do it? As of TensorFlow 1.3 tf.gather has an axis parameter, so the various workarounds here are no longer necessary. There\'s a tracking bug to support this use-case here: https://github.com/tensorflow/tensorflow/issues/206\n\ntranspose your matrix so that dimension to gather is first (transpose is expensive)\n\nreshape your tensor into 1d (reshape is cheap) and turn your gather column indices into a list of individual element indices at linear indexing, then reshape back\n\nuse gather_nd. Will still need to turn your column indices into list of individual element indices. \n\nNote that tf.gather has an axis parameter as of TensorFlow 1.3. With gather_nd you can now do this as follows:\n\ncat_idx = tf.concat([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=0) result = tf.gather_nd(matrix, cat_idx)\n\nAlso, as reported by user Nova in a thread referenced by @Yaroslav Bulatov\'s:\n\nx = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) idx = tf.constant([1, 0, 2]) idx_flattened = tf.range(0, x.shape[0]) * x.shape[1] + idx y = tf.gather(tf.reshape(x, [-1]), # flatten input idx_flattened) # use flattened indices with tf.Session(\'\'): print y.eval() # [2 4 9]\n\nThe gist is flatten the tensor and use strided 1D addressing with tf.gather(...). \n\nI\'m not sure your first example works. Let\'s say tf.shape(x)[0] is 1, then cat_idx will be [0, 0, 2, 3, 8], which is not what you want to use with tf.gather_nd. In fact, in this case it would throw an error because the length of the innermost dimension of indices (2nd argument to gather_nd) cannot be bigger than the rank of params (1st argument to gather_nd). I\'ve posted a corrected version (using tf.stack) below. Yet another solution using tf.unstack(...), tf.gather(...) and tf.stack(..)\n\nimport tensorflow as tf import numpy as np shape = [2, 2, 2, 10] L = np.arange(np.prod(shape)) L = np.reshape(L, shape) indices = [0, 2, 3, 8] axis = -1 # last dimension def gather_axis(params, indices, axis=0): return tf.stack(tf.unstack(tf.gather(tf.unstack(params, axis=axis), indices)), axis=axis) print(L) with tf.Session() as sess: partL = sess.run(gather_axis(L, indices, axis)) print(partL)\n\nL = [[[[ 0 1 2 3 4 5 6 7 8 9] [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29] [30 31 32 33 34 35 36 37 38 39]]] [[[40 41 42 43 44 45 46 47 48 49] [50 51 52 53 54 55 56 57 58 59]] [[60 61 62 63 64 65 66 67 68 69] [70 71 72 73 74 75 76 77 78 79]]]] partL = [[[[ 0 2 3 8] [10 12 13 18]] [[20 22 23 28] [30 32 33 38]]] [[[40 42 43 48] [50 52 53 58]] [[60 62 63 68] [70 72 73 78]]]]\n\nA correct version of @Andrei\'s answer would read\n\ncat_idx = tf.stack([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=1) result = tf.gather_nd(matrix, cat_idx)\n\nYou can try this way, for instance(in most cases in NLP at the least),\n\nThe parameter is of shape [batch_size, depth] and the indices are [i, j, k, n, m] of which the length is batch_size. Then gather_nd can be helpful.""""""', '"""""" In Tensorflow, how to use tf.gather() for the last dimension? \n\nI am trying to gather slices of a tensor in terms of the last dimension for partial connection between layers. Because the output tensor\'s shape is [batch_size, h, w, depth], I want to select slices based on the last dimension, such as\n\n# L is intermediate tensor partL = L[:, :, :, [0,2,3,8]]\n\nHowever, tf.gather(L, [0, 2,3,8]) seems to only work for the first dimension (right?) Can anyone tell me how to do it? As of TensorFlow 1.3 tf.gather has an axis parameter, so the various workarounds here are no longer necessary. https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/gather https://github.com/tensorflow/tensorflow/issues/11223\n\n\n\nThere\'s a tracking bug to support this use-case here: https://github.com/tensorflow/tensorflow/issues/206\n\ntranspose your matrix so that dimension to gather is first (transpose is expensive)\n\nreshape your tensor into 1d (reshape is cheap) and turn your gather column indices into a list of individual element indices at linear indexing, then reshape back\n\nuse gather_nd. Will still need to turn your column indices into list of individual element indices. \n\nNote that tf.gather has an axis parameter as of TensorFlow 1.3. With gather_nd you can now do this as follows:\n\ncat_idx = tf.concat([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=0) result = tf.gather_nd(matrix, cat_idx)\n\nAlso, as reported by user Nova in a thread referenced by @Yaroslav Bulatov\'s:\n\nx = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) idx = tf.constant([1, 0, 2]) idx_flattened = tf.range(0, x.shape[0]) * x.shape[1] + idx y = tf.gather(tf.reshape(x, [-1]), # flatten input idx_flattened) # use flattened indices with tf.Session(\'\'): print y.eval() # [2 4 9]\n\nThe gist is flatten the tensor and use strided 1D addressing with tf.gather(...). \n\nI'm not sure your first example works. Let\'s say tf.shape(x)[0] is 1, then cat_idx will be [0, 0, 2, 3, 8], which is not what you want to use with tf.gather_nd. In fact, in this case it would throw an error because the length of the innermost dimension of indices (2nd argument to gather_nd) cannot be bigger than the rank of params (1st argument to gather_nd). I\'ve posted a corrected version (using tf.stack) below. Yet another solution using tf.unstack(...), tf.gather(...) and tf.stack(..)\n\nimport tensorflow as tf import numpy as np shape = [2, 2, 2, 10] L = np.arange(np.prod(shape)) L = np.reshape(L, shape) indices = [0, 2, 3, 8] axis = -1 # last dimension def gather_axis(params, indices, axis=0): return tf.stack(tf.unstack(tf.gather(tf.unstack(params, axis=axis), indices)), axis=axis) print(L) with tf.Session() as sess: partL = sess.run(gather_axis(L, indices, axis)) print(partL)\n\nL = [[[[ 0 1 2 3 4 5 6 7 8 9] [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29] [30 31 32 33 34 35 36 37 38 39]]] [[[40 41 42 43 44 45 46 47 48 49] [50 51 52 53 54 55 56 57 58 59]] [[60 61 62 63 64 65 66 67 68 69] [70 71 72 73 74 75 76 77 78 79]]]] partL = [[[[ 0 2 3 8] [10 12 13 18]] [[20 22 23 28] [30 32 33 38]]] [[[40 42 43 48] [50 52 53 58]] [[60 62 63 68] [70 72 73 78]]]]\n\nA correct version of @Andrei\'s answer would read\n\ncat_idx = tf.stack([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=1) result = tf.gather_nd(matrix, cat_idx)\n\nEdward HughesEdward Hughes\n\nYou can try this way, for instance(in most cases in NLP at the least),\n\nThe parameter is of shape [batch_size, depth] and the indices are [i, j, k, n, m] of which the length is batch_size. Then gather_nd can be helpful.""""""', '"""""" In Tensorflow, how to use tf.gather() for the last dimension? \n\nI am trying to gather slices of a tensor in terms of the last dimension for partial connection between layers. Because the output tensor\'s shape is [batch_size, h, w, depth], I want to select slices based on the last dimension, such as\n\n# L is intermediate tensor partL = L[:, :, :, [0,2,3,8]]\n\nHowever, tf.gather(L, [0, 2,3,8]) seems to only work for the first dimension (right?) Can anyone tell me how to do it? As of TensorFlow 1.3 tf.gather has an axis parameter, so the various workarounds here are no longer necessary. https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/gather https://github.com/tensorflow/tensorflow/issues/11223\n\n\n\nThere\'s a tracking bug to support this use-case here: https://github.com/tensorflow/tensorflow/issues/206\n\ntranspose your matrix so that dimension to gather is first (transpose is expensive)\n\nreshape your tensor into 1d (reshape is cheap) and turn your gather column indices into a list of individual element indices at linear indexing, then reshape back\n\nuse gather_nd. Will still need to turn your column indices into list of individual element indices. \n\nNote that tf.gather has an axis parameter as of TensorFlow 1.3. With gather_nd you can now do this as follows:\n\ncat_idx = tf.concat([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=0) result = tf.gather_nd(matrix, cat_idx)\n\nAlso, as reported by user Nova in a thread referenced by @Yaroslav Bulatov\'s:\n\n x = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) idx = tf.constant([1, 0, 2]) idx_flattened = tf.range(0, x.shape[0]) * x.shape[1] + idx y = tf.gather(tf.reshape(x, [-1]), # flatten input idx_flattened) # use flattened indices with tf.Session(\'\'): print y.eval() # [2 4 9]\n\nThe gist is flatten the tensor and use strided 1D addressing with tf.gather(...). I'm not sure your first example works. Let's say tf.shape(x)[0] is 1, then cat_idx will be [0, 0, 2, 3, 8], which is not what you want to use with tf.gather_nd. In fact, in this case it would throw an error because the length of the innermost dimension of indices (2nd argument to gather_nd) cannot be bigger than the rank of params (1st argument to gather_nd). I\'ve posted a corrected version (using tf.stack) below. Yet another solution using tf.unstack(...), tf.gather(...) and tf.stack(..)\n\nimport tensorflow as tf import numpy as np shape = [2, 2, 2, 10] L = np.arange(np.prod(shape)) L = np.reshape(L, shape) indices = [0, 2, 3, 8] axis = -1 # last dimension def gather_axis(params, indices, axis=0): return tf.stack(tf.unstack(tf.gather(tf.unstack(params, axis=axis), indices)), axis=axis) print(L) with tf.Session() as sess: partL = sess.run(gather_axis(L, indices, axis)) print(partL)\n\nL = [[[[ 0 1 2 3 4 5 6 7 8 9] [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29] [30 31 32 33 34 35 36 37 38 39]]] [[[40 41 42 43 44 45 46 47 48 49] [50 51 52 53 54 55 56 57 58 59]] [[60 61 62 63 64 65 66 67 68 69] [70 71 72 73 74 75 76 77 78 79]]]] partL = [[[[ 0 2 3 8] [10 12 13 18]] [[20 22 23 28] [30 32 33 38]]] [[[40 42 43 48] [50 52 53 58]] [[60 62 63 68] [70 72 73 78]]]]\\n\nA correct version of @Andrei\'s answer would read\n\ncat_idx = tf.stack([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=1) result = tf.gather_nd(matrix, cat_idx)\n\nEdward HughesEdward Hughes\n\nYou can try this way, for instance(in most cases in NLP at the least),\n\nThe parameter is of shape [batch_size, depth] and the indices are [i, j, k, n, m] of which the length is batch_size. Then gather_nd can be helpful.""""""']","When working with TensorFlow, you may encounter a situation where a tensor has a shape of `[?, 0]` after using operations like `tf.gather` with `tf.where`. This shape indicates that the tensor has an unknown number of rows (`?`) and zero columns, which can be confusing and problematic for further processing.

The issue arises because `tf.where` returns the indices of non-zero elements, and when used with `tf.gather`, it can result in a tensor with a shape that includes a dimension of size 0. This happens because the condition in `tf.where` might not find any non-zero elements, leading to an empty tensor along the specified dimension.

To reshape the tensor from `[?, 0]` to `[?,]`, you need to understand that a dimension of size 0 means there are no elements along that dimension. Therefore, the tensor effectively has no data to reshape. The goal is to remove the dimension with size 0, resulting in a tensor with a shape of `[?,]`, which is a one-dimensional tensor with an unknown number of elements.

In TensorFlow, you can achieve this by using operations that remove dimensions of size 0. One approach is to use `tf.squeeze`, which removes dimensions of size 1, but in this case, you need to handle the dimension of size 0 specifically. Another approach is to use `tf.reshape` to explicitly reshape the tensor to the desired shape.

By understanding the nature of the tensor's shape and using appropriate TensorFlow operations, you can effectively reshape a tensor from `[?, 0]` to `[?,]`, making it suitable for further processing in your machine learning pipeline."
56286350,tf.keras.metrics.SensitivityAtSpecificity,example required,tf.keras.metrics.SpecificityAtSensitivity num_thresholds interpretation,"<p>I'm trying to get my head around <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/metrics/SensitivityAtSpecificity"" rel=""nofollow noreferrer"">tf.keras.metrics.SensitivityAtSpecificity</a>. I'm fine with the concept of sensity and specificity in isolation, but I'm unsure how the two are related in this single metric.</p>

<p>More specifically, I'm unsure how to interpret the <code>num_thresholds</code> argument. The example in documentation has <code>num_thresholds=1</code>. Setting <code>num_thresholds</code> greater than 1 with the same input data seems to always return a metric value of 1.0.</p>

<pre class=""lang-py prettyprint-override""><code>def print_metric_value(num_thresholds):
    # other values based on docs example
    m = tf.keras.metrics.SensitivityAtSpecificity(
        0.4, num_thresholds=num_thresholds)
    m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])
    print('Result with num_thresholds = %d: %.1f' %
          (num_thresholds, m.result().numpy()))

print_metric_value(1)    # 0.5 - same as docs
print_metric_value(2)    # 1.0
print_metric_value(200)  # 1.0
</code></pre>
","<p>The <code>num_thresholds</code> refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0). </p>

<p>For example, consider the prediction vector as <code>[0, 0.5, 0.3, 0.9]</code> which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of <code>0.1</code>, we get <code>[0, 1, 1, 1]</code>; or if we apply threshold value of <code>0.6</code> we get <code>[0, 0, 0, 1]</code> (i.e. only the confidence of last prediction is higher than <code>0.6</code>).   </p>

<p>Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What <code>SensitivityAtSpecificity</code> metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given <code>0.4</code> as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to <code>SpecificityAtSensitivity</code> metric, just swap ""specificity"" and ""sensitivity"" in this paragraph.</p>

<p>You might also ask: what are the threshold values? The answer is if <code>num_thresholds=1</code> then the only threshold is 0.5. If <code>num_thresholds &gt; 1</code> then, besides 0 and 1 as thresholds, the interval (0,1) will be split into <code>num_thresholds - 1</code> equal sub-intervals and the split points are chosen as additional threshold values. For example:</p>

<pre><code>num_threshold  |  thresholds
=============================
1              | [0.5]
2              | [0, 1]
3              | [0, 0.5, 1]
4              | [0, 0.33, 0.66, 1]
5              | [0, 0.25, 0.5, 0.75, 1]
...
</code></pre>
","The <code>num_thresholds</code> refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0).

For example, consider the prediction vector as <code>[0, 0.5, 0.3, 0.9]</code> which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of <code>0.1</code>, we get <code>[0, 1, 1, 1]</code>; or if we apply threshold value of <code>0.6</code> we get <code>[0, 0, 0, 1]</code> (i.e. only the confidence of last prediction is higher than <code>0.6</code>).

Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What <code>SensitivityAtSpecificity</code> metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given <code>0.4</code> as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to <code>SpecificityAtSensitivity</code> metric, just swap ""specificity"" and ""sensitivity"" in this paragraph.

You might also ask: what are the threshold values? The answer is if <code>num_thresholds=1</code> then the only threshold is 0.5. If <code>num_thresholds &gt; 1</code> then, besides 0 and 1 as thresholds, the interval (0,1) will be split into <code>num_thresholds - 1</code> equal sub-intervals and the split points are chosen as additional threshold values. For example:

<pre><code>num_threshold  |  thresholds
=============================
1              | [0.5]
2              | [0, 1]
3              | [0, 0.5, 1]
4              | [0, 0.33, 0.66, 1]
5              | [0, 0.25, 0.5, 0.75, 1]
...
</code></pre>",,"['Understanding tf.keras.metrics.SensitivityAtSpecificity in TensorFlow', 'How to use num_thresholds in tf.keras.metrics.SensitivityAtSpecificity', 'Interpreting num_thresholds argument in TensorFlow metrics', 'TensorFlow SensitivityAtSpecificity metric explained', 'Examples of using tf.keras.metrics.SensitivityAtSpecificity with different num_thresholds', 'Why does num_thresholds greater than 1 return 1.0 in tf.keras.metrics.SensitivityAtSpecificity', 'Step-by-step guide to tf.keras.metrics.SensitivityAtSpecificity', 'TensorFlow metrics: Sensitivity and Specificity combined', 'How to set num_thresholds in TensorFlow SensitivityAtSpecificity metric', 'Practical examples of tf.keras.metrics.SensitivityAtSpecificity']","['What is the purpose of the num_thresholds argument in tf.keras.metrics.SensitivityAtSpecificity?', 'How does the num_thresholds argument affect the calculation of SensitivityAtSpecificity in TensorFlow?', 'Why does setting num_thresholds greater than 1 in tf.keras.metrics.SensitivityAtSpecificity return a metric value of 1.0?', 'Can you provide examples of using tf.keras.metrics.SensitivityAtSpecificity with different num_thresholds values?', 'What is the relationship between sensitivity and specificity in tf.keras.metrics.SensitivityAtSpecificity?', 'How does tf.keras.metrics.SensitivityAtSpecificity handle different threshold values when num_thresholds is set to a value greater than 1?']",set(),[],{'https://stackoverflow.com/questions/56286350/tf-keras-metrics-specificityatsensitivity-num-thresholds-interpretation'},"['""""""tf.keras.metrics.SpecificityAtSensitivity num_thresholds interpretation\n\nI'm trying to get my head around tf.keras.metrics.SensitivityAtSpecificity. I\'m fine with the concept of sensity and specificity in isolation, but I'm unsure how the two are related in this single metric. More specifically, I'm unsure how to interpret the num_thresholds argument. The example in documentation has num_thresholds=1. Setting num_thresholds greater than 1 with the same input data seems to always return a metric value of 1.0. def print_metric_value(num_thresholds): # other values based on docs example m = tf.keras.metrics.SensitivityAtSpecificity( 0.4, num_thresholds=num_thresholds) m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9]) print(\'Result with num_thresholds = %d: %.1f\' % (num_thresholds, m.result().numpy())) print_metric_value(1) # 0.5 - same as docs print_metric_value(2) # 1.0 print_metric_value(200) # 1.0\n\n. The num_thresholds refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0). For example, consider the prediction vector as [0, 0.5, 0.3, 0.9] which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of 0.1, we get [0, 1, 1, 1]; or if we apply threshold value of 0.6 we get [0, 0, 0, 1] (i.e. only the confidence of last prediction is higher than 0.6). Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What SensitivityAtSpecificity metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given 0.4 as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to SpecificityAtSensitivity metric, just swap ""specificity"" and ""sensitivity"" in this paragraph. You might also ask: what are the threshold values? The answer is if num_thresholds=1 then the only threshold is 0.5. If num_thresholds > 1 then, besides 0 and 1 as thresholds, the interval (0,1) will be split into num_thresholds - 1 equal sub-intervals and the split points are chosen as additional threshold values. For example:\n\nnum_threshold | thresholds ============================= 1 | [0.5] 2 | [0, 1] 3 | [0, 0.5, 1] 4 | [0, 0.33, 0.66, 1] 5 | [0, 0.25, 0.5, 0.75, 1] ... 6\n\nExactly the answer I was looking for. Turns out my data leads to ambiguous thresholds - anything in (0, 0.5) gives a specificity of 0.5 (closest possible value to 0.4), but the sensitivity value changes dramatically at 0.3\n\nOne final question: am I right in concluding that SpecitivityAtSensitivity(anything, num_thresholds=1) is equivalent to Specitivity(0.5)?. The SpecitivityAtSensitivity(anything, num_thresholds=1) would be equivalent to returning the specificity value at threshold 0.5, because that\'s the only threshold we have considered. I'd just assumed it existed, guess not :).""""""']","The question addresses the interpretation of the `num_thresholds` argument in the `tf.keras.metrics.SensitivityAtSpecificity` metric. This metric is designed to compute the best sensitivity where the specificity is greater than or equal to a specified value. 

The `num_thresholds` parameter determines the number of thresholds to be used for matching the given specificity. A threshold in this context is a value in the range [0,1] that determines whether a prediction is considered positive or negative. For example, with a threshold of 0.5, predictions greater than 0.5 are considered positive, and those less than or equal to 0.5 are considered negative.

When `num_thresholds` is set to 1, the only threshold considered is 0.5. This means that the metric will evaluate the specificity and sensitivity at this single threshold. If `num_thresholds` is greater than 1, the interval (0,1) is split into `num_thresholds - 1` equal sub-intervals, and these split points, along with 0 and 1, are used as additional thresholds. For instance, if `num_thresholds` is 2, the thresholds are [0, 1]; if `num_thresholds` is 3, the thresholds are [0, 0.5, 1]; and so on.

The metric computes the specificity at each threshold and selects the threshold that has the closest specificity to the specified value. It then computes the sensitivity at this selected threshold and returns it as the metric value. 

In the provided example, setting `num_thresholds` to 1 results in a metric value of 0.5, which matches the documentation. However, increasing `num_thresholds` to values greater than 1 (e.g., 2 or 200) results in a metric value of 1.0. This occurs because the data leads to ambiguous thresholds where any threshold in the range (0, 0.5) gives a specificity of 0.5, but the sensitivity value changes dramatically at 0.3.

In conclusion, the `num_thresholds` parameter controls the granularity of the thresholds used to compute the specificity and sensitivity. When `num_thresholds` is set to 1, it is equivalent to evaluating the specificity at a threshold of 0.5. For values greater than 1, the metric evaluates multiple thresholds to find the best sensitivity at the specified specificity."
74005009,tf.data.Dataset,example required,How to create output_signature for tensorflow.dataset.from_generator,"<p>I have a generator yielding data and labels <code>yield data, labels</code> where the data is
an <code>numpy.ndarray</code> with variable rows and 500 columns of type <code>dtype=float32</code> and the labels are integers of <code>numpy.int64</code>.</p>
<p>I'm trying to pass this data into TensorFlow from_generator function to create a TensorFlow dataset: <code>tf.data.Dataset.from_generator</code></p>
<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">docs</a> say that the from_generator function needs a parameter <code>output_signature</code> as an input. But I'm having trouble understanding how to build this output_signature.</p>
<p>How can I make the output_signature for the generator I described?</p>
<p>Thank you!</p>
<p>Edit:
I used <code>tf.type_spec_from_value</code> to get this:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
   datagen_row,
   output_signature=(
      tf.TensorSpec(shape=(None, 512), dtype=tf.float32, name=None),
      tf.TensorSpec(shape=(), dtype=tf.int64, name=None)
   )
)
</code></pre>
<p>But is it correct to use None when the number of rows is varying for the first data type?</p>
","<p>if your datagen_row() function yields input_data, label with format 500 and 1
than your output_signature should be:</p>
<pre><code>  output_signature=(
  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),
  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))
</code></pre>
<p>where the first TensorSpec is for the data format and the second one for the label format.
But it would be helpful if you post the function + maybe data examples or data shape here. Otherwise it is hard to help.</p>
","If your datagen_row() function yields input_data, label with format 500 and 1 than your output_signature should be:
<pre><code>  output_signature=(
  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),
  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))
</code></pre>
where the first TensorSpec is for the data format and the second one for the label format. But it would be helpful if you post the function + maybe data examples or data shape here. Otherwise it is hard to help.","<pre><code>  output_signature=(
  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),
  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))
</code></pre>","['How to use tf.data.Dataset.from_generator with variable row numpy arrays in TensorFlow?', 'What is the correct way to define output_signature for tf.data.Dataset.from_generator when the data has variable rows?', 'Can tf.TensorSpec handle variable dimensions in TensorFlow datasets?', 'Examples of using tf.data.Dataset.from_generator with variable shape data', 'How to use tf.type_spec_from_value to generate output_signature for TensorFlow datasets?']","['How to use tf.data.Dataset.from_generator with variable row numpy arrays?', 'What is the correct way to define output_signature for tf.data.Dataset.from_generator when the number of rows is variable?', 'Is it correct to use None for the shape in tf.TensorSpec when the number of rows is variable?', 'Examples of using tf.data.Dataset.from_generator with variable shape tensors', 'How to handle variable shape data in TensorFlow datasets?']",set(),[],{'https://stackoverflow.com/questions/74005009/how-to-create-output-signature-for-tensorflow-dataset-from-generator'},"['""""""How to create output_signature for tensorflow.dataset.from_generator\n\nI have a generator yielding data and labels yield data, labels where the data is an numpy.ndarray with variable rows and 500 columns of type dtype=float32 and the labels are integers of numpy.int64. I\'m trying to pass this data into TensorFlow from_generator function to create a TensorFlow dataset: tf.data.Dataset.from_generator\n\nThe docs say that the from_generator function needs a parameter output_signature as an input. But I\'m having trouble understanding how to build this output_signature. How can I make the output_signature for the generator I described? Edit: I used tf.type_spec_from_value to get this:\n\ndataset = tf.data.Dataset.from_generator( datagen_row, output_signature=( tf.TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), tf.TensorSpec(shape=(), dtype=tf.int64, name=None) ) )\n\nBut is it correct to use None when the number of rows is varying for the first data type? 1\n\nIf possible, add some dummy data with generator. if your datagen_row() function yields input_data, label with format 500 and 1 than your output_signature should be:\n\noutput_signature=( tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None), tf.TensorSpec(shape=(), dtype=tf.int64, name=None))\n\nwhere the first TensorSpec is for the data format and the second one for the label format. But it would be helpful if you post the function + maybe data examples or data shape here.""""""']","To create the `output_signature` for `tf.data.Dataset.from_generator` when your generator yields data and labels, where the data is a `numpy.ndarray` with variable rows and 500 columns of type `dtype=float32` and the labels are integers of `numpy.int64`, you need to define the `output_signature` using `tf.TensorSpec`. 

The `output_signature` parameter is a nested structure of `tf.TypeSpec` objects that specifies the type and shape of each component of an element yielded by the generator. In your case, the data has a variable number of rows and a fixed number of 500 columns, and the labels are scalar integers.

For the data, you should use `tf.TensorSpec` with `shape=(None, 500)` to indicate that the number of rows is variable, and `dtype=tf.float32` to match the data type. For the labels, you should use `tf.TensorSpec` with `shape=()` to indicate a scalar value, and `dtype=tf.int64` to match the label type.

Using `None` for the number of rows in the `shape` is correct when the number of rows is variable. This allows TensorFlow to handle batches of data with different numbers of rows while maintaining the fixed number of columns.

In summary, the `output_signature` should be defined as a tuple of `tf.TensorSpec` objects, where the first `TensorSpec` corresponds to the data with a shape of `(None, 500)` and `dtype=tf.float32`, and the second `TensorSpec` corresponds to the labels with a shape of `()` and `dtype=tf.int64`. This setup ensures that TensorFlow correctly interprets the structure and types of the elements yielded by your generator."
60013980,tf.nn.embedding_lookup_sparse,example required,tf.nn.embedding_lookup_sparse 3D sparse tensor input,"<p>I have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse"" rel=""nofollow noreferrer""><code>tf.nn.embedding_lookup_sparse</code></a> I found it only supports 2D sparse tensors,</p>

<blockquote>
  <p>sp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary.</p>
</blockquote>

<p>My example code here</p>

<pre><code>import numpy as np
import tensorflow as tf
tf.enable_eager_execution()

# [feature number, embedding dim] 
w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer())

z = np.array(
     [
      [
        [0, 1, 2, 3],   # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum
        [2, 3]
      ],

      [
        [1, 3],
        [2]
      ],

      [
        [0, 1, 3],
        [1, 2]
      ]
     ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2],
                              [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0],
                              [2,0,1],[2,0,3],[2,1,1],[2,1,2]],
                     dense_shape=[3, 2, 4])

tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')
# the outputs
&lt;tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy=
array([[-5.8729677 , -1.3900641 ,  0.8126096 , -3.1223912 ],
       [-1.0788026 , -1.1324122 ,  0.34160078,  0.23714277],
       [-2.497394  , -2.7855003 ,  3.0201516 , -1.8009453 ]],
      dtype=float32)&gt;

print(w)
&lt;tf.Variable 'w:0' shape=(4, 4) dtype=float32, numpy=
array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)&gt;
</code></pre>

<p>But the expected output is a matrix with a dimension of <code>3x2x4</code>, not <code>3x4</code>. Does <code>tf.nn.embedding_lookup_sparse</code> support this operation?</p>
","<p>The most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape.</p>

<pre class=""lang-py prettyprint-override""><code># First make the z as a 2D arr and create a sparse tensor 
z = np.array([
        [0, 1, 2, 3],  # get the row 0,1,2,3 of the embedding matrix w and get the sum
        [2, 3],
        [1, 3],
        [2],
        [0, 1, 3],
        [1, 2]
      ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1],
                              [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]],
                     dense_shape=[6, 4])

res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')

res.numpy()
# the output
array([[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
       [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ],
       [ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
       [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]],

# reshape
tf.reshape(res, [-1, 2, 4])
# that is exacly what I want.
array([[[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
        [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ]],

       [[ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
        [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532]],

       [[-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
        [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]]])

# print w, and the above result is right
w.numpy()

array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)
</code></pre>

<p>So, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.</p>
","The most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape.
So, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.

","<pre class=""lang-py prettyprint-override""><code># First make the z as a 2D arr and create a sparse tensor 
z = np.array([
        [0, 1, 2, 3],  # get the row 0,1,2,3 of the embedding matrix w and get the sum
        [2, 3],
        [1, 3],
        [2],
        [0, 1, 3],
        [1, 2]
      ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1],
                              [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]],
                     dense_shape=[6, 4])

res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')

res.numpy()
# the output
array([[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
       [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ],
       [ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
       [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]],

# reshape
tf.reshape(res, [-1, 2, 4])
# that is exacly what I want.
array([[[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
        [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ]],

       [[ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
        [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532]],

       [[-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
        [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]]])

# print w, and the above result is right
w.numpy()

array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)
</code></pre>","['How to use tf.nn.embedding_lookup_sparse with 3D sparse tensors?', 'Alternatives to tf.nn.embedding_lookup_sparse for handling 3D sparse tensors in TensorFlow', 'How to reshape the output of tf.nn.embedding_lookup_sparse to match the expected dimensions?', 'Using tf.nn.embedding_lookup_sparse with higher-dimensional sparse tensors', 'TensorFlow embedding lookup for 3D sparse tensors tutorial']","['Does tf.nn.embedding_lookup_sparse support 3D sparse tensors?', 'How to use tf.nn.embedding_lookup_sparse with 3D sparse tensors?', 'What are the limitations of tf.nn.embedding_lookup_sparse in terms of tensor dimensions?', 'Are there any alternative TensorFlow functions to perform embedding lookup with 3D sparse tensors?', 'How to reshape the output of tf.nn.embedding_lookup_sparse to match the expected dimensions?']","{'https://www.youtube.com/watch?v=t3z0bOsaDQ0', 'https://www.youtube.com/watch?v=vbHX5R1rIo8'}","['""""""[Document(page_content=""today i want to go over the basics of sparse tensors and spatially sparse neural networks this is a part of the gtc talk titled take your deep learning to high dimensions with tensor methods i\'m chris choi and i work as a research scientist at nvidia before i joined nvidia i studied and developed 3d perception reconstruction and registration algorithms and my thesis was on high dimensional convolutional neural network for 3d perception currently i develop state-of-the-art 3d perception algorithms and maintain minkowski engine a neural network library for spatially sparse tensors in this section we\'ll discuss a new type of neural networks that can process point clouds 3d video or high dimensional data efficiently this is an example of a 4d network defined on the spatial temporal space that can process 3d videos or a sequence of 3d scans on the top right you can see that the network semantically segments the data and matches the ground turns on the bottom left corner before we proceed let\'s talk about the type of sparsity in a neural network here in this example we\'re feeding an image into a network and an image is a rank 3 tensor since it consists of xy plane and a color channel then we convolve this input with a set of network weights which is also a dense tensor so there are two types of tensors network rates and input or output features if we make the net neural network weight sparse we have a sparse convolutional neural networks and this has been the key component for network compression however we can add sparsity in the input specifically we can embed sparsity in position rather than the channels let\'s take this image as an example here we have a digit on the white background if we zoom in we can see that most of the region is 0. this forms a sparse matrix and the sparsity is in the position of the input and if the data has too many zeros then simply we can discard zeros and store data more efficiently in 3d space such spatial sparsity is more pronounced this is an example of 3d scan of a room and you can see that there\'s a lot of empty space in the data and the problem gets even worse as we increase the resolution of the space if we quantize the space with 20 centimeter voxels in the previous example 78 of the space is zero if we further increase the resolution and use 2.5 centimeter voxel the 98 of the space is empty and has value zero so if we apply any operators such as convolution and this dense tensor with 98 percent of zeros most of the computation will just take zeros as an input and return zeros as output in other words we\'re wasting 98 of the computation processing zeros then how can we save computation as well as excessive memory consumption let\'s say that we have a sparse matrix with values on its diagonal here we\'re saving all of its elements including zeros but instead we can save danzig values and their coordinates by representing a sparse matrix as a set of coordinate and value pairs of non-zero elements here since we have four on the first row and first column we save the coordinate at zero comma zero and its value 4. similarly we save value 1 and 1 comma 1. a sparse tensor is a high dimensional extension of a sparse matrix for example if we stack additional sparse matrix along a new dimension we have a sparse tensor if we also represent a sparse tensor as a list of matrices it could be very inefficient so we can save a set of coordinates and values of nonzero elements like this to give you a concrete example let\'s convert this scan into a dense tensor which gives us a size 400 by 200 by 100 dense tensor if we use channel size 128 per voxel then we need 4 gigabyte of gpu memory just to save the room but by discarding zeros and saving only the coordinates and values of non-zero elements it requires mere 180 megabytes to store the same data so we can see how efficient this representation could be for 3d or higher dimensional spaces easily this representation is known as the coordinate list representation in high dimensional spaces is it is also known as the high co representation in a neural network context however we do not use a scalar for feature we use vectors for features so the sparse tensor has the rank d plus one where d is the number of dimensions in the space and one for the feature vector and we can represent this compactly using two matrices coordinate and feature matrices like this now that we\'ve defined a sparse tensor let\'s discuss how we can extend convolution which is one of the most fundamental operators for perception to sparse tensors here i visualized a simple convolution on a 2d plane for each output pixel we extract features from the input and compute the weighted sum if we do the same for the rest of the output pixels then we have the convolution output we can define convolution on a sparse tensor in the same manner for each pixel on the output we can compute the weighted sum like before but for sparse tensors we compute weighted sum for non-zero values only if we do the same for the rest of the pixels of interest on the output we have the convolution output on the sparse tensor we call this generalized convolution since it allows us to compute convolution on arbitrary sparsity patterns on both input and output sparse tensors the standard neural network library such as pytorch and tensorflow do not support such generalized convolution so to use spatially sparse tensors you need pytorch or tensorflow extensions and minkowski engine is one of these few extension libraries that provide autodev functions for spatially sparse sensors it is open sourced on nvidia github page and provides many gpu optimized functions as well as examples and api documents so using minkowski engine you\'ll be able to create 3d networks in the way that you created standard 2d neural networks for example this is in your network architecture for classification in the 3d space and the input sparse tensor has 3d spatial dimensions although the convolution blocks look tense all features are sparse tensors and thus the network can process very high resolution point clouds similarly we can create semantic segmentation networks that process the entire point cloud fully convolutionally and generate symmetric segmentation of the 3d input scans here i visualize the 3d u-shaped network or pyramid network on the top note that the network has skip connections across network like units and image perception on the bottom i visualize the input sparse tensor on the left and a network prediction on the right also one of the contributions of the generalized convolution is that it supports generated architectures such as sheet completion and reconstruction on the top the completion network takes a partial 3d scan of a chair and generates a completed 3d chair as an output on the bottom the generation network creates a sparse tensor as an output from on one hot vector and minkowski engine supports all these architectures on gpu here i visualize the feed for time in log scale using a combat with 42 layers on cpu v100 and a100 respectively the size of the sparse tensor ranges from 100 000 to 3 million and is on the x-axis of both graphs the right graph i visualize the speed up of v100 and a100 over cpu as you can see from both graphs processing these large data with gpu is extremely fast and with gpus it gives us around 100x to 300x speedups first here\'s an example of 2d data with batch size 2. the first chunk represents batch index 0 and the second chunk represents patch index one in pi torch we simply create a dense tensor with zeros and the shape of the data is batch times channel times height times width however in a sparse tensor we only save coordinates and features of non-zero elements first we have 2.1 here since it is on the zeroth patch zeroth row and the zero second column we put zero comma zero comma two on the coordinate and for features we put two point one similarly uh we skip all the zeros and go to the next row and we have one and it is on the zeroth patch first row first column so we put zero comma one comma one on the coordinate and we put one on the feature once you finish collecting all nonzero elements you can simply feed the coordinates and features to the sparse tensor class to create a high dimensional sparse tensor creating a neural network is also very simple we add a list of layers to a pi torch module or you can extend the pytorch module superclass exactly the same way you create a 2d component on pytorch then you feed the sparse tensor you created before by passing it as an argument to the network for more information please visit the minkowski engine api page and examples the api page of minko scanton is available in github.com nvidia slash minkowski engine thank you for your attention"", metadata={\'source\': \'t3z0bOsaDQ0\'})]""""""', '""""""[Document(page_content=""WEI WEI: Hi there. Welcome back to our video series\\nof building recommendation systems with TensorFlow. My name is Wei. And I\'m a Developer\\nAdvocate at Google. If you are building\\nlarge scale recommenders, one of the biggest\\nchallenges must be with the large embedding\\ntables in your model. These embedding tables\\nare critical components. But the embedding lookup\\noperations on them are usually very expensive\\nto run, which makes them a performance bottleneck. So in this video,\\nwe\'re going to discuss how to tackle this challenge\\nwith TPU embeddings. Let\'s first refresh\\nour memory on how retrieval works in modern large\\nscale recommendation systems. First, we train a\\nneural network model, for example, the\\nclassical two tower model, to learn how to map query an\\nitem into a joint embedding space. Second, we map all [? kind ?]\\nitems in the embedding space with a learned item tower. Lastly, at runtime, we embed\\nthe query into query embedding and look up the nearest items\\nin the embedding space using vector similarity search. What was [INAUDIBLE] scan\\ncan accelerate the vector similarity search. Training the embedding\\ntables might be quite challenging in the first place. If you have a large vocabulary\\nof users or items, say more than 100 million\\nitems to recommend, or some high-dimensional\\nsparse features, you will need large\\nembedding tables to store embeddings for them. These embedding tables often may\\nnot fit on a single accelerator chip. So now, you have to share them\\nacross multiple accelerators, which introduces\\ncommunication overhead and makes the lookup\\noperation expensive. While there are some\\nsoftware-based solutions that aim to alleviate this,\\nit would be better to tackle this from both\\nthe hardware and software side, which leads\\nus to TPU embedding. On Google\'s latest\\nTPUs, there are specifically-designed\\nhardware on-chip called SparseCore, which is\\ndedicated to accelerating embedding lookup operation. SparseCore, together with\\nultra-fast chip-to-chip interconnect and the software\\nprogramming interface, TPU embedding API, gives\\nsignificant speed-up over large\\nrecommendation models. Here\'s an example\\nperformance benchmark for a Google internal\\nproduction recommender model. As you can see, by using TPU\\nembedding on TPU v3 and v4, there is a 10x and 30x speed-up\\nover embeddings placed on CPU, which is simply amazing. You can find out more in\\nthe paper linked below. Now you have seen the\\npower of TPU embeddings, How do you use them? Let\'s walk through\\na simple example to understand how to\\nleverage TPU embeddings. Since TPUs live on\\nGoogle Cloud, we need to have a GCS bucket to\\nfeed the data to the TPUs. We\'re going to use\\nthe same old movielens 100k data set as before. But this time, we convert\\nthe user IDs and movie IDs to integers. We shuffle and split the\\ndata set into training and test the sets as usual. Then we batch and\\ncache the data sets. Note that, here, strategy\\nis a TPU strategy object defined in advance. And then we convert them\\nto distributed data sets. Next, we define the\\noptimizer and table configs. To place the embeddings\\non TPU SparseCore, we need to define table configs,\\nwhich specifies the vocabulary size and embedding\\ndimension, and then associate features\\nwith table configs through feature configs. So here, we are placing movie\\nID on the movie table and user ID on the user table. Now, we can define our\\nrecommendation model. It\'s very similar with the\\ntypical tf recommender ranking model, except, this\\ntime, we\'re using tfrs.layers.embe\\ndding.TPUEmbedding instead of a vanilla TensorFlow\\nembedding layer. And we pass the feature config\\ninto the TPU embedding layer along with the optimizer. Next step is to define the\\ncore and compute loss methods. Note that, when we\\nsum up the loss, we need to scale it down by a\\nfactor of global batch size, which is equal to the product\\nof per replica batch size and\\nstrategy.num_replicas_in_sync. Finally, we compile, fit,\\nand evaluate the model. After training, we can save\\nthe model to a GCS bucket. And we can restore\\nthe checkpoint later. And we can also restore the\\nTPU-trained weights on CPU. Finally, we can\\nexport the CPU model as saved_model for serving. We can pass a user_id and a\\nmovie_id to the loaded model and then get a\\nrating prediction. So to sum up, today, we\\nintroduced you to TPU embedding and walked through how to\\nleverage it to accelerate embedding operations. Although it\'s a\\npretty simple model, I hope it gives you a good\\nconceptual understanding of how it works. If you want to learn more,\\nour colleague, [INAUDIBLE],, who is a Product Manager\\nfor TPU Embedding, gave a more detailed talk at\\nour recommendation system dev summit. We also had a guest speaker,\\n[INAUDIBLE] from Snap, to share their practical\\nexperience with TPU embeddings. I highly recommend watching\\nthat session in the link below. With that, thank you\\nfor watching this video. I\'ll see you next time. [MUSIC PLAYING]"", metadata={\'source\': \'vbHX5R1rIo8\'})]""""""']","{'https://stackoverflow.com/questions/60013980/tf-nn-embedding-lookup-sparse-3d-sparse-tensor-input', 'https://stackoverflow.com/questions/39207587/how-to-use-tf-nn-embedding-lookup-sparse-in-tensorflow', 'https://stackoverflow.com/questions/34870614/what-does-tf-nn-embedding-lookup-function-do'}","['""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\n I have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""', '""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\n I have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""', '""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\nAsked 4 years, 2 months ago\n\nModified 4 years, 2 months ago\n\nI have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""', '""""""Any comment could be appreciated. After diving into safe_embedding_lookup_sparse\'s unit test, I'm more confused why I got this result if giving the sparse weights, especially why we got something like embedding_weights[0][3] where 3 is not appeared in the code above. 4\n\nPlease, let me know if my answer solved your problem :)\n\nThanks @rvinas . I don't figure it out yet after reading safe_embedding_lookup_sparse's unit test. I have updated the question and would you like to explain the code for us?""""""', '""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\nI have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""']","The question addresses whether `tf.nn.embedding_lookup_sparse` supports 3D sparse tensors for embedding lookups, given that the expected output is a matrix with dimensions `3x2x4`, not `3x4`.

`tf.nn.embedding_lookup_sparse` is designed to look up embeddings for given ids and weights from a list of tensors. According to the TensorFlow API documentation, `sp_ids` must be a 2D `SparseTensor` or `RaggedTensor`. This means that `tf.nn.embedding_lookup_sparse` does not natively support 3D sparse tensors.

In the provided example, the user has an embedding matrix and a 3D sparse tensor. When attempting to use `tf.nn.embedding_lookup_sparse`, the output is a matrix with dimensions `3x4`, which does not match the expected `3x2x4` dimensions. This discrepancy arises because the function only supports 2D sparse tensors, and thus, it cannot directly handle the 3D sparse tensor input.

To achieve the desired output dimensions, the recommended approach is to convert the 3D sparse tensor into a 2D sparse tensor. This involves flattening the 3D structure into a 2D array, performing the embedding lookup, and then reshaping the result back into the desired 3D shape. By doing so, the embedding lookup can be performed correctly, and the final output can be reshaped to match the expected dimensions.

In summary, `tf.nn.embedding_lookup_sparse` does not support 3D sparse tensors directly. The solution is to convert the 3D sparse tensor into a 2D sparse tensor, perform the embedding lookup, and then reshape the result to the desired dimensions. This approach ensures that the embedding lookup operation is compatible with the function's requirements and produces the expected output shape."
57349824,tf.keras,example required,"Recurrent neural network, time series prediction with newer Tensorflow 1.14","<p>How to use new tf.keras API with recurrent neural network? I have checked the documentation but there is no example of such a situation.
There is this great book Hands on machine learning from 2017. Since that year the API of tensorflow has evolved and I am trying to rewrite recurrent neural network for time series prediction with using version <code>1.14</code> code.
The code from the book is using older <code>tf.nn.dynamic_rnn</code> and <code>tf.nn.rnn_cell.BasicRNNCell</code>:</p>

<pre><code>n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1
learning_rate = 0.001

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])
cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)
rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)
stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])
stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
loss = tf.reduce_mean(tf.square(outputs - y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()
n_iterations = 500
batch_size = 50

with tf.Session() as sess:
    init.run()
        for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})
</code></pre>

<p>And this code works just fine (except that it throws warnings about deprecation left and right). I wanted to use <code>tf.keras</code> API as suggested in warning. My code is the same except:</p>

<pre><code>cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)  
rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

<p>But this yields following exception:</p>

<pre><code>InvalidArgumentError: Input to reshape is a tensor with 50 values, but the requested shape requires a multiple of 20
 [[node Reshape_1 (defined at &lt;ipython-input-9-879361be49dd&gt;:3) ]]
</code></pre>

<p>so I understand that the problematic line is</p>

<pre><code>outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
</code></pre>

<p>After checking and comparing documentation for both cells <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a> and 
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN</a> I can't find the culprit.</p>

<p><strong>What is the difference with these two cells? How to use tf.keras API with time series?</strong></p>

<p>Full old code: <a href=""https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb"" rel=""nofollow noreferrer"">https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb</a></p>

<p>Full ""my"" code:</p>

<pre><code>import numpy as np
import tensorflow as tf
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd
from utils import shuffle_batch, variable_summaries
import os


dir_path = os.getcwd()

now = datetime.utcnow().strftime(""%Y%m%d%H%M%S"")
root_logdir = ""tf_logs""
logdir = ""{}/run-{}/"".format(root_logdir, now)
print(dir_path)


t_min, t_max = -5, 5
section_start = (t_max + t_min) / 2
resolution = 0.1
n_steps = 20

def time_series(t):
    return np.sin(t)

def next_batch(batch_size, n_steps):
    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)
    Ts = t0 + np.arange(0., n_steps + 1) * resolution
    ys = time_series(Ts)
    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)


t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))

t_instance = np.linspace(start = section_start, stop = section_start + resolution * (n_steps + 1),num = n_steps + 1)

plt.figure(figsize=(11,4))
plt.subplot(121)
plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"")
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)
#plt.axis([-10, 10, -17, 13])
plt.xlabel(""Time"")
plt.ylabel(""Value"")

plt.subplot(122)
plt.title(""A training instance"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""c*"", markersize=10, label=""target"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")


# In[6]:


n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])


# In[7]:


cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)                        


rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
print(rnn_outputs.get_shape())


stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons], name='reshape1')
stacked_outputs = tf.keras.layers.Dense(n_outputs,name=""hidden2"")(stacked_rnn_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs], name='reshape2')


learning_rate = 0.001

loss = tf.reduce_mean(tf.square(outputs - y)) # MSE
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()

n_iterations = 1500
batch_size = 50
save_path =os.path.join(dir_path,""model"",""recurrent_sinus_model"")

with tf.Session() as sess:
    init.run()
    for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    saver.save(sess, save_path)


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})


plt.title(""Testing the model"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""w*"", markersize=10, label=""target"")
plt.plot(t_instance[1:], y_pred[0,:,0], ""r."", markersize=10, label=""prediction"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")

plt.show()


# In[ ]:


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t.reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})



plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"",linewidth=5,c='r')
plt.plot(t[:-1], time_series(t[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)

plt.xlabel(""Time"")
plt.ylabel(""Value"")
</code></pre>
","<p>So the answer is:</p>

<pre><code>rnn_outputs, rnn_states  = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)
</code></pre>

<p>instead of </p>

<pre><code>rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

<p>so the parameter <code>return_sequences=True</code> make the RNN return the time series as well, and well, this is the point.</p>
","So the answer is:
<pre><code>rnn_outputs, rnn_states  = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)
</code></pre>

instead of
<pre><code>rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

so the parameter <code>return_sequences=True</code> make the RNN return the time series as well, and well, this is the point.",,"['How to use tf.keras.layers.SimpleRNNCell for time series prediction in TensorFlow 1.14?', 'Differences between tf.nn.dynamic_rnn and tf.keras.layers.RNN in TensorFlow', 'How to reshape RNN outputs in TensorFlow using tf.keras API?', 'Time series prediction using tf.keras RNN layers in TensorFlow 1.14', 'Handling shape mismatches in TensorFlow RNNs with tf.keras API', 'Converting TensorFlow 1.x RNN code to tf.keras API', 'Best practices for using tf.keras.layers.RNN for time series data', 'Common errors and solutions when using tf.keras.layers.SimpleRNNCell']","['How to use tf.keras.layers.SimpleRNNCell with tf.keras.layers.RNN for time series prediction?', 'Difference between tf.nn.dynamic_rnn and tf.keras.layers.RNN in TensorFlow 1.14', 'How to reshape RNN outputs in TensorFlow 1.14 using tf.keras API?', 'Example of time series prediction using tf.keras.layers.SimpleRNNCell in TensorFlow 1.14', 'How to handle shape mismatch errors in TensorFlow when using tf.keras.layers.RNN?', 'Best practices for migrating from tf.nn.dynamic_rnn to tf.keras.layers.RNN', 'How to use tf.keras.layers.Dense with RNN outputs in TensorFlow 1.14', 'Common issues and solutions when using tf.keras.layers.RNN for time series prediction']","{'https://www.youtube.com/watch?v=Ng_uGKcWfIo', 'https://www.youtube.com/watch?v=T9u2XNWIn8s'}","['""""""[Document(page_content=""hello friends in this series of tutorial for the time series forecasting we are going to discuss the lstm network today so lstm is a artificially recurring neural network the rnn1 architecture which is a part of the deep learning method so today we will discuss about the uh multiple things you are relating to lstm first thing is that how it is differing from our legacy uh regression models so what you have learned till now like arima or ar or ma or arima model so how this lstm framework or this lstm network is differencing from that and the second thing is like how you can predict using lstm so we\'ll discuss it how theoretically it is done so it is like a short-term memory propagating over the train and test data and the last thing we will discuss like how using the loss function we can see that the prediction is accurate over the iteration of the epochs and then we will compare our actual test data with the predicted data with a very simple data set which we have i have borrowed from jason brownlee so he is the like mastermind in explaining his lstm you can go through his blog and you can learn it wonderfully but i just make a gist of it and all credit goes to him so let\'s begin so first thing is uh like where our legacy regression models fails so first thing is if your data is having too much noise or if your data is having outliers so then your regression model will fail and it will fail if there is a non-linear relationship between y and x the dependent and the independent variable and it will fail if you have a multivariate environment so always the time series prediction or forecasting you have done using an univariate environment so in case of multivariate it will fail now let\'s see how the lstm actually works so lstm works like let\'s say in your trained data you have like three you know um [Music] incidents or like three samples okay and using these three samples so let\'s say this is t minus 3 and for this one and this is t minus 2 and then it is t minus 1 so based on these three samples you have predicted the current t as 4 and then it will shift the training data and it will include this predicted data into the training data so now the training data will be two three and four and then the 5 will be generated so in this way this short term memory propagate over the predicted data and it will predict further so this is like you can say in in theoretical terms so this is a sequence prediction so this is a sequence of samples and how can you classify your sequence and how can you generate your sequence and using that sequence how can you predict the further sequence so that\'s how this is the whole fundamental of the lstm prediction you can check it in brownies blog i will give it in the description but this is in very short way how it is and the lstm lifecycle so what all things you need to do to get a prediction over lstm so it\'s very simple like you need to define the network and then you need to compile the network and then you need to fit the network and then you need to evaluate the network and make prediction so i will describe this one by one so now i have taken this data set the monthly car sales data set from the jason brownlee\'s blog and i read it using pandas and this is how the data is and you see the data varies over a very big range right so first thing first we will make the month or by the way i have described this as an univariate function but lstm works for the multivariate as well so i index the month field because that is the time field for me and then i just show you the data if the month is the time field and the cells is the like the output field what i need to predict and now i just decompose this data set and get like what is my like seasonality what is my trend and what is my uh residual so clearly this data is having a trend you see this is a trend and it has some seasonality because it has some uh trough and craft so let\'s proceed so first thing to fit the lstm what we need to do uh we need to erase the variance of the data because if the data varies uh over a very long range so it will like make the lstm a bad prediction [Music] the rstm will make a bad prediction so let\'s scale the data using the min max scalar and first i will define the min max scalar and i have borrowed it from the sql and preprocessing and then i just split the data using the train set and the test set and then i have used the keras preprocessing time series generator okay because it actually expect the lstm actually expect the data in a specific shape so what is that shape so that means the number of input in this sequence so you need to what is the sequence and what you how the sequence is generated so it\'s a very important part in the time series generation so in my example i have shown you like one two three so there is number of input is equal to three so n input is equal to three so i have given here six because i just make a permutation and combination and get a like a proper number of lags or number of inputs you require to predict this car sales data accurately so this can vary and you need to check what is your like adequate number so so in my case the n input is six like one two three four five six there are six samples in my trained data set and that will propagate over all the predicted data so one by one the predicted data will come in this input field and one by one well the oldest lag will it will be erased from this number of samples and since i have given you the only univariate data the number of features is equal to one so if it is a multivariate data this will be greater than one and then i generate these shapes uh from my trained data and test data i will show you how the data will look like so let\'s run it and then i just get only one data uh like from this generated trend and i will show you how the data look like so i as i have told like i just scale the data that\'s why you are getting this kind of decimal numbers but you see there are six samples in this data set so this is a input and this is the output so this is how the shape will be defined so you know that sequence shape should be defined in this way number of input and then output and then this will be shifted here and this will be your output that\'s the way and very important you always generate this shape because before you predict further let\'s proceed and i just show you the entire data that how it looks like so you see that all these data is actually regenerating this kind of output and this is a like a multi-dimensional array uh how this shape is defined so that\'s why i just show you how it is so uh i have used like most simple lstm framework like the vanilla iron the how can you say that it is vanilla because it\'s like a very simple and i have used the hyperbolic time function using mimic for my activation function [Music] and this is the output dimension so this is the output dimension and this is the activation function so i have defined the hyperbolic tangent and this is my input shape number of input and number of features to be predicted then this is how your model is defined using this add and compile and then i fit my the training data for this particular epoch so i have defined here 300 epochs so how i got this number 300 because you need to check the loss function and if your loss function reaches like a number like 0.001 then you can say this is properly diminished and it has a problem of like exploding the loss function as well so you need to avoid that so you need to always have the loss function diminished towards like 0 very near to 0 like 0.001 let\'s see how my loss function once i okay i have not run it so i have used these three things the from keras model i have used the sequential and ah from keras layer i have used the dense and i have imported the lstm framework as well so now your data is fitting over 300 epochs so it will take time i will just skip it to the end result and you see your loss function value is diminishing so it is now 0.01 so it started from the 0.05 you can say almost like your 5 percent and you need to reach till ah 0.1 percent kind of thing like 0.001 [Music] so initially i started with 50 epochs and then i say that in 50 epochs that is not diminished properly so that\'s why i increase the number and i get like where it is diminished properly you can also put a graph ah to get this kind of loss function plot so that you can easily check whether it is divisible towards 0 or not but if better than graph you can check it easily using this loss function value it generates so now see you see that uh this loss value is like divine is to very near to zero so it is like or in every case it is near to 0.001 or less than that so let\'s proceed with this fitted data and let\'s check our prediction so to predict it so you see uh what i have explained that whatever prediction you have done so that will be included for the next prediction that\'s how it is actually taking care of that non-linear relationship right like your test data time is also part of your trend data or your predicted data is also part of your trend data if you proceed further so that is like a sequence creation sequence generation and sequence prediction so how it is done [Music] so first thing is that i have used this fitted model and i have created the current prediction and then i appended this prediction in my predicted data so that i can plot it and i can compare it with my test data and then i remove the like the oldest lag from my current batch so you say that you can say that the you know the dynamic training data is having like a current patch so this is the like the batch i have generated and this is my first batch like with a number of inputs like the last six input of my training data so training data sorry i just used my mouse and it will have like last six value so if it is like six it will be five into four three two one okay and this is the last six value of my training data and i have removed everything else and then this is my first batch and how that first batch is reshaped in the same way like number of inputs and number of features and then i proceed and take it from one like i just remove one and if i have predicted seven so that will be included in these steps so i just removed it first and then i added this current prediction with my current batch and then make this as my current batch so this is how it is so these are very important steps you just need to generate the sequence and you need to reshape the sequence so this is very important steps and then once you predicted all the data you can like plot it as it is or you can uh rescale it to your old actual value because you just use a scalar value right so scaled value you can retransform it to your old value non-scale value and you can plot and compare with my test data so i have just checked that as well you can use the like mean square error as well so you see this is almost like implying that test data so the prediction is good you can check it using the msc score as well so that is how it is and for the loss function i have used the msc here you can check so this is how you can use the lstm network to predict the time series data and it is far better than the regression model in case of nonlinear relationship or if you have like the noise or outliers or if you have the multivariate environment thank you so much please stay tuned for more videos in this series thank you so much"", metadata={\'source\': \'T9u2XNWIn8s\'})]""""""', '""""""[Document(page_content=""[Music] hey everyone how\'s it going my name is daryl welcome back to my channel today i\'m going to talk about how to reshape input data for long short term memory network often it can be difficult to understand how to prepare your sequence data for input to an lstm model there\'s a confusion about how to convert your 1d or 2d matrix to the required 3d format for an lstm inputs also often there\'s a confusion around how to define the inputs layer for the rstm model so in this tutorial you will learn three things the first is how to define a lstms inputs layer and then you will learn how to reshape multi-parallel series data for lstm inputs and finally you will learn how to build and train a lstm model ready to go let\'s get started to make it easy to follow you can download this notebook from github and follow along with this step-by-step tutorial the most critical part of this video is to teach you how to reshape the multiple parallel series status that you have for a rstm inputs the rstm inputs layer is specified by the input arguments that is the input shaped arguments on the first hidden layer of the network so in that in that case this can make things confusing for beginners and the inputs to every rscm layers that has to be three-dimensional which is um which is unlike what we have with the traditional new network the three-dimensional them the three-dimensional dimensions of these inputs including the samples the time steps and also the features this means that the input layer expects a 3d array of data when fitting the models and when making predictions even if specified dimensions of the arrays contain only a single value or one sample or only one feature we still need to create it as a 3d shape so let\'s learn it by doing first thing first uh let\'s import the data set um to use we are going to import the data with the use of penders so we\'re going to impose the pandas frameworks and at the same time because we need to work with the 3d arrays so which is a nd numpy rate so we need to import the numpy framework as well and in this example what we\'re going to do is to download the data from the aemo which is the australian energy market operators download electricity data that includes the price and also the electricity consumptions so you can actually follow this link to download the data and then i already download the data and append them month by month and then you can see that we already have around one and a half years later with these datas what we\'re going to do is to use the electricity demand state data and the price data in the previous date to predict what is happening in the next 30 minutes about the price so to predict the price at 30 minutes later now let\'s take a look on the csv file first we have the index columns because i append the data month by month so i still keep the original index columns for in in the column a and then for the column b that is for the regions uh this is the victoria regions and then for the settlements that is the settlement dates and settlement times and and then we have the total demands for that period of times and then the fh price for that period of times and that is um the columns and the datas that we have so the first things that we are going to do is use the pd.we switch csv files to with this data into a data frame and this is the data frame that we just um that we just extracted from the csv file and let\'s take a look on the types for each of the columns and for the index that is an integer regions that is an object settlement date that is an object the total demands and the price are the floating and then the period types is another object there are three columns that we\'re going to use including the settlement days total demands and also the price and you can see that the settlement days right now is an object ties and total demands and the price are the floating types so the first thing that we need to do is to convert these settlement dates from an object types to a date time object in that case what we are going to do is to use the built-in methods that is two days time methods to convert these types the columns that we would like to convert is the df settlement date that is the first argument and then the second argument is that we set the dates first equals to true it means that um the first uh the first uh the first value here is a date and then followed by month and then by years so we set the date first equals to true and here we assign as a new columns that is called the date time and then for this one now because this this is a dates time objects so we can just convert it we can just use the daytime memphis that is a wt dot day to extract the day and to extract the month the years the hours and also the minutes so in total you can see that there is a six additional column show here that includes the date time uh which is a day times objects the days the month the years the hours and also the minutes now if we print out the column types you can see that the date times is a day times objects and then followed by the integer types for for the day month years hours and minutes and normally and these um these total demands and also price might not be the data types that you want so in that case you might want to use the two numericals to change the types of these total demands and also the the price and in this case it\'s already it\'s the white types but still i just want to show you the how to convert these object types to a numerical in that case we use the top two numerical methods and then the first argument is that you say total is the uh is the total demand columns and then for this one the first the first argument is the price column here we set the errors equals to coerce it it means that for any missing value we will just fill it up with nan and so we then assign it to a data frame with the new columns called demand and price and if we take a look on the data types and now we have the demand and price that is a numerical data the next things that i would like to do is to drop out all the other columns that are not needed in this data frame and that includes the index regions settlement days total demands our our pre period types so all of them will be dropped out and now what we have uh in this data frame that includes the price the demands and also the day month years hours and minutes and now we are ready to transform the data the first things that i would like to do is to create a and empty leads uh for each of the features and also the targets and then with this and the list what we\'re going to do is to append each of the values into these empty leads so what i\'m doing here is actually like this is that i take out 47 points for the x points and then i shift one step and and another 48 points and then continues to append to the empty leads so in that case what we are going to have is that we have a bunch of samples over here and then for each of the sample we have 48 points and this is for the demands columns and then i\'m going to append the dates the month the years the hour the minutes the demands and also the price with similar logic and so you can see i just take out all previous 48 steps and then appends into each of the and and the pants in each of the row in these uh or each of the elements in this empty list and that is for the features for the target is like this so this is 40 accept so this let me highlight this for you this is a 40x step so in that case what i would like to do is to use these 48 steps to predict what is happening in the next 30 minutes in that case what we are going to predict is these uh these um spots price of the electricity so and then of course it will continue to shift for each of the steps for each of the 30 minutes in the phone and that is for the label let me print out the types of the x5 that is one of the features that is the demands features and you can see that it\'s a steal at least and so this is what we got for the x5 this is the lisk and then originally is inside a data frame and now it has been appends just like what i mentioned before with the use of these for loop so say for example it take out the 48 point over here and then it will shift one point for each of the row for each of the sample so in that case um you you just shift 30 minutes and then store another sample and it continues until it reaches the end and now because this is still a lisk so i would like to convert them into a np array that is the nd numpy array so for each of them i will just use the np dot array function method to convert it to convert the list into a array now let\'s take a look on the output shapes this is the output shape in order for it to work with the training algorithms we need to expand these output shapes with an additional dimensions over here to make sure it works properly with the trailing algorithm so we just need to use these we shape functions and then add one direct dimensions into these render to smooth the trainings normally we need to normalize the data or standardize the data and in this case we are going to use the mean mass scalar and then which which is which provides a range between zero to one and in that case what we\'re going to do is to transform all of the features as well as the target with these mean mess scalar so we will first use this b mass scalar and then besides the range that is 0 to 1 and in this case and then work into assign as a scalar object and then once we have these scalar objects what we\'re going to do is use the fit transform functions uh transform functions for um for each of their feature apply these feed transfer functions to each of the features and then we will just convert assign it back to the original some original nd away and now we have um all of them has been scale scale dance between 0 and 1 and now this is the results that we have for one of the features and this is the demand features and let me let\'s take a look on this shape that is for this demand features and now we have the we have around 25 000 samples and then for the sequence for the time steps we have around 48. the next step is the most important steps in order for us to transform it into a 3d format required by the lstms layer what we\'ve done here is to use the numpy stack that is to stack each of the features into these x array and then with the access equals to two so it means that we are going to set each of the features along the x 2 and because at this point we do not have the x x 2 that is 0 1 and x x 2 in that case what what is that means is that we are going to expand these features with new dimensions with these seven features so you can see that the final shift is this is looks like this this is a the 3d required format for the lstm models and now for the first for the first argument for the first elements that contains the sample and then for the second elements that contains the time steps that is the previous state or the previous 48 time steps for each of the 30 for each of 30 minutes interval and then finally we have the seven features so we just finished to we just finished the two we shapes the multi multiple parallel series data for a lstm input the next things we are going to do is to build the rstm model we just separate the last 10 days for for for the testing so here you can see that um we assign the x and it starts from the beginning to the last 10 days up to the last 10 days for training and then the last 10 days will be used for testing now and then we also assign the labels in with the similar logic and you can see that for the x string dot shaped the first um the second dimensions that is 48 and then the third dimensions that is seven and this is the input shape for the lstm and now we are ready to use the tensorflow carriers to build the models the methods that we are going to use is to use the sequential apis to build the models layer by layer so of course we need to import the sequential models and then for the layers of course we need to import the lstm and also the dense layer and we also impose the optimizers for some parameters tuning now we first assign our models as a sequential models and then what we\'re going to do is to add two lstms layers and then two dense layers for the first lstms layers we assigns 50 neurons and then the return sequence it has need to be set as a true the reason is because we are going to have an other lstms layer in that case we need to reset it equals to true for this one because what we we do not have another additional rstml layers lstm layers followed by these stm layers we have a dense layer followed by this one this layer so in that case we can set it as false for this for this um for this lines of codes because this is the first input layer so we need to assign the input shapes and remember that this is the input shape so we just put input shapes equals to the x train dog shape dimension 1 and x chain dot shapes dimension 2 this is the input shape and then now we have this input layer and the next layer we will add an additional rstm and the return sequence equals to false because the next layer will be just a dense layers and for these dense layers the activations function is value and finally we just add a last layers which is a the the output and that is um and the activations is just linear so we didn\'t we do not need to add that but with one new one because the target is uh it\'s a single it\'s a single output now if we take let\'s take a look on the model\'s summary so with the input shapes and then go through these areas tms layer it will provide these output shapes remember it\'s because we set the return sequence equals to true it will return to a vb output shape for the next lstms layer and then because for the return sequence equals to force for the for the second lstm layers so it will just flatten it and then return you a 2d output result for the next layers now we are ready to go for the train links before we fit the data into the sequential models the first things that we would like to do is to import the model checkpoint and also the early stopping functions to um to early stops the to early stop the trainings if uh if there\'s a if we find that the validation loss is going up and on the other hand we also would like to save the model save the best only models into these paths so once we set this callback and set this file path and set the set up the model checkpoint and early stopping properly we can then set up the optimizer in this case i\'m going to use the sgd um sgd optimizer and with momentum equals to 0.9 and so this is the optimizer of sgd and the loss functions that i\'m going to use is mse and for the metrics that i would like to monitor is mae and finally we are ready to fit the training data into the models and i take up um 20 of the training data for the validation and outside the callbacks as the callbacks that we set over here and the batch size is 16 and not too long after around 21 deposh it will just end the training and finally i also even use the model.evaluates methods to evaluate with the test set data and evaluates give us the mse and also the mae over here and finally we can also use the predict methods to make a predictions on the output remember that we just uh transformed the original data into uh with the use of the um in math scalar so in that case we need to use the same scalar to do the inverse transform of the predictions so now these are the results after we use the inverse transform scalar and let\'s take a look on the parts over here and from this part uh you can see that the red line is the actual price actual electricity price and then the blue line is the forecast price and in terms of the trends it actually track the um trade quite well however in terms of the spike you can see that it doesn\'t follows too much and if we shoot means to this huge spike and you can see that indeed these forecast value also predicts a huge values in in this huge spike period and of course we can further increase more features and fine tunes the hyper parameters to make a better predictions the whole point of this tutorial is to provide you a and ideas and templates on how to set up the rstms inputs layers and voa rstm models from the from the raw data from the cs from the data from the csv and then convert it into a into a 3d shapes that is required formats that is the required format for the rstm models so if you have any any questions any further comments please feel free to leave me the comments and i will do my best to answer so see you in the next video bye bye"", metadata={\'source\': \'Ng_uGKcWfIo\'})]""""""']","{'https://stackoverflow.com/questions/54989442/rnn-in-tensorflow-vs-keras-depreciation-of-tf-nn-dynamic-rnn', 'https://stackoverflow.com/questions/57349824/recurrent-neural-network-time-series-prediction-with-newer-tensorflow-1-14'}","['""""""RNN in Tensorflow vs Keras, depreciation of tf.nn.dynamic_rnn()\n\nMy question is: Are the tf.nn.dynamic_rnn and keras.layers.RNN(cell) truly identical as stated in docs? I am planning on building an RNN, however, it seems that tf.nn.dynamic_rnn is depricated in favour of Keras. In particular, it states that:\n\nWarning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use keras.layers.RNN(cell), which is equivalent to this API\n\nBut I don\'t see how the APIs are equivalent, in the case of variable sequence lengths! In raw TF, we can specify a tensor of shape (batch_size, seq_lengths). This way, if our sequence is [0, 1, 2, 3, 4] and the longest sequence in the batch is of size 10, we can pad it with 0s and [0, 1, 2, 3, 4, 0, 0, 0, 0, 0], we can say seq_length=5 to process [0, 1, 2, 3, 4]. However, in Keras, this is not how it works! What we can do, is specify the mask_zero=True in previous Layers, e.g. the Embedding Layer. This will also mask the 1st zero! I can go around it by adding ones to the whole vector, but then thats extra preprocessing that I need to do after processing using tft.compute_vocabulary(), which maps vocabulary words to 0 indexed vector. 6\n\nare you talking about keras or tf.keras?""""""', '""""""Please help us improve Stack Overflow. Take our short survey\n\nTake our short survey\n\nRecurrent neural network, time series prediction with newer Tensorflow 1.14\n\nHow to use new tf.keras API with recurrent neural network? I have checked the documentation but there is no example of such a situation. There is this great book Hands on machine learning from 2017. Since that year the API of tensorflow has evolved and I am trying to rewrite recurrent neural network for time series prediction with using version 1.14 code. The code from the book is using older tf.nn.dynamic_rnn and tf.nn.rnn_cell.BasicRNNCell:\n\nn_steps = 20 n_inputs = 1 n_neurons = 100 n_outputs = 1 learning_rate = 0.001 X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) y = tf.placeholder(tf.float32, [None, n_steps, n_outputs]) cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu) rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32) stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs) outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs]) loss = tf.reduce_mean(tf.square(outputs - y)) optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) training_op = optimizer.minimize(loss) init = tf.global_variables_initializer() saver = tf.train.Saver() n_iterations = 500 batch_size = 50 with tf.Session() as sess: init.run() for iteration in range(n_iterations): X_batch, y_batch = next_batch(batch_size, n_steps) sess.run(training_op, feed_dict={X: X_batch, y: y_batch}) if iteration % 100 == 0: mse = loss.eval(feed_dict={X: X_batch, y: y_batch}) print(iteration, ""\\tMSE:"", mse) X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs))) y_pred = sess.run(outputs, feed_dict={X: X_new})\n\nAnd this code works just fine (except that it throws warnings about deprecation left and right). I wanted to use tf.keras API as suggested in warning. My code is the same except:\n\ncell = tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu) rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)\n\nBut this yields following exception:\n\nInvalidArgumentError: Input to reshape is a tensor with 50 values, but the requested shape requires a multiple of 20 [[node Reshape_1 (defined at <ipython-input-9-879361be49dd>:3) ]]\n\nso I understand that the problematic line is\n\noutputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n\nAfter checking and comparing documentation for both cells https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn and https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN I can\'t find the culprit. What is the difference with these two cells? How to use tf.keras API with time series? Full old code: https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb\n\nimport numpy as np import tensorflow as tf from datetime import datetime import matplotlib.pyplot as plt from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split import pandas as pd from utils import shuffle_batch, variable_summaries import os dir_path = os.getcwd() now = datetime.utcnow().strftime(""%Y%m%d%H%M%S"") root_logdir = ""tf_logs"" logdir = ""{}/run-{}/"".format(root_logdir, now) print(dir_path) t_min, t_max = -5, 5 section_start = (t_max + t_min) / 2 resolution = 0.1 n_steps = 20 def time_series(t): return np.sin(t) def next_batch(batch_size, n_steps): t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution) Ts = t0 + np.arange(0., n_steps + 1) * resolution ys = time_series(Ts) return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1) t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution)) t_instance = np.linspace(start = section_start, stop = section_start + resolution * (n_steps + 1),num = n_steps + 1) plt.figure(figsize=(11,4)) plt.subplot(121) plt.title(""A time series (generated)"", fontsize=14) plt.plot(t, time_series(t), label=r""original"") plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""b-"", linewidth=3, label=""A training instance"") plt.legend(loc=""lower left"", fontsize=14) #plt.axis([-10, 10, -17, 13]) plt.xlabel(""Time"") plt.ylabel(""Value"") plt.subplot(122) plt.title(""A training instance"", fontsize=14) plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"") plt.plot(t_instance[1:], time_series(t_instance[1:]), ""c*"", markersize=10, label=""target"") plt.legend(loc=""upper left"") plt.xlabel(""Time"") # In[6]: n_steps = 20 n_inputs = 1 n_neurons = 100 n_outputs = 1 X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) y = tf.placeholder(tf.float32, [None, n_steps, n_outputs]) # In[7]: cell = tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu) rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X) print(rnn_outputs.get_shape()) stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons], name=\'reshape1\') stacked_outputs = tf.keras.layers.Dense(n_outputs,name=""hidden2"")(stacked_rnn_outputs) outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs], name=\'reshape2\') learning_rate = 0.001 loss = tf.reduce_mean(tf.square(outputs - y)) # MSE optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) training_op = optimizer.minimize(loss) init = tf.global_variables_initializer() saver = tf.train.Saver() n_iterations = 1500 batch_size = 50 save_path =os.path.join(dir_path,""model"",""recurrent_sinus_model"") with tf.Session() as sess: init.run() for iteration in range(n_iterations): X_batch, y_batch = next_batch(batch_size, n_steps) sess.run(training_op, feed_dict={X: X_batch, y: y_batch}) if iteration % 100 == 0: mse = loss.eval(feed_dict={X: X_batch, y: y_batch}) print(iteration, ""\\tMSE:"", mse) saver.save(sess, save_path) with tf.Session() as sess: saver.restore(sess, save_path) X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs))) y_pred = sess.run(outputs, feed_dict={X: X_new}) plt.title(""Testing the model"", fontsize=14) plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"") plt.plot(t_instance[1:], time_series(t_instance[1:]), ""w*"", markersize=10, label=""target"") plt.plot(t_instance[1:], y_pred[0,:,0], ""r."", markersize=10, label=""prediction"") plt.legend(loc=""upper left"") plt.xlabel(""Time"") plt.show() # In[ ]: with tf.Session() as sess: saver.restore(sess, save_path) X_new = time_series(np.array(t.reshape(-1, n_steps, n_inputs))) y_pred = sess.run(outputs, feed_dict={X: X_new}) plt.title(""A time series (generated)"", fontsize=14) plt.plot(t, time_series(t), label=r""original"",linewidth=5,c=\'r\') plt.plot(t[:-1], time_series(t[:-1]), ""b-"", linewidth=3, label=""A training instance"") plt.legend(loc=""lower left"", fontsize=14) plt.xlabel(""Time"") plt.ylabel(""Value"")\n\nrecurrent-neural-network\n\n rnn_outputs, rnn_states = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)\n\nrnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)\n\nso the parameter return_sequences=True make the RNN return the time series as well, and well, this is the point. """"""', '""""""RNN in Tensorflow vs Keras, depreciation of tf.nn.dynamic_rnn()\n\nMy question is: Are the tf.nn.dynamic_rnn and keras.layers.RNN(cell) truly identical as stated in docs? I am planning on building an RNN, however, it seems that tf.nn.dynamic_rnn is depricated in favour of Keras. In particular, it states that:\n\nWarning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use keras.layers.RNN(cell), which is equivalent to this API\n\nBut I don\'t see how the APIs are equivalent, in the case of variable sequence lengths! In raw TF, we can specify a tensor of shape (batch_size, seq_lengths). This way, if our sequence is [0, 1, 2, 3, 4] and the longest sequence in the batch is of size 10, we can pad it with 0s and [0, 1, 2, 3, 4, 0, 0, 0, 0, 0], we can say seq_length=5 to process [0, 1, 2, 3, 4]. However, in Keras, this is not how it works! What we can do, is specify the mask_zero=True in previous Layers, e.g. the Embedding Layer. This will also mask the 1st zero! I can go around it by adding ones to the whole vector, but then thats extra preprocessing that I need to do after processing using tft.compute_vocabulary(), which maps vocabulary words to 0 indexed vector. 6\n\nare you talking about keras or tf.keras?""""""']","### Description

The question addresses the transition from using the deprecated `tf.nn.dynamic_rnn` and `tf.nn.rnn_cell.BasicRNNCell` to the newer `tf.keras` API for building a recurrent neural network (RNN) for time series prediction. The user is encountering an issue with reshaping tensors when using `tf.keras.layers.RNN` and `tf.keras.layers.SimpleRNNCell`.

### Explanation

The `tf.nn.dynamic_rnn` function and `tf.keras.layers.RNN` are designed to serve similar purposes, but they have differences in their implementation and usage, especially when handling variable sequence lengths and tensor shapes.

1. **Deprecation of `tf.nn.dynamic_rnn`**:
   - The `tf.nn.dynamic_rnn` function is deprecated in favor of the `tf.keras.layers.RNN` API. The deprecation notice suggests using `tf.keras.layers.RNN` as it provides a more integrated and flexible approach within the Keras framework.

2. **Handling Variable Sequence Lengths**:
   - In `tf.nn.dynamic_rnn`, you can specify a tensor of shape `(batch_size, seq_lengths)` to handle variable sequence lengths. This allows you to pad sequences and specify the actual lengths to process.
   - In `tf.keras`, handling variable sequence lengths is typically done using the `mask_zero=True` parameter in layers like `tf.keras.layers.Embedding`. This masks the zero values in the input sequences. However, this approach might require additional preprocessing if your vocabulary maps words to a zero-indexed vector.

3. **Tensor Reshaping Issue**:
   - The error `InvalidArgumentError: Input to reshape is a tensor with 50 values, but the requested shape requires a multiple of 20` indicates a mismatch in the expected tensor shape during reshaping.
   - In the original code using `tf.nn.dynamic_rnn`, the reshaping of `rnn_outputs` to `stacked_rnn_outputs` and then to `stacked_outputs` is straightforward because the output shape is well-defined.
   - When using `tf.keras.layers.RNN`, the output tensor shape might differ, leading to issues during reshaping. The `tf.keras.layers.RNN` layer returns the entire sequence by default, which might not match the expected shape for further processing.

4. **Solution**:
   - Ensure that the `return_sequences` parameter is set correctly in the `tf.keras.layers.RNN` layer. If you need the entire sequence, set `return_sequences=True`. If you only need the final output, set `return_sequences=False`.
   - Verify the shapes of the tensors at each step to ensure they match the expected dimensions for reshaping and further processing.

By understanding these differences and ensuring the correct configuration of the `tf.keras.layers.RNN` layer, you can successfully transition from the deprecated `tf.nn.dynamic_rnn` to the newer `tf.keras` API for building RNNs in TensorFlow."
55573670,tf.nn.sparse_softmax_cross_entropy_with_logits,example required,Unexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits,"<p>The TensorFlow documentation for <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> explicitly declares that I should not apply softmax to the inputs of this op:</p>

<blockquote>
  <p>This op expects unscaled logits, since it performs a softmax on logits
  internally for efficiency. Do not call this op with the output of
  softmax, as it will produce incorrect results.</p>
</blockquote>

<p>However if I use cross entropy without softmax it gives me unexpected results. According to <a href=""https://cs231n.github.io/neural-networks-3/#sanitycheck"" rel=""nofollow noreferrer"">CS231n course</a> the expected loss value is around 2.3 for CIFAR-10:</p>

<blockquote>
  <p>For example, for CIFAR-10 with a Softmax classifier we would expect
  the initial loss to be 2.302, because we expect a diffuse probability
  of 0.1 for each class (since there are 10 classes), and Softmax loss
  is the negative log probability of the correct class so: -ln(0.1) =
  2.302.</p>
</blockquote>

<p>However without softmax I get much bigger values, for example 108.91984.</p>

<p>What exactly am I doing wrong with <code>sparse_softmax_cross_entropy_with_logits</code>? The TF code is shown below.</p>

<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.python import keras


(_, _), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_test = np.reshape(x_test, [-1, 32, 32, 3])

y_test = np.reshape(y_test, (10000,))
y_test = y_test.astype(np.int32)

x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3))
y = tf.placeholder(dtype=tf.int32, shape=(None,))

layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x)
layer = tf.nn.relu(layer)
layer = tf.layers.Flatten()(layer)
layer = tf.layers.Dense(units=1000)(layer)
layer = tf.nn.relu(layer)
logits = tf.layers.Dense(units=10)(layer)

# If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)

loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,
                                                      logits=logits)
loss = tf.reduce_mean(loss, name='cross_entropy')

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]})
    print(""loss: "", res)
    # Expected output is value close to 2.3
    # Real outputs are 108.91984, 72.82324, etc.

</code></pre>
","<p>The issue is not in the lines </p>

<pre><code># If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)
</code></pre>

<p>Images in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your <code>x_test</code> by 255 </p>

<pre><code>x_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255
</code></pre>

<p>the values will be rescaled to [0,1] and <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> will return expected values</p>
","The issue is not in the lines 
<pre><code># If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)
</code></pre>

Images in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your <code>x_test</code> by 255 
<pre><code>x_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255
</code></pre>

the values will be rescaled to [0,1] and <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> will return expected values.",,"['Understanding tf.nn.sparse_softmax_cross_entropy_with_logits in TensorFlow', 'Why should you not apply softmax before using tf.nn.sparse_softmax_cross_entropy_with_logits?', 'Common mistakes when using tf.nn.sparse_softmax_cross_entropy_with_logits', 'Expected loss values for CIFAR-10 using tf.nn.sparse_softmax_cross_entropy_with_logits', 'How to correctly use tf.nn.sparse_softmax_cross_entropy_with_logits in TensorFlow', 'Troubleshooting high loss values in TensorFlow models', 'TensorFlow cross-entropy loss function explained', 'Difference between logits and probabilities in TensorFlow', 'Best practices for using tf.nn.sparse_softmax_cross_entropy_with_logits']","['Why does tf.nn.sparse_softmax_cross_entropy_with_logits expect unscaled logits?', 'What are the common mistakes when using tf.nn.sparse_softmax_cross_entropy_with_logits?', 'How to correctly use tf.nn.sparse_softmax_cross_entropy_with_logits in TensorFlow?', 'Why is the initial loss value around 2.3 for CIFAR-10 with a Softmax classifier?', 'What are the implications of applying softmax before tf.nn.sparse_softmax_cross_entropy_with_logits?', 'How to debug high loss values when using tf.nn.sparse_softmax_cross_entropy_with_logits?']",set(),[],"{'https://stackoverflow.com/questions/43394152/tensorflow-what-exact-formula-is-applied-in-tf-nn-sparse-softmax-cross-entropy', 'https://stackoverflow.com/questions/37312421/whats-the-difference-between-sparse-softmax-cross-entropy-with-logits-and-softm', 'https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop', 'https://stackoverflow.com/questions/41412335/tf-nn-softmax-cross-entropy-with-logits-error-logits-and-labels-must-be-same', 'https://stackoverflow.com/questions/55573670/unexpected-output-for-tf-nn-sparse-softmax-cross-entropy-with-logits'}","['""""""We can compute the cross-entropy loss on a row-wise basis and see the results. Below we can see that training instance 1 has a loss of 0.479, while training instance 2 has a higher loss of 1.200. This result makes sense because in our example above, y_hat_softmax showed that training instance 1\'s highest probability was for ""Class 2"", which matches training instance 1 in y_true; however, the prediction for training instance 2 showed a highest probability for ""Class 1"", which does not match the true class ""Class 3"". loss_per_instance_1 = -tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1]) sess.run(loss_per_instance_1) # array([ 0.4790107 , 1.19967598])\n\nWhat we really want is the total loss over all the training instances. So we can compute:\n\ntotal_loss_1 = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1])) sess.run(total_loss_1) # 0.83934333897877944\n\nUsing softmax_cross_entropy_with_logits()\n\nWe can instead compute the total cross entropy loss using the tf.nn.softmax_cross_entropy_with_logits() function, as shown below. loss_per_instance_2 = tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true) sess.run(loss_per_instance_2) # array([ 0.4790107 , 1.19967598]) total_loss_2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true)) sess.run(total_loss_2) # 0.83934333897877922\n\nNote that total_loss_1 and total_loss_2 produce essentially equivalent results with some small differences in the very final digits. However, you might as well use the second approach: it takes one less line of code and accumulates less numerical error because the softmax is done for you inside of softmax_cross_entropy_with_logits(). \n\nI confirm all of the above. The simple code: M = tf.random.uniform([100, 10], minval=-1.0, maxval=1.0); labels = tf.one_hot(tf.random.uniform([100], minval=0, maxval=10 , dtype=\'int32\'), 10); tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=M) - tf.reduce_sum(-tf.nn.log_softmax(M)*tf.one_hot(labels, 10), -1) returns close-to-zero everywhere\n\n\n\nSorry for simple/dummy question. I didn\'t understand getting loss \'0.479\' from training instance-1. True label for instance-1 is \'2\'. If I apply -1xlog2(0.619) I get 0.691. Edit: Loss is calculated using log \'e\' base, okay. tf.nn.softmax computes the forward propagation through a softmax layer. You use it during evaluation of the model when you compute the probabilities that the model outputs. tf.nn.softmax_cross_entropy_with_logits computes the cost for a softmax layer. It is only used during training. The logits are the unnormalized log probabilities output the model (the values output before the softmax normalization is applied to them). \n\nI get it. Why not call the function, tf.nn.softmax_cross_entropy_sans_normalization? @auro because it normalizes the values (internally) during the cross-entropy computation. The point of tf.nn.softmax_cross_entropy_with_logits is to evaluate how much the model deviates from the gold labels, not to provide a normalized output. In the case of using tf.nn.sparse_softmax_cross_entropy_with_logits() computes the cost of a sparse softmax layer, and thus should only be used during training what would be the alternative when running the model against new data, is it possible to obtain probabilities from this one. @SerialDev, it\'s not possible to get probabilities from tf.nn.sparse_softmax_cross_entropy_with_logits. To get probabilities use tf.nn.softmax. They\'re not log probabilities but log odds. Mathematical motivation for term\n\nWhen we wish to constrain an output between 0 and 1, but our model architecture outputs unconstrained values, we can add a normalisation layer to enforce this. A common choice is a sigmoid function.1 In binary classification this is typically the logistic function, and in multi-class tasks the multinomial logistic function (a.k.a softmax).2\n\nIf we want to interpret the outputs of our new final layer as \'probabilities\', then (by implication) the unconstrained inputs to our sigmoid must be inverse-sigmoid(probabilities). In the logistic case this is equivalent to the log-odds of our probability (i.e. the log of the odds) a.k.a. logit:\n\nThat is why the arguments to softmax is called logits in Tensorflow - because under the assumption that softmax is the final layer in the model, and the output p is interpreted as a probability, the input x to this layer is interpretable as a logit:\n\nIn Machine Learning there is a propensity to generalise terminology borrowed from maths/stats/computer science, hence in Tensorflow logit (by analogy) is used as a synonym for the input to many normalisation functions. While it has nice properties such as being easily diferentiable, and the aforementioned probabilistic interpretation, it is somewhat arbitrary. softmax might be more accurately called softargmax, as it is a smooth approximation of the argmax function. 0\n\nAbove answers have enough description for the asked question. Adding to that, Tensorflow has optimised the operation of applying the activation function then calculating cost using its own activation followed by cost functions. Hence it is a good practice to use: tf.nn.softmax_cross_entropy() over tf.nn.softmax(); tf.nn.cross_entropy()\n\nYou can find prominent difference between them in a resource intensive model. 2\n\nthe answer above clearly haven\'t read the question.. They all say the same things, which are known, but don\'t answer the question itself\n\n\n\n@abhish Did you mean, tf.nn.softmax followed by tf.losses.softmax_cross_entropy? Tensorflow 2.0 Compatible Answer: The explanations of dga and stackoverflowuser2010 are very detailed about Logits and the related Functions. All those functions, when used in Tensorflow 1.x will work fine, but if you migrate your code from 1.x (1.14, 1.15, etc) to 2.x (2.0, 2.1, etc..), using those functions result in error. Hence, specifying the 2.0 Compatible Calls for all the functions, we discussed above, if we migrate from 1.x to 2.x, for the benefit of the community. tf.nn.softmax_cross_entropy_with_logits\n\ntf.nn.sparse_softmax_cross_entropy_with_logits\n\nRespective Functions when Migrated from 1.x to 2.x:\n\ntf.compat.v2.nn.softmax\n\ntf.compat.v2.nn.softmax_cross_entropy_with_logits\n\ntf.compat.v2.nn.sparse_softmax_cross_entropy_with_logits\n\nFor more information about migration from 1.x to 2.x, please refer this Migration Guide. user11530462user11530462\n\nLogits are the unnormalized outputs of a neural network. Softmax is a normalization function that squashes the outputs of a neural network so that they are all between 0 and 1 and sum to 1. Softmax_cross_entropy_with_logits is a loss function that takes in the outputs of a neural network (after they have been squashed by softmax) and the true labels for those outputs, and returns a loss value. One more thing that I would definitely like to highlight as logit is just a raw output, generally the output of last layer. This can be a negative value as well. If we use it as it\'s for ""cross entropy"" evaluation as mentioned below:\n\n-tf.reduce_sum(y_true * tf.log(logits))\n\nthen it wont work. As log of -ve is not defined.""""""', '""""""What\'s the difference between sparse_softmax_cross_entropy_with_logits and softmax_cross_entropy_with_logits? \n\n I recently came across tf.nn.sparse_softmax_cross_entropy_with_logits and I can not figure out what the difference is compared to tf.nn.softmax_cross_entropy_with_logits. Is the only difference that training vectors y have to be one-hot encoded when using sparse_softmax_cross_entropy_with_logits? Reading the API, I was unable to find any other difference compared to softmax_cross_entropy_with_logits. But why do we need the extra function then? Shouldn\'t softmax_cross_entropy_with_logits produce the same results as sparse_softmax_cross_entropy_with_logits, if it is supplied with one-hot encoded training data/vectors? 2\n\nI\'m interested in seeing a comparison of their performance if both can be used (e.g. with exclusive image labels); I\'d expect the sparse version to be more efficient, at least memory-wise. See also this question, which discusses all cross-entropy functions in tensorflow (turns out there are lots of them). Having two different functions is a convenience, as they produce the same result. The difference is simple:\n\nFor sparse_softmax_cross_entropy_with_logits, labels must have the shape [batch_size] and the dtype int32 or int64. Each label is an int in range [0, num_classes-1]. For softmax_cross_entropy_with_logits, labels must have the shape [batch_size, num_classes] and dtype float32 or float64. Labels used in softmax_cross_entropy_with_logits are the one hot version of labels used in sparse_softmax_cross_entropy_with_logits. Another tiny difference is that with sparse_softmax_cross_entropy_with_logits, you can give -1 as a label to have loss 0 on this label.  \n\nIs the -1 correct? As the documentation reads: ""Each entry in labels must be an index in [0, num_classes). Other values will raise an exception when this op is run on CPU, and return NaN for corresponding loss and gradient rows on GPU.""\n\n\n\n[0, num_classes) = [0, num_classes-1]\n\n\n\nIs this statement correct? ""Labels used in softmax_cross_entropy_with_logits are the one hot version of labels used in sparse_softmax_cross_entropy_with_logits."" Is it backwards? Isn\'t the sparse loss function the one with int of 0, so isn\'t the sparse one the one-hot version? I would just like to add 2 things to accepted answer that you can also find in TF documentation. tf.nn.softmax_cross_entropy_with_logits\n\nNOTE: While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution. If they are not, the computation of the gradient will be incorrect. tf.nn.sparse_softmax_cross_entropy_with_logits\n\nNOTE: For this operation, the probability of a given label is considered exclusive. That is, soft classes are not allowed, and the labels vector must provide a single specific index for the true class for each row of logits (each minibatch entry). 3\n\nWhat should we use if the classes are not mutually exclusive.""""""', '""""""Unexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits\n\nThe TensorFlow documentation for tf.nn.sparse_softmax_cross_entropy_with_logits explicitly declares that I should not apply softmax to the inputs of this op:\n\nThis op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results. However if I use cross entropy without softmax it gives me unexpected results. According to CS231n course the expected loss value is around 2.3 for CIFAR-10:\n\nFor example, for CIFAR-10 with a Softmax classifier we would expect the initial loss to be 2.302, because we expect a diffuse probability of 0.1 for each class (since there are 10 classes), and Softmax loss is the negative log probability of the correct class so: -ln(0.1) = 2.302. However without softmax I get much bigger values, for example 108.91984. What exactly am I doing wrong with sparse_softmax_cross_entropy_with_logits? The TF code is shown below. import tensorflow as tf import numpy as np from tensorflow.python import keras (_, _), (x_test, y_test) = keras.datasets.cifar10.load_data() x_test = np.reshape(x_test, [-1, 32, 32, 3]) y_test = np.reshape(y_test, (10000,)) y_test = y_test.astype(np.int32) x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3)) y = tf.placeholder(dtype=tf.int32, shape=(None,)) layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x) layer = tf.nn.relu(layer) layer = tf.layers.Flatten()(layer) layer = tf.layers.Dense(units=1000)(layer) layer = tf.nn.relu(layer) logits = tf.layers.Dense(units=10)(layer) # If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits) loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits) loss = tf.reduce_mean(loss, name=\'cross_entropy\') with tf.Session() as sess: sess.run(tf.global_variables_initializer()) res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]}) print(""loss: "", res) # Expected output is value close to 2.3 # Real outputs are 108.91984, 72.82324, etc. The issue is not in the lines\n\n# If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits)\n\nImages in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your x_test by 255\n\nx_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255\n\nthe values will be rescaled to [0,1] and tf.nn.sparse_softmax_cross_entropy_with_logits will return expected values\n\n\n\n1\n\nGood answer! Added exact code how to get desired behavior\n\n""""""']","The question addresses an unexpected output when using `tf.nn.sparse_softmax_cross_entropy_with_logits` in TensorFlow. The user expects an initial loss value around 2.3 for the CIFAR-10 dataset, but instead receives much larger values, such as 108.91984.

The key point to understand is that `tf.nn.sparse_softmax_cross_entropy_with_logits` expects unscaled logits as input because it performs the softmax operation internally. This means you should not apply the softmax function to the logits before passing them to this function, as it will produce incorrect results.

In the provided code, the user correctly avoids applying the softmax function to the logits before passing them to `tf.nn.sparse_softmax_cross_entropy_with_logits`. However, the unexpected high loss values are likely due to the input data not being normalized. The CIFAR-10 dataset images have pixel values in the range [0, 255], and these values should be normalized to the range [0, 1] to ensure the model's logits are appropriately scaled.

To address the issue, the user should normalize the `x_test` data by dividing it by 255. This normalization step ensures that the input data is on a similar scale to what the model expects, leading to more reasonable initial loss values.

In summary, the unexpected high loss values are due to the lack of normalization of the input data. By normalizing the input data to the range [0, 1], the user can achieve the expected initial loss value around 2.3 for the CIFAR-10 dataset when using `tf.nn.sparse_softmax_cross_entropy_with_logits`."
54047604,tf.custom_gradient,example required,How to assign custom gradient to TensorFlow op with multiple inputs,"<p>I'm trying to use TensorFlow's <code>@tf.custom_gradient</code> functionality to assign a custom gradient to a function with multiple inputs.  I can put together a working setup for only one input, but not for two or more.</p>

<p>I've based my code on <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">TensorFlow's custom_gradient documentation</a>, which works just fine for one input, as in this example:</p>

<pre><code>import tensorflow as tf
import os

# Suppress Tensorflow startup info
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

# Custom gradient decorator on a function,
# as described in documentation
@tf.custom_gradient
def my_identity(x):

    # The custom gradient
    def grad(dy):
        return dy

    # Return the result AND the gradient
    return tf.identity(x), grad

# Make a variable, run it through the custom op
x = tf.get_variable('x', initializer=1.)
y = my_identity(x)

# Calculate loss, make an optimizer, train the variable
loss = tf.abs(y)
opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)
train = opt.minimize(loss)

# Start a TensorFlow session, initialize variables, train
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(train)
</code></pre>

<p>This example runs silently, then closes.  No issues, no errors.  The variable optimizes as expected.  However, in my application, I need to do such a calculation with multiple inputs, so something of this form:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad
</code></pre>

<p>Running this in place of the example (and adding another variable input to the call of <code>my_identify</code>) results in the following error output.  Best as I can tell, the last parts of the error are from the dynamic generation of the op -- the information format matches the C++ formatting required in the op establishment (though that's about all I know about it).</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 27, in &lt;module&gt;
    train = opt.minimize(loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 400, in minimize
    grad_loss=grad_loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 519, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 630, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 821, in _GradientsHelper
    _VerifyGeneratedGradients(in_grads, op)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 323, in _VerifyGeneratedGradients
    ""inputs %d"" % (len(grads), op.node_def, len(op.inputs)))
ValueError: Num gradients 2 generated for op name: ""IdentityN""
op: ""IdentityN""
input: ""Identity""
input: ""x/read""
input: ""y/read""
attr {
  key: ""T""
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_gradient_op_type""
  value {
    s: ""CustomGradient-9""
  }
}
 do not match num inputs 3
</code></pre>

<p>Based on other custom gradient options, I surmised that the issue was a lack of supplied gradient for the second input argument.  So, I changed my function to this:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad, grad
</code></pre>

<p>This results in the following more familiar error:</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 22, in &lt;module&gt;
    y = my_identity(x, z)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 111, in decorated
    return _graph_mode_decorator(f, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 132, in _graph_mode_decorator
    result, grad_fn = f(*args)
ValueError: too many values to unpack (expected 2)
</code></pre>

<p>The <code>@custom_gradient</code> decorator is only identifying the last returned element as a gradient.  So, I tried putting the two gradients into a tuple as <code>(grad, grad)</code> such that there would only be ""two"" outputs for the function.  TensorFlow rejected this too, this time because it can't call a tuple like it would a Tensor -- entirely reasonable, in hindsight.</p>

<p>I've fussed around with the example some more, but to no avail.  No matter what I try, I can't get the custom-defined gradient to deal with multiple inputs.  I'm hoping that somebody with more knowledge than I regarding custom ops and gradients will have a better idea on this -- thanks in advance for the help!</p>
","<p>If we use multiple variables as input, the number of gradients return from ""grad"" function should be equals to number of input variables, though we maybe don't care about some of them. </p>

<p>For example:</p>

<pre><code>@tf.custom_gradient
def my_multiple(x,z):

def grad(dy):
    # return two gradients, one for 'x' and one for 'z'
    return (dy*z, dy*x)

return tf.identity(x*z), grad
</code></pre>

<p>Note that the second output of ""my_multiple"" is a function, not a gradient tensor. </p>
","If we use multiple variables as input, the number of gradients return from ""grad"" function should be equals to number of input variables, though we maybe don't care about some of them.
Note that the second output of ""my_multiple"" is a function, not a gradient tensor.","<pre><code>@tf.custom_gradient
def my_multiple(x,z):

def grad(dy):
    # return two gradients, one for 'x' and one for 'z'
    return (dy*z, dy*x)

return tf.identity(x*z), grad
</code></pre>","['How to use @tf.custom_gradient with multiple inputs in TensorFlow?', 'TensorFlow custom gradient for functions with multiple inputs', 'Handling multiple input gradients in TensorFlow custom_gradient', 'Example of @tf.custom_gradient with two or more inputs in TensorFlow', 'Defining custom gradients for multi-input functions in TensorFlow', 'TensorFlow custom_gradient decorator for functions with multiple arguments', 'How to return multiple gradients in TensorFlow custom_gradient', 'Troubleshooting TensorFlow custom_gradient with multiple inputs', 'Advanced usage of @tf.custom_gradient in TensorFlow', 'TensorFlow custom gradient tutorial for multi-input functions']","['How to use @tf.custom_gradient with multiple inputs in TensorFlow?', 'How to define custom gradients for functions with multiple inputs in TensorFlow?', 'Example of @tf.custom_gradient with two inputs in TensorFlow', 'Handling multiple input gradients in TensorFlow custom_gradient', 'How to return multiple gradients in @tf.custom_gradient decorator in TensorFlow?', 'Troubleshooting ValueError: too many values to unpack (expected 2) in TensorFlow custom_gradient', 'Best practices for implementing custom gradients for multi-input functions in TensorFlow']",{'https://www.youtube.com/watch?v=VmaBfi-CWv4'},"['""""""[Document(page_content=""hello guys and welcome to another tensorflow tutorial today I\'ll be showing you guys how to make a custom layer with custom gradient so without further Ado let\'s just start coding so obviously we\'re going to import dense flow as TF as always and then we\'re gonna actually make it close let me just add this a few lines so that python doesn\'t complain about formatting issues so you\'re going to be replicating the dense layer so I\'m just going to call it my dense layer and then we have to we\'re going to extend off the the layer class so layers.layer then now we have the make an init function um begin I want to pass in the input size and the hidden hidden size then we\'ll just initialize W this is not really needed like all these initializes these next three lines that I\'m going to do but I\'m just going to put them on so it\'s easier to convert this to make it more robust which I\'ll explain to you guys later how you can make it more robust um then so yeah we\'re just gonna re we\'re gonna write over W now which is solve.add I\'m going to solve that ad weight and then we\'re just going to name this W then shape equals input size sorry input size then hidden it\'s actually soft but here in size we\'ll just leave it at that salon so this is we can just hold paste this into somewhere else to make a more robust in the future then we\'re gonna have an initializer it\'s going to be a random normal then we have to set trainable to true Okay cool so off that what is oh okay so yeah we\'ve got something really important which is we have to add this line in um and actually I have to add in the class name as well comma solve then that should yeah okay that works and then we want to do the same for w as well but W is going to be a bit different because the shape is actually it\'s just the hidden hidden size and we\'ll just add a comma afterwards okay check trainable to True randomly um I think we can for now we\'ll just send this but normally you just set um B2B 0 that\'s fine W has to be randomly initialized so that it\'s not symmetrical because if you set it to zero then it\'s just all the neurons are going to basically do the same function it\'s the same operation the same inputs so it\'s good the function is going to be symmetrical well the operation is going to be symmetrical so what we want to do next is wanna just create the core function this is going to be the the forward pass basically and this would just be return matte sorry TF dot Matt small tf.map more and then why what do we have to do with the scanner yeah so this would be solve Dot W and then I\'m just trying to think now if we think it\'ll be soft so yeah okay so that\'s to be X first and then yeah solve the dot solve the W and then we Plus solve that b so this is how you just replicate like a dense layer and also this is actually the an indent this that should be fine okay so yeah let\'s format that so this is without like a custom gradient this is just you can use tensorflows functions to build your own custom layer and as long as you\'re using tensorflow\'s functions a tensor will be able to keep track of the the computational graph but if you\'re not gonna if you want to create your own function with your own gradients you\'ll have to actually make your own tensorflow function with that with a custom gradient so um to do that we\'ll just um we\'ll have to start with TF Dot well we\'ll just call this custom we\'ll make the function for gradient then we\'re going to take in a WRB and an X and then we have to decorate the function just return decorate the function with TF dot custom gradient there is no brackets of that okay so um four passes the same as autopia so let\'s just go paste this and take out the solves by the way also note that the um this this function is actually outside of the class but you can put it in but like yeah it\'s better to but uh it\'s fine if you have it outside as well um after that we actually Gonna Wanna do the back propagation so we\'re gonna create the gradient function so that\'s gonna take in dldz which is the the gradients that have been back propagated through the network so we take that in and before actually I go into this I\'m going to explain to you guys how like how I came about these formulas and like where I got them from Etc so you guys can follow along easily and explain to you a bit about that so I\'ll see you there okay cool so these are the these are the standard formulas for computing the gradients for the fully connected layer or dense layer intense flows the case so first I want you to notice that um the input data X at the bottom right over here it\'s uh it\'s in well the each training example is in its own column so like a training example would be like one image or one row of a table if you were working with tabular data um but yeah so as you can see tensorflow actually stores the the data in the opposite way that was in the previous slide so like it\'s actually the rows are for each training example so that\'s why we\'re gonna have to tweak it a bit so to get these formulas that I have in front of you over here what I\'ve actually done is I\'ve just transposed X so like the tensorflow X X of T and I\'m multiplied by dldz deltz is also like transpose from the previous slide so the the LDL dldz is the The Still d said but transpose then yeah I did that for both W and wnx so I basically just transpose this W or the X and I swap these two the dldb is basically the same as before because it\'s just straight up a dld of all the bias grain is basically the ldb is just this dldz it\'s straight up just equal to that the catch for that is that we actually are working in batches so we have many dld said it\'s not like exactly so so this would be like 100 Vector but this would be like 32 by a hundred so what we\'re gonna have to do is that we\'re gonna we\'re going to have to um we\'re gonna have to sum across the the batching dimension so that would be the First Dimension but yeah that\'s all you kind of need to know so yeah let\'s continue coding so from the previous previous uh slides we actually need to compute two things quick before do anything else I\'m gonna copy the transverse of w and then transpose of X TF dot transpose and X easy as that tldw so dldw was actually just TF dot mat mole of X of t d l d z if you can remember and then dldx is equal to TF dot map Mall of DLT said and WFT and then the ldb I said was equal to so dldb is equal to TF dot reduce sum of the LTZ axis so I was I was actually just equal to dltz but we\'re going to want to sum this so it\'s just some quick so tf.reduce sum and then we\'re gonna do it across the batching Dimension which is zero and then we want to return the ldw dldb DL DX the order of this is very important first of all I just want to make two comments so the order of this is very important as to be the same order as the as the parameters are passed into the actual like the the function it should be custom operation and second of all that this W has to be the same Dimension as this B has to be the same Dimension as this x has to be the same Dimension as this well sorry this has to be the same Dimension as X for this to work all stance flow is going to throw some errors after that we kind of we just have to return we have to return the Y of course and then we have the return grad function but we don\'t actually turn the the function we just returned point all the we don\'t return like a value from the function we turn the function itself so we don\'t put a bracket at the end there so after that actually it\'s Gonna Wanna I\'m just gonna put this in here and then we\'re actually going to change this to custom operation then that should be the same so I\'m just double checking everything everything looks good so let me just show you guys how to actually use this so it\'s just a if name equals main then I\'m just gonna pull in we can use mnst to test this so X train comma y train comma X test comma y test then we want to pull in the TF dot qrs.datorsets dot and then we want mnest mnest.load data X train so we want to actually pre-process extra invest it\'s uh 28 by 28 by one so you want to kind of reshape it so that we can flatten it into a two-dimensional tensor so what we\'re going to do for that is we\'re going to go X train and then minus one so tens flow is going to infer the dimension while the the value of this Dimension or how big this is and then the image is 28 by 28 so that\'s why we\'re going to add you know the 28 by 28 and then I\'m just gonna put this to float32 I don\'t think this is really needed because when we divide by 255.0 I think it will change that to float32 anyway and we\'ll do the same for X test so let\'s just that could paste this for X test cool all right so let\'s just first um I just want to print because we\'re gonna do this we\'re gonna do a test for both the custom dance layer and the intense Flow State so this one I\'ll print this I\'m gonna make like a heading there basically and off that we\'re gonna actually create our model so without custom layer in it so TF Dot curs.sequential sorry about that and then tf.curus we want an input layer sorry layers Dot input and then shape is equal to 28 times 28. that\'s fine off that put a comma at the end and then Rihanna put in our dense layer so the input is going to be 28 times 28. and then we want also the output size of the header and size this would be 64. and then just copy paste this three times okay so we actually have to so this is we\'re gonna feed a dimension of 64 in here so we\'re gonna want to change this to 64. you can lower this this is going to be 32 this will be 10. after that we\'ll actually I think that\'s it um then we\'ll add model zero dot compile and then we want to just set our losses loss is equal tip TFT losses dot sparse categorical entropy and then from logit\'s multi true so basically um normally we\'d put it into a soft Max but since we\'re not putting it into a soft Max we\'re going to say it\'s from the largest so it\'s going to apply the soft Max and then it\'s going to apply this loss function um yeah and after that we will just do Optimizer equals TF dot curious Dot optimizers dot atom and then we\'ll just have the default learning rate so we don\'t need a actually add anything after that we\'ll have metrics this is obviously accuracy tens flows well Python\'s getting in the way accuracy um after that we\'ll just we can just fit the model Modelo dot fit extreme y train and then we\'re just gonna do four five epochs um and we\'ll do even worry about it we\'ll evaluate it on the test set um evaluate X test whitest and then so I said we\'re gonna do this for both uh our custom layer and also our of all tense flows dense layers so let\'s just change this um so tensorflow no I\'m not the right one this is tensorflow I just want to add this up here quick so we know it when it ends we\'re going to change this to an equals double line to show that it\'s done this at the bottom here as well so I don\'t forget later tensorflow dance layer okay so we want to change this to so for with python we can just you can just middle click and well not middle click sorry you click on your scroller and you just drag and it does this like a block highlight so tf.kiris dot layers dot dance and then we don\'t need this and we don\'t need this sorry I don\'t need first numbers 64 and this would so you can see the difference between all those right here just in terms of like when you initialize them you have to add both the inputs but tensorflow kind of um just infers the size so yeah uh everything seems to be set up so we can just actually run this up we got an error what is this it\'s not callable oh I think I did something yeah I\'ve got the dot reshape we have to reshape this all right let\'s run this again oh another area Okay um object has no attribute X we have to not double check this so let\'s just change this quick solter W salt dot b and then we we don\'t put in solve.x we put in x all right let\'s try this one more time this should work cool there\'s a working so yeah off this is done training I\'ll get back to you guys all right cool so it\'s done we can see that the results are very similar so it starts off at like 80 89 this starts off at like maybe 89.5 this is 88.5 so percent higher then afterwards it gets to about 92 this gets to 92.35 but the tensorflow actually beats it out by a a fraction of a percent in on the test set but this is basically due to how the weights are initialized and yeah that would depend on like maybe the this uh first first layer got better initialization weights and was able to train faster but yeah um they seem quite similar and there\'s very little difference let me just tell you guys how how you can make this more robust and you don\'t have to actually add in an input layer so what we can do is instead of having it in it well this this coding in it we can actually make a a bold function and this is called when tensorflow gets the input shape and maybe the models compiled I\'m not completely sure when this is run it\'s run like different size but basically it passes in the input shape and we can use this input shape to actually initialize our weights and we won\'t have to actually get in the input shape from the U from the the function initialization actually get our when tensorflow finds out the input shape and bolts the the neural network so let\'s just change our code so that it fits and this would be -1 because we want the last we can also just put one here because we\'re expecting two-dimensional input but yeah let\'s just leave it at one minus one so that it\'s more robust after that we actually have to change this so let\'s just so we don\'t need any of this and our layers are basically equal now and if we run it it should work but yeah that\'s what you that\'s how you create a custom layer with custom gradient intense flow hope you guys enjoyed please leave a like And subscribe if you want to see more content like this also drop a comment if you guys want to see anything if you guys want me to explain or make a tutorial on something that you guys are confused about hope you guys have a great day bye"", metadata={\'source\': \'VmaBfi-CWv4\'})]""""""']",{'https://stackoverflow.com/questions/51836242/tf-custom-gradient-with-multiple-inputs'},"['""""""tf.custom_gradient with multiple inputs\n\ntf.custom_gradient accepts only one Tensor x, what if this op needs more than one inputs? For example, to define the gradient of Softmax which needs input x and label? Thanks for the suggestion from @AllenLavoie, I use a Python list as input. def self_define_op_multiple_inputs(): @tf.custom_gradient def loss_func(input_): x = input_[0] label = input_[2] def grad(dy): return [dy, dy] return x - label, grad x = tf.range(10, dtype=tf.float32) y = tf.range(10, dtype=tf.int32) loss = loss_func([x, y]) if __name__ == \'__main__\': self_define_op_multiple_inputs()\n\nIt seems that it will convert the Python list to a Tensor. The snippet above will raise a TypeError: TypeError: Cannot convert a list containing a tensor of dtype <dtype: \'int32\'> to <dtype: \'float32\'> (Tensor is: <tf.Tensor \'range_1:0\' shape=(10,) dtype=int32>)\n\nThe documentation says x and y can both either be Tensors or sequences of Tensors. Did this not work for you?  Actually this is exactly what confused me. I don\'t understand what\'s sequences of Tensors, does it mean a Python list of Tensor? My interpretation is Python list (or tuple, etc.). So len(x) is the number of inputs to the operation, len(y) is the number of outputs. Then the gradient function takes len(y) Tensor argument and returns len(x) Tensors. I tried to use list but it seems like a list will be converted as a Tensor, which will cause an error if there are multiple inputs with different type and matched shape. The question has been updated. @AllenLavoie I created an issue on github\n\n I ran into a similar problem yesterday and found this post, and I believe I know what you are running into. Problem is that while using @tf.custom_gradient, the function that it decorates can have multiple inputs (instead of a list of tensors). Look at the following code(note that it\'s just a test code with no actual meaning):\n\n@tf.custom_gradient def loop1(x,a): def grad(dy): return dy*3,dy*2 n = tf.multiply(x,a) return n,grad\n\nBy using two inputs x and a, you have to return two gradients respectively in the grad function. dy*3 corresponds to the gradient of x and dy*2 corresponds to the gradient of a. I think in this function the documents make people very confusing, but you can still use multiple inputs, just make sure that you also have the same number of gradients, or else you will run into errors. 1\n\nCan we return None as gradients for unused terms ? I believe you need something like this a tf Graph input:+ n_input is the input number\n\nx = tf.placeholder(""float"", [None, n_input]) y = tf.placeholder(""float"", [None])\n\nDoes this answer your question ? 1\n\nThanks for your help.""""""', '""""""But it seems that you didn\'t understand what I am talking about. tf.custom_gradient is not a computational graph. You can read docs for more details.""""""']","To address the question of how to assign a custom gradient to a TensorFlow operation with multiple inputs using `@tf.custom_gradient`, it is important to understand the correct way to define and return gradients for each input. The `@tf.custom_gradient` decorator allows you to define a function with custom gradients, which can be particularly useful for ensuring numerical stability or efficiency in gradient computation.

When using `@tf.custom_gradient` with multiple inputs, the decorated function should return a tuple consisting of the output and a gradient function. The gradient function must return a gradient for each input. If the function has two inputs, the gradient function should return two gradients, one for each input. The number of gradients returned by the gradient function must match the number of inputs to the decorated function.

In the context of the provided example, the issue arises because the gradient function does not return the correct number of gradients for the inputs. The correct approach is to ensure that the gradient function returns a gradient for each input. If the function has two inputs, the gradient function should return two gradients, one for each input. This ensures that TensorFlow can correctly compute the gradients for each input during backpropagation.

Additionally, it is important to note that the `@tf.custom_gradient` decorator expects the decorated function to return exactly two values: the output of the function and the gradient function. The gradient function itself should return a tuple of gradients corresponding to each input.

In summary, to assign a custom gradient to a TensorFlow operation with multiple inputs using `@tf.custom_gradient`, ensure that the gradient function returns a gradient for each input, and that the decorated function returns a tuple consisting of the output and the gradient function. This approach aligns with the TensorFlow documentation and ensures that the custom gradient is correctly applied to each input."
59555206,tf.keras,example required,keras to tf.keras Conversion: Dense layer dimensions not defined?,"<p>So I've built a convnet using pure <code>keras</code>. It compiles and operates exactly as intended, but I need to convert it to use <code>tf.keras</code> so that I can make use of <code>tfmot</code>. Having read documentation, I attempted to convert it, only to get the following error:</p>

<p><code>The last dimension of the inputs to Dense should be defined. Found None.</code> </p>

<p>Any idea what I'm doing wrong?</p>

<p>Thanks!</p>

<p>Original <code>keras</code> model:</p>

<pre><code>input_layer = keras.layers.Input(shape=(100,))
reshape_layer = keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = keras.layers.Flatten()(conv_layer_5)
label_layer = keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = keras.layers.Dense(1, activation=""linear"")(label_layer)

model = keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>Converted <code>tf.keras</code> model:</p>

<pre><code>input_layer = tf.keras.layers.InputLayer(input_shape=(100,))
reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>EDIT 1:</p>

<p>I thought maybe I could get around the issue by saving the <code>keras</code> model after creation and loading it as a <code>tf.keras</code> model immediately before compilation / training. That throws the same error! </p>
","<p>There's few issues with your code. Fix them and you should be good to go,</p>

<h2>Issue 1: Use <code>Input</code> instead of <code>InputLayer</code></h2>

<p>The standard is to use <code>Input</code> layer instead of <code>InputLayer</code> (which infact uses <code>InputLayer</code> internally). You also need to change <code>input_shape</code> to <code>shape</code> if you are using <code>Input</code> layer.</p>

<pre><code>input_layer = tf.keras.layers.Input(shape=(100,))
</code></pre>

<h2>Issue 2: 2 <code>None</code> dimensions in the output</h2>

<p>When you execute the following line, you get two <code>None</code> dimensions in your output. </p>

<pre><code>reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
</code></pre>

<p>Which is why you are getting the above error. When defining the <code>Reshape</code> layer you don't define the <code>batch</code> dimension, which will be None. And that's the only dimension you can have as <code>None</code> if you want to use a <code>Dense</code> layer. Otherwise, the <code>Dense</code> layer cannot infer the shape of its weights (which is why you get the error). So change that to,</p>

<pre><code>reshape_layer = tf.keras.layers.Reshape((1, 100, 1))(input_layer)
</code></pre>

<p>The rest stays the same.</p>

<pre><code>conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
model.summary()
</code></pre>
","There's few issues with your code. Fix them and you should be good to go,
Issue 1: Use <code>Input</code> instead of <code>InputLayer</code></h2>

The standard is to use <code>Input</code> layer instead of <code>InputLayer</code> (which infact uses <code>InputLayer</code> internally). You also need to change <code>input_shape</code> to <code>shape</code> if you are using <code>Input</code> layer.

<pre><code>input_layer = tf.keras.layers.Input(shape=(100,))
</code></pre>

Issue 2: 2 <code>None</code> dimensions in the output</h2>

When you execute the following line, you get two <code>None</code> dimensions in your output.
<pre><code>reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
</code></pre>

Which is why you are getting the above error. When defining the <code>Reshape</code> layer you don't define the <code>batch</code> dimension, which will be None. And that's the only dimension you can have as <code>None</code> if you want to use a <code>Dense</code> layer. Otherwise, the <code>Dense</code> layer cannot infer the shape of its weights (which is why you get the error). So change that to,

<pre><code>reshape_layer = tf.keras.layers.Reshape((1, 100, 1))(input_layer)
</code></pre>","<pre><code>conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
model.summary()
</code></pre>","['How to convert a Keras model to a tf.keras model?', 'Common issues when converting Keras models to tf.keras models', 'How to define input shapes correctly in tf.keras?', 'How to use tf.keras.layers.InputLayer correctly?', ""How to debug 'The last dimension of the inputs to Dense should be defined. Found None.' error in tf.keras?"", 'How to reshape layers in tf.keras?', 'How to use tfmot with tf.keras models?', 'How to save and load models in tf.keras?']","['How to convert a Keras model to a tf.keras model?', 'What is the correct way to define the input layer in tf.keras?', ""How to resolve 'The last dimension of the inputs to Dense should be defined. Found None.' error in tf.keras?"", 'Differences between keras.layers.Input and tf.keras.layers.InputLayer', 'How to reshape input layers correctly in tf.keras?', 'Common issues when converting Keras models to tf.keras models']","{'https://www.youtube.com/watch?v=FIReIQlyZmM', 'https://www.youtube.com/watch?v=UYRBHFAvLSs', 'https://www.youtube.com/watch?v=oJ1i2c1KxKk', 'https://www.youtube.com/watch?v=ukBG9ALd8T8'}",,"{'https://stackoverflow.com/questions/71335830/what-is-the-difference-between-tf-keras-layers-input-and-tf-keras-layers-flatt', 'https://stackoverflow.com/questions/44466066/how-can-i-convert-a-trained-tensorflow-model-to-keras', 'https://stackoverflow.com/questions/45217973/what-is-the-advantage-of-using-an-inputlayer-or-an-input-in-a-keras-model-with', 'https://stackoverflow.com/questions/56918388/error-valueerror-the-last-dimension-of-the-inputs-to-dense-should-be-defined'}","['""""""Tensorflow 2.0: Shape inference with Reshape returns None dimension\n\nI\'m working with a CNN-LSTM model on Tensorflow 2.0 + Keras to perform sequence classification. My model is defined as following:\n\ninp = Input(input_shape) rshp = Reshape((input_shape[0]*input_shape[1], 1), input_shape=input_shape)(inp) cnn1 = Conv1D(100, 9, activation=\'relu\')(rshp) cnn2 = Conv1D(100, 9, activation=\'relu\')(cnn1) mp1 = MaxPooling1D((3,))(cnn2) cnn3 = Conv1D(50, 3, activation=\'relu\')(mp1) cnn4 = Conv1D(50, 3, activation=\'relu\')(cnn3) gap1 = AveragePooling1D((3,))(cnn4) dropout1 = Dropout(rate=dropout[0])(gap1) flt1 = Flatten()(dropout1) rshp2 = Reshape((input_shape[0], -1), input_shape=flt1.shape)(flt1) bilstm1 = Bidirectional(LSTM(240, return_sequences=True, recurrent_dropout=dropout[1]), merge_mode=merge)(rshp2) dense1 = TimeDistributed(Dense(30, activation=\'relu\'))(rshp2) dropout2 = Dropout(rate=dropout[2])(dense1) prediction = TimeDistributed(Dense(1, activation=\'sigmoid\'))(dropout2) model = Model(inp, prediction, name=""CNN-bLSTM_per_segment"") print(model.summary(line_length=75))\n\nWhere input_shape = (60, 60). This definition, however, raises the following error:\n\nTypeError: unsupported operand type(s) for +: \'NoneType\' and \'int\'\n\nAt first, I thought it was because the rshp2 layer could not reshape the flt1 output to shape (60, X). So I added a printing block before the Bidirectional(LSTM)) layer:\n\nprint(\'reshape1: \', rshp.shape) print(\'cnn1: \', cnn1.shape) print(\'cnn2: \', cnn2.shape) print(\'mp1: \', mp1.shape) print(\'cnn3: \', cnn3.shape) print(\'cnn4: \', cnn4.shape) print(\'gap1: \', gap1.shape) print(\'flatten 1: \', flt1.shape) print(\'reshape 2: \', rshp2.shape)\n\nAnd the shapes were:\n\nreshape 1: (None, 3600, 1) cnn1: (None, 3592, 100) cnn2: (None, 3584, 100) mp1: (None, 1194, 100) cnn3: (None, 1192, 50) cnn4: (None, 1190, 50) gap1: (None, 396, 50) flatten 1: (None, 19800) reshape 2: (None, 60, None)\n\nLooking at the flt1 layer, its output shape is (19800,), which can be reshaped as (60, 330), but for some reason the (60, -1) of the rshp2 layer is not working as intended, evidenced by the print reshape 2: (None, 60, None). When I try to reshape as (60, 330) it works just fine. Does anyone knows why the (-1) is not working? From Reshape documentation, https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape\n\nthe layer returns a tensor with shape (batch_size,) + target_shape\n\nSo, the batch size stays the same, the other dimensions are calculated based on your target_shape. From the doc, look at the last example,\n\n# also supports shape inference using `-1` as dimension model.add(tf.keras.layers.Reshape((-1, 2, 2))) model.output_shape\n\nIf you pass -1 in your target shape, the Keras will store None, this is useful if you expect variable-length data in that axis, but if your data shape is always same, just put the dimension hard-coded that will place the dimension when you print the shape later. N.B: Also no need to specify input_shape=input_shape for your intermediate layers in functional API. The model will infer that for you.""""""', '""""""thanks I made a post. I would love some input as to what I am missing\n\n\n\nCurrently, there is no direct in-built support in Tensorflow or Keras to convert the frozen model or the checkpoint file to hdf5 format. But since you have mentioned that you have the code of Tensorflow model, you will have to rewrite that model\'s code in Keras. Then, you will have to read the values of your variables from the checkpoint file and assign it to Keras model using layer.load_weights(weights) method. More than this methodology, I would suggest to you to do the training directly in Keras as it claimed that Keras\' optimizers are 5-10% times faster than Tensorflow\'s optimizers. Other way is to write your code in Tensorflow with tf.contrib.keras module and save the file directly in hdf5 format. Unsure if this is what you are looking for, but I happened to just do the same with the newly released keras support in TF 1.2. You can find more on the API here: https://www.tensorflow.org/api_docs/python/tf/contrib/keras\n\nTo save you a little time, I also found that I had to include keras modules as shown below with the additional python.keras appended to what is shown in the API docs. from tensorflow.contrib.keras.python.keras.models import Sequential\n\nHope that helps get you where you want to go. Essentially once integrated in, you then just handle your model/weight export as usual. """"""', '""""""What is the difference between tf.keras.layers.Input() and tf.keras.layers.Flatten()\n\nI have seen multiple uses of both tf.keras.layers.Flatten() (ex. here) and tf.keras.layers.Input() (ex. here). After reading the documentation, it is not clear to me\n\nwhether either of them uses the other\n\nwhether both can be used interchangeably when introducing to a model an input layer (let\'s say with dimensions (64, 64))\n\nBillTheKidBillTheKid\n\n0\n\nI think the confusion comes from using a tf.keras.Sequential model, which does not need an explicit Input layer. Consider the following two models, which are equivalent:\n\nimport tensorflow as tf model1 = tf.keras.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(5, activation=\'relu\'), ]) model1.build((1, 28, 28, 1))\n\nmodel2 = tf.keras.Sequential([ tf.keras.layers.Input((28, 28, 1)), tf.keras.layers.Flatten(), tf.keras.layers.Dense(5, activation=\'relu\'), ])\n\nThe difference is that I explicitly set the input shape of model2 using an Input layer. In model1, the input shape will be inferred when you pass real data to it or call model.build. Now regarding the Flatten layer, this layer simply converts a n-dimensional tensor (for example (28, 28, 1)) into a 1D tensor (28 x 28 x 1). The Flatten layer and Input layer can coexist in a Sequential model but do not depend on each other. \n\nSo If I understand correctly, in the example of code I used for the tf.keras.layers.Input class, the data are not flattened, they are kept in the same shape, and the class is just used to specify their shape. In that specific example it is necessary to use Input, although the model is Sequential, right? So If I understand correctly, in the example of code I used for the tf.keras.layers.Input class, the data are not flattened, they are kept in the same shape, and the class is just used to specify their shape <--yes. ,,,,, In that specific example it is necessary to use Input, although the model is Sequential, right? <-- it is optional not necessary. Ok this solves my questions!""""""', '"""""" How can I convert a trained Tensorflow model to Keras? I have a trained Tensorflow model and weights vector which have been exported to protobuf and weights files respectively. How can I convert these to JSON or YAML and HDF5 files which can be used by Keras? I have the code for the Tensorflow model, so it would also be acceptable to convert the tf.Session to a keras model and save that in code. I think the callback in keras is also a solution. The ckpt file can be saved by TF with:\n\nsaver = tf.train.Saver() saver.save(sess, checkpoint_name)\n\nand to load checkpoint in Keras, you need a callback class as follow:\n\nclass RestoreCkptCallback(keras.callbacks.Callback): def __init__(self, pretrained_file): self.pretrained_file = pretrained_file self.sess = keras.backend.get_session() self.saver = tf.train.Saver() def on_train_begin(self, logs=None): if self.pretrian_model_path: self.saver.restore(self.sess, self.pretrian_model_path) print(\'load weights: OK.\')\n\nThen in your keras script:\n\nmodel.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\') restore_ckpt_callback = RestoreCkptCallback(pretrian_model_path=\'./XXXX.ckpt\') model.fit(x_train, y_train, batch_size=128, epochs=20, callbacks=[restore_ckpt_callback])\n\nThat will be fine. I think it is easy to implement and hope it helps.""""""', '""""""What is the advantage of using an InputLayer (or an Input) in a Keras model with Tensorflow tensors? A Keras model can used as a Tensorflow function on a Tensor, through the functional API, as described here. from keras.layers import InputLayer a = tf.placeholder(dtype=tf.float32, shape=(None, 784)) model = Sequential() model.add(InputLayer(input_tensor=a, input_shape=(None, 784))) model.add(Dense(32, activation=\'relu\')) model.add(Dense(10, activation=\'softmax\')) output = model.output\n\n<tf.Tensor \'dense_24/Softmax:0\' shape=(?, 10) dtype=float32>\n\nBut, this also works without any InputLayer:\n\na = tf.placeholder(dtype=tf.float32, shape=(None, 784)) model = Sequential() model.add(Dense(32, activation=\'relu\', input_shape=(784,))) model.add(Dense(10, activation=\'softmax\')) output = model(a)\n\nworks, and output has the same shape as before:\n\n<tf.Tensor \'sequential_9/dense_22/Softmax:0\' shape=(?, 10) dtype=float32>\n\nI assume the first form permits:\n\nto explicitely attach the inputs and outputs as attributes of the model (of the same names), so we can reuse them elsewhere. For example with other TF ops. to transform the tensors given as inputs into Keras inputs, with additional metadata (such as _keras_history as stated in the source code). But this is not something we cannot do with the second form, so, is there a special usage of the InputLayer (and Input a fortiori) (except for multiple inputs)? Moreover, the InputLayer is tricky because it\'s using input_shape differently from other keras layers: we specify the batch size (None here), which is not usually the case... It would seem that InputLayer has some uses:\n\nFirst, it allows you to give pure tensorflow tensors as is, without specifying their shape. E.g. you could have written\n\nmodel.add(InputLayer(input_tensor=a))\n\nThis is nice for several obvious reasons, among others less duplication. Second, they allow you to write non-sequential networks with a single input, e.g. input / \\ / \\ / \\ conv1 conv2 | |\n\nWithout InputLayer you would need to explicitly feed conv1 and conv2 the same tensor, or create an arbitrary identity layer on top of the model. Neither is quite pleasing.""""""']","### Description

This response addresses the issue of converting a Keras model to a `tf.keras` model, specifically focusing on the error: ""The last dimension of the inputs to Dense should be defined. Found None.""

### Explanation

The error arises because the `tf.keras.layers.InputLayer` is used incorrectly in the converted model. In the original Keras model, `keras.layers.Input` is used to define the input layer, which correctly specifies the input shape. However, in the converted `tf.keras` model, `tf.keras.layers.InputLayer` is used instead of `tf.keras.layers.Input`. This is a crucial difference.

The `tf.keras.layers.Input` function is used to instantiate a Keras tensor, which is necessary for defining the input shape explicitly. On the other hand, `tf.keras.layers.InputLayer` is typically used within a Sequential model to add an input layer, but it does not instantiate a Keras tensor in the same way.

In the original Keras model, the input layer is defined with `keras.layers.Input(shape=(100,))`, which correctly sets the input shape. This input tensor is then passed through the subsequent layers, ensuring that the dimensions are properly defined.

In the converted `tf.keras` model, replacing `tf.keras.layers.InputLayer(input_shape=(100,))` with `tf.keras.layers.Input(shape=(100,))` will resolve the issue. This change ensures that the input tensor is correctly instantiated, and the dimensions are properly defined for the subsequent layers, including the Dense layers.

Additionally, the use of `tf.keras.layers.Reshape((-1, 100, 1))` should be carefully reviewed. The `-1` in the reshape layer is used for shape inference, but it requires that the other dimensions are correctly specified. If the input shape is not properly defined, the reshape operation may not work as intended, leading to the error encountered.

In summary, the error ""The last dimension of the inputs to Dense should be defined. Found None."" is due to the incorrect use of `tf.keras.layers.InputLayer` instead of `tf.keras.layers.Input`. By using `tf.keras.layers.Input` to define the input layer, the input shape is correctly specified, and the dimensions are properly defined for the subsequent layers, resolving the issue."
57813806,tf.feature_column,example required,Apply feature columns without tf.Estimator (Tensorflow 2.0.0-rc0),"<p>In the Tensorflow tf.Estimator and tf.feature_column docs it is well documented, how to use feature columns together with an Estimator e.g. in order to one-hot encode the categorical features in the dataset being used.</p>

<p>However, I want to ""apply"" my feature columns directly to a tf.dataset which I create from a .csv file (with two columns: UserID, MovieID), without even defining a model or an Estimator. (Reason: I want to check what's happening exactly in my datapipeline, i.e. I'd like to be able to run a batch of samples through my the pipeline, and then see in the output how the features got encoded.)</p>

<p>This is what I have tried so far:</p>

<pre><code>column_names = ['UserID', 'MovieID']

user_col = tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000)
movie_col = tf.feature_column.categorical_column_with_hash_bucket(key='MovieID', hash_bucket_size=1000)
feature_columns = [tf.feature_column.indicator_column(user_col), tf.feature_column.indicator_column(movie_col)]

feature_layer = tf.keras.layers.DenseFeatures(feature_columns=feature_columns)

def process_csv(line):
  fields = tf.io.decode_csv(line, record_defaults=[tf.constant([], dtype=tf.int32)]*2, field_delim="";"")
  features = dict(zip(column_names, fields))

  return features 

ds = tf.data.TextLineDataset(csv_filepath)
ds = ds.map(process_csv, num_parallel_calls=4)
ds = ds.batch(10)
ds.map(lambda x: feature_layer(x))
</code></pre>

<p>However the last line with the map call raises the following error:</p>

<blockquote>
  <p>ValueError: Column dtype and SparseTensors dtype must be compatible.
  key: MovieID, column dtype: , tensor dtype: </p>
</blockquote>

<p>I'm not sure what this error means...
I also tried to define a tf.keras model with only the feature_layer I defined, and then run .predict() on my dataset - instead of using ds.map(lambda x: feature_layer(x)):</p>

<pre><code>model = tf.keras.Sequential([feature_layer])
model.compile()
model.predict(ds)
</code></pre>

<p>However, this results exactly in the same error as above.
Does anybody have an idea what is going wrong? Is there maybe an easier way to achieve this?</p>
","<p>Just found the issue:
tf.feature_column.categorical_column_with_hash_bucket() takes an optional argument dtype, which is set to tf.dtypes.string by default.
However, the datatype of my columns is numerical (tf.dtypes.int32).
This solved the issue:</p>

<pre><code>tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000, dtype=tf.dtypes.int32)
</code></pre>
","Just found the issue:
tf.feature_column.categorical_column_with_hash_bucket() takes an optional argument dtype, which is set to tf.dtypes.string by default. However, the datatype of my columns is numerical (tf.dtypes.int32).

This solved the issue:
<pre><code>tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000, dtype=tf.dtypes.int32)
</code></pre>",,"['How to use tf.feature_column with tf.data.Dataset in TensorFlow?', 'How to apply feature columns directly to a tf.data.Dataset in TensorFlow?', 'How to one-hot encode categorical features using tf.feature_column and tf.data.Dataset?', 'How to debug ValueError: Column dtype and SparseTensors dtype must be compatible in TensorFlow?', 'How to use tf.keras.layers.DenseFeatures with tf.data.Dataset?', 'How to preprocess CSV data using tf.data.Dataset and tf.feature_column in TensorFlow?', 'How to map feature columns to a dataset without defining a model in TensorFlow?', 'How to use tf.feature_column.indicator_column with tf.data.Dataset?']","['How to use tf.feature_column with tf.data.Dataset in TensorFlow?', 'How to apply feature columns directly to a tf.data.Dataset?', 'How to one-hot encode categorical features in a tf.data.Dataset using tf.feature_column?', 'How to debug ValueError: Column dtype and SparseTensors dtype must be compatible in TensorFlow?', 'How to use tf.keras.layers.DenseFeatures with tf.data.Dataset?', 'How to process CSV data with tf.data.TextLineDataset and tf.feature_column?', 'How to use tf.feature_column.indicator_column with tf.data.Dataset?', 'How to map feature columns to a dataset in TensorFlow?']",set(),[],"{'https://stackoverflow.com/questions/57403472/how-do-i-add-a-new-feature-column-to-a-tf-data-dataset-object', 'https://stackoverflow.com/questions/43653116/how-to-one-hot-encode-category-features-with-pandas-or-tensorflow', 'https://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder'}","['""""""How do I add a new feature column to a tf.data.Dataset object? \n\nI am building an input pipeline for proprietary data using Tensorflow 2.0\'s data module and using the tf.data.Dataset object to store my features. Here is my issue - the data source is a CSV file that has only 3 columns, a label column and then two columns which just hold strings referring to JSON files where that data is stored. I have developed functions that access all the data I need, and am able to use Dataset\'s map function on the columns to get the data, but I don\'t see how I can add a new column to my tf.data.Dataset object to hold the new data. So if anyone could help with the following questions, it would really help:\n\nHow can a new feature be appended to a tf.data.Dataset object? Should this process be done on the entire Dataset before iterating through it, or during (I think during iteration would allow utilization of the performance boost, but I don\'t know how this functionality works)? I have all the methods for taking the input as the elements from the columns and performing everything required to get the features for each element, I just don\'t understand how to get this data into the dataset. I could do ""hacky"" workarounds, using a Pandas Dataframe as a ""mediator"" or something along those lines, but I want to keep everything within the Tensorflow Dataset and pipeline process, for both performance gains and higher quality code. I have looked through the Tensorflow 2.0 documentation for the Dataset class (https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset), but haven\'t been able to find a method that can manipulate the structure of the object. Here is the function I use to load the original dataset:\n\ndef load_dataset(self): # TODO: Function to get max number of available CPU threads dataset = tf.data.experimental.make_csv_dataset(self.dataset_path, self.batch_size, label_name=\'score\', shuffle_buffer_size=self.get_dataset_size(), shuffle_seed=self.seed, num_parallel_reads=1) return dataset\n\nThen, I have methods which allow me to take a string input (column element) and return the actual feature data. And I am able to access the elements from the Dataset using a function like "".map"". But how do I add that as a column? \n\nWow, this is embarassing, but I have found the solution and it\'s simplicity literally makes me feel like an idiot for asking this.""""""']","### Description

This response addresses the question of how to apply feature columns directly to a `tf.data.Dataset` without using a `tf.Estimator` in TensorFlow 2.0.0-rc0. The user aims to preprocess and encode features from a CSV file using feature columns and then inspect the transformed data.

### Explanation

To achieve this, you can use TensorFlow's `tf.feature_column` module to define feature columns and then apply these columns to your dataset using a `tf.keras.layers.DenseFeatures` layer. The process involves several steps:

1. **Define Feature Columns**: Create feature columns for each feature in your dataset. For example, you can use `tf.feature_column.categorical_column_with_hash_bucket` to handle categorical features and then wrap them with `tf.feature_column.indicator_column` to convert them into one-hot encoded dense representations.

2. **Create a Feature Layer**: Use `tf.keras.layers.DenseFeatures` to create a feature layer that will apply the transformations defined by your feature columns.

3. **Process CSV Data**: Define a function to parse and process each line of the CSV file. This function should decode the CSV line into a dictionary of features.

4. **Create and Transform Dataset**: Use `tf.data.TextLineDataset` to read the CSV file and apply the processing function using the `map` method. Batch the dataset and then apply the feature layer to transform the features.

### Common Issues and Solutions

- **Data Type Compatibility**: Ensure that the data types of the columns in your dataset match the expected data types of the feature columns. The error ""Column dtype and SparseTensors dtype must be compatible"" indicates a mismatch between the data types. Verify that the data types specified in the `record_defaults` of the `tf.io.decode_csv` function align with the data types expected by the feature columns.

- **Batching and Mapping**: When applying the feature layer, ensure that the dataset is batched before mapping the feature layer. This allows the feature layer to process a batch of samples at once, which is necessary for the transformations to be applied correctly.

By following these steps, you can preprocess and encode features directly within a `tf.data.Dataset` pipeline, allowing you to inspect the transformed data without defining a model or an Estimator. This approach provides a clear and efficient way to handle feature transformations within the TensorFlow data pipeline."
76324368,tf.keras.layers.Dense,example required,Understanding tf.keras.layers.Dense(),"<p>I am trying to understand why there is a difference between calculating a dense layer operation directly and using the <code>keras</code> implementation.</p>
<p>Following the documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense</a>) <code>tf.keras.layers.Dense()</code> should implement the operation <code>output = activation(dot(input, kernel) + bias)</code> but <code>result</code> and <code>result1</code> below are not the same.</p>
<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(5,10)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<p>output</p>
<pre class=""lang-py prettyprint-override""><code>
[[2.87080455]
 [3.25458574]
 [3.28776264]
 [3.14319134]
 [2.04760242]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]

</code></pre>
<p>Using <code>test.get_weights()</code> I can see that the kernel and bias (<code>b</code>) are getting set to the correct values. I am using TF version 2.12.0.</p>
","<p>After some experimentation I realized that the <code>kernel</code> for the dense layer needs to be of <code>shape=(10,5)</code> as apposed to <code>(5,10)</code> as in the code from the original question above. This is implicit because <code>units=5</code> so a vector of size <code>10</code> needs to be passed (hence why <code>input_shape=(10,)</code> is commented out as a reminder). Below is the corrected code:</p>
<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias   = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            # input_shape=(10,),
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<pre class=""lang-py prettyprint-override""><code>[[2.38769]
 [3.63470697]
 [2.62423944]
 [3.31286287]
 [2.91121125]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]
</code></pre>
<p>Ultimately, I am not entirely sure what was happening under the hood and why <code>keras</code> did not raise an error. I will check with the <code>tf.keras.layers.Dense()</code> implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!</p>
","After some experimentation I realized that the <code>kernel</code> for the dense layer needs to be of <code>shape=(10,5)</code> as apposed to <code>(5,10)</code> as in the code from the original question above. This is implicit because <code>units=5</code> so a vector of size <code>10</code> needs to be passed (hence why <code>input_shape=(10,)</code> is commented out as a reminder). 

Ultimately, I am not entirely sure what was happening under the hood and why <code>keras</code> did not raise an error. I will check with the <code>tf.keras.layers.Dense()</code> implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!","<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias   = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            # input_shape=(10,),
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<pre class=""lang-py prettyprint-override""><code>[[2.38769]
 [3.63470697]
 [2.62423944]
 [3.31286287]
 [2.91121125]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]
</code></pre>","['Understanding the tf.keras.layers.Dense layer in TensorFlow', 'How to use kernel_initializer and bias_initializer in tf.keras.layers.Dense', 'Difference between tf.linalg.matmul and tf.keras.layers.Dense', 'How to set and retrieve weights in tf.keras.layers.Dense', 'Common mistakes when using tf.keras.layers.Dense with custom initializers', 'Debugging discrepancies in TensorFlow dense layer outputs', 'Step-by-step guide to implementing a dense layer in TensorFlow', 'Using tf.nn.relu with custom weights and biases in TensorFlow', 'TensorFlow 2.12.0 dense layer implementation details']","['Why is there a difference between calculating a dense layer operation directly and using the keras implementation?', 'How does tf.keras.layers.Dense() handle input shapes and transpositions?', 'What are the differences in input handling between tf.linalg.matmul and tf.keras.layers.Dense?', 'How does tf.keras.layers.Dense() apply the activation function and bias?', 'What are the best practices for initializing kernel and bias in tf.keras.layers.Dense?', 'How to ensure consistent results between manual dense layer calculations and tf.keras.layers.Dense?']",set(),[],"{'https://stackoverflow.com/questions/66626700/difference-between-tensorflows-tf-keras-layers-dense-and-pytorchs-torch-nn-lin', 'https://stackoverflow.com/questions/76324368/understanding-tf-keras-layers-dense', 'https://stackoverflow.com/questions/60783216/what-exactly-does-tf-keras-layers-dense-do'}","['""""""What exactly does tf.keras.layers.Dense do? Asked 4 years, 3 months ago\n\nI\'m using the Keras to build a convolutional neural network. I ran across the following:\n\nmodel = tf.keras.Sequential() model.add(layers.Dense(10*10*256, use_bias=False, input_shape=(100,)))\n\nI\'m curious - what exactly mathematically is going on here? My guess is that for input of size [100,N], the network will be evaluated N times, once for each training example. The Dense layer created by layers.Dense contains (10*10*256) * (100) parameters that will be updated during backpropagation. Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True). Note: If the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with kernel. # as first layer in a sequential model: model = Sequential() model.add(Dense(32, input_shape=(16,))) # now the model will take as input arrays of shape (*, 16) # and output arrays of shape (*, 32) # after the first layer, you don\'t need to specify # the size of the input anymore: model.add(Dense(32))\n\n> units: Positive integer, dimensionality of the output space. > activation: Activation function to use.""""""', '""""""Understanding tf.keras.layers.Dense()\n\nI am trying to understand why there is a difference between calculating a dense layer operation directly and using the keras implementation. Following the documentation (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) tf.keras.layers.Dense() should implement the operation output = activation(dot(input, kernel) + bias) but result and result1 below are not the same. tf.random.set_seed(1) bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32) kernel = tf.Variable(tf.random.uniform(shape=(5,10)), dtype=tf.float32) x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32)) result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x) + bias) tf.print(result) test = tf.keras.layers.Dense(units = 5, activation = \'relu\', use_bias = True, kernel_initializer = tf.keras.initializers.Constant(value=kernel), bias_initializer = tf.keras.initializers.Constant(value=bias), dtype=tf.float32) result1 = test(tf.transpose(x)) print() tf.print(result1)\n\n[[2.87080455] [3.25458574] [3.28776264] [3.14319134] [2.04760242]] [[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]\n\nUsing test.get_weights() I can see that the kernel and bias (b) are getting set to the correct values. I am using TF version 2.12.0. After some experimentation I realized that the kernel for the dense layer needs to be of shape=(10,5) as apposed to (5,10) as in the code from the original question above. This is implicit because units=5 so a vector of size 10 needs to be passed (hence why input_shape=(10,) is commented out as a reminder). Below is the corrected code:\n\ntf.random.set_seed(1) bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32) kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32) x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32)) result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias) tf.print(result) test = tf.keras.layers.Dense(units = 5, # input_shape=(10,), activation = \'relu\', use_bias = True, kernel_initializer = tf.keras.initializers.Constant(value=kernel), bias_initializer = tf.keras.initializers.Constant(value=bias), dtype=tf.float32) result1 = test(tf.transpose(x)) print() tf.print(result1)\n\n[[2.38769] [3.63470697] [2.62423944] [3.31286287] [2.91121125]] [[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]\n\nUltimately, I am not entirely sure what was happening under the hood and why keras did not raise an error. I will check with the tf.keras.layers.Dense() implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!""""""', '""""""Oh, I see. The question title confused me. It seems like you wanted to know how they\'re calculated behind. Alex\'s answer should ok for you. Yes, I could\'ve phrased it slightly better. But regardless, I just needed clarification of the Linear Algebra itself and how these Layers differ between Linears. The derivative is one example in how they differ ( as they\'re different linear algrabra operations ). I did state a \'guess\' of what TF\'s Dense layer is and if it\'s the same. So, I might make an edit to the title if other people think it\'ll help with clarification! Thank you for the explanation of the TF\'s Dense layer though! :D\n\n\n\ntf.keras.layers.Dense is defined here in the tensorflow source code:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/core.py#L1081\n\nIf you follow the references in its call function, it leads you to the definition of the operation used here, which is indeed a matrix multiplication of the inputs and weights plus a bias vector as expected:\n\nhttps://github.com/tensorflow/tensorflow/blob/a68c6117a1a53431e739752bd2ab8654dbe2534a/tensorflow/python/keras/layers/ops/core.py#L74\n\noutputs = gen_math_ops.MatMul(a=inputs, b=kernel) ... outputs = nn_ops.bias_add(outputs, bias)\n\n4\n\nSo, the definition of the kernel variable is a weight matrix but of the opposite dimension of PyTorch\'s weight matrix? So, let\'s say I have A input features of batch size N, and B output features. The dimensionality of kernel would be [A, B] whereas in the case of PyTorch it\'d be [B, A] (because there\'s a transpose applied to it?)\n\n\n\nYes they store the weights slightly differently (W.T vs W) but the result is still the same. PyTorch\'s representation is closer to the notation in text books. You can check this quickly by printing out the shape of the Linear/Dense weights in torch and tf. In line 1192 of the first link to the TF source code above, the weights in are initialised with shape=[last_dim, self.units] (N_feats, N_out) and in PyTorch (source code link), the weights are initialised with Parameter(torch.Tensor(out_features, in_features)) (N_out, N_feats)\n\n\n\nAlright, so for a linear layer of input x of shape (N_samp, N_feats) the output for TF would be matmul(x, A) + b where A is (N_feats, N_out) and b is (N_out, ) and for PyTorch it\'s matmul(x, A^T) + b where A is now (N_out, N_feats) and b is (N_out, ). Alright, so it seems that the 2 libraries define their Linear layers differently!""""""']","### Understanding tf.keras.layers.Dense()

The question addresses the difference between calculating a dense layer operation directly and using the `tf.keras.layers.Dense` implementation. The `Dense` layer in TensorFlow implements the operation `output = activation(dot(input, kernel) + bias)`, where `activation` is the element-wise activation function passed as the `activation` argument, `kernel` is a weights matrix created by the layer, and `bias` is a bias vector created by the layer (if `use_bias` is `True`).

In the provided example, the discrepancy arises due to the shape of the `kernel` matrix. Initially, the `kernel` is defined with a shape of `(5, 10)`, which does not align with the expected shape for the `Dense` layer. The `Dense` layer expects the `kernel` to have a shape of `(input_dim, units)`, where `input_dim` is the dimensionality of the input and `units` is the dimensionality of the output space. In this case, the correct shape for the `kernel` should be `(10, 5)` because the input has a shape of `(10, 1)` and the `Dense` layer is configured with `units=5`.

When the `kernel` is correctly reshaped to `(10, 5)`, the operation `output = activation(dot(input, kernel) + bias)` produces the expected results, matching the direct calculation. The `Dense` layer performs a matrix multiplication between the input and the `kernel`, followed by the addition of the `bias` vector, and then applies the specified activation function.

The confusion stems from the implicit requirement that the `kernel` shape must match the expected dimensions based on the input and output sizes. TensorFlow does not raise an error when the `kernel` shape is incorrect, but the results will not be as expected. Ensuring that the `kernel` and `bias` initializers are set with the correct shapes resolves the discrepancy.

In summary, the difference observed is due to the incorrect shape of the `kernel` matrix. The `Dense` layer expects the `kernel` to have a shape of `(input_dim, units)`, and when this condition is met, the results from the `Dense` layer match the direct calculation."
68984841,tf.keras.layers.Dense,example required,How can I understand the kernel of tf.keras.layers.Dense for rank >2?,"<p>How can I understand the kernel of <code>tf.keras.layers.Dense</code> for rank &gt;2?</p>
<p>The official API doc states that:</p>
<blockquote>
<p>Note: If the input to the layer has a rank greater than 2, then Dense
computes the dot product between the inputs and the kernel along the
last axis of the inputs and axis 0 of the kernel (using tf.tensordot).
For example, if input has dimensions (batch_size, d0, d1), then we
create a kernel with shape (d1, units), and the kernel operates along
axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there
are batch_size * d0 such sub-tensors). The output in this case will
have shape (batch_size, d0, units).</p>
</blockquote>
<p>My understanding is that for a rank larger than 2 (for example rank 3) only <strong>one</strong> kernel is created and thus the same kernel is applied on all slices of the second dimension, like above.
That would consequently mean that the outputs for different indices of the second dimension are <strong>not independent</strong> of each other (especially during training).</p>
<p>Is my understanding correct? And if yes, is there a simple way to use a stack of kernels instead or do I have to implement the tensor multiplication?</p>
","<p>Yes, your understanding is correct.</p>
<p>To achieve what you want, you need to define a custom keras layer. Let's suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original <code>Dense</code> layer (link: <a href=""https://github.com/tensorflow/tensorflow/blob/22ffec3a9c44133cba2182d60678d49bb372f020/tensorflow/python/keras/layers/core.py#L1077"" rel=""nofollow noreferrer"">github</a>), except that</p>
<ol>
<li>In the <code>build</code> function, the shape of <code>self.kernel</code> is (d0, i0, units) instead. You can get the value of <code>d0</code> as well as <code>i0</code> from <code>input_shape</code>.</li>
<li>In the <code>call</code> function, to do the specified tensor multiplication between <code>inputs</code> and <code>self.kernel</code>, use <code>tf.einsum</code> with this equation: <code>tf.einsum('abc,bcg-&gt;abg', inputs, self.kernel)</code></li>
</ol>
","Yes, your understanding is correct. To achieve what you want, you need to define a custom keras layer. Let's suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original <code>Dense</code> layer, except that

1. In the <code>build</code> function, the shape of <code>self.kernel</code> is (d0, i0, units) instead. You can get the value of <code>d0</code> as well as <code>i0</code> from <code>input_shape</code>.
2. In the <code>call</code> function, to do the specified tensor multiplication between <code>inputs</code> and <code>self.kernel</code>, use <code>tf.einsum</code> with this equation: <code>tf.einsum('abc,bcg-&gt;abg', inputs, self.kernel)</code>",,"['Understanding tf.keras.layers.Dense for rank > 2 inputs', 'How does tf.keras.layers.Dense handle inputs with rank greater than 2?', 'TensorFlow Dense layer with rank 3 input explanation', 'Using multiple kernels in tf.keras.layers.Dense for higher rank inputs', 'TensorFlow Dense layer kernel application on higher rank tensors', 'Independent outputs for different indices in tf.keras.layers.Dense', 'Implementing tensor multiplication for tf.keras.layers.Dense with rank > 2 inputs']","['How does tf.keras.layers.Dense handle inputs with rank greater than 2?', 'Is it true that tf.keras.layers.Dense uses the same kernel for all slices of the second dimension when the input rank is greater than 2?', 'How can I use a stack of kernels in tf.keras.layers.Dense for inputs with rank greater than 2?', 'Are the outputs for different indices of the second dimension dependent on each other when using tf.keras.layers.Dense with rank greater than 2 inputs?', 'What is the best way to implement tensor multiplication with a stack of kernels in TensorFlow?']","{'https://www.youtube.com/watch?v=oJ1i2c1KxKk', 'https://www.youtube.com/watch?v=lor2LnEVn8M', 'https://www.youtube.com/watch?v=kyktbJpg2mU'}","['""""""[Document(page_content=""hi I\'m Zack Dean mayor and in this course I\'ll be teaching you advanced deep learning concepts using the Charis functional API you will learn how to build functional Kerris models including advanced topics such as shared layers categorical embeddings multiple inputs and multiple outputs the Charis functional API is extremely simple yet immensely powerful by the end of this class you will build a model that is capable of solving a regression and a classification problem at the same time chapter one is a refresher on building simple models where you will learn how to use the Charis functional API in Chapter two you will build a Karass model with two inputs in Chapter three you will learn how to generalize your two input model to three or more inputs and finally in Chapter four you will build models with multiple outputs that can solve multiple problems you will be using two datasets of college basketball games from American colleges the first data set is from the regular season and has the following data the IDS of the two teams that played whether the first team was home or away whether the first team won or lost the game and by how many points the first team won or lost for the tournament data set you also have the tournament seed which is a pre-tournament ranking for each team these seeds range from 1 to 16 where the best four teams get a seed of one and the worst four teams get a seed of 16 you will use the difference in the two team seeds as an input to your model here are the first five rows of both the data sets you can see that the team variables are encoded as integers and the tournament data set has one additional column the difference between the tournament seats for both teams other than the seed difference the two datasets have identical columns within a given year a team\'s roster stays relatively constant but between years it can change a lot as seniors graduate and freshmen start therefore for every year each school is given a unique integer ID Terrace models at their simplest are fundamentally composed of two parts an input layer and an output layer to start I\'ll define a very simple Kerris model which only expects a single input I\'ll specify this using the input function from the Charis layers module the number of columns in the input is specified using the shape parameter this tells the model how much data to expect note that the shape argument expects a tupple the input function returns a tensor if you print this tensor you\'ll see that it is a TF tensor object which indicates it is ready to be used by our model as input now that we\'ve defined our input layer let\'s define the output layer outputs in Kerris are most commonly a single dense layer which specifies the shape of the expected output in this case we are expecting our model to predict a single value so we pass one unit to the dense layer if you print the output layer the result is not a tensorflow tensor it is a function which takes a tensor as input and produces a tensor as output the difference between layers in tensors is key to understanding the Charis functional API layers are used to construct a deep learning model in tensors are used to define the data flow through the model in this case the input layer defines a tensor which we then pass to the output layer function the final output of our model is a tensor it is time for you to build some layers"", metadata={\'source\': \'oJ1i2c1KxKk\'})]""""""', '""""""[Document(page_content=""hello everyone Dr data science here welcome to Deep dive into Caris this is lecture one where we talk about sequential API to implement a simple neural network model for the very famous exclusive or or xor example so what is the sequential API the sequential API in Caris is a stack of layers where you can simply add one layer at a time and the information will through flow through the first layer and will go to the next layer and so on until it reaches the last uh layer of your network and obviously in this case each layer has weights that corresponds to the layer that follows it right so for example here we have the weights that connect the this input layer to the hidden layer and also the weights that they go from the hidden layer to the output layer and it\'s a very straightforward and simple way to build and train models for more complex architectures you probably want to look at the functional API in cares uh and we\'re going to talk about that in a future video but let\'s get it started today uh with the sequential API so in order to implement neural network in this case you have to follow five steps the very first step is to create and uh object so remember uh when we working with python we work with object oriented programming where we have classes and once we instantiate a class that\'s what we call an object and in order to do that you just simply from car. Models you import sequential so this is a sequential a API and then you instantiate this to create this model object and once you do that now you can add layers right um so one of the uh you know layers that we work a lot with is this dense layer which means that all the neurons are connected to the neurons in the previous layer um that\'s why it\'s called as the fully connected or dance layer and you can do so very simply by just using this method called model. add so this adds a layer to your network and the thing that you really have to hear specify is the number of units or the number of neurons in that layer uh for the very first layer you also so it\'s always a good idea to to uh give the dimension of your input data for example if you work with a two-dimensional data here uh the input DM would be two and also the activation function or the nonlinear function that that you use for your uh for that layer and here you can see that now we have also um another layer um that we are um adding um here you know we have units and activation here you know we don\'t Define input dim anymore more because we already know how many units we have before so you don\'t need any more input them here and then for the very F last layer you can add model. add um the number of units and this really depends on the uh data set that you have if you have a binary classification then you only use one unit here uh with the sigmoid activation function um and if you have like let\'s say uh a classification problem with 10 classes then use here unit equals 10 and activation is equal to softmax um so to just to summarize this your first and last layer are very much controlled by your data set but you have um a lot of freedom or flexibility in terms of what hidden layers you want to use the next step once you define or create your model is to compile it and this is where you provide the optimizer that you want to use remember we are using gradient descent uh type optimization techniques here so we can say here for example SGD or RMS prop or Adam or whatever else Optimizer that you have and we\'re going to talk about this in a future video and then the loss function and then the metrics that you want to use to to to uh monitor to learning progress and once you do this now you you do model feeding so that\'s where you actually like train your model you have to provide your training data the number of epoch or the number of times that you have to go through the data set and the B size which means that um how many data points are using uh for each uh gradient desent update and once you uh train your model now your model um is trained which means that now you can make predictions so you can use model. predict and um now we\'re going to see how all these five steps work together to to solve uh a classification problem so we\'re going to start by importing the essentials meaning import n as NP uh M plug le. pyplot as PLT this is what we need for plotting figures obviously we are working with Caris you have to import tensor flow as TF and also from tensor flow we import Caris um we can also look at the version of tensor flow that you have currently I have 2.1 um Z right so uh I definitely recommend you to use 10 tensorflow uh 2.0 so in order to create the data set for this problem in order uh for you to be able to replicate these uh experiments and I also put a link down below for for the for the GitHub page for these codes uh we\'re going to work with the synthetic data set so we\'re going to work with uh what is called as make blops as the name um says you\'re going to create Blobs of data I\'m using np. random. seit to make sure that um you know again for the producibility and then I\'m using make blobs where I provide four centers here and each of these centers is a two-dimensional Vector um so you can see here that these are the four blobs that we create the only thing I do here is that I want to make sure that this is a binary classification problem um so I\'m going to uh convert those four labels that are created here uh into a binary classification I just assigned them um two different values um and this is the exclusive or problem that you can see in a lot of um you know neuron networks and deep learning textbooks that when you have zero and zero you get zero one and one you get one so this mean sorry one and one you get zero uh so this means that these two uh clusters belong to the same class and then when you have zero and one or one and zero you get one so that\'s the other class that we have so that\'s why it\'s called exclusive or um and other than that here we just using you know scatter plot to to plot the data with the colors as the labels uh and using the title um X and Y labels that\'s always a good practice to to follow but the point that really uh is important here is to you know um create the model you know um compile it and train it uh in order to do that we you know as we said use carat models import sequential so that\'s for the sequential API and then you import the dense layer you instantiate your um object here this model object you add your first uh hidden layer which has two units in it and I\'m using here exponential linear unit as my activation and I\'m going to say that the input Dimension here is two right so if I go back to this very first uh figure that we have here we can see that this is a two-dimensional problem so these are the two inputs that I have and these are the two units that I have in my uh single hidden layer in this uh problem so therefore we have four raats and also we have two B bies remember we always have biases unless if we we turn off that option but for now we have these biases so this a total of six parameters that we have to learn four weights and two bies and then going from hidden layer to the output there are two weights and one bi that goes to the output layer okay so now uh one thing that you can do so once you define your model and you compile it so here I\'m using a stochastic gradient descent and because it\'s a class ification problem I\'m using binary cross entropy um so now we can use model. summary so this is exactly what I was talking about that you can see that we have six parameters that we have to train uh for the first layer and then three for the second one right uh so this is including bies that we have to include then you can look at U model. layers so this this gives you some attributes or whatever layers that we have and you can see that if I look at the first layer that\'s why index zero and use this method get weights you can see that we have a 2X two weight Matrix and two biases um and even though we have not train anything right now um you can see that there are still values here because we initialize this you know usually randomly um and so you can see that the weight metrix has know some random numbers here um and then the biases are usually initialized by by zeros um you can see that here too for the next layer we have a um you know a two weights um that takes us from the hidden layer to the output layer and then the bi but the point that you start to train this model is when you use this model. fit where you provide your data both the inputs and the labels the number of epoch which I have here choose 10 and the batch size which I have chosen to be four so these are uh options that you have to provide in in general so you can see that based on what we have here uh printed we have Epoch one two up to 10 um the last function is what you try to minimize so that\'s what\'s um you know usually hope that it will be uh descending or or decreasing function as as as the number of epoch increases and the accuracy here is classification accuracy so you want that to be as close as to be to one and you can see that it is you know at the end um 0 99 so very close to one so we can actually look at the accuracy and loss as the is a function of number of epochs because this is the information stored in that history um object that we have here and this gives us um a lot of good information right so if you look at it let\'s look at um you know accuracy first so we can see that accuracy is increasing so we are starting um you know from you know Point uh if I don\'t make mistake here from 0 five which means that you uh flip a coin and you get you know 50% um classification accuracy um and then uh as we have more Epoch we can see that this gets closer and closer to one or 100% And and then we see consistent results with the loss function right the loss function uh you know decreases consistently as the number of epoch increases so this is a perfect scenario of uh a neural network model that works um that works well for a given problem and this is what we expect because of the uh synthetic data set that we have and now after you train your model you can again look at those weights for the first layer and if you look at it these are different um than uh what we had before because you know we trained this model and the same with biases we can see that now we actually have nonzero values for for this bios terms the last thing I want to to talk about here is how you can visualize your classifier and have that nice plot of the probabilities that we just saw in order to do that you have to first create a two dimension dional grid so you provide the mean and Max values for both uh X and Y AIS um Su step size and then use this np. mesh grid um and this what basically does is that gives you all the coordinates that you need to create a a two-dimensional grid and now you can just Ravel them meaning that you flatten them and you concatenate them to create this mesh underscore input uh where you have these two dimensional data points or coordinates for all the sort of like you know data points on your grid and then use model. predict and in this case this gives you the probability that your data point belongs to uh class uh one so that\'s what we get here with predictions uh and then we we fit this to the Contour plot right so this PLT do contourf um that\'s what gives you this really nice plot right so these are the probabilities that we get here so you can see that obviously the separation here that this Middle Street is one class and then when you get farther from both sides then is more more likely that you belong to the other class the data points that you have um so that\'s why here you can see that this neural network uh is successful at uh predicting these classes correctly even though this is a complex problem because a linear classifier cannot correctly you know classify all these data points so this was uh one of the first examples of neural networks to show that um you know um that they work very well with these types of uh problems with subclusters and as a very final note um to just uh you know again collaborate the fact that if you use model that predict in in Paris you get probabilities um I\'m going to plot a histogram of these values and you can see that they\'re from zero to one right so as we said these are probability scores U and you can see that you know for you know about like 10,000 um soort of like cases or so um here we have um probabilities very close to zero and then probabilities very close to one um similarly and then a few data points that we are very close to like 50% right so these are the you know more difficult cases to to predict thank you so much for watching this video"", metadata={\'source\': \'kyktbJpg2mU\'})]""""""', '""""""[Document(page_content=""hi today we will study what is danger layer while you is dense layer and how we use danger layer intensive flow tool previously we studied how single node is working if you have a closed loop the node is just had three steps first multiplying input with the weight second adding bias Dudley applying activation function and return the output here picture I use the sigmoid as activation function and our compute this node for the interlayer explanation then the layer is just a set of nodes when inputs come to danger layer a danger layer provides input to all nodes in it thus providing all outputs to the next layer at once as a result this is an example of two nodes than the layer and this is an example of three nodes dense layer there are many reasons why we use danger layer most importantly we use tenth layer to put the data in the different dimension let\'s understand it with easy example before speak about the dense layer let\'s keep in mind that one node can draw one decision boundary therefore two nodes can draw to the Sun boundary previously we made and an or operation with one single node the reason why we could implement and an or operation with just one single node is because this new operation just need a one decision boundary to classify all or X and one node can draw one decision boundary as you can see from this picture however we cannot implement XOR operation with one single node because as you can see from this picture one decision boundary cannot classify or extremely since one node Rose one Sun boundary at least we can draw through the same boundaries using two nodes let\'s say first node is z1 and the second node is z2 and since it\'s not output is sigmoid function output we can say if the output value is greater than 0.5 the output is true or the output is false and you can find I marked one side from that eastern boundary to true and the other side is forced here for better understanding I put the table having the output from z1 and z2 so now let\'s have one other coordinate in which ugh z1 and z2 as dimensions you can see the right side chart where the z1 and z2 are axes there are two O\'s are overlapped and the two axes are scattered in order to classify oh and X from this dimension we\'ll need one more decision boundary tapping said we need one more node in this dimension then we can classify XOR dataset clearly awesome we will implement it using tensor flow too soon in this video to sum up in order to draw to the same boundary we need one dense layer having two nodes then we need one another dense layer having just one node to classify data point in first dense layers dimension I believe you can understand even easier with this picture I visualize how the first and the second dentin layer draws this young boundary and the here is a tensile flow to code to make XOR input and labels respectively and here is the code where I make first dense layer with two nodes for which text two-dimensional input data and you can see it as a Content layer has a one single node for one decision boundary on for stencil layers dimension and here you can find I use the gradient descent for the optimization and the cross entropy as a loss function finally we got a hundred percent test result from our tensor flow model with two dense layer you also can print each dentin layer node wait and buyers just make sure the number of columns are the number of nodes in the tens layer and the number of the rules are the numbers of the weights in the node and here you can find the second denser layers of weight and bias value as well then the layer also very useful for last layer of the classification model since n node danger layer output and output this is an example of classifying M needs the ten digits by having ten nodes then the layer at the last layer we can use the greatest output value index as a models prediction however since the denser layers node output are not normalized normally we apply softmax function at the last dense layer so the outputs to be normalized now you can see the zooming off of each node output is 1 so you can use the each node value as confidence for each number and we can use those the great greatest output value as a modest prediction this is all for this video and you can always practice XOR or in this our link thanks for watching and I\'ll come back to next video with a nice digital classification"", metadata={\'source\': \'lor2LnEVn8M\'})]""""""']","{'https://stackoverflow.com/questions/68984841/how-can-i-understand-the-kernel-of-tf-keras-layers-dense-for-rank-2', 'https://stackoverflow.com/questions/52089601/keras-dense-layers-input-is-not-flattened', 'https://stackoverflow.com/questions/63507023/how-to-make-a-keras-dense-layer-deal-with-3d-tensor-as-input-for-this-softmax-fu'}","['""""""Keras Dense layer\'s input is not flattened\n\nThis is my test code:\n\nfrom keras import layers input1 = layers.Input((2,3)) output = layers.Dense(4)(input1) print(output)\n\n<tf.Tensor \'dense_2/add:0\' shape=(?, 2, 4) dtype=float32>\n\nThe documentation says:\n\nNote: if the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with kernel. While the output is reshaped?""""""', '""""""How can I understand the kernel of tf.keras.layers.Dense for rank >2? \n\nHow can I understand the kernel of tf.keras.layers.Dense for rank >2? The official API doc states that:\n\nNote: If the input to the layer has a rank greater than 2, then Dense computes the dot product between the inputs and the kernel along the last axis of the inputs and axis 0 of the kernel (using tf.tensordot). For example, if input has dimensions (batch_size, d0, d1), then we create a kernel with shape (d1, units), and the kernel operates along axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there are batch_size * d0 such sub-tensors). The output in this case will have shape (batch_size, d0, units). My understanding is that for a rank larger than 2 (for example rank 3) only one kernel is created and thus the same kernel is applied on all slices of the second dimension, like above. That would consequently mean that the outputs for different indices of the second dimension are not independent of each other (especially during training). Is my understanding correct? And if yes, is there a simple way to use a stack of kernels instead or do I have to implement the tensor multiplication? Yes, your understanding is correct. To achieve what you want, you need to define a custom keras layer. Let\'s suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original Dense layer (link: github), except that\n\nIn the build function, the shape of self.kernel is (d0, i0, units) instead. You can get the value of d0 as well as i0 from input_shape. In the call function, to do the specified tensor multiplication between inputs and self.kernel, use tf.einsum with this equation: tf.einsum(\'abc,bcg->abg\', inputs, self.kernel)""""""']","### Understanding the Kernel of `tf.keras.layers.Dense` for Rank > 2

When using the `tf.keras.layers.Dense` layer with inputs that have a rank greater than 2, the layer computes the dot product between the inputs and the kernel along the last axis of the inputs and axis 0 of the kernel. For instance, if the input has dimensions `(batch_size, d0, d1)`, a kernel with shape `(d1, units)` is created. This kernel operates along axis 2 of the input, on every sub-tensor of shape `(1, 1, d1)`, resulting in an output shape of `(batch_size, d0, units)`.

Your understanding is correct: for inputs with a rank greater than 2, only one kernel is created, and this same kernel is applied to all slices of the second dimension. Consequently, the outputs for different indices of the second dimension are not independent of each other, especially during training.

To achieve independence across different indices of the second dimension, you would need to define a custom Keras layer. This custom layer would involve creating a stack of kernels instead of a single kernel and performing the specified tensor multiplication using `tf.einsum`.

This explanation addresses the question of how the kernel of `tf.keras.layers.Dense` operates for inputs with a rank greater than 2, confirming the understanding that a single kernel is applied across all slices of the second dimension and suggesting the creation of a custom layer for achieving independence across these slices."
53079436,tf.cond,example required,tensorflow Tf.cond giving unexpected output,"<p>I seem to be having a misunderstanding on how <code>tf.cond</code> works. In the tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/cond"" rel=""nofollow noreferrer"">documentation</a>, it gives the following example:</p>

<pre><code>z = tf.multiply(a, b)
result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))
</code></pre>

<p>The result of the example, if <code>x&lt;y</code> is <code>True</code> is <code>tf.add(x,z)</code> else <code>tf.square(y)</code></p>

<p>Following this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation.</p>

<p>in my example, <code>deterministic_action = 4</code>, <code>random_action = 11</code>, <code>chose_random=False</code>. The <code>stochastic_action</code> should be <code>4</code>, instead it is <code>1</code>.
Where did the value 1 come from?</p>

<pre><code>#!/usr/bin/env python3

import tensorflow as tf
import numpy as np

with tf.Graph().as_default():
    with tf.device('/cpu:0'):
        stochastic_ph = tf.placeholder(tf.bool, (), name=""stochastic"")
        eps = tf.get_variable(""eps"", (), initializer=tf.constant_initializer(0))
        with tf.variable_scope('test_cond') as sc:
            deterministic_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=0) # 4
            random_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=1) # 11
            chose_random = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32) &lt; eps # False because eps = 0
            stochastic_action = tf.cond(chose_random, lambda: random_action, lambda: deterministic_action) # S_action should be 4 but it is 1
            #output_action = tf.cond(stochastic_ph, lambda: stochastic_action, lambda: deterministic_action)


    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init, feed_dict={stochastic_ph: True})
    print (""s_ph = "", stochastic_ph)
    d_action = sess.run(deterministic_action)
    print (""det_action= "", d_action)
    r_action = sess.run(random_action)
    print (""rand_action= "", r_action)
    e = sess.run(eps)
    c_action = sess.run(chose_random)
    print (""chose_rand= "", c_action)
    s_action = sess.run(stochastic_action)
    print (""s_action= "", s_action)
    #output = sess.run(output_action)
</code></pre>

<p>here is the output:</p>

<pre><code>python random_vec.py
2018-10-31 09:46:15.028376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
</code></pre>
","<p>This is because you are evaluating again in a new sess.run. 
Since you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1.
Here is the result of your code, when I extract the value of deterministic_action as well in the last step.</p>

<p>Modification:</p>

<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
r_action = sess.run(random_action)
print (""rand_action= "", r_action)
e = sess.run(eps)
c_action = sess.run(chose_random)
print (""chose_rand= "", c_action)
s_action, d_action = sess.run([stochastic_action, deterministic_action])
print (""s_action= "", s_action)
print (""det_action= "", d_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
det_action=  1
</code></pre>

<p>Now all you need to do is run everything in one sess.run</p>

<pre><code>d_action, r_action, e,  c_action, s_action = sess.run([deterministic_action, random_action, eps, chose_random, stochastic_action])
print (""det_action= "", d_action)
print (""rand_action= "", r_action)
print (""chose_rand= "", c_action)
print (""s_action= "", s_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  4
</code></pre>

<p>Update:</p>

<p>I was not clear on why the random_uniform generates different values when seed is set. This is because the code is running with the same session object that it initialized the variables with.
Modifying the code with a new session object, this is what happens:</p>

<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
sess.close()
sess = tf.Session()
sess.run(init, feed_dict={stochastic_ph: True})
s_action = sess.run(stochastic_action)
print (""s_action= "", s_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
s_action=  4
</code></pre>
","This is because you are evaluating again in a new sess.run. 
Since you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1.
Here is the result of your code, when I extract the value of deterministic_action as well in the last step.","<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
r_action = sess.run(random_action)
print (""rand_action= "", r_action)
e = sess.run(eps)
c_action = sess.run(chose_random)
print (""chose_rand= "", c_action)
s_action, d_action = sess.run([stochastic_action, deterministic_action])
print (""s_action= "", s_action)
print (""det_action= "", d_action)
</code></pre>","['Understanding tf.cond in TensorFlow with examples', 'How to use tf.cond in TensorFlow', 'Common mistakes when using tf.cond in TensorFlow', 'TensorFlow tf.cond tutorial', 'Debugging tf.cond in TensorFlow', 'TensorFlow conditional operations with tf.cond', 'TensorFlow tf.cond vs tf.case', 'TensorFlow control flow operations: tf.cond', 'TensorFlow tf.cond with random operations', 'TensorFlow tf.cond with placeholders and variables']","['How does tf.cond work in TensorFlow?', 'Why does tf.cond return unexpected results in TensorFlow?', 'How to debug tf.cond in TensorFlow?', 'What are common pitfalls when using tf.cond in TensorFlow?', 'How does tf.random_uniform work in TensorFlow?', 'Why does tf.random_uniform return different values on each run?', 'How to ensure deterministic behavior in TensorFlow?', 'How to use tf.placeholder and tf.get_variable correctly in TensorFlow?', 'What is the role of tf.global_variables_initializer in TensorFlow?', 'How to correctly use feed_dict in TensorFlow sessions?']",{'https://www.youtube.com/watch?v=IzKXEbpT9Lg'},"['""""""[Document(page_content=\'SKYE WANDERMAN-MILNE: I\\\'m Skye,\\nfor those who don\\\'t know me. I\\\'ve been working on\\nControl Flow in TensorFlow for quite some time, with\\nthe help of [? Sarab ?] and many other\\nindividuals on the team. And so my goal with\\nthis talk is to tell you everything I know about\\nControl Flow that\\\'s important. Let\\\'s get started. I\\\'m going to start\\nby going over the lay of the land with Control\\nFlow in TensorFlow. So starting with what I\\\'m\\ngoing to call the Base APIs, tf dot cond and\\ntf dot while loop. So these are the\\nprimitives that are exposed in the public\\nPython API for users to access Control Flow. So you have conditional\\nexecution and loops. That\\\'s it. So you might be wondering, what\\nabout all the other Control Flow functions I know and\\nlove, like map or case? These are all built on those two\\nbase APIs, cond and while loop. They\\\'re sort of\\nwrappers around it that add useful functionality. So diving down\\ninto the stack, how are these primitives, cond and\\nwhile, actually implemented? How are they represented\\nin the graph? So in TensorFlow 1.x, we have\\nthese low-level Control Flow ops. You might have heard of them,\\nExit, Enter, Nextiteration, Switch, and Merge. We\\\'ll talk more\\nabout these in a bit. There\\\'s also an\\nalternate representation. That\\\'s what Control Flow\\nversion 2 is all about. These are the ""functional"" ops. And I put ""functional"" in\\nquotes because it\\\'s caused some confusion in the past. It\\\'s not like pure functional. In the programming sense,\\nthey\\\'re still state. But they\\\'re higher\\norder functions that take functions as input. So now, the cond branches will\\nbe represented as functions. So these sort of do the same\\nthing as the low-level ops, but the higher level\\nfunctionality is all wrapped up into a single op. Moving back up the\\nstack, you might be wondering what\\\'s going to\\nhappen with TensorFlow 2.0. If you\\\'re using Eager\\nexecution, you just write Python and you just use\\nPython Control Flow. So if statements, or loops,\\nor list comprehensions, that kind of thing. So there\\\'s no arrow connecting\\nit to this graph mode stuff. But if you use tf dot\\nfunction, maybe some people have heard of Autograph,\\nwhich is automatically included in tf dot\\nfunction, and this attempts to take your eager\\nstyle, just Python code, and convert it into new Python\\ncode that calls the TensorFlow graph APIs. So it\\\'s going to\\ntry to rewrite all that Python Control Flow, your\\nif statements and while loops, into tf dot cond and\\ntf dot while loop. So note that Autograph\\nis just dealing at this abstraction layer of\\nthe public TensorFlow API. It doesn\\\'t have to dive\\ndown into the low-level ops or anything like that. So that\\\'s kind of\\nwhere we\\\'re at. We have the 2.0 world where you\\njust write Python that maybe it can get converted into our\\npublic Graph APIs, which in turn are producing these\\nvarious operators in the graph. And one more thing. Right now, in this\\nnew implementation of Control Flow,\\nControl Flow version 2, we are still converting\\nthe functional ops back into the low-level ops. This is basically a\\nperformance optimization. I hope we don\\\'t have\\nto do it in the future. That\\\'s why it\\\'s this\\nfaded-dash arrow. So this talk, we\\\'re gonna\\nfocus on the base API and how it\\\'s implemented. I think there\\\'ll be another\\ntalk about Autographs, so hopefully they can talk\\nabout Control Flow there. Maybe there\\\'s also talk\\nabout Eager execution and the high-level APIs\\nthat are not so complicated. So leave that as an\\nexercise to the viewer. OK. So I\\\'m going to start with\\ngoing over Control Flow v1, the original\\nlow-level representation. You might be asking, why? Why do we care at all? So like I showed\\nin the diagram, we do still convert the functional\\nops to this representation. So this is basically how\\nit\\\'s executed today, always. Furthermore, this is still\\nwhat we use in TensorFlow 1.x. So all 1.x code is\\nusing Control Flow v1. Still very much alive. And I hope it provides a\\nlittle bit of motivation for why we wanted to\\nimplement Control Flow using the functional ops. So I\\\'m going to start\\nwith these low-level ops. So up here, Switch and Merge are\\nused for conditional execution, this is tf dot cond. Also in while loops to determine\\nwhether we need to keep iterating or we\\\'re done. And then Enter, Exit,\\nand Nextiteration are just used while loops\\nto manage the iterations. So let\\\'s dive in. So Switch and Merge, these\\nare for conditionals. Let\\\'s just start with Switch. The idea is you get your\\npredicate tensor in, this is a Boolean, that tells\\nyou which conditional branch you want to take. And then it has a\\nsingle data input, so [INAUDIBLE] some tensor. And it\\\'s just going to\\nforward that data input to one of its two outputs\\ndepending on the predicate. So in this picture, the\\npredicate must be false. And so the data\\\'s coming\\nout of the false output. Merge basically\\ndoes the opposite. It takes two inputs,\\nbut it only expects data from one of its inputs. And then it just\\noutputs a single output. So Switch is how you start\\nyour conditional execution, because it\\\'s going to divert\\nthat data into one branch. And then Merge brings\\nit back together into your mainline execution. It\\\'s not conditional anymore. One implementation detail\\nI\\\'m going to mention here is dead tensors. So you might think\\nthat nothing is going to come out of the\\ntrue output of the Switch, but it actually does output\\na special dead tensor, which is just like a sentinel value. Like a little tiny thing. And dead tensors flow\\nthrough the whole untaken conditional branch. And eventually, you\\\'re\\ngoing to get a dead tensor into this Merge. It just ignores it and outputs\\nwhatever data tensor it gets. So dead tensors are needed\\nfor distributed Control Flow, which I\\\'m actually not\\ngoing to cover in this talk. Because it\\\'s kind\\nof technical and I haven\\\'t found it that important\\nto know the details of it. It\\\'s covered in Yuan\\\'s paper. But I\\\'m mentioning dead\\ntensors because they do show up a lot in the execution. Like, if you look at\\nthe executor code, there\\\'s all this special\\ncase for dead tensors. This is what they\\\'re about,\\nit\\\'s for conditional execution so we can do distribution. SPEAKER 1: And retval\\nzero doesn\\\'t help any. SKYE WANDERMAN-MILNE: Oh, yeah. And that famous\\nerror message I want to put on a t-shirt, retval\\nzero does not have a value. That means you\\\'re trying\\nto read a dead tensor, or it probably\\nmeans there\\\'s a bug. OK. Moving on to the low-level\\nops we use for while loops. These manage\\niterations, basically. The concept you need to know\\nabout in execution is frames. So you have one\\nframe per execution. And this is what\\nallows the executor to keep track of\\nmultiple iterations, and allows a single op to\\nbe run multiple times as you do multiple iterations. So a frame defines a name, which\\nis for the whole while loop. And then it also has\\nan iteration number. So the Enter op, that just\\nestablishes a new frame. It means we\\\'re starting\\na new while loop. So it just forwards its input. It\\\'s like an identity,\\nexcept that output is now in this new frame. And it has an attribute\\nthat\\\'s the frame name, starts at frame 0. Exit\\\'s the opposite. It just it\\\'s like an\\nidentity, except it strips the frame from its input. So output is now not\\nin that frame anymore. And these can be stacked. So if you have a bunch of\\nEnters on a bunch of frames, you have a bunch of Exits, it\\\'ll\\npop them off one at the time. The Nextiteration\\\'s just\\nthe final piece in order to increment that\\niteration count. This might make more sense\\nwhen we put it all together, so let\\\'s do that. Starting with tf cond again. Let\\\'s just work through this. So down here, you have the\\nAPI call that we\\\'re using. So we start, we\\nhave this predicate. Note that the predicate isn\\\'t\\nactually part of the cond. It happens outside here,\\nbut then we feed it into the Switch operators. So the Switches and\\nMerges mark the boundary of the conditional\\nexecution, remember. So we\\\'ll feed this predicate\\nand then, the true branch is an Add. So we have a Switch\\nfor each input, for x and z, which is\\nthe external tensors we use in that branch. You\\\'ll note that they\\nare only being emitted from the true side of it. So if the false branch is taken,\\nnothing\\\'s connected to that. That comes out of Add, then\\nsimilarly on the other side, we\\\'re Squaring y, so we\\nhave a Switch for the y. This time, it\\\'s going to be\\nemitted from the false branch into the Square. And then, we only\\nhave one output from this cond so we\\nhave a single Merge. Either the Square or the\\nAdd, only one of those is going to actually have data,\\nand that\\\'s what will be output. So note that there is\\na Switch for each input and a Merge for each output,\\nthey don\\\'t have to match. And in this example,\\nthe two branches are using disjoint tensors. But say, we did the\\nSquare of x instead of y, then you would have\\nan edge from both the true output and the\\nfalse output, depending. Go to the Add or the Square. Let\\\'s quickly, actually,\\ngo over the while loop API, just to make\\nsure we all remember. So the first argument,\\nis a function. That\\\'s the predicate function. The second function is the body\\nthat we\\\'re going to execute. And this is where it\\\'s\\nkind of interesting. So you have some inputs, these\\nare called the loop variables, the input to the while loop. And then it\\\'s going to\\noutput updated versions of those same loop variables. So the inputs of the body\\nmatch the outputs of the body. Like, same number-type shape\\nof tensors because they\\\'re just the updated variables. SPEAKER 2: Can\\\'t the\\nshape-type [INAUDIBLE] SKYE WANDERMAN-MILNE: The\\nshape can change, you\\\'re right. Same number and types. And then the final, we\\\'d\\nprovide some initial input to start it off. So that\\\'s the 0,\\nthe final argument. And then the output\\nis going to be whatever the final value\\nof the loop variables are. And then the predicate function\\ntakes those same loop variables as input but just\\noutputs a Boolean, like, do we continue execution or not? So now we\\\'ll start\\nwith the inter-node. This, remember,\\nestablishes the new frame. We\\\'re starting a new while loop. I guess it\\\'s called L for loop. We go through a Merge now,\\nkind of reversed from the cond where you start with the Switch. Now you start with a Merge. Because it\\\'s choosing is\\nthis the initial value or is this the new, updated\\nvalue from an iteration? That feeds into the predicate. Note that the predicate\\nis inside the while loop now because it has to\\nexecute multiple times. The output goes\\ninto the Switch node to choose whether if\\nit\\\'s false, and we\\\'re going to exit the while\\nloop with that exit node. Otherwise, we go into the body,\\nwhich is an Add in this case, take the output of the body,\\nfeed it to the next iteration. Because we have to bump\\nthat frame count, remember? And then feed it\\nback into the Merge, which will forward it\\nback again and again, until we get to the Exit. So, hopefully, this\\nkind of makes sense. You can see there\\\'s\\na loop in there. That\\\'s the while loop. SPEAKER 3: For sequential\\nones, how does the Merge know to select the z or [INAUDIBLE]? Because wouldn\\\'t neither of them\\nbe dead tensors at that point? SKYE WANDERMAN-MILNE: I\\ndon\\\'t know the details of how this is implemented. But I think because\\nthe frame is different, z only is in the first frame. Because each frame\\nis conceptually like you made a\\ncopy of the body, it\\\'s going to keep track\\nof different pending counts for each node in\\nthe body, or the Merge, or the Switch. So I think that\\\'s why. OK. All right, so that\\\'s\\nall I\\\'m going to go over with Control Flow v1. It does have some advantages. It all, kind of,\\nfalls out of the fact that these low-level operators\\nare designed to naturally fit within the dataflow model,\\nbecause data graphs are dataflow graphs. So you get nice\\nfeatures like pruning, works pretty naturally,\\nbecause it\\\'s all regular nodes, sort of, for pruning. You can have parallel execution\\nof while loop iterations, which is actually pretty\\ncool, I think. Because once you add\\nin this frames logic, it kind of naturally keeps\\ntrack of all the pending counts. It runs just like a regular-- like, if you unrolled\\nthe loop and the data will flow through\\nas far as it can. Ops will be executed\\nas soon as they can. It just kind of works. However, there are\\nsome disadvantages. It\\\'s very complicated. Like, you can see that\\nthis is a bunch of nodes to express what in most\\nprogramming languages is like one line, like while. This shows up\\nespecially in gradients and nested Control Flow. You end up with all\\nthese crazy edge cases where you didn\\\'t hook\\nup the inner Merges correctly or whatever. As a result of this complexity,\\nhigher order derivatives are not implemented. This is not like a\\ndesign problem, per se. It\\\'s just it\\\'s so\\ncomplicated and there\\\'s so many edge cases no one\\nhas been able to do it, or has wanted to do it. Similarly to graph\\nconstruction being complicated, the runtime is complicated. Because you have to have\\nall this dead tensor logic, all this firm logic, and\\nit\\\'s very intricately baked into the executor. And this makes it hard\\nto read and maintain, and also, adds\\nperformance overhead. It\\\'s hard for other\\ndownstream things to analyze and make sense of. An example of this\\nis [INAUDIBLE] has been trying to do\\n[? auto ?] clustering for XLA, and so he has like\\nwhole docs written on how to handle dead\\ntensors, because they can show up anywhere. Similarly, XLA actually\\nrepresents Control Flow in a functional way\\nif in while ops. So when they consume\\nTensorFlow graphs, they have to pattern-match\\nthis crazy stuff back into just the while op that\\noriginally produced it. And especially with gradients\\nand nested Control Flow, it gets very complicated. There is a number of edge cases. This was actually one\\nof the main motivations for building Control Flow v2. Because we were fixing\\nso many bugs and how this was represented in so many\\nedge cases, that it\\\'s like, we just need a simpler\\nrepresentation. OK. So, hopefully, this\\nwill be simpler. I can fit it on\\none slide for both. [LAUGHTER] So tf dot cond, it\\\'s\\njust an if op now. You have the Boolean\\npredicate coming in. These arrows represent the\\ntype signature of the op, not individual tensors per se. So then this could be\\nany number and type of tensors coming into input. And then similarly, any number\\nof type tensor is coming out. They don\\\'t have to match. Then these represent,\\nthey\\\'re technically function attributes,\\nbut they\\\'re basically functions attached to this op\\nrepresenting the true branch and the false branch. So they\\\'re like,\\nlittle subgraphs. One thing to note that\\\'s\\nimportant with these functions is that the function\\nsignatures have to match. So the functions have the same\\ninputs and the same outputs. The inputs and\\noutputs don\\\'t have to match, what but they have to\\nmatch across the two branches. SPEAKER 4: [INAUDIBLE]\\nthe type, not values? SKYE WANDERMAN-MILNE: Yes. Sorry. Well, we\\\'re just talking\\nsignatures right now. So just type and possibly\\nshape in some cases. Yeah, it doesn\\\'t even have\\nto be implemented this way, but it is. It makes somethings\\nsimpler to think about. But keep that in mind. Similarly, tf dot while loop\\njust turns into a while op now. Now all our inputs and outputs\\nare just the loop variables. Because, remember, the predicate\\ntakes those loop variables as inputs. So you have a cond function\\nor a predicate function, takes a loop verbals as\\ninput, output, or Bool. And then the body function that\\ntakes the loop variable inputs and outputs, the updated\\nversion, which will eventually be-- the final value will be\\nupdated output from the op. So does this make sense? This picture. SPEAKER 4: One thing to clarify\\nis, in tf cond it doesn\\\'t have, actually, any concept of\\nvariables in the higher level API. So this is things we\\ncapture and we take care of making sure they match. So from the user\\\'s\\npoint of view, they don\\\'t have to\\ndo anything special. SKYE WANDERMAN-MILNE: Right. That\\\'s, kind of, like the\\nwhile op very closely matches the TensorFlow semantics. But the if op is a\\nlittle bit different. They have to match [INAUDIBLE]\\ninputs at all, because we do it through closures and API. That\\\'s like, you do\\nit within your code. So if this is good\\nfor everyone, I\\\'m going to move on to\\ngoing over gradients. I\\\'m going over how gradients\\nwork in Control Flow v2. It is somewhat general. It\\\'s much simpler to think\\nabout with the functional ops. So let\\\'s start at a high level. Just conceptually, what\\nis the gradient of a cond? It\\\'s basically,\\njust another cond. And you take the same\\npredicate, and you take the gradient of both sides. So if we took the\\nforward true branch, then we want to take the\\ngradient of the true branch on the way back. Make sense? Hopefully, this is good. While loops, a little bit\\nmore complicated, not too bad. So say we have this\\nforward while loop, you have your cond\\nand body functions. Just assume it executes end\\ntimes for now, we just know. So now the gradient, we\\nhave to execute the gradient of the body function N times. Like we just have\\nto do the reverse. Imagine an unrolled loop, we\\ndid N invocations of the body. Now we\\\'re going to\\ndo N invocations of the gradient of the body. And you pass in the grad y\\\'s\\nor cotangents or whatever. And those are your\\nloop variables. Then your predicate,\\nnow, is just this counter to make\\nsure we execute N times. So, hopefully, this makes sense. The big question is, how\\ndo we know what N is? The answer is that, at\\nleast in Control Flow v2, we just add a little counter\\nto every a while loop. That just outputs the\\ntotal number of iterations. And we don\\\'t return\\nthis to the user, but we can wire it through to\\nthe gradient when we need it. Does this make sense\\nat a high level? We\\\'re going to dive\\ninto the details. But this is concept. OK. So I\\\'m about to go into\\nmore concrete examples. And I\\\'m also going to\\ndiscuss the tricky part about gradients, which\\nis intermediate values. Basically, when you\\nhave a data dependency from the forward pass\\nto the backwards pass. So start with cond. Here is a similar diagram. I rearranged it to\\nmake it fit nicer. But one important\\nthing to notice is that now the arrows\\nare actual tensors. They\\\'re not just type\\nsignatures anymore. So the predicate is a Boolean. In this example, there\\\'s only\\none input and one output, maybe they\\\'re different\\ntypes, who knows. Doesn\\\'t matter for this example. And then you have the\\ntrue and false functions with the same types. OK. So here\\\'s the gradient function. It\\\'s just another if. This time we\\\'re dealing\\nwith the cotangents instead of the initial forward values. And we have the gradient\\nof the true function and the gradient of\\nthe false function. Looks good so far. Hopefully. If there was no\\ndata dependencies between the forward and backward\\npass, like if you\\\'re doing y equals x plus 1,\\nthis is all you need. But what if somewhere in\\nthe forward pass, let\\\'s say the true function,\\nthere\\\'s an op? And we need to use its\\noutput in the backwards pass? So this is conceptually\\nwhat we need to do. We need z in the\\ngradient function. This is a problem,\\nbecause you can\\\'t just have an edge between two\\nfunction definitions. You need to have\\ninputs and outputs. Like, they need to go-- The If ops need to be attached\\nto each other with an edge. This doesn\\\'t make\\nsense by itself. So we\\\'re, basically,\\ngoing to do just that. We\\\'re going to make\\ninputs and outputs. We\\\'re going to add\\nthem to the if op. So let\\\'s do that. So we\\\'re going to output\\nz from true function. And then similarly,\\nadd it as an output from the if op, because the if\\nop is calling true function. And then we\\\'re going to add\\nit as an input to the gradient if op. And add it as an input to\\nthe gradient true function. OK, there\\\'s still\\none problem, though. And that\\\'s that now the true\\nand false branches of both if op don\\\'t match anymore. We need them to have\\nthe same signature. So let\\\'s just add some\\ninputs and outputs. Starting on the gradient\\nside, this is fine. We can just add z as an\\ninput to the false function. It\\\'s just going to ignore\\nit, it\\\'s an unused input. But on the forward\\npass, this is a problem. Because we need to add z as an\\noutput to the false function, but we don\\\'t actually\\nhave anything to output. It\\\'s like, what is\\nthis question mark op? And it needs to be the same\\ntype, and possibly shape, if we want to keep a strong\\nshape, or a fully known shape. And we might not know\\nthe shape until runtime. So what we do? I had to think about\\nthis for a long time and came up with many\\ndifferent solutions. And I partially\\nimplemented all of them before coming up\\nwith using Optionals. Optionals are maybe types. You\\\'ve heard of that? It\\\'s a special\\nkind of tensor that can hold another tensor\\ninside of it or not. So it\\\'s just a wrapper that may\\nor may not have another tensor inside of it. And it\\\'s also a tensor. It\\\'s like a variant tensor. So the true function is\\ngoing to return an Optional with the z value inside of it. The false function is\\ngoing to return an Optional with no value inside of it. OK, great. Now they\\\'re the\\nsame type, Optional. Could have the same\\nthing inside them. In a gradient true\\nfunction, we can unwrap that Optional\\nto get the raw z value. And then the false\\nfunction still just ignores it, which\\nis great, because there\\\'s nothing inside of it. I didn\\\'t know how to draw\\nthis, but that\\\'s what we do. So all the intermediate\\nvalues that are needed by the\\ngrading computation are added as Optional\\noutputs of the forward pass. Does this make\\nsense to everyone? That\\\'s it for cond gradients. SPEAKER 3: Conceptually, what\\\'s\\nthe difference between doing this and the dead tensor stuff? SKYE WANDERMAN-MILNE: Oh. Yeah. Great question. I meant to go over that,\\nso thank you for asking. At a high level,\\nthis is just how it works in Control Flow v1. The gradient if cond\\nis another cond. You can express that\\ninto low-level ops. But the dead tensors\\nare the big difference. So v1 was, kind of, using dead\\ntensors instead of Optionals. And you would just\\nhave that edge because there\\\'s no\\nfunctions [INAUDIBLE].. You could just draw\\nthat edge between the forward and backward pass. And if it\\\'s the\\nuntaken branch, you\\\'ll have a dead tensor\\nflowing across that edge. There\\\'s none of this\\nmatching business, you just draw the edge. SPEAKER 3: The interesting\\nthing with the Optional is that it tells you in the type\\nof it that it might be that. Where in the dead tensor you\\nhad no such information around. SKYE WANDERMAN-MILNE: Right. SPEAKER 3: So someone\\nlike [INAUDIBLE] doesn\\\'t have to spend as much\\ntime reverse engineering. [INAUDIBLE] exactly what it was\\nmeant to do complicated cases. So now what tensors\\nmight be dead or not? SPEAKER 3: So this\\nis, essentially, a much more explicit way\\nof making it clear what it be done versus what might now. SKYE WANDERMAN-MILNE: It\\\'s\\nkind of like, more complicated. Like, this was actually\\nsimpler in Control Flow v2, because you\\\'re just\\nlike, draw the edge, and the executor will take care\\nof all this dead tensor stuff. Yeah, it made the whole system\\nmore complicated as a whole to support that. OK, so let\\\'s move on\\nto while gradients. So again, we\\\'re dealing,\\nnow, with concrete tensors. So input x, output y. They have the same type but\\nthey are different values. The body function--\\nnote that I used xi because it\\\'s run multiple times. And each time it\\ntakes, it might be x or it might be an\\nintermediate value and outputs the updated\\nvalue of y of i. Then I drew the\\ncond function small. And I didn\\\'t draw as\\ninputs and outputs, because they don\\\'t really matter\\nthat much for the gradient, but they\\\'re there. It does have them. So same thing for the gradient. Very similar to the\\ncond case, now we\\\'re dealing with the cotangents. Hoping this makes sense. We took the gradient of the\\nbody and we\\\'re running N times. I forgot to draw N,\\ntoo, but it\\\'s there. Same scenario. Oh, no. What are we going to do? We can\\\'t just draw this edge\\nbetween the two function definitions. So this time, we don\\\'t have to\\nworry about the matching thing anymore. Thank goodness. We\\\'ll add the input\\nto the grad body function and the\\ngrad cond function, but that\\\'s fine because\\nwe can ignore inputs. But we have a new problem,\\nwhich is that there\\\'s actually multiple values of z. Because the body\\nfunction is going to execute multiple times,\\nthere\\\'s no guarantee that this op that\\noutputs z is going to output the same value\\non every iteration. So we actually have to\\noutput all the values of z from the forward\\npass, and we don\\\'t know how many that\\nwill be until we run it and take them as input\\nto the gradient function. So we use stacks,\\notherwise known as accumulators in\\nthe code sometimes. So we\\\'re going to\\nstart with an empty-- we use tensor lists, which are\\nkind of like tensor arrays, but not stateful. You can see in these\\nlittle function signatures, we\\\'re going to start\\nwith an empty tensor list that we pass through the while. And then in the\\nforward pass, we\\\'re going to push values onto\\nthat stack, or that list. And since it\\\'s stateless,\\nyou take the list in as input and the value\\nyou want to add to it and it, conceptually, returns\\nyou a new list that has that new element added to it. Under the hood it\\ndoesn\\\'t actually have to make all\\nthese copies, I hope. Similarly in the backwards. So then we\\\'re going to\\nkeep pushing values, outputting these new lists,\\nand keep pushing to them until we get the full list\\nwith all the values in it. That\\\'s output from\\nthe while loop. Actually, I have a\\npicture for this. So I guess the point is\\nthat, in the backwards pass you just pop,\\nopposite of push, to get the value out again. And so, this is a\\nlittle bit complicated. But you start with the\\nempty list as input, now these lists are\\nactually loop variables. So the stateless tensor list\\nworks quite nicely with this, because the loop\\nvariable is going to have whatever has accumulated\\nso far as input to the body function. And it adds the\\nnew z and outputs that as the updated version. And so the final\\nlist is going to be the full list, which you pass\\ninto the gradient function. It\\\'s going to do the same\\nthing, except popping to pass, to get that raw value of z. And then finally, the list\\nshould be empty at the end. And then, since it\\\'s\\na loop variable, we end up outputting\\nan empty list, but we don\\\'t actually\\nneed that output. That\\\'s just how it works. SPEAKER 2: I have a question. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 2: Are you saying\\nthe gradient values always [INAUDIBLE]? SKYE WANDERMAN-MILNE: It\\\'s only\\nwhen you when you need them. SPEAKER 2: It\\\'s just\\nalways [INAUDIBLE].. OK. Thank you. SKYE WANDERMAN-MILNE: Yeah. That\\\'s a good question. SPEAKER 4: Now you\\ncould [INAUDIBLE] in the normal TensorFlow\\ngraph probably is able to remove them. SKYE WANDERMAN-MILNE:\\nYeah, that\\\'s the way it actually used to do. Although, that\\\'s a little\\nweird through functions so we changed it. SPEAKER 3: Another question. Does this imply that\\nin your while loop, your memory consumption\\nis, basically, linear in the number of\\nvariations you go through? SKYE WANDERMAN-MILNE: Yeah, if\\nyou have a gradient like this. That\\\'s some future work. I would love to see\\ndoing re-materialization, or check-pointing, I think\\nit\\\'s called in the literature. But we don\\\'t do that. SPEAKER 2: Can explain\\nagain, in the if, why can\\\'t you draw a line\\njust from the original-- SKYE WANDERMAN-MILNE: Oh, yeah. The blue boxes are\\nfunction definition. And then the while op is\\ngoing to call that function many times. So it\\\'s sort of like, if you\\\'re\\nwriting two functions in Python and they\\\'re not\\nnested or anything, they\\\'re just side by side. You can\\\'t take an intermediate\\nvariable from one function and use it in another one. It\\\'s going to be like, I\\ndon\\\'t know what this is. You have to output\\nit then have it as input to the other function. Or at least in TensorFlow we\\ndon\\\'t have closures or anything fancy like that. So that\\\'s how we do it. Does that make sense? SPEAKER 2: Kind of. SPEAKER 3: The value for\\na particular execution of a function of particular\\nintermediate value of a particular\\nfunction execution doesn\\\'t have a name that\\ncan be addressed in order-- And if it had a name,\\nit would greatly complicate the lifetime issues. We wouldn\\\'t be\\nable to [INAUDIBLE] intermediate\\n[INAUDIBLE] functions. SKYE WANDERMAN-MILNE:\\nOr maybe another way is that these\\nfunction definitions aren\\\'t actually in the graph. I draw them as if they are,\\nbut they\\\'re off to the side. All you see are the while ops. And then when you call the\\nfunction, then you see that. But you only see\\nit for that call. So it\\\'s like this z op in\\nhere doesn\\\'t exist out here in the main graph where this\\ngradient while op can see it, or in this other\\nfunction definition. Oh, and to compare to\\nControl Flow v1 again, same general idea. These while ops could be the\\nwhole mess of low-level ops and, due to some true while\\nloops, represent it that way. The big difference, this\\ntime, is in the stacks. They use the old resource\\nback tensor arrays, which were stateful. SPEAKER 4: We actually use the\\nresource [INAUDIBLE] stack. SKYE WANDERMAN-MILNE:\\nOh, you\\\'re right. You\\\'re right. SPEAKER 4: Separate nests. SKYE WANDERMAN-MILNE: OK, yeah. But they were\\nstateful, is the point. So they were\\nactually just inputs. They weren\\\'t outputs. And you just modify that state. One big disadvantage of\\nthis was that you couldn\\\'t take higher-order derivatives\\nbecause you would exhaust the stack once,\\nand it\\\'s stateful and you can\\\'t get\\nit back anymore. Whereas these, it\\\'s\\nthis full list. Because it\\\'s a\\nstateless thing, I can pass it to another\\nwhile op, no problem. So coming back to\\nControl Flow v2. Let\\\'s recap what\\\'s\\ngood and bad about it. So now we can take\\nhigher-order derivatives because it\\\'s very simple. The gradient code, when\\nit\\\'s looking at an if op, it doesn\\\'t know if\\nthat if op was actually the first derivative\\nof some other if op. They\\\'re are all the same. Inputs and outputs\\njust are normal. It\\\'s much easier to\\nconvert to the XLA if and while ops and\\ndownstream TPU integration. Graph construction\\nlogic, I hope is simpler. Take a look for yourself. So besides being\\neasier to maintain, this lets us give\\nbetter error messages, and hopefully there\\\'ll\\nbe fewer bugs. OK. So now assuming that we\\njust run the functional ops, even though I said\\nwe don\\\'t, assume we do. The execution could\\nbe much simpler, because we don\\\'t\\nhave dead tensors or because we use Optionals now. And we don\\\'t have frames because\\nit\\\'s managed by the while op. But the disadvantage\\nof running these ops is that they aren\\\'t as\\nperformant for a number of reasons listed there. So we could fix this\\nwith the functional ops. And it would make sense to do\\nthis because a lot of these also apply to just regular\\nfunction calls, which are kind of a big deal now. But for now, we decided to\\njust take the functional op. So right before you run it--\\nso you\\\'ve already constructed the graph, you\\\'re\\nready to run it-- we\\\'re going to convert it\\nback into the old low-level representation. So now we get rid\\nof the disadvantages because we\\\'re, hopefully,\\njust running the same thing. But we also don\\\'t get our\\nsimpler execution because we\\\'re still running the old thing. So we call this\\nlowering, because they\\\'re sort of lowering to this\\nmore low-level form. This was, basically,\\na staging trick so that we can do all the\\ngraph construction stuff, which is taking quite some time,\\nwithout having to worry about the execution as much. Because there were\\nstill some issues. It\\\'s very similar to\\nfunction in-lining. An if op and a while op are kind\\nof very fancy function calls. And so this is how\\nyou in-line them, with these low-level\\nlevel dataflow operators. And so it runs with in-lining\\nbefore anything else happens, and this is so we\\ncan take advantage of any downstream optimization\\nor placement or whatever. In the case of\\nControl Flow, we want it to work the same as it did\\nbefore in Control Flow v1. And I think Eugene is\\nfixing this all up, so this is actually true now. As of, like, last week. SPEAKER 5: So this converting\\nwill be removed eventually? SKYE WANDERMAN-MILNE: I\\nwould love to see it removed. Oh, yeah. So right now we\\nin-line everything, including function calls,\\nbecause similar story for functions, it makes\\na lot of things easier. I hope that we don\\\'t\\ndepend on this forever. That we sort of\\ndo try to make it so function calls are just\\nas performant and as good not in-line. Because it\\\'s the same\\nfor Control Flow. If we always assume\\neverything\\\'s in-line, then we\\\'re never going\\nto be able to get our simpler execution and\\njust run the functional ops. Because they\\\'re very, very\\nsimilar function calls, they have the same problems. So if you fix it\\nfor functions it\\\'s not a huge step to, then,\\nfix it for Control Flow. Where are we at with\\nControl Flow v2? It\\\'s still under development. There\\\'s bugs and features\\nthat need to be implemented. But it\\\'s basically on in tf 2.0,\\nif you\\\'re using pure 2.0 code. So remember Eager, doing his\\nown thing, just use Python. And then, Control Flow v2 is\\nalways on in tf dot functions. There\\\'s no way to\\nget old Control Flow. If you want to run new Control\\nFlow in either 1.x code or you\\\'re using a\\ncompact dot v1 dot graph, those still use the\\nold Control Flow, you can use this environment\\nvariable to turn it on. So now when people ping\\nme in and are like, I have this horrible\\nControl Flow bug. I\\\'m like, try the\\nenvironment variable. And sometimes it fixes it. Or sometimes it at least\\ngives an easier to debug error message. Unfortunately, I\\nwould love to have realized the glorious future,\\nwhere it\\\'s all new Control Flow. Old Control Flow doesn\\\'t exist. We can delete that code. I don\\\'t know if it makes\\nsense to do the work to make it so we can\\nturn it on in 1.x code because there\\\'s a\\nfew big blockers. Namely, functions don\\\'t\\nwork with ref variables. And so by extension,\\nthese functional ops don\\\'t work with ref variables. That would be a lot\\nof work to implement. And the question that you asked\\nabout how we add the gradient outputs when you\\nrequest a gradient, only when they\\\'re needed,\\nwhich it will only know after you build\\nthe gradient graph and see what incoming\\nedges you have. This actually breaks sessions. Sessions do not like it when you\\nadd inputs and outputs to ops. And will potentially make\\nyour session unusable. You\\\'ll have to\\nmake a new session. So in 2.0 we don\\\'t\\nhave sessions, great. But in 1.x we definitely\\nhave sessions. Another little note. In addition to Control\\nFlow V2, there\\\'s a new effort to\\nre-implement tensor arrays. And I sort of hinted\\nat this by incorrectly stating the old tensor array as\\nstacks but it\\\'s the same idea. Tensor arrays were these\\nresource back stateful things. Now we\\\'re going to\\nmake tensor arrays. It\\\'s still the same\\nAPI, so nothing should change for the\\nuser, but under the hood, we\\\'re going to use immutable\\ntensor lists, which are variants instead of resources. And so you get\\nhigher-order derivatives, it\\\'s easier to reason\\nabout something that\\\'s dataflow style instead\\nof stateful in our dataflow graphs. It\\\'s nicer. And then in particular, an\\narea of active development is that we do need to make these\\nnew tensor arrays work in XLA. So this is kind of annoying,\\nbecause we\\\'ve kept saying, oh, the new Control\\nFlow [INAUDIBLE],, it\\\'s going to make XLA so easy. It\\\'s just going to work. But we do have to\\nimplement this one thing. [? Sarab\\\'s ?] working on this. I think it\\\'s almost there. We\\\'ll see. SPEAKER 4: Getting there. Question. So is it true that\\nTensorFlow [INAUDIBLE] where you only use\\nthe [INAUDIBLE]?? SKYE WANDERMAN-MILNE: Yes. Yeah, so it\\\'s\\nmaybe theoretically different from Control Flow,\\nbecause it\\\'s tensor arrays. But tensor arrays are so\\ntightly linked to Control Flow. And we only support\\nthe new tensor arrays in new Control Flow\\nbecause we don\\\'t want to deal with\\nthe stateful thing. SPEAKER 2: You don\\\'t know\\nwhat tensor array is. Usually when you do\\nControl Flow and it models, you have something like an\\nRNN, that computes something for [INAUDIBLE]. And you often want to\\ntake a single tensor that represents the results of\\nall time steps together. And tensor array is\\nthe data structure that lets you do that. SKYE WANDERMAN-MILNE: Yeah. I don\\\'t think there\\\'s too\\nmuch use for tensor array outside of while loops,\\nI\\\'m sure I would stand corrected if I looked into it. So these are some details\\non what\\\'s going on here. That\\\'s all I have. I\\\'m going to end on\\nthis slide so you can look at the beautiful picture. And I guess we have plenty\\nof time for questions. So what was your Control\\nFlow v1 question? SPEAKER 3: How does it work\\nwith the branches [INAUDIBLE]?? SKYE WANDERMAN-MILNE:\\nOh, good question. So this is when you\\nhave a tf dot cond, remember just takes lambdas and\\ncaptures everything by closure. So you could just not\\nclose over anything. Like, return one or two. SPEAKER 1: Or like, it\\\'s a\\nsourceless op like [INAUDIBLE].. SKYE WANDERMAN-MILNE: Yeah. It uses the predicate. It wires together all the\\ndataflow using the predicate. And in particular,\\nyou can also have a cond that doesn\\\'t\\nreturn anything, it just has side effects. And I think in\\nControl Flow v1, it will return to predicate value. I thinl it does that\\nin Control Flow v2 because I wanted to test\\nthe pass in both cases. But it\\\'s a little arbitrary. SPEAKER 4: So the\\nway to do this is you have ops that have a control\\ndependency on something that depends on the Switch. Because [INAUDIBLE] propagates\\nthrough [INAUDIBLE] as well. So this is how it\\\'s actually\\nimplemented in Control Flow v1. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 1: Well, it can\\\'t\\ndepend on the Switch. It has to depend\\non like one output. SPEAKER 4: Yeah. So you have a Switch\\nof the predicate. And on each side\\nof that [INAUDIBLE] that takes the predicate twice. Then you have an identity\\nop on each branch. And every op that\\\'s inside\\none of the Switch branches has a control dependency on\\nthat corresponding identity. So because, then, this\\npropagates through control edges, it makes things work. SPEAKER 1: That makes sense. SKYE WANDERMAN-MILNE: That\\\'s a\\npart of why we were able to do [INAUDIBLE]. There\\\'s a lot of storage. Yeah? SPEAKER 2: So when you\\ndescribed the graph modification for taking gradients of if, when\\ndoes this modification happen? Does it happen when\\nyou construct the if op or when you\\\'re taking gradients? SKYE WANDERMAN-MILNE:\\nGreat question. It happens when you\\ntake the gradient. SPEAKER 2: The gradient. So for those-- SPEAKER 3: Does that depend\\non whether you\\\'re using tape gradients or tf dot gradients? SKYE WANDERMAN-MILNE: No. SPEAKER 2: We could\\n[INAUDIBLE] early if you\\\'re doing tape gradients. We currently do not. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 4: So that means for\\nthose function arguments, or functional attributes, you\\ncannot draw lines between two, but you can modify one. SKYE WANDERMAN-MILNE:\\nYeah, you can modify them to add\\ninputs and outputs, which you\\\'re not really supposed\\nto do with sessions. But we do it. The reason we do it when you\\nrequest a gradient is that, a, if you never take\\nthe gradient we don\\\'t want to add extra stuff,\\nalthough it could get pruned. SPEAKER 4: You want\\nto look [INAUDIBLE].. SKYE WANDERMAN-MILNE: It makes\\nyour graph look nice at least, to not have all\\nthe extra outputs. And also, you don\\\'t\\nknow which intermediates you\\\'re going to need until\\nyou build the gradient graph. So if we did it\\nwith the tape, we could say, oh,\\npresumably because you\\\'re running with a\\ntape, you are going to want to take the\\ngradient at some point. SPEAKER 4: We can\\nactually ask the tape if the tape is\\ngoing to integrate into one of those outputs. We can\\\'t answer their questions. SKYE WANDERMAN-MILNE: So\\nthen we could proactively create the gradient\\nat the same time as you create the forward pass\\nand add the outputs there, all at once. But since we have\\nthe two code pass, we just do it the same\\nin a two code pass. Because with tf\\ndoc gradients, you have no idea if\\nyou\\\'re gonna call it or not until it happens. That\\\'s a good question. Functions work the same\\nway too, because they have like a similar-- if you just have\\na function call, you\\\'ll have the same\\nthing with intermediates and you\\\'ll have to add\\ninputs and outputs. So we\\\'re back in\\nControl Flow v1, right? This is what it looks\\nlike, this stuff. What if you want to run your\\nbranch functions or your body or whatever on multiple devices? So I don\\\'t totally\\nunderstand this myself. It\\\'s going to be brief. Cond, it\\\'s pretty simple. You just do it like\\nnormal, I guess. You add the sends and\\nreceives, dead tensors can flow through these. So this is why you\\nneed the dead tensors. Because for the untaken\\nbranch, you basically need to tell other\\ndevice, this isn\\\'t taken. Stop waiting for inputs on this. So you can shut\\ndown or whatever. SPEAKER 4: Another,\\nwe could have chosen to send the predicate instead. But was a simple modification\\nof the existing TensorFlow that had a huge cost. If I had chosen to\\nsend the predicate, we wouldn\\\'t need so much of\\nthat tensor propagation and all the bugs associated with it. SKYE WANDERMAN-MILNE: Dead\\ntensors are kind of crazy. In really big graphs, you will\\nspend time just propagating all the dead tensors, and\\nsend data across the network, or whatever. It\\\'s one of those things. We added all this\\nstuff and now this is very conceptually simple. You just add the\\nsend and receive. It just works. Can we do the same\\nthing for while loops? Just add the sends and receives. This time it\\\'s going\\nto be in a loop. Seems fine. It\\\'s not fine. The problem is that\\nthis device doesn\\\'t know that this op is supposed\\nto be run multiple times. I guess we didn\\\'t forward\\nthe frame information. SPEAKER 3: It doesn\\\'t know\\nhow many times it should run. SKYE WANDERMAN-MILNE:\\nWell, it\\\'s going to run once or like 0\\ntimes, then you\\\'ll have-- or maybe the dead\\ntensor will work. But if you run it\\nonce, it\\\'s just going to immediately shut down\\nbecause it thinks that it has to run once, like a regular op. So the solution, you, basically,\\nbuild a tiny little while loop on the other device. And so you can see\\nthere\\\'s no real data going through this computation. But it\\\'s just used through\\ncarefully placed control dependencies to drive this\\nop as many times as you need. So this is like a whole\\nlittle while loop built just to run this op n times. This while loop is indirectly\\ndriven by the real one. SPEAKER 3: It\\\'s driven\\nby the predicate. SKYE WANDERMAN-MILNE: Yeah. Right, exactly. You can see that this guy\\ndoes not have a predicate. SPEAKER 4: So we\\\'re essentially\\nsending the predicate around for the while loop case but\\nnot doing it for the cond case. SKYE WANDERMAN-MILNE: And we\\nbuild a little tiny while loop to actually use that predicate. SPEAKER 4: And essentially, if\\nwe wanted to partition into two ops, we would have\\nto build something like this for both the\\ncond and [INAUDIBLE].. Or it would at least\\nlook simpler, I think. SPEAKER 1: Well, the control\\ncould be centralized. SPEAKER 4: Well, you\\ncould send the predicate to other places, yes. SPEAKER 1: [INAUDIBLE]\\nexecution, yeah. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 4: You would need a\\nwhile loop [INAUDIBLE] device, but the predicate computation\\nonly needs to happen once. SKYE WANDERMAN-MILNE: Do we? Because we have\\nmulti-device functions, you could just call that\\nmultiple times, right? SPEAKER 4: Yeah. I mean, sure. SKYE WANDERMAN-MILNE: You won\\\'t\\nget like parallel iterations and everything. So that\\\'s distribution. SPEAKER 6: I\\\'m glad\\nyou speak clear. SPEAKER 3: How did the\\nintermediate value sharing work with distribution [INAUDIBLE]? SPEAKER 1: It\\nworks the same way, except there\\\'s a\\nlot more arrows. [LAUGHTER] Conceptually, they do not\\ninterfere with [INAUDIBLE].. But you end up with the diagram\\nto show both at the same time would be overwhelming. SKYE WANDERMAN-MILNE: Yeah,\\nthat\\\'s a good point, though. I feel like it\\\'s not\\nimmediately obvious that it works with all\\nthe dead tensors and stuff between the forward\\nand backwards pass. Because now you\\\'re like\\nmixing [INAUDIBLE].. But it does somehow work. SPEAKER 4: You need to\\nthink of the intermediates as happening before you\\ndo the partitioning, and then you can see\\nwhat should happen. SKYE WANDERMAN-MILNE: I\\\'ll\\ngo back to my pretty picture. Well, thanks, everyone. SPEAKER 6: Thank you. [APPLAUSE]\', metadata={\'source\': \'IzKXEbpT9Lg\'})]""""""']","{'https://stackoverflow.com/questions/53079436/tensorflow-tf-cond-giving-unexpected-output', 'https://stackoverflow.com/questions/37063952/confused-by-the-behavior-of-tf-cond',  'https://stackoverflow.com/questions/68444180/tf-case-and-tf-cond-executes-all-the-functions-within-in-tensorflow'}","['""""""`tf.case` and `tf.cond` executes all the functions within in TensorFlow\n\nI\'m trying to execute some condition-dependent functions where each function needs to contract tensors differently depending on their shapes, for instance. However, I realised that tf.cond and tf.case is executing all functions regardless of the condition. Prepared the following code as an example;\n\ndef a(): print(""a"") return tf.constant(2) def b(): print(""b"") return tf.constant(3) def c(): print(""c"") return tf.constant(4) def d(): print(""default"") return tf.constant(1) x = tf.constant(1) @tf.function def f(): return tf.case([ (tf.equal(x,1), a), (tf.equal(x,2), b), (tf.equal(x,2), c) ], default=d, exclusive=True) @tf.function def f1(): def cond3(): return tf.cond(tf.equal(x,2), c, d) def cond2(): return tf.cond(tf.equal(x,2), b, cond3) return tf.cond(tf.equal(x,1), a, cond2) print(f()) print(f1()) # Output: # a # b # c # default # tf.Tensor(2, shape=(), dtype=int32) # a # b # c # default # tf.Tensor(2, shape=(), dtype=int32)\n\nas you can see for both of the cases, the result is as expected but each function is executed while reaching the conclusion. Hence in my particular case, since I\'m doing different calculations depending on the tensor\'s shape, I get a multitude of errors. I\'ve seen many such bug reports but haven\'t found a solution. Is there another way to do conditional execution that I\'m not aware of where different functions can be executed depending on the condition? Note that I tried simply using if tf.equal(x,2): ... but in that case, I\'m getting an error saying that tensor output can not be used as python boolean. Note that this example is much-simplified version of my problem, my conditions are based on tensor shapes such as tf.equal(tf.size(tensor), N) so I really need a way to execute different things for different cases. After @LaplaceRicky \'s answer I realised that the code that I provided was not representative enough so I\'m providing a better example showing what I need to do;\n\nx = tf.ones((3,2,1)) y = tf.ones((1,2,3)) z = tf.ones((4,3,5)) k = tf.ones((3,5,5)) def a(t): def exe(): return tf.einsum(""ijk,lmi"", t, y) return exe def b(t): def exe(): return tf.einsum(""ijk,ljm"", t, z) return exe def d(t): def exe(): return tf.einsum(""ijk,klm"", t, z) return exe c = tf.constant(1) @tf.function def f(t): y = tf.case([ (tf.equal(tf.shape(t)[0], 3), a(t)), (tf.equal(tf.shape(t)[1], 3), b(t)), ], default=d, exclusive=True) return y print(f(x))\n\nThis function will execute properly without tf.function decorator leading to\n\ntf.Tensor( [[[[3. 3.]]] [[[3. 3.]]]], shape=(2, 1, 1, 2), dtype=float32\n\nHowever, when the decorator is included I got a ValueError which shows that all the cases are executed. TensorFlow version: 2.4.1\n\nPython version: 3.8.2\n\nShort answer: use tf.print instead of print to check whether a particular branch is really being executed in tensorflow graph mode. Explanations: print does not work and won\'t print in graph mode but it will print during tracing. The printed messages actually implies all of the branches were added to the tensorflow graph but it does not imply all branches will be executed all the time in graph mode. tf.print should be used instead for the debugging. For more information: https://www.tensorflow.org/guide/function#conditionals\n\ndef a(): tf.print(\'a\') return tf.constant(10) def b(): tf.print(\'b\') return tf.constant(11) def c(): tf.print(\'c\') return tf.constant(12) @tf.function def cond_fn(x): return tf.switch_case(x, {0:a,1:b}, default=c) print(cond_fn(tf.constant(0))) print(cond_fn(tf.constant(1))) print(cond_fn(tf.constant(2)))\n\na tf.Tensor(10, shape=(), dtype=int32) b tf.Tensor(11, shape=(), dtype=int32) c tf.Tensor(12, shape=(), dtype=int32)\n\nThe ValueError error message is because tensorflow graph does not support this kind of feature very well, at least not with tf.einsum. One way of the workarounds is to have a graph that supports variable-shaped inputs by using tf.function(f).get_concrete_function(tf.TensorSpec(shape=[None,None,None])). Besides, tf.einsum is problematic in the process and have to be replaced by tf.transpose and tf.tensordot. x = tf.random.normal((3,2,1)) y = tf.random.normal((1,2,3)) z = tf.random.normal((4,3,5)) k = tf.random.normal((3,5,5)) #for checking the values def f2(t): p = tf.case([ (tf.equal(tf.shape(t)[0], 3), lambda:tf.einsum(""ijk,lmi"", t, y)), (tf.equal(tf.shape(t)[1], 3), lambda:tf.einsum(""ijk,ljm"", t, z)), ], default=lambda:tf.einsum(""ijk,klm"", t, k), exclusive=True) return p #work around def f(t): if tf.shape(t)[0] == 3: tf.print(\'branch a executed\') return tf.tensordot(tf.transpose(t,[1,2,0]), tf.transpose(y,[2,0,1]),1) elif tf.shape(t)[1] == 3: tf.print(\'branch b executed\') return tf.tensordot(tf.transpose(t,[0,2,1]), tf.transpose(z,[1,0,2]),1) else: tf.print(\'branch c executed\') return tf.tensordot(t, k,1) graph_f=tf.function(f).get_concrete_function(tf.TensorSpec(shape=[None,None,None])) print(np.allclose(graph_f(x),f2(x))) print(np.allclose(graph_f(y),f2(y))) print(np.allclose(graph_f(z),f2(z)))\n\nbranch a executed True branch c executed True branch b executed True\n\nSorry, you are correct I didn\'t provide a proper example, thanks for your answer. I updated the code that I provided which I believe exemplifies my situation better.""""""', '""""""Confused by the behavior of `tf.cond`\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""tensorflow Tf.cond giving unexpected output\n\nI seem to be having a misunderstanding on how tf.cond works. In the tensorflow documentation, it gives the following example:\n\nz = tf.multiply(a, b) result = tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))\n\nThe result of the example, if x<y is True is tf.add(x,z) else tf.square(y)\n\nFollowing this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation. in my example, deterministic_action = 4, random_action = 11, chose_random=False.""""""', '""""""And how to solve this problem? TL;DR: If you want tf.cond() to perform a side effect (like an assignment) in one of the branches, you must create the op that performs the side effect inside the function that you pass to tf.cond(). The behavior of tf.cond() is a little unintuitive. Because execution in a TensorFlow graph flows forward through the graph, all operations that you refer to in either branch must execute before the conditional is evaluated. This means that both the true and the false branches receive a control dependency on the tf.assign() op, and so y always gets set to 2, even if pred is False. The solution is to create the tf.assign() op inside the function that defines the true branch. For example, you could structure your code as follows:\n\npred = tf.placeholder(tf.bool, shape=[]) x = tf.Variable([1]) def update_x_2(): with tf.control_dependencies([tf.assign(x, [2])]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval(feed_dict={pred: False})) # ==> [1] print(y.eval(feed_dict={pred: True})) # ==> [2]\n\n\n\n 4\n\nYeah, that\'s the one that confuses me also. My understand is that before executing tf.cond, the runtime makes sure all the dependencies are executed. Dependencies of ops in True and False branches are also dependencies of cond, so even though an op in a branch may never be executed, all of it\'s dependencies are executed, does that that sound right? – Yep - the graph pruning considers all potential dependencies (of either branch) for execution, and only inhibits their execution if they were defined inside one of the branches, because the CondContext adds a control dependency on the pivot and that dependency will be a dead tensor (preventing the op from executing) if it is in the branch not taken. What was the reasoning doing it this way? Why not prune the subgraph behind the non-active branch? – The pruning happens before the value for pred has been computed. This enables TensorFlow to cache a single pruned graph based on a simple key (essentially the arguments to Session.run()), and makes the implementation of conditional execution simple and lightweight. The same mechanism is used to implement tf.while_loop(), where the advantages of performing the control flow at this level are more evident. pred = tf.constant(False) x = tf.Variable([1]) def update_x_2(): assign_x_2 = tf.assign(x, [2]) with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nThis will get the result of [1]. """"""', '""""""Where did the value 1 come from? #!/usr/bin/env python3 import tensorflow as tf import numpy as np with tf.Graph().as_default(): with tf.device(\'/cpu:0\'): stochastic_ph = tf.placeholder(tf.bool, (), name=""stochastic"") eps = tf.get_variable(""eps"", (), initializer=tf.constant_initializer(0)) with tf.variable_scope(\'test_cond\') as sc: deterministic_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=0) # 4 random_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=1) # 11 chose_random = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32) < eps # False because eps = 0 stochastic_action = tf.cond(chose_random, lambda: random_action, lambda: deterministic_action) # S_action should be 4 but it is 1 #output_action = tf.cond(stochastic_ph, lambda: stochastic_action, lambda: deterministic_action) init = tf.global_variables_initializer() sess = tf.Session() sess.run(init, feed_dict={stochastic_ph: True}) print (""s_ph = "", stochastic_ph) d_action = sess.run(deterministic_action) print (""det_action= "", d_action) r_action = sess.run(random_action) print (""rand_action= "", r_action) e = sess.run(eps) c_action = sess.run(chose_random) print (""chose_rand= "", c_action) s_action = sess.run(stochastic_action) print (""s_action= "", s_action) #output = sess.run(output_action)\n\npython random_vec.py 2018-10-31 09:46:15.028376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA s_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 rand_action= 11 chose_rand= False s_action= 1\n\n\n\nThis is because you are evaluating again in a new sess.run. Since you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1. Here is the result of your code, when I extract the value of deterministic_action as well in the last step. print (""s_ph = "", stochastic_ph) d_action = sess.run(deterministic_action) print (""det_action= "", d_action) r_action = sess.run(random_action) print (""rand_action= "", r_action) e = sess.run(eps) c_action = sess.run(chose_random) print (""chose_rand= "", c_action) s_action, d_action = sess.run([stochastic_action, deterministic_action]) print (""s_action= "", s_action) print (""det_action= "", d_action)\n\ns_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 rand_action= 11 chose_rand= False s_action= 1 det_action= 1\n\nNow all you need to do is run everything in one sess.run\n\nd_action, r_action, e, c_action, s_action = sess.run([deterministic_action, random_action, eps, chose_random, stochastic_action]) print (""det_action= "", d_action) print (""rand_action= "", r_action) print (""chose_rand= "", c_action) print (""s_action= "", s_action)\n\ns_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 rand_action= 11 chose_rand= False s_action= 4\n\nI was not clear on why the random_uniform generates different values when seed is set. This is because the code is running with the same session object that it initialized the variables with. Modifying the code with a new session object, this is what happens:\n\nprint (""s_ph = "", stochastic_ph) d_action = sess.run(deterministic_action) print (""det_action= "", d_action) sess.close() sess = tf.Session() sess.run(init, feed_dict={stochastic_ph: True}) s_action = sess.run(stochastic_action) print (""s_action= "", s_action)\n\ns_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 s_action= 4\n\n 4\n\nThe seed is fixed. So, irrespective of the session you run in, the random value should always be the same. @tandem the sequence of numbers you get would be the same, but not the value every time. If you notice my first result, where I\'m just reading out the value of deterministic_action along with stochastic_action that you are getting in your last step. Your deterministic_action is 1, which means your result is also 1. When I put all the evaluations together in a single session run, your deterministic_action is 4, and hence your result is also 4. Seed should always give the same random number. as long as it is set. That explanation doesnt still make sense\n\n\n\n@tandem tensorflow computation graphs depend on your initialization. In the above example, you are still using the session object that is initialized at the beginning. This means tensorflow is keeping a track of the state of its variables in the session object, and thus does not reinitialize the random_uniform. Close the session object with sess.close() and then open a new session object and run your stochastic_action variable, it will produce the result 4 as expected. """"""']","### Explanation of Unexpected Output in `tf.cond`

The user is experiencing unexpected behavior when using `tf.cond` in TensorFlow. Specifically, the `stochastic_action` should be `4` but is instead `1`. This discrepancy arises from the way TensorFlow handles random number generation and session runs.

In TensorFlow, the `tf.cond` function is used to return the result of `true_fn` if the predicate `pred` is true, otherwise it returns the result of `false_fn`. However, it is important to note that any Tensors or Operations created outside of `true_fn` and `false_fn` will be executed regardless of which branch is selected at runtime. This behavior is consistent with TensorFlow's dataflow model but can be surprising to users expecting lazier semantics.

In the provided example, `deterministic_action` and `random_action` are both generated using `tf.random_uniform` with fixed seeds. The `chose_random` tensor is determined to be `False` because `eps` is initialized to `0`. Therefore, `stochastic_action` should be equal to `deterministic_action`.

The unexpected output (`s_action=1` instead of `4`) occurs because the random number generation is evaluated again in a new `sess.run` call. Each call to `sess.run` generates a new random number, which is why `deterministic_action` changes from `4` to `1` in subsequent evaluations. This behavior is due to the stateful nature of random number generation in TensorFlow, where the sequence of random numbers is maintained across session runs.

To ensure consistent results, all evaluations should be performed within a single `sess.run` call. This way, the state of the random number generator is preserved, and the expected values are produced.

In summary, the issue arises from the separate evaluations of `deterministic_action` and `stochastic_action` in different `sess.run` calls, leading to different random values being generated. To avoid this, combine all evaluations into a single `sess.run` call to maintain the state of the random number generator and achieve consistent results."
61305781,tf.feature_column.categorical_column_with_vocabulary_list,example required,Using Tensorflow embedded columns raises All feature_columns must be _FeatureColumn instances error,"<p>I am new to tensorflow and I was trying to follow the official documentation where I came across 
tf.feature_column.categorical_column_with_vocabulary_list</p>

<p>The code I tested is: </p>

<pre><code>key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), default_value=0)
columns = [[tfc.embedding_column(colors, 3)], ...]
features = tf.io.parse_example(..., features=tfc.make_parse_example_spec(columns))
dense_tensor = tfc.input_layer(features, columns)
</code></pre>

<p>However , when I run this sample code I get the following error : 
 ValueError: All feature_columns must be _FeatureColumn instances. Given: [EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), dtype=tf.string, default_value=0, num_oov_buckets=0), dimension=3, combiner='mean', initializer=, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]</p>

<p>What I am doing wrong?  </p>
","<p><code>make_parse_example_spec</code> expects <code>FeatureColumn instances</code>. You can create the FeatureColumn instance using the below method for the category list.</p>

<pre><code>colors = feature_column.categorical_column_with_vocabulary_list(key='colors',vocabulary_lis=('R', 'G', 'B', 'Y'),num_oov_buckets=2)
my_feature_columns = [feature_column.indicator_column(colors)]
feature_column.make_parse_example_spec(my_feature_columns)
</code></pre>

<p>Output :</p>

<pre><code>{'colors': VarLenFeature(dtype=tf.string)}  
</code></pre>

<p>If you want to create a dense embedding tensor on your categorical column, you can follow the below example.  </p>

<pre><code>data = {'colors': ['X', 'R', 'G', 'B', 'Y']}

df = pd.DataFrame(data)

colors = feature_column.categorical_column_with_vocabulary_list('colors', df['colors'].unique())

colors_embedding = feature_column.embedding_column(colors, dimension=4)

dense_tensor = tf.keras.layers.DenseFeatures(colors_embedding)(data)
</code></pre>

<p>Result: </p>

<pre><code>tf.Tensor(
[[ 0.17071894  0.29407692 -0.26661882  0.07768019]
 [ 0.26196313  0.14372464 -0.41102907 -0.7207164 ]
 [-0.7888006  -0.07049363 -0.49007863  0.45744416]
 [ 0.56329435 -0.7051675   0.04742934 -0.69377   ]
 [-0.52031726  0.488502   -0.37031132 -0.44338205]], shape=(5, 4), dtype=float32)
</code></pre>
",<code>make_parse_example_spec</code> expects <code>FeatureColumn instances</code>. You can create the FeatureColumn instance using the below method for the category list.,"<pre><code>data = {'colors': ['X', 'R', 'G', 'B', 'Y']}

df = pd.DataFrame(data)

colors = feature_column.categorical_column_with_vocabulary_list('colors', df['colors'].unique())

colors_embedding = feature_column.embedding_column(colors, dimension=4)

dense_tensor = tf.keras.layers.DenseFeatures(colors_embedding)(data)
</code></pre>

<p>Result: </p>

<pre><code>tf.Tensor(
[[ 0.17071894  0.29407692 -0.26661882  0.07768019]
 [ 0.26196313  0.14372464 -0.41102907 -0.7207164 ]
 [-0.7888006  -0.07049363 -0.49007863  0.45744416]
 [ 0.56329435 -0.7051675   0.04742934 -0.69377   ]
 [-0.52031726  0.488502   -0.37031132 -0.44338205]], shape=(5, 4), dtype=float32)
</code></pre>","['How to use tf.feature_column.categorical_column_with_vocabulary_list in TensorFlow?', 'Common errors with tf.feature_column.categorical_column_with_vocabulary_list and how to fix them', 'How to create and use embedding columns in TensorFlow?', 'Understanding tfc.embedding_column and its parameters', 'How to use tf.io.parse_example and tfc.make_parse_example_spec in TensorFlow?', 'How to use tfc.input_layer with feature columns in TensorFlow?', ""Troubleshooting 'All feature_columns must be _FeatureColumn instances' error in TensorFlow""]","['How to use tf.feature_column.categorical_column_with_vocabulary_list in TensorFlow?', 'What are the common errors when using tf.feature_column.categorical_column_with_vocabulary_list?', 'How to correctly define feature columns in TensorFlow?', 'What is the correct way to use tfc.embedding_column with tf.feature_column.categorical_column_with_vocabulary_list?', ""How to resolve 'All feature_columns must be _FeatureColumn instances' error in TensorFlow?""]",set(),[],"{'https://stackoverflow.com/questions/48697799/tensorflow-feature-column-for-variable-list-of-values', 'https://stackoverflow.com/questions/34870614/what-does-tf-nn-embedding-lookup-function-do', 'https://stackoverflow.com/questions/46834680/creating-many-feature-columns-in-tensorflow'}","['""""""Tensorflow feature column for variable list of values\n\nFrom the TensorFlow docs it\'s clear how to use tf.feature_column.categorical_column_with_vocabulary_list to create a feature column which takes as input some string and outputs a one-hot vector. For example\n\nvocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list( key=""vocab_feature"", vocabulary_list=[""kitchenware"", ""electronics"", ""sports""])\n\nLet\'s say ""kitchenware"" maps to [1,0,0] and ""electronics"" maps to [0,1,0]. My question is related to having a list of strings as a feature. For example, if the feature value was [""kitchenware"",""electronics""] then the desired output would be [1,1,0]. The input list length is not fixed but the output dimension is. The use case is a straight bag-of-words type model (obviously with a much larger vocabulary list!). What is the correct way to implement this? GratefulGuestGratefulGuest\n\nHere is an example how to feed data to the indicator column:\n\nfeatures = {\'letter\': [[\'A\',\'A\'], [\'C\',\'D\'], [\'E\',\'F\'], [\'G\',\'A\'], [\'X\',\'R\']]} letter_feature = tf.feature_column.categorical_column_with_vocabulary_list( ""letter"", [""A"", ""B"", ""C""], dtype=tf.string) indicator = tf.feature_column.indicator_column(letter_feature) tensor = tf.feature_column.input_layer(features, [indicator]) with tf.Session() as session: session.run(tf.global_variables_initializer()) session.run(tf.tables_initializer()) print(session.run([tensor]))\n\n[array([[2., 0., 0.], [0., 0., 1.], [0., 0., 0.], [1., 0., 0.], [0., 0., 0.]], dtype=float32)]\n\n 3\n\nin above example the features is passed as dict. How do I get the same results when I have a column in csv file which is space separated and I need to multi-hot encode using the example above ? Can we use Embedding column here? In case we have large number of values in the column (a very common case), we may end up with a sparse column if we use indicator column. you should use tf.feature_column.indicator_column see https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column\n\n Could you give an example of what the structure of the training data should look like in this case. The doc you post to show what the input data inso converted into but not what you feed it.""""""']","### Explanation

The question addresses an error encountered when using TensorFlow's `tf.feature_column.categorical_column_with_vocabulary_list` in conjunction with embedding columns. The error message ""All feature_columns must be _FeatureColumn instances"" indicates that the provided feature columns are not recognized as valid `_FeatureColumn` instances by TensorFlow.

The issue arises from the way the `columns` list is constructed. In the provided code, the `columns` list is nested within another list, which is incorrect. The `columns` list should directly contain the feature columns without any additional nesting.

To resolve this issue, ensure that the `columns` list is correctly structured by directly including the feature columns. This will allow TensorFlow to properly recognize and process the feature columns, avoiding the `_FeatureColumn` instance error.

Additionally, it is important to note that `tf.feature_column.categorical_column_with_vocabulary_list` is deprecated. The recommended approach is to use Keras preprocessing layers or the `tf.keras.utils.FeatureSpace` utility for feature preprocessing when training a Keras model. This modern approach provides a more streamlined and efficient way to handle feature columns.

In summary, the error is due to incorrect nesting of the `columns` list. Correcting the structure of the `columns` list and considering the use of Keras preprocessing layers or `tf.keras.utils.FeatureSpace` will resolve the issue and align with the latest TensorFlow practices."
49987839,tf.clip_by_global_norm,example required,How to handle None in tf.clip_by_global_norm?,"<p>I have read in answers to <a href=""https://stackoverflow.com/questions/36498127/how-to-apply-gradient-clipping-in-tensorflow"">this question here</a> that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws </p>

<p>ValueError: None values not supported.</p>

<pre><code>tf.reset_default_graph()
z = tf.get_variable(name = 'z', shape = [1])
b = tf.get_variable('b', [1])
c = b*b - 2*b + 1
optimizer = tf.train.AdamOptimizer(0.1)
gradients, variables = zip(*optimizer.compute_gradients(c))
gradients = tf.clip_by_global_norm(gradients, 2.5)
train_op = optimizer.apply_gradients(zip(gradients, variables))
</code></pre>

<p>Can somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually</p>

<p>The official documentation seems to agree with @danijar's comments. see <a href=""https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/clip_by_global_norm"" rel=""nofollow noreferrer"">here</a></p>

<blockquote>
  <p>Any of the entries of t_list that are of type None are ignored.</p>
</blockquote>
","<p>There's a small problem in your code: you're assigning the return value of <code>tf.clip_by_global_norm</code> to a single variable, when this function returns a pair of values.</p>

<p>The documentation says:</p>

<blockquote>
  <p>Returns:</p>
  
  <p>list_clipped: A list of Tensors of the same type as list_t.</p>
  
  <p>global_norm: A 0-D (scalar) Tensor representing the global norm.</p>
</blockquote>

<p>Hence, the problem arises when you try to apply the gradients to the variables, in the next line.</p>

<p>You can easily fix your code ignoring the global_norm returned value.</p>

<pre><code>gradients, _ = tf.clip_by_global_norm(gradients, 2.5)
</code></pre>
","There's a small problem in your code: you're assigning the return value of <code>tf.clip_by_global_norm</code> to a single variable, when this function returns a pair of values.
The documentation says:
<blockquote>
  Returns:
  list_clipped: A list of Tensors of the same type as list_t.
  global_norm: A 0-D (scalar) Tensor representing the global norm.
</blockquote>

Hence, the problem arises when you try to apply the gradients to the variables, in the next line.
You can easily fix your code ignoring the global_norm returned value.

<pre><code>gradients, _ = tf.clip_by_global_norm(gradients, 2.5)
</code></pre>",,"['How to handle None gradients in TensorFlow using tf.clip_by_global_norm?', 'Common issues and solutions when using tf.clip_by_global_norm in TensorFlow', 'Step-by-step guide to using tf.clip_by_global_norm with AdamOptimizer in TensorFlow', 'How to manually handle None gradients in TensorFlow', 'Best practices for gradient clipping in TensorFlow']","['How to handle None gradients in TensorFlow when using tf.clip_by_global_norm()?', 'Does tf.clip_by_global_norm() ignore None gradients in TensorFlow?', ""Why does tf.clip_by_global_norm() throw 'ValueError: None values not supported' in TensorFlow?"", 'How to manually handle None gradients in TensorFlow before using tf.clip_by_global_norm()?', 'What is the correct way to use tf.clip_by_global_norm() with AdamOptimizer in TensorFlow?']",{'https://www.youtube.com/watch?v=KrQp1TxTCUY'},"['""""""[Document(page_content=""unstable gradients are one of the main problems of deep neural networks and most of the time batch normalization is the answer to deal with this problem but when you\'re dealing with recurrent neural networks batch normalization is a little bit tricky to implement so instead we might use something else called gradient clipping so in this video let\'s learn what gradient clipping is and how we can apply it so gradient clipping is used for the exploding gradients problem and what you do is quite simple it\'s just that there are a bunch of approaches to it that we will cover in this video so basically with gradient clipping you very simply clip the gradients to be in a certain threshold so for example if you determine that you want your gradients to be between one and one you can easily set the parameter to be one and then from then on whatever your gradients are calculated to be that means whatever your weights were going to be updated with they will be clipped to be between minus one and one the tricky part here is that when you clip some of the gradients and some not the direction of your gradient is going to change so let\'s take this for example let\'s say this is the graph that we have and this is kind of the graph of how we can change the weight 1 and weight 2 and how the cost is going to change from then on so if you let\'s say out of a gradient vector like this that has 0.9 3.2 150 minus 2.1 and 0.0.23 what you\'re going to do if you apply gradient clipping here is that you\'re going to clip the gradients that are higher than 1 and also lower than minus one to be between one and minus one and you\'re going to bring them to be one and minus one so let\'s say in the original vectors the vector\'s direction the direction and the graph was going to look this way but if you clip the gradients the vector is going to change and what\'s going to happen is that your vector is going to be pointing in a completely different direction something you can do to maintain the direction of the gradient is what we call clipping by norm so basically instead of only clipping the ones that are outside of the ranges that you\'re aiming for you can just lower all of your gradient values all of the values that are in your gradient vector to be in between -1 and 1. this way you\'re keeping the proportion of the numbers in your gradient vector and thus keeping the direction of your original gradient vector the main problem with this approach is that this time some of your gradient values are going to become very very very small and at the end they might not actually be effective in updating the parameters of your network unfortunately there are no hard rules when it comes to gradient clipping you\'re going to have to try grading clipping and also grading clipping with norm and see which one works better for you you might also need to try different threshold values to see which one gives you a better result but at the end of the day this is a very effective way of solving the exploding gradients problem and luckily it is very simple to implement using the keras deep learning library but that is all you need to know about grading clipping as i said it\'s a very easy to use and effective way of dealing with the exploding gradients problem and lucky for you and me it is very simple to implement it using the keras deep learning library i hope you enjoyed this video if you liked it don\'t forget to give us a like and maybe even subscribe to show us your support we would also love to hear any of your comments or questions in the comment section below but for now thanks for watching again and i will see you in the next video"", metadata={\'source\': \'KrQp1TxTCUY\'})]""""""']","{'https://stackoverflow.com/questions/36498127/how-to-apply-gradient-clipping-in-tensorflow', 'https://stackoverflow.com/questions/49987839/how-to-handle-none-in-tf-clip-by-global-norm'}","['""""""OverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nHow to handle None in tf.clip_by_global_norm? I have read in answers to this question here that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws\n\nValueError: None values not supported. tf.reset_default_graph() z = tf.get_variable(name = \'z\', shape = [1]) b = tf.get_variable(\'b\', [1]) c = b*b - 2*b + 1 optimizer = tf.train.AdamOptimizer(0.1) gradients, variables = zip(*optimizer.compute_gradients(c)) gradients = tf.clip_by_global_norm(gradients, 2.5) train_op = optimizer.apply_gradients(zip(gradients, variables))\n\nCan somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually\n\nThe official documentation seems to agree with @danijar\'s comments. see here\n\nAny of the entries of t_list that are of type None are ignored.""""""']","### Handling `None` Values in `tf.clip_by_global_norm`

The question addresses an issue encountered when using `tf.clip_by_global_norm` in TensorFlow, specifically regarding the handling of `None` values within the list of tensors to be clipped. The user reports receiving a `ValueError: None values not supported` despite the official documentation stating that `None` values are ignored.

According to the TensorFlow API documentation, `tf.clip_by_global_norm` is designed to clip the values of multiple tensors by the ratio of the sum of their norms. The function accepts a tuple or list of tensors (`t_list`), a clipping ratio (`clip_norm`), and optionally, a precomputed global norm (`use_norm`). The documentation explicitly states that any entries in `t_list` that are of type `None` are ignored during the clipping process.

However, the user's experience suggests that `None` values are not being ignored as expected, resulting in a `ValueError`. This discrepancy indicates that there might be an issue with how the `None` values are being handled in the specific context of the user's code.

To address this, it is important to ensure that the list of gradients passed to `tf.clip_by_global_norm` does not contain `None` values. This can be achieved by manually filtering out `None` values from the list of gradients before passing it to the function. This step ensures that only valid tensors are included in the clipping operation, thereby preventing the `ValueError`.

In summary, while `tf.clip_by_global_norm` is designed to ignore `None` values, practical implementation may require manual handling of `None` values to avoid errors. This involves filtering out `None` values from the list of tensors before invoking the function. This approach aligns with the official documentation and ensures smooth execution of the gradient clipping process."
55560676,tf.while_loop,example required,How to use tf.while_loop with eager execution?,"<p>In the documentation, the body of a tf.while_loop needs to be a python callable.</p>

<pre><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>works but</p>

<pre><code>def b(i):
    tf.add(i,1)

i = tf.constant(0)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>throws a ValueError: Attempt to convert a value (None) with an unsupported type() to a Tensor</p>

<p>In 2.0, eager execution is default, I wonder what's the problem?!</p>
","<p>You forgot to add return statement to your function:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def b(i):
    return tf.add(i, 1)

i = tf.constant(0)
c = lambda i: tf.less(i, 10)
tf.while_loop(c, b, [i]) # &lt;tf.Tensor: id=51, shape=(), dtype=int32, numpy=10&gt;
</code></pre>

<p>Note that in your first example function <code>b</code> does return incremented value:</p>

<pre class=""lang-py prettyprint-override""><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
print(b(1).numpy()) # 2
</code></pre>
",,"<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def b(i):
    return tf.add(i, 1)

i = tf.constant(0)
c = lambda i: tf.less(i, 10)
tf.while_loop(c, b, [i]) # &lt;tf.Tensor: id=51, shape=(), dtype=int32, numpy=10&gt;
</code></pre>
<pre class=""lang-py prettyprint-override""><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
print(b(1).numpy()) # 2
</code></pre>","['Understanding tf.while_loop in TensorFlow 2.0', 'How to use tf.while_loop with Python functions in TensorFlow', 'Common errors with tf.while_loop in TensorFlow 2.0', 'Differences between lambda functions and def functions in TensorFlow 2.0', 'Eager execution in TensorFlow 2.0 and its impact on tf.while_loop', 'How to properly define the body function for tf.while_loop in TensorFlow 2.0']","['Why does tf.while_loop require the body to be a Python callable?', 'How to correctly define the body function for tf.while_loop in TensorFlow 2.0?', 'What are common errors when using tf.while_loop in TensorFlow 2.0?', 'How does eager execution affect tf.while_loop in TensorFlow 2.0?', 'What is the correct way to return a value from a function used in tf.while_loop?']","{'https://www.youtube.com/watch?v=KrS94hG4VU0', 'https://www.youtube.com/watch?v=RPocW_aMZKE', 'https://www.youtube.com/watch?v=iFZRUwGcrxQ'}",,"{'https://stackoverflow.com/questions/37441140/how-to-use-tf-while-loop-in-tensorflow', 'https://stackoverflow.com/questions/59332392/tf-function-and-tf-while-loop-in-tensorflow-2-0', 'https://stackoverflow.com/questions/41604686/how-to-use-tf-while-loop-for-variable-length-inputs-in-tensorflow', 'https://stackoverflow.com/questions/37571017/tensorflow-stuck-into-endless-loop-using-tf-while-loop', 'https://stackoverflow.com/questions/46768386/while-loop-error-in-tensorflow'}","['""""""How to use tf.while_loop() for variable-length inputs in tensorflow? \n\nI am trying to use tf.while_loop() to process variable-length inputs. However, I can only use it for fixed length. The code no longer works after I change shape=(4) to shape=(None). tf.dynamic_rnn seems to handle variable-length inputs. I am not sure how tf.dynamic_rnn achieves this with tf.while_loop(). import tensorflow as tf import numpy as np from tensorflow.python.ops import tensor_array_ops from tensorflow.python.ops import array_ops with tf.Graph().as_default(), tf.Session() as sess: initial_m = tf.Variable(0.0, name=\'m\') inputs = tf.placeholder(dtype=\'float32\', shape=(4)) #The code no longer works after I change shape=(4) to shape=(None) #inputs = tf.placeholder(dtype=\'float32\', shape=(None)) time_steps = tf.shape(inputs)[0] initial_outputs = tf.TensorArray(dtype=tf.float32, size=time_steps) initial_t = tf.constant(0, dtype=\'int32\') def should_continue(t, *args): return t < time_steps def iteration(t, m, outputs_): cur = tf.gather(inputs, t) m = m * 0.5 + cur * 0.5 outputs_ = outputs_.write(t, m) return t + 1, m, outputs_ t, m, outputs = tf.while_loop( should_continue, iteration, [initial_t, initial_m, initial_outputs]) outputs = outputs.pack() init = tf.global_variables_initializer() sess.run([init]) print sess.run([outputs], feed_dict={inputs: np.asarray([1,1,1,1])})\n\noutput (before change):\n\n[array([ 0.5 , 0.75 , 0.875 , 0.9375], dtype=float32)]\n\noutput (after change):\n\nTraceback (most recent call last): File ""simple.py"", line 26, in <module> [initial_t, initial_m, initial_outputs]) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2636, in while_loop result = context.BuildLoop(cond, body, loop_vars, shape_invariants) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2469, in BuildLoop pred, body, original_loop_vars, loop_vars, shape_invariants) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2450, in _BuildLoop _EnforceShapeInvariant(m_var, n_var) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 586, in _EnforceShapeInvariant % (merge_var.name, m_shape, n_shape)) ValueError: The shape for while/Merge_1:0 is not an invariant for the loop. It enters the loop with shape (), but has shape <unknown> after one iteration. Provide shape invariants using either the `shape_invariants` argument of tf.while_loop or set_shape() on the loop variables. 0\n\nIt works if you remove shapes from all the variables:\n\nimport tensorflow as tf import numpy as np config = tf.ConfigProto(graph_options=tf.GraphOptions( optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0))) tf.reset_default_graph() sess = tf.Session("""", config=config) #initial_m = tf.Variable(0.0, name=\'m\') #The code no longer works after I change shape=(4) to shape=(None) inputs = tf.placeholder(dtype=\'float32\', shape=(None)) time_steps = tf.shape(inputs)[0] initial_outputs = tf.TensorArray(dtype=tf.float32, size=time_steps) initial_t = tf.placeholder(dtype=\'int32\') initial_m = tf.placeholder(dtype=tf.float32) def should_continue(t, *args): return t < time_steps def iteration(t, m, outputs_): cur = tf.gather(inputs, t) m = m * 0.5 + cur * 0.5 outputs_ = outputs_.write(t, m) return t + 1, m, outputs_ t, m, outputs = tf.while_loop(should_continue, iteration, [initial_t, initial_m, initial_outputs]) outputs = outputs.stack() init = tf.global_variables_initializer() sess.run([init]) print(sess.run([outputs], feed_dict={inputs: np.asarray([1, 1, 1, 1]), initial_t: 0, initial_m: 0.}))\n\n\ BTW, is it possible to avoid using placeholder? initial_t and initial_m are are alway zeros.""""""', '""""""How to use tf.while_loop() in tensorflow\n\n This is a generic question. I found that in the tensorflow, after we build the graph, fetch data into the graph, the output from graph is a tensor. but in many cases, we need to do some computation based on this output (which is a tensor), which is not allowed in tensorflow. for example, I\'m trying to implement a RNN, which loops times based on data self property. That is, I need use a tensor to judge whether I should stop (I am not using dynamic_rnn since in my design, the rnn is highly customized). I find tf.while_loop(cond,body.....) might be a candidate for my implementation. But the official tutorial is too simple.""""""', '""""""tf.function and tf.while loop in Tensorflow 2.0\n\n I am trying to parallelize loop using tf.while_loop. As suggested here, the parallel_iterations argument doesn\'t make a difference in the eager mode. So I attempted to wrap tf.while_loop with tf.function. However, after adding the decorator,the behavior of the iteration variable changes. For example, this piece of code works. result = np.zeros(10) iteration = tf.constant(0) c = lambda i: tf.less(i, 10) def print_fun(iteration): result[iteration] = iteration iteration += 1 return (iteration,) tf.while_loop(c, print_fun, [iteration])\n\nIf I add the decorator, bug occurs. result = np.zeros(10) iteration = tf.constant(0) c = lambda i: tf.less(i, 10) def print_fun(iteration): result[iteration] = iteration iteration += 1 return (iteration,) @tf.function def run_graph(): iteration = tf.constant(0) tf.while_loop(c, print_fun, [iteration]) run_graph()\n\nFrom my debugging process, I found that variable iteration changes from a tensor to a placeholder. Why is that?""""""', '""""""I will edit my question based on your answer here\n\nWhat\'s the expected answer for your code? The global summ and ignoring the second body argument is suspicious: you probably want to pass 0. as the initial value for the second loop variable, and use the second body argument instead of the global summ as the accumulator. If you see this error: ValueError: The two structures don\'t have the same number of elements. If you see it in a while_loop, that means your inputs and outputs out of the while loop have different shapes. I solved it by making sure that I return the same structure of loop_vars from my while loop function, the condition function must also accept same loop vars. Here is an example code\n\nloop_vars = [i, loss, batch_size, smaller_str_lens] def condition(*loop_vars): i = loop_vars[0] batch_size = loop_vars[2] return tf.less(i, batch_size) def body(*loop_vars): i, loss, batch_size, smaller_str_lens = loop_vars tf.print(""The loop passed here"") ## logic here i = tf.add(i, 1) return i, loss, batch_size, smaller_str_lens loss = tf.while_loop(condition, compare_strings, loop_vars)[1]\n\nThe body func must return loop vars, and the condition func must accept loop vars.""""""']","To address the question of how to use `tf.while_loop` with eager execution in TensorFlow 2.0, it is important to understand the requirements and constraints of the `tf.while_loop` function. The `tf.while_loop` function requires the `body` argument to be a callable that returns a tuple of tensors. This callable is executed repeatedly until the `cond` callable returns `False`.

In the context of eager execution, which is the default mode in TensorFlow 2.0, the `body` function must explicitly return the updated loop variables. If the `body` function does not return the updated loop variables, TensorFlow will raise a `ValueError` because it expects the `body` to return a value that can be used in the next iteration of the loop.

The issue arises when the `body` function is defined as a standard Python function that does not return the updated loop variables. In eager execution, TensorFlow attempts to convert the return value of the `body` function to a tensor, and if the return value is `None`, it results in a `ValueError`.

To resolve this, ensure that the `body` function explicitly returns the updated loop variables. This allows TensorFlow to correctly propagate the loop variables through each iteration of the loop. Additionally, the `cond` function should also be a callable that returns a boolean scalar tensor, which determines whether the loop should continue.

In summary, when using `tf.while_loop` with eager execution in TensorFlow 2.0, it is crucial to define the `body` function such that it returns the updated loop variables. This ensures that TensorFlow can correctly manage the loop iterations and avoid errors related to unsupported return types."
59531864,tf.nn.conv1d,example required,Why does TensorFlow calculate 2D convolutions when 1D convolution is called?,"<p>In the documentation of tf.nn.conv1d, it is stated that</p>

<blockquote>
  <p>Internally, this op reshapes the input tensors and invokes tf.nn.conv2d. For example, if data_format does not start with ""NC"", a tensor of shape [batch, in_width, in_channels] is reshaped to [batch, 1, in_width, in_channels], and the filter is reshaped to [1, filter_width, in_channels, out_channels]. The result is then reshaped back to [batch, out_width, out_channels] (where out_width is a function of the stride and padding as in conv2d) and returned to the caller.</p>
</blockquote>

<p>I get that the operations are equivalent, but I am a bit confused about the implications of this implementation detail. </p>

<p>Does the reshaping create some computational overhead? 
The 3D convolution has its own implementation, so why not the 1D convolution?</p>

<p>Thanks for any explanation that helps me and others to understand this implementation detail of TensorFlow!</p>
","<p>Digging through the source code, I conclude that it's likely done for convenience and minimalism of implementation - details below. </p>

<p>First, there is no ""reshaping"", only expanding, squeezing, and re-ordering dims, which bears a tiny overhead; no array elements are actually being moved in memory - only the tensor object's indexing specifiers are changed.</p>

<p>Second, all <code>conv</code> ultimately route to <a href=""https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/nn_ops.py#L942"" rel=""nofollow noreferrer""><code>tf.nn_ops.convolution_internal</code></a>, which then routes to either <code>gen_nn_ops.conv2d</code> or <code>gen_nn_ops.conv3d</code>; a <code>conv1d</code> does not exist in <code>gen_nn_ops.py</code>. Note that for some reason, you won't find that file in the Git respository - but it should be in your local install, <code>/python/ops/gen_nn_ops.py</code>.</p>

<p>Lastly, to get a real answer on why there isn't a dedicated <code>conv1d</code> implementation, you'll need to ask the cuDNN developers behind the convolution algorithms found in <code>gen_nn_ops.py</code>; it's possible that they found no performance improvements, and that <code>conv2d</code> works just as fast. From a low-level standpoint, this makes sense, as the number of matrix multiplications in sliding a kernel with <code>N x 1</code> elements along an <code>M x 1</code> input is identical to that of <code>N</code> along <code>M</code> - again, the only difference is in indexing.</p>

<p>Unfortunately devs decided to encapsulate the ultimate call, that is to <code>_pywrap_tensorflow_internal.TFE_Py_FastPathExecute</code>; the module consists of a <code>.lib</code> and a <code>.pyd</code> file - basically, compiled C (Cython) code that requires disassembly for introspection. </p>

<hr>

<p>TL;DR (1) the ""reshaping"" has a trivial overhead; (2) lack of a dedicated <code>conv1d</code> implementation is likely per sparing redundancy as <code>conv2d</code> is just as fast; (3) I'm not a cuDNN expert, so if you need to be sure, better ask over at <a href=""https://developer.nvidia.com/cudnn"" rel=""nofollow noreferrer"">cuDNN</a>, or read their <a href=""https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html"" rel=""nofollow noreferrer"">SDK Documentation</a>. Alternatively, a dev at <a href=""https://github.com/tensorflow/tensorflow/issues"" rel=""nofollow noreferrer"">TF Github</a> may help. I haven't seen cuDNN devs answer on SO for years now, so posting here may not be the best bet.</p>

<hr>

<p><strong>Dim reordering performance demo</strong>:</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
from time import time

x = np.random.randn(700, 800, 900) # 504,000,000 elements

t0 = time()
for i in range(1000):
    if i % 2 == 0:
        x = x.reshape(700, 900, 800)
    else:
        x = x.reshape(700, 800, 900)
print(time() - t0)
</code></pre>

<pre><code>0.0009968280792236328
</code></pre>
","Digging through the source code, I conclude that it's likely done for convenience and minimalism of implementation - details below.

First, there is no ""reshaping"", only expanding, squeezing, and re-ordering dims, which bears a tiny overhead; no array elements are actually being moved in memory - only the tensor object's indexing specifiers are changed.
Second, all <code>conv</code> ultimately route to <code>tf.nn_ops.convolution_internal</code>, which then routes to either <code>gen_nn_ops.conv2d</code> or <code>gen_nn_ops.conv3d</code>; a <code>conv1d</code> does not exist in <code>gen_nn_ops.py</code>. Note that for some reason, you won't find that file in the Git respository - but it should be in your local install, <code>/python/ops/gen_nn_ops.py</code>.

Lastly, to get a real answer on why there isn't a dedicated <code>conv1d</code> implementation, you'll need to ask the cuDNN developers behind the convolution algorithms found in <code>gen_nn_ops.py</code>; it's possible that they found no performance improvements, and that <code>conv2d</code> works just as fast. From a low-level standpoint, this makes sense, as the number of matrix multiplications in sliding a kernel with <code>N x 1</code> elements along an <code>M x 1</code> input is identical to that of <code>N</code> along <code>M</code> - again, the only difference is in indexing.

Unfortunately devs decided to encapsulate the ultimate call, that is to <code>_pywrap_tensorflow_internal.TFE_Py_FastPathExecute</code>; the module consists of a <code>.lib</code> and a <code>.pyd</code> file - basically, compiled C (Cython) code that requires disassembly for introspection.

(1) the ""reshaping"" has a trivial overhead; (2) lack of a dedicated <code>conv1d</code> implementation is likely per sparing redundancy as <code>conv2d</code> is just as fast; (3) I'm not a cuDNN expert, so if you need to be sure, better ask over at cuDNN, or read their SDK Documentation. Alternatively, a dev at TF Github may help. I haven't seen cuDNN devs answer on SO for years now, so posting here may not be the best bet.","<pre class=""lang-py prettyprint-override""><code>import numpy as np
from time import time

x = np.random.randn(700, 800, 900) # 504,000,000 elements

t0 = time()
for i in range(1000):
    if i % 2 == 0:
        x = x.reshape(700, 900, 800)
    else:
        x = x.reshape(700, 800, 900)
print(time() - t0)
</code></pre>

<pre><code>0.0009968280792236328
</code></pre>","['What is the internal implementation of tf.nn.conv1d in TensorFlow?', 'Does reshaping tensors in TensorFlow create computational overhead?', 'Why does TensorFlow use tf.nn.conv2d for implementing tf.nn.conv1d?', 'What are the performance implications of using tf.nn.conv1d compared to tf.nn.conv2d?', 'Are there any specific optimizations for 1D convolutions in TensorFlow?', 'How does TensorFlow handle data_format in tf.nn.conv1d and tf.nn.conv2d?', 'What are the best practices for using tf.nn.conv1d in TensorFlow?']","['Does reshaping tensors in tf.nn.conv1d create computational overhead?', 'Why does TensorFlow use tf.nn.conv2d internally for tf.nn.conv1d instead of having a separate implementation for 1D convolution?', 'What are the performance implications of using tf.nn.conv2d for 1D convolution in TensorFlow?', 'Are there any benefits to using tf.nn.conv2d for implementing tf.nn.conv1d in TensorFlow?', 'How does the reshaping of tensors in tf.nn.conv1d affect memory usage and computational efficiency?']",set(),[],{'https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow'},"['"""""" What does tf.nn.conv2d do in tensorflow? \n\nI was looking at the docs of tensorflow about tf.nn.conv2d here. But I can\'t understand what it does or what it is trying to achieve. It says on the docs,\n\n#1 : Flattens the filter to a 2-D matrix with shape\n\n[filter_height * filter_width * in_channels, output_channels]. Now what does that do? Is that element-wise multiplication or just plain matrix multiplication? I also could not understand the other two points mentioned in the docs. I have written them below :\n\n# 2: Extracts image patches from the the input tensor to form a virtual tensor of shape\n\n[batch, out_height, out_width, filter_height * filter_width * in_channels]. # 3: For each patch, right-multiplies the filter matrix and the image patch vector. It would be really helpful if anyone could give an example, a piece of code (extremely helpful) maybe and explain what is going on there and why the operation is like this. I\'ve tried coding a small portion and printing out the shape of the operation. Still, I can\'t understand. I tried something like this:\n\nop = tf.shape(tf.nn.conv2d(tf.random_normal([1,10,10,10]), tf.random_normal([2,10,10,10]), strides=[1, 2, 2, 1], padding=\'SAME\')) with tf.Session() as sess: result = sess.run(op) print(result)\n\nI understand bits and pieces of convolutional neural networks. I studied them here. But the implementation on tensorflow is not what I expected. So it raised the question. EDIT: So, I implemented a much simpler code. But I can\'t figure out what\'s going on. I mean how the results are like this.""""""']","### Explanation of Why TensorFlow Uses 2D Convolutions for 1D Convolution Operations

In TensorFlow, the `tf.nn.conv1d` function is designed to perform 1D convolution operations on 3D input tensors. However, internally, TensorFlow reshapes the input tensors and invokes the `tf.nn.conv2d` function to perform the equivalent convolution operation. This implementation detail might seem confusing, but it is essential to understand the rationale behind it.

When `tf.nn.conv1d` is called, the input tensor of shape `[batch, in_width, in_channels]` (assuming the default data format `""NWC""`) is reshaped to `[batch, 1, in_width, in_channels]`. Similarly, the filter tensor of shape `[filter_width, in_channels, out_channels]` is reshaped to `[1, filter_width, in_channels, out_channels]`. This reshaping allows the 1D convolution to be treated as a special case of the 2D convolution, where one of the spatial dimensions has a size of 1. After the 2D convolution operation is performed, the result is reshaped back to `[batch, out_width, out_channels]`.

The primary reason for this approach is to leverage the existing optimized implementation of 2D convolutions in TensorFlow. By reusing the `tf.nn.conv2d` function, TensorFlow can avoid duplicating code and ensure that the 1D convolution benefits from the same performance optimizations and hardware acceleration as the 2D convolution.

While this reshaping process might introduce some computational overhead, it is generally minimal compared to the overall cost of the convolution operation. The benefits of code reuse and optimization typically outweigh the minor overhead introduced by reshaping the tensors.

In summary, TensorFlow uses 2D convolutions for 1D convolution operations to take advantage of the optimized implementation of `tf.nn.conv2d`. This approach ensures efficient computation while maintaining the flexibility to handle 1D convolution tasks."
55422537,tf.estimator.DNNClassifier,example required,Testing TF serving model fails with bytes as strings and strings as bytes confusion,"<p>I'm having a problem serving my text classification model on <code>Tensorflow 1.12</code>. I'm using <code>tf.estimator.inputs.pandas_input_fn</code> to read in my data, and <code>tf.estimator.DNNClassifier</code> to train/evaluate. I'd then like to serve my model.
(Apologies in advance, it's tough to provide a full working example here, but it's very much like the example TF provides at <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier</a>  )</p>

<p>I'm currently saving my model with ...</p>

<pre class=""lang-py prettyprint-override""><code>...
estimator.export_savedmodel(""./TEST_SERVING/"", self.serving_input_receiver_fn, strip_default_attrs=True)
...
def serving_input_receiver_fn(self):
      """"""An input receiver that expects a serialized tf.Example.""""""

      # feature spec dictionary  determines our input parameters for the model
      feature_spec = {
          'Headline': tf.VarLenFeature(dtype=tf.string),
          'Description': tf.VarLenFeature(dtype=tf.string)
      }

      # the inputs will be initially fed as strings with data serialized by
      # Google ProtoBuffers
      serialized_tf_example = tf.placeholder(
          dtype=tf.string, shape=None, name='input_example_tensor')
      receiver_tensors = {'examples': serialized_tf_example}

      # deserialize input
      features = tf.parse_example(serialized_tf_example, feature_spec)
      return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)


</code></pre>

<p>This actually fails to run with the error:</p>

<pre class=""lang-sh prettyprint-override""><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt; to Tensor. Contents: SparseTensor(indices=Tensor(""ParseExample/ParseExample:0"", shape=(?, 2), 
dtype=int64), values=Tensor(""ParseExample/ParseExample:2"", shape=(?,), dtype=string), dense_shape=Tensor(""ParseExample/ParseExample:4"", shape=(2,), dtype=int64)). Consider casting elements to a supported type.

</code></pre>

<p>I tried to save a second way doing:</p>

<pre class=""lang-py prettyprint-override""><code>def serving_input_receiver_fn(self):
  """"""Build the serving inputs.""""""
  INPUT_COLUMNS = [""Headline"",""Description""]
  inputs = {}
  for feat in INPUT_COLUMNS:
    inputs[feat] = tf.placeholder(shape=[None], dtype=tf.string, name=feat)
  return tf.estimator.export.ServingInputReceiver(inputs, inputs)
</code></pre>

<p>This actually works, until I try testing it with the <code>saved_model_cli</code>.
Some output for <code>saved_model_cli show --all --dir TEST_SERVING/1553879255/</code>:</p>

<pre class=""lang-sh prettyprint-override""><code>MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['predict']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['Description'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Description:0
    inputs['Headline'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Headline:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['class_ids'] tensor_info:
        dtype: DT_INT64
        shape: (-1, 1)
        name: dnn/head/predictions/ExpandDims:0
    outputs['classes'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: dnn/head/predictions/str_classes:0
    outputs['logits'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/logits/BiasAdd:0
    outputs['probabilities'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/head/predictions/probabilities:0
  Method name is: tensorflow/serving/predict

</code></pre>

<p>But now I can't seem to test it.</p>

<pre class=""lang-sh prettyprint-override""><code>&gt;&gt;&gt; saved_model_cli run --dir TEST_SERVING/1553879255/ --tag_set serve --signature_def predict --input_examples 'inputs=[{""Description"":[""What is going on""],""Headline"":[""Help me""]}]'
Traceback (most recent call last):
 ...
  File ""/Users/Josh/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 489, in _create_example_string
    feature_list)
TypeError: 'What is going on' has type str, but expected one of: bytes

</code></pre>

<p>Ok, lets turn it into a bytes object by changing to <code>b[""What is going on""]</code> and <code>b[""Help me""]</code>...</p>

<pre class=""lang-sh prettyprint-override""><code>ValueError: Type &lt;class 'bytes'&gt; for value b'What is going on' is not supported for tf.train.Feature.
</code></pre>

<p>Any ideas/thoughts??
Thanks!</p>
","<p>Ok, so eventually I found the answer, quoted in <a href=""https://stackoverflow.com/questions/51482730/tensorflow-how-to-export-estimator-using-tensorhub-module"">TensorFlow: how to export estimator using TensorHub module?</a> </p>

<p>The problem was with serialization stuff I don't really understand. The solution allows to pass raw strings to <code>tf.estimator.export.build_raw_serving_input_receiver_fn</code> instead.</p>

<p>My saving funciton now looks like this:</p>

<pre class=""lang-py prettyprint-override""><code>  def save_serving_model(self,estimator):
      feature_placeholder = {'Headline': tf.placeholder('string', [1], name='headline_placeholder'),
      'Description': tf.placeholder('string', [1], name='description_placeholder')}
      serving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholder)

      estimator.export_savedmodel(""TEST_SERVING/"", serving_input_fn)
</code></pre>

<p>where using the <code>saved_model_cli</code> works. I.e.:</p>

<pre class=""lang-sh prettyprint-override""><code>saved_model_cli run --dir /path/to/model/ --tag_set serve --signature_def predict --input_exprs=""Headline=['Finally, it works'];Description=['Yay, it works']"" 

</code></pre>

<pre class=""lang-sh prettyprint-override""><code>Result for output key class_ids:
[[2]]
Result for output key classes:
[[b'2']]
Result for output key logits:
[[-0.56755465  0.31625098  0.39260274]]
Result for output key probabilities:
[[0.16577701 0.40119565 0.4330274 ]]
</code></pre>
",,"<pre class=""lang-py prettyprint-override""><code>  def save_serving_model(self,estimator):
      feature_placeholder = {'Headline': tf.placeholder('string', [1], name='headline_placeholder'),
      'Description': tf.placeholder('string', [1], name='description_placeholder')}
      serving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholder)

      estimator.export_savedmodel(""TEST_SERVING/"", serving_input_fn)
</code></pre>

<p>where using the <code>saved_model_cli</code> works. I.e.:</p>

<pre class=""lang-sh prettyprint-override""><code>saved_model_cli run --dir /path/to/model/ --tag_set serve --signature_def predict --input_exprs=""Headline=['Finally, it works'];Description=['Yay, it works']"" 

</code></pre>

<pre class=""lang-sh prettyprint-override""><code>Result for output key class_ids:
[[2]]
Result for output key classes:
[[b'2']]
Result for output key logits:
[[-0.56755465  0.31625098  0.39260274]]
Result for output key probabilities:
[[0.16577701 0.40119565 0.4330274 ]]
</code></pre>","['How to use tf.estimator.inputs.pandas_input_fn in TensorFlow 1.12', 'How to train and evaluate a text classification model using tf.estimator.DNNClassifier', 'How to export a TensorFlow model for serving using tf.estimator.export_savedmodel', 'How to define a serving_input_receiver_fn for text data in TensorFlow', 'How to handle SparseTensor in TensorFlow serving input functions', 'How to test a TensorFlow SavedModel using saved_model_cli', 'How to format input examples for saved_model_cli in TensorFlow', 'Common issues and solutions when serving TensorFlow models with text inputs']","['How to properly use tf.estimator.export.ServingInputReceiver with tf.VarLenFeature in TensorFlow 1.12?', 'How to handle SparseTensor conversion error in TensorFlow 1.12 when using tf.estimator.export.ServingInputReceiver?', 'How to test a TensorFlow model saved with tf.estimator.export.ServingInputReceiver using saved_model_cli?', 'How to format input examples for saved_model_cli when using tf.estimator.export.ServingInputReceiver?', 'How to convert string inputs to bytes for tf.train.Feature in TensorFlow 1.12?']",set(),[],"{'https://stackoverflow.com/questions/46098863/how-to-import-an-saved-tensorflow-model-train-using-tf-estimator-and-predict-on', 'https://stackoverflow.com/questions/42835809/how-to-export-estimator-model-with-export-savedmodel-function'}","['""""""How to export Estimator model with export_savedmodel function\n\n are there any tutorials available about export_savedmodel ? I have gone through this article on tensorflow.org and unittest code on github.com, and still have no idea about how to construct the parameter serving_input_fn of function export_savedmodel\n\n 2\n\nExample of export_savedmodel function\n\n your_feature_spec = { ""some_feature"": tf.FixedLenFeature([], dtype=tf.string, default_value=""""), ""some_feature"": tf.VarLenFeature(dtype=tf.string), } def _serving_input_receiver_fn(): serialized_tf_example = tf.placeholder(dtype=tf.string, shape=None, name=\'input_example_tensor\') # key (e.g. \'examples\') should be same with the inputKey when you # buid the request for prediction receiver_tensors = {\'examples\': serialized_tf_example} features = tf.parse_example(serialized_tf_example, your_feature_spec) return tf.estimator.export.ServingInputReceiver(features, receiver_tensors) estimator.export_savedmodel(export_dir, _serving_input_receiver_fn)\n\nThen you can request the served model with ""predict"" signature name by batch. \n\nusing feature_spec = {\'x\': tf.FixedLenFeature([224, 224, 3], dtype=tf.float32)} i got the error: TypeError: Failed to convert object of type <type \'dict\'> to Tensor\n\n\n\nThe signature is \'predict\', is there a way to specify custom signature? Or set back to the \'serving_default\'. if you are using tensorflow straight from the master branch there\'s a module tensorflow.python.estimator.export that provides a function for that:\n\nfrom tensorflow.python.estimator.export import export feature_spec = {\'MY_FEATURE\': tf.constant(2.0, shape=[1, 1])} serving_input_fn = export.build_raw_serving_input_receiver_fn(feature_spec)\n\nUnfortunately at least for me it will not go further than that but I\'m not sure if my model is really correct so maybe you have more luck than I do. Alternatively, there are the following functions for the current version installed from pypi:\n\nserving_input_fn = tf.contrib.learn.utils.build_parsing_serving_input_fn(feature_spec) serving_input_fn = tf.contrib.learn.utils.build_default_serving_input_fn(feature_spec)\n\nBut I couldn\'t get them to work, too. Probably, I\'m not understanding this correctly so I hope you\'ll have more luck. \n\nExport your model to work with JSON dictionaries\n\nIn my mlengine-boilerplate repository, I use this to export estimator models to Cloud ML Engine to easily use this with online predictions (sample code for the predictions). Essential part:\n\ndef serving_input_fn(): feature_placeholders = { \'id\': tf.placeholder(tf.string, [None], name=""id_placeholder""), \'feat\': tf.placeholder(tf.float32, [None, FEAT_LEN], name=""feat_placeholder""), #label is not required since serving is only used for inference } return input_fn_utils.InputFnOps( feature_placeholders, None, feature_placeholders)\n\nExport your model to work with Tensorflow Examples\n\nThis tutorial shows how you can use export_savedmodel to serve the Wide & Deep Model implemented with estimators and how to feed Tensorflow examples into the exported model. The essential part:\n\nfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utils serving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\n\n\n\n1,4\n\nI updated the tutorial to support r1.3. You should probably update your answer to reflect new changes.""""""', '""""""Could you add the Java side of the prediction to this answer, please? Mainly to see how you are preparing the input for build_parsing_serving_input_receiver_fn in Java. – It appears that the TensorFlow team does not agree that there is a bug in version 1.3 using canned estimators for exporting a model under use case #2. The response I received from TensorFlow is that the input must only be a single string tensor. It appears that there may be a way to consolidate multiple features into a single string tensor using serialized TF.examples, but I have not found a clear method to do this. If anyone has code showing how to do this, I would be appreciative. \n\nYou need to export the saved model using tf.contrib.export_savedmodel and you need to define input receiver function to pass input to. Later you can load the saved model ( generally saved.model.pb) from the disk and serve it. """"""']","### Description

This response addresses the issue of testing a TensorFlow serving model, specifically a text classification model, which fails due to confusion between bytes and strings. The user is utilizing `tf.estimator.inputs.pandas_input_fn` for data ingestion and `tf.estimator.DNNClassifier` for training and evaluation. The model is saved using the `export_savedmodel` method, but issues arise when testing the model with `saved_model_cli`.

The problem stems from the handling of string inputs and their serialization. Initially, the user attempts to define the `serving_input_receiver_fn` with `tf.VarLenFeature` for string features, which results in a `TypeError` due to the conversion of `SparseTensor` to `Tensor`. To resolve this, the user modifies the `serving_input_receiver_fn` to use `tf.placeholder` for string inputs, which works for saving the model but leads to issues during testing with `saved_model_cli`.

When testing the model, the user encounters a `TypeError` indicating that a string was expected but a bytes object was provided. Conversely, converting the input to bytes results in a `ValueError` as the type bytes is not supported for `tf.train.Feature`.

To address this, ensure that the input data types match the expected types defined in the `serving_input_receiver_fn`. Specifically, when using `saved_model_cli`, the input examples should be provided as strings, not bytes. This can be achieved by ensuring the input JSON dictionary contains string values for the features. Additionally, verify that the `serving_input_receiver_fn` correctly defines the input placeholders and feature specifications to match the expected input format during serving.

By aligning the input data types and ensuring consistency between the `serving_input_receiver_fn` and the input provided during testing, the model can be successfully served and tested without type conversion errors."
52572275,tf.scatter_nd,example required,tensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)?,"<p>I've read the <a href=""https://www.tensorflow.org/api_docs/python/tf/manip/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_nd documentation</a> and run the example code for 1D and 3D tensors... and now I'm trying to do it for a 2D tensor.  I want to 'interleave' the columns of two tensors.  For 1D tensors, one can do this via</p>

<pre><code>'''
We want to interleave elements of 1D tensors arr1 and arr2, where
arr1 = [10, 11, 12]
arr2 = [1, 2, 3, 4, 5, 6]
such that
desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12]
'''

import tensorflow as tf

with tf.Session() as sess:

    updates1 = tf.constant([1,2,3,4,5,6])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)

    updates2 = tf.constant([10,11,12])
    indices2 = tf.constant([[2], [5], [8]])
    scatter2 = tf.scatter_nd(indices2, updates2, shape)

    result = scatter1 + scatter2

    print(sess.run(result))
</code></pre>

<p>(aside: is there a <em>better</em> way to do this?  I'm all ears.)</p>

<p>This gives the output</p>

<p><code>[ 1  2 10  3  4 11  5  6 12]</code></p>

<p>Yay! that worked!</p>

<p>Now lets' try to extend this to 2D.</p>

<pre><code>    '''
    We want to interleave the *columns* (not rows; rows would be easy!) of

    arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]
    arr2 = [[10 11 12], [10 11 12], [10 11 12]]
    such that
    desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]]
    '''

    updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([3, 9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)
</code></pre>

<p>This gives the error
<code>ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1
dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but
are 6 and 3. Shapes are [6] and [3]. for 'ScatterNd_2' (op: 'ScatterNd') with
input shapes: [6,1], [3,6], [2].</code></p>

<p>Seems like my <code>indices</code> is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean
I need to <em>explicitly</em> specify every single pair of indices for every element in <code>updates1</code>?
Or is there some kind of 'wildcard' specification I can use for the rows? (Note <code>indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]])</code> gives syntax errors, as it probably should.)</p>

<p>Would it be easier to just do a transpose, interleave the rows, then transpose back?
Because I tried that...</p>

<pre><code>scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))
print(sess.run(tf.transpose(scatter1)))
</code></pre>

<p>...and got a <em>much</em> longer error message, that I don't feel like posting unless someone requests it. </p>

<p>PS- I searched to make sure this isn't a duplicate -- I find it hard to imagine that someone else hasn't asked this before -- but turned up nothing. </p>
","<p>This is pure slicing but I didn't know that syntax like <code>arr1[0:,:][:,:2]</code> actually works. It seems it does but not sure if it is better.</p>

<p>This may be the <em>wildcard</em> slicing mechanism you are looking for.</p>

<pre><code>arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]])
arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]])

with tf.Session() as sess :
    sess.run( tf.global_variables_initializer() )
    print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1],
                              arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2],
                              arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))
</code></pre>

<p>Output is</p>

<pre><code>[[ 1  2 10  3  4 11  5  6 12]
 [ 1  2 10  3  4 11  5  7 12]
 [ 1  2 10  3  4 11  5  8 12]]
</code></pre>

<p>So, for example,</p>

<p><code>arr1[0:,:]</code> returns</p>

<pre><code>[[1 2 3 4 5 6]
 [1 2 3 4 5 7]
 [1 2 3 4 5 8]]
</code></pre>

<p>and <code>arr1[0:,:][:,:2]</code> returns the first two columns</p>

<pre><code>[[1 2]
 [1 2]
 [1 2]]
</code></pre>

<p>axis is 1.</p>
","This is pure slicing but I didn't know that syntax like <code>arr1[0:,:][:,:2]</code> actually works. It seems it does but not sure if it is better. This may be the <em>wildcard</em> slicing mechanism you are looking for.","<pre><code>arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]])
arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]])

with tf.Session() as sess :
    sess.run( tf.global_variables_initializer() )
    print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1],
                              arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2],
                              arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))
</code></pre>","['How to use tf.scatter_nd for 2D tensors in TensorFlow?', 'Interleaving columns of two 2D tensors using TensorFlow', 'Handling indices for tf.scatter_nd with 2D tensors', 'Efficient ways to interleave columns of 2D tensors in TensorFlow', 'Using tf.scatter_nd with multi-dimensional tensors', 'Common errors and solutions when using tf.scatter_nd for 2D tensors', 'Alternatives to tf.scatter_nd for interleaving columns in TensorFlow', 'Step-by-step guide to interleave columns of 2D tensors in TensorFlow']","['How to interleave columns of two 2D tensors using TensorFlow?', 'How to use tf.scatter_nd for 2D tensors in TensorFlow?', 'Is there a way to specify wildcard indices in tf.scatter_nd for TensorFlow?', 'How to handle indices for column-wise operations in TensorFlow?', 'Best practices for interleaving columns of 2D tensors in TensorFlow', 'How to transpose tensors for interleaving columns and then transpose back in TensorFlow?', 'Common errors and solutions when using tf.scatter_nd for 2D tensors in TensorFlow']","{'https://www.youtube.com/watch?v=e1B7l3smXFE', 'https://www.youtube.com/watch?v=9buk4Z_JlXk'}","['""""""[Document(page_content=""hey it\'s no no and I\'m gonna show you how to do some operations with tensorflow in Python so first thing we\'re gonna do is make sure we can run Python code so the easiest way that I know of you can go to collab dot research google.com so you can use Google collab which is a version of I think it\'s a version of Jupiter lab in size Google servers so you can run a notebook in no time and they even have support for not only CPU but GPU and TPU for free so if you go here change the run type and click on GPU you can to get the most out of color about using GPU unless you need one learn more let\'s see what they say here in order to be able to offer computational research for free kolja maintains flexibility to adjust on the fly we have heard for many users who want faster GPUs longer running notebooks and memory as well as usage limits are higher and don\'t flip to it as much introducing call approach the first step we\'re taking towards having users want to do more in collab so there seems to be plans for Google to scale this so there is $10 a month recurring billing and you can get access to that faster if you use longer time more memory what kinds of GP are available call a pro ka DSP 100 T fors and I\'m looking to connect up to 24 hours and little time ups are relatively lenient in the free version they can run for at most 12 hours needle time is much stricter than in color Pro so this seems to be a good alternative we can use the free version and that will let us run with whatever we want right now so first thing that we can do let\'s just make this a bit bigger so we import tensorflow TF execute that and then we can just print TF version to see what version of tensorflow we\'re gonna have available ones our kernel initialize you see now we\'re connected this is going to be executed we have to point to release candidate three so not even two point one we have two point two we can also run a command to see the version that we\'re running with Python so this might be I don\'t know I would guess three point yeah three point six point nine and now we can start going so we could do a simple operation with tensor so easiest thing is like we can create a tensor from an array so for instance we have this data and we want to make a tensor so that tensor that we got here I don\'t know why this is taking so long right now yeah we have a tensor shape three integer 32 with that we can perform simple operations within a tensor as if we were just performing math so we can do tensor plus one for instance and that you see just adds one to each member if we log the tensor once again we have the original if we want to modify it we will have to do this or with better syntax we can just do that so now our tensor has changed to two three four if we want to preview that ten Serena or human-readable wave and though we\'re losing information we do tensor numpy so you can just see the actual array with the contents of that tensor and let\'s see what else can we do so we can perform multiplications so let\'s say we do let\'s see if we can work out with this so supply by 2 and then numpy yep so yeah so let\'s see if we do that yeah so we just get the valley is there execution yeah so that\'s multiplying this by 2 you can see each component of course we can also do division but that that\'s a still a bit boring so let\'s go back to let\'s say we multiply by 0.5 so we get back our whoo integer so maybe we define I\'m gonna do that so huh so we cannot divide by 2 so we can do tensor equals tensor maybe that that\'s a bit better okay so let\'s go back so now we\'ve seen some operations let\'s go back and define that\'s with it before our tensor as 1 2 3 so we can do for example run TF squeeze our tensor that\'s not gonna do anything because our tensor is already flattened we can try TF gather and we tell we won from that tensor we want element 0 right what this is gonna do to see these index is getting this item and if we do 0 1 2 we\'re gonna get element 0 1 and 2 we get the same tensor but if we have values here we could get you see for example element 0 element 1 then element 0 then Y element 1 dang element 2 for x and we gathered those elements in a new tensor and we\'ll have a comment there it\'s you see we have these numbers here so we\'ve gathered the values at these indices from this tensor that were specifying here in a new tensor so that\'s a really good way to to just grab values from another tensor so let\'s try to do so this has shape so it\'s 8 so let\'s make it shape 9 so for instance to make it more apparent let\'s just make this be this so 1 1 1 2 2 2 so we\'re gonna get you know 0 0 0 so 1 1 1 2 2 2 3 3 3 so we can do now to convert this into an image right something that would be represented a tensor that represents a 3d image we can do now so let\'s say our tensor with gather right it\'s gonna be this and we now you know we have this tensor but we want it to be on the shape of 3 by 3 by 3 right so this means that we have three items in the in the X 3 items on the Y with three items each right so let\'s see let\'s see how we can get that we are looking for a tensor with shape so at any time you can say okay what\'s your shape right so we print and just note that in any notebook the last statement that you put is printed here but if you have more code below so let\'s say I define a variable that\'s gonna get printed so if you want to print multiple things where things are not the last line of a block in a Jupiter notebook you have to print for sure okay so we have a tensor that is shaped 9 and what we want to do is use the function reshape then start gather and the shape that we want to try to to do is so let\'s specify here and shape is going to be 3 3 3 let\'s see what it says okay input to reshape an internship with 9 values by the request it has 27 so here what we actually would be able to get is the tensor that you know has this shape I just mock it up here so X Y Z 3 x right so the shape of this tensor is actually let\'s actually debug that so we would get right so let\'s say that we have this and then our tensor or this is an array has that value we can print our array so that\'s our array right so we can actually do DF convert to tensor array and then ask for its shape so wait sir so we\'re gonna print that shape okay so it\'s three three so what we can actually do in the tensor that we had here is that we can do reshape tensor gather and now specify our shape is gonna be three three you know so now these tensor here that was a flat array has been reshaped into three by three matrix and what do we need to make it an image right so let\'s say we can just add another code block here and our tensor image maybe we can do gather mmm tensor gather well we want to keep this reshape right so tensor gather reshaped I\'m naming these things too long but you know you can just name the tensor the same way all the way down and just have one variable we\'re replacing its value so we have this here and we\'re gonna pick now so you can see how if I do here in this tends to reshape gather we have to run that block so now if I print tensor gather reshaped you see this value here right and the shape is three three let\'s see if we can get well can we get so DF yeah so we have here perfect power thanks very much so we\'re gonna gather maybe a element zero right so that gives us this so let\'s see we make this okay we get it inside of another race or the shape this is one one three so this is actually an image with just one row right x equals 1 y equals 3 3 you can see so what we\'re gonna do is well actually it\'s 1 1 so sorry so the image the image would be with equals 1 height equals 1 right there is 1 1 there is only one element 1 pixels with 3 RGB colors and those are RGB is 1 1 1 so our in that pixel we have our G B equals 1 1 1 okay so what we want to do is get an image that is not 1 pixel but 9 pixels so 3 by 3 how do we do that so we can do instead of doing this reshaping what we can do is we can get 3 pixels with the first color so 1 1 1 and now 3 pixels with the first color and later okay so we have 1 array second array and then the third array is gonna be the third color we\'re going to see how that looks axis must be color okay so let\'s wrap this up on an array all right so now we have I think we over we overdid it but we are going to do a different thing so we\'re going to take out this elements have this look all right so maybe we just needed to do this yeah let\'s just make it from scratch so we specify we want three rows right and we\'re gonna have 0 1 & 2 ok so now we have an array for the first row 1 pixel an array so this is 3 by 1 ok and now we have 3 1 & 2 so that\'s gonna give us a 3 by 3 matrix right you see so we have 3 by 3 the 3 pixels on the top row are RGB 1 1 1 then RGB - to 210 RGB 3 3 3 this is already animated how do we visualize it let\'s just load hmm mat lot live pipe lot oh that was a Randy\'s help and now we can do easily is PLT in the show and we haven\'t really oh yeah tensor image we have a variable there and PLT show I\'m sure I\'m missing something but let\'s see if this visualizes alright so we actually have it right we can take out the the axis if we want by running axis off and we can do a bunch of things with pie plot you can see you there\'s nothing really there because the pixel colors that were using our 1 1 1 2 2 2 & 3 2 3 but we can go to something like Photoshop or the color picker here in Google and I\'m gonna get this color so this is these 3 values which is before getting more colors from there right yeah so all right so what we need to do is we need to define our colors here so we\'re gonna have our first color it\'s gonna be that one second we\'ll change it later now so these are three colors I\'m just gonna get two more so let\'s say we get blue and then some yellow all right let\'s clean this up a bit so we have our colors so colors here that works so let\'s see colors I\'m not sure if this is gonna work with this that is say an array is not a tensor we\'ll just try it so from colors I\'m gonna do that gathering you see so we have a row with three pixels with bread three pictures with blue three pixels with yellow now we render this whoa nice so we actually get that working it\'s such a simple image I think this is the flag of some country again remember so you know the image what makes the tensor an image is just its dimensions so here we have a three by three by three matrix so this means that we have three rows on the x3 so actually there will be three columns in the x3 rows on the Y and then three three values per per pixel that represent the color for that pixel this image could actually be easily turned into RGB if we just specify one one value per image right so we have a three one three so that\'s actually not what I wanted so that would be I don\'t know if I can do it like this not really okay so I\'m not sure right now because we want it to be three by three oh okay so actually what we need to do is make because you know the the shape of the array is being inferred by the data we\'re feeding into right and these colors are RGB colors right so these are RGB colors what we will need to do is have gray sky colors which you know the only difference is that we instead of three elements RGB which is have one so the brightness so zero would be black and then 27 would be gray and 255 would be white and now this would be our element zero element 1 and element 2 of our colors array so we\'re going to go to say that our colors are going to be the the grayscale colors and when we do this gather operation now we get a 3 by 3 matrix but without any depth in the in the Y so in the third dimension so if we try to plot this you see what what happens here this is actually already a grayscale image the only problem or no problem the good thing is this color palette is a color palette that mudblood leaf adds when we have black and white color map that the black and white color map gets represented with whatever color map we specify here so for example you know that Inferno has diagram that is with red colors and they\'re they\'re a ton of colors that you can use here so see map my plot live and I don\'t know there dozens if not hundreds of of gamuts let\'s see you you see so you can use any of these names here so cool for example we use cool you see that\'s gonna use this color palette here but you know you might not want a color palette because we were saying that we had a black and white image we didn\'t really have a color image so what can we do there we can pre-process the image so real image let\'s say there are a few things we can do so we can I think the easiest is if we do TF Kara\'s pre-processing image and then array to image function and we pass our tensor image through there so that\'s our real image and then we show the real image who expected image to have rank three single image color right with shape three three right so what\'s happening here is that this image even though madly plot plot said that\'s an image is not having the dimensions of a three by three image with a single channel that would be three three one so what we\'re gonna try to do is reshape so black and white image let\'s call it image black and white we\'re just gonna do a reshape of our tensor image and we\'re gonna put it the shape of so three three one let\'s see what happens okay so that works let\'s see what Apple we\'re getting you see so that\'s three three one what happened is that those pixels go flat got flattened on the x-axis to be independent components and but we still have the zero 127 and two to five what happens here I think if we run this visualization with the tensor image we\'re going to get the same that before right Matt leaves still understands it\'s a black and white image but is rendering it with my map that you choose and but we said that\'s not what we wanted what we wanted is to render the actual black and white image so we pre process the image with Kerris so it transforms that black and white image into an actual image that can be rendered see the path see this we run that and okay again we don\'t get that and this is because I\'m not using it means black and white all right let\'s see okay so Kara\'s helps us process images sometimes but not always so last resource I\'m gonna try is tensor black and white is TF image grayscale to RGB and we\'re gonna pass our image black and white and this is what we are gonna try to render here okay and now that we\'re we\'ve done that all the way through so this is what we actually have that is rendering the actual image even though what we\'ve done and you can take a look at that here so if we print the tensor black and white you know what it\'s actually done is make those colors a three component one so we actually have a black and white image but we\'re wasting information because we\'re using two more components that we need to pair a pixel whereas you can encode that image in a three by three by one tensor so just to you know to the pic that this was working properly I\'m just gonna make let\'s see if we can make a more complex example where we we make a gradient right and an image that has a gradient in colors so let\'s say I don\'t know let\'s just make a loop here and make a tensor that has so X is going to be let\'s just start with 1 9 by 9 so 9 by 9 for e in range X tax we have the grey colors are going to stay the same and we\'re gonna put this in a different block so okay we get that there we just wanted this one okay so we\'re getting that and you know we would get here an image that is 3 3 by 3 by 3 because we\'re using one component we\'re just gonna do that and you know that way we\'ll get a tensor that has 9 by 9 so that\'s a big image well really small image in terms of real images but big for the amount of numbers we\'ve been working with in this in this notebook and you know I\'m just gonna do it the old way so we have an array of numbers that is empty and we\'re gonna append each of those numbers there and now we\'re gonna log our array right so we have a big array of numbers the first thing we\'re gonna do is get our so array as tensor so TF convert to tensor and we put that array in and we\'re not gonna see it because we didn\'t print it so we just want to bring that here alright so we have that how do we need to reshape it right so we just reshape our array as tensor us and then the shape is going to be what we said before right it\'s gonna be 3 by 3 by 1 but in this case is X by Y so whatever size we need it and now you see that you know we have that gradient where the tensor has is pleated has it split although values that we\'re gonna represent the scholars across the gamut so across the rows and columns of the of the pixels right from here we can see we\'re gonna go from black to some shade of dark gray and we\'re gonna try then we\'ll try to fix it later but we already have a tensor that we don\'t really need to map with any colors or anything so we can actually just delete all this stuff that we\'ve done to gather our tensors and stuff and we\'re just going to do the representation so we\'re just gonna show that a Reyes tensor let\'s see if that works okay invalid shape 81 for image data so we are going to try here to parse that as an image with carrots pre-processing spec the image have a rank okay this is the same problem we saw before I thought with this we will be able to not have it but we\'re gonna do a conversion of her image sensor and first game which was you to dimension okay let\'s actually inspect this element so we have a nine by nine by one which should be black and white image but we\'re not saving it okay so we didn\'t save it so my bad and we probably should have gone with doing this set of polling the numbers so nine by nine by one so as I said before I think this is something that Matt lives should be able to render directly invalid shape for image state okay so I\'m gonna repeat the steps that I did before ray to image so we have our ray Stantz ER and we have this here so we have okay nice so we got that gradient you know the or that we\'re doing here that in some way is cheating is that this map is being mapped on this on the color map that we select or the default one from zero to one right from the minimum color to the maximum color you can see that here we can see the full spectrum of a a color map or so here so you can see the full expectrum of a color map with with an operation like this but this is also because you know Chara\'s also helps us there and Matt load leaf remaps the image let\'s try what we were gonna do before so if we try rendering that image as black and white you see we can actually see the the actual values of the colors this is going from 0 to 80 and if we wanted to do our own remapping so our own mapping of those colors so they are going from 0 to 255 for whatever trivial size we choose to have on the image what we\'re gonna do is that you know this is the amount of pixels that we have so let\'s say this is pixel amount we put it here and we wanna do is we wanna see the total amount of pixels divided by 255 right so our scaling factor it\'s gonna be the pixel amount divided by 255 right so that way so let\'s see if we do for example 255 divided 80 right that\'s three point 18 so we do if we do here 3 oh you cannot probably see that so if we were to multiply that by Eddie will get 255 that\'s the maximum number we want so these are scale and what we\'re gonna do is that we\'re gonna pen not the number but the number scaled and now we should see a full spectrum from from black to gray [Music] so pixel amount scale let\'s inspect the values that we\'re actually getting there seems to be something failing here all right and those are not integers right let\'s try to do one thing so we got that the way I expected them to be we convert the tensor we reshape and then we have this tensor this is actually what I was looking for so we are going to try to do this a cast 8 M let\'s inspect it again right that seems to be what I wanted to get to yeah okay so we\'ve remapped manually right so what we did before was we had colors that didn\'t and we can see we\'re not reaching 255 maybe because we\'re starting at zero just try this okay so now we\'re going from full black to full white we\'ve mapped it manually but as I was mentioned before if you don\'t do this remapping and you convert the image with Charis Charis would actually map it from 0 to 1 and then Matt loudly is represented using the color map that you choose and you know we can see that here for instance if I run with that cool that cool color map now we\'re getting the full spectrum so now that we have this done let\'s just play a little bit with it before we wrap up and you know what I\'m gonna do right now is I\'m just gonna set an image that\'s gonna be well first really small so 3 by 3 see what we get you get a 3 by 3 image in that spectrum of colors and now we\'re going to go to 256 by 256 nice so that\'s a perfect gradient and you know maybe if you go you can see but I cannot see any difference with the pixels so we\'ve made manually with me the tensor we\'ve learned how to you know this is a cool physical image so you know any then we can put this here right it\'s gonna be my my wrap-up background so I hope this was useful so this was an exercise to me to just remember some of the basic operations that you can use with tensorflow to to just manipulate arrays as tensors and change their shape and get a rate data and convert it into an image so an image is just basically a three by not not a three by three but like XY by three or X Y and the third dimension a one which represents an RGB image or a single channel image you can have a four channel image as well if you have RGB a so you can imagine that instead of having you know a three component color we\'ll have a 4 component color with the a so the fourth component is the Alpha so the transparency that might go from 0 to 255 or friend 0 to 1 depending on the mapping that you\'re doing so yeah this was a first video I\'ve done talking about tensor flow and how to manipulate tensors if you enjoyed the video leave some comments maybe like the video and also feel free to subscribe to get notifications when I ain\'t go live or when I make new videos for the channel thank you so much bye"", metadata={\'source\': \'e1B7l3smXFE\'})]""""""', '""""""[Document(page_content=""we import tensorflow as tf and then we print the tensorflow version we are using tensorflow 1.0.1 now we\'re going to create two tensorflow variables that will hold random numbers we use tensorflow variables so that they maintain the same state across multiple calls of the session run we\'re creating this tensorflow variable using the tensorflow random underscore uniform functionality we\'re gonna generate a tensor that is two by three by four has a minimum value of 0 a max value of 10 and the data type is tensorflow int 32 n32 is a 32 bit signed integer so that is random underscore tensor underscore var underscore one we define random underscore tensor underscore var underscore two the same way we use the tensorflow random underscore uniform we have a tensor that\'s two by three by four min value of 0 max value of 10 the data type is also n32 next we use tensorflow global underscore variables underscore initializer so that when we run the session we can initialize all the variables then we define our session variable and initialize all our variables so here we\'re going to have two variables remember random underscore tensor underscore var underscore one and random underscore tensor underscore var underscore two first let\'s print our random underscore tense around the score var underscore one to see what it looks like we see that it is integers and it is two by three by four next we print our second tensor and we see that it is also two by three by four it\'s all integers and it is a completely different tensor from the first one to concatenate tensors we\'re going to use tf.concat what we do is we pass a list of tensors and then we specify the dimension we want to concatenate across we are going to concatenate across the zeroth dimension remember python is zero based index and we\'re going to assign this concatenation to python variable can cat underscore tensor underscore dim underscore zero now we\'re going to print the result we evaluate the variable inside of the session and we print the result we see that it has the four matrices so 6 5 four one two three five eight three four nine zero they\'re all there and we can run tensorflow.shape on our concat underscore tensor underscore dem underscore zero variable run it in the session and print the result and we see that it is four by three by four this is expected we\'re concatenating the two tensors across the zeroth dimension so that would be the first dimension since each tensorflow tensor was two by three by four we see that it is four by three by four so we have these three by four matrices and there are four of them on top of each other we\'re going to do another concatenation between random underscore around the score var underscore 1 and random underscore tense around the score var underscore 2. this time we\'re concatenating across dimension 1. we use the tensorflow.concat functionality and we\'re going to assign it to the python variable can cat underscore tensor underscore dim underscore one we evaluate the variable inside of our session and print the result to see that we have one matrix here one matrix here and it is now one two three four five six rows by four columns so we have two matrices six rows four columns so when we use the tensorflow.shape to get the dimensions we can see that it is two by six by four which is what we expect because each tensor originally was two by three by four so when we concatenated it across dimension one we would expect the shape to be two by six by four the last concatenation we do is across the second dimension remember this tensor is two by three by four so it has three dimensions python is a zero based index so this two will be the last one we assign it to the python variable can cat underscore tensor underscore dim under score two we print the result and we see that we have two matrices with one two three rows and one two three four five six seven eight columns when we print out the shape using the tensorflow.shape functionality we can see that it is indeed two by three by eight which is expected each original tensor was two by three by four so when we concatenated across the second dimension we would expect this to be two by three by four plus four which is exactly what we got the last thing we do is we close the tensorflow session to release the tensorflow resources we used in this session as we no longer require them"", metadata={\'source\': \'9buk4Z_JlXk\'})]""""""']","{'https://stackoverflow.com/questions/56969703/how-to-use-tf-scatter-nd-with-multi-dimensional-tensors', 'https://stackoverflow.com/questions/52572275/tensorflow-how-to-interleave-columns-of-two-tensors-e-g-using-tf-scatter-nd', 'https://stackoverflow.com/questions/39684415/tensorflow-getting-elements-of-every-row-for-specific-columns', 'https://stackoverflow.com/questions/56491633/what-is-the-difference-between-tf-scatter-add-and-tf-scatter-nd-when-indices-is'}","['""""""tensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)? Asked 5 years, 9 months ago\n\nModified 5 years, 9 months ago\n\nI\'ve read the tf.scatter_nd documentation and run the example code for 1D and 3D tensors... and now I\'m trying to do it for a 2D tensor. I want to \'interleave\' the columns of two tensors. For 1D tensors, one can do this via\n\n\'\'\' We want to interleave elements of 1D tensors arr1 and arr2, where arr1 = [10, 11, 12] arr2 = [1, 2, 3, 4, 5, 6] such that desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12] \'\'\' import tensorflow as tf with tf.Session() as sess: updates1 = tf.constant([1,2,3,4,5,6]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([9]) scatter1 = tf.scatter_nd(indices1, updates1, shape) updates2 = tf.constant([10,11,12]) indices2 = tf.constant([[2], [5], [8]]) scatter2 = tf.scatter_nd(indices2, updates2, shape) result = scatter1 + scatter2 print(sess.run(result))\n\n(aside: is there a better way to do this? I\'m all ears.)\n\nThis gives the output\n\n[ 1 2 10 3 4 11 5 6 12]\n\nNow lets\' try to extend this to 2D. \'\'\' We want to interleave the *columns* (not rows; rows would be easy!) of arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]] arr2 = [[10 11 12], [10 11 12], [10 11 12]] such that desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]] \'\'\' updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([3, 9]) scatter1 = tf.scatter_nd(indices1, updates1, shape)\n\nThis gives the error ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1 dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but are 6 and 3. Shapes are [6] and [3]. for \'ScatterNd_2\' (op: \'ScatterNd\') with input shapes: [6,1], [3,6], [2]. Seems like my indices is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean I need to explicitly specify every single pair of indices for every element in updates1? Or is there some kind of \'wildcard\' specification I can use for the rows? (Note indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]]) gives syntax errors, as it probably should.)\n\nWould it be easier to just do a transpose, interleave the rows, then transpose back? Because I tried that... scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape)) print(sess.run(tf.transpose(scatter1)))\n\n...and got a much longer error message, that I don\'t feel like posting unless someone requests it. PS- I searched to make sure this isn\'t a duplicate -- I find it hard to imagine that someone else hasn\'t asked this before -- but turned up nothing. 2\n\nOk, the following lines actually work, but I have no idea why... shape = tf.constant([9, 3]), scatter1 = tf.transpose(tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))) ...Particularly strange that I have to define shape as [9,3] and take its transpose, whereas just defining it as [3,9] and using it that way gives an error. I would have thought I need to use a shape of [9,3] if I\'m using the traspose, or else define [3,9] and then take its transpose. ? ...So, while I now have \'working code\', I\'d rather not \'answer my own question\': If you can either explain why this is necessary, or offer a better way to do what I want to do, then the prize is yours! ;-)\n\n\n\nThis is pure slicing but I didn\'t know that syntax like arr1[0:,:][:,:2] actually works. It seems it does but not sure if it is better. This may be the wildcard slicing mechanism you are looking for. arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]]) arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]]) with tf.Session() as sess : sess.run( tf.global_variables_initializer() ) print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1], arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2], arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))\n\n[[ 1 2 10 3 4 11 5 6 12] [ 1 2 10 3 4 11 5 7 12] [ 1 2 10 3 4 11 5 8 12]]\n\n[[1 2 3 4 5 6] [1 2 3 4 5 7] [1 2 3 4 5 8]]\n\nand arr1[0:,:][:,:2] returns the first two columns\n\n I was using scatter_nd instead of concatenate because I need the solution to scale up to hundreds of columns, which I can\'t count on being able to specify ""by hand"". Still, if there\'s a way to make this ""scale"", i.e. programatically specifying the columns (without a hundred concat operations which would be slow), then this answer wins. I also hit upon a different (non-scatter_nd) answer using permutation matrices, which I\'ll post in a bit... Some moderators might have regarded my question as a duplicate of this one, not because the questions are the same, but only because the answers contain parts one can use to answer this question -- i.e. specifying every index combination by hand. A totally different method would be to multiply by a permutation matrix as shown in the last answer to this question. Since my original question was about scatter_nd, I\'m going to post this solution but wait to see what other answers come in... (Alternatively, I or someone could edit the question to make it about reordering columns, not specific to scatter_nd --EDIT: I have just edited the question title to reflect this). Here, we concatenate the two different arrays/tensors... import numpy as np import tensorflow as tf sess = tf.Session() # the ultimate application is for merging variables which should be in groups, # e.g. in this example, [1,2,10] is a group of 3, and there are 3 groups of 3 n_groups = 3 vars_per_group = 3 # once the single value from arr2 (below) is included arr1 = 10+tf.range(n_groups, dtype=float) arr1 = tf.stack((arr1,arr1,arr1),0) arr2 = 1+tf.range(n_groups * (vars_per_group-1), dtype=float) arr2 = tf.stack((arr2,arr2,arr2),0) catted = tf.concat((arr1,arr2),1) # concatenate the two arrays together print(""arr1 = \\n"",sess.run(arr1)) print(""arr2 = \\n"",sess.run(arr2)) print(""catted = \\n"",sess.run(catted))\n\narr1 = [[10. 11.""""""']","To interleave columns of two 2D tensors using TensorFlow, the `tf.scatter_nd` function can be employed, but it requires careful handling of indices and shapes. The goal is to interleave columns of two tensors, similar to how it is done for 1D tensors, but extended to 2D.

For 1D tensors, the interleaving can be achieved by specifying the indices where elements from each tensor should be placed and then using `tf.scatter_nd` to create the final interleaved tensor. This approach works well for 1D tensors, as demonstrated in the provided example where elements from two 1D tensors are interleaved to form a new tensor.

When extending this to 2D tensors, the challenge lies in specifying the correct indices for the columns rather than rows. The error encountered in the provided example arises because the indices are interpreted as row indices, leading to a mismatch in dimensions. To interleave columns, one must explicitly specify the indices for each element in the updates tensor, which can be cumbersome and error-prone.

An alternative approach involves transposing the tensors, interleaving the rows (which is straightforward), and then transposing back to achieve the desired column interleaving. This method, however, also encountered issues due to shape mismatches and the need for correct handling of transpositions.

A more scalable solution involves using slicing and concatenation. By slicing the tensors into the desired column groups and concatenating them along the appropriate axis, one can achieve the interleaving without manually specifying each index. This method is more efficient and easier to scale for tensors with a large number of columns.

In summary, while `tf.scatter_nd` can be used for interleaving columns of 2D tensors, it requires careful handling of indices and shapes. An alternative and more scalable approach is to use slicing and concatenation to achieve the desired interleaving. This method avoids the complexity of manually specifying indices and is more efficient for tensors with many columns."
71129505,tf.data.Dataset,example required,"Is it possible to split a tensorflow dataset into train, validation AND test datasets when using image_dataset_from_directory?","<p>I am using <code>tf.keras.utils.image_dataset_from_directory</code> to load a dataset of 4575 images. While this function allows to split the data into two subsets (with the <code>validation_split</code> parameter), I want to split it into training, testing, and validation subsets.</p>
<p>I have tried using <code>dataset.skip()</code> and <code>dataset.take()</code> to further split one of the resulting subsets, but these functions return a <code>SkipDataset</code> and a <code>TakeDataset</code> respectively (by the way, contrary to <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#take"" rel=""nofollow noreferrer"">the documentation</a>, where it is claimed that these functions return a <code>Dataset</code>). This leads to problems when fitting the model - the metrics calculated on validation sets (val_loss, val_accuracy) disappear from model history.</p>
<p>So, my question is: is there a way to split a <code>Dataset</code> into three subsets for training, validation and testing, so that all three subsets are also <code>Dataset</code> objects?</p>
<p><strong>Code used to load the data</strong></p>
<pre><code>def load_data_tf(data_path: str, img_shape=(256,256), batch_size: int=8):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.2,
        subset=&quot;training&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    val_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.3,
        subset=&quot;validation&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    return train_ds, val_ds

train_dataset, test_val_ds = load_data_tf('data_folder', img_shape = (256,256), batch_size=8)
test_dataset = test_val_ds.take(686)
val_dataset = test_val_ds.skip(686)
</code></pre>
<p><strong>Model compilation and fitting</strong></p>
<pre><code>model.compile(optimizer='sgd',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])
history = model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=1)
</code></pre>
<p><strong>When using a normal <code>Dataset</code>, <code>val_accuracy</code> and <code>val_loss</code> are present in the history of the model:</strong></p>
<p><a href=""https://i.stack.imgur.com/Qn1Yf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qn1Yf.png"" alt=""Expected behaviour: when using a Dataset, validation metrics are calculated"" /></a></p>
<p><strong>But when using a <code>SkipDataset</code>, they are not:</strong></p>
<p><a href=""https://i.stack.imgur.com/GMnBM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GMnBM.png"" alt=""Using the SkipDataset produced by test_val_ds.take() leads to validation metrics disappearing from model history"" /></a></p>
<p><a href=""https://i.stack.imgur.com/omU5U.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/omU5U.png"" alt=""val_accuracy and val_loss are not present in history keys when using a SkipDataset or a TakeDataset"" /></a></p>
","<p>The issue is that you are not taking and skipping samples when you do <code>test_val_ds.take(686)</code> and <code>test_val_ds.skip(686)</code>, but actually batches. Try running <code>print(val_dataset.cardinality())</code> and you will see how many batches you really have reserved for validation. I am guessing <code>val_dataset</code> is empty, because you do not have 686 batches for validation. Here is a working example:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import pathlib

dataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;validation&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

test_dataset = val_ds.take(5)
val_ds = val_ds.skip(5)

print('Batches for testing --&gt;', test_dataset.cardinality())
print('Batches for validating --&gt;', val_ds.cardinality())

model = tf.keras.Sequential([
  tf.keras.layers.Rescaling(1./255, input_shape=(180, 180, 3)),
  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(5)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=1
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=1
)
</code></pre>
<pre><code>Found 3670 files belonging to 5 classes.
Using 2936 files for training.
Found 3670 files belonging to 5 classes.
Using 734 files for validation.
Batches for testing --&gt; tf.Tensor(5, shape=(), dtype=int64)
Batches for validating --&gt; tf.Tensor(18, shape=(), dtype=int64)
92/92 [==============================] - 96s 1s/step - loss: 1.3516 - accuracy: 0.4489 - val_loss: 1.1332 - val_accuracy: 0.5645
</code></pre>
<p>In this example, with a <code>batch_size</code> of 32, you can clearly see that the validation set reserved 23 batches. Afterwards, 5 batches were given to the test set and 18 batches remained for the validation set.</p>
","The issue is that you are not taking and skipping samples when you do <code>test_val_ds.take(686)</code> and <code>test_val_ds.skip(686)</code>, but actually batches. Try running <code>print(val_dataset.cardinality())</code> and you will see how many batches you really have reserved for validation. I am guessing <code>val_dataset</code> is empty, because you do not have 686 batches for validation.","<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import pathlib

dataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;validation&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

test_dataset = val_ds.take(5)
val_ds = val_ds.skip(5)

print('Batches for testing --&gt;', test_dataset.cardinality())
print('Batches for validating --&gt;', val_ds.cardinality())

model = tf.keras.Sequential([
  tf.keras.layers.Rescaling(1./255, input_shape=(180, 180, 3)),
  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(5)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=1
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=1
)
</code></pre>","['How to split a TensorFlow Dataset into training, validation, and test sets using tf.data API?', 'How to use tf.keras.utils.image_dataset_from_directory to create three subsets: training, validation, and test?', 'How to handle SkipDataset and TakeDataset in TensorFlow for model training and validation?', 'How to ensure validation metrics are calculated when using SkipDataset and TakeDataset in TensorFlow?', 'Best practices for splitting image datasets into training, validation, and test sets in TensorFlow', 'How to use tf.data.Dataset.skip() and tf.data.Dataset.take() correctly for model validation in TensorFlow?', 'How to maintain validation metrics in TensorFlow model history when using custom dataset splits?']","['How to split a TensorFlow Dataset into training, validation, and test sets?', 'How to use tf.data.Dataset.skip() and tf.data.Dataset.take() without losing validation metrics in model history?', 'How to ensure validation metrics are calculated when using SkipDataset and TakeDataset in TensorFlow?', 'Best practices for splitting image datasets into training, validation, and test sets using tf.keras.utils.image_dataset_from_directory', 'How to maintain Dataset object type when splitting datasets in TensorFlow?']","{'https://www.youtube.com/watch?v=oW89weRFJj8', 'https://www.youtube.com/watch?v=U8Ixc2OLSkQ', 'https://www.youtube.com/watch?v=bqeUmLCgsVw'}","['""""""[Document(page_content=""hello explorers and welcome to another\\nvideo today I\'m gonna talk a little bit about TF data or tensorflow data and\\nthis come about because I watched the tensorflow summit and they talked a lot\\nabout tensorflow data and this new API that you can use to actually make\\nthings easy for yourself easily read data into a system and easily make\\nbetter performant models and I thought that that was really interesting so I\\nwanted to try it out so I went to their home page and looked at the\\ndocumentation and I thought it was quite hard to follow\\nso I actually wanted to make this video to give you an understanding on how you\\ncan set it up and how you can get started much quicker than I actually got\\nand everything that I will show today is up on my github so you can see it there\\nand let\'s get started we are talking about code and first off we have two\\nfeature functions here and these are just wrapper functions that will take\\nsome value and wrap it inside of a byte list or an int 64 list so an int of size\\n64 so these are just some simple functions to make features of data and\\nthen we have this little load image function it takes an image it resizes it\\nto one size and then changes the color to RGB so that\'s what I want my image to\\nbe when I actually are working with them and all the images that I load today\\ncome from a data set that were a competition of some sort to train cats\\nand dogs images and see if we can figure out what\'s a cat what\'s a dog and\\nyeah alone and this image set has a lot of different sizes of images and so on\\nso if you actually want make this viable set you should actually\\nlook at the images maybe filter some of them out maybe do some pre steps in\\nthe images to actually make the classification more viable and and get a\\nbetter trained model and usually when you\'re working with datasets you really\\nwant to find good solutions to actually clean up your datasets as much as\\npossible and of course if you want to find things in dirty datasets then you\\nmight might want to train with dirty datasets as well but as we don\'t build a\\nfunction that will find let\'s say a dog in an image we just want to see if this\\nis an image of a dog then it might be better to do that beforehand and then we\\nhave the next function here will actually create a data record and these\\nare the TF record files that the data TF data will use when it reads in TF data\\ncan read CSV files and other files but they are good at reading binary TF\\nrecords so these this is the way to create those and you create a\\nwriter from Python io TF record right there\\nand the output file name and then I have an little function here so I go through\\nall the addresses of all the images and I take a little print out each thousand\\nthat I do because there are think twenty five thousand images so we could be good\\nto have some progress you know how much you have actually read I load the image I\\ntake the label for that image if I didn\'t get any image then skip this one\\nand then I create a new feature with the wrapping of bytes for the image and then\\nI wrap the label with an int 64 and then I create an example so I wrap everything\\nin the feature with a which I wrap in an example\\nthat example I will serialize to the writer and write out the file and what\\nI\'ve done I close to the file and I\'m and flush everything out and when I\\ncreate this you will get three different files I will look at those\\nlater and those are in the range of eight gigabytes and to gigabytes so\\nthey\'re quite large so you need to have some space on your disk if you want to\\nrun this example and then I set up at path a glob to where my images are so in\\nmy directory pet images I have cats and dogs so this star here is the\\ncat directory and the dog directory and then I have some jpegs and all the\\njpegs are one two three four five dot jpg and I read the addresses from\\nthis glob command and the labels will actually take the address and then look\\nif the address has the word cat in it so if the directory is cat you will set 0\\nin the label else it will get a 1 in the label and we\'ll have created these I\\nwill actually zip these together and create a list I will shove that list and\\nthen I will unzip that list again so I will actually get the address and labels\\nback it\'s a really neat feature in Python actually I didn\'t know that you\\ncould do things like this I\'m not usually writing that much Python code so\\nit was really nice to see this another nice feature that you see down here is\\nwhere I split up my training set into 60%\\ntraining 20% validation and 20% test data it\'s very easily done with these\\narray ranges and when I\'ve done this I will create records for the training\\naddresses their validation addresses and the testing addresses and I will put\\nthose in different files with their labels\\nso what I\'ve done that prepared the data and have these large files then we will\\ngo into the training part of of this video so this is the training and we\\nfirst off look at setting up a new session and initializing the global\\nvariables and then I have this parse function I have up here and that will\\nactually take one record from the TF record file and parse it out so I\\nactually get the label and the image out so first off I need to say what kind of\\nfeatures I actually had in my file I have this image raw and the label and these\\nare strings and int 64 so this is just to define how the data structure in the\\nfile is set up and then I will read one record from the file and then I will\\ntake the image raw part out and take bites out of it and decode the raw image\\nhere I will cast the image to floats because that\'s what the model needs and\\nI will also reshape the image so it actually is in the shape of the size of\\nthe image so it\'s at 224 times 224 and three colors or a depth of three and\\nthen I will read out the label and I will cast that to int 32 because that\\nwill be used in the model as well and that I will return that from my parser\\nand the estimate I will use later will need an input function and I will create\\nthis input function from this helper function I have here and it will first\\noff create my data record so this is a dataset of the TF record so this is the\\nTF data we talked about earlier that you could do a lot of performance\\nenhancements on and so on since this is the API that I want to do showcase in\\nthis video and also I created my data set I will map it through my parser so I\\nactually will parse the labels and the images\\nand if I\'m in training that I will shuffle them up and if not in training I\\nwill only repeat ones and not shuffle them because I want to have a\\ngood evaluation every time the same and then I will repeat and setup the\\nbatch size the batch size is 32 in this case I make a one-shot in iterator and I\\nget the batch of the iterators and return that batch back to the training\\nfunction so then I set up a training function here with the train records and\\nthe test records and I set training to true and then I do the same with\\nthe validation records but I set training to false and so these are the\\ntrain input function and the validation input function and the first and you see\\nhere I have some code add commented out here it\'s just to print the image I\\nwanted to see that after had saved it down and read it again I want to see\\nthat I had this same image I can verify that I didn\'t do anything wrong in that\\nprocess and here I have feature columns that I want to run through a fully\\nconnected classifier so I set up this one and it has layers here 128 64 32\\nand 16 and so this is what was one of the networks that I tried and it has an\\nadam optimizer and I ran it through 100,000 steps and it ran I think four\\nthousand per 10 minutes so night I was able to run this little classifier and I\\ngot about forty nine fifty percent right so it was just like a coin flip\\nit was totally worthless or it wasn\'t it wasn\'t more wrong than if I just guessed\\nbut it wasn\'t good either and so that I wanted to try\\na little bit more sophisticated model so I have my model function here and I set\\nup in network that we have seen before it\'s one convolution with some\\npooling then a convolution again with some pooling we flatten the net and then\\nwe do two fully connected layers and then we take the predictions down here\\nif you want to actually do predict something so this is if we want to go\\ninto the predict mode of the estimator then we need to take out the prediction\\nand the prediction class and if not then we just put this result of the\\nnetwork into the sparse soft max cross entropy with logits function and we\\nreduce and find how much loss we have we run that through an adam optimizer and\\nwe return some metrics so we can see how accurate we are now and then we create\\nthis estimator specification down here that we actually return and in order to\\nset up a new estimate that we want to run we put our model function into it we\\ngive it a learning rate and that learning rate is used inside of the adam\\noptimizer we set the model dir so it knows where to save all the all the\\nfiles when it does snapshots and then we have a little function here while I go\\nthrough 100,000 times again but in this case I actually want to evaluate off the\\nthousand print the result and the accuracy and then I flush it out and\\nthen I try around another pass and I\'ve run this for a little while I was a\\nlittle bit pressed on time but the best it started somewhere around 70% and I\\nthink the best result I got was 71 or 72 something like that and that could\\neither mean that I have an unclean dataset so I\\nmight want to find a good function to clean it up and maybe another function\\nto crop the images so I don\'t lose that much when I actually resize them maybe I\\nused too little image maybe I want to use larger images but that will also\\nslow down the training and maybe I could fix my model maybe I can have a better\\nmodel I\'ve just tried with this model and but that could be tweaked as well to\\nget a better performance or accuracy in the model and but I think this is a good\\nstarting point so you can see how you can set up things and actually get the\\nTF record working with tensorflow data and everything else after that is\\noptimization I hope that you found this video interesting I hope that you\\nlearned something today if you have any questions about tensorflow data or this\\nset up then please ask in the comments below all the code you can find on\\ngithub I will leave the link below as well and if you like this video give it\\na like share it with your friends and colleagues and if you haven\'t subscribed\\nyet please do that and I really hope to see you in the next video"", metadata={\'source\': \'bqeUmLCgsVw\'})]""""""', '""""""[Document(page_content=""so this will be a tutorial on how to work with images in python and how to import images and how to download image data so you can actually use it for data analysis so i have an image in my files this time so if i run it i have this part so if i now say img i i say email.show dot open and specify the parts we can have a new image opened up here but this is not a point the main thing is the image data site that is actually available in google apis and then it can be useful of image analysis or data analysis using images so how do we get here so let me explain to you step by step so i\'m going to take this one away so that we can start right from the scratch so the first thing i like to do because the idea is that i want you to have ebay data site downloaded so i\'m going to open a new python notebook so the number of things you have to import the first one is always because we are going to be storing images in our file system so we also going to import p i l p i l is a library for managing images we also need to import pil or we can say from sorry let me just say from p i l import image okay so we need this to be able to open image and modify images and also we have another library called sk image that we are going to be using later in port io so i\'m going to show you two ways to actually uh use images um okay i\'m also going to say from times of flow sorry import times of law as time saw flow as tf and from times of flow the data sites from times of flow data sites imports uh known second so i\'m going to import things uploaded data sites as tiny soft law data sites okay so let me run it just make sure everything is fine now there is one thing about tensorflow and sk imagine pil this have to be installed uh in your system uh in the packages for python so if you go to your anaconda let me just go to anaconda if you go to anaconda to your base here you want to make sure that tensorflow is installed and all these other things are installed so if i go to install right now you can see tensorflow installed but if it\'s not installed you go here and search for it and then you have to install it so for instance if i go to check here okay so you can see sk image right here so this is how you install packages uh in your python or directory or as part of the packages so just in case something fails yeah know that that is exactly how you are going to use it install it using anaconda all right let\'s now download a set of images and to do that i\'ll have to also import one more library called path lib part slide now the image data site available uh as part of the uh tensorflow libraries is uh called flower photos and that is the one we are going to be using so i want to put the part here my click uh right here so let me just say data set the image data site url is going to be this let me just paste it because i copied it to my clipboard right oh sorry yeah so this is the url for the dataset for the images so you can actually check for it by actually searching for this in google okay so the next thing we want to do is to create a local directory i\'m going to say data directory now in my file system i\'m going to create a local directory tf.keras dot utils utils dot get file and save the origin of this file is going to be the data set url we created data set url and you are going to say f the name of the the name of the folder that\'s going to hold the images it\'s going to fold the name will be flower images so i\'m going to create a lookout for that called flower images and now this this folder here coming from the online repository is a tab folder so i\'m going to untie it or on zippy so i\'m going to say ontar is equal to true all right and finally uh i want to now yeah so this is what we have okay so i\'m going to say that i specify the data directory so this data directory now refers exactly to this part in my file system i\'m going to show you where this part is located so at this point the images is going to download uh to my local directory so the question you might be asking is where is this location this is the data directory where is it located so you can also you can just check for uh by entering it right here and you can see that it is located in this place all right so if i go to this directory my file system if i go to that directory uh i think it\'s a hidden directory so if i hit on my keyboard command enter dots i have the hidden directory open so if i go to keras and go to data site you can see that we have the flower photos right here and we have list of clouds downloaded to our local system right here so let\'s open some of them uh in python or code all right so let me get back here so how do we open uh this file so the first thing i\'d like to do is to get the the folder containing the roses remember we have a number of folders we have daisy we have then the neon we have roses we have some flowers we have tulips so let\'s get the roses so i\'m going to zero this is equal to the list of the data directory object data direct created and i\'m going to get the roses rosy slash star so getting all the uh all the file extension uh what is png or jpeg is going to be here so if you want to look at what is the roses here it\'s going to just be always giving us an empty directory all right so i\'m going to kind of repeat the same process so we have flower photos okay so let me see uh and here i have flower image um so that is a problem so let me just change it to flower photos flower photos okay so that\'s going to be my data directory so i\'m going to just kind of copy this i\'m going to just execute this one more time and i think i should have it at this point so let\'s see all right so if i run this and run this and run this now you can see that we have uh the result here so if i zero this you can see it gives us the directory to all the images in the roses directory all right so how do we then display the actual images right here there are a number of ways to do it let me show you the easy way first and later i\'m going to show you a different way so let\'s start by saying uh i\'m going to simply say i i\'m going to say image.open and specify the directory for a particular image so for one particular rose i\'m going to say str because to convert exposes parts to actual parts you\'re going to use a string so i\'m going to convert it by saying rows is specify zero so at this point i should be able to see one image so again i can just change this to one to see some other image and so we have the image of our roses showing up here that is fine now i would like us to display this image in a grid view okay so i\'m going to do now is i\'m going to create r1 is equal to io that i am read now if you use i am read it\'s going to get the image image meta metadata into this variable i\'m calling it r1 so img i am read is a library as part of the i o which we imported uh from sk image right here so it\'s for reading images installing your files in your files this time so uh it\'s going to be so basically we are going to be taking this right here so this is uh for the first one and we are going to be changing it up so this case we have zero and let\'s let me just create four different image images i\'m gonna be displaying them in a grid uh of four of a grid a grid of four images so it\'s going to be four and let me just change this one to one this one to two on base one to three so i\'m going to run and this is fine so i want to display this image in a grid view using matplotlib so i\'m going to create a figo i\'m going to say the figure i\'m going to create is they call the plt that\'s a mud plot like the pipeline figure i think you should know about this by now so i\'m going to use a fixed size of 15 and 20 okay so it\'s gonna be fixed size is equal to 1520 i don\'t want to make any mistake here so is this plt ah so so i\'m going to before i do that i\'m going to say imports mud plots live that\'s pi plots as plt i\'m gonna now run so we have this uh figure created so i\'m gonna create some plots i\'m gonna create a subplot ax one ax one is equal to f uh fig the art subplots so if you look at the link in the description box you\'ll see a link to be explained soft plots all right so we want one column and four rows so it\'s going to be four rows and i want to display image one i\'m going to say x one dot i am show and it\'s going to be our bump so i\'m going to run it now and it says add sub so i think there\'s an error add some plots add softwares okay so you can see it display the first image so basically you can just copy this on uh paste and just change the numbers so i\'m gonna paste paste paste so here i\'m gonna display this is r1 r2 it\'s gonna be r2 and here we have r3 and here i have r4 so one four one one four two and here one four three and this is going to be 1 4 4 and this is going to be ax 1 this is going to be x 2 2 and here is going to be a x 3 a x 3 and here it\'s going to be x 4 x x4 um yeah this is fine so i\'m going to run everything and now you can see display uh the images correctly so you can actually repeat the same process and display it in a second grid of several grid and frozen columns so check in this description box you\'ll see how to work with subplots and this is basically how to display images so how many ways have i showed you i\'ve showed you the first way simply use img.open and it\'s going to open this image or you can use img read i am read and then display the images using subplots using i am show all right i\'m going to be stopping here uh later on i\'m going to be showing you how to actually analyze images i\'ve done a bit of this in our previous tutorial i put the link in the description box on how to analyze handwriting uh images using tensorflow so please remember to subscribe to my channel and feel free to leave me a comment if this has been informative for you"", metadata={\'source\': \'oW89weRFJj8\'})]""""""', '""""""[Document(page_content=""hey I\'m maybe from deep lizard in this episode we\'ll demonstrate how we can use tensorflow scarus API to create a validation set on the fly during training before we demonstrate how to build a validation set using Kerris let\'s first talk about what exactly a validation set is so whenever we train a model our hope is that when we train it that we see good results from the training output that we have low loss and high accuracy but we don\'t ever train a model just for the sake of training it we want to take that model and hopefully be able to use it in some way on data that it wasn\'t necessarily exposed to during the training process and although this new data is data that the models never seen before the hope is that the model will be good enough to be able to generalize well on this new data and give accurate predictions for it we can actually get an understanding of how well our model is generalizing by introducing a validation set during the training process to create a validation set before training begins we can choose to take a subset of the training set and then separate it into a separate set labeled as validation data and then during the training process the model will only train on the training data and then we\'ll validate on the separated validation data so what do we mean by validating well essentially if we have the addition of a validation set then during training the model will be learning the features of the training set just as we\'ve already seen but in addition in each epoch after the model has gone through the actual training process it\'ll take what it\'s learned from the training data and then validate by predicting on the data in the validation set using only what it\'s learned from the training data though so then during the training process when we look at the output of the accuracy and loss not only will we be seeing that accuracy and loss computed for the training set we\'ll also see that computed on the validation set it\'s important to understand though that the model is only learning on or training on the training data it\'s not taking the validation set into account during training the validation set is just for us to be able to see how well the model is able to predict on data that it was not exposed to during the training process in other words it allows us to see how general our model is how well it\'s able to generalize on data that is not included in the training data so knowing this information will allow us to see if our model is running into the famous overfitting problem so overfitting occurs when the model has learned the specific features of the training set really well but it\'s unable to generalize on data it hasn\'t seen before so if while training we see that the model is giving really good results for the training set but less than good results for the validation set then we can conclude that we have an overfitting problem and then take the steps necessary to combat that specific issue if you\'d like to see the overfitting problem covered in more detail then there is an episode for that in the deep learning fundamentals course all right so now let\'s discuss how we can create and use a validation set with a Karass sequential model there\'s actually two ways that we can create and work with validation sets with a sequential model and the first way is to have a completely separate validation set from the training set and then to pass that validation set to the model in the fit function there is a validation data parameter and so we can just set that equal to the structure that is holding our validation data and there\'s a write-up in the corresponding blog for this episode that contains more details about the format that that data needs to be in but we\'re going to actually only focus on the second way of creating and using a validation set this step actually saves us a step because we don\'t have to explicitly go through the creation process of the validation set instead we can get carers to create it for us all right so we\'re back in our Jupiter notebook right where we left off last time and we\'re here on the model dot Fit function and recall this is what we use last time to train our model now I\'ve already edited this cell to include this new parameter which is validation split and what validation split does is it does what it sounds like it splits out a portion of the training set into a validation set so we just set this to a number between 0 and 1 so just a fractional number to tell Karis how much of the training set we need to split out into the validation set so here I\'m splitting out 10% of the training set so it\'s important to note that whenever we do this the validation set is completely held out of the training set so the training samples that we remove from the training set into validation set are no longer contained within the training data any longer so using this approach the validation set will be created on the fly whenever we call the fit function now there\'s one other thing worth mentioning here and remember last time I discussed this shuffle equals true parameter and I said that by default the training set is shuffled whenever we call fit so this shuffle equals true is already set by default but I was just bringing it up to let you know that that the training set is being shuffled so that is a good thing we want the training set to be shuffled but whenever we call validation split in this way this split occurs before the training set is shuffled meaning that if we created our training set and say we put all of the sick patients first and then the non sick patients second and then we say that we want to split off the last 10% of the training data to be our validation data it\'s going to take the last 10% of the training data and therefore it could just take all of the the second group that we put in the training set and not get any of the first group so I wanted to mention that because although the training data is being shuffled with the fit function if you haven\'t already shuffled your training data before you pass it to fit then you also use the split parameter it\'s important to know that your validation set is going to be the last X percent of your training set and therefore may not be shuffled and may yield some strange results because you think that everything has been shuffled when really it\'s only the training set has been shuffled after the validation set has been taken out so just keep that in mind the way that we created our training set before this episode we actually shuffled the training data before it\'s ever passed to the fit function so in the future whenever you\'re working with data it\'s a good idea to make sure that your data is also shuffled beforehand especially if you\'re going to be making use of the validation split parameter to create a validation set all right so now we\'ll run this cell one more time calling the fit function but this time not only will we see loss and accuracy metrics for the training set we\'ll also see these metrics for the validation set all right so the model has just finished running it\'s 30 epochs and now we see both the loss and accuracy on the left-hand side as well as the validation loss and validation accuracy on the right-hand side so we can see let\'s just look at the accuracy between the two they\'re both starting at around the same 50 percent mark and going up gradually around the same rate so we just scroll all the way to our last epoch we can see that the accuracy and validation accuracy are pretty similar with only one percent difference between the two and yeah the loss values are similar as well so we can see in this example that our model is not overfitting it is actually performing pretty well or just as well rather on the validation set as it is on the training set so our model is generalizing well if however we saw that the opposite case was true and our validation accuracy was seriously lagging behind our training accuracy then we know that we have a overfitting problem and we would need to take steps to address that issue alright so we\'ve now seen how to train the model how to validate the model and how to make use of both training and validation that\'s in the next episode we\'re going to see how to make use of a third data set the test data set to use the model for inference by the way we are currently in Vietnam filming this episode if you didn\'t know we also have a vlog channel where we document our travels and share a little bit more about ourselves so check that out at people\'s our vlog on YouTube also be sure to check out the corresponding blog for this episode along with other resources available on deep loser calm and check out the people\'s archive mine where you can gain exclusive access to perks and rewards thanks for contributing to collective intelligence I\'ll see you next time [Music] [Music]"", metadata={\'source\': \'U8Ixc2OLSkQ\'})]""""""']","{'https://stackoverflow.com/questions/71704268/using-tf-keras-utils-image-dataset-from-directory-with-label-list', 'https://stackoverflow.com/questions/48213766/split-a-dataset-created-by-tensorflow-dataset-api-in-to-train-and-test', 'https://stackoverflow.com/questions/41859605/split-tensor-into-training-and-test-sets', 'https://stackoverflow.com/questions/73044151/how-to-use-tf-keras-utils-image-dataset-from-directory-to-load-test-dataset'}","['""""""How to use tf.keras.utils.image_dataset_from_directory to load test dataset? Asked 1 year, 10 months ago\n\nI am using tf.keras.utils.image_dataset_from_directory in my binary classification Mobilenet V2 model to split the dataset by defining training and validation subsets as following:\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(directory, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, validation_split=0.2, subset=\'training\', seed=42) validation_dataset = tf.keras.utils.image_dataset_from_directory(directory, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, validation_split=0.2, subset=\'validation\', seed=42)\n\nNow, I want to use model.predict() on a set of images to look at the predictions. How can I use image_dataset_from_directory considering that there won\'t be two different folders containing the respective classes but only one folder for which I want the predictions? In addition, what should be the parameters of the image_dataset_from_directory function now? You need to have a separate directory containing test images. Then do the same thing you did for train/val datasets but with shuffle=False and without validation_split. As mentioned by @Djinn, You can do it in the same way and no need to define validation_split while accessing the folder. For example, Suppose I have a binary_data folder inside the dogs_cats/binary_data folder where I have stored multiple class images (5-5 images for each cats and dogs), then you can give the path till dogs_cats. This will automatically fetch all images inside the binary_data folder by stating class 1 where you can have multiple class images(binary - as per model) stored. After training the model, you can pass this dataset in model.predict() and can check the predictions for each image. Please check the below code:\n\ntest_dataset = tf.keras.utils.image_dataset_from_directory( ""/content/GoogleDrive/My Drive/MY WORK/dataset/dogs_cats/"", shuffle=True, #or False batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n\nFound 10 files belonging to 1 classes. and the predictions part:\n\npredictions = model.predict(test_dataset) predictions = tf.where(predictions < 0.5,0, 1) print(\'Predictions:\\n\', predictions.numpy())\n\nPredictions: [[0] [1] [0] [0] [1] [1] [1] [1] [1] [1]]\n\nNote: Prediction\'s accuracy may depend on the model performance. user11530462user11530462\n\nGood to know that.""""""', '""""""I hope it better answers your question. use Keras - model.fit(dataset,.., validation.split=0.7, ...) see its all possible arguments\n\n\n\nAssuming you have all_dataset variable of tf.data.Dataset type:\n\ntest_dataset = all_dataset.take(1000) train_dataset = all_dataset.skip(1000)\n\nTest dataset now has first 1000 elements and the rest goes for training. 1,3\n\nAs also mentioned in ted\'s answer, adding all_dataset.shuffle() allows for a shuffled split. Possibly add as code comment in answer like so? # all_dataset = all_dataset.shuffle() # in case you want a shuffled split\n\n\n\nTensorFlow 2.10.0 will have a utility function for splitting, see my answer: stackoverflow.com/a/73591823/1389680\n\n\n\ntake and skip return TfTakeDatasets/SkipDatasets which have less functionality than TfDatasets. Does anyone know how to map those to tfDatasets or split into train test splits and get back TfDataset objects? You may use Dataset.take() and Dataset.skip():\n\ntrain_size = int(0.7 * DATASET_SIZE) val_size = int(0.15 * DATASET_SIZE) test_size = int(0.15 * DATASET_SIZE) full_dataset = tf.data.TFRecordDataset(FLAGS.input_file) full_dataset = full_dataset.shuffle() train_dataset = full_dataset.take(train_size) test_dataset = full_dataset.skip(train_size) val_dataset = test_dataset.skip(val_size) test_dataset = test_dataset.take(test_size)\n\nFor more generality, I gave an example using a 70/15/15 train/val/test split but if you don\'t need a test or a val set, just ignore the last 2 lines. Creates a Dataset with at most count elements from this dataset. Creates a Dataset that skips count elements from this dataset. You may also want to look into Dataset.shard():\n\nCreates a Dataset that includes only 1/num_shards of this dataset. Disclaimer I stumbled upon this question after answering this one so I thought I\'d spread the love\n\n 7\n\nThank you very much @ted! Is there a way to divide the dataset in a stratified way? Or, alternatively, how can we have an idea of the class proportions (suppose a binary problem) after the train/val/test split? Thanks a lot in advance! Have a look at this blogpost I wrote; eventhough it\'s for multilabel datasets, should be easily usable for single label, multiclass datasets -> vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow\n\n\n\nThis causes my train,validation and test datasets to have overlap between them. Is this supposed to happen and not a big deal? I would assume it\'s not a good idea to have the model train on validation and test data. @c_student I had the same problem and I figured out what I was missing: when you shuffle use the option reshuffle_each_iteration=False otherwise elements could be repeated in train, test and val\n\n\n\nThis is very true @xdola, and in particular when using list_files you should use shuffle=False and then shuffle with the .shuffle with reshuffle_each_iteration=False. | Show 2 more comments\n\nMost of the answers here use take() and skip(), which requires knowing the size of your dataset before hand. This isn\'t always possible, or is difficult/intensive to ascertain. Instead what you can do is to essentially slice the dataset up so that 1 every N records becomes a validation record. To accomplish this, lets start with a simple dataset of 0-9:\n\ndataset = tf.data.Dataset.range(10) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nNow for our example, we\'re going to slice it so that we have a 3/1 train/validation split. Meaning 3 records will go to training, then 1 record to validation, then repeat. split = 3 dataset_train = dataset.window(split, split + 1).flat_map(lambda ds: ds) # [0, 1, 2, 4, 5, 6, 8, 9] dataset_validation = dataset.skip(split).window(1, split + 1).flat_map(lambda ds: ds) # [3, 7]\n\nSo the first dataset.window(split, split + 1) says to grab split number (3) of elements, then advance split + 1 elements, and repeat. That + 1 effectively skips the 1 element we\'re going to use in our validation dataset. The flat_map(lambda ds: ds) is because window() returns the results in batches, which we don\'t want. So we flatten it back out. Then for the validation data we first skip(split), which skips over the first split number (3) of elements that were grabbed in the first training window, so we start our iteration on the 4th element. The window(1, split + 1) then grabs 1 element, advances split + 1 (4), and repeats. Note on nested datasets: The above example works well for simple datasets, but flat_map() will generate an error if the dataset is nested. To address this, you can swap out the flat_map() with a more complicated version that can handle both simple and nested datasets:\n\n.flat_map(lambda *ds: ds[0] if len(ds) == 1 else tf.data.Dataset.zip(ds))\n\n 7\n\nDoesn\'t window just use skip under the hood? How does is the disadvantage The other disadvantage is that with skip() it has to read, and then discard, all the skipped records, which if your data source is slow means you might have a large spool-up time before results are emitted. adressed? If you have a dataset of 1000 records, and you want a 10% for validation, you would have to skip the first 900 records before a single validation record is emitted. With this solution, it only has to skip 9 records. It does end up skipping the same amount overall, but if you use dataset.prefetch(), it can read in the background while doing other things. The difference is just saving the initial spool-up time. Thinking about it a bit more, and I removed the statement.""""""']","To address the question of splitting a TensorFlow dataset into training, validation, and test subsets when using `tf.keras.utils.image_dataset_from_directory`, it is indeed possible to achieve this by leveraging the `skip` and `take` methods from the `tf.data.Dataset` API. The `image_dataset_from_directory` function allows splitting the dataset into two subsets using the `validation_split` parameter, but to further split one of these subsets into additional subsets, you can use the `skip` and `take` methods.

The `skip` method creates a dataset that skips a specified number of elements from the original dataset, while the `take` method creates a dataset that takes a specified number of elements from the original dataset. Although these methods return `SkipDataset` and `TakeDataset` objects respectively, they are still subclasses of `tf.data.Dataset` and can be used in the same way as any other dataset.

To split the dataset into three subsets, you can first use `image_dataset_from_directory` to create the initial training and combined validation/test datasets. Then, apply the `take` method to extract the test dataset from the combined validation/test dataset, and use the `skip` method to obtain the remaining validation dataset. This approach ensures that all three subsets are `tf.data.Dataset` objects, which can be used for model training, validation, and testing.

When fitting the model, ensure that the validation dataset is correctly passed to the `validation_data` parameter in the `model.fit` method. This will allow the model to calculate and report validation metrics such as `val_loss` and `val_accuracy` during training.

In summary, by using the `skip` and `take` methods, you can effectively split a dataset into training, validation, and test subsets while maintaining the integrity of the `tf.data.Dataset` objects, ensuring that the model's validation metrics are correctly calculated and reported."
