QuestionId,QuestionAPI,IssueType,Title,Question,GroundTruth,GT_Explain,GT_Code,yt_queries,so_queries,yt_urls,yt_transcripts,so_urls,contexts
51586693,tf.gather,example required,"Tensor has shape [?, 0] -- how to reshape to [?,]","<p>When <code>src</code> has shape <code>[?]</code>, <code>tf.gather(src, tf.where(src != 0))</code> returns a tensor with shape <code>[?, 0]</code>. I'm not sure how a dimension can have size 0, and I'm especially unsure how to change the tensor back. I didn't find anything in the documentation to explain this, either.</p>

<p>I tried to <code>tf.transpose(tensor)[0]</code>, but the first dimension of the transposed tensor has size 0 and cannot be accessed! What's wrong?</p>
","<p>I think you should use <a href=""https://www.tensorflow.org/api_docs/python/tf/not_equal"" rel=""nofollow noreferrer""><code>tf.not_equal</code></a> to perform elementwise comparison on the tensor.</p>

<pre><code>src = tf.constant([0, 1, 1, 0], dtype=tf.int8)
tf.gather(src, tf.where(tf.not_equal(src, 0))).eval(session=tf.Session())

array([[1],
       [1]], dtype=int8)
</code></pre>

<p>You can also shorten this a bit and use <a href=""https://www.tensorflow.org/api_docs/python/tf/boolean_mask"" rel=""nofollow noreferrer""><code>tf.boolean_mask</code></a> instead of <code>tf.where</code> and <code>tf.gather</code>:</p>

<pre><code>tf.boolean_mask(src, tf.not_equal(src, 0)).eval(session=tf.Session())
array([1, 1], dtype=int8)
</code></pre>

<p>Note the difference in the shape of the outputs.</p>
",,"<pre><code>src = tf.constant([0, 1, 1, 0], dtype=tf.int8)
tf.gather(src, tf.where(tf.not_equal(src, 0))).eval(session=tf.Session())

array([[1],
       [1]], dtype=int8)
</code></pre>","['Understanding tf.gather and tf.where in TensorFlow', 'Handling tensors with zero dimensions in TensorFlow', 'How to reshape tensors in TensorFlow', 'Common issues with tf.gather and tf.where in TensorFlow', 'TensorFlow: Working with sparse tensors and zero values', 'TensorFlow: Reshaping and manipulating tensor dimensions', 'TensorFlow: Dealing with unexpected tensor shapes', 'TensorFlow: Practical examples of tf.gather and tf.where']","['Why does tf.gather(src, tf.where(src != 0)) return a tensor with shape [?, 0]?', 'How can I reshape a tensor with shape [?, 0] to a valid shape in TensorFlow?', 'What is the correct way to filter out zero elements from a tensor in TensorFlow?', 'How to use tf.where and tf.gather correctly to avoid getting a tensor with shape [?, 0]?', 'What are the best practices for handling tensors with dynamic shapes in TensorFlow?']","{'https://www.youtube.com/watch?v=WLtkPIrCs9Y', 'https://www.youtube.com/watch?v=ukBG9ALd8T8'}","['""""""[Document(page_content=""JASON MAYES: So\\nbefore you move on to using the second\\ntype of pre-made model, you need to understand a\\nvery important concept known as a tensor. TensorFlow is, after\\nall, named after it. So as you may have guessed,\\nit\'s pretty key to a subject. So let\'s find out some more. Now, the very first\\nthing you\'ll find, if you look at the TensorFlow.js\\nAPI as shown on this slide, is this thing called a tensor. And tensors are the\\nprimary data structure in TensorFlow programs. Machine-learning\\nmodels literally take tensors as inputs,\\nmanipulate them in some way, and then spit out\\ntensors as outputs. You can think of them as\\nbeing similar in structure to an array. And just like arrays, they\\ncan have multiple dimensions. But tensors almost always\\nonly contain numerical data, unlike regular\\nJavaScript arrays, that could contain a\\nwhole mix of objects that you might use or invent. Furthermore, the\\ntensor class, itself, has a whole bunch\\nof useful functions that can assist in transforming\\nthem into different sizes or dimensions, or doing math\\nupon the numbers contained inside them, and much more. Basically, an array\\nextended with super powers. Now, this flow of tensors for a\\nmachine-learning model is where TensorFlow gets its name from-- essentially, the flow of\\ntensors through the model. Now, I mentioned tensors\\ncan have multiple dimensions just like arrays. Let\'s quickly recap\\nwhat this looks like, and the slightly different\\nterms you might hear when speaking about tensors. First, the most\\nsimple is some data that has no dimensions, a\\nsingle value, if you will, also known as a scalar value in\\nmathematics-- like the number six. Here, you can see\\na little bucket of memory shown in orange\\ncontaining the single number all by itself. Now, machine-learning folk\\nlike to describe dimensionality in terms of a word called rank. So here, the tensor\\nhas a rank of zero-- which simply means it has\\nzero dimensions, or axes, if you prefer. In JavaScript code,\\nyou\'ve used scalar values like this over time. For example, when you\\ncreate a variable, and assign it a single\\nnumber as a value-- like let value equals 6,\\nas shown on this slide. Using the TensorFlow.js\\nAPI, you can instead call tf.scalar, and pass\\nit the number directly to return a tensor\\nholding that number. Next, you can have a\\none-dimensional tensor. You can think of this\\nas a list of numbers, just like a\\none-dimensional array. And mathematicians would\\ncall this collection of numbers a vector. And when constructed\\nas a tensor, TensorFlow folk would call\\nthis a rank one tensor, as it uses a\\none-dimensional array to store those three numbers. It should be noted,\\nhowever, that in this case, the vector data stored\\nis three dimensional-- it has three numbers in the array. Those numbers could\\nrepresent a single coordinate in 3D space-- in x, y,\\nand z, respectively. So in that sense, the data,\\nitself, is three dimensional. Now, do not confuse a 3D\\nvector with a 3D tensor. In the prior example,\\nthe vector is 3D as it contained three numbers. But for tensor holding that\\ndata was one-dimensional, or 1D. If you had four numbers in the\\narray, the vector would be 4D, but the tensor would still be\\none dimensional with rank one. So for term of\\ndimensionality can represent one of two things,\\nas you just saw. It can either denote\\nthe number of elements along a specific\\naxes of a tensor-- like the 3D vector\\nthat you just saw-- or the number of\\naxes in a tensor. In this case, it was one,\\nas the container is just a standard\\none-dimensional array. Here, you can\\nvisualize the array as a list of numbers\\nin memory, all going in one dimension,\\nas shown on the right. In JavaScript code, you probably\\nused a one-dimensional array over time to store\\nvalues as shown. Using the TensorFlow.js API, you\\ncan instead call tf.tensor1d, and pass it to one-dimensional\\narray of numbers instead, to return a tensor of\\nrank one holding those numbers. Up next is two\\ndimensional tensors. Imagine you had a\\ngrayscale image. Every pixel in the image would\\nhave a value from zero to 255, representing different shades\\nof gray the computer could draw. Now, each pixel has\\nan x and y location somewhere on that 2D image. So to store those\\nvalues whilst retaining the correct positions,\\nyou might choose to store this data as\\na two-dimensional array in your code. Now, mathematicians\\ncall this a matrix. And TensorFlow folk would\\ncall this a rank 2 tensor. Here, you can\\nvisualize the array as a rectangle or square of\\nnumbers as shown on the right. In JavaScript code, you may have\\nalready used 2D arrays already, like the code shown, to\\nstore some data for an image, or maybe even a\\nboard game state, for example, to keep\\ntrack of what pieces is in what location of the board. Now, using the\\nTensorFlow.js API, you can call\\ntf.tensor2d and pass it with two-dimensional\\narray of numbers to return a tensor of rank\\n2, holding those numbers. And in a similar manner,\\nthree-dimensional tensors also exist. A great example of this is a\\nregular, full-color RGB image. You may think images\\nare two-dimensional, which, for the purposes\\nof grayscale images, that\'s pretty true. However, a color image is\\nmade of red, green, and blue channels. Each pixel, therefore,\\nneeds three numbers to produce the color that\\nyou see on your screen with the correct mixture\\nof red, green, and blue. So to store the data\\nfor a color image, you actually need a\\nrank 3 tensor, as shown. This example essentially\\nshows a 3 by 3 pixel RGB image stored in memory, where one\\nlayer could be the red values, layer two of green, and\\nlayer three the blue. To visualize this, you can\\nthink of many 2D layers stacked together to create a 3D\\nshape, like this cube on the right-hand side, with\\neach sub-cube containing a number in this case. Hopefully by now, you\\ncan see the pattern in the code, where\\nas you increase the number of dimensions,\\nyou\'re essentially nesting more arrays inside each other. And the TensorFlow.js code\\njust calls tf.tensorxd, where x is the\\nnumber of dimensions that you have, up\\nto a maximum of six. You then pass\\nthrough that function the multidimensional\\narray of numbers, which will return a\\ntensor whose rank is the same as the\\ndimensions required. Visualizing beyond\\n3D is sort of tricky. So I\'ve tried my best here\\nto draw some visualizations to help you see how\\nthis works in terms of the nesting of\\narrays in a visual way. A rank 4 tensor\\nstructure is simply an array of three-dimensional\\narrays that you just saw. Here, you can see a light\\nblue container representing the fourth dimension,\\nwhich itself contains a collection of\\n3D arrays like the ones you saw on the previous slide. Now I\'ve not written\\nthe code for this, as it\'s hard to fit\\non a single slide, but the principle is the\\nsame as you previously saw. Hopefully, this\\nvisualization helps illustrate what\'s going on. And a common use case\\nfor this sort of data would be video data that\\ncontains a time element. Here, you can see that\\na video after all, is just an ordered set\\nof RGB images over time. And in the example\\nshown here, you can see that you have\\nthree, 3 by 3 pixel RGB images stored over time. Each with a red, green, and blue\\nchannel, one after each other, and all contained\\nwithin the new array. And yes, you can go further. A rank 5 tensor is\\nshown here, building upon the previous\\nexample, which is like having a batch of videos. Here, you can see how each\\nvideo from the prior slide is now stacked inside a new\\narray containing them all. And it should be noted\\nthat there are also some real-world scenarios\\nthat might need a rank 5 tensor to store their\\ndata from sensors that are more advanced\\nthan regular webcams, or when using very specific data\\ntypes, say, in the 3D industry. One potential example\\nwould be storing voxels, which simply is\\na fancy word for saying three-dimensional pixels. Lets look into this deeper. In the image on\\nthe right, you can see a screenshot of the popular\\ncomputer game called Minecraft. This digital world\\nis represented by a whole bunch of cubes that\\nare essentially the smallest subdivision of the 3D world\\nspace that you can have, which is known as a voxel. Just like the smallest\\nsubdivision of a 2D space is known as a pixel\\nfor regular images. Now, each one of these voxels\\nhas a specific color value, representing different\\nobjects in the game. But the users can manipulate\\nto create and build whatever they want. Now, if you were to store a\\nportion of this Minecraft world in the form of a\\ntensor, each voxel may need to store the RGB\\ncolor value it represents. As free values would\\nneed to be stored in a one-dimensional array, this\\nwould be the first dimension-- the color of the voxel. This voxel now needs to be\\nassigned a location in the game world, for example\\nin x, y, and z. Which means you need a second,\\nthird, and fourth dimension, respectively, so you can\\ntrack the coordinates of where that voxel is\\nlocated in three dimensions. And finally, if you were\\ncoding these values over time, you would even need\\nthe fifth dimension to store frames of this data. You can think of\\nthis as an animation that records changes\\nto the voxels, but you can then play back\\nover some time interval. And last but not least, you\\nmight summon a rank 6 tensor-- this is the highest rank tensor\\nthat TensorFlow supports. Realistically, you\\nprobably won\'t ever need to use it for\\nmost situations, but know that it exists. Continuing the\\nprevious rank 5 example for recording voxel\\nstates over time, you might find\\nyou need to record a batch of voxel animations to\\nsend to your model in parallel. In this case, you\'d need\\nthat sixth dimension here to do that. All right, that\'s\\nquite a bit to digest, especially as you\\ntypically only work up to three dimensions\\nin your mind. So feel free to rewind and\\nunderstand the examples provided before continuing. Now, when working\\nwith tensors, there\'s some common vocabulary you\'ll\\nhear folk often referring to. Most importantly,\\nall tensors have two fundamental properties--\\ndata type and shape. So let\'s dive into the details. Data type is the type of data\\nthat the tensor will store. For example, integers\\nwhich are just whole numbers, or floating\\npoint numbers, which are just fractional numbers\\nwith a decimal point, like 0.2. The amount of memory used\\nto store these numbers defines the range of\\nvalues that they can store. So as you can see on\\nthis slide, int-8 stores a smaller range of\\nnumbers than int-16. Now, as a JavaScript programmer\\nin the web.dev world, you may not have had to\\ndeal with specifying numbers to this level of detail before. Typically, you would\\njust say, let x equal 2, and be done with it. But in the\\nmachine-learning world, it\'s important to do so,\\nas using the wrong type could eat a ton more memory,\\nas often larger networks are dealing with millions\\nof numbers in the model. For this reason,\\nyou\'ll see typed arrays being used a lot in\\nTensorFlow.js that JavaScript also supports, even\\nthough few people need to use them normally. This not only helps\\nwith memory efficiency, but also for performance. If an array only\\nstores one type, then it can be accessed\\nmore efficiently, too, making a program as\\nfast as possible. Next, shape is the\\nlength of a number of elements, if you will, of\\neach of the axes of the tensor. In this example, you have\\nthree-dimensional tensors, as you saw before. The shape for the tense on\\nthe left would be 3 by 3 by 3. And on the one on the\\nright, which is also a three-dimensional tensor, its\\nshape might be described as 3 by 3 by 6, using\\nthe same convention. Now, rank, as you\\nsaw before, is simply the number of axes\\nthat the tensor has, or the dimensions, if you\\nprefer to think of it like that. This tensor has three axes,\\nso it has a rank of three. Axes or dimensions can be\\nindividually called up to. For example, axes two\\nin this visualization runs along the cube from the\\nleft to the right, as shown. Finally, size is just the total\\nnumber of items in the tensor. If you know the\\nshape of a tensor, you can multiply the\\nnumbers to get its size. This 3 by 3 by 3 tensor has a\\nsize of 27 on the left there, and the 3 by 3 by 6\\ntensor has a size of 54. Now, once you\'ve got\\nyour data in tensor form, you can now make use of all\\nthe powerful functions provided by the TensorFlow.js library. A few simple examples\\nare shown here. In the first line\\nof code, you can see it just creates\\na new 2D tensor and assigns it to a\\nvariable, called tensor. In a similar manner,\\nthe second line of code creates a scalar tensor\\nwith the value of 2, and assigns it to a\\nvariable called scalar. But next line shows you\\nhow you can multiply all values in the first tensor\\nwith the scalar value you just created by calling tensor.mul,\\nand passing it the scalar tensor you want to multiply by. Next, if you put the contents\\nof a new tensor just created by doing that, you can\\nsee all of the values are now double what they\\nwere in the first tensor that you created at the start. Now, you might wonder, why not\\njust use regular JavaScript to multiply all\\nthe numbers by 2? Well, simply put,\\nusing tensors means you can take advantage\\nof the faster execution on the graphics\\ncard, or other back ends, that TensorFlow.js\\nsupports, which can do many of these operations\\nin parallel or much faster than vanilla JavaScript. This means your program\\nis going to run super fast when doing these\\nsorts of operations on huge arrays of numbers. Which when you\'re\\ndealing with things like images that contain\\nmillions of numbers, that performance difference\\ncan make a huge difference in execution time. Finally, on the\\nlast line, you can see how you can even change\\nthe shape of tensors. In this case, it takes the\\n2D tensor from the first line and reshapes it into a\\none-dimensional tensor with six elements. Pretty neat. Now, these examples may not mean\\nmuch on their own right now, but later in this course, you\'ll\\nsee more useful use cases, for which these sorts of\\ntransformations-- for example, when working with image data-- and converting back\\nto being tensor form, will be input into a\\nmodel more efficiently. Now, the beauty of having these\\nstandard ways to represent data is that the library knows\\nhow it can use such data on different hardware types. As it now can rely\\nupon the fact that data will always be consistent in\\nthis well-defined tensor form. But TensorFlow.js library\\nworks on several backends, as you saw before, like\\nWebGL for the graphics card, or WebAssembly for the CPU. And this means that the library\\ncan accelerate the tensor operations that you perform\\non the desired hardware for you, without you having to\\nworry about what the tensor is actually executing on\\nyourself, saving you a lot of time and complexity\\nof writing all that code, yourself. Now, one final point I\'d like\\nto share for consideration, is that tensors need to\\nbe manually destroyed, and are not disposed of like\\nmost things in JavaScript. In regular JavaScript, if you\\ndeclare a variable-- let\'s say, x equal 1-- and then stop using\\nthe variable, x, the browser will\\nautomatically clean up the memory it used with\\nits garbage collector, freeing up the RAM and\\nresources for the computer. For a tensor, you\\nmust dispose of memory yourself manually using a\\nspecial dispose function or the convenient tf.tidy,\\nwhich will automatically dispose of any tensors created\\nwithin a given function. Now, this might come as\\na bit of a shock to you, if you\'re not used to writing\\nin other languages, like C, you have to remember to\\ndispose of variables that you create but you no\\nlonger need as standard. You\'ll learn more\\nabout putting this into practice later\\nin the course. So for now, just realize this\\nis something you\'ll need to do. Otherwise, you could\\ncause a memory leak if you keep creating\\ntensors, say, in a loop, and never dispose\\nof the old ones. Great, so with that, you now\\nhave the 101 of what tensors are, it\'s time to\\nhead back to learning how to use slightly more\\nadvanced premade models well you\'ll need to work\\nat the tensor level to pass data in and retrieve\\noutputs from such models. See you in the next section."", metadata={\'source\': \'WLtkPIrCs9Y\'})]""""""', '""""""[Document(page_content=""we start by importing tensorflow as tf then we print the version of tensorflow that we are using we\'re using tensorflow 1.5.0 in this video we\'re going to use tensorflow reshape to change the shape of a tensorflow tensor as long as the number of elements stay the same we will do three examples to show how reshape works let\'s start out with an initial tensorflow constant tensor shaped two by three by four with numerical integer values between 1 and 24 all of whom have the data type of n32 so we use tensorflow.constant we have our two by three by four tensor we have the data type as n32 and we see the numbers are one two three four all the way through 24 and we assign it to the python variable tf underscore initial underscore tensor underscore constant now that we have it let\'s print out the tf initial tensor constant python variable to see what we have we see that it\'s a tensorflow constant the shape is two by three by four the data type is n32 because we haven\'t run it in a tensorflow session yet it doesn\'t seem to have values even though we just defined it as a constant the same will apply to the other reshapes we\'re about to create for the first example let\'s go from a tensor whose shape is two by three by four to a tensor whose shape is two by twelve so we\'re going to use tensorflow.reshape we pass in the initial tensor constant and then we pass in the specifics of what we want the new shape to be so it\'ll be 2 comma 12 and we assign the whole thing to the python variable tf x 1 reshape tensor 2 by 12. note that the number of elements will stay the same as 2 times 3 times 4 is 24 and 2 times 12 is 24. let\'s print out the tfx one reshaped tensor 2 by 12 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 2 by 12 and we see that the data type is in 32. it\'s not showing any values yet because we\'re still building the tensorflow graph and we haven\'t run at any tensorflow session for the second example let\'s change a tensor whose shape is two by three by four to a tensor whose shape is two by three by two by two so we use tensorflow.reshape we pass in our initial tensor and then we specify what the shape is going to be so we pass in two comma three comma two comma 2 and we assign it to the python variable tf x 2 reshape tensor 2 by 3 by 2 by 2. note that the number of elements will stay the same as 2 times 3 times 4 is 24 and 2 times 3 times 2 times 2 is 24 as well let\'s print out the tf x to reshape tensor 2 by 3 by 2 by 2 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 2 by 3 by 2 by 2 which is what we would expect and the data type is in 32 for the third example we\'re going to change a tensorflow tensor whose shape is 2 by 3 by 4 to a vector of 24 elements and the way we do that is we use the tensorflow.reshape operation we pass in our initial tensor and here we\'re going to use a negative one so what that\'s going to do is it\'s just going to flatten the tensor so that\'s just going to be a list of 24 elements we assign it to the python variable tf x tree reshape tensor one by 24. let\'s print out the tf x tree reshape tensor one by 24 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 24 comma that means it\'s going to be a vector the data type is n32 now that we have created our tensorflow tensors it\'s time to run the computational graph first we launch the graph in a session then we initialize all the global variables in the graph in our case it\'s going to be all the tensors we\'ve created next we\'re going to print out the four tensors to see how tensorflow\'s reshape works let\'s print out our initial tensor constant so we do a print session run tf initial tensor constant we see that it\'s a two by three by four tensor the numbers go from one to twenty four and none of them have decimal points so we know that they\'re in 32 numbers let\'s now print our first reshaped tensor so we use the print session run tfx1 reshape tensor2 by 12. we see that it\'s a tensor that has two matrices inside of it the first matrix has one row and 12 columns the second matrix has one row and 12 columns so all of our elements are there one through 24. let\'s now print our second reshaped tensor python variable tf x2 reshaped tensor two by three by two by two awesome we see that it\'s a tensor that has two interior tensors each of which has three matrices that are two by two perfect so two rows two columns two rows two columns two rows two columns and then two rows two columns two rows two columns two rows two columns so overall we can see that the shape is two by three by two by two and all our numbers are there finally let\'s print our third reshape tensorflow example this is the python variable tfx tree reshape tensor 1 by 24 awesome we see that it\'s a vector that\'s 24 elements long so we see the number 1 all the way to 24. so all our numbers are there perfect we were able to use tensorflow reshape to change the shape of a tensorflow tensor as long as the number of elements stayed the same"", metadata={\'source\': \'ukBG9ALd8T8\'})]""""""']","{'https://stackoverflow.com/questions/37868935/tensorflow-reshape-tensor', 'https://stackoverflow.com/questions/62092075/tensorflow-2-0-shape-inference-with-reshape-returns-none-dimension', 'https://stackoverflow.com/questions/36764791/in-tensorflow-how-to-use-tf-gather-for-the-last-dimension', 'https://stackoverflow.com/questions/42194051/filter-out-non-zero-values-in-a-tensor'}","['""""""Filter out non-zero values in a tensor\n\nAsked 7 years, 1 month ago\n\nModified 3 years, 8 months ago\n\nSuppose I have an array: input = np.array([[1,0,3,5,0,8,6]]), and I want to filter out [1,3,5,8,6]. I know that you can use tf.where with a condition but the returned value still has 0\'s in it.""""""', '"""""" In Tensorflow, how to use tf.gather() for the last dimension? Asked 8 years, 1 month ago\n\nModified 6 years, 6 months ago\n\nI am trying to gather slices of a tensor in terms of the last dimension for partial connection between layers. Because the output tensor\'s shape is [batch_size, h, w, depth], I want to select slices based on the last dimension, such as\n\n# L is intermediate tensor partL = L[:, :, :, [0,2,3,8]]\n\nHowever, tf.gather(L, [0, 2,3,8]) seems to only work for the first dimension (right?) Can anyone tell me how to do it? As of TensorFlow 1.3 tf.gather has an axis parameter, so the various workarounds here are no longer necessary. https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/gather https://github.com/tensorflow/tensorflow/issues/11223\n\n\n\nThere\'s a tracking bug to support this use-case here: https://github.com/tensorflow/tensorflow/issues/206\n\ntranspose your matrix so that dimension to gather is first (transpose is expensive)\n\nreshape your tensor into 1d (reshape is cheap) and turn your gather column indices into a list of individual element indices at linear indexing, then reshape back\n\nuse gather_nd. Will still need to turn your column indices into list of individual element indices. Yaroslav BulatovYaroslav Bulatov\n\n 1\n\nNote that tf.gather has an axis parameter as of TensorFlow 1.3. With gather_nd you can now do this as follows:\n\ncat_idx = tf.concat([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=0) result = tf.gather_nd(matrix, cat_idx)\n\nAlso, as reported by user Nova in a thread referenced by @Yaroslav Bulatov\'s:\n\nx = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) idx = tf.constant([1, 0, 2]) idx_flattened = tf.range(0, x.shape[0]) * x.shape[1] + idx y = tf.gather(tf.reshape(x, [-1]), # flatten input idx_flattened) # use flattened indices with tf.Session(\'\'): print y.eval() # [2 4 9]\n\nThe gist is flatten the tensor and use strided 1D addressing with tf.gather(...). Andrei PokrovskyAndrei Pokrovsky\n\n 2\n\nI\'m not sure your first example works. Let\'s say tf.shape(x)[0] is 1, then cat_idx will be [0, 0, 2, 3, 8], which is not what you want to use with tf.gather_nd. In fact, in this case it would throw an error because the length of the innermost dimension of indices (2nd argument to gather_nd) cannot be bigger than the rank of params (1st argument to gather_nd). I\'ve posted a corrected version (using tf.stack) below. Yet another solution using tf.unstack(...), tf.gather(...) and tf.stack(..)\n\nimport tensorflow as tf import numpy as np shape = [2, 2, 2, 10] L = np.arange(np.prod(shape)) L = np.reshape(L, shape) indices = [0, 2, 3, 8] axis = -1 # last dimension def gather_axis(params, indices, axis=0): return tf.stack(tf.unstack(tf.gather(tf.unstack(params, axis=axis), indices)), axis=axis) print(L) with tf.Session() as sess: partL = sess.run(gather_axis(L, indices, axis)) print(partL)\n\nL = [[[[ 0 1 2 3 4 5 6 7 8 9] [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29] [30 31 32 33 34 35 36 37 38 39]]] [[[40 41 42 43 44 45 46 47 48 49] [50 51 52 53 54 55 56 57 58 59]] [[60 61 62 63 64 65 66 67 68 69] [70 71 72 73 74 75 76 77 78 79]]]] partL = [[[[ 0 2 3 8] [10 12 13 18]] [[20 22 23 28] [30 32 33 38]]] [[[40 42 43 48] [50 52 53 58]] [[60 62 63 68] [70 72 73 78]]]]\n\nYunseong HwangYunseong Hwang\n\nA correct version of @Andrei\'s answer would read\n\ncat_idx = tf.stack([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=1) result = tf.gather_nd(matrix, cat_idx)\n\nEdward HughesEdward Hughes\n\nYou can try this way, for instance(in most cases in NLP at the least),\n\nThe parameter is of shape [batch_size, depth] and the indices are [i, j, k, n, m] of which the length is batch_size. Then gather_nd can be helpful.""""""', '"""""" In Tensorflow, how to use tf.gather() for the last dimension? Asked 8 years, 1 month ago\n\nModified 6 years, 6 months ago\n\nI am trying to gather slices of a tensor in terms of the last dimension for partial connection between layers. Because the output tensor\'s shape is [batch_size, h, w, depth], I want to select slices based on the last dimension, such as\n\n# L is intermediate tensor partL = L[:, :, :, [0,2,3,8]]\n\nHowever, tf.gather(L, [0, 2,3,8]) seems to only work for the first dimension (right?) Can anyone tell me how to do it? As of TensorFlow 1.3 tf.gather has an axis parameter, so the various workarounds here are no longer necessary. https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/gather https://github.com/tensorflow/tensorflow/issues/11223\n\n\n\nThere\'s a tracking bug to support this use-case here: https://github.com/tensorflow/tensorflow/issues/206\n\ntranspose your matrix so that dimension to gather is first (transpose is expensive)\n\nreshape your tensor into 1d (reshape is cheap) and turn your gather column indices into a list of individual element indices at linear indexing, then reshape back\n\nuse gather_nd. Will still need to turn your column indices into list of individual element indices. Yaroslav BulatovYaroslav Bulatov\n\n 1\n\nNote that tf.gather has an axis parameter as of TensorFlow 1.3. With gather_nd you can now do this as follows:\n\ncat_idx = tf.concat([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=0) result = tf.gather_nd(matrix, cat_idx)\n\nAlso, as reported by user Nova in a thread referenced by @Yaroslav Bulatov\'s:\n\nx = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) idx = tf.constant([1, 0, 2]) idx_flattened = tf.range(0, x.shape[0]) * x.shape[1] + idx y = tf.gather(tf.reshape(x, [-1]), # flatten input idx_flattened) # use flattened indices with tf.Session(\'\'): print y.eval() # [2 4 9]\n\nThe gist is flatten the tensor and use strided 1D addressing with tf.gather(...). Andrei PokrovskyAndrei Pokrovsky\n\n 2\n\nI\'m not sure your first example works. Let\'s say tf.shape(x)[0] is 1, then cat_idx will be [0, 0, 2, 3, 8], which is not what you want to use with tf.gather_nd. In fact, in this case it would throw an error because the length of the innermost dimension of indices (2nd argument to gather_nd) cannot be bigger than the rank of params (1st argument to gather_nd). I\'ve posted a corrected version (using tf.stack) below. Yet another solution using tf.unstack(...), tf.gather(...) and tf.stack(..)\n\nimport tensorflow as tf import numpy as np shape = [2, 2, 2, 10] L = np.arange(np.prod(shape)) L = np.reshape(L, shape) indices = [0, 2, 3, 8] axis = -1 # last dimension def gather_axis(params, indices, axis=0): return tf.stack(tf.unstack(tf.gather(tf.unstack(params, axis=axis), indices)), axis=axis) print(L) with tf.Session() as sess: partL = sess.run(gather_axis(L, indices, axis)) print(partL)\n\nL = [[[[ 0 1 2 3 4 5 6 7 8 9] [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29] [30 31 32 33 34 35 36 37 38 39]]] [[[40 41 42 43 44 45 46 47 48 49] [50 51 52 53 54 55 56 57 58 59]] [[60 61 62 63 64 65 66 67 68 69] [70 71 72 73 74 75 76 77 78 79]]]] partL = [[[[ 0 2 3 8] [10 12 13 18]] [[20 22 23 28] [30 32 33 38]]] [[[40 42 43 48] [50 52 53 58]] [[60 62 63 68] [70 72 73 78]]]]\n\nYunseong HwangYunseong Hwang\n\nA correct version of @Andrei\'s answer would read\n\ncat_idx = tf.stack([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=1) result = tf.gather_nd(matrix, cat_idx)\n\nEdward HughesEdward Hughes\n\nYou can try this way, for instance(in most cases in NLP at the least),\n\nThe parameter is of shape [batch_size, depth] and the indices are [i, j, k, n, m] of which the length is batch_size. Then gather_nd can be helpful.""""""', '"""""" In Tensorflow, how to use tf.gather() for the last dimension? Asked 8 years, 1 month ago\n\nModified 6 years, 6 months ago\n\nI am trying to gather slices of a tensor in terms of the last dimension for partial connection between layers. Because the output tensor\'s shape is [batch_size, h, w, depth], I want to select slices based on the last dimension, such as\n\n# L is intermediate tensor partL = L[:, :, :, [0,2,3,8]]\n\nHowever, tf.gather(L, [0, 2,3,8]) seems to only work for the first dimension (right?) Can anyone tell me how to do it? As of TensorFlow 1.3 tf.gather has an axis parameter, so the various workarounds here are no longer necessary. https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/gather https://github.com/tensorflow/tensorflow/issues/11223\n\n\n\nThere\'s a tracking bug to support this use-case here: https://github.com/tensorflow/tensorflow/issues/206\n\ntranspose your matrix so that dimension to gather is first (transpose is expensive)\n\nreshape your tensor into 1d (reshape is cheap) and turn your gather column indices into a list of individual element indices at linear indexing, then reshape back\n\nuse gather_nd. Will still need to turn your column indices into list of individual element indices. Yaroslav BulatovYaroslav Bulatov\n\n 1\n\nNote that tf.gather has an axis parameter as of TensorFlow 1.3. With gather_nd you can now do this as follows:\n\ncat_idx = tf.concat([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=0) result = tf.gather_nd(matrix, cat_idx)\n\nAlso, as reported by user Nova in a thread referenced by @Yaroslav Bulatov\'s:\n\nx = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) idx = tf.constant([1, 0, 2]) idx_flattened = tf.range(0, x.shape[0]) * x.shape[1] + idx y = tf.gather(tf.reshape(x, [-1]), # flatten input idx_flattened) # use flattened indices with tf.Session(\'\'): print y.eval() # [2 4 9]\n\nThe gist is flatten the tensor and use strided 1D addressing with tf.gather(...). Andrei PokrovskyAndrei Pokrovsky\n\n 2\n\nI\'m not sure your first example works. Let\'s say tf.shape(x)[0] is 1, then cat_idx will be [0, 0, 2, 3, 8], which is not what you want to use with tf.gather_nd. In fact, in this case it would throw an error because the length of the innermost dimension of indices (2nd argument to gather_nd) cannot be bigger than the rank of params (1st argument to gather_nd). I\'ve posted a corrected version (using tf.stack) below. Yet another solution using tf.unstack(...), tf.gather(...) and tf.stack(..)\n\nimport tensorflow as tf import numpy as np shape = [2, 2, 2, 10] L = np.arange(np.prod(shape)) L = np.reshape(L, shape) indices = [0, 2, 3, 8] axis = -1 # last dimension def gather_axis(params, indices, axis=0): return tf.stack(tf.unstack(tf.gather(tf.unstack(params, axis=axis), indices)), axis=axis) print(L) with tf.Session() as sess: partL = sess.run(gather_axis(L, indices, axis)) print(partL)\n\nL = [[[[ 0 1 2 3 4 5 6 7 8 9] [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29] [30 31 32 33 34 35 36 37 38 39]]] [[[40 41 42 43 44 45 46 47 48 49] [50 51 52 53 54 55 56 57 58 59]] [[60 61 62 63 64 65 66 67 68 69] [70 71 72 73 74 75 76 77 78 79]]]] partL = [[[[ 0 2 3 8] [10 12 13 18]] [[20 22 23 28] [30 32 33 38]]] [[[40 42 43 48] [50 52 53 58]] [[60 62 63 68] [70 72 73 78]]]]\n\nYunseong HwangYunseong Hwang\n\nA correct version of @Andrei\'s answer would read\n\ncat_idx = tf.stack([tf.range(0, tf.shape(x)[0]), indices_for_dim1], axis=1) result = tf.gather_nd(matrix, cat_idx)\n\nEdward HughesEdward Hughes\n\nYou can try this way, for instance(in most cases in NLP at the least),\n\nThe parameter is of shape [batch_size, depth] and the indices are [i, j, k, n, m] of which the length is batch_size. Then gather_nd can be helpful.""""""']"
56286350,tf.keras.metrics.SensitivityAtSpecificity,example required,tf.keras.metrics.SpecificityAtSensitivity num_thresholds interpretation,"<p>I'm trying to get my head around <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/metrics/SensitivityAtSpecificity"" rel=""nofollow noreferrer"">tf.keras.metrics.SensitivityAtSpecificity</a>. I'm fine with the concept of sensity and specificity in isolation, but I'm unsure how the two are related in this single metric.</p>

<p>More specifically, I'm unsure how to interpret the <code>num_thresholds</code> argument. The example in documentation has <code>num_thresholds=1</code>. Setting <code>num_thresholds</code> greater than 1 with the same input data seems to always return a metric value of 1.0.</p>

<pre class=""lang-py prettyprint-override""><code>def print_metric_value(num_thresholds):
    # other values based on docs example
    m = tf.keras.metrics.SensitivityAtSpecificity(
        0.4, num_thresholds=num_thresholds)
    m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])
    print('Result with num_thresholds = %d: %.1f' %
          (num_thresholds, m.result().numpy()))

print_metric_value(1)    # 0.5 - same as docs
print_metric_value(2)    # 1.0
print_metric_value(200)  # 1.0
</code></pre>
","<p>The <code>num_thresholds</code> refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0). </p>

<p>For example, consider the prediction vector as <code>[0, 0.5, 0.3, 0.9]</code> which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of <code>0.1</code>, we get <code>[0, 1, 1, 1]</code>; or if we apply threshold value of <code>0.6</code> we get <code>[0, 0, 0, 1]</code> (i.e. only the confidence of last prediction is higher than <code>0.6</code>).   </p>

<p>Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What <code>SensitivityAtSpecificity</code> metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given <code>0.4</code> as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to <code>SpecificityAtSensitivity</code> metric, just swap ""specificity"" and ""sensitivity"" in this paragraph.</p>

<p>You might also ask: what are the threshold values? The answer is if <code>num_thresholds=1</code> then the only threshold is 0.5. If <code>num_thresholds &gt; 1</code> then, besides 0 and 1 as thresholds, the interval (0,1) will be split into <code>num_thresholds - 1</code> equal sub-intervals and the split points are chosen as additional threshold values. For example:</p>

<pre><code>num_threshold  |  thresholds
=============================
1              | [0.5]
2              | [0, 1]
3              | [0, 0.5, 1]
4              | [0, 0.33, 0.66, 1]
5              | [0, 0.25, 0.5, 0.75, 1]
...
</code></pre>
","The <code>num_thresholds</code> refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0).

For example, consider the prediction vector as <code>[0, 0.5, 0.3, 0.9]</code> which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of <code>0.1</code>, we get <code>[0, 1, 1, 1]</code>; or if we apply threshold value of <code>0.6</code> we get <code>[0, 0, 0, 1]</code> (i.e. only the confidence of last prediction is higher than <code>0.6</code>).

Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What <code>SensitivityAtSpecificity</code> metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given <code>0.4</code> as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to <code>SpecificityAtSensitivity</code> metric, just swap ""specificity"" and ""sensitivity"" in this paragraph.

You might also ask: what are the threshold values? The answer is if <code>num_thresholds=1</code> then the only threshold is 0.5. If <code>num_thresholds &gt; 1</code> then, besides 0 and 1 as thresholds, the interval (0,1) will be split into <code>num_thresholds - 1</code> equal sub-intervals and the split points are chosen as additional threshold values. For example:

<pre><code>num_threshold  |  thresholds
=============================
1              | [0.5]
2              | [0, 1]
3              | [0, 0.5, 1]
4              | [0, 0.33, 0.66, 1]
5              | [0, 0.25, 0.5, 0.75, 1]
...
</code></pre>",,"['Understanding tf.keras.metrics.SensitivityAtSpecificity in TensorFlow', 'How to use num_thresholds in tf.keras.metrics.SensitivityAtSpecificity', 'Interpreting num_thresholds argument in TensorFlow metrics', 'TensorFlow SensitivityAtSpecificity metric explained', 'Examples of using tf.keras.metrics.SensitivityAtSpecificity with different num_thresholds', 'Why does num_thresholds greater than 1 return 1.0 in tf.keras.metrics.SensitivityAtSpecificity', 'Step-by-step guide to tf.keras.metrics.SensitivityAtSpecificity', 'TensorFlow metrics: Sensitivity and Specificity combined', 'How to set num_thresholds in TensorFlow SensitivityAtSpecificity metric', 'Practical examples of tf.keras.metrics.SensitivityAtSpecificity']","['What is the purpose of the num_thresholds argument in tf.keras.metrics.SensitivityAtSpecificity?', 'How does the num_thresholds argument affect the calculation of SensitivityAtSpecificity in TensorFlow?', 'Why does setting num_thresholds greater than 1 in tf.keras.metrics.SensitivityAtSpecificity return a metric value of 1.0?', 'Can you provide examples of using tf.keras.metrics.SensitivityAtSpecificity with different num_thresholds values?', 'What is the relationship between sensitivity and specificity in tf.keras.metrics.SensitivityAtSpecificity?', 'How does tf.keras.metrics.SensitivityAtSpecificity handle different threshold values when num_thresholds is set to a value greater than 1?']",set(),[],{'https://stackoverflow.com/questions/56286350/tf-keras-metrics-specificityatsensitivity-num-thresholds-interpretation'},"['""""""tf.keras.metrics.SpecificityAtSensitivity num_thresholds interpretation\n\nAsked 4 years, 10 months ago\n\nModified 4 years, 10 months ago\n\nI\'m trying to get my head around tf.keras.metrics.SensitivityAtSpecificity. I\'m fine with the concept of sensity and specificity in isolation, but I\'m unsure how the two are related in this single metric. More specifically, I\'m unsure how to interpret the num_thresholds argument. The example in documentation has num_thresholds=1. Setting num_thresholds greater than 1 with the same input data seems to always return a metric value of 1.0. def print_metric_value(num_thresholds): # other values based on docs example m = tf.keras.metrics.SensitivityAtSpecificity( 0.4, num_thresholds=num_thresholds) m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9]) print(\'Result with num_thresholds = %d: %.1f\' % (num_thresholds, m.result().numpy())) print_metric_value(1) # 0.5 - same as docs print_metric_value(2) # 1.0 print_metric_value(200) # 1.0\n\n 1\n\nRelated: github.com/keras-team/keras/issues/6507\n\nâ€“ A T May 28, 2019 at 15:40\n\nThe num_thresholds refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0). For example, consider the prediction vector as [0, 0.5, 0.3, 0.9] which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of 0.1, we get [0, 1, 1, 1]; or if we apply threshold value of 0.6 we get [0, 0, 0, 1] (i.e. only the confidence of last prediction is higher than 0.6). Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What SensitivityAtSpecificity metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given 0.4 as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to SpecificityAtSensitivity metric, just swap ""specificity"" and ""sensitivity"" in this paragraph. You might also ask: what are the threshold values? The answer is if num_thresholds=1 then the only threshold is 0.5. If num_thresholds > 1 then, besides 0 and 1 as thresholds, the interval (0,1) will be split into num_thresholds - 1 equal sub-intervals and the split points are chosen as additional threshold values. For example:\n\nnum_threshold | thresholds ============================= 1 | [0.5] 2 | [0, 1] 3 | [0, 0.5, 1] 4 | [0, 0.33, 0.66, 1] 5 | [0, 0.25, 0.5, 0.75, 1] ... 6\n\nExactly the answer I was looking for. Turns out my data leads to ambiguous thresholds - anything in (0, 0.5) gives a specificity of 0.5 (closest possible value to 0.4), but the sensitivity value changes dramatically at 0.3\n\nOne final question: am I right in concluding that SpecitivityAtSensitivity(anything, num_thresholds=1) is equivalent to Specitivity(0.5)? @DomJack Sorry, I don\'t understand what you mean by Specificity(0.5) (I could not find such a metric in TF!). The SpecitivityAtSensitivity(anything, num_thresholds=1) would be equivalent to returning the specificity value at threshold 0.5, because that\'s the only threshold we have considered. I\'d just assumed it existed, guess not :).""""""']"
74005009,tf.data.Dataset,example required,How to create output_signature for tensorflow.dataset.from_generator,"<p>I have a generator yielding data and labels <code>yield data, labels</code> where the data is
an <code>numpy.ndarray</code> with variable rows and 500 columns of type <code>dtype=float32</code> and the labels are integers of <code>numpy.int64</code>.</p>
<p>I'm trying to pass this data into TensorFlow from_generator function to create a TensorFlow dataset: <code>tf.data.Dataset.from_generator</code></p>
<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">docs</a> say that the from_generator function needs a parameter <code>output_signature</code> as an input. But I'm having trouble understanding how to build this output_signature.</p>
<p>How can I make the output_signature for the generator I described?</p>
<p>Thank you!</p>
<p>Edit:
I used <code>tf.type_spec_from_value</code> to get this:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
   datagen_row,
   output_signature=(
      tf.TensorSpec(shape=(None, 512), dtype=tf.float32, name=None),
      tf.TensorSpec(shape=(), dtype=tf.int64, name=None)
   )
)
</code></pre>
<p>But is it correct to use None when the number of rows is varying for the first data type?</p>
","<p>if your datagen_row() function yields input_data, label with format 500 and 1
than your output_signature should be:</p>
<pre><code>  output_signature=(
  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),
  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))
</code></pre>
<p>where the first TensorSpec is for the data format and the second one for the label format.
But it would be helpful if you post the function + maybe data examples or data shape here. Otherwise it is hard to help.</p>
","If your datagen_row() function yields input_data, label with format 500 and 1 than your output_signature should be:
<pre><code>  output_signature=(
  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),
  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))
</code></pre>
where the first TensorSpec is for the data format and the second one for the label format. But it would be helpful if you post the function + maybe data examples or data shape here. Otherwise it is hard to help.","<pre><code>  output_signature=(
  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),
  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))
</code></pre>","['How to use tf.data.Dataset.from_generator with variable row numpy arrays in TensorFlow?', 'What is the correct way to define output_signature for tf.data.Dataset.from_generator when the data has variable rows?', 'Can tf.TensorSpec handle variable dimensions in TensorFlow datasets?', 'Examples of using tf.data.Dataset.from_generator with variable shape data', 'How to use tf.type_spec_from_value to generate output_signature for TensorFlow datasets?']","['How to use tf.data.Dataset.from_generator with variable row numpy arrays?', 'What is the correct way to define output_signature for tf.data.Dataset.from_generator when the number of rows is variable?', 'Is it correct to use None for the shape in tf.TensorSpec when the number of rows is variable?', 'Examples of using tf.data.Dataset.from_generator with variable shape tensors', 'How to handle variable shape data in TensorFlow datasets?']",set(),[],{'https://stackoverflow.com/questions/74005009/how-to-create-output-signature-for-tensorflow-dataset-from-generator'},"['""""""Share Your Experience: How to create output_signature for tensorflow.dataset.from_generator\n\nAsked 1 year, 7 months ago\n\nModified 1 year, 6 months ago\n\nI have a generator yielding data and labels yield data, labels where the data is an numpy.ndarray with variable rows and 500 columns of type dtype=float32 and the labels are integers of numpy.int64. I\'m trying to pass this data into TensorFlow from_generator function to create a TensorFlow dataset: tf.data.Dataset.from_generator\n\nThe docs say that the from_generator function needs a parameter output_signature as an input. But I\'m having trouble understanding how to build this output_signature. How can I make the output_signature for the generator I described? Edit: I used tf.type_spec_from_value to get this:\n\ndataset = tf.data.Dataset.from_generator( datagen_row, output_signature=( tf.TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), tf.TensorSpec(shape=(), dtype=tf.int64, name=None) ) )\n\nBut is it correct to use None when the number of rows is varying for the first data type? 1\n\nIf possible, add some dummy data with generator. if your datagen_row() function yields input_data, label with format 500 and 1 than your output_signature should be:\n\noutput_signature=( tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None), tf.TensorSpec(shape=(), dtype=tf.int64, name=None))\n\nwhere the first TensorSpec is for the data format and the second one for the label format. But it would be helpful if you post the function + maybe data examples or data shape here.""""""']"
60013980,tf.nn.embedding_lookup_sparse,example required,tf.nn.embedding_lookup_sparse 3D sparse tensor input,"<p>I have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse"" rel=""nofollow noreferrer""><code>tf.nn.embedding_lookup_sparse</code></a> I found it only supports 2D sparse tensors,</p>

<blockquote>
  <p>sp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary.</p>
</blockquote>

<p>My example code here</p>

<pre><code>import numpy as np
import tensorflow as tf
tf.enable_eager_execution()

# [feature number, embedding dim] 
w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer())

z = np.array(
     [
      [
        [0, 1, 2, 3],   # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum
        [2, 3]
      ],

      [
        [1, 3],
        [2]
      ],

      [
        [0, 1, 3],
        [1, 2]
      ]
     ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2],
                              [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0],
                              [2,0,1],[2,0,3],[2,1,1],[2,1,2]],
                     dense_shape=[3, 2, 4])

tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')
# the outputs
&lt;tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy=
array([[-5.8729677 , -1.3900641 ,  0.8126096 , -3.1223912 ],
       [-1.0788026 , -1.1324122 ,  0.34160078,  0.23714277],
       [-2.497394  , -2.7855003 ,  3.0201516 , -1.8009453 ]],
      dtype=float32)&gt;

print(w)
&lt;tf.Variable 'w:0' shape=(4, 4) dtype=float32, numpy=
array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)&gt;
</code></pre>

<p>But the expected output is a matrix with a dimension of <code>3x2x4</code>, not <code>3x4</code>. Does <code>tf.nn.embedding_lookup_sparse</code> support this operation?</p>
","<p>The most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape.</p>

<pre class=""lang-py prettyprint-override""><code># First make the z as a 2D arr and create a sparse tensor 
z = np.array([
        [0, 1, 2, 3],  # get the row 0,1,2,3 of the embedding matrix w and get the sum
        [2, 3],
        [1, 3],
        [2],
        [0, 1, 3],
        [1, 2]
      ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1],
                              [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]],
                     dense_shape=[6, 4])

res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')

res.numpy()
# the output
array([[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
       [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ],
       [ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
       [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]],

# reshape
tf.reshape(res, [-1, 2, 4])
# that is exacly what I want.
array([[[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
        [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ]],

       [[ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
        [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532]],

       [[-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
        [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]]])

# print w, and the above result is right
w.numpy()

array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)
</code></pre>

<p>So, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.</p>
","The most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape.
So, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.

","<pre class=""lang-py prettyprint-override""><code># First make the z as a 2D arr and create a sparse tensor 
z = np.array([
        [0, 1, 2, 3],  # get the row 0,1,2,3 of the embedding matrix w and get the sum
        [2, 3],
        [1, 3],
        [2],
        [0, 1, 3],
        [1, 2]
      ])

sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],
                     indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1],
                              [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]],
                     dense_shape=[6, 4])

res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner='sum')

res.numpy()
# the output
array([[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
       [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ],
       [ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
       [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]],

# reshape
tf.reshape(res, [-1, 2, 4])
# that is exacly what I want.
array([[[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],
        [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ]],

       [[ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],
        [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532]],

       [[-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],
        [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]]])

# print w, and the above result is right
w.numpy()

array([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],
       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],
       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],
       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],
      dtype=float32)
</code></pre>","['How to use tf.nn.embedding_lookup_sparse with 3D sparse tensors?', 'Alternatives to tf.nn.embedding_lookup_sparse for handling 3D sparse tensors in TensorFlow', 'How to reshape the output of tf.nn.embedding_lookup_sparse to match the expected dimensions?', 'Using tf.nn.embedding_lookup_sparse with higher-dimensional sparse tensors', 'TensorFlow embedding lookup for 3D sparse tensors tutorial']","['Does tf.nn.embedding_lookup_sparse support 3D sparse tensors?', 'How to use tf.nn.embedding_lookup_sparse with 3D sparse tensors?', 'What are the limitations of tf.nn.embedding_lookup_sparse in terms of tensor dimensions?', 'Are there any alternative TensorFlow functions to perform embedding lookup with 3D sparse tensors?', 'How to reshape the output of tf.nn.embedding_lookup_sparse to match the expected dimensions?']","{'https://www.youtube.com/watch?v=t3z0bOsaDQ0', 'https://www.youtube.com/watch?v=vbHX5R1rIo8'}","['""""""[Document(page_content=""today i want to go over the basics of sparse tensors and spatially sparse neural networks this is a part of the gtc talk titled take your deep learning to high dimensions with tensor methods i\'m chris choi and i work as a research scientist at nvidia before i joined nvidia i studied and developed 3d perception reconstruction and registration algorithms and my thesis was on high dimensional convolutional neural network for 3d perception currently i develop state-of-the-art 3d perception algorithms and maintain minkowski engine a neural network library for spatially sparse tensors in this section we\'ll discuss a new type of neural networks that can process point clouds 3d video or high dimensional data efficiently this is an example of a 4d network defined on the spatial temporal space that can process 3d videos or a sequence of 3d scans on the top right you can see that the network semantically segments the data and matches the ground turns on the bottom left corner before we proceed let\'s talk about the type of sparsity in a neural network here in this example we\'re feeding an image into a network and an image is a rank 3 tensor since it consists of xy plane and a color channel then we convolve this input with a set of network weights which is also a dense tensor so there are two types of tensors network rates and input or output features if we make the net neural network weight sparse we have a sparse convolutional neural networks and this has been the key component for network compression however we can add sparsity in the input specifically we can embed sparsity in position rather than the channels let\'s take this image as an example here we have a digit on the white background if we zoom in we can see that most of the region is 0. this forms a sparse matrix and the sparsity is in the position of the input and if the data has too many zeros then simply we can discard zeros and store data more efficiently in 3d space such spatial sparsity is more pronounced this is an example of 3d scan of a room and you can see that there\'s a lot of empty space in the data and the problem gets even worse as we increase the resolution of the space if we quantize the space with 20 centimeter voxels in the previous example 78 of the space is zero if we further increase the resolution and use 2.5 centimeter voxel the 98 of the space is empty and has value zero so if we apply any operators such as convolution and this dense tensor with 98 percent of zeros most of the computation will just take zeros as an input and return zeros as output in other words we\'re wasting 98 of the computation processing zeros then how can we save computation as well as excessive memory consumption let\'s say that we have a sparse matrix with values on its diagonal here we\'re saving all of its elements including zeros but instead we can save danzig values and their coordinates by representing a sparse matrix as a set of coordinate and value pairs of non-zero elements here since we have four on the first row and first column we save the coordinate at zero comma zero and its value 4. similarly we save value 1 and 1 comma 1. a sparse tensor is a high dimensional extension of a sparse matrix for example if we stack additional sparse matrix along a new dimension we have a sparse tensor if we also represent a sparse tensor as a list of matrices it could be very inefficient so we can save a set of coordinates and values of nonzero elements like this to give you a concrete example let\'s convert this scan into a dense tensor which gives us a size 400 by 200 by 100 dense tensor if we use channel size 128 per voxel then we need 4 gigabyte of gpu memory just to save the room but by discarding zeros and saving only the coordinates and values of non-zero elements it requires mere 180 megabytes to store the same data so we can see how efficient this representation could be for 3d or higher dimensional spaces easily this representation is known as the coordinate list representation in high dimensional spaces is it is also known as the high co representation in a neural network context however we do not use a scalar for feature we use vectors for features so the sparse tensor has the rank d plus one where d is the number of dimensions in the space and one for the feature vector and we can represent this compactly using two matrices coordinate and feature matrices like this now that we\'ve defined a sparse tensor let\'s discuss how we can extend convolution which is one of the most fundamental operators for perception to sparse tensors here i visualized a simple convolution on a 2d plane for each output pixel we extract features from the input and compute the weighted sum if we do the same for the rest of the output pixels then we have the convolution output we can define convolution on a sparse tensor in the same manner for each pixel on the output we can compute the weighted sum like before but for sparse tensors we compute weighted sum for non-zero values only if we do the same for the rest of the pixels of interest on the output we have the convolution output on the sparse tensor we call this generalized convolution since it allows us to compute convolution on arbitrary sparsity patterns on both input and output sparse tensors the standard neural network library such as pytorch and tensorflow do not support such generalized convolution so to use spatially sparse tensors you need pytorch or tensorflow extensions and minkowski engine is one of these few extension libraries that provide autodev functions for spatially sparse sensors it is open sourced on nvidia github page and provides many gpu optimized functions as well as examples and api documents so using minkowski engine you\'ll be able to create 3d networks in the way that you created standard 2d neural networks for example this is in your network architecture for classification in the 3d space and the input sparse tensor has 3d spatial dimensions although the convolution blocks look tense all features are sparse tensors and thus the network can process very high resolution point clouds similarly we can create semantic segmentation networks that process the entire point cloud fully convolutionally and generate symmetric segmentation of the 3d input scans here i visualize the 3d u-shaped network or pyramid network on the top note that the network has skip connections across network like units and image perception on the bottom i visualize the input sparse tensor on the left and a network prediction on the right also one of the contributions of the generalized convolution is that it supports generated architectures such as sheet completion and reconstruction on the top the completion network takes a partial 3d scan of a chair and generates a completed 3d chair as an output on the bottom the generation network creates a sparse tensor as an output from on one hot vector and minkowski engine supports all these architectures on gpu here i visualize the feed for time in log scale using a combat with 42 layers on cpu v100 and a100 respectively the size of the sparse tensor ranges from 100 000 to 3 million and is on the x-axis of both graphs the right graph i visualize the speed up of v100 and a100 over cpu as you can see from both graphs processing these large data with gpu is extremely fast and with gpus it gives us around 100x to 300x speedups first here\'s an example of 2d data with batch size 2. the first chunk represents batch index 0 and the second chunk represents patch index one in pi torch we simply create a dense tensor with zeros and the shape of the data is batch times channel times height times width however in a sparse tensor we only save coordinates and features of non-zero elements first we have 2.1 here since it is on the zeroth patch zeroth row and the zero second column we put zero comma zero comma two on the coordinate and for features we put two point one similarly uh we skip all the zeros and go to the next row and we have one and it is on the zeroth patch first row first column so we put zero comma one comma one on the coordinate and we put one on the feature once you finish collecting all nonzero elements you can simply feed the coordinates and features to the sparse tensor class to create a high dimensional sparse tensor creating a neural network is also very simple we add a list of layers to a pi torch module or you can extend the pytorch module superclass exactly the same way you create a 2d component on pytorch then you feed the sparse tensor you created before by passing it as an argument to the network for more information please visit the minkowski engine api page and examples the api page of minko scanton is available in github.com nvidia slash minkowski engine thank you for your attention"", metadata={\'source\': \'t3z0bOsaDQ0\'})]""""""', '""""""[Document(page_content=""WEI WEI: Hi there. Welcome back to our video series\\nof building recommendation systems with TensorFlow. My name is Wei. And I\'m a Developer\\nAdvocate at Google. If you are building\\nlarge scale recommenders, one of the biggest\\nchallenges must be with the large embedding\\ntables in your model. These embedding tables\\nare critical components. But the embedding lookup\\noperations on them are usually very expensive\\nto run, which makes them a performance bottleneck. So in this video,\\nwe\'re going to discuss how to tackle this challenge\\nwith TPU embeddings. Let\'s first refresh\\nour memory on how retrieval works in modern large\\nscale recommendation systems. First, we train a\\nneural network model, for example, the\\nclassical two tower model, to learn how to map query an\\nitem into a joint embedding space. Second, we map all [? kind ?]\\nitems in the embedding space with a learned item tower. Lastly, at runtime, we embed\\nthe query into query embedding and look up the nearest items\\nin the embedding space using vector similarity search. What was [INAUDIBLE] scan\\ncan accelerate the vector similarity search. Training the embedding\\ntables might be quite challenging in the first place. If you have a large vocabulary\\nof users or items, say more than 100 million\\nitems to recommend, or some high-dimensional\\nsparse features, you will need large\\nembedding tables to store embeddings for them. These embedding tables often may\\nnot fit on a single accelerator chip. So now, you have to share them\\nacross multiple accelerators, which introduces\\ncommunication overhead and makes the lookup\\noperation expensive. While there are some\\nsoftware-based solutions that aim to alleviate this,\\nit would be better to tackle this from both\\nthe hardware and software side, which leads\\nus to TPU embedding. On Google\'s latest\\nTPUs, there are specifically-designed\\nhardware on-chip called SparseCore, which is\\ndedicated to accelerating embedding lookup operation. SparseCore, together with\\nultra-fast chip-to-chip interconnect and the software\\nprogramming interface, TPU embedding API, gives\\nsignificant speed-up over large\\nrecommendation models. Here\'s an example\\nperformance benchmark for a Google internal\\nproduction recommender model. As you can see, by using TPU\\nembedding on TPU v3 and v4, there is a 10x and 30x speed-up\\nover embeddings placed on CPU, which is simply amazing. You can find out more in\\nthe paper linked below. Now you have seen the\\npower of TPU embeddings, How do you use them? Let\'s walk through\\na simple example to understand how to\\nleverage TPU embeddings. Since TPUs live on\\nGoogle Cloud, we need to have a GCS bucket to\\nfeed the data to the TPUs. We\'re going to use\\nthe same old movielens 100k data set as before. But this time, we convert\\nthe user IDs and movie IDs to integers. We shuffle and split the\\ndata set into training and test the sets as usual. Then we batch and\\ncache the data sets. Note that, here, strategy\\nis a TPU strategy object defined in advance. And then we convert them\\nto distributed data sets. Next, we define the\\noptimizer and table configs. To place the embeddings\\non TPU SparseCore, we need to define table configs,\\nwhich specifies the vocabulary size and embedding\\ndimension, and then associate features\\nwith table configs through feature configs. So here, we are placing movie\\nID on the movie table and user ID on the user table. Now, we can define our\\nrecommendation model. It\'s very similar with the\\ntypical tf recommender ranking model, except, this\\ntime, we\'re using tfrs.layers.embe\\ndding.TPUEmbedding instead of a vanilla TensorFlow\\nembedding layer. And we pass the feature config\\ninto the TPU embedding layer along with the optimizer. Next step is to define the\\ncore and compute loss methods. Note that, when we\\nsum up the loss, we need to scale it down by a\\nfactor of global batch size, which is equal to the product\\nof per replica batch size and\\nstrategy.num_replicas_in_sync. Finally, we compile, fit,\\nand evaluate the model. After training, we can save\\nthe model to a GCS bucket. And we can restore\\nthe checkpoint later. And we can also restore the\\nTPU-trained weights on CPU. Finally, we can\\nexport the CPU model as saved_model for serving. We can pass a user_id and a\\nmovie_id to the loaded model and then get a\\nrating prediction. So to sum up, today, we\\nintroduced you to TPU embedding and walked through how to\\nleverage it to accelerate embedding operations. Although it\'s a\\npretty simple model, I hope it gives you a good\\nconceptual understanding of how it works. If you want to learn more,\\nour colleague, [INAUDIBLE],, who is a Product Manager\\nfor TPU Embedding, gave a more detailed talk at\\nour recommendation system dev summit. We also had a guest speaker,\\n[INAUDIBLE] from Snap, to share their practical\\nexperience with TPU embeddings. I highly recommend watching\\nthat session in the link below. With that, thank you\\nfor watching this video. I\'ll see you next time. [MUSIC PLAYING]"", metadata={\'source\': \'vbHX5R1rIo8\'})]""""""']","{'https://stackoverflow.com/questions/60013980/tf-nn-embedding-lookup-sparse-3d-sparse-tensor-input', 'https://stackoverflow.com/questions/39207587/how-to-use-tf-nn-embedding-lookup-sparse-in-tensorflow', 'https://stackoverflow.com/questions/34870614/what-does-tf-nn-embedding-lookup-function-do'}","['""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\nAsked 4 years, 2 months ago\n\nModified 4 years, 2 months ago\n\nI have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""', '""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\nAsked 4 years, 2 months ago\n\nModified 4 years, 2 months ago\n\nI have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""', '""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\nAsked 4 years, 2 months ago\n\nModified 4 years, 2 months ago\n\nI have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""', '""""""Any comment could be appreciated. After diving into safe_embedding_lookup_sparse\'s unit test, I\'m more confused why I got this result if giving the sparse weights, especially why we got something like embedding_weights[0][3] where 3 is not appeared in the code above. 4\n\nPlease, let me know if my answer solved your problem :)\n\nThanks @rvinas . I don\'t figure it out yet after reading safe_embedding_lookup_sparse\'s unit test. I have updated the question and would you like to explain the code for us?""""""', '""""""tf.nn.embedding_lookup_sparse 3D sparse tensor input\n\nAsked 4 years, 2 months ago\n\nModified 4 years, 2 months ago\n\nI have an embedding matrix and there is a 3D sparse tensor which is used to get the embedding output, after reading the docs of tf.nn.embedding_lookup_sparse I found it only supports 2D sparse tensors,\n\nsp_ids: N x M SparseTensor of int64 ids where N is typically batch size and M is arbitrary. My example code here\n\nimport numpy as np import tensorflow as tf tf.enable_eager_execution() # [feature number, embedding dim] w = tf.get_variable(""w"", [4, 4], initializer=tf.random_normal_initializer()) z = np.array( [ [ [0, 1, 2, 3], # get the vector of row 0, 1, 2, 3 of the embedding matrix w and get the sum [2, 3] ], [ [1, 3], [2] ], [ [0, 1, 3], [1, 2] ] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0,0],[0,0,1],[0,0,2],[0,0,3],[0,1,2], [0,1,3],[1,0,1],[1,0,3],[1,1,2],[2,0,0], [2,0,1],[2,0,3],[2,1,1],[2,1,2]], dense_shape=[3, 2, 4]) tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') # the outputs <tf.Tensor: id=970, shape=(3, 4), dtype=float32, numpy= array([[-5.8729677 , -1.3900641 , 0.8126096 , -3.1223912 ], [-1.0788026 , -1.1324122 , 0.34160078, 0.23714277], [-2.497394 , -2.7855003 , 3.0201516 , -1.8009453 ]], dtype=float32)> print(w) <tf.Variable \'w:0\' shape=(4, 4) dtype=float32, numpy= array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)>\n\nBut the expected output is a matrix with a dimension of 3x2x4, not 3x4. Does tf.nn.embedding_lookup_sparse support this operation? GoingMyWayGoingMyWay\n\n\n\nThe most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape. # First make the z as a 2D arr and create a sparse tensor z = np.array([ [0, 1, 2, 3], # get the row 0,1,2,3 of the embedding matrix w and get the sum [2, 3], [1, 3], [2], [0, 1, 3], [1, 2] ]) sp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2], indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1], [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]], dense_shape=[6, 4]) res = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\') res.numpy() # the output array([[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ], [ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]], # reshape tf.reshape(res, [-1, 2, 4]) # that is exacly what I want. array([[[-3.6457794 , -1.5215762 , 1.7455802 , -2.5802398 ], [-2.227188 , 0.13151208, -0.9329706 , -0.5421516 ]], [[ 0.2612 , -0.6687883 , 1.7068193 , -0.03506255], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532]], [[-2.3057768 , -1.0579524 , 3.1107986 , -2.8524451 ], [-0.19161725, -1.7275481 , -0.0906471 , 1.0514997 ]]]) # print w, and the above result is right w.numpy() array([[-2.5669768 , -0.38916406, 1.4039794 , -2.8173826 ], [ 1.1483854 , -1.2639242 , 1.2745714 , 0.7792944 ], [-1.3400027 , -0.46362385, -1.3652185 , 0.27220532], [-0.8871854 , 0.5951359 , 0.43224794, -0.8143569 ]], dtype=float32)\n\nSo, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.""""""']"
57349824,tf.keras,example required,"Recurrent neural network, time series prediction with newer Tensorflow 1.14","<p>How to use new tf.keras API with recurrent neural network? I have checked the documentation but there is no example of such a situation.
There is this great book Hands on machine learning from 2017. Since that year the API of tensorflow has evolved and I am trying to rewrite recurrent neural network for time series prediction with using version <code>1.14</code> code.
The code from the book is using older <code>tf.nn.dynamic_rnn</code> and <code>tf.nn.rnn_cell.BasicRNNCell</code>:</p>

<pre><code>n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1
learning_rate = 0.001

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])
cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)
rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)
stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])
stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
loss = tf.reduce_mean(tf.square(outputs - y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()
n_iterations = 500
batch_size = 50

with tf.Session() as sess:
    init.run()
        for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})
</code></pre>

<p>And this code works just fine (except that it throws warnings about deprecation left and right). I wanted to use <code>tf.keras</code> API as suggested in warning. My code is the same except:</p>

<pre><code>cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)  
rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

<p>But this yields following exception:</p>

<pre><code>InvalidArgumentError: Input to reshape is a tensor with 50 values, but the requested shape requires a multiple of 20
 [[node Reshape_1 (defined at &lt;ipython-input-9-879361be49dd&gt;:3) ]]
</code></pre>

<p>so I understand that the problematic line is</p>

<pre><code>outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
</code></pre>

<p>After checking and comparing documentation for both cells <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a> and 
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN</a> I can't find the culprit.</p>

<p><strong>What is the difference with these two cells? How to use tf.keras API with time series?</strong></p>

<p>Full old code: <a href=""https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb"" rel=""nofollow noreferrer"">https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb</a></p>

<p>Full ""my"" code:</p>

<pre><code>import numpy as np
import tensorflow as tf
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pandas as pd
from utils import shuffle_batch, variable_summaries
import os


dir_path = os.getcwd()

now = datetime.utcnow().strftime(""%Y%m%d%H%M%S"")
root_logdir = ""tf_logs""
logdir = ""{}/run-{}/"".format(root_logdir, now)
print(dir_path)


t_min, t_max = -5, 5
section_start = (t_max + t_min) / 2
resolution = 0.1
n_steps = 20

def time_series(t):
    return np.sin(t)

def next_batch(batch_size, n_steps):
    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)
    Ts = t0 + np.arange(0., n_steps + 1) * resolution
    ys = time_series(Ts)
    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)


t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))

t_instance = np.linspace(start = section_start, stop = section_start + resolution * (n_steps + 1),num = n_steps + 1)

plt.figure(figsize=(11,4))
plt.subplot(121)
plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"")
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)
#plt.axis([-10, 10, -17, 13])
plt.xlabel(""Time"")
plt.ylabel(""Value"")

plt.subplot(122)
plt.title(""A training instance"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""c*"", markersize=10, label=""target"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")


# In[6]:


n_steps = 20
n_inputs = 1
n_neurons = 100
n_outputs = 1

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])


# In[7]:


cell =  tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu)                        


rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
print(rnn_outputs.get_shape())


stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons], name='reshape1')
stacked_outputs = tf.keras.layers.Dense(n_outputs,name=""hidden2"")(stacked_rnn_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs], name='reshape2')


learning_rate = 0.001

loss = tf.reduce_mean(tf.square(outputs - y)) # MSE
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()

n_iterations = 1500
batch_size = 50
save_path =os.path.join(dir_path,""model"",""recurrent_sinus_model"")

with tf.Session() as sess:
    init.run()
    for iteration in range(n_iterations):
        X_batch, y_batch = next_batch(batch_size, n_steps)
        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
        if iteration % 100 == 0:
            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})
            print(iteration, ""\tMSE:"", mse)

    saver.save(sess, save_path)


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})


plt.title(""Testing the model"", fontsize=14)
plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"")
plt.plot(t_instance[1:], time_series(t_instance[1:]), ""w*"", markersize=10, label=""target"")
plt.plot(t_instance[1:], y_pred[0,:,0], ""r."", markersize=10, label=""prediction"")
plt.legend(loc=""upper left"")
plt.xlabel(""Time"")

plt.show()


# In[ ]:


with tf.Session() as sess:                      
    saver.restore(sess, save_path)  

    X_new = time_series(np.array(t.reshape(-1, n_steps, n_inputs)))
    y_pred = sess.run(outputs, feed_dict={X: X_new})



plt.title(""A time series (generated)"", fontsize=14)
plt.plot(t, time_series(t), label=r""original"",linewidth=5,c='r')
plt.plot(t[:-1], time_series(t[:-1]), ""b-"", linewidth=3, label=""A training instance"")
plt.legend(loc=""lower left"", fontsize=14)

plt.xlabel(""Time"")
plt.ylabel(""Value"")
</code></pre>
","<p>So the answer is:</p>

<pre><code>rnn_outputs, rnn_states  = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)
</code></pre>

<p>instead of </p>

<pre><code>rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

<p>so the parameter <code>return_sequences=True</code> make the RNN return the time series as well, and well, this is the point.</p>
","So the answer is:
<pre><code>rnn_outputs, rnn_states  = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)
</code></pre>

instead of
<pre><code>rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)
</code></pre>

so the parameter <code>return_sequences=True</code> make the RNN return the time series as well, and well, this is the point.",,"['How to use tf.keras.layers.SimpleRNNCell for time series prediction in TensorFlow 1.14?', 'Differences between tf.nn.dynamic_rnn and tf.keras.layers.RNN in TensorFlow', 'How to reshape RNN outputs in TensorFlow using tf.keras API?', 'Time series prediction using tf.keras RNN layers in TensorFlow 1.14', 'Handling shape mismatches in TensorFlow RNNs with tf.keras API', 'Converting TensorFlow 1.x RNN code to tf.keras API', 'Best practices for using tf.keras.layers.RNN for time series data', 'Common errors and solutions when using tf.keras.layers.SimpleRNNCell']","['How to use tf.keras.layers.SimpleRNNCell with tf.keras.layers.RNN for time series prediction?', 'Difference between tf.nn.dynamic_rnn and tf.keras.layers.RNN in TensorFlow 1.14', 'How to reshape RNN outputs in TensorFlow 1.14 using tf.keras API?', 'Example of time series prediction using tf.keras.layers.SimpleRNNCell in TensorFlow 1.14', 'How to handle shape mismatch errors in TensorFlow when using tf.keras.layers.RNN?', 'Best practices for migrating from tf.nn.dynamic_rnn to tf.keras.layers.RNN', 'How to use tf.keras.layers.Dense with RNN outputs in TensorFlow 1.14', 'Common issues and solutions when using tf.keras.layers.RNN for time series prediction']","{'https://www.youtube.com/watch?v=Ng_uGKcWfIo', 'https://www.youtube.com/watch?v=T9u2XNWIn8s'}","['""""""[Document(page_content=""hello friends in this series of tutorial for the time series forecasting we are going to discuss the lstm network today so lstm is a artificially recurring neural network the rnn1 architecture which is a part of the deep learning method so today we will discuss about the uh multiple things you are relating to lstm first thing is that how it is differing from our legacy uh regression models so what you have learned till now like arima or ar or ma or arima model so how this lstm framework or this lstm network is differencing from that and the second thing is like how you can predict using lstm so we\'ll discuss it how theoretically it is done so it is like a short-term memory propagating over the train and test data and the last thing we will discuss like how using the loss function we can see that the prediction is accurate over the iteration of the epochs and then we will compare our actual test data with the predicted data with a very simple data set which we have i have borrowed from jason brownlee so he is the like mastermind in explaining his lstm you can go through his blog and you can learn it wonderfully but i just make a gist of it and all credit goes to him so let\'s begin so first thing is uh like where our legacy regression models fails so first thing is if your data is having too much noise or if your data is having outliers so then your regression model will fail and it will fail if there is a non-linear relationship between y and x the dependent and the independent variable and it will fail if you have a multivariate environment so always the time series prediction or forecasting you have done using an univariate environment so in case of multivariate it will fail now let\'s see how the lstm actually works so lstm works like let\'s say in your trained data you have like three you know um [Music] incidents or like three samples okay and using these three samples so let\'s say this is t minus 3 and for this one and this is t minus 2 and then it is t minus 1 so based on these three samples you have predicted the current t as 4 and then it will shift the training data and it will include this predicted data into the training data so now the training data will be two three and four and then the 5 will be generated so in this way this short term memory propagate over the predicted data and it will predict further so this is like you can say in in theoretical terms so this is a sequence prediction so this is a sequence of samples and how can you classify your sequence and how can you generate your sequence and using that sequence how can you predict the further sequence so that\'s how this is the whole fundamental of the lstm prediction you can check it in brownies blog i will give it in the description but this is in very short way how it is and the lstm lifecycle so what all things you need to do to get a prediction over lstm so it\'s very simple like you need to define the network and then you need to compile the network and then you need to fit the network and then you need to evaluate the network and make prediction so i will describe this one by one so now i have taken this data set the monthly car sales data set from the jason brownlee\'s blog and i read it using pandas and this is how the data is and you see the data varies over a very big range right so first thing first we will make the month or by the way i have described this as an univariate function but lstm works for the multivariate as well so i index the month field because that is the time field for me and then i just show you the data if the month is the time field and the cells is the like the output field what i need to predict and now i just decompose this data set and get like what is my like seasonality what is my trend and what is my uh residual so clearly this data is having a trend you see this is a trend and it has some seasonality because it has some uh trough and craft so let\'s proceed so first thing to fit the lstm what we need to do uh we need to erase the variance of the data because if the data varies uh over a very long range so it will like make the lstm a bad prediction [Music] the rstm will make a bad prediction so let\'s scale the data using the min max scalar and first i will define the min max scalar and i have borrowed it from the sql and preprocessing and then i just split the data using the train set and the test set and then i have used the keras preprocessing time series generator okay because it actually expect the lstm actually expect the data in a specific shape so what is that shape so that means the number of input in this sequence so you need to what is the sequence and what you how the sequence is generated so it\'s a very important part in the time series generation so in my example i have shown you like one two three so there is number of input is equal to three so n input is equal to three so i have given here six because i just make a permutation and combination and get a like a proper number of lags or number of inputs you require to predict this car sales data accurately so this can vary and you need to check what is your like adequate number so so in my case the n input is six like one two three four five six there are six samples in my trained data set and that will propagate over all the predicted data so one by one the predicted data will come in this input field and one by one well the oldest lag will it will be erased from this number of samples and since i have given you the only univariate data the number of features is equal to one so if it is a multivariate data this will be greater than one and then i generate these shapes uh from my trained data and test data i will show you how the data will look like so let\'s run it and then i just get only one data uh like from this generated trend and i will show you how the data look like so i as i have told like i just scale the data that\'s why you are getting this kind of decimal numbers but you see there are six samples in this data set so this is a input and this is the output so this is how the shape will be defined so you know that sequence shape should be defined in this way number of input and then output and then this will be shifted here and this will be your output that\'s the way and very important you always generate this shape because before you predict further let\'s proceed and i just show you the entire data that how it looks like so you see that all these data is actually regenerating this kind of output and this is a like a multi-dimensional array uh how this shape is defined so that\'s why i just show you how it is so uh i have used like most simple lstm framework like the vanilla iron the how can you say that it is vanilla because it\'s like a very simple and i have used the hyperbolic time function using mimic for my activation function [Music] and this is the output dimension so this is the output dimension and this is the activation function so i have defined the hyperbolic tangent and this is my input shape number of input and number of features to be predicted then this is how your model is defined using this add and compile and then i fit my the training data for this particular epoch so i have defined here 300 epochs so how i got this number 300 because you need to check the loss function and if your loss function reaches like a number like 0.001 then you can say this is properly diminished and it has a problem of like exploding the loss function as well so you need to avoid that so you need to always have the loss function diminished towards like 0 very near to 0 like 0.001 let\'s see how my loss function once i okay i have not run it so i have used these three things the from keras model i have used the sequential and ah from keras layer i have used the dense and i have imported the lstm framework as well so now your data is fitting over 300 epochs so it will take time i will just skip it to the end result and you see your loss function value is diminishing so it is now 0.01 so it started from the 0.05 you can say almost like your 5 percent and you need to reach till ah 0.1 percent kind of thing like 0.001 [Music] so initially i started with 50 epochs and then i say that in 50 epochs that is not diminished properly so that\'s why i increase the number and i get like where it is diminished properly you can also put a graph ah to get this kind of loss function plot so that you can easily check whether it is divisible towards 0 or not but if better than graph you can check it easily using this loss function value it generates so now see you see that uh this loss value is like divine is to very near to zero so it is like or in every case it is near to 0.001 or less than that so let\'s proceed with this fitted data and let\'s check our prediction so to predict it so you see uh what i have explained that whatever prediction you have done so that will be included for the next prediction that\'s how it is actually taking care of that non-linear relationship right like your test data time is also part of your trend data or your predicted data is also part of your trend data if you proceed further so that is like a sequence creation sequence generation and sequence prediction so how it is done [Music] so first thing is that i have used this fitted model and i have created the current prediction and then i appended this prediction in my predicted data so that i can plot it and i can compare it with my test data and then i remove the like the oldest lag from my current batch so you say that you can say that the you know the dynamic training data is having like a current patch so this is the like the batch i have generated and this is my first batch like with a number of inputs like the last six input of my training data so training data sorry i just used my mouse and it will have like last six value so if it is like six it will be five into four three two one okay and this is the last six value of my training data and i have removed everything else and then this is my first batch and how that first batch is reshaped in the same way like number of inputs and number of features and then i proceed and take it from one like i just remove one and if i have predicted seven so that will be included in these steps so i just removed it first and then i added this current prediction with my current batch and then make this as my current batch so this is how it is so these are very important steps you just need to generate the sequence and you need to reshape the sequence so this is very important steps and then once you predicted all the data you can like plot it as it is or you can uh rescale it to your old actual value because you just use a scalar value right so scaled value you can retransform it to your old value non-scale value and you can plot and compare with my test data so i have just checked that as well you can use the like mean square error as well so you see this is almost like implying that test data so the prediction is good you can check it using the msc score as well so that is how it is and for the loss function i have used the msc here you can check so this is how you can use the lstm network to predict the time series data and it is far better than the regression model in case of nonlinear relationship or if you have like the noise or outliers or if you have the multivariate environment thank you so much please stay tuned for more videos in this series thank you so much"", metadata={\'source\': \'T9u2XNWIn8s\'})]""""""', '""""""[Document(page_content=""[Music] hey everyone how\'s it going my name is daryl welcome back to my channel today i\'m going to talk about how to reshape input data for long short term memory network often it can be difficult to understand how to prepare your sequence data for input to an lstm model there\'s a confusion about how to convert your 1d or 2d matrix to the required 3d format for an lstm inputs also often there\'s a confusion around how to define the inputs layer for the rstm model so in this tutorial you will learn three things the first is how to define a lstms inputs layer and then you will learn how to reshape multi-parallel series data for lstm inputs and finally you will learn how to build and train a lstm model ready to go let\'s get started to make it easy to follow you can download this notebook from github and follow along with this step-by-step tutorial the most critical part of this video is to teach you how to reshape the multiple parallel series status that you have for a rstm inputs the rstm inputs layer is specified by the input arguments that is the input shaped arguments on the first hidden layer of the network so in that in that case this can make things confusing for beginners and the inputs to every rscm layers that has to be three-dimensional which is um which is unlike what we have with the traditional new network the three-dimensional them the three-dimensional dimensions of these inputs including the samples the time steps and also the features this means that the input layer expects a 3d array of data when fitting the models and when making predictions even if specified dimensions of the arrays contain only a single value or one sample or only one feature we still need to create it as a 3d shape so let\'s learn it by doing first thing first uh let\'s import the data set um to use we are going to import the data with the use of penders so we\'re going to impose the pandas frameworks and at the same time because we need to work with the 3d arrays so which is a nd numpy rate so we need to import the numpy framework as well and in this example what we\'re going to do is to download the data from the aemo which is the australian energy market operators download electricity data that includes the price and also the electricity consumptions so you can actually follow this link to download the data and then i already download the data and append them month by month and then you can see that we already have around one and a half years later with these datas what we\'re going to do is to use the electricity demand state data and the price data in the previous date to predict what is happening in the next 30 minutes about the price so to predict the price at 30 minutes later now let\'s take a look on the csv file first we have the index columns because i append the data month by month so i still keep the original index columns for in in the column a and then for the column b that is for the regions uh this is the victoria regions and then for the settlements that is the settlement dates and settlement times and and then we have the total demands for that period of times and then the fh price for that period of times and that is um the columns and the datas that we have so the first things that we are going to do is use the pd.we switch csv files to with this data into a data frame and this is the data frame that we just um that we just extracted from the csv file and let\'s take a look on the types for each of the columns and for the index that is an integer regions that is an object settlement date that is an object the total demands and the price are the floating and then the period types is another object there are three columns that we\'re going to use including the settlement days total demands and also the price and you can see that the settlement days right now is an object ties and total demands and the price are the floating types so the first thing that we need to do is to convert these settlement dates from an object types to a date time object in that case what we are going to do is to use the built-in methods that is two days time methods to convert these types the columns that we would like to convert is the df settlement date that is the first argument and then the second argument is that we set the dates first equals to true it means that um the first uh the first uh the first value here is a date and then followed by month and then by years so we set the date first equals to true and here we assign as a new columns that is called the date time and then for this one now because this this is a dates time objects so we can just convert it we can just use the daytime memphis that is a wt dot day to extract the day and to extract the month the years the hours and also the minutes so in total you can see that there is a six additional column show here that includes the date time uh which is a day times objects the days the month the years the hours and also the minutes now if we print out the column types you can see that the date times is a day times objects and then followed by the integer types for for the day month years hours and minutes and normally and these um these total demands and also price might not be the data types that you want so in that case you might want to use the two numericals to change the types of these total demands and also the the price and in this case it\'s already it\'s the white types but still i just want to show you the how to convert these object types to a numerical in that case we use the top two numerical methods and then the first argument is that you say total is the uh is the total demand columns and then for this one the first the first argument is the price column here we set the errors equals to coerce it it means that for any missing value we will just fill it up with nan and so we then assign it to a data frame with the new columns called demand and price and if we take a look on the data types and now we have the demand and price that is a numerical data the next things that i would like to do is to drop out all the other columns that are not needed in this data frame and that includes the index regions settlement days total demands our our pre period types so all of them will be dropped out and now what we have uh in this data frame that includes the price the demands and also the day month years hours and minutes and now we are ready to transform the data the first things that i would like to do is to create a and empty leads uh for each of the features and also the targets and then with this and the list what we\'re going to do is to append each of the values into these empty leads so what i\'m doing here is actually like this is that i take out 47 points for the x points and then i shift one step and and another 48 points and then continues to append to the empty leads so in that case what we are going to have is that we have a bunch of samples over here and then for each of the sample we have 48 points and this is for the demands columns and then i\'m going to append the dates the month the years the hour the minutes the demands and also the price with similar logic and so you can see i just take out all previous 48 steps and then appends into each of the and and the pants in each of the row in these uh or each of the elements in this empty list and that is for the features for the target is like this so this is 40 accept so this let me highlight this for you this is a 40x step so in that case what i would like to do is to use these 48 steps to predict what is happening in the next 30 minutes in that case what we are going to predict is these uh these um spots price of the electricity so and then of course it will continue to shift for each of the steps for each of the 30 minutes in the phone and that is for the label let me print out the types of the x5 that is one of the features that is the demands features and you can see that it\'s a steal at least and so this is what we got for the x5 this is the lisk and then originally is inside a data frame and now it has been appends just like what i mentioned before with the use of these for loop so say for example it take out the 48 point over here and then it will shift one point for each of the row for each of the sample so in that case um you you just shift 30 minutes and then store another sample and it continues until it reaches the end and now because this is still a lisk so i would like to convert them into a np array that is the nd numpy array so for each of them i will just use the np dot array function method to convert it to convert the list into a array now let\'s take a look on the output shapes this is the output shape in order for it to work with the training algorithms we need to expand these output shapes with an additional dimensions over here to make sure it works properly with the trailing algorithm so we just need to use these we shape functions and then add one direct dimensions into these render to smooth the trainings normally we need to normalize the data or standardize the data and in this case we are going to use the mean mass scalar and then which which is which provides a range between zero to one and in that case what we\'re going to do is to transform all of the features as well as the target with these mean mess scalar so we will first use this b mass scalar and then besides the range that is 0 to 1 and in this case and then work into assign as a scalar object and then once we have these scalar objects what we\'re going to do is use the fit transform functions uh transform functions for um for each of their feature apply these feed transfer functions to each of the features and then we will just convert assign it back to the original some original nd away and now we have um all of them has been scale scale dance between 0 and 1 and now this is the results that we have for one of the features and this is the demand features and let me let\'s take a look on this shape that is for this demand features and now we have the we have around 25 000 samples and then for the sequence for the time steps we have around 48. the next step is the most important steps in order for us to transform it into a 3d format required by the lstms layer what we\'ve done here is to use the numpy stack that is to stack each of the features into these x array and then with the access equals to two so it means that we are going to set each of the features along the x 2 and because at this point we do not have the x x 2 that is 0 1 and x x 2 in that case what what is that means is that we are going to expand these features with new dimensions with these seven features so you can see that the final shift is this is looks like this this is a the 3d required format for the lstm models and now for the first for the first argument for the first elements that contains the sample and then for the second elements that contains the time steps that is the previous state or the previous 48 time steps for each of the 30 for each of 30 minutes interval and then finally we have the seven features so we just finished to we just finished the two we shapes the multi multiple parallel series data for a lstm input the next things we are going to do is to build the rstm model we just separate the last 10 days for for for the testing so here you can see that um we assign the x and it starts from the beginning to the last 10 days up to the last 10 days for training and then the last 10 days will be used for testing now and then we also assign the labels in with the similar logic and you can see that for the x string dot shaped the first um the second dimensions that is 48 and then the third dimensions that is seven and this is the input shape for the lstm and now we are ready to use the tensorflow carriers to build the models the methods that we are going to use is to use the sequential apis to build the models layer by layer so of course we need to import the sequential models and then for the layers of course we need to import the lstm and also the dense layer and we also impose the optimizers for some parameters tuning now we first assign our models as a sequential models and then what we\'re going to do is to add two lstms layers and then two dense layers for the first lstms layers we assigns 50 neurons and then the return sequence it has need to be set as a true the reason is because we are going to have an other lstms layer in that case we need to reset it equals to true for this one because what we we do not have another additional rstml layers lstm layers followed by these stm layers we have a dense layer followed by this one this layer so in that case we can set it as false for this for this um for this lines of codes because this is the first input layer so we need to assign the input shapes and remember that this is the input shape so we just put input shapes equals to the x train dog shape dimension 1 and x chain dot shapes dimension 2 this is the input shape and then now we have this input layer and the next layer we will add an additional rstm and the return sequence equals to false because the next layer will be just a dense layers and for these dense layers the activations function is value and finally we just add a last layers which is a the the output and that is um and the activations is just linear so we didn\'t we do not need to add that but with one new one because the target is uh it\'s a single it\'s a single output now if we take let\'s take a look on the model\'s summary so with the input shapes and then go through these areas tms layer it will provide these output shapes remember it\'s because we set the return sequence equals to true it will return to a vb output shape for the next lstms layer and then because for the return sequence equals to force for the for the second lstm layers so it will just flatten it and then return you a 2d output result for the next layers now we are ready to go for the train links before we fit the data into the sequential models the first things that we would like to do is to import the model checkpoint and also the early stopping functions to um to early stops the to early stop the trainings if uh if there\'s a if we find that the validation loss is going up and on the other hand we also would like to save the model save the best only models into these paths so once we set this callback and set this file path and set the set up the model checkpoint and early stopping properly we can then set up the optimizer in this case i\'m going to use the sgd um sgd optimizer and with momentum equals to 0.9 and so this is the optimizer of sgd and the loss functions that i\'m going to use is mse and for the metrics that i would like to monitor is mae and finally we are ready to fit the training data into the models and i take up um 20 of the training data for the validation and outside the callbacks as the callbacks that we set over here and the batch size is 16 and not too long after around 21 deposh it will just end the training and finally i also even use the model.evaluates methods to evaluate with the test set data and evaluates give us the mse and also the mae over here and finally we can also use the predict methods to make a predictions on the output remember that we just uh transformed the original data into uh with the use of the um in math scalar so in that case we need to use the same scalar to do the inverse transform of the predictions so now these are the results after we use the inverse transform scalar and let\'s take a look on the parts over here and from this part uh you can see that the red line is the actual price actual electricity price and then the blue line is the forecast price and in terms of the trends it actually track the um trade quite well however in terms of the spike you can see that it doesn\'t follows too much and if we shoot means to this huge spike and you can see that indeed these forecast value also predicts a huge values in in this huge spike period and of course we can further increase more features and fine tunes the hyper parameters to make a better predictions the whole point of this tutorial is to provide you a and ideas and templates on how to set up the rstms inputs layers and voa rstm models from the from the raw data from the cs from the data from the csv and then convert it into a into a 3d shapes that is required formats that is the required format for the rstm models so if you have any any questions any further comments please feel free to leave me the comments and i will do my best to answer so see you in the next video bye bye"", metadata={\'source\': \'Ng_uGKcWfIo\'})]""""""']","{'https://stackoverflow.com/questions/54989442/rnn-in-tensorflow-vs-keras-depreciation-of-tf-nn-dynamic-rnn', 'https://stackoverflow.com/questions/57349824/recurrent-neural-network-time-series-prediction-with-newer-tensorflow-1-14'}","['""""""RNN in Tensorflow vs Keras, depreciation of tf.nn.dynamic_rnn()\n\nAsked 5 years, 3 months ago\n\nModified 5 years, 1 month ago\n\nMy question is: Are the tf.nn.dynamic_rnn and keras.layers.RNN(cell) truly identical as stated in docs? I am planning on building an RNN, however, it seems that tf.nn.dynamic_rnn is depricated in favour of Keras. In particular, it states that:\n\nWarning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use keras.layers.RNN(cell), which is equivalent to this API\n\nBut I don\'t see how the APIs are equivalent, in the case of variable sequence lengths! In raw TF, we can specify a tensor of shape (batch_size, seq_lengths). This way, if our sequence is [0, 1, 2, 3, 4] and the longest sequence in the batch is of size 10, we can pad it with 0s and [0, 1, 2, 3, 4, 0, 0, 0, 0, 0], we can say seq_length=5 to process [0, 1, 2, 3, 4]. However, in Keras, this is not how it works! What we can do, is specify the mask_zero=True in previous Layers, e.g. the Embedding Layer. This will also mask the 1st zero! I can go around it by adding ones to the whole vector, but then thats extra preprocessing that I need to do after processing using tft.compute_vocabulary(), which maps vocabulary words to 0 indexed vector. 6\n\nare you talking about keras or tf.keras?""""""', '""""""Please help us improve Stack Overflow. Take our short survey\n\nTake our short survey\n\nRecurrent neural network, time series prediction with newer Tensorflow 1.14\n\nAsked 4 years, 11 months ago\n\nModified 4 years, 11 months ago\n\nHow to use new tf.keras API with recurrent neural network? I have checked the documentation but there is no example of such a situation. There is this great book Hands on machine learning from 2017. Since that year the API of tensorflow has evolved and I am trying to rewrite recurrent neural network for time series prediction with using version 1.14 code. The code from the book is using older tf.nn.dynamic_rnn and tf.nn.rnn_cell.BasicRNNCell:\n\nn_steps = 20 n_inputs = 1 n_neurons = 100 n_outputs = 1 learning_rate = 0.001 X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) y = tf.placeholder(tf.float32, [None, n_steps, n_outputs]) cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu) rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32) stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs) outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs]) loss = tf.reduce_mean(tf.square(outputs - y)) optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) training_op = optimizer.minimize(loss) init = tf.global_variables_initializer() saver = tf.train.Saver() n_iterations = 500 batch_size = 50 with tf.Session() as sess: init.run() for iteration in range(n_iterations): X_batch, y_batch = next_batch(batch_size, n_steps) sess.run(training_op, feed_dict={X: X_batch, y: y_batch}) if iteration % 100 == 0: mse = loss.eval(feed_dict={X: X_batch, y: y_batch}) print(iteration, ""\\tMSE:"", mse) X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs))) y_pred = sess.run(outputs, feed_dict={X: X_new})\n\nAnd this code works just fine (except that it throws warnings about deprecation left and right). I wanted to use tf.keras API as suggested in warning. My code is the same except:\n\ncell = tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu) rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)\n\nBut this yields following exception:\n\nInvalidArgumentError: Input to reshape is a tensor with 50 values, but the requested shape requires a multiple of 20 [[node Reshape_1 (defined at <ipython-input-9-879361be49dd>:3) ]]\n\nso I understand that the problematic line is\n\noutputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n\nAfter checking and comparing documentation for both cells https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn and https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN I can\'t find the culprit. What is the difference with these two cells? How to use tf.keras API with time series? Full old code: https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb\n\nimport numpy as np import tensorflow as tf from datetime import datetime import matplotlib.pyplot as plt from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split import pandas as pd from utils import shuffle_batch, variable_summaries import os dir_path = os.getcwd() now = datetime.utcnow().strftime(""%Y%m%d%H%M%S"") root_logdir = ""tf_logs"" logdir = ""{}/run-{}/"".format(root_logdir, now) print(dir_path) t_min, t_max = -5, 5 section_start = (t_max + t_min) / 2 resolution = 0.1 n_steps = 20 def time_series(t): return np.sin(t) def next_batch(batch_size, n_steps): t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution) Ts = t0 + np.arange(0., n_steps + 1) * resolution ys = time_series(Ts) return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1) t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution)) t_instance = np.linspace(start = section_start, stop = section_start + resolution * (n_steps + 1),num = n_steps + 1) plt.figure(figsize=(11,4)) plt.subplot(121) plt.title(""A time series (generated)"", fontsize=14) plt.plot(t, time_series(t), label=r""original"") plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""b-"", linewidth=3, label=""A training instance"") plt.legend(loc=""lower left"", fontsize=14) #plt.axis([-10, 10, -17, 13]) plt.xlabel(""Time"") plt.ylabel(""Value"") plt.subplot(122) plt.title(""A training instance"", fontsize=14) plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"") plt.plot(t_instance[1:], time_series(t_instance[1:]), ""c*"", markersize=10, label=""target"") plt.legend(loc=""upper left"") plt.xlabel(""Time"") # In[6]: n_steps = 20 n_inputs = 1 n_neurons = 100 n_outputs = 1 X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) y = tf.placeholder(tf.float32, [None, n_steps, n_outputs]) # In[7]: cell = tf.keras.layers.SimpleRNNCell(units=n_neurons, activation=tf.nn.relu) rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X) print(rnn_outputs.get_shape()) stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons], name=\'reshape1\') stacked_outputs = tf.keras.layers.Dense(n_outputs,name=""hidden2"")(stacked_rnn_outputs) outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs], name=\'reshape2\') learning_rate = 0.001 loss = tf.reduce_mean(tf.square(outputs - y)) # MSE optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) training_op = optimizer.minimize(loss) init = tf.global_variables_initializer() saver = tf.train.Saver() n_iterations = 1500 batch_size = 50 save_path =os.path.join(dir_path,""model"",""recurrent_sinus_model"") with tf.Session() as sess: init.run() for iteration in range(n_iterations): X_batch, y_batch = next_batch(batch_size, n_steps) sess.run(training_op, feed_dict={X: X_batch, y: y_batch}) if iteration % 100 == 0: mse = loss.eval(feed_dict={X: X_batch, y: y_batch}) print(iteration, ""\\tMSE:"", mse) saver.save(sess, save_path) with tf.Session() as sess: saver.restore(sess, save_path) X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs))) y_pred = sess.run(outputs, feed_dict={X: X_new}) plt.title(""Testing the model"", fontsize=14) plt.plot(t_instance[:-1], time_series(t_instance[:-1]), ""bo"", markersize=10, label=""instance"") plt.plot(t_instance[1:], time_series(t_instance[1:]), ""w*"", markersize=10, label=""target"") plt.plot(t_instance[1:], y_pred[0,:,0], ""r."", markersize=10, label=""prediction"") plt.legend(loc=""upper left"") plt.xlabel(""Time"") plt.show() # In[ ]: with tf.Session() as sess: saver.restore(sess, save_path) X_new = time_series(np.array(t.reshape(-1, n_steps, n_inputs))) y_pred = sess.run(outputs, feed_dict={X: X_new}) plt.title(""A time series (generated)"", fontsize=14) plt.plot(t, time_series(t), label=r""original"",linewidth=5,c=\'r\') plt.plot(t[:-1], time_series(t[:-1]), ""b-"", linewidth=3, label=""A training instance"") plt.legend(loc=""lower left"", fontsize=14) plt.xlabel(""Time"") plt.ylabel(""Value"")\n\nrecurrent-neural-network\n\nBartek WÃ³jcikBartek WÃ³jcik\n\nrnn_outputs, rnn_states = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)\n\nrnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)\n\nso the parameter return_sequences=True make the RNN return the time series as well, and well, this is the point. Bartek WÃ³jcikBartek WÃ³jcik\n\n""""""', '""""""RNN in Tensorflow vs Keras, depreciation of tf.nn.dynamic_rnn()\n\nAsked 5 years, 3 months ago\n\nModified 5 years, 1 month ago\n\nMy question is: Are the tf.nn.dynamic_rnn and keras.layers.RNN(cell) truly identical as stated in docs? I am planning on building an RNN, however, it seems that tf.nn.dynamic_rnn is depricated in favour of Keras. In particular, it states that:\n\nWarning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use keras.layers.RNN(cell), which is equivalent to this API\n\nBut I don\'t see how the APIs are equivalent, in the case of variable sequence lengths! In raw TF, we can specify a tensor of shape (batch_size, seq_lengths). This way, if our sequence is [0, 1, 2, 3, 4] and the longest sequence in the batch is of size 10, we can pad it with 0s and [0, 1, 2, 3, 4, 0, 0, 0, 0, 0], we can say seq_length=5 to process [0, 1, 2, 3, 4]. However, in Keras, this is not how it works! What we can do, is specify the mask_zero=True in previous Layers, e.g. the Embedding Layer. This will also mask the 1st zero! I can go around it by adding ones to the whole vector, but then thats extra preprocessing that I need to do after processing using tft.compute_vocabulary(), which maps vocabulary words to 0 indexed vector. 6\n\nare you talking about keras or tf.keras?""""""']"
55573670,tf.nn.sparse_softmax_cross_entropy_with_logits,example required,Unexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits,"<p>The TensorFlow documentation for <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> explicitly declares that I should not apply softmax to the inputs of this op:</p>

<blockquote>
  <p>This op expects unscaled logits, since it performs a softmax on logits
  internally for efficiency. Do not call this op with the output of
  softmax, as it will produce incorrect results.</p>
</blockquote>

<p>However if I use cross entropy without softmax it gives me unexpected results. According to <a href=""https://cs231n.github.io/neural-networks-3/#sanitycheck"" rel=""nofollow noreferrer"">CS231n course</a> the expected loss value is around 2.3 for CIFAR-10:</p>

<blockquote>
  <p>For example, for CIFAR-10 with a Softmax classifier we would expect
  the initial loss to be 2.302, because we expect a diffuse probability
  of 0.1 for each class (since there are 10 classes), and Softmax loss
  is the negative log probability of the correct class so: -ln(0.1) =
  2.302.</p>
</blockquote>

<p>However without softmax I get much bigger values, for example 108.91984.</p>

<p>What exactly am I doing wrong with <code>sparse_softmax_cross_entropy_with_logits</code>? The TF code is shown below.</p>

<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.python import keras


(_, _), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_test = np.reshape(x_test, [-1, 32, 32, 3])

y_test = np.reshape(y_test, (10000,))
y_test = y_test.astype(np.int32)

x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3))
y = tf.placeholder(dtype=tf.int32, shape=(None,))

layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x)
layer = tf.nn.relu(layer)
layer = tf.layers.Flatten()(layer)
layer = tf.layers.Dense(units=1000)(layer)
layer = tf.nn.relu(layer)
logits = tf.layers.Dense(units=10)(layer)

# If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)

loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,
                                                      logits=logits)
loss = tf.reduce_mean(loss, name='cross_entropy')

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]})
    print(""loss: "", res)
    # Expected output is value close to 2.3
    # Real outputs are 108.91984, 72.82324, etc.

</code></pre>
","<p>The issue is not in the lines </p>

<pre><code># If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)
</code></pre>

<p>Images in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your <code>x_test</code> by 255 </p>

<pre><code>x_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255
</code></pre>

<p>the values will be rescaled to [0,1] and <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> will return expected values</p>
","The issue is not in the lines 
<pre><code># If this line is uncommented I get expected value around 2.3
# logits = tf.nn.softmax(logits)
</code></pre>

Images in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your <code>x_test</code> by 255 
<pre><code>x_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255
</code></pre>

the values will be rescaled to [0,1] and <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> will return expected values.",,"['Understanding tf.nn.sparse_softmax_cross_entropy_with_logits in TensorFlow', 'Why should you not apply softmax before using tf.nn.sparse_softmax_cross_entropy_with_logits?', 'Common mistakes when using tf.nn.sparse_softmax_cross_entropy_with_logits', 'Expected loss values for CIFAR-10 using tf.nn.sparse_softmax_cross_entropy_with_logits', 'How to correctly use tf.nn.sparse_softmax_cross_entropy_with_logits in TensorFlow', 'Troubleshooting high loss values in TensorFlow models', 'TensorFlow cross-entropy loss function explained', 'Difference between logits and probabilities in TensorFlow', 'Best practices for using tf.nn.sparse_softmax_cross_entropy_with_logits']","['Why does tf.nn.sparse_softmax_cross_entropy_with_logits expect unscaled logits?', 'What are the common mistakes when using tf.nn.sparse_softmax_cross_entropy_with_logits?', 'How to correctly use tf.nn.sparse_softmax_cross_entropy_with_logits in TensorFlow?', 'Why is the initial loss value around 2.3 for CIFAR-10 with a Softmax classifier?', 'What are the implications of applying softmax before tf.nn.sparse_softmax_cross_entropy_with_logits?', 'How to debug high loss values when using tf.nn.sparse_softmax_cross_entropy_with_logits?']",set(),[],"{'https://stackoverflow.com/questions/43394152/tensorflow-what-exact-formula-is-applied-in-tf-nn-sparse-softmax-cross-entropy', 'https://stackoverflow.com/questions/37312421/whats-the-difference-between-sparse-softmax-cross-entropy-with-logits-and-softm', 'https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop', 'https://stackoverflow.com/questions/41412335/tf-nn-softmax-cross-entropy-with-logits-error-logits-and-labels-must-be-same', 'https://stackoverflow.com/questions/55573670/unexpected-output-for-tf-nn-sparse-softmax-cross-entropy-with-logits'}","['""""""We can compute the cross-entropy loss on a row-wise basis and see the results. Below we can see that training instance 1 has a loss of 0.479, while training instance 2 has a higher loss of 1.200. This result makes sense because in our example above, y_hat_softmax showed that training instance 1\'s highest probability was for ""Class 2"", which matches training instance 1 in y_true; however, the prediction for training instance 2 showed a highest probability for ""Class 1"", which does not match the true class ""Class 3"". loss_per_instance_1 = -tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1]) sess.run(loss_per_instance_1) # array([ 0.4790107 , 1.19967598])\n\nWhat we really want is the total loss over all the training instances. So we can compute:\n\ntotal_loss_1 = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1])) sess.run(total_loss_1) # 0.83934333897877944\n\nUsing softmax_cross_entropy_with_logits()\n\nWe can instead compute the total cross entropy loss using the tf.nn.softmax_cross_entropy_with_logits() function, as shown below. loss_per_instance_2 = tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true) sess.run(loss_per_instance_2) # array([ 0.4790107 , 1.19967598]) total_loss_2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true)) sess.run(total_loss_2) # 0.83934333897877922\n\nNote that total_loss_1 and total_loss_2 produce essentially equivalent results with some small differences in the very final digits. However, you might as well use the second approach: it takes one less line of code and accumulates less numerical error because the softmax is done for you inside of softmax_cross_entropy_with_logits(). stackoverflowuser2010stackoverflowuser2010\n\n 3\n\nI confirm all of the above. The simple code: M = tf.random.uniform([100, 10], minval=-1.0, maxval=1.0); labels = tf.one_hot(tf.random.uniform([100], minval=0, maxval=10 , dtype=\'int32\'), 10); tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=M) - tf.reduce_sum(-tf.nn.log_softmax(M)*tf.one_hot(labels, 10), -1) returns close-to-zero everywhere\n\n\n\nSorry for simple/dummy question. I didn\'t understand getting loss \'0.479\' from training instance-1. True label for instance-1 is \'2\'. If I apply -1xlog2(0.619) I get 0.691. Edit: Loss is calculated using log \'e\' base, okay. tf.nn.softmax computes the forward propagation through a softmax layer. You use it during evaluation of the model when you compute the probabilities that the model outputs. tf.nn.softmax_cross_entropy_with_logits computes the cost for a softmax layer. It is only used during training. The logits are the unnormalized log probabilities output the model (the values output before the softmax normalization is applied to them). Ian GoodfellowIan Goodfellow\n\n 7\n\nI get it. Why not call the function, tf.nn.softmax_cross_entropy_sans_normalization? @auro because it normalizes the values (internally) during the cross-entropy computation. The point of tf.nn.softmax_cross_entropy_with_logits is to evaluate how much the model deviates from the gold labels, not to provide a normalized output. In the case of using tf.nn.sparse_softmax_cross_entropy_with_logits() computes the cost of a sparse softmax layer, and thus should only be used during training what would be the alternative when running the model against new data, is it possible to obtain probabilities from this one. @SerialDev, it\'s not possible to get probabilities from tf.nn.sparse_softmax_cross_entropy_with_logits. To get probabilities use tf.nn.softmax. They\'re not log probabilities but log odds. | Show 2 more comments\n\nMathematical motivation for term\n\nWhen we wish to constrain an output between 0 and 1, but our model architecture outputs unconstrained values, we can add a normalisation layer to enforce this. A common choice is a sigmoid function.1 In binary classification this is typically the logistic function, and in multi-class tasks the multinomial logistic function (a.k.a softmax).2\n\nIf we want to interpret the outputs of our new final layer as \'probabilities\', then (by implication) the unconstrained inputs to our sigmoid must be inverse-sigmoid(probabilities). In the logistic case this is equivalent to the log-odds of our probability (i.e. the log of the odds) a.k.a. logit:\n\nThat is why the arguments to softmax is called logits in Tensorflow - because under the assumption that softmax is the final layer in the model, and the output p is interpreted as a probability, the input x to this layer is interpretable as a logit:\n\nIn Machine Learning there is a propensity to generalise terminology borrowed from maths/stats/computer science, hence in Tensorflow logit (by analogy) is used as a synonym for the input to many normalisation functions. While it has nice properties such as being easily diferentiable, and the aforementioned probabilistic interpretation, it is somewhat arbitrary. softmax might be more accurately called softargmax, as it is a smooth approximation of the argmax function. 0\n\nAbove answers have enough description for the asked question. Adding to that, Tensorflow has optimised the operation of applying the activation function then calculating cost using its own activation followed by cost functions. Hence it is a good practice to use: tf.nn.softmax_cross_entropy() over tf.nn.softmax(); tf.nn.cross_entropy()\n\nYou can find prominent difference between them in a resource intensive model. 2\n\nthe answer above clearly haven\'t read the question.. They all say the same things, which are known, but don\'t answer the question itself\n\n\n\n@abhish Did you mean, tf.nn.softmax followed by tf.losses.softmax_cross_entropy? Tensorflow 2.0 Compatible Answer: The explanations of dga and stackoverflowuser2010 are very detailed about Logits and the related Functions. All those functions, when used in Tensorflow 1.x will work fine, but if you migrate your code from 1.x (1.14, 1.15, etc) to 2.x (2.0, 2.1, etc..), using those functions result in error. Hence, specifying the 2.0 Compatible Calls for all the functions, we discussed above, if we migrate from 1.x to 2.x, for the benefit of the community. tf.nn.softmax_cross_entropy_with_logits\n\ntf.nn.sparse_softmax_cross_entropy_with_logits\n\nRespective Functions when Migrated from 1.x to 2.x:\n\ntf.compat.v2.nn.softmax\n\ntf.compat.v2.nn.softmax_cross_entropy_with_logits\n\ntf.compat.v2.nn.sparse_softmax_cross_entropy_with_logits\n\nFor more information about migration from 1.x to 2.x, please refer this Migration Guide. user11530462user11530462\n\nLogits are the unnormalized outputs of a neural network. Softmax is a normalization function that squashes the outputs of a neural network so that they are all between 0 and 1 and sum to 1. Softmax_cross_entropy_with_logits is a loss function that takes in the outputs of a neural network (after they have been squashed by softmax) and the true labels for those outputs, and returns a loss value. Matias MolinasMatias Molinas\n\n2,One more thing that I would definitely like to highlight as logit is just a raw output, generally the output of last layer. This can be a negative value as well. If we use it as it\'s for ""cross entropy"" evaluation as mentioned below:\n\n-tf.reduce_sum(y_true * tf.log(logits))\n\nthen it wont work. As log of -ve is not defined.""""""', '""""""We can compute the cross-entropy loss on a row-wise basis and see the results. Below we can see that training instance 1 has a loss of 0.479, while training instance 2 has a higher loss of 1.200. This result makes sense because in our example above, y_hat_softmax showed that training instance 1\'s highest probability was for ""Class 2"", which matches training instance 1 in y_true; however, the prediction for training instance 2 showed a highest probability for ""Class 1"", which does not match the true class ""Class 3"". loss_per_instance_1 = -tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1]) sess.run(loss_per_instance_1) # array([ 0.4790107 , 1.19967598])\n\nWhat we really want is the total loss over all the training instances. So we can compute:\n\ntotal_loss_1 = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1])) sess.run(total_loss_1) # 0.83934333897877944\n\nUsing softmax_cross_entropy_with_logits()\n\nWe can instead compute the total cross entropy loss using the tf.nn.softmax_cross_entropy_with_logits() function, as shown below. loss_per_instance_2 = tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true) sess.run(loss_per_instance_2) # array([ 0.4790107 , 1.19967598]) total_loss_2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true)) sess.run(total_loss_2) # 0.83934333897877922\n\nNote that total_loss_1 and total_loss_2 produce essentially equivalent results with some small differences in the very final digits. However, you might as well use the second approach: it takes one less line of code and accumulates less numerical error because the softmax is done for you inside of softmax_cross_entropy_with_logits(). stackoverflowuser2010stackoverflowuser2010\n\n 3\n\nI confirm all of the above. The simple code: M = tf.random.uniform([100, 10], minval=-1.0, maxval=1.0); labels = tf.one_hot(tf.random.uniform([100], minval=0, maxval=10 , dtype=\'int32\'), 10); tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=M) - tf.reduce_sum(-tf.nn.log_softmax(M)*tf.one_hot(labels, 10), -1) returns close-to-zero everywhere\n\n\n\nSorry for simple/dummy question. I didn\'t understand getting loss \'0.479\' from training instance-1. True label for instance-1 is \'2\'. If I apply -1xlog2(0.619) I get 0.691. Edit: Loss is calculated using log \'e\' base, okay. tf.nn.softmax computes the forward propagation through a softmax layer. You use it during evaluation of the model when you compute the probabilities that the model outputs. tf.nn.softmax_cross_entropy_with_logits computes the cost for a softmax layer. It is only used during training. The logits are the unnormalized log probabilities output the model (the values output before the softmax normalization is applied to them). Ian GoodfellowIan Goodfellow\n\n 7\n\nI get it. Why not call the function, tf.nn.softmax_cross_entropy_sans_normalization? @auro because it normalizes the values (internally) during the cross-entropy computation. The point of tf.nn.softmax_cross_entropy_with_logits is to evaluate how much the model deviates from the gold labels, not to provide a normalized output. In the case of using tf.nn.sparse_softmax_cross_entropy_with_logits() computes the cost of a sparse softmax layer, and thus should only be used during training what would be the alternative when running the model against new data, is it possible to obtain probabilities from this one. @SerialDev, it\'s not possible to get probabilities from tf.nn.sparse_softmax_cross_entropy_with_logits. To get probabilities use tf.nn.softmax. They\'re not log probabilities but log odds. | Show 2 more comments\n\nMathematical motivation for term\n\nWhen we wish to constrain an output between 0 and 1, but our model architecture outputs unconstrained values, we can add a normalisation layer to enforce this. A common choice is a sigmoid function.1 In binary classification this is typically the logistic function, and in multi-class tasks the multinomial logistic function (a.k.a softmax).2\n\nIf we want to interpret the outputs of our new final layer as \'probabilities\', then (by implication) the unconstrained inputs to our sigmoid must be inverse-sigmoid(probabilities). In the logistic case this is equivalent to the log-odds of our probability (i.e. the log of the odds) a.k.a. logit:\n\nThat is why the arguments to softmax is called logits in Tensorflow - because under the assumption that softmax is the final layer in the model, and the output p is interpreted as a probability, the input x to this layer is interpretable as a logit:\n\nIn Machine Learning there is a propensity to generalise terminology borrowed from maths/stats/computer science, hence in Tensorflow logit (by analogy) is used as a synonym for the input to many normalisation functions. While it has nice properties such as being easily diferentiable, and the aforementioned probabilistic interpretation, it is somewhat arbitrary. softmax might be more accurately called softargmax, as it is a smooth approximation of the argmax function. 0\n\nAbove answers have enough description for the asked question. Adding to that, Tensorflow has optimised the operation of applying the activation function then calculating cost using its own activation followed by cost functions. Hence it is a good practice to use: tf.nn.softmax_cross_entropy() over tf.nn.softmax(); tf.nn.cross_entropy()\n\nYou can find prominent difference between them in a resource intensive model. 2\n\nthe answer above clearly haven\'t read the question.. They all say the same things, which are known, but don\'t answer the question itself\n\n\n\n@abhish Did you mean, tf.nn.softmax followed by tf.losses.softmax_cross_entropy? Tensorflow 2.0 Compatible Answer: The explanations of dga and stackoverflowuser2010 are very detailed about Logits and the related Functions. All those functions, when used in Tensorflow 1.x will work fine, but if you migrate your code from 1.x (1.14, 1.15, etc) to 2.x (2.0, 2.1, etc..), using those functions result in error. Hence, specifying the 2.0 Compatible Calls for all the functions, we discussed above, if we migrate from 1.x to 2.x, for the benefit of the community. tf.nn.softmax_cross_entropy_with_logits\n\ntf.nn.sparse_softmax_cross_entropy_with_logits\n\nRespective Functions when Migrated from 1.x to 2.x:\n\ntf.compat.v2.nn.softmax\n\ntf.compat.v2.nn.softmax_cross_entropy_with_logits\n\ntf.compat.v2.nn.sparse_softmax_cross_entropy_with_logits\n\nFor more information about migration from 1.x to 2.x, please refer this Migration Guide. user11530462user11530462\n\nLogits are the unnormalized outputs of a neural network. Softmax is a normalization function that squashes the outputs of a neural network so that they are all between 0 and 1 and sum to 1. Softmax_cross_entropy_with_logits is a loss function that takes in the outputs of a neural network (after they have been squashed by softmax) and the true labels for those outputs, and returns a loss value. Matias MolinasMatias Molinas\n\n2,One more thing that I would definitely like to highlight as logit is just a raw output, generally the output of last layer. This can be a negative value as well. If we use it as it\'s for ""cross entropy"" evaluation as mentioned below:\n\n-tf.reduce_sum(y_true * tf.log(logits))\n\nthen it wont work. As log of -ve is not defined.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nWhat\'s the difference between sparse_softmax_cross_entropy_with_logits and softmax_cross_entropy_with_logits? Asked 8 years, 2 months ago\n\nModified 6 years, 1 month ago\n\nI recently came across tf.nn.sparse_softmax_cross_entropy_with_logits and I can not figure out what the difference is compared to tf.nn.softmax_cross_entropy_with_logits. Is the only difference that training vectors y have to be one-hot encoded when using sparse_softmax_cross_entropy_with_logits? Reading the API, I was unable to find any other difference compared to softmax_cross_entropy_with_logits. But why do we need the extra function then? Shouldn\'t softmax_cross_entropy_with_logits produce the same results as sparse_softmax_cross_entropy_with_logits, if it is supplied with one-hot encoded training data/vectors? 2\n\nI\'m interested in seeing a comparison of their performance if both can be used (e.g. with exclusive image labels); I\'d expect the sparse version to be more efficient, at least memory-wise. See also this question, which discusses all cross-entropy functions in tensorflow (turns out there are lots of them). Having two different functions is a convenience, as they produce the same result. The difference is simple:\n\nFor sparse_softmax_cross_entropy_with_logits, labels must have the shape [batch_size] and the dtype int32 or int64. Each label is an int in range [0, num_classes-1]. For softmax_cross_entropy_with_logits, labels must have the shape [batch_size, num_classes] and dtype float32 or float64. Labels used in softmax_cross_entropy_with_logits are the one hot version of labels used in sparse_softmax_cross_entropy_with_logits. Another tiny difference is that with sparse_softmax_cross_entropy_with_logits, you can give -1 as a label to have loss 0 on this label. Olivier MoindrotOlivier Moindrot\n\n 3\n\nIs the -1 correct? As the documentation reads: ""Each entry in labels must be an index in [0, num_classes). Other values will raise an exception when this op is run on CPU, and return NaN for corresponding loss and gradient rows on GPU.""\n\n\n\n[0, num_classes) = [0, num_classes-1]\n\n\n\nIs this statement correct? ""Labels used in softmax_cross_entropy_with_logits are the one hot version of labels used in sparse_softmax_cross_entropy_with_logits."" Is it backwards? Isn\'t the sparse loss function the one with int of 0, so isn\'t the sparse one the one-hot version? I would just like to add 2 things to accepted answer that you can also find in TF documentation. tf.nn.softmax_cross_entropy_with_logits\n\nNOTE: While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution. If they are not, the computation of the gradient will be incorrect. tf.nn.sparse_softmax_cross_entropy_with_logits\n\nNOTE: For this operation, the probability of a given label is considered exclusive. That is, soft classes are not allowed, and the labels vector must provide a single specific index for the true class for each row of logits (each minibatch entry). 3\n\nWhat should we use if the classes are not mutually exclusive.""""""', '""""""only). Search jobs\n\nUnexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits\n\nAsked 5 years, 1 month ago\n\nModified 5 years, 1 month ago\n\nThe TensorFlow documentation for tf.nn.sparse_softmax_cross_entropy_with_logits explicitly declares that I should not apply softmax to the inputs of this op:\n\nThis op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results. However if I use cross entropy without softmax it gives me unexpected results. According to CS231n course the expected loss value is around 2.3 for CIFAR-10:\n\nFor example, for CIFAR-10 with a Softmax classifier we would expect the initial loss to be 2.302, because we expect a diffuse probability of 0.1 for each class (since there are 10 classes), and Softmax loss is the negative log probability of the correct class so: -ln(0.1) = 2.302. However without softmax I get much bigger values, for example 108.91984. What exactly am I doing wrong with sparse_softmax_cross_entropy_with_logits? The TF code is shown below. import tensorflow as tf import numpy as np from tensorflow.python import keras (_, _), (x_test, y_test) = keras.datasets.cifar10.load_data() x_test = np.reshape(x_test, [-1, 32, 32, 3]) y_test = np.reshape(y_test, (10000,)) y_test = y_test.astype(np.int32) x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3)) y = tf.placeholder(dtype=tf.int32, shape=(None,)) layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x) layer = tf.nn.relu(layer) layer = tf.layers.Flatten()(layer) layer = tf.layers.Dense(units=1000)(layer) layer = tf.nn.relu(layer) logits = tf.layers.Dense(units=10)(layer) # If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits) loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits) loss = tf.reduce_mean(loss, name=\'cross_entropy\') with tf.Session() as sess: sess.run(tf.global_variables_initializer()) res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]}) print(""loss: "", res) # Expected output is value close to 2.3 # Real outputs are 108.91984, 72.82324, etc. The issue is not in the lines\n\n# If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits)\n\nImages in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your x_test by 255\n\nx_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255\n\nthe values will be rescaled to [0,1] and tf.nn.sparse_softmax_cross_entropy_with_logits will return expected values\n\n\n\n1\n\nGood answer! Added exact code how to get desired behavior\n\n""""""', '""""""only). Search jobs\n\nUnexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits\n\nAsked 5 years, 1 month ago\n\nModified 5 years, 1 month ago\n\nThe TensorFlow documentation for tf.nn.sparse_softmax_cross_entropy_with_logits explicitly declares that I should not apply softmax to the inputs of this op:\n\nThis op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results. However if I use cross entropy without softmax it gives me unexpected results. According to CS231n course the expected loss value is around 2.3 for CIFAR-10:\n\nFor example, for CIFAR-10 with a Softmax classifier we would expect the initial loss to be 2.302, because we expect a diffuse probability of 0.1 for each class (since there are 10 classes), and Softmax loss is the negative log probability of the correct class so: -ln(0.1) = 2.302. However without softmax I get much bigger values, for example 108.91984. What exactly am I doing wrong with sparse_softmax_cross_entropy_with_logits? The TF code is shown below. import tensorflow as tf import numpy as np from tensorflow.python import keras (_, _), (x_test, y_test) = keras.datasets.cifar10.load_data() x_test = np.reshape(x_test, [-1, 32, 32, 3]) y_test = np.reshape(y_test, (10000,)) y_test = y_test.astype(np.int32) x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3)) y = tf.placeholder(dtype=tf.int32, shape=(None,)) layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x) layer = tf.nn.relu(layer) layer = tf.layers.Flatten()(layer) layer = tf.layers.Dense(units=1000)(layer) layer = tf.nn.relu(layer) logits = tf.layers.Dense(units=10)(layer) # If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits) loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits) loss = tf.reduce_mean(loss, name=\'cross_entropy\') with tf.Session() as sess: sess.run(tf.global_variables_initializer()) res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]}) print(""loss: "", res) # Expected output is value close to 2.3 # Real outputs are 108.91984, 72.82324, etc. The issue is not in the lines\n\n# If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits)\n\nImages in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your x_test by 255\n\nx_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255\n\nthe values will be rescaled to [0,1] and tf.nn.sparse_softmax_cross_entropy_with_logits will return expected values\n\n\n\n1\n\nGood answer! Added exact code how to get desired behavior\n\n""""""', '""""""only). Search jobs\n\nUnexpected output for tf.nn.sparse_softmax_cross_entropy_with_logits\n\nAsked 5 years, 1 month ago\n\nModified 5 years, 1 month ago\n\nThe TensorFlow documentation for tf.nn.sparse_softmax_cross_entropy_with_logits explicitly declares that I should not apply softmax to the inputs of this op:\n\nThis op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results. However if I use cross entropy without softmax it gives me unexpected results. According to CS231n course the expected loss value is around 2.3 for CIFAR-10:\n\nFor example, for CIFAR-10 with a Softmax classifier we would expect the initial loss to be 2.302, because we expect a diffuse probability of 0.1 for each class (since there are 10 classes), and Softmax loss is the negative log probability of the correct class so: -ln(0.1) = 2.302. However without softmax I get much bigger values, for example 108.91984. What exactly am I doing wrong with sparse_softmax_cross_entropy_with_logits? The TF code is shown below. import tensorflow as tf import numpy as np from tensorflow.python import keras (_, _), (x_test, y_test) = keras.datasets.cifar10.load_data() x_test = np.reshape(x_test, [-1, 32, 32, 3]) y_test = np.reshape(y_test, (10000,)) y_test = y_test.astype(np.int32) x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 3)) y = tf.placeholder(dtype=tf.int32, shape=(None,)) layer = tf.layers.Conv2D(filters=16, kernel_size=3)(x) layer = tf.nn.relu(layer) layer = tf.layers.Flatten()(layer) layer = tf.layers.Dense(units=1000)(layer) layer = tf.nn.relu(layer) logits = tf.layers.Dense(units=10)(layer) # If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits) loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits) loss = tf.reduce_mean(loss, name=\'cross_entropy\') with tf.Session() as sess: sess.run(tf.global_variables_initializer()) res = sess.run(loss, feed_dict={x: x_test[0:256], y: y_test[0:256]}) print(""loss: "", res) # Expected output is value close to 2.3 # Real outputs are 108.91984, 72.82324, etc. The issue is not in the lines\n\n# If this line is uncommented I get expected value around 2.3 # logits = tf.nn.softmax(logits)\n\nImages in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your x_test by 255\n\nx_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255\n\nthe values will be rescaled to [0,1] and tf.nn.sparse_softmax_cross_entropy_with_logits will return expected values\n\n\n\n1\n\nGood answer! Added exact code how to get desired behavior\n\n""""""']"
54047604,tf.custom_gradient,example required,How to assign custom gradient to TensorFlow op with multiple inputs,"<p>I'm trying to use TensorFlow's <code>@tf.custom_gradient</code> functionality to assign a custom gradient to a function with multiple inputs.  I can put together a working setup for only one input, but not for two or more.</p>

<p>I've based my code on <a href=""https://www.tensorflow.org/api_docs/python/tf/custom_gradient"" rel=""nofollow noreferrer"">TensorFlow's custom_gradient documentation</a>, which works just fine for one input, as in this example:</p>

<pre><code>import tensorflow as tf
import os

# Suppress Tensorflow startup info
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

# Custom gradient decorator on a function,
# as described in documentation
@tf.custom_gradient
def my_identity(x):

    # The custom gradient
    def grad(dy):
        return dy

    # Return the result AND the gradient
    return tf.identity(x), grad

# Make a variable, run it through the custom op
x = tf.get_variable('x', initializer=1.)
y = my_identity(x)

# Calculate loss, make an optimizer, train the variable
loss = tf.abs(y)
opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)
train = opt.minimize(loss)

# Start a TensorFlow session, initialize variables, train
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(train)
</code></pre>

<p>This example runs silently, then closes.  No issues, no errors.  The variable optimizes as expected.  However, in my application, I need to do such a calculation with multiple inputs, so something of this form:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad
</code></pre>

<p>Running this in place of the example (and adding another variable input to the call of <code>my_identify</code>) results in the following error output.  Best as I can tell, the last parts of the error are from the dynamic generation of the op -- the information format matches the C++ formatting required in the op establishment (though that's about all I know about it).</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 27, in &lt;module&gt;
    train = opt.minimize(loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 400, in minimize
    grad_loss=grad_loss)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/training/optimizer.py"", line 519, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 630, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 821, in _GradientsHelper
    _VerifyGeneratedGradients(in_grads, op)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/gradients_impl.py"", line 323, in _VerifyGeneratedGradients
    ""inputs %d"" % (len(grads), op.node_def, len(op.inputs)))
ValueError: Num gradients 2 generated for op name: ""IdentityN""
op: ""IdentityN""
input: ""Identity""
input: ""x/read""
input: ""y/read""
attr {
  key: ""T""
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_gradient_op_type""
  value {
    s: ""CustomGradient-9""
  }
}
 do not match num inputs 3
</code></pre>

<p>Based on other custom gradient options, I surmised that the issue was a lack of supplied gradient for the second input argument.  So, I changed my function to this:</p>

<pre><code>@tf.custom_gradient
def my_identity(x, z):

    def grad(dy):
        return dy

    return tf.identity(x*z), grad, grad
</code></pre>

<p>This results in the following more familiar error:</p>

<pre><code>Traceback (most recent call last):
  File ""testing.py"", line 22, in &lt;module&gt;
    y = my_identity(x, z)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 111, in decorated
    return _graph_mode_decorator(f, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/tensorflow/python/ops/custom_gradient.py"", line 132, in _graph_mode_decorator
    result, grad_fn = f(*args)
ValueError: too many values to unpack (expected 2)
</code></pre>

<p>The <code>@custom_gradient</code> decorator is only identifying the last returned element as a gradient.  So, I tried putting the two gradients into a tuple as <code>(grad, grad)</code> such that there would only be ""two"" outputs for the function.  TensorFlow rejected this too, this time because it can't call a tuple like it would a Tensor -- entirely reasonable, in hindsight.</p>

<p>I've fussed around with the example some more, but to no avail.  No matter what I try, I can't get the custom-defined gradient to deal with multiple inputs.  I'm hoping that somebody with more knowledge than I regarding custom ops and gradients will have a better idea on this -- thanks in advance for the help!</p>
","<p>If we use multiple variables as input, the number of gradients return from ""grad"" function should be equals to number of input variables, though we maybe don't care about some of them. </p>

<p>For example:</p>

<pre><code>@tf.custom_gradient
def my_multiple(x,z):

def grad(dy):
    # return two gradients, one for 'x' and one for 'z'
    return (dy*z, dy*x)

return tf.identity(x*z), grad
</code></pre>

<p>Note that the second output of ""my_multiple"" is a function, not a gradient tensor. </p>
","If we use multiple variables as input, the number of gradients return from ""grad"" function should be equals to number of input variables, though we maybe don't care about some of them.
Note that the second output of ""my_multiple"" is a function, not a gradient tensor.","<pre><code>@tf.custom_gradient
def my_multiple(x,z):

def grad(dy):
    # return two gradients, one for 'x' and one for 'z'
    return (dy*z, dy*x)

return tf.identity(x*z), grad
</code></pre>","['How to use @tf.custom_gradient with multiple inputs in TensorFlow?', 'TensorFlow custom gradient for functions with multiple inputs', 'Handling multiple input gradients in TensorFlow custom_gradient', 'Example of @tf.custom_gradient with two or more inputs in TensorFlow', 'Defining custom gradients for multi-input functions in TensorFlow', 'TensorFlow custom_gradient decorator for functions with multiple arguments', 'How to return multiple gradients in TensorFlow custom_gradient', 'Troubleshooting TensorFlow custom_gradient with multiple inputs', 'Advanced usage of @tf.custom_gradient in TensorFlow', 'TensorFlow custom gradient tutorial for multi-input functions']","['How to use @tf.custom_gradient with multiple inputs in TensorFlow?', 'How to define custom gradients for functions with multiple inputs in TensorFlow?', 'Example of @tf.custom_gradient with two inputs in TensorFlow', 'Handling multiple input gradients in TensorFlow custom_gradient', 'How to return multiple gradients in @tf.custom_gradient decorator in TensorFlow?', 'Troubleshooting ValueError: too many values to unpack (expected 2) in TensorFlow custom_gradient', 'Best practices for implementing custom gradients for multi-input functions in TensorFlow']",{'https://www.youtube.com/watch?v=VmaBfi-CWv4'},"['""""""[Document(page_content=""hello guys and welcome to another tensorflow tutorial today I\'ll be showing you guys how to make a custom layer with custom gradient so without further Ado let\'s just start coding so obviously we\'re going to import dense flow as TF as always and then we\'re gonna actually make it close let me just add this a few lines so that python doesn\'t complain about formatting issues so you\'re going to be replicating the dense layer so I\'m just going to call it my dense layer and then we have to we\'re going to extend off the the layer class so layers.layer then now we have the make an init function um begin I want to pass in the input size and the hidden hidden size then we\'ll just initialize W this is not really needed like all these initializes these next three lines that I\'m going to do but I\'m just going to put them on so it\'s easier to convert this to make it more robust which I\'ll explain to you guys later how you can make it more robust um then so yeah we\'re just gonna re we\'re gonna write over W now which is solve.add I\'m going to solve that ad weight and then we\'re just going to name this W then shape equals input size sorry input size then hidden it\'s actually soft but here in size we\'ll just leave it at that salon so this is we can just hold paste this into somewhere else to make a more robust in the future then we\'re gonna have an initializer it\'s going to be a random normal then we have to set trainable to true Okay cool so off that what is oh okay so yeah we\'ve got something really important which is we have to add this line in um and actually I have to add in the class name as well comma solve then that should yeah okay that works and then we want to do the same for w as well but W is going to be a bit different because the shape is actually it\'s just the hidden hidden size and we\'ll just add a comma afterwards okay check trainable to True randomly um I think we can for now we\'ll just send this but normally you just set um B2B 0 that\'s fine W has to be randomly initialized so that it\'s not symmetrical because if you set it to zero then it\'s just all the neurons are going to basically do the same function it\'s the same operation the same inputs so it\'s good the function is going to be symmetrical well the operation is going to be symmetrical so what we want to do next is wanna just create the core function this is going to be the the forward pass basically and this would just be return matte sorry TF dot Matt small tf.map more and then why what do we have to do with the scanner yeah so this would be solve Dot W and then I\'m just trying to think now if we think it\'ll be soft so yeah okay so that\'s to be X first and then yeah solve the dot solve the W and then we Plus solve that b so this is how you just replicate like a dense layer and also this is actually the an indent this that should be fine okay so yeah let\'s format that so this is without like a custom gradient this is just you can use tensorflows functions to build your own custom layer and as long as you\'re using tensorflow\'s functions a tensor will be able to keep track of the the computational graph but if you\'re not gonna if you want to create your own function with your own gradients you\'ll have to actually make your own tensorflow function with that with a custom gradient so um to do that we\'ll just um we\'ll have to start with TF Dot well we\'ll just call this custom we\'ll make the function for gradient then we\'re going to take in a WRB and an X and then we have to decorate the function just return decorate the function with TF dot custom gradient there is no brackets of that okay so um four passes the same as autopia so let\'s just go paste this and take out the solves by the way also note that the um this this function is actually outside of the class but you can put it in but like yeah it\'s better to but uh it\'s fine if you have it outside as well um after that we actually Gonna Wanna do the back propagation so we\'re gonna create the gradient function so that\'s gonna take in dldz which is the the gradients that have been back propagated through the network so we take that in and before actually I go into this I\'m going to explain to you guys how like how I came about these formulas and like where I got them from Etc so you guys can follow along easily and explain to you a bit about that so I\'ll see you there okay cool so these are the these are the standard formulas for computing the gradients for the fully connected layer or dense layer intense flows the case so first I want you to notice that um the input data X at the bottom right over here it\'s uh it\'s in well the each training example is in its own column so like a training example would be like one image or one row of a table if you were working with tabular data um but yeah so as you can see tensorflow actually stores the the data in the opposite way that was in the previous slide so like it\'s actually the rows are for each training example so that\'s why we\'re gonna have to tweak it a bit so to get these formulas that I have in front of you over here what I\'ve actually done is I\'ve just transposed X so like the tensorflow X X of T and I\'m multiplied by dldz deltz is also like transpose from the previous slide so the the LDL dldz is the The Still d said but transpose then yeah I did that for both W and wnx so I basically just transpose this W or the X and I swap these two the dldb is basically the same as before because it\'s just straight up a dld of all the bias grain is basically the ldb is just this dldz it\'s straight up just equal to that the catch for that is that we actually are working in batches so we have many dld said it\'s not like exactly so so this would be like 100 Vector but this would be like 32 by a hundred so what we\'re gonna have to do is that we\'re gonna we\'re going to have to um we\'re gonna have to sum across the the batching dimension so that would be the First Dimension but yeah that\'s all you kind of need to know so yeah let\'s continue coding so from the previous previous uh slides we actually need to compute two things quick before do anything else I\'m gonna copy the transverse of w and then transpose of X TF dot transpose and X easy as that tldw so dldw was actually just TF dot mat mole of X of t d l d z if you can remember and then dldx is equal to TF dot map Mall of DLT said and WFT and then the ldb I said was equal to so dldb is equal to TF dot reduce sum of the LTZ axis so I was I was actually just equal to dltz but we\'re going to want to sum this so it\'s just some quick so tf.reduce sum and then we\'re gonna do it across the batching Dimension which is zero and then we want to return the ldw dldb DL DX the order of this is very important first of all I just want to make two comments so the order of this is very important as to be the same order as the as the parameters are passed into the actual like the the function it should be custom operation and second of all that this W has to be the same Dimension as this B has to be the same Dimension as this x has to be the same Dimension as this well sorry this has to be the same Dimension as X for this to work all stance flow is going to throw some errors after that we kind of we just have to return we have to return the Y of course and then we have the return grad function but we don\'t actually turn the the function we just returned point all the we don\'t return like a value from the function we turn the function itself so we don\'t put a bracket at the end there so after that actually it\'s Gonna Wanna I\'m just gonna put this in here and then we\'re actually going to change this to custom operation then that should be the same so I\'m just double checking everything everything looks good so let me just show you guys how to actually use this so it\'s just a if name equals main then I\'m just gonna pull in we can use mnst to test this so X train comma y train comma X test comma y test then we want to pull in the TF dot qrs.datorsets dot and then we want mnest mnest.load data X train so we want to actually pre-process extra invest it\'s uh 28 by 28 by one so you want to kind of reshape it so that we can flatten it into a two-dimensional tensor so what we\'re going to do for that is we\'re going to go X train and then minus one so tens flow is going to infer the dimension while the the value of this Dimension or how big this is and then the image is 28 by 28 so that\'s why we\'re going to add you know the 28 by 28 and then I\'m just gonna put this to float32 I don\'t think this is really needed because when we divide by 255.0 I think it will change that to float32 anyway and we\'ll do the same for X test so let\'s just that could paste this for X test cool all right so let\'s just first um I just want to print because we\'re gonna do this we\'re gonna do a test for both the custom dance layer and the intense Flow State so this one I\'ll print this I\'m gonna make like a heading there basically and off that we\'re gonna actually create our model so without custom layer in it so TF Dot curs.sequential sorry about that and then tf.curus we want an input layer sorry layers Dot input and then shape is equal to 28 times 28. that\'s fine off that put a comma at the end and then Rihanna put in our dense layer so the input is going to be 28 times 28. and then we want also the output size of the header and size this would be 64. and then just copy paste this three times okay so we actually have to so this is we\'re gonna feed a dimension of 64 in here so we\'re gonna want to change this to 64. you can lower this this is going to be 32 this will be 10. after that we\'ll actually I think that\'s it um then we\'ll add model zero dot compile and then we want to just set our losses loss is equal tip TFT losses dot sparse categorical entropy and then from logit\'s multi true so basically um normally we\'d put it into a soft Max but since we\'re not putting it into a soft Max we\'re going to say it\'s from the largest so it\'s going to apply the soft Max and then it\'s going to apply this loss function um yeah and after that we will just do Optimizer equals TF dot curious Dot optimizers dot atom and then we\'ll just have the default learning rate so we don\'t need a actually add anything after that we\'ll have metrics this is obviously accuracy tens flows well Python\'s getting in the way accuracy um after that we\'ll just we can just fit the model Modelo dot fit extreme y train and then we\'re just gonna do four five epochs um and we\'ll do even worry about it we\'ll evaluate it on the test set um evaluate X test whitest and then so I said we\'re gonna do this for both uh our custom layer and also our of all tense flows dense layers so let\'s just change this um so tensorflow no I\'m not the right one this is tensorflow I just want to add this up here quick so we know it when it ends we\'re going to change this to an equals double line to show that it\'s done this at the bottom here as well so I don\'t forget later tensorflow dance layer okay so we want to change this to so for with python we can just you can just middle click and well not middle click sorry you click on your scroller and you just drag and it does this like a block highlight so tf.kiris dot layers dot dance and then we don\'t need this and we don\'t need this sorry I don\'t need first numbers 64 and this would so you can see the difference between all those right here just in terms of like when you initialize them you have to add both the inputs but tensorflow kind of um just infers the size so yeah uh everything seems to be set up so we can just actually run this up we got an error what is this it\'s not callable oh I think I did something yeah I\'ve got the dot reshape we have to reshape this all right let\'s run this again oh another area Okay um object has no attribute X we have to not double check this so let\'s just change this quick solter W salt dot b and then we we don\'t put in solve.x we put in x all right let\'s try this one more time this should work cool there\'s a working so yeah off this is done training I\'ll get back to you guys all right cool so it\'s done we can see that the results are very similar so it starts off at like 80 89 this starts off at like maybe 89.5 this is 88.5 so percent higher then afterwards it gets to about 92 this gets to 92.35 but the tensorflow actually beats it out by a a fraction of a percent in on the test set but this is basically due to how the weights are initialized and yeah that would depend on like maybe the this uh first first layer got better initialization weights and was able to train faster but yeah um they seem quite similar and there\'s very little difference let me just tell you guys how how you can make this more robust and you don\'t have to actually add in an input layer so what we can do is instead of having it in it well this this coding in it we can actually make a a bold function and this is called when tensorflow gets the input shape and maybe the models compiled I\'m not completely sure when this is run it\'s run like different size but basically it passes in the input shape and we can use this input shape to actually initialize our weights and we won\'t have to actually get in the input shape from the U from the the function initialization actually get our when tensorflow finds out the input shape and bolts the the neural network so let\'s just change our code so that it fits and this would be -1 because we want the last we can also just put one here because we\'re expecting two-dimensional input but yeah let\'s just leave it at one minus one so that it\'s more robust after that we actually have to change this so let\'s just so we don\'t need any of this and our layers are basically equal now and if we run it it should work but yeah that\'s what you that\'s how you create a custom layer with custom gradient intense flow hope you guys enjoyed please leave a like And subscribe if you want to see more content like this also drop a comment if you guys want to see anything if you guys want me to explain or make a tutorial on something that you guys are confused about hope you guys have a great day bye"", metadata={\'source\': \'VmaBfi-CWv4\'})]""""""']",{'https://stackoverflow.com/questions/51836242/tf-custom-gradient-with-multiple-inputs'},"['""""""tf.custom_gradient with multiple inputs\n\nAsked 5 years, 7 months ago\n\nModified 5 years ago\n\ntf.custom_gradient accepts only one Tensor x, what if this op needs more than one inputs? For example, to define the gradient of Softmax which needs input x and label? Thanks for the suggestion from @AllenLavoie, I use a Python list as input. def self_define_op_multiple_inputs(): @tf.custom_gradient def loss_func(input_): x = input_[0] label = input_[2] def grad(dy): return [dy, dy] return x - label, grad x = tf.range(10, dtype=tf.float32) y = tf.range(10, dtype=tf.int32) loss = loss_func([x, y]) if __name__ == \'__main__\': self_define_op_multiple_inputs()\n\nIt seems that it will convert the Python list to a Tensor. The snippet above will raise a TypeError: TypeError: Cannot convert a list containing a tensor of dtype <dtype: \'int32\'> to <dtype: \'float32\'> (Tensor is: <tf.Tensor \'range_1:0\' shape=(10,) dtype=int32>)\n\nhuangbiubiuhuangbiubiu\n\n1,6\n\nThe documentation says x and y can both either be Tensors or sequences of Tensors. Did this not work for you? â€“ Allen Lavoie Aug 14, 2018 at 16:32\n\n@AllenLavoie Actually this is exactly what confused me. I don\'t understand what\'s sequences of Tensors, does it mean a Python list of Tensor? My interpretation is Python list (or tuple, etc.). So len(x) is the number of inputs to the operation, len(y) is the number of outputs. Then the gradient function takes len(y) Tensor argument and returns len(x) Tensors. â€“ Allen Lavoie Aug 15, 2018 at 18:33\n\n@AllenLavoie I tried to use list but it seems like a list will be converted as a Tensor, which will cause an error if there are multiple inputs with different type and matched shape. The question has been updated. @AllenLavoie I created an issue on github\n\n | Show 1 more comment\n\nI ran into a similar problem yesterday and found this post, and I believe I know what you are running into. Problem is that while using @tf.custom_gradient, the function that it decorates can have multiple inputs (instead of a list of tensors). Look at the following code(note that it\'s just a test code with no actual meaning):\n\n@tf.custom_gradient def loop1(x,a): def grad(dy): return dy*3,dy*2 n = tf.multiply(x,a) return n,grad\n\nBy using two inputs x and a, you have to return two gradients respectively in the grad function. dy*3 corresponds to the gradient of x and dy*2 corresponds to the gradient of a. I think in this function the documents make people very confusing, but you can still use multiple inputs, just make sure that you also have the same number of gradients, or else you will run into errors. 1\n\nCan we return None as gradients for unused terms ? I believe you need something like this a tf Graph input:+ n_input is the input number\n\nx = tf.placeholder(""float"", [None, n_input]) y = tf.placeholder(""float"", [None])\n\nDoes this answer your question ? 1\n\nThanks for your help.""""""', '""""""But it seems that you didn\'t understand what I am talking about. tf.custom_gradient is not a computational graph. You can read docs for more details.""""""', '""""""tf.custom_gradient with multiple inputs\n\nAsked 5 years, 7 months ago\n\nModified 5 years ago\n\ntf.custom_gradient accepts only one Tensor x, what if this op needs more than one inputs? For example, to define the gradient of Softmax which needs input x and label? Thanks for the suggestion from @AllenLavoie, I use a Python list as input. def self_define_op_multiple_inputs(): @tf.custom_gradient def loss_func(input_): x = input_[0] label = input_[2] def grad(dy): return [dy, dy] return x - label, grad x = tf.range(10, dtype=tf.float32) y = tf.range(10, dtype=tf.int32) loss = loss_func([x, y]) if __name__ == \'__main__\': self_define_op_multiple_inputs()\n\nIt seems that it will convert the Python list to a Tensor. The snippet above will raise a TypeError: TypeError: Cannot convert a list containing a tensor of dtype <dtype: \'int32\'> to <dtype: \'float32\'> (Tensor is: <tf.Tensor \'range_1:0\' shape=(10,) dtype=int32>)\n\nhuangbiubiuhuangbiubiu\n\n1,6\n\nThe documentation says x and y can both either be Tensors or sequences of Tensors. Did this not work for you? â€“ Allen Lavoie Aug 14, 2018 at 16:32\n\n@AllenLavoie Actually this is exactly what confused me. I don\'t understand what\'s sequences of Tensors, does it mean a Python list of Tensor? My interpretation is Python list (or tuple, etc.). So len(x) is the number of inputs to the operation, len(y) is the number of outputs. Then the gradient function takes len(y) Tensor argument and returns len(x) Tensors. â€“ Allen Lavoie Aug 15, 2018 at 18:33\n\n@AllenLavoie I tried to use list but it seems like a list will be converted as a Tensor, which will cause an error if there are multiple inputs with different type and matched shape. The question has been updated. @AllenLavoie I created an issue on github\n\n | Show 1 more comment\n\nI ran into a similar problem yesterday and found this post, and I believe I know what you are running into. Problem is that while using @tf.custom_gradient, the function that it decorates can have multiple inputs (instead of a list of tensors). Look at the following code(note that it\'s just a test code with no actual meaning):\n\n@tf.custom_gradient def loop1(x,a): def grad(dy): return dy*3,dy*2 n = tf.multiply(x,a) return n,grad\n\nBy using two inputs x and a, you have to return two gradients respectively in the grad function. dy*3 corresponds to the gradient of x and dy*2 corresponds to the gradient of a. I think in this function the documents make people very confusing, but you can still use multiple inputs, just make sure that you also have the same number of gradients, or else you will run into errors. 1\n\nCan we return None as gradients for unused terms ? I believe you need something like this a tf Graph input:+ n_input is the input number\n\nx = tf.placeholder(""float"", [None, n_input]) y = tf.placeholder(""float"", [None])\n\nDoes this answer your question ? 1\n\nThanks for your help.""""""', '""""""But it seems that you didn\'t understand what I am talking about. tf.custom_gradient is not a computational graph. You can read docs for more details.""""""', '""""""tf.custom_gradient with multiple inputs\n\nAsked 5 years, 7 months ago\n\nModified 5 years ago\n\ntf.custom_gradient accepts only one Tensor x, what if this op needs more than one inputs? For example, to define the gradient of Softmax which needs input x and label? Thanks for the suggestion from @AllenLavoie, I use a Python list as input. def self_define_op_multiple_inputs(): @tf.custom_gradient def loss_func(input_): x = input_[0] label = input_[2] def grad(dy): return [dy, dy] return x - label, grad x = tf.range(10, dtype=tf.float32) y = tf.range(10, dtype=tf.int32) loss = loss_func([x, y]) if __name__ == \'__main__\': self_define_op_multiple_inputs()\n\nIt seems that it will convert the Python list to a Tensor. The snippet above will raise a TypeError: TypeError: Cannot convert a list containing a tensor of dtype <dtype: \'int32\'> to <dtype: \'float32\'> (Tensor is: <tf.Tensor \'range_1:0\' shape=(10,) dtype=int32>)\n\nhuangbiubiuhuangbiubiu\n\n1,6\n\nThe documentation says x and y can both either be Tensors or sequences of Tensors. Did this not work for you? â€“ Allen Lavoie Aug 14, 2018 at 16:32\n\n@AllenLavoie Actually this is exactly what confused me. I don\'t understand what\'s sequences of Tensors, does it mean a Python list of Tensor? My interpretation is Python list (or tuple, etc.). So len(x) is the number of inputs to the operation, len(y) is the number of outputs. Then the gradient function takes len(y) Tensor argument and returns len(x) Tensors. â€“ Allen Lavoie Aug 15, 2018 at 18:33\n\n@AllenLavoie I tried to use list but it seems like a list will be converted as a Tensor, which will cause an error if there are multiple inputs with different type and matched shape. The question has been updated. @AllenLavoie I created an issue on github\n\n | Show 1 more comment\n\nI ran into a similar problem yesterday and found this post, and I believe I know what you are running into. Problem is that while using @tf.custom_gradient, the function that it decorates can have multiple inputs (instead of a list of tensors). Look at the following code(note that it\'s just a test code with no actual meaning):\n\n@tf.custom_gradient def loop1(x,a): def grad(dy): return dy*3,dy*2 n = tf.multiply(x,a) return n,grad\n\nBy using two inputs x and a, you have to return two gradients respectively in the grad function. dy*3 corresponds to the gradient of x and dy*2 corresponds to the gradient of a. I think in this function the documents make people very confusing, but you can still use multiple inputs, just make sure that you also have the same number of gradients, or else you will run into errors. 1\n\nCan we return None as gradients for unused terms ? I believe you need something like this a tf Graph input:+ n_input is the input number\n\nx = tf.placeholder(""float"", [None, n_input]) y = tf.placeholder(""float"", [None])\n\nDoes this answer your question ? 1\n\nThanks for your help.""""""', '""""""But it seems that you didn\'t understand what I am talking about. tf.custom_gradient is not a computational graph. You can read docs for more details.""""""', '""""""tf.custom_gradient with multiple inputs\n\nAsked 5 years, 7 months ago\n\nModified 5 years ago\n\ntf.custom_gradient accepts only one Tensor x, what if this op needs more than one inputs? For example, to define the gradient of Softmax which needs input x and label? Thanks for the suggestion from @AllenLavoie, I use a Python list as input. def self_define_op_multiple_inputs(): @tf.custom_gradient def loss_func(input_): x = input_[0] label = input_[2] def grad(dy): return [dy, dy] return x - label, grad x = tf.range(10, dtype=tf.float32) y = tf.range(10, dtype=tf.int32) loss = loss_func([x, y]) if __name__ == \'__main__\': self_define_op_multiple_inputs()\n\nIt seems that it will convert the Python list to a Tensor. The snippet above will raise a TypeError: TypeError: Cannot convert a list containing a tensor of dtype <dtype: \'int32\'> to <dtype: \'float32\'> (Tensor is: <tf.Tensor \'range_1:0\' shape=(10,) dtype=int32>)\n\nhuangbiubiuhuangbiubiu\n\n1,6\n\nThe documentation says x and y can both either be Tensors or sequences of Tensors. Did this not work for you? â€“ Allen Lavoie Aug 14, 2018 at 16:32\n\n@AllenLavoie Actually this is exactly what confused me. I don\'t understand what\'s sequences of Tensors, does it mean a Python list of Tensor? My interpretation is Python list (or tuple, etc.). So len(x) is the number of inputs to the operation, len(y) is the number of outputs. Then the gradient function takes len(y) Tensor argument and returns len(x) Tensors. â€“ Allen Lavoie Aug 15, 2018 at 18:33\n\n@AllenLavoie I tried to use list but it seems like a list will be converted as a Tensor, which will cause an error if there are multiple inputs with different type and matched shape. The question has been updated. @AllenLavoie I created an issue on github\n\n | Show 1 more comment\n\nI ran into a similar problem yesterday and found this post, and I believe I know what you are running into. Problem is that while using @tf.custom_gradient, the function that it decorates can have multiple inputs (instead of a list of tensors). Look at the following code(note that it\'s just a test code with no actual meaning):\n\n@tf.custom_gradient def loop1(x,a): def grad(dy): return dy*3,dy*2 n = tf.multiply(x,a) return n,grad\n\nBy using two inputs x and a, you have to return two gradients respectively in the grad function. dy*3 corresponds to the gradient of x and dy*2 corresponds to the gradient of a. I think in this function the documents make people very confusing, but you can still use multiple inputs, just make sure that you also have the same number of gradients, or else you will run into errors. 1\n\nCan we return None as gradients for unused terms ? I believe you need something like this a tf Graph input:+ n_input is the input number\n\nx = tf.placeholder(""float"", [None, n_input]) y = tf.placeholder(""float"", [None])\n\nDoes this answer your question ? 1\n\nThanks for your help.""""""', '""""""But it seems that you didn\'t understand what I am talking about. tf.custom_gradient is not a computational graph. You can read docs for more details.""""""']"
59555206,tf.keras,example required,keras to tf.keras Conversion: Dense layer dimensions not defined?,"<p>So I've built a convnet using pure <code>keras</code>. It compiles and operates exactly as intended, but I need to convert it to use <code>tf.keras</code> so that I can make use of <code>tfmot</code>. Having read documentation, I attempted to convert it, only to get the following error:</p>

<p><code>The last dimension of the inputs to Dense should be defined. Found None.</code> </p>

<p>Any idea what I'm doing wrong?</p>

<p>Thanks!</p>

<p>Original <code>keras</code> model:</p>

<pre><code>input_layer = keras.layers.Input(shape=(100,))
reshape_layer = keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = keras.layers.Flatten()(conv_layer_5)
label_layer = keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = keras.layers.Dense(1, activation=""linear"")(label_layer)

model = keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>Converted <code>tf.keras</code> model:</p>

<pre><code>input_layer = tf.keras.layers.InputLayer(input_shape=(100,))
reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
</code></pre>

<p>EDIT 1:</p>

<p>I thought maybe I could get around the issue by saving the <code>keras</code> model after creation and loading it as a <code>tf.keras</code> model immediately before compilation / training. That throws the same error! </p>
","<p>There's few issues with your code. Fix them and you should be good to go,</p>

<h2>Issue 1: Use <code>Input</code> instead of <code>InputLayer</code></h2>

<p>The standard is to use <code>Input</code> layer instead of <code>InputLayer</code> (which infact uses <code>InputLayer</code> internally). You also need to change <code>input_shape</code> to <code>shape</code> if you are using <code>Input</code> layer.</p>

<pre><code>input_layer = tf.keras.layers.Input(shape=(100,))
</code></pre>

<h2>Issue 2: 2 <code>None</code> dimensions in the output</h2>

<p>When you execute the following line, you get two <code>None</code> dimensions in your output. </p>

<pre><code>reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
</code></pre>

<p>Which is why you are getting the above error. When defining the <code>Reshape</code> layer you don't define the <code>batch</code> dimension, which will be None. And that's the only dimension you can have as <code>None</code> if you want to use a <code>Dense</code> layer. Otherwise, the <code>Dense</code> layer cannot infer the shape of its weights (which is why you get the error). So change that to,</p>

<pre><code>reshape_layer = tf.keras.layers.Reshape((1, 100, 1))(input_layer)
</code></pre>

<p>The rest stays the same.</p>

<pre><code>conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
model.summary()
</code></pre>
","There's few issues with your code. Fix them and you should be good to go,
Issue 1: Use <code>Input</code> instead of <code>InputLayer</code></h2>

The standard is to use <code>Input</code> layer instead of <code>InputLayer</code> (which infact uses <code>InputLayer</code> internally). You also need to change <code>input_shape</code> to <code>shape</code> if you are using <code>Input</code> layer.

<pre><code>input_layer = tf.keras.layers.Input(shape=(100,))
</code></pre>

Issue 2: 2 <code>None</code> dimensions in the output</h2>

When you execute the following line, you get two <code>None</code> dimensions in your output.
<pre><code>reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)
</code></pre>

Which is why you are getting the above error. When defining the <code>Reshape</code> layer you don't define the <code>batch</code> dimension, which will be None. And that's the only dimension you can have as <code>None</code> if you want to use a <code>Dense</code> layer. Otherwise, the <code>Dense</code> layer cannot infer the shape of its weights (which is why you get the error). So change that to,

<pre><code>reshape_layer = tf.keras.layers.Reshape((1, 100, 1))(input_layer)
</code></pre>","<pre><code>conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)
conv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)
conv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)
conv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)
conv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)
flatten_layer = tf.keras.layers.Flatten()(conv_layer_5)
label_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)
output_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)

model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
model.summary()
</code></pre>","['How to convert a Keras model to a tf.keras model?', 'Common issues when converting Keras models to tf.keras models', 'How to define input shapes correctly in tf.keras?', 'How to use tf.keras.layers.InputLayer correctly?', ""How to debug 'The last dimension of the inputs to Dense should be defined. Found None.' error in tf.keras?"", 'How to reshape layers in tf.keras?', 'How to use tfmot with tf.keras models?', 'How to save and load models in tf.keras?']","['How to convert a Keras model to a tf.keras model?', 'What is the correct way to define the input layer in tf.keras?', ""How to resolve 'The last dimension of the inputs to Dense should be defined. Found None.' error in tf.keras?"", 'Differences between keras.layers.Input and tf.keras.layers.InputLayer', 'How to reshape input layers correctly in tf.keras?', 'Common issues when converting Keras models to tf.keras models']","{'https://www.youtube.com/watch?v=FIReIQlyZmM', 'https://www.youtube.com/watch?v=UYRBHFAvLSs', 'https://www.youtube.com/watch?v=oJ1i2c1KxKk', 'https://www.youtube.com/watch?v=ukBG9ALd8T8'}","['""""""[Document(page_content=""FRANCOIS CHOLLET:\\nHello, everyone. I\'m Francois. And I work on the Keras team. I\'m going to be talking\\nabout TensorFlow Keras. So this talk will\\nmix information about how to use the\\nKeras API in TensorFlow and how the Keras API is\\nimplemented under the hood. So we\'ll cover another view\\nof the Keras architecture. We\'ll do a deep dive into\\nthe layer class and the model class. We\'ll have an overview\\nof the functional API and a number of\\nfeatures that are specific to functional models. We\'ll look at how training\\nand inference work. And finally, we\'ll look at\\ncustom losses and metrics. So this is the overview of\\nthe Keras architecture and all the different submodules\\nand the different classes you should know about. The core of the Keras\\nimplementation is the engine module, which contains\\nthe layer class-- the base layer class from\\nwhich all layers inherit, as well as the network\\nclass, which is-- it\'s basically kind of modeled\\nits directed acyclic graph layers-- as well as the model class which\\nbasically takes the network class but adds training and\\nevaluation and sitting on top of it, and also the sequential\\nclass, which is, again, another type of model which\\njust wraps a list of layers. Then we have the layers\\nmodule, where all the action instances-- usable\\ninstances of layers go. We have losses and metrics\\nwith a base class for each, and a number of\\nconcrete instances that you can use in your models. We have callbacks,\\noptimizers, regularizers, and constraints, which\\nare much like the modules. So in this presentation,\\nwe go mostly over what\'s going on in the\\nEngine module, and also losses and metrics, not so much\\ncallbacks, optimizers, regularizers, and constraints. So in general, for\\nany of these topics, you could easily\\ndo a one-hour talk. So I\'m just going to focus on\\nthe most important information. So let\'s start with\\nthe layer class. So the layer is the core\\nabstraction in the Keras API. I think if you want\\nto have a simple API, then you should\\nhave one abstraction that everything is centered on. And in the case of\\nKeras, it\'s a layer. Everything in Keras pretty\\nmuch is a layer or something that interacts\\nclosely with layers, like models and instances. So a layer has a lot\\nof responsibilities, lots of built-in features. At its core, a layer is a\\ncontainer for some computation. So it\'s in charge of\\ntransforming a batch of inputs into a batch of outputs. Very importantly, this\\nis batchwise computation, meaning that you expect\\nN samples as inputs, and you\'re going to be\\nreturning N output samples. And the computation\\nshould typically not see any interaction\\nbetween samples. And so it\'s meant to work\\nwith eager execution, also graph execution. All the built-in layers\\nin Keras support both. But user-written layers could\\nbe only eager, potentially. We support having layers that\\nhave two different modules-- AUDIENCE: So this would mean\\nthat using different layers can support either\\nin graph or on eager? FRANCOIS CHOLLET: Yes. AUDIENCE: Yeah, OK. FRANCOIS CHOLLET: That\'s right. And typically, most layers are\\ngoing to be supporting both. If you only support\\neager, it typically means that you\'re\\ndoing things that are impossible to\\nexpress as graphs, such as recursive\\nlayers, such as SEMs. This is actually\\nsomething that we\'ll cover in this presentation. So, yeah, so layers also support\\ntwo modes-- so a training mode, an inference mode-- to do different things. And each mode,\\nwhich is something like dropout layer or the\\nbatch normalization layer. There\'s a support for\\nbuilt-in masking, which is about specifying certain\\nfeatures of timestamps and inputs that\\nyou want to ignore. This is very useful,\\nin particular, if you\'re doing sequence\\nprocessing with sequences where you have padded\\ntime steps or where you have missing time steps. A layer is also container\\nfor state, meaning variable. So, in particular,\\na trainable state-- the trainable\\nweights on the layer, which is what parametrizes\\nthe computation of the layer and that you update\\nduring back propagation; and the nontrainable\\nweights, which could be anything else that is\\nmanually managed by the layer implementer. It\'s also potentially\\na container that you can use to track losses\\nand metrics that you define on the fly during computation. This is something\\nwe\'ll cover in detail. Layers can also do a form\\nof static type checking. So they can check-- there is infrastructure\\nthat\'s built in to check the assumptions\\nthat the layer is making about its inputs that we can\\nraise nice and helpful error messages in case of user error. We support state\\nfreezing for layers, which is useful for\\nthings like fine-tuning, and transfer learning, and GANs. You have infrastructure for\\nserializing and deserializing layers and saving\\nand loading a state. We have an API that you\\ncan use to build directed acyclic graphs of layers. It\'s called a functional API. We\'ll cover it in detail. And in the near future,\\nlayers will also have built-in support\\nfor mixed precision. So layers do lots of things. They don\'t do everything. They have some assumptions. They have some restrictions. In particular, gradients\\nare not something that you specify on the layer. You cannot specify custom a\\nbackwards pass on that layer, but this is something we\'re\\nactually considering adding, potentially, something like a\\ngradient method on the layer. So it\'s not currently a feature. They do not support most\\nlow-level considerations, such as device\\nplacement, for instance. They do not generally take\\ninto account distribution. So they do not include\\ndistribution-specific logic. At least, that should be true. In practice, it\'s almost true. So they\'re as distribution\\nagnostic as possible. And very importantly, they only\\nsupport batchwise computation, meaning that\\nanything a layer does should start with a\\ntensor containing-- or a nested structure of\\ntensors containing N samples and should output\\nalso N samples. That means, for\\ninstance, you\'re not going to do non-batch\\ncomputation, such as bucketing samples of the same length. When you\'re doing\\ntime-switch processing, you\'re not going to\\nprocess [INAUDIBLE] data sets with layers. You\'re not going to have\\nlayers that don\'t have an input or don\'t have an output outside\\nof a very specific case, which is the input layer,\\nwhich we will cover. So this is the most basic layer. You could possibly write it\\nas a constructor in which you create two-tier variables. And you say these\\nvariables are trainable. And you assign them as\\nattributes on the layer. And then it has a call method,\\nwhich essentially contains the batch of inputs to batchify\\nthis computation, in this case, just w x plus b. So what happens\\nwhen you instantiate this layer is that it\'s going\\nto create these two variables, set them as attributes. And they are automatically\\ntracked into this list, trainable_weights. And when you call the layer\\nusing __call operator, it\'s just going to pass. So it\'s going to defer\\nto this call method. So in practice, most layers\\nyou\'re going to write are going to be a\\nlittle bit more refined. They\'re going to look like this. So this is a lazy layer. So in the constructor,\\nyou do not create weights. And the reason you\\ndo not create weights is because you want to\\nbe able to instantiate your layer without knowing what\\nthe input shape is going to be. Whereas in the\\nprevious case, here-- so this is the previous slide-- you had to pass the input\\ndimension as a constructor argument. So in this case, you\\ndon\'t have to do this because you\'re going to create\\nthe state in a build method, which takes an input\\nshape argument. And when instantiated,\\nthe layer, it does not have any weights. And when you call it\\nfor the first time, this __call operator is going to\\nchain the build method that you have here and the call method. And the build\\nmethod, you see, we use these add weight shortcut. So it\'s basically just a\\nslightly shorter version of creating a variable and\\nassigning it on the layer. OK. Layers can also have\\nnontrainable states. So a trainable state\\nis just variables that are tracked in\\ntrainable_weights. Nontrainable state is tracked\\nin non_trainable_weights. It\'s very simple. So in this layer,\\nin the constructor, you create this\\nself.total scalar variable that starts at 0. You specify it\'s nontrainable. And in the computation method,\\nyou just update this variable. And basically, you\\njust keep track of the total sum of the\\ninputs seen by this layer. So it\'s a kind of useless layer. And as you see,\\nevery time you call this layer, the value of these\\nvariables is being updated. Layers can be nested. So you can set-- you can set layer instances\\nas attributes to a layer, even if they\'re\\nunbuilt, like here. And when you do that, the outer\\ncontainers-- so in this case, the MLPBlock instance--\\nis going to be keeping track of the trainable weights\\nand nontrainable weights of the underlying layers. And all these layers, which in\\nthe constructor are unbuilt, are going to be built,\\nso have their variables created the first time you\\ncall the outer instance. And this is the most\\nbasic way in which you can be using a layer. You would just instantiate-- you know-- grab\\nsome loss function, which could be anything. Grab some optimizer. Iterate with some data-- so we have input\\ndata and targets. Open the GradientTape. Call the layer inside\\nthe GradientTape-- so that\'s operations\\ndone by the call method and recorded on the tape. Call your loss function\\nto get some loss value. And then you use the\\ntape and the loss value to retrieve the gradients of the\\ntrainable state of the layer. Then you apply these gradients. So this is a full,\\nend-to-end, training loop. By that point, you\\nknow about layers, which are containers for\\nstate and computation; you know about trainable\\nstate, nontrainable state. You know about nesting layers. And you know about training\\nthem with this kind of loop. So typically, you\\nwould put a spot of the loop-- like\\neverything starting with opening\\nGradientTape-- ending with applying the gradients. You put that in a TF function\\nto get a graph execution and faster performance. So when you know\\nall these things, you can use the Keras API to\\nimplement literally anything. However, it\'s going to\\nbe a fairly low-level way of implementing things. So by that point, you know\\neverything except you actually know nothing. So let\'s go further. One neat feature is\\nthat you can use layers to keep track of\\nlosses and also metrics that you define on the\\nfly, doing computation. Let\'s say, for instance, with\\nour linear layer after we just compute w, x, we\\nwant to keep track-- we want to add an\\nactivation loss on the value x, which is just going to be\\nthe sum of this output times-- So it\'s not actually a great\\nloss because it should probably be squared-- sum of the square instead\\nof just sum, but whatever-- times some factor. And when you have a layer like\\nthis, every time you call it, the scalar tensor that you\\nadded here in this add_loss call is going to be tracked in\\nthis layer.losses list. And every time you call\\nthe layer, this gets reset. When you have nested layers,\\nthen the outer container is going to keep track of the\\nlosses of the inner layers. And you can call the inner\\nlayers multiple times. It\'s not going to reset the\\nlosses until you actually call the outer container. So the way you would use this\\nfeature is something like this. After you open your GradientTape\\nand you call your layer and you compute the\\nmain loss value, you would add to this loss value\\nthe sum of the losses collected during the forward pass. So you can use this\\nfeature to do things like weight triggerization,\\nactivity regularization compute things like the\\nKL divergence, so all kinds of losses\\nthat basically are easier to compute\\nwhen you have access to intermediate results in the-- AUDIENCE: Just a question. So if you have call at loss in\\na inner layer, does it call-- but that layer is contained\\nin another layer-- does it call add_loss\\non the outer layer too? FRANCOIS CHOLLET: Yes. So for instance, if linear layer\\nand multiple layers inside it, when you retrieve\\nthis, this should be a linear layer that losses-- not [INAUDIBLE]\\nlosses, whatever. It\'s going to recursively\\nretrieve all the losses, including the top-level losses. AUDIENCE: So, I\\nguess my question is, does a layer know that it\'s\\nbeing called from inside the-- FRANCOIS CHOLLET:\\nThat\'s correct, meaning that\'s when\\nit\'s called from inside, you can create multiple terms. It\'s not going to\\nreset the losses. The losses are only reset\\nwhen you call the top level container. So there is a call\\ncontext thing. AUDIENCE: That\'s-- I would\\nexpect it to be reset every time you call it, but the\\nparents\' losses [INAUDIBLE].. FRANCOIS CHOLLET:\\nSo if you do that, you could not share\\na layer that creates losses inside a bigger model. AUDIENCE: I mean, I\\nguess I was thinking that the inner\\nlayer would reset, but the outer layer\\nwould not reset. So it would keep-- as long as all the inner\\nlayer losses [INAUDIBLE].. FRANCOIS CHOLLET: So\\nthey\'re gathered on the fly. So that\'s not exactly accurate. But yeah, anyway, so yeah. AUDIENCE: How does\\nthe resetting happen? Can you explain? FRANCOIS CHOLLET: Yeah, sure. Basically, you just--\\nso you are going to-- so you can-- it\'s called at\\nthe end of __call for the outer container. And it\'s called recursively. So it\'s going to clear the\\nlosses of all the inner layers. If you want to do it manually,\\nall layers and models have a reset losses,\\nI believe it\'s called, method that you\\ncan use to force clear all the losses, which\\ncould happen, for instance, if you have multiple\\ncalls of the same model. [INAUDIBLE] potentially\\nthe [INAUDIBLE] use case could be-- anyway, AUDIENCE: Sorry, so\\nI didn\'t understand how reset losses is not called. How does a layer know\\nthat it\'s been called as-- from an outer layer? AUDIENCE: In _call, there\'s\\nbasically a contact manager that sort of says\\nyou\'re in _call. And so that\'s why as you\\ngo down the line, if you\'re calling a layer that\'s\\nalready being called inside another layer, it\\ncan use that contact manager to know whether it\'s\\nthe top-level call. AUDIENCE: OK. FRANCOIS CHOLLET: So, yeah. So layers also\\nsupport serialization. So if you want to make\\na layer serializable, you just implement\\na get_config method, which typically just packs\\nthe constructor arguments into a dictionary. And when you\'ve implemented\\nthis get_config method, you can serialize your layer as\\nthis [INAUDIBLE] config dict, which is JSON serializable. And you can use it to\\nre-instantiate the same layer. So this does not keep track\\nof the state of the layer, meaning the value of the weight. So this is done separately. And so layers also\\nsupports two modes-- training mode and\\ninference mode. If you want to use\\nthis feature, you would have a training\\nargument in call. So this is a very simple example\\nof a BatchNormalization layer, where, when you\'re\\nin training mode, you\'re going to be computing\\nthe mean and variance of the current batch. And you\'re going to use\\nthese statistics to normalize your inputs. And you\'re going to be\\nupdating the moving mean and variance on the layer, which\\nare nontrainable weights here. And if you\'re in\\ninference mode, you\'re just going to use the moving\\nstatistics to normalize your inputs. So now let\'s move on\\nto the model class. You saw in one of\\nthe previous examples that layers can be nested. If you just switch\\nin this example from, I think, the MLP class inherit\\nfrom the model class instead of the layer class, then\\nessentially nothing changes except that now you have access\\nto a training and evaluation and inference and saving API. So once you\'ve\\ninherited from model, you can do things\\nlike mlp.compile with an optimizer in\\nthe loss instance. Then you can call fit, which is\\ngoing to automatically iterate over this data set and minimize\\nthis BinaryCrossentropy from logits loss using\\nthe Adam optimizer. It\'s going to iterate 10\\ntimes over the data set. And you can also save\\nthe state of this model with this mlp.save method. So what\'s the difference\\nbetween the layer and the model? In short, it\'s that\\na model handles top-level functionality. So a model is a layer. So it does everything\\nlayer does in terms of network construction. It also has these compile, fit,\\nevaluate, and predict methods. It\'s about saving. So when you call save,\\nthat includes not only the configuration\\nof the model, like the get config thing\\nwe saw previously. It also includes the\\nstate of the model and the value of the weights. It also includes the\\noptimizer that the model was compiled with and the\\nstate of the optimizer. It also supports some basic\\nforms of model summarization and visualization. I can call model\\nSummary, which is going to return a description of\\nall the layers inside the model and the number of parameters\\nthat the model uses and so on. In short, the layer\\nclass corresponds to what is usually\\nreferred to as a layer, like when you talk\\nabout convolution layer, recurrent layer, so on. It can also be used to refer\\nto as what is sometimes called a block, like a resonant\\nblock or inception block. So a layer is basically either\\na literal layer or block in a bigger model. And the model is really like\\nthe top level of things-- the outer thing--\\nlike what people refer to as a model or a network. So typically, what you will\\ndo is use the layer class to define inner\\ncomputation blocks and use the model class to\\ndefine the one outer model-- so the thing that\\nyou\'re actually going to be training and saving\\nand exporting for production. For instance, if you are\\nworking on the ResNet50 model, you\'d probably have\\nseveral ResNet blocks subclassing the layer class. And then you would combine\\nthem into one big subclass model on which you would be\\nable to compile and fit and save and so on. One situation that\'s\\nspecific to TensorFlow 2 that not many\\npeople know about is that by default, when\\nyou call compile and fit, you\'re going to be using graph\\nexecution because it\'s faster. However, if you want to\\nexecute your model eagerly, you can pass this run_eagerly\\nargument in compile. You can also just\\nset it directly as an attribute on\\nthe model instance. So when you do that,\\nall your call methods are in the top level MLP model. And so all the inner layers are\\ngoing to be executed eagerly. If you don\'t do\\nthis, by default, you\'re going be\\ngenerating a graph function that does the\\ncompetition, which is faster. So-- AUDIENCE: Before you go\\non, I had a question. Could you explain the difference\\nbetween compile and fit? Like what goes between--\\nwhat goes in compile and what goes in fit? I don\'t feel like that\'s a-- FRANCOIS CHOLLET: Right. So compile is about configuring\\nthe training process. So you specify which\\noptimizer you want to use. You specify which loss\\nyou want to minimize. You specify which\\nmetrics you want to try. And anything else is\\ngoing to modify the way the computation is done. It\'s going to modify the\\nexecution function, which is something we\'re going\\nto go over in more detail. And in fit, you\'re passing the\\ndata itself and information about how you want this\\ndata to be processed, like how many times you\\nwant to iterate over the data, potentially the size\\nof the batches you want to use to iterate with the\\ndata, which callbacks you want to be called at\\ndifferent stages of training, and so on. So its configuration\\nand compile, and basically passing the data\\nand related metadata in fit. So typically, you\\ncompile your model once. But you might be calling\\nfit multiple times. AUDIENCE: So are we to think\\nabout it is if in TF1 style, the stuff that\\ndoesn\'t compile is the stuff that you\'d use when\\nyou\'re building your graph. And the stuff that goes to fit\\nis simply batch.session.run? FRANCOIS CHOLLET: Yes. That\'s correct. So let\'s move on to\\nfunctional models. So in the previous example,\\nyou saw a subclass model, so essentially something\\nthat you wrote subclassing the model class. In practice, very often\\nin the literature, you see the planning\\nmodels that look like this, that look like\\ndirected acyclic graphs. So on top, you have [INAUDIBLE]. At the bottom, you have\\nvarious bits of transformer. So these are directed\\nacyclic graphs of layers that are\\nconnected with these arrows. So there\'s an API in\\nKeras for configuring the connectivity of the directed\\nacyclic graph of layers. It\'s called a functional API. It looks roughly like this. You start with\\ninput nodes, which are like these input objects. And then you\'re going to\\nbe calling layer instances on that object. So you can think of\\nthis input object as a spec describing a tensor. So doesn\'t actually\\ncontain any data. It\'s just a spec specifying the\\nshape of the input you\'re going to be expecting, the data type\\nof the input you\'re going to be expecting-- maybe include-- so annotate with the name. And every time you\\ncall layer, that\'s roughly the action of drawing\\nan arrow from one layer instance to the next. So here, you\'re going to have\\none input node, two layers. And here you are drawing an\\narrow from the input node to the first layer. Here you\'re drawing an\\narrow from previous layer to this new layer, and doing\\nthat for the output layer finally. And then you can\\ninstantiate a model by just specifying its\\ninputs and its outputs. And what it\'s going to do\\nwhen you do this is basically build this directed\\nacyclic graph, right here. So you can actually\\nplot this graph. You can call utils.plot_model\\non your model instance. It\'s going to\\ngenerate this image. So a functional model\\nis basically just like any other model. But it\'s just a model that\\nyou do not write yourself. So it has a bunch of methods\\nthat are autogenerated. In particular, the call\\nmethod is autogenerated. The build method\\nis autogenerated. And the serialization\\nget_config is autogenerated. Yes? AUDIENCE: You said the\\ninput does not have data. But could it have data? Like if you wanted\\nto be able to check you work as you went along. FRANCOIS CHOLLET: No. It could not. So when you define your\\nmodel, you\'re not actually executing anything. You\'re just configuring a graph. So it\'s going to be\\nrunning a bunch of checks. But they\'re only\\ncompatibility checks, essentially checking that the\\nlayers that you are connecting together are compatible,\\nthat the data can actually be transmitted. But there\'s no execution. So there\'s no notion of data. It\'s really just an\\nAPI for building a DAG. So, yeah, so for instance, the\\ncall method is autogenerated. It\'s just going be something\\nthat we called a graphic layer executor. And so when you call\\nyour model, it\'s going to be basically running\\nthrough this graph of layers, calling each layer in succession\\nwith the proper inputs. And likewise, assuming that each\\nlayer in your graph of layer implements is\\nget_config method, then you can call\\nget_config on your DAG and get something that you\\ncan use to re-instantiate the same model. AUDIENCE: Excuse me. So can we go back\\nto [INAUDIBLE].. So on the line, y\\nequals to model x. So the x is a layer\\nof the input x. FRANCOIS CHOLLET: x is\\nthe output of the layer. So you start by instantiating\\nthis input object using tf.keras.Input, which is\\nbasically a spec for a tensor. It has a-- AUDIENCE: This-- the x here\\nis different than the x above. FRANCOIS CHOLLET: Oh, right. Yeah, sorry. This is confusing. Yeah. Yeah. This is supposed to be a\\ntensor, like an eager tensor, for instance. Right. Sorry. Yeah. It\'s a bit confusing. Sorry. Yeah, so you can call\\nyour model like you would call any other model\\ninstance or any function on a bit of data. It\'s going to return\\na bit of data. So what does a functional\\nAPI do, roughly? Well, it\'s really an API\\nfor configuring DAGs. It\'s targeted more at\\nusers than developers. People who are very comfortable\\nwith writing classes and functions in\\nPython will have no issues using\\nmodel subclassing to create new models. But when you want to use\\nmore like building APIs and you want more handholding,\\nthen the functional API is actually a lot easier to use. And its maps very closely to\\nhow you think about your model. So if you\'re not\\na Python developer because you think about your\\nmodels typically like that, in terms of DAGs of layers. So it\'s declarative, meaning\\nthat you write no logic. You write no functions. You subclass nothing. It\'s really just\\nconfiguration level. So all the logic that\'s\\ngoing to be executed during-- when you actually call\\nyour model on some data, it\'s contained inside of layers. Typically, you don\'t write it. So that means that\\nall debugging that happens when you\\nbuild these models is done statically at\\nconstruction time in terms of compatibility\\nchecks between layers. That means that any\\nfunctional model that you can instantiate\\nwithout the framework, creating as you-- is the\\nmodel that\'s going to run. So it means you don\'t write\\nany actual Python code. You\'re just connecting\\nnodes in a DAG, meaning you don\'t\\nactually write bugs. The only kind of bugs\\nyou can be writing is misconfiguration of your\\nDAG topology, which is what they call topology debugging. And that can be done visually\\nby literally printing your graphs of\\nlayers and looking at how they\'re connected. And on the [INAUDIBLE]\\nsides, these models can be expressed as static\\ndata structures that can generate code-- that can\\ngenerate a call method, meaning that they\'re inspectable. For instance, you can retrieve\\nintermediate activations in your DAG and use them\\nto build a new model. That\'s actually\\nvery useful when you do transfer learning\\nbecause it makes it very easy to do feature extraction. That means your models\\nare also plottable. You can actually generate\\nthese little graphs because you have a literal data\\nstructure in the random model. And you can serialize them. When you have subclass model\\nin your model topologies, it\'s actually a bit\\nof a Python byte code, which is harder to serialize. You have to [INAUDIBLE] it. There\'s one very\\nimportant restriction when you\'re writing\\nlayers that should be compatible with the\\nfunctional API, which is that all the\\ninputs of your layer should be contained\\nin the first argument, meaning that if you\\nhave multiple inputs, you should use\\n[INAUDIBLE] argument or maybe dictionary argument\\nif you have many inputs and they have names. AUDIENCE: Tensor inputs? FRANCOIS CHOLLET: Yes. Tensor inputs. So essentially, anything that\\ncomes from another layer. So like anything that you want\\nto transfer using these arrows. Each arrow corresponds\\nto the first argument in the call of the layer. So this is a restriction\\nthat also exists in Torch 7, in case you know. A lot of people who have been\\ncriticizing this restriction are people who say Torch 7 is\\nthe pinnacle of deep learning API. So I think this is funny. OK. So what actually\\nhappens when you build this functional model? Let\'s go in detail. When you instantiate this\\ninput object, it basically-- this spec object of\\nthe shape and dtype-- when you create it, it also\\ncreates an input layer, which is basically a node\\nin your graph of layers. And this input objects is going\\nto have an _keras_history field of metadata on it that\\ntracks who created it, where it comes from. And every time you\\ncall a layer instance on one of these spec objects,\\nwhat it\'s going to be doing is returning a new spec object-- nested structure spec object--\\nwith the inferred shape and dtype corresponding to the\\ncomputation that would normally be done by the layer. We can practice-- no\\nactual computation is happening when you do this. And this output has an updated\\n_keras_history metadata that tracks the node that you\\njust created in your graph of layers. And finally, when you\\ninstantiate your model from these inputs\\nand outputs, you\'re going to recursively\\nreconstruct-- retrieve every node\\nthat has been created and check that they\\nactually do form a valid DAG of layer calls. AUDIENCE: So this\\n_keras_history field, does that have transitively\\na reference to all the layers that were-- FRANCOIS CHOLLET: So these\\nare weighted contents. So it\'s basically-- keras is\\njust basically the coordinates of your tensor in a 3D space-- discrete 3D space. It\'s basically a tuple-- a named tuple with\\nthree entries. So the first one\\nis the reference to the layer that\'s\\ncreated this tensor-- this spec. The second one is the\\nnode_index because layers can be called multiple times. So it\'s not true that that\'s\\nactually one node that\'s instantiated with one layer. A node is instantiated\\nwith a layer call. So if you call layer\\ninstance multiple times, there\'s multiple nodes. So this node index is basically\\nthe index of the nodes created by the layer as referenced\\nin layer._output_nodes. And finally, there\'s\\na tensor_index. So the tensor_index\\nis basically to handle the case of multioutput layers. If you have a layer with a bunch\\nof tensor outputs, what they\'re going to do is deterministically\\nflatten these outputs into a list and then\\nindex this list. And this tensor_index\\ntells you the index of this specific\\ntensor among the values since that\'s returned\\nby this layer call. AUDIENCE: Can you\\n[INAUDIBLE] why, and I just call\\nlike tf.relu on it, it will still populate\\nthe keras history and-- FRANCOIS CHOLLET:\\nNot immediately. So the tf.relu, tf.nn.relu,\\nis not going to create this _keras_history object. But when this object is\\nseen again by a layer, it\'s going to check-- it\'s going to walk the graph and\\ncheck whether it was originally coming from a layer. And if it does, then it\'s going\\nto wrap the various ops that were not containing layers. It\'s going to wrap\\nthem into new layers so that you can\\nactually step out of the keras graph of layers\\nand insert any TensorFlow op. And each TensorFlow op is going\\nto be treated as its own nodes in the graph of layers. AUDIENCE: So two questions. One is, let\'s say\\nthat happened twice. Would there be two\\nRelu layers created? Or would it-- FRANCOIS CHOLLET: Yes. So it\'s one layer per op. AUDIENCE: --same\\nnode in the graph? FRANCOIS CHOLLET: Yeah. So one node corresponds\\nto one call of the layer. So every time you\\ncall layer, I mean, even if it\'s the same\\nlayer that\'s in your node, because it has to be a DAG. AUDIENCE: OK. So I guess when you say Relu,\\nit creates a tensor, right? FRANCOIS CHOLLET: Yeah. AUDIENCE: And that tensor is\\nthen passed to another layer? FRANCOIS CHOLLET: Yeah. AUDIENCE: At that point, does\\nit create a layer for the Relu? FRANCOIS CHOLLET:\\nThat\'s correct. Yes. AUDIENCE: So right then. And then if I were to pass\\nthat output of the Relu to another layer-- not the first layer-- would it create\\nanother layer for the-- [INTERPOSING VOICES] --reuse the-- FRANCOIS CHOLLET: I believe it\\ndoes not recreate the layer. So it reuses the previous layer. But I will have to check. AUDIENCE: This is all making\\nme wonder about the lifetimes of all these layers. Is there references to all\\nthese layers just kept forever? Or is that-- FRANCOIS CHOLLET: Yes. They are kept forever. AUDIENCE: Layers are\\nnever garbage collected. FRANCOIS CHOLLET: Yes. There\'s actually a\\nutility in the back end to force destroy all of this. It\'s called clear session. So, yeah, so this illustrates\\nthe importance of having these three coordinates. You can have-- so this is some\\nrandom variation of autoencoder example I took\\nfrom the internet. So it\'s interesting\\nbecause it shows layers that have multiple\\ninputs and multiple outputs. And, like, for\\ninstance, the outputs of this layer are going to be\\ngoing into-- one of the outputs is going to be going\\ninto this other layer. One of the other\\noutputs is going to be going further downstream. So with these three\\ncoordinates, you can do completely arbitrary\\ngraph topology in that case. So there\'s a lot\\nof keras features that are specific\\nto these functional models, in particular,\\nthe ability to do static compatibility\\nchecks on the inputs of a layer; the ability to do\\nwhole-model saving, meaning saving a file that enables\\nyou to reinstantiate the exact same Python\\nobjects with the same state; the ability to do\\nmodel plotting, which is something we\\nalready just saw; automatic masking,\\nwhich is something which we cover in detail;\\nand dynamic layers, which is something that\'s not\\nreally relevant if you\'re not using the functional API. So let\'s talk about\\nstatic type checking. When you create a custom layer,\\nyou can set an input_spec field on it, which is going to have\\nto be an instance of this input spec object or maybe a\\nnested structure input spec object, which describes the\\nexpectations that the layer has with regard to which\\nwe calling it on. And when you call your layer\\nfor the first time here-- you instantiate it\\nhere when you call it-- first, it\'s going to-- sorry-- it\'s going to\\ncheck that this input is compatible with the current\\ninput spec, which was set here in the constructor, which just\\nsays the tensor should have at least rank 2. Then it\'s going to\\nactually build a layer. But here, using this build\\nmethod, the input shape that\'s passed here gives us\\nmore refined information about the expectations\\nof the layer. So we update the input spec. So not only should it\\nbe a rank at least 2. The last axis-- so axis minus 1. It\'s the last axis-- should have exactly this value. So after you build,\\nit\'s going to recheck that the updated input spec\\nis compatible with this input. That\'s the right\\nlast dimensions. And finally, it\'s going\\nto call the [INAUDIBLE].. So every time you call a\\nlayer in the functional API to build these graphs, if the\\nlayer has set this input spec object, it\'s going to be\\nchecking compatibility and raising a very\\ndetailed-- and, therefore, our messages in case\\nof the compatibility, it\'s going to tell you what\\nyou passed, what was expected, and what you can do to fix it. You can also do\\nwhole-model saving, meaning that you have this\\nget config method that is autogenerated. You can use it to recreate\\nthe same model, in this case, without the state. You can also just call save. When you call load_model,\\nthen this object is the exact same Python\\nobject pretty much with the same topology,\\nthe same state. And you can load it\\nacross platforms. For instance, you can\\nalso load it in pascal.js. Yes. AUDIENCE: If I created\\nmy own custom layer, do I need to do\\nsomething special-- FRANCOIS CHOLLET: Absolutely. So if you want to\\nwrite custom layers and reload your model in\\na completely different environment, that environment\\nshould have access to some implementation\\nof your custom layer. So if it\'s a Python\\nenvironment, then you basically just need to make sure\\nthe code is available. And you would wrap your\\nload_model call inside a scope where you specify\\nthe custom objects you want to be\\ntaken into account during the\\ndeserialization process. If you want to load your\\nmodel into a JS, for instance, you first have to write\\na JavaScript/TypeScript implementation of your layer. And, yeah, model plotting, which\\nis something we already saw, it\'s pretty useful\\nwhen you want to check the correctness of\\nthe DAGs that you\'re building unless they\'re\\ntoo large, in which case it\'s not so great. So this is just a very simple\\ntwo input, two output model-- three input, sorry,\\ntwo output model-- where you have\\nsome title fields, some body fields,\\nsome DAG field. They\'re doing some processing. And you end up with\\na priority prediction and department predictions. And this is just something\\nfrom some random tutorial. And then one neat feature\\nis automatic masking. So let\'s go over that in detail. Here\'s just a simple\\nend-to-end example. You start from an\\ninput object that\'s going to be a variable\\nlength sequence of ints. It\'s called word sequence. So it\'s just going to be a\\nsequence of word indices. You embed it with\\nthis embedding layer. And in the embedding layer, you\\nspecify mask_zero equals true. So this layer is going to be\\ngenerating a mask using zero entries in any data you\'re going\\nto be passing along this graph connection. And every time you call a layer\\nthat\'s compatible with masking, it\'s going to pass\\nthrough this mask. And some layers,\\nlike the LSTM layer, are going to be mask consumers. So they\'re going to be looking\\nat the mask that\'s passed and use it to ignore\\nthe padded entries. And some layers--\\nfor instance, if you have an LSTM layer that\\ndoes not return sequences and that just\\nbasically just returns a single vector, the sample,\\nincluding the entire sequence, it\'s going to be\\ndestroying the mask. So the next layer is not\\ngoing to be seeing the mask. So when you do\\nsomething like this, you\'re automatically telling\\nthe LSTM layer, which is significantly downstream\\nfrom your embedding layer, to do the right thing\\nwith your sequences. So if you\'re not super-familiar\\nwith the specifics of masking, this is very simple and magical. You just say mask_zero at\\nthe start of your model. And suddenly, all\\nthe layers that should be aware of masking\\njust do the right thing. AUDIENCE: A little more detail\\nabout what-- what is masking? Is it like-- is there a vector\\nof Booleans or something? FRANCOIS CHOLLET: Yes. Absolutely. So here\'s the detail. A mask is, indeed, a vector-- a tensor of Booleans. Each sample has its own mask. And each mask is basically\\njust a plain vector of ones and zeros. It does not make assumptions\\nabout things like padding, for instance. So you could mask completely\\narbitrary time steps. Yeah. So you have three types of\\nlayers that interact with mask. You have layers that\\nwill consume a mask. So in order to consume mask,\\njust specify this mask argument in the call signature. And this will be your\\nbatch of Boolean vectors. You can also pass\\nthrough a mask. There\'s almost nothing\\nyou need to do. But it\'s opt-in. You need to explicitly\\nsay it supports masking. The reason why this is\\nopt-in is because many layers are going to be changing\\nthe shape of the inputs that are going to be returning\\noutputs that are not the same shape as the inputs. And this interacts with masking. So it\'s typically not true to\\nassume-- for instance, here-- to typically be\\nnot true to assume that the mask that needs to\\nbe consumed by this LSTM layer is the same that was generated\\nby the embedding layer. When in practice, it\'s the case. But if this dense layer\\nhad been doing anything to change the shape\\nof the inputs, it would have been different. And then you have\\nmask-generating layers. So for instance, the embedding\\nlayer does something like this. It looks at the inputs and gives\\nyou a mask of Boolean entries that is one for all non-zero\\nentries in your input. And in case you\\nhave a layer that modifies the shape of your\\ninputs, it should also-- if it wants to be\\ncompatible with masking-- should also implement this\\ncomputation called mask method. For instance, if\\nyou have concatenate layer that takes\\nmultiple inputs-- some of which may be masks,\\nsome of which may not-- the output mask should\\ndo the concatenation of the different masks. AUDIENCE: So that\\ncompute mask method didn\'t use the mask argument. But normally you would? FRANCOIS CHOLLET: Sorry, what? Oh, yeah, yeah. So you can-- yes. So for instance,\\nthe embedding layer is going to ignore\\nthe mask argument and just generate the\\nmask based on inputs. But if instead you have\\na concatenate layer, it\'s going to ignore\\nthe inputs and just generate the mask based on\\nthe prior mask argument. So let\'s look in a lot of\\ndetail at how all of this is implemented. So what happens when you\\ncall a layer instance on a bunch of symbolic inputs? So first thing we do is\\nstatic type checking-- determining whether\\nall the inputs are compatible with this layer. If the layer is unbuilt,\\nwe\'re going to build it-- potentially check input\\ncompatibility, again, in case input spec was updated. We\'re going to check whether\\nthis layer is mask consumer. Does it have a mask\\nargument in its call method? If yes, we\'re going to\\nretrieve the mask associated with the inputs of the layer,\\nwhich we do via metadata. We\'re going to\\nopen a graph scope, check if our layer is graphable. So this is a concept we\'re\\ngoing to look at in more detail afterwards. If the layer can be\\nturned into a graph, we\'re going to autograph\\ncall automatically. And we\'re going to call this-- so this is in order to convert\\nif statements, for instance, or for loops, into\\nsymbolic conditionals. We\'re going to call the call\\nmethod that was autographed using the proper\\nmask and training argument that we retrieved\\nfrom the current context. If the layer happens\\nto be dynamic, meaning that you cannot\\nconvert it to graph, you\'re just going to return\\na brand new symbolic tensors. And in order to know\\nwhat shape and detail these symbolic\\ntensors should be, you\'re going to use the\\nstatic shape inference method of your layer. Meaning that if you\\nhave a layer that\'s dynamic, that\'s\\nnongraphable, and you want to use it in\\nfunctional API, it should implement this\\nstatic shape inference method, compute output shape. For no other use\\ncase are you going to need compute output shape. So finally, you create\\nthe nodes in the graph of layers from this call. You set the metadata on the\\noutputs, which are either-- this is brand new\\nsymbolic tensors created using static shape\\ninference-- or the outputs of the actual\\ngraph mode call, so with the metadata\\nabove the node. And finally, you set\\nthe mask metadata, which is what the\\nnext layer is going to retrieve in case that\\nlayer is a mass consumer. AUDIENCE: So what\'s\\nhappening in step 5? What is the graph scope\\nthat you\'re talking about? FRANCOIS CHOLLET: So Keras\\nmaintains its own graph, which is a fun graph object. And when it creates\\na symbolic tensor, it\'s always in that graph. So before you call\\nthe graph mode call or before you instantiate\\nnew symbolic tensors, which are basically\\nplaceholders, first you need to open the graph scope. AUDIENCE: Slight correction. It will enter that graph\\nunless a different one has been specified. FRANCOIS CHOLLET: Yes,\\nwhich is only valid in V1. In V2, typically, we only ever-- like the only graph you\'re\\ngoing to be manipulating is the Keras graph. Everything else is going to be\\neither eager or TF function. So we mentioned the\\nnotion of dynamic layers. So what\'s dynamic layer? Well, maybe you remember this\\nBatchNormalization example. There\'s actually something\\nvery subtle going on with this BatchNormalization example,\\nwhich means that it cannot be turned into a static graph. And that is because-- so it uses this\\nif/else statement. And inside one of\\nthe branches, it does variable updates and the\\nother branch, it does not. And this actually does not\\nplay well with autograph. So this is actually\\nsomething that\'s fairly easy to fix\\nby simply having symmetrical conditional\\nbranches, where you have the same\\nstatements assigning nothing in the other branch. However, for the\\nsake of argument, let\'s say we cannot\\ngraph this layer. What are we going to do? Well, we are going to pass this\\ndynamic equals true argument in the constructor. And that tells the framework\\nthat this layer is not compatible with graph execution. It should never be\\nexecuted in a graph. And when you build a functional\\nAPI model using this, it\'s going to do what we\\nwere mentioning in step 6. It\'s just going to use\\nstatic shape inference to compute the outputs. And when you call\\nfit, it\'s going to be using pure eager\\nexecution without forcing you to specify [INAUDIBLE]\\nequals true in compile. It\'s just automatically\\nset to the right default. AUDIENCE: So I think\\nthis one actually works because it should\\nretrace for different bodies of training. FRANCOIS CHOLLET: This? AUDIENCE: This particular\\nexample should work in a graph with-- FRANCOIS CHOLLET:\\nLast time I checked, it would not work with\\nautograph unless-- AUDIENCE: Its final training\\nis in Python Boolean. But if it\'s a tensor, it\'s not. FRANCOIS CHOLLET: Implicitly,\\nit\'s actually tensor because-- so the reason why training\\nis usually a tensor is because we use the same graph\\nwhen you do fits and evaluates. And we change the value of\\ntraining by fitting the value. Training is always symbolic. But yeah, you\'re right. If it\'s a Python\\nBoolean, this works fine. In fact, autograph\\nis not even relevant because the if\\nstatements are just going to be ignored by autograph. AUDIENCE: What\'s the actual\\nproblem with [INAUDIBLE]?? I thought it was fine\\nto have the [INAUDIBLE] up on one side of\\nthe [INAUDIBLE].. AUDIENCE: Is that there\\nisn\'t a corresponding output. And so they\'re-- like autograph\\ncan\'t match the function signatures? AUDIENCE: Aren\'t those not\\noutputs of each branch, though? So it would just be\\nthe [INAUDIBLE] in-- It\'s like an API issue with\\n[INAUDIBLE] or something. AUDIENCE: Yes. It\'s a built-in issue. There\'s a long thread on this. FRANCOIS CHOLLET:\\nPotentially fixable. It\'s potentially fixable. Anyway, this was just\\nfor the sake of example. There are also layers that\\nare more fundamentally nongraphable, like a\\ntree LSTM, for instance. AUDIENCE: [INAUDIBLE] to that\\nbasically, the second question is, why is it important that you\\nuse the same wrap for both fit and evaluate? Given that, for instance,\\nin graph mode, the training versus inference flag,\\nlike in the olden days, I think that was a\\nPython Boolean, right? FRANCOIS CHOLLET:\\nYes, that\'s correct. That\'s the reason\\nwhy, historically, you had one graph for string\\nand one graph for inference is because you\\nwould do inference on a separate machine that\\nwould load a checkpoint and run asynchronously\\ncompared to the main training. That\'s what we\'re\\nused to at Google. In Keras, however, there\'s\\ngoing to be a running evaluation at the end of each epoch. So potentially, you\'re going\\nto be running evaluation very often. And you\'re going to be doing\\nthat on the same machine. So it\'s actually\\nquite a bit more efficient to use a single\\ngraph to do this instead of keeping it on two graphs. AUDIENCE: If you have\\nsomething and you call batch normal on it, that\\nif they\'re in the same graph-- for instance, you don\'t\\nhave to declare at that time whether you\'re doing\\ntraining and inference-- you can just have your tensor. You can do whatever you\\nwant downstream with it. Whereas, if you have\\nseparate graphs, if you, for instance, output\\nlike a result in training mode and a result in inference\\nmode, then the user has to track that. And it\'s just-- it\'s\\nnot as pleasant. AUDIENCE: Certainly,\\nit should be maybe different graphs that\\nshare all of the variables or even different functions. AUDIENCE: Different-- AUDIENCE: Yeah. AUDIENCE: Is this\\nsomething that\'s like maybe an\\nimplementation detail that-- FRANCOIS CHOLLET: It is very\\nmuch an implementation detail. We could choose to\\ngenerate a new graph when you do evaluation. Again, the reason this\\ndecision was made initially is really efficiencies because\\ntwo graphs is actually-- [INAUDIBLE] graph this big. And even though the two graphs\\nare almost entirely redundant, they only differ by a few\\ncounts for an actual part layer and batch normal layers. So we saw that having a\\nsymbolic training argument is actually much more efficient."", metadata={\'source\': \'UYRBHFAvLSs\'})]""""""', '""""""[Document(page_content=""hello and welcome to code horrific in this video you will learn how to convert input shapes between different layers in keras remember that every problem has more than one programming solutions and this video is about one of those in this program i\'m going to first write a simple cnn model and as you can see in this architecture besides first input layer there is one two dimensional convolution block that contains activation which is exponential linear unit and it is followed by uh two dimensional max pooling and if you notice that we are going to repeat the same convolution block again as it second convolution but after adding lstm and dropout and at the end we will be flattening our uh output obtained from second two-dimensional max pooling and after adding dropout we will end the model after adding two dense layers here as you can see there are two reshape inputs which are actually reshaped layers and this is because when we are going to add lstm layer after max pool 2d the output of 2d max pooling is 4 dimensional but lstm takes 3 dimensional input so here we have added reshape layer so that we can convert 4 dimension output to prepare three-dimensional input for lstm this convolution layer will take four dimensional layer but the output of lstm layer is three dimensional so here we have added a reshape layer we will be expanding the output from lstm so that the three-dimensional output is converted to four-dimensional format to be processed as input by second block of 2d convolution so this is the architecture let\'s start programming so i have opened my spider this is the python editor that comes with anaconda and as you can see here i have already imported my important libraries that i am going to use in this program the first one is tensorflow sdf and kerastart models i have imported model from it and as keras layers i have imported input to deconvolution yellow activation max pooling 2d flattening dance dropout lstm and reshape in the beginning i am going to mention my input shape and let\'s say for example my input shape is 100 by 80 and it is a colored image which is rgb format and to add the first convolution block i have added convolution 2d library and it has 32 number of filters with stride 3x3 and i have kept the padding same and it will take input image as input okay next i am going to add my uh exponential linear unit activation and its input is whatever this convolution duty has generated or in other words it\'s convolution one variable and the next thing i am going to add max pool 2d we have added a one convolution block so let\'s run our code so far okay now if i print convolution one variable we are getting the shape of four dimension output and it has 32 filters with shape 100 by 80 and after convolution we have added activation and after doing max pulling on inu activated output i\'m going to print pull one data and as you can see here final output we got is four dimension the first one none represent always the batch number or the sample number sample size now we are going to add our lstm block so here i have used my uh lstm that contains units five and i have kept written sequences strong so let\'s uh try this one first before we go to reshaping poll one i\'m going to input full one to my lstm layer and let\'s see what does it say i\'m going to run the lstm with robot so as you can see here it is giving me value error which says the input zero of layer lstm is incompatible with the layer expected number of dimensions three but four were given pool one has four dimensions but to process the lstm we need to convert it into three dimensions how we are going to use it we are going to use v-shaped layer from keras to reshape our pool output data i\'m going to write it here reshape is equal to [Music] reshape and it will take size of new dimension so i am going to pass my pool 1 shape reshape layer takes two parameters first one i have mentioned is negative one and the second one i have mentioned the shape to index from pole one shape so if i print here the shape of pool one data you can see it has four dimensions uh zero one two and three so what does this mean here i am seeing saying that uh arrange my full one data according to the shape index two of pool one and uh negative one means that i am leaving the rest up to keras to decide or how it will manage the data the only thing we need to mention is to give one dimension and it will keep the rest as it decides so if you want it you cannot change this parameter it will stay as it is which is negative one so we want to enforce scaras to take control and uh rearrange our pool one data only based on the shape index 2 of full one so i have defined my v-shaped layer next i am going to pass input to this layer so i\'m going to run this line and let\'s print reshape and now you see here that the four dimension is converted to three dimension now we are good to go and we can pass this reshaped data to our nstm layer i\'m going to run lstm followed by a dropout layer and if i print my drop 1 you will see that my input data that i obtained in reshape is processed now after lstm i\'m going to add second block of duty convolution and to do that i am going to copy this block and will replace convolution 1 to convolution 2. okay so i have replaced everything to stay unique in second block of 2d convolution as for now i have added drop one input and password to combination 2d remember that conversation 2d text 4 dimension parameter and if i run this line we will get the same error that we obtained for lstm before we reshape it says that expected number of dimension for 2d convolution is 4 but we found number of dimension three we are going to reshape our output obtained from top one we are not going to use the reshape layer for keras but instead we are going to expand the layer and to do that we are going to use tensorflow i am going to create a variable external shape that will contain the extended layer and i am going to use expand dimension function of tensorflow and i am passing drop one data i print drop one shape you can see that it has three dimensions but if i add negative one here it means that i am going to say to tensorflow that add one dimension a new dimension will be added after five and it will be one so let\'s run this line sorry there is an error that says there is no attribute function and i mistakenly add dot instead of underscore so this is complete nemo function let\'s run it again and if i print extend shape you will see that drop one layer data has four dimensions and you can see that the dimension one has been added at the end of five now that we have prepared our three dimension and converted it to fourth dimension i am going to pass this input to my 2d convolution which is second block and let\'s run this block i\'m going to pre-pull two and as you can see here in my input data that i got from extended shape has been processed now i am going to add my flattening layer with dropout followed by two dance layers okay now i am going to define my model that will take input image as input and will generate output as obtained here in this variable and i\'m going to name this model as model and to print the model i am going to print this summary or you can enclose this inside the print now i am going to create my model as you can see in the python console my model is ready to be trained and i have successfully changed the shapes according to my different former soft layers inside my model this is it for this video thank you for watching i hope you find it helpful if you did do like and share also subscribe the channel and hit the bell icon so that you get notified whenever i upload a new video if you have any suggestions leave them in comments section i will do consider it thank you"", metadata={\'source\': \'FIReIQlyZmM\'})]""""""', '""""""[Document(page_content=""hi I\'m Zack Dean mayor and in this course I\'ll be teaching you advanced deep learning concepts using the Charis functional API you will learn how to build functional Kerris models including advanced topics such as shared layers categorical embeddings multiple inputs and multiple outputs the Charis functional API is extremely simple yet immensely powerful by the end of this class you will build a model that is capable of solving a regression and a classification problem at the same time chapter one is a refresher on building simple models where you will learn how to use the Charis functional API in Chapter two you will build a Karass model with two inputs in Chapter three you will learn how to generalize your two input model to three or more inputs and finally in Chapter four you will build models with multiple outputs that can solve multiple problems you will be using two datasets of college basketball games from American colleges the first data set is from the regular season and has the following data the IDS of the two teams that played whether the first team was home or away whether the first team won or lost the game and by how many points the first team won or lost for the tournament data set you also have the tournament seed which is a pre-tournament ranking for each team these seeds range from 1 to 16 where the best four teams get a seed of one and the worst four teams get a seed of 16 you will use the difference in the two team seeds as an input to your model here are the first five rows of both the data sets you can see that the team variables are encoded as integers and the tournament data set has one additional column the difference between the tournament seats for both teams other than the seed difference the two datasets have identical columns within a given year a team\'s roster stays relatively constant but between years it can change a lot as seniors graduate and freshmen start therefore for every year each school is given a unique integer ID Terrace models at their simplest are fundamentally composed of two parts an input layer and an output layer to start I\'ll define a very simple Kerris model which only expects a single input I\'ll specify this using the input function from the Charis layers module the number of columns in the input is specified using the shape parameter this tells the model how much data to expect note that the shape argument expects a tupple the input function returns a tensor if you print this tensor you\'ll see that it is a TF tensor object which indicates it is ready to be used by our model as input now that we\'ve defined our input layer let\'s define the output layer outputs in Kerris are most commonly a single dense layer which specifies the shape of the expected output in this case we are expecting our model to predict a single value so we pass one unit to the dense layer if you print the output layer the result is not a tensorflow tensor it is a function which takes a tensor as input and produces a tensor as output the difference between layers in tensors is key to understanding the Charis functional API layers are used to construct a deep learning model in tensors are used to define the data flow through the model in this case the input layer defines a tensor which we then pass to the output layer function the final output of our model is a tensor it is time for you to build some layers"", metadata={\'source\': \'oJ1i2c1KxKk\'})]""""""', '""""""[Document(page_content=""we start by importing tensorflow as tf then we print the version of tensorflow that we are using we\'re using tensorflow 1.5.0 in this video we\'re going to use tensorflow reshape to change the shape of a tensorflow tensor as long as the number of elements stay the same we will do three examples to show how reshape works let\'s start out with an initial tensorflow constant tensor shaped two by three by four with numerical integer values between 1 and 24 all of whom have the data type of n32 so we use tensorflow.constant we have our two by three by four tensor we have the data type as n32 and we see the numbers are one two three four all the way through 24 and we assign it to the python variable tf underscore initial underscore tensor underscore constant now that we have it let\'s print out the tf initial tensor constant python variable to see what we have we see that it\'s a tensorflow constant the shape is two by three by four the data type is n32 because we haven\'t run it in a tensorflow session yet it doesn\'t seem to have values even though we just defined it as a constant the same will apply to the other reshapes we\'re about to create for the first example let\'s go from a tensor whose shape is two by three by four to a tensor whose shape is two by twelve so we\'re going to use tensorflow.reshape we pass in the initial tensor constant and then we pass in the specifics of what we want the new shape to be so it\'ll be 2 comma 12 and we assign the whole thing to the python variable tf x 1 reshape tensor 2 by 12. note that the number of elements will stay the same as 2 times 3 times 4 is 24 and 2 times 12 is 24. let\'s print out the tfx one reshaped tensor 2 by 12 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 2 by 12 and we see that the data type is in 32. it\'s not showing any values yet because we\'re still building the tensorflow graph and we haven\'t run at any tensorflow session for the second example let\'s change a tensor whose shape is two by three by four to a tensor whose shape is two by three by two by two so we use tensorflow.reshape we pass in our initial tensor and then we specify what the shape is going to be so we pass in two comma three comma two comma 2 and we assign it to the python variable tf x 2 reshape tensor 2 by 3 by 2 by 2. note that the number of elements will stay the same as 2 times 3 times 4 is 24 and 2 times 3 times 2 times 2 is 24 as well let\'s print out the tf x to reshape tensor 2 by 3 by 2 by 2 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 2 by 3 by 2 by 2 which is what we would expect and the data type is in 32 for the third example we\'re going to change a tensorflow tensor whose shape is 2 by 3 by 4 to a vector of 24 elements and the way we do that is we use the tensorflow.reshape operation we pass in our initial tensor and here we\'re going to use a negative one so what that\'s going to do is it\'s just going to flatten the tensor so that\'s just going to be a list of 24 elements we assign it to the python variable tf x tree reshape tensor one by 24. let\'s print out the tf x tree reshape tensor one by 24 python variable to see what we have we see that it\'s a tensorflow tensor we see that the shape is 24 comma that means it\'s going to be a vector the data type is n32 now that we have created our tensorflow tensors it\'s time to run the computational graph first we launch the graph in a session then we initialize all the global variables in the graph in our case it\'s going to be all the tensors we\'ve created next we\'re going to print out the four tensors to see how tensorflow\'s reshape works let\'s print out our initial tensor constant so we do a print session run tf initial tensor constant we see that it\'s a two by three by four tensor the numbers go from one to twenty four and none of them have decimal points so we know that they\'re in 32 numbers let\'s now print our first reshaped tensor so we use the print session run tfx1 reshape tensor2 by 12. we see that it\'s a tensor that has two matrices inside of it the first matrix has one row and 12 columns the second matrix has one row and 12 columns so all of our elements are there one through 24. let\'s now print our second reshaped tensor python variable tf x2 reshaped tensor two by three by two by two awesome we see that it\'s a tensor that has two interior tensors each of which has three matrices that are two by two perfect so two rows two columns two rows two columns two rows two columns and then two rows two columns two rows two columns two rows two columns so overall we can see that the shape is two by three by two by two and all our numbers are there finally let\'s print our third reshape tensorflow example this is the python variable tfx tree reshape tensor 1 by 24 awesome we see that it\'s a vector that\'s 24 elements long so we see the number 1 all the way to 24. so all our numbers are there perfect we were able to use tensorflow reshape to change the shape of a tensorflow tensor as long as the number of elements stayed the same"", metadata={\'source\': \'ukBG9ALd8T8\'})]""""""']","{'https://stackoverflow.com/questions/71335830/what-is-the-difference-between-tf-keras-layers-input-and-tf-keras-layers-flatt', 'https://stackoverflow.com/questions/44466066/how-can-i-convert-a-trained-tensorflow-model-to-keras', 'https://stackoverflow.com/questions/45217973/what-is-the-advantage-of-using-an-inputlayer-or-an-input-in-a-keras-model-with', 'https://stackoverflow.com/questions/56918388/error-valueerror-the-last-dimension-of-the-inputs-to-dense-should-be-defined'}","['""""""Share Your Experience: Tensorflow 2.0: Shape inference with Reshape returns None dimension\n\nAsked 3 years, 11 months ago\n\nModified 3 years, 11 months ago\n\nI\'m working with a CNN-LSTM model on Tensorflow 2.0 + Keras to perform sequence classification. My model is defined as following:\n\ninp = Input(input_shape) rshp = Reshape((input_shape[0]*input_shape[1], 1), input_shape=input_shape)(inp) cnn1 = Conv1D(100, 9, activation=\'relu\')(rshp) cnn2 = Conv1D(100, 9, activation=\'relu\')(cnn1) mp1 = MaxPooling1D((3,))(cnn2) cnn3 = Conv1D(50, 3, activation=\'relu\')(mp1) cnn4 = Conv1D(50, 3, activation=\'relu\')(cnn3) gap1 = AveragePooling1D((3,))(cnn4) dropout1 = Dropout(rate=dropout[0])(gap1) flt1 = Flatten()(dropout1) rshp2 = Reshape((input_shape[0], -1), input_shape=flt1.shape)(flt1) bilstm1 = Bidirectional(LSTM(240, return_sequences=True, recurrent_dropout=dropout[1]), merge_mode=merge)(rshp2) dense1 = TimeDistributed(Dense(30, activation=\'relu\'))(rshp2) dropout2 = Dropout(rate=dropout[2])(dense1) prediction = TimeDistributed(Dense(1, activation=\'sigmoid\'))(dropout2) model = Model(inp, prediction, name=""CNN-bLSTM_per_segment"") print(model.summary(line_length=75))\n\nWhere input_shape = (60, 60). This definition, however, raises the following error:\n\nTypeError: unsupported operand type(s) for +: \'NoneType\' and \'int\'\n\nAt first, I thought it was because the rshp2 layer could not reshape the flt1 output to shape (60, X). So I added a printing block before the Bidirectional(LSTM)) layer:\n\nprint(\'reshape1: \', rshp.shape) print(\'cnn1: \', cnn1.shape) print(\'cnn2: \', cnn2.shape) print(\'mp1: \', mp1.shape) print(\'cnn3: \', cnn3.shape) print(\'cnn4: \', cnn4.shape) print(\'gap1: \', gap1.shape) print(\'flatten 1: \', flt1.shape) print(\'reshape 2: \', rshp2.shape)\n\nAnd the shapes were:\n\nreshape 1: (None, 3600, 1) cnn1: (None, 3592, 100) cnn2: (None, 3584, 100) mp1: (None, 1194, 100) cnn3: (None, 1192, 50) cnn4: (None, 1190, 50) gap1: (None, 396, 50) flatten 1: (None, 19800) reshape 2: (None, 60, None)\n\nLooking at the flt1 layer, its output shape is (19800,), which can be reshaped as (60, 330), but for some reason the (60, -1) of the rshp2 layer is not working as intended, evidenced by the print reshape 2: (None, 60, None). When I try to reshape as (60, 330) it works just fine. Does anyone knows why the (-1) is not working? From Reshape documentation, https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape\n\nthe layer returns a tensor with shape (batch_size,) + target_shape\n\nSo, the batch size stays the same, the other dimensions are calculated based on your target_shape. From the doc, look at the last example,\n\n# also supports shape inference using `-1` as dimension model.add(tf.keras.layers.Reshape((-1, 2, 2))) model.output_shape\n\nIf you pass -1 in your target shape, the Keras will store None, this is useful if you expect variable-length data in that axis, but if your data shape is always same, just put the dimension hard-coded that will place the dimension when you print the shape later. N.B: Also no need to specify input_shape=input_shape for your intermediate layers in functional API. The model will infer that for you.""""""', '""""""thanks I made a post. I would love some input as to what I am missing\n\n\n\nCurrently, there is no direct in-built support in Tensorflow or Keras to convert the frozen model or the checkpoint file to hdf5 format. But since you have mentioned that you have the code of Tensorflow model, you will have to rewrite that model\'s code in Keras. Then, you will have to read the values of your variables from the checkpoint file and assign it to Keras model using layer.load_weights(weights) method. More than this methodology, I would suggest to you to do the training directly in Keras as it claimed that Keras\' optimizers are 5-10% times faster than Tensorflow\'s optimizers. Other way is to write your code in Tensorflow with tf.contrib.keras module and save the file directly in hdf5 format. Unsure if this is what you are looking for, but I happened to just do the same with the newly released keras support in TF 1.2. You can find more on the API here: https://www.tensorflow.org/api_docs/python/tf/contrib/keras\n\nTo save you a little time, I also found that I had to include keras modules as shown below with the additional python.keras appended to what is shown in the API docs. from tensorflow.contrib.keras.python.keras.models import Sequential\n\nHope that helps get you where you want to go. Essentially once integrated in, you then just handle your model/weight export as usual. """"""', '""""""Share Your Experience: What is the difference between tf.keras.layers.Input() and tf.keras.layers.Flatten()\n\nAsked 2 years, 2 months ago\n\nModified 2 years, 2 months ago\n\nI have seen multiple uses of both tf.keras.layers.Flatten() (ex. here) and tf.keras.layers.Input() (ex. here). After reading the documentation, it is not clear to me\n\nwhether either of them uses the other\n\nwhether both can be used interchangeably when introducing to a model an input layer (let\'s say with dimensions (64, 64))\n\nBillTheKidBillTheKid\n\n0\n\nI think the confusion comes from using a tf.keras.Sequential model, which does not need an explicit Input layer. Consider the following two models, which are equivalent:\n\nimport tensorflow as tf model1 = tf.keras.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(5, activation=\'relu\'), ]) model1.build((1, 28, 28, 1))\n\nmodel2 = tf.keras.Sequential([ tf.keras.layers.Input((28, 28, 1)), tf.keras.layers.Flatten(), tf.keras.layers.Dense(5, activation=\'relu\'), ])\n\nThe difference is that I explicitly set the input shape of model2 using an Input layer. In model1, the input shape will be inferred when you pass real data to it or call model.build. Now regarding the Flatten layer, this layer simply converts a n-dimensional tensor (for example (28, 28, 1)) into a 1D tensor (28 x 28 x 1). The Flatten layer and Input layer can coexist in a Sequential model but do not depend on each other. AloneTogetherAloneTogether\n\n 4\n\nSo If I understand correctly, in the example of code I used for the tf.keras.layers.Input class, the data are not flattened, they are kept in the same shape, and the class is just used to specify their shape. In that specific example it is necessary to use Input, although the model is Sequential, right? So If I understand correctly, in the example of code I used for the tf.keras.layers.Input class, the data are not flattened, they are kept in the same shape, and the class is just used to specify their shape <--yes. ,,,,, In that specific example it is necessary to use Input, although the model is Sequential, right? <-- it is optional not necessary. Ok this solves my questions!""""""', '"""""" How can I convert a trained Tensorflow model to Keras? Modified 5 years, 6 months ago\n\nI have a trained Tensorflow model and weights vector which have been exported to protobuf and weights files respectively. How can I convert these to JSON or YAML and HDF5 files which can be used by Keras? I have the code for the Tensorflow model, so it would also be acceptable to convert the tf.Session to a keras model and save that in code. I think the callback in keras is also a solution. The ckpt file can be saved by TF with:\n\nsaver = tf.train.Saver() saver.save(sess, checkpoint_name)\n\nand to load checkpoint in Keras, you need a callback class as follow:\n\nclass RestoreCkptCallback(keras.callbacks.Callback): def __init__(self, pretrained_file): self.pretrained_file = pretrained_file self.sess = keras.backend.get_session() self.saver = tf.train.Saver() def on_train_begin(self, logs=None): if self.pretrian_model_path: self.saver.restore(self.sess, self.pretrian_model_path) print(\'load weights: OK.\')\n\nThen in your keras script:\n\nmodel.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\') restore_ckpt_callback = RestoreCkptCallback(pretrian_model_path=\'./XXXX.ckpt\') model.fit(x_train, y_train, batch_size=128, epochs=20, callbacks=[restore_ckpt_callback])\n\nThat will be fine. I think it is easy to implement and hope it helps.""""""', '""""""What is the advantage of using an InputLayer (or an Input) in a Keras model with Tensorflow tensors? Asked 6 years, 9 months ago\n\nModified 3 years, 1 month ago\n\nA Keras model can used as a Tensorflow function on a Tensor, through the functional API, as described here. from keras.layers import InputLayer a = tf.placeholder(dtype=tf.float32, shape=(None, 784)) model = Sequential() model.add(InputLayer(input_tensor=a, input_shape=(None, 784))) model.add(Dense(32, activation=\'relu\')) model.add(Dense(10, activation=\'softmax\')) output = model.output\n\n<tf.Tensor \'dense_24/Softmax:0\' shape=(?, 10) dtype=float32>\n\nBut, this also works without any InputLayer:\n\na = tf.placeholder(dtype=tf.float32, shape=(None, 784)) model = Sequential() model.add(Dense(32, activation=\'relu\', input_shape=(784,))) model.add(Dense(10, activation=\'softmax\')) output = model(a)\n\nworks, and output has the same shape as before:\n\n<tf.Tensor \'sequential_9/dense_22/Softmax:0\' shape=(?, 10) dtype=float32>\n\nI assume the first form permits:\n\nto explicitely attach the inputs and outputs as attributes of the model (of the same names), so we can reuse them elsewhere. For example with other TF ops. to transform the tensors given as inputs into Keras inputs, with additional metadata (such as _keras_history as stated in the source code). But this is not something we cannot do with the second form, so, is there a special usage of the InputLayer (and Input a fortiori) (except for multiple inputs)? Moreover, the InputLayer is tricky because it\'s using input_shape differently from other keras layers: we specify the batch size (None here), which is not usually the case... It would seem that InputLayer has some uses:\n\nFirst, it allows you to give pure tensorflow tensors as is, without specifying their shape. E.g. you could have written\n\nmodel.add(InputLayer(input_tensor=a))\n\nThis is nice for several obvious reasons, among others less duplication. Second, they allow you to write non-sequential networks with a single input, e.g. input / \\ / \\ / \\ conv1 conv2 | |\n\nWithout InputLayer you would need to explicitly feed conv1 and conv2 the same tensor, or create an arbitrary identity layer on top of the model. Neither is quite pleasing.""""""', '"""""" How can I convert a trained Tensorflow model to Keras? Modified 5 years, 6 months ago\n\nI have a trained Tensorflow model and weights vector which have been exported to protobuf and weights files respectively. How can I convert these to JSON or YAML and HDF5 files which can be used by Keras? I have the code for the Tensorflow model, so it would also be acceptable to convert the tf.Session to a keras model and save that in code. I think the callback in keras is also a solution. The ckpt file can be saved by TF with:\n\nsaver = tf.train.Saver() saver.save(sess, checkpoint_name)\n\nand to load checkpoint in Keras, you need a callback class as follow:\n\nclass RestoreCkptCallback(keras.callbacks.Callback): def __init__(self, pretrained_file): self.pretrained_file = pretrained_file self.sess = keras.backend.get_session() self.saver = tf.train.Saver() def on_train_begin(self, logs=None): if self.pretrian_model_path: self.saver.restore(self.sess, self.pretrian_model_path) print(\'load weights: OK.\')\n\nThen in your keras script:\n\nmodel.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\') restore_ckpt_callback = RestoreCkptCallback(pretrian_model_path=\'./XXXX.ckpt\') model.fit(x_train, y_train, batch_size=128, epochs=20, callbacks=[restore_ckpt_callback])\n\nThat will be fine. I think it is easy to implement and hope it helps.""""""', '""""""What is the advantage of using an InputLayer (or an Input) in a Keras model with Tensorflow tensors? Asked 6 years, 9 months ago\n\nModified 3 years, 1 month ago\n\nA Keras model can used as a Tensorflow function on a Tensor, through the functional API, as described here. from keras.layers import InputLayer a = tf.placeholder(dtype=tf.float32, shape=(None, 784)) model = Sequential() model.add(InputLayer(input_tensor=a, input_shape=(None, 784))) model.add(Dense(32, activation=\'relu\')) model.add(Dense(10, activation=\'softmax\')) output = model.output\n\n<tf.Tensor \'dense_24/Softmax:0\' shape=(?, 10) dtype=float32>\n\nBut, this also works without any InputLayer:\n\na = tf.placeholder(dtype=tf.float32, shape=(None, 784)) model = Sequential() model.add(Dense(32, activation=\'relu\', input_shape=(784,))) model.add(Dense(10, activation=\'softmax\')) output = model(a)\n\nworks, and output has the same shape as before:\n\n<tf.Tensor \'sequential_9/dense_22/Softmax:0\' shape=(?, 10) dtype=float32>\n\nI assume the first form permits:\n\nto explicitely attach the inputs and outputs as attributes of the model (of the same names), so we can reuse them elsewhere. For example with other TF ops. to transform the tensors given as inputs into Keras inputs, with additional metadata (such as _keras_history as stated in the source code). But this is not something we cannot do with the second form, so, is there a special usage of the InputLayer (and Input a fortiori) (except for multiple inputs)? Moreover, the InputLayer is tricky because it\'s using input_shape differently from other keras layers: we specify the batch size (None here), which is not usually the case... It would seem that InputLayer has some uses:\n\nFirst, it allows you to give pure tensorflow tensors as is, without specifying their shape. E.g. you could have written\n\nmodel.add(InputLayer(input_tensor=a))\n\nThis is nice for several obvious reasons, among others less duplication. Second, they allow you to write non-sequential networks with a single input, e.g. input / \\ / \\ / \\ conv1 conv2 | |\n\nWithout InputLayer you would need to explicitly feed conv1 and conv2 the same tensor, or create an arbitrary identity layer on top of the model. Neither is quite pleasing.""""""', '"""""" How can I convert a trained Tensorflow model to Keras? Modified 5 years, 6 months ago\n\nI have a trained Tensorflow model and weights vector which have been exported to protobuf and weights files respectively. How can I convert these to JSON or YAML and HDF5 files which can be used by Keras? I have the code for the Tensorflow model, so it would also be acceptable to convert the tf.Session to a keras model and save that in code. I think the callback in keras is also a solution. The ckpt file can be saved by TF with:\n\nsaver = tf.train.Saver() saver.save(sess, checkpoint_name)\n\nand to load checkpoint in Keras, you need a callback class as follow:\n\nclass RestoreCkptCallback(keras.callbacks.Callback): def __init__(self, pretrained_file): self.pretrained_file = pretrained_file self.sess = keras.backend.get_session() self.saver = tf.train.Saver() def on_train_begin(self, logs=None): if self.pretrian_model_path: self.saver.restore(self.sess, self.pretrian_model_path) print(\'load weights: OK.\')\n\nThen in your keras script:\n\nmodel.compile(loss=\'categorical_crossentropy\', optimizer=\'rmsprop\') restore_ckpt_callback = RestoreCkptCallback(pretrian_model_path=\'./XXXX.ckpt\') model.fit(x_train, y_train, batch_size=128, epochs=20, callbacks=[restore_ckpt_callback])\n\nThat will be fine. I think it is easy to implement and hope it helps.""""""']"
57813806,tf.feature_column,example required,Apply feature columns without tf.Estimator (Tensorflow 2.0.0-rc0),"<p>In the Tensorflow tf.Estimator and tf.feature_column docs it is well documented, how to use feature columns together with an Estimator e.g. in order to one-hot encode the categorical features in the dataset being used.</p>

<p>However, I want to ""apply"" my feature columns directly to a tf.dataset which I create from a .csv file (with two columns: UserID, MovieID), without even defining a model or an Estimator. (Reason: I want to check what's happening exactly in my datapipeline, i.e. I'd like to be able to run a batch of samples through my the pipeline, and then see in the output how the features got encoded.)</p>

<p>This is what I have tried so far:</p>

<pre><code>column_names = ['UserID', 'MovieID']

user_col = tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000)
movie_col = tf.feature_column.categorical_column_with_hash_bucket(key='MovieID', hash_bucket_size=1000)
feature_columns = [tf.feature_column.indicator_column(user_col), tf.feature_column.indicator_column(movie_col)]

feature_layer = tf.keras.layers.DenseFeatures(feature_columns=feature_columns)

def process_csv(line):
  fields = tf.io.decode_csv(line, record_defaults=[tf.constant([], dtype=tf.int32)]*2, field_delim="";"")
  features = dict(zip(column_names, fields))

  return features 

ds = tf.data.TextLineDataset(csv_filepath)
ds = ds.map(process_csv, num_parallel_calls=4)
ds = ds.batch(10)
ds.map(lambda x: feature_layer(x))
</code></pre>

<p>However the last line with the map call raises the following error:</p>

<blockquote>
  <p>ValueError: Column dtype and SparseTensors dtype must be compatible.
  key: MovieID, column dtype: , tensor dtype: </p>
</blockquote>

<p>I'm not sure what this error means...
I also tried to define a tf.keras model with only the feature_layer I defined, and then run .predict() on my dataset - instead of using ds.map(lambda x: feature_layer(x)):</p>

<pre><code>model = tf.keras.Sequential([feature_layer])
model.compile()
model.predict(ds)
</code></pre>

<p>However, this results exactly in the same error as above.
Does anybody have an idea what is going wrong? Is there maybe an easier way to achieve this?</p>
","<p>Just found the issue:
tf.feature_column.categorical_column_with_hash_bucket() takes an optional argument dtype, which is set to tf.dtypes.string by default.
However, the datatype of my columns is numerical (tf.dtypes.int32).
This solved the issue:</p>

<pre><code>tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000, dtype=tf.dtypes.int32)
</code></pre>
","Just found the issue:
tf.feature_column.categorical_column_with_hash_bucket() takes an optional argument dtype, which is set to tf.dtypes.string by default. However, the datatype of my columns is numerical (tf.dtypes.int32).

This solved the issue:
<pre><code>tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000, dtype=tf.dtypes.int32)
</code></pre>",,"['How to use tf.feature_column with tf.data.Dataset in TensorFlow?', 'How to apply feature columns directly to a tf.data.Dataset in TensorFlow?', 'How to one-hot encode categorical features using tf.feature_column and tf.data.Dataset?', 'How to debug ValueError: Column dtype and SparseTensors dtype must be compatible in TensorFlow?', 'How to use tf.keras.layers.DenseFeatures with tf.data.Dataset?', 'How to preprocess CSV data using tf.data.Dataset and tf.feature_column in TensorFlow?', 'How to map feature columns to a dataset without defining a model in TensorFlow?', 'How to use tf.feature_column.indicator_column with tf.data.Dataset?']","['How to use tf.feature_column with tf.data.Dataset in TensorFlow?', 'How to apply feature columns directly to a tf.data.Dataset?', 'How to one-hot encode categorical features in a tf.data.Dataset using tf.feature_column?', 'How to debug ValueError: Column dtype and SparseTensors dtype must be compatible in TensorFlow?', 'How to use tf.keras.layers.DenseFeatures with tf.data.Dataset?', 'How to process CSV data with tf.data.TextLineDataset and tf.feature_column?', 'How to use tf.feature_column.indicator_column with tf.data.Dataset?', 'How to map feature columns to a dataset in TensorFlow?']",set(),[],"{'https://stackoverflow.com/questions/57403472/how-do-i-add-a-new-feature-column-to-a-tf-data-dataset-object', 'https://stackoverflow.com/questions/43653116/how-to-one-hot-encode-category-features-with-pandas-or-tensorflow', 'https://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder'}","['""""""How do I add a new feature column to a tf.data.Dataset object? Modified 4 years ago\n\nI am building an input pipeline for proprietary data using Tensorflow 2.0\'s data module and using the tf.data.Dataset object to store my features. Here is my issue - the data source is a CSV file that has only 3 columns, a label column and then two columns which just hold strings referring to JSON files where that data is stored. I have developed functions that access all the data I need, and am able to use Dataset\'s map function on the columns to get the data, but I don\'t see how I can add a new column to my tf.data.Dataset object to hold the new data. So if anyone could help with the following questions, it would really help:\n\nHow can a new feature be appended to a tf.data.Dataset object? Should this process be done on the entire Dataset before iterating through it, or during (I think during iteration would allow utilization of the performance boost, but I don\'t know how this functionality works)? I have all the methods for taking the input as the elements from the columns and performing everything required to get the features for each element, I just don\'t understand how to get this data into the dataset. I could do ""hacky"" workarounds, using a Pandas Dataframe as a ""mediator"" or something along those lines, but I want to keep everything within the Tensorflow Dataset and pipeline process, for both performance gains and higher quality code. I have looked through the Tensorflow 2.0 documentation for the Dataset class (https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset), but haven\'t been able to find a method that can manipulate the structure of the object. Here is the function I use to load the original dataset:\n\ndef load_dataset(self): # TODO: Function to get max number of available CPU threads dataset = tf.data.experimental.make_csv_dataset(self.dataset_path, self.batch_size, label_name=\'score\', shuffle_buffer_size=self.get_dataset_size(), shuffle_seed=self.seed, num_parallel_reads=1) return dataset\n\nThen, I have methods which allow me to take a string input (column element) and return the actual feature data. And I am able to access the elements from the Dataset using a function like "".map"". But how do I add that as a column? deepdreamsdeepdreams\n\nWow, this is embarassing, but I have found the solution and it\'s simplicity literally makes me feel like an idiot for asking this.""""""', '""""""How do I add a new feature column to a tf.data.Dataset object? Modified 4 years ago\n\nI am building an input pipeline for proprietary data using Tensorflow 2.0\'s data module and using the tf.data.Dataset object to store my features. Here is my issue - the data source is a CSV file that has only 3 columns, a label column and then two columns which just hold strings referring to JSON files where that data is stored. I have developed functions that access all the data I need, and am able to use Dataset\'s map function on the columns to get the data, but I don\'t see how I can add a new column to my tf.data.Dataset object to hold the new data. So if anyone could help with the following questions, it would really help:\n\nHow can a new feature be appended to a tf.data.Dataset object? Should this process be done on the entire Dataset before iterating through it, or during (I think during iteration would allow utilization of the performance boost, but I don\'t know how this functionality works)? I have all the methods for taking the input as the elements from the columns and performing everything required to get the features for each element, I just don\'t understand how to get this data into the dataset. I could do ""hacky"" workarounds, using a Pandas Dataframe as a ""mediator"" or something along those lines, but I want to keep everything within the Tensorflow Dataset and pipeline process, for both performance gains and higher quality code. I have looked through the Tensorflow 2.0 documentation for the Dataset class (https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset), but haven\'t been able to find a method that can manipulate the structure of the object. Here is the function I use to load the original dataset:\n\ndef load_dataset(self): # TODO: Function to get max number of available CPU threads dataset = tf.data.experimental.make_csv_dataset(self.dataset_path, self.batch_size, label_name=\'score\', shuffle_buffer_size=self.get_dataset_size(), shuffle_seed=self.seed, num_parallel_reads=1) return dataset\n\nThen, I have methods which allow me to take a string input (column element) and return the actual feature data. And I am able to access the elements from the Dataset using a function like "".map"". But how do I add that as a column? deepdreamsdeepdreams\n\nWow, this is embarassing, but I have found the solution and it\'s simplicity literally makes me feel like an idiot for asking this.""""""', '""""""How do I add a new feature column to a tf.data.Dataset object? Modified 4 years ago\n\nI am building an input pipeline for proprietary data using Tensorflow 2.0\'s data module and using the tf.data.Dataset object to store my features. Here is my issue - the data source is a CSV file that has only 3 columns, a label column and then two columns which just hold strings referring to JSON files where that data is stored. I have developed functions that access all the data I need, and am able to use Dataset\'s map function on the columns to get the data, but I don\'t see how I can add a new column to my tf.data.Dataset object to hold the new data. So if anyone could help with the following questions, it would really help:\n\nHow can a new feature be appended to a tf.data.Dataset object? Should this process be done on the entire Dataset before iterating through it, or during (I think during iteration would allow utilization of the performance boost, but I don\'t know how this functionality works)? I have all the methods for taking the input as the elements from the columns and performing everything required to get the features for each element, I just don\'t understand how to get this data into the dataset. I could do ""hacky"" workarounds, using a Pandas Dataframe as a ""mediator"" or something along those lines, but I want to keep everything within the Tensorflow Dataset and pipeline process, for both performance gains and higher quality code. I have looked through the Tensorflow 2.0 documentation for the Dataset class (https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset), but haven\'t been able to find a method that can manipulate the structure of the object. Here is the function I use to load the original dataset:\n\ndef load_dataset(self): # TODO: Function to get max number of available CPU threads dataset = tf.data.experimental.make_csv_dataset(self.dataset_path, self.batch_size, label_name=\'score\', shuffle_buffer_size=self.get_dataset_size(), shuffle_seed=self.seed, num_parallel_reads=1) return dataset\n\nThen, I have methods which allow me to take a string input (column element) and return the actual feature data. And I am able to access the elements from the Dataset using a function like "".map"". But how do I add that as a column? deepdreamsdeepdreams\n\nWow, this is embarassing, but I have found the solution and it\'s simplicity literally makes me feel like an idiot for asking this.""""""', '""""""How do I add a new feature column to a tf.data.Dataset object? Modified 4 years ago\n\nI am building an input pipeline for proprietary data using Tensorflow 2.0\'s data module and using the tf.data.Dataset object to store my features. Here is my issue - the data source is a CSV file that has only 3 columns, a label column and then two columns which just hold strings referring to JSON files where that data is stored. I have developed functions that access all the data I need, and am able to use Dataset\'s map function on the columns to get the data, but I don\'t see how I can add a new column to my tf.data.Dataset object to hold the new data. So if anyone could help with the following questions, it would really help:\n\nHow can a new feature be appended to a tf.data.Dataset object? Should this process be done on the entire Dataset before iterating through it, or during (I think during iteration would allow utilization of the performance boost, but I don\'t know how this functionality works)? I have all the methods for taking the input as the elements from the columns and performing everything required to get the features for each element, I just don\'t understand how to get this data into the dataset. I could do ""hacky"" workarounds, using a Pandas Dataframe as a ""mediator"" or something along those lines, but I want to keep everything within the Tensorflow Dataset and pipeline process, for both performance gains and higher quality code. I have looked through the Tensorflow 2.0 documentation for the Dataset class (https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset), but haven\'t been able to find a method that can manipulate the structure of the object. Here is the function I use to load the original dataset:\n\ndef load_dataset(self): # TODO: Function to get max number of available CPU threads dataset = tf.data.experimental.make_csv_dataset(self.dataset_path, self.batch_size, label_name=\'score\', shuffle_buffer_size=self.get_dataset_size(), shuffle_seed=self.seed, num_parallel_reads=1) return dataset\n\nThen, I have methods which allow me to take a string input (column element) and return the actual feature data. And I am able to access the elements from the Dataset using a function like "".map"". But how do I add that as a column? deepdreamsdeepdreams\n\nWow, this is embarassing, but I have found the solution and it\'s simplicity literally makes me feel like an idiot for asking this.""""""']"
76324368,tf.keras.layers.Dense,example required,Understanding tf.keras.layers.Dense(),"<p>I am trying to understand why there is a difference between calculating a dense layer operation directly and using the <code>keras</code> implementation.</p>
<p>Following the documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense</a>) <code>tf.keras.layers.Dense()</code> should implement the operation <code>output = activation(dot(input, kernel) + bias)</code> but <code>result</code> and <code>result1</code> below are not the same.</p>
<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(5,10)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<p>output</p>
<pre class=""lang-py prettyprint-override""><code>
[[2.87080455]
 [3.25458574]
 [3.28776264]
 [3.14319134]
 [2.04760242]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]

</code></pre>
<p>Using <code>test.get_weights()</code> I can see that the kernel and bias (<code>b</code>) are getting set to the correct values. I am using TF version 2.12.0.</p>
","<p>After some experimentation I realized that the <code>kernel</code> for the dense layer needs to be of <code>shape=(10,5)</code> as apposed to <code>(5,10)</code> as in the code from the original question above. This is implicit because <code>units=5</code> so a vector of size <code>10</code> needs to be passed (hence why <code>input_shape=(10,)</code> is commented out as a reminder). Below is the corrected code:</p>
<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias   = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            # input_shape=(10,),
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<pre class=""lang-py prettyprint-override""><code>[[2.38769]
 [3.63470697]
 [2.62423944]
 [3.31286287]
 [2.91121125]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]
</code></pre>
<p>Ultimately, I am not entirely sure what was happening under the hood and why <code>keras</code> did not raise an error. I will check with the <code>tf.keras.layers.Dense()</code> implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!</p>
","After some experimentation I realized that the <code>kernel</code> for the dense layer needs to be of <code>shape=(10,5)</code> as apposed to <code>(5,10)</code> as in the code from the original question above. This is implicit because <code>units=5</code> so a vector of size <code>10</code> needs to be passed (hence why <code>input_shape=(10,)</code> is commented out as a reminder). 

Ultimately, I am not entirely sure what was happening under the hood and why <code>keras</code> did not raise an error. I will check with the <code>tf.keras.layers.Dense()</code> implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!","<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)

bias   = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)
kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32)
x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))

result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias)
tf.print(result)

test = tf.keras.layers.Dense(units = 5, 
                            # input_shape=(10,),
                            activation = 'relu',
                            use_bias = True, 
                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), 
                            bias_initializer = tf.keras.initializers.Constant(value=bias), 
                            dtype=tf.float32)

result1 = test(tf.transpose(x))

print()
tf.print(result1)

</code></pre>
<pre class=""lang-py prettyprint-override""><code>[[2.38769]
 [3.63470697]
 [2.62423944]
 [3.31286287]
 [2.91121125]]

[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]
</code></pre>","['Understanding the tf.keras.layers.Dense layer in TensorFlow', 'How to use kernel_initializer and bias_initializer in tf.keras.layers.Dense', 'Difference between tf.linalg.matmul and tf.keras.layers.Dense', 'How to set and retrieve weights in tf.keras.layers.Dense', 'Common mistakes when using tf.keras.layers.Dense with custom initializers', 'Debugging discrepancies in TensorFlow dense layer outputs', 'Step-by-step guide to implementing a dense layer in TensorFlow', 'Using tf.nn.relu with custom weights and biases in TensorFlow', 'TensorFlow 2.12.0 dense layer implementation details']","['Why is there a difference between calculating a dense layer operation directly and using the keras implementation?', 'How does tf.keras.layers.Dense() handle input shapes and transpositions?', 'What are the differences in input handling between tf.linalg.matmul and tf.keras.layers.Dense?', 'How does tf.keras.layers.Dense() apply the activation function and bias?', 'What are the best practices for initializing kernel and bias in tf.keras.layers.Dense?', 'How to ensure consistent results between manual dense layer calculations and tf.keras.layers.Dense?']",set(),[],"{'https://stackoverflow.com/questions/66626700/difference-between-tensorflows-tf-keras-layers-dense-and-pytorchs-torch-nn-lin', 'https://stackoverflow.com/questions/76324368/understanding-tf-keras-layers-dense', 'https://stackoverflow.com/questions/60783216/what-exactly-does-tf-keras-layers-dense-do'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nWhat exactly does tf.keras.layers.Dense do? Asked 4 years, 3 months ago\n\nModified 4 years, 3 months ago\n\nI\'m using the Keras to build a convolutional neural network. I ran across the following:\n\nmodel = tf.keras.Sequential() model.add(layers.Dense(10*10*256, use_bias=False, input_shape=(100,)))\n\nI\'m curious - what exactly mathematically is going on here? My guess is that for input of size [100,N], the network will be evaluated N times, once for each training example. The Dense layer created by layers.Dense contains (10*10*256) * (100) parameters that will be updated during backpropagation. wheresmycookiewheresmycookie\n\n\n\nDense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True). Note: If the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with kernel. # as first layer in a sequential model: model = Sequential() model.add(Dense(32, input_shape=(16,))) # now the model will take as input arrays of shape (*, 16) # and output arrays of shape (*, 32) # after the first layer, you don\'t need to specify # the size of the input anymore: model.add(Dense(32))\n\n> units: Positive integer, dimensionality of the output space. > activation: Activation function to use.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nUnderstanding tf.keras.layers.Dense()\n\nAsked 1 year, 2 months ago\n\nModified 7 months ago\n\nI am trying to understand why there is a difference between calculating a dense layer operation directly and using the keras implementation. Following the documentation (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) tf.keras.layers.Dense() should implement the operation output = activation(dot(input, kernel) + bias) but result and result1 below are not the same. tf.random.set_seed(1) bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32) kernel = tf.Variable(tf.random.uniform(shape=(5,10)), dtype=tf.float32) x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32)) result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x) + bias) tf.print(result) test = tf.keras.layers.Dense(units = 5, activation = \'relu\', use_bias = True, kernel_initializer = tf.keras.initializers.Constant(value=kernel), bias_initializer = tf.keras.initializers.Constant(value=bias), dtype=tf.float32) result1 = test(tf.transpose(x)) print() tf.print(result1)\n\n[[2.87080455] [3.25458574] [3.28776264] [3.14319134] [2.04760242]] [[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]\n\nUsing test.get_weights() I can see that the kernel and bias (b) are getting set to the correct values. I am using TF version 2.12.0. edited Jan 7 at 7:48\n\n\n\nAfter some experimentation I realized that the kernel for the dense layer needs to be of shape=(10,5) as apposed to (5,10) as in the code from the original question above. This is implicit because units=5 so a vector of size 10 needs to be passed (hence why input_shape=(10,) is commented out as a reminder). Below is the corrected code:\n\ntf.random.set_seed(1) bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32) kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32) x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32)) result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias) tf.print(result) test = tf.keras.layers.Dense(units = 5, # input_shape=(10,), activation = \'relu\', use_bias = True, kernel_initializer = tf.keras.initializers.Constant(value=kernel), bias_initializer = tf.keras.initializers.Constant(value=bias), dtype=tf.float32) result1 = test(tf.transpose(x)) print() tf.print(result1)\n\n[[2.38769] [3.63470697] [2.62423944] [3.31286287] [2.91121125]] [[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]\n\nUltimately, I am not entirely sure what was happening under the hood and why keras did not raise an error. I will check with the tf.keras.layers.Dense() implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nUnderstanding tf.keras.layers.Dense()\n\nAsked 1 year, 2 months ago\n\nModified 7 months ago\n\nI am trying to understand why there is a difference between calculating a dense layer operation directly and using the keras implementation. Following the documentation (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) tf.keras.layers.Dense() should implement the operation output = activation(dot(input, kernel) + bias) but result and result1 below are not the same. tf.random.set_seed(1) bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32) kernel = tf.Variable(tf.random.uniform(shape=(5,10)), dtype=tf.float32) x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32)) result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x) + bias) tf.print(result) test = tf.keras.layers.Dense(units = 5, activation = \'relu\', use_bias = True, kernel_initializer = tf.keras.initializers.Constant(value=kernel), bias_initializer = tf.keras.initializers.Constant(value=bias), dtype=tf.float32) result1 = test(tf.transpose(x)) print() tf.print(result1)\n\n[[2.87080455] [3.25458574] [3.28776264] [3.14319134] [2.04760242]] [[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]\n\nUsing test.get_weights() I can see that the kernel and bias (b) are getting set to the correct values. I am using TF version 2.12.0. edited Jan 7 at 7:48\n\n\n\nAfter some experimentation I realized that the kernel for the dense layer needs to be of shape=(10,5) as apposed to (5,10) as in the code from the original question above. This is implicit because units=5 so a vector of size 10 needs to be passed (hence why input_shape=(10,) is commented out as a reminder). Below is the corrected code:\n\ntf.random.set_seed(1) bias = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32) kernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32) x = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32)) result = tf.nn.relu(tf.linalg.matmul(a=kernel, b=x, transpose_a=True) + bias) tf.print(result) test = tf.keras.layers.Dense(units = 5, # input_shape=(10,), activation = \'relu\', use_bias = True, kernel_initializer = tf.keras.initializers.Constant(value=kernel), bias_initializer = tf.keras.initializers.Constant(value=bias), dtype=tf.float32) result1 = test(tf.transpose(x)) print() tf.print(result1)\n\n[[2.38769] [3.63470697] [2.62423944] [3.31286287] [2.91121125]] [[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]\n\nUltimately, I am not entirely sure what was happening under the hood and why keras did not raise an error. I will check with the tf.keras.layers.Dense() implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!""""""', '""""""Oh, I see. The question title confused me. It seems like you wanted to know how they\'re calculated behind. Alex\'s answer should ok for you. Yes, I could\'ve phrased it slightly better. But regardless, I just needed clarification of the Linear Algebra itself and how these Layers differ between Linears. The derivative is one example in how they differ ( as they\'re different linear algrabra operations ). I did state a \'guess\' of what TF\'s Dense layer is and if it\'s the same. So, I might make an edit to the title if other people think it\'ll help with clarification! Thank you for the explanation of the TF\'s Dense layer though! :D\n\n\n\ntf.keras.layers.Dense is defined here in the tensorflow source code:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/core.py#L1081\n\nIf you follow the references in its call function, it leads you to the definition of the operation used here, which is indeed a matrix multiplication of the inputs and weights plus a bias vector as expected:\n\nhttps://github.com/tensorflow/tensorflow/blob/a68c6117a1a53431e739752bd2ab8654dbe2534a/tensorflow/python/keras/layers/ops/core.py#L74\n\noutputs = gen_math_ops.MatMul(a=inputs, b=kernel) ... outputs = nn_ops.bias_add(outputs, bias)\n\n4\n\nSo, the definition of the kernel variable is a weight matrix but of the opposite dimension of PyTorch\'s weight matrix? So, let\'s say I have A input features of batch size N, and B output features. The dimensionality of kernel would be [A, B] whereas in the case of PyTorch it\'d be [B, A] (because there\'s a transpose applied to it?)\n\n\n\nYes they store the weights slightly differently (W.T vs W) but the result is still the same. PyTorch\'s representation is closer to the notation in text books. You can check this quickly by printing out the shape of the Linear/Dense weights in torch and tf. In line 1192 of the first link to the TF source code above, the weights in are initialised with shape=[last_dim, self.units] (N_feats, N_out) and in PyTorch (source code link), the weights are initialised with Parameter(torch.Tensor(out_features, in_features)) (N_out, N_feats)\n\n\n\nAlright, so for a linear layer of input x of shape (N_samp, N_feats) the output for TF would be matmul(x, A) + b where A is (N_feats, N_out) and b is (N_out, ) and for PyTorch it\'s matmul(x, A^T) + b where A is now (N_out, N_feats) and b is (N_out, ). Alright, so it seems that the 2 libraries define their Linear layers differently! Thank you @Alex!""""""']"
68984841,tf.keras.layers.Dense,example required,How can I understand the kernel of tf.keras.layers.Dense for rank >2?,"<p>How can I understand the kernel of <code>tf.keras.layers.Dense</code> for rank &gt;2?</p>
<p>The official API doc states that:</p>
<blockquote>
<p>Note: If the input to the layer has a rank greater than 2, then Dense
computes the dot product between the inputs and the kernel along the
last axis of the inputs and axis 0 of the kernel (using tf.tensordot).
For example, if input has dimensions (batch_size, d0, d1), then we
create a kernel with shape (d1, units), and the kernel operates along
axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there
are batch_size * d0 such sub-tensors). The output in this case will
have shape (batch_size, d0, units).</p>
</blockquote>
<p>My understanding is that for a rank larger than 2 (for example rank 3) only <strong>one</strong> kernel is created and thus the same kernel is applied on all slices of the second dimension, like above.
That would consequently mean that the outputs for different indices of the second dimension are <strong>not independent</strong> of each other (especially during training).</p>
<p>Is my understanding correct? And if yes, is there a simple way to use a stack of kernels instead or do I have to implement the tensor multiplication?</p>
","<p>Yes, your understanding is correct.</p>
<p>To achieve what you want, you need to define a custom keras layer. Let's suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original <code>Dense</code> layer (link: <a href=""https://github.com/tensorflow/tensorflow/blob/22ffec3a9c44133cba2182d60678d49bb372f020/tensorflow/python/keras/layers/core.py#L1077"" rel=""nofollow noreferrer"">github</a>), except that</p>
<ol>
<li>In the <code>build</code> function, the shape of <code>self.kernel</code> is (d0, i0, units) instead. You can get the value of <code>d0</code> as well as <code>i0</code> from <code>input_shape</code>.</li>
<li>In the <code>call</code> function, to do the specified tensor multiplication between <code>inputs</code> and <code>self.kernel</code>, use <code>tf.einsum</code> with this equation: <code>tf.einsum('abc,bcg-&gt;abg', inputs, self.kernel)</code></li>
</ol>
","Yes, your understanding is correct. To achieve what you want, you need to define a custom keras layer. Let's suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original <code>Dense</code> layer, except that

1. In the <code>build</code> function, the shape of <code>self.kernel</code> is (d0, i0, units) instead. You can get the value of <code>d0</code> as well as <code>i0</code> from <code>input_shape</code>.
2. In the <code>call</code> function, to do the specified tensor multiplication between <code>inputs</code> and <code>self.kernel</code>, use <code>tf.einsum</code> with this equation: <code>tf.einsum('abc,bcg-&gt;abg', inputs, self.kernel)</code>",,"['Understanding tf.keras.layers.Dense for rank > 2 inputs', 'How does tf.keras.layers.Dense handle inputs with rank greater than 2?', 'TensorFlow Dense layer with rank 3 input explanation', 'Using multiple kernels in tf.keras.layers.Dense for higher rank inputs', 'TensorFlow Dense layer kernel application on higher rank tensors', 'Independent outputs for different indices in tf.keras.layers.Dense', 'Implementing tensor multiplication for tf.keras.layers.Dense with rank > 2 inputs']","['How does tf.keras.layers.Dense handle inputs with rank greater than 2?', 'Is it true that tf.keras.layers.Dense uses the same kernel for all slices of the second dimension when the input rank is greater than 2?', 'How can I use a stack of kernels in tf.keras.layers.Dense for inputs with rank greater than 2?', 'Are the outputs for different indices of the second dimension dependent on each other when using tf.keras.layers.Dense with rank greater than 2 inputs?', 'What is the best way to implement tensor multiplication with a stack of kernels in TensorFlow?']","{'https://www.youtube.com/watch?v=oJ1i2c1KxKk', 'https://www.youtube.com/watch?v=lor2LnEVn8M', 'https://www.youtube.com/watch?v=kyktbJpg2mU'}","['""""""[Document(page_content=""hi I\'m Zack Dean mayor and in this course I\'ll be teaching you advanced deep learning concepts using the Charis functional API you will learn how to build functional Kerris models including advanced topics such as shared layers categorical embeddings multiple inputs and multiple outputs the Charis functional API is extremely simple yet immensely powerful by the end of this class you will build a model that is capable of solving a regression and a classification problem at the same time chapter one is a refresher on building simple models where you will learn how to use the Charis functional API in Chapter two you will build a Karass model with two inputs in Chapter three you will learn how to generalize your two input model to three or more inputs and finally in Chapter four you will build models with multiple outputs that can solve multiple problems you will be using two datasets of college basketball games from American colleges the first data set is from the regular season and has the following data the IDS of the two teams that played whether the first team was home or away whether the first team won or lost the game and by how many points the first team won or lost for the tournament data set you also have the tournament seed which is a pre-tournament ranking for each team these seeds range from 1 to 16 where the best four teams get a seed of one and the worst four teams get a seed of 16 you will use the difference in the two team seeds as an input to your model here are the first five rows of both the data sets you can see that the team variables are encoded as integers and the tournament data set has one additional column the difference between the tournament seats for both teams other than the seed difference the two datasets have identical columns within a given year a team\'s roster stays relatively constant but between years it can change a lot as seniors graduate and freshmen start therefore for every year each school is given a unique integer ID Terrace models at their simplest are fundamentally composed of two parts an input layer and an output layer to start I\'ll define a very simple Kerris model which only expects a single input I\'ll specify this using the input function from the Charis layers module the number of columns in the input is specified using the shape parameter this tells the model how much data to expect note that the shape argument expects a tupple the input function returns a tensor if you print this tensor you\'ll see that it is a TF tensor object which indicates it is ready to be used by our model as input now that we\'ve defined our input layer let\'s define the output layer outputs in Kerris are most commonly a single dense layer which specifies the shape of the expected output in this case we are expecting our model to predict a single value so we pass one unit to the dense layer if you print the output layer the result is not a tensorflow tensor it is a function which takes a tensor as input and produces a tensor as output the difference between layers in tensors is key to understanding the Charis functional API layers are used to construct a deep learning model in tensors are used to define the data flow through the model in this case the input layer defines a tensor which we then pass to the output layer function the final output of our model is a tensor it is time for you to build some layers"", metadata={\'source\': \'oJ1i2c1KxKk\'})]""""""', '""""""[Document(page_content=""hello everyone Dr data science here welcome to Deep dive into Caris this is lecture one where we talk about sequential API to implement a simple neural network model for the very famous exclusive or or xor example so what is the sequential API the sequential API in Caris is a stack of layers where you can simply add one layer at a time and the information will through flow through the first layer and will go to the next layer and so on until it reaches the last uh layer of your network and obviously in this case each layer has weights that corresponds to the layer that follows it right so for example here we have the weights that connect the this input layer to the hidden layer and also the weights that they go from the hidden layer to the output layer and it\'s a very straightforward and simple way to build and train models for more complex architectures you probably want to look at the functional API in cares uh and we\'re going to talk about that in a future video but let\'s get it started today uh with the sequential API so in order to implement neural network in this case you have to follow five steps the very first step is to create and uh object so remember uh when we working with python we work with object oriented programming where we have classes and once we instantiate a class that\'s what we call an object and in order to do that you just simply from car. Models you import sequential so this is a sequential a API and then you instantiate this to create this model object and once you do that now you can add layers right um so one of the uh you know layers that we work a lot with is this dense layer which means that all the neurons are connected to the neurons in the previous layer um that\'s why it\'s called as the fully connected or dance layer and you can do so very simply by just using this method called model. add so this adds a layer to your network and the thing that you really have to hear specify is the number of units or the number of neurons in that layer uh for the very first layer you also so it\'s always a good idea to to uh give the dimension of your input data for example if you work with a two-dimensional data here uh the input DM would be two and also the activation function or the nonlinear function that that you use for your uh for that layer and here you can see that now we have also um another layer um that we are um adding um here you know we have units and activation here you know we don\'t Define input dim anymore more because we already know how many units we have before so you don\'t need any more input them here and then for the very F last layer you can add model. add um the number of units and this really depends on the uh data set that you have if you have a binary classification then you only use one unit here uh with the sigmoid activation function um and if you have like let\'s say uh a classification problem with 10 classes then use here unit equals 10 and activation is equal to softmax um so to just to summarize this your first and last layer are very much controlled by your data set but you have um a lot of freedom or flexibility in terms of what hidden layers you want to use the next step once you define or create your model is to compile it and this is where you provide the optimizer that you want to use remember we are using gradient descent uh type optimization techniques here so we can say here for example SGD or RMS prop or Adam or whatever else Optimizer that you have and we\'re going to talk about this in a future video and then the loss function and then the metrics that you want to use to to to uh monitor to learning progress and once you do this now you you do model feeding so that\'s where you actually like train your model you have to provide your training data the number of epoch or the number of times that you have to go through the data set and the B size which means that um how many data points are using uh for each uh gradient desent update and once you uh train your model now your model um is trained which means that now you can make predictions so you can use model. predict and um now we\'re going to see how all these five steps work together to to solve uh a classification problem so we\'re going to start by importing the essentials meaning import n as NP uh M plug le. pyplot as PLT this is what we need for plotting figures obviously we are working with Caris you have to import tensor flow as TF and also from tensor flow we import Caris um we can also look at the version of tensor flow that you have currently I have 2.1 um Z right so uh I definitely recommend you to use 10 tensorflow uh 2.0 so in order to create the data set for this problem in order uh for you to be able to replicate these uh experiments and I also put a link down below for for the for the GitHub page for these codes uh we\'re going to work with the synthetic data set so we\'re going to work with uh what is called as make blops as the name um says you\'re going to create Blobs of data I\'m using np. random. seit to make sure that um you know again for the producibility and then I\'m using make blobs where I provide four centers here and each of these centers is a two-dimensional Vector um so you can see here that these are the four blobs that we create the only thing I do here is that I want to make sure that this is a binary classification problem um so I\'m going to uh convert those four labels that are created here uh into a binary classification I just assigned them um two different values um and this is the exclusive or problem that you can see in a lot of um you know neuron networks and deep learning textbooks that when you have zero and zero you get zero one and one you get one so this mean sorry one and one you get zero uh so this means that these two uh clusters belong to the same class and then when you have zero and one or one and zero you get one so that\'s the other class that we have so that\'s why it\'s called exclusive or um and other than that here we just using you know scatter plot to to plot the data with the colors as the labels uh and using the title um X and Y labels that\'s always a good practice to to follow but the point that really uh is important here is to you know um create the model you know um compile it and train it uh in order to do that we you know as we said use carat models import sequential so that\'s for the sequential API and then you import the dense layer you instantiate your um object here this model object you add your first uh hidden layer which has two units in it and I\'m using here exponential linear unit as my activation and I\'m going to say that the input Dimension here is two right so if I go back to this very first uh figure that we have here we can see that this is a two-dimensional problem so these are the two inputs that I have and these are the two units that I have in my uh single hidden layer in this uh problem so therefore we have four raats and also we have two B bies remember we always have biases unless if we we turn off that option but for now we have these biases so this a total of six parameters that we have to learn four weights and two bies and then going from hidden layer to the output there are two weights and one bi that goes to the output layer okay so now uh one thing that you can do so once you define your model and you compile it so here I\'m using a stochastic gradient descent and because it\'s a class ification problem I\'m using binary cross entropy um so now we can use model. summary so this is exactly what I was talking about that you can see that we have six parameters that we have to train uh for the first layer and then three for the second one right uh so this is including bies that we have to include then you can look at U model. layers so this this gives you some attributes or whatever layers that we have and you can see that if I look at the first layer that\'s why index zero and use this method get weights you can see that we have a 2X two weight Matrix and two biases um and even though we have not train anything right now um you can see that there are still values here because we initialize this you know usually randomly um and so you can see that the weight metrix has know some random numbers here um and then the biases are usually initialized by by zeros um you can see that here too for the next layer we have a um you know a two weights um that takes us from the hidden layer to the output layer and then the bi but the point that you start to train this model is when you use this model. fit where you provide your data both the inputs and the labels the number of epoch which I have here choose 10 and the batch size which I have chosen to be four so these are uh options that you have to provide in in general so you can see that based on what we have here uh printed we have Epoch one two up to 10 um the last function is what you try to minimize so that\'s what\'s um you know usually hope that it will be uh descending or or decreasing function as as as the number of epoch increases and the accuracy here is classification accuracy so you want that to be as close as to be to one and you can see that it is you know at the end um 0 99 so very close to one so we can actually look at the accuracy and loss as the is a function of number of epochs because this is the information stored in that history um object that we have here and this gives us um a lot of good information right so if you look at it let\'s look at um you know accuracy first so we can see that accuracy is increasing so we are starting um you know from you know Point uh if I don\'t make mistake here from 0 five which means that you uh flip a coin and you get you know 50% um classification accuracy um and then uh as we have more Epoch we can see that this gets closer and closer to one or 100% And and then we see consistent results with the loss function right the loss function uh you know decreases consistently as the number of epoch increases so this is a perfect scenario of uh a neural network model that works um that works well for a given problem and this is what we expect because of the uh synthetic data set that we have and now after you train your model you can again look at those weights for the first layer and if you look at it these are different um than uh what we had before because you know we trained this model and the same with biases we can see that now we actually have nonzero values for for this bios terms the last thing I want to to talk about here is how you can visualize your classifier and have that nice plot of the probabilities that we just saw in order to do that you have to first create a two dimension dional grid so you provide the mean and Max values for both uh X and Y AIS um Su step size and then use this np. mesh grid um and this what basically does is that gives you all the coordinates that you need to create a a two-dimensional grid and now you can just Ravel them meaning that you flatten them and you concatenate them to create this mesh underscore input uh where you have these two dimensional data points or coordinates for all the sort of like you know data points on your grid and then use model. predict and in this case this gives you the probability that your data point belongs to uh class uh one so that\'s what we get here with predictions uh and then we we fit this to the Contour plot right so this PLT do contourf um that\'s what gives you this really nice plot right so these are the probabilities that we get here so you can see that obviously the separation here that this Middle Street is one class and then when you get farther from both sides then is more more likely that you belong to the other class the data points that you have um so that\'s why here you can see that this neural network uh is successful at uh predicting these classes correctly even though this is a complex problem because a linear classifier cannot correctly you know classify all these data points so this was uh one of the first examples of neural networks to show that um you know um that they work very well with these types of uh problems with subclusters and as a very final note um to just uh you know again collaborate the fact that if you use model that predict in in Paris you get probabilities um I\'m going to plot a histogram of these values and you can see that they\'re from zero to one right so as we said these are probability scores U and you can see that you know for you know about like 10,000 um soort of like cases or so um here we have um probabilities very close to zero and then probabilities very close to one um similarly and then a few data points that we are very close to like 50% right so these are the you know more difficult cases to to predict thank you so much for watching this video"", metadata={\'source\': \'kyktbJpg2mU\'})]""""""', '""""""[Document(page_content=""hi today we will study what is danger layer while you is dense layer and how we use danger layer intensive flow tool previously we studied how single node is working if you have a closed loop the node is just had three steps first multiplying input with the weight second adding bias Dudley applying activation function and return the output here picture I use the sigmoid as activation function and our compute this node for the interlayer explanation then the layer is just a set of nodes when inputs come to danger layer a danger layer provides input to all nodes in it thus providing all outputs to the next layer at once as a result this is an example of two nodes than the layer and this is an example of three nodes dense layer there are many reasons why we use danger layer most importantly we use tenth layer to put the data in the different dimension let\'s understand it with easy example before speak about the dense layer let\'s keep in mind that one node can draw one decision boundary therefore two nodes can draw to the Sun boundary previously we made and an or operation with one single node the reason why we could implement and an or operation with just one single node is because this new operation just need a one decision boundary to classify all or X and one node can draw one decision boundary as you can see from this picture however we cannot implement XOR operation with one single node because as you can see from this picture one decision boundary cannot classify or extremely since one node Rose one Sun boundary at least we can draw through the same boundaries using two nodes let\'s say first node is z1 and the second node is z2 and since it\'s not output is sigmoid function output we can say if the output value is greater than 0.5 the output is true or the output is false and you can find I marked one side from that eastern boundary to true and the other side is forced here for better understanding I put the table having the output from z1 and z2 so now let\'s have one other coordinate in which ugh z1 and z2 as dimensions you can see the right side chart where the z1 and z2 are axes there are two O\'s are overlapped and the two axes are scattered in order to classify oh and X from this dimension we\'ll need one more decision boundary tapping said we need one more node in this dimension then we can classify XOR dataset clearly awesome we will implement it using tensor flow too soon in this video to sum up in order to draw to the same boundary we need one dense layer having two nodes then we need one another dense layer having just one node to classify data point in first dense layers dimension I believe you can understand even easier with this picture I visualize how the first and the second dentin layer draws this young boundary and the here is a tensile flow to code to make XOR input and labels respectively and here is the code where I make first dense layer with two nodes for which text two-dimensional input data and you can see it as a Content layer has a one single node for one decision boundary on for stencil layers dimension and here you can find I use the gradient descent for the optimization and the cross entropy as a loss function finally we got a hundred percent test result from our tensor flow model with two dense layer you also can print each dentin layer node wait and buyers just make sure the number of columns are the number of nodes in the tens layer and the number of the rules are the numbers of the weights in the node and here you can find the second denser layers of weight and bias value as well then the layer also very useful for last layer of the classification model since n node danger layer output and output this is an example of classifying M needs the ten digits by having ten nodes then the layer at the last layer we can use the greatest output value index as a models prediction however since the denser layers node output are not normalized normally we apply softmax function at the last dense layer so the outputs to be normalized now you can see the zooming off of each node output is 1 so you can use the each node value as confidence for each number and we can use those the great greatest output value as a modest prediction this is all for this video and you can always practice XOR or in this our link thanks for watching and I\'ll come back to next video with a nice digital classification"", metadata={\'source\': \'lor2LnEVn8M\'})]""""""']","{'https://stackoverflow.com/questions/68984841/how-can-i-understand-the-kernel-of-tf-keras-layers-dense-for-rank-2', 'https://stackoverflow.com/questions/52089601/keras-dense-layers-input-is-not-flattened', 'https://stackoverflow.com/questions/63507023/how-to-make-a-keras-dense-layer-deal-with-3d-tensor-as-input-for-this-softmax-fu'}","['""""""Keras Dense layer\'s input is not flattened\n\nAsked 4 years, 10 months ago\n\nModified 4 years, 3 months ago\n\nThis is my test code:\n\nfrom keras import layers input1 = layers.Input((2,3)) output = layers.Dense(4)(input1) print(output)\n\n<tf.Tensor \'dense_2/add:0\' shape=(?, 2, 4) dtype=float32>\n\nThe documentation says:\n\nNote: if the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with kernel. While the output is reshaped?""""""', '""""""Take the 2023 Developer Survey. How can I understand the kernel of tf.keras.layers.Dense for rank >2? Asked 1 year, 8 months ago\n\nModified 1 year, 8 months ago\n\nHow can I understand the kernel of tf.keras.layers.Dense for rank >2? The official API doc states that:\n\nNote: If the input to the layer has a rank greater than 2, then Dense computes the dot product between the inputs and the kernel along the last axis of the inputs and axis 0 of the kernel (using tf.tensordot). For example, if input has dimensions (batch_size, d0, d1), then we create a kernel with shape (d1, units), and the kernel operates along axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there are batch_size * d0 such sub-tensors). The output in this case will have shape (batch_size, d0, units). My understanding is that for a rank larger than 2 (for example rank 3) only one kernel is created and thus the same kernel is applied on all slices of the second dimension, like above. That would consequently mean that the outputs for different indices of the second dimension are not independent of each other (especially during training). Is my understanding correct? And if yes, is there a simple way to use a stack of kernels instead or do I have to implement the tensor multiplication? Yes, your understanding is correct. To achieve what you want, you need to define a custom keras layer. Let\'s suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original Dense layer (link: github), except that\n\nIn the build function, the shape of self.kernel is (d0, i0, units) instead. You can get the value of d0 as well as i0 from input_shape. In the call function, to do the specified tensor multiplication between inputs and self.kernel, use tf.einsum with this equation: tf.einsum(\'abc,bcg->abg\', inputs, self.kernel)\n\nLaplace RickyLaplace Ricky\n\n1,""""""', '""""""Take the 2023 Developer Survey. How can I understand the kernel of tf.keras.layers.Dense for rank >2? Asked 1 year, 8 months ago\n\nModified 1 year, 8 months ago\n\nHow can I understand the kernel of tf.keras.layers.Dense for rank >2? The official API doc states that:\n\nNote: If the input to the layer has a rank greater than 2, then Dense computes the dot product between the inputs and the kernel along the last axis of the inputs and axis 0 of the kernel (using tf.tensordot). For example, if input has dimensions (batch_size, d0, d1), then we create a kernel with shape (d1, units), and the kernel operates along axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there are batch_size * d0 such sub-tensors). The output in this case will have shape (batch_size, d0, units). My understanding is that for a rank larger than 2 (for example rank 3) only one kernel is created and thus the same kernel is applied on all slices of the second dimension, like above. That would consequently mean that the outputs for different indices of the second dimension are not independent of each other (especially during training). Is my understanding correct? And if yes, is there a simple way to use a stack of kernels instead or do I have to implement the tensor multiplication? Yes, your understanding is correct. To achieve what you want, you need to define a custom keras layer. Let\'s suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original Dense layer (link: github), except that\n\nIn the build function, the shape of self.kernel is (d0, i0, units) instead. You can get the value of d0 as well as i0 from input_shape. In the call function, to do the specified tensor multiplication between inputs and self.kernel, use tf.einsum with this equation: tf.einsum(\'abc,bcg->abg\', inputs, self.kernel)\n\nLaplace RickyLaplace Ricky\n\n1,""""""']"
53079436,tf.cond,example required,tensorflow Tf.cond giving unexpected output,"<p>I seem to be having a misunderstanding on how <code>tf.cond</code> works. In the tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/cond"" rel=""nofollow noreferrer"">documentation</a>, it gives the following example:</p>

<pre><code>z = tf.multiply(a, b)
result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))
</code></pre>

<p>The result of the example, if <code>x&lt;y</code> is <code>True</code> is <code>tf.add(x,z)</code> else <code>tf.square(y)</code></p>

<p>Following this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation.</p>

<p>in my example, <code>deterministic_action = 4</code>, <code>random_action = 11</code>, <code>chose_random=False</code>. The <code>stochastic_action</code> should be <code>4</code>, instead it is <code>1</code>.
Where did the value 1 come from?</p>

<pre><code>#!/usr/bin/env python3

import tensorflow as tf
import numpy as np

with tf.Graph().as_default():
    with tf.device('/cpu:0'):
        stochastic_ph = tf.placeholder(tf.bool, (), name=""stochastic"")
        eps = tf.get_variable(""eps"", (), initializer=tf.constant_initializer(0))
        with tf.variable_scope('test_cond') as sc:
            deterministic_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=0) # 4
            random_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=1) # 11
            chose_random = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32) &lt; eps # False because eps = 0
            stochastic_action = tf.cond(chose_random, lambda: random_action, lambda: deterministic_action) # S_action should be 4 but it is 1
            #output_action = tf.cond(stochastic_ph, lambda: stochastic_action, lambda: deterministic_action)


    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init, feed_dict={stochastic_ph: True})
    print (""s_ph = "", stochastic_ph)
    d_action = sess.run(deterministic_action)
    print (""det_action= "", d_action)
    r_action = sess.run(random_action)
    print (""rand_action= "", r_action)
    e = sess.run(eps)
    c_action = sess.run(chose_random)
    print (""chose_rand= "", c_action)
    s_action = sess.run(stochastic_action)
    print (""s_action= "", s_action)
    #output = sess.run(output_action)
</code></pre>

<p>here is the output:</p>

<pre><code>python random_vec.py
2018-10-31 09:46:15.028376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
</code></pre>
","<p>This is because you are evaluating again in a new sess.run. 
Since you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1.
Here is the result of your code, when I extract the value of deterministic_action as well in the last step.</p>

<p>Modification:</p>

<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
r_action = sess.run(random_action)
print (""rand_action= "", r_action)
e = sess.run(eps)
c_action = sess.run(chose_random)
print (""chose_rand= "", c_action)
s_action, d_action = sess.run([stochastic_action, deterministic_action])
print (""s_action= "", s_action)
print (""det_action= "", d_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
det_action=  1
</code></pre>

<p>Now all you need to do is run everything in one sess.run</p>

<pre><code>d_action, r_action, e,  c_action, s_action = sess.run([deterministic_action, random_action, eps, chose_random, stochastic_action])
print (""det_action= "", d_action)
print (""rand_action= "", r_action)
print (""chose_rand= "", c_action)
print (""s_action= "", s_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  4
</code></pre>

<p>Update:</p>

<p>I was not clear on why the random_uniform generates different values when seed is set. This is because the code is running with the same session object that it initialized the variables with.
Modifying the code with a new session object, this is what happens:</p>

<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
sess.close()
sess = tf.Session()
sess.run(init, feed_dict={stochastic_ph: True})
s_action = sess.run(stochastic_action)
print (""s_action= "", s_action)
</code></pre>

<p>Result:</p>

<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
s_action=  4
</code></pre>
","This is because you are evaluating again in a new sess.run. 
Since you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1.
Here is the result of your code, when I extract the value of deterministic_action as well in the last step.","<pre><code>print (""s_ph = "", stochastic_ph)
d_action = sess.run(deterministic_action)
print (""det_action= "", d_action)
r_action = sess.run(random_action)
print (""rand_action= "", r_action)
e = sess.run(eps)
c_action = sess.run(chose_random)
print (""chose_rand= "", c_action)
s_action, d_action = sess.run([stochastic_action, deterministic_action])
print (""s_action= "", s_action)
print (""det_action= "", d_action)
</code></pre>","['Understanding tf.cond in TensorFlow with examples', 'How to use tf.cond in TensorFlow', 'Common mistakes when using tf.cond in TensorFlow', 'TensorFlow tf.cond tutorial', 'Debugging tf.cond in TensorFlow', 'TensorFlow conditional operations with tf.cond', 'TensorFlow tf.cond vs tf.case', 'TensorFlow control flow operations: tf.cond', 'TensorFlow tf.cond with random operations', 'TensorFlow tf.cond with placeholders and variables']","['How does tf.cond work in TensorFlow?', 'Why does tf.cond return unexpected results in TensorFlow?', 'How to debug tf.cond in TensorFlow?', 'What are common pitfalls when using tf.cond in TensorFlow?', 'How does tf.random_uniform work in TensorFlow?', 'Why does tf.random_uniform return different values on each run?', 'How to ensure deterministic behavior in TensorFlow?', 'How to use tf.placeholder and tf.get_variable correctly in TensorFlow?', 'What is the role of tf.global_variables_initializer in TensorFlow?', 'How to correctly use feed_dict in TensorFlow sessions?']",{'https://www.youtube.com/watch?v=IzKXEbpT9Lg'},"['""""""[Document(page_content=\'SKYE WANDERMAN-MILNE: I\\\'m Skye,\\nfor those who don\\\'t know me. I\\\'ve been working on\\nControl Flow in TensorFlow for quite some time, with\\nthe help of [? Sarab ?] and many other\\nindividuals on the team. And so my goal with\\nthis talk is to tell you everything I know about\\nControl Flow that\\\'s important. Let\\\'s get started. I\\\'m going to start\\nby going over the lay of the land with Control\\nFlow in TensorFlow. So starting with what I\\\'m\\ngoing to call the Base APIs, tf dot cond and\\ntf dot while loop. So these are the\\nprimitives that are exposed in the public\\nPython API for users to access Control Flow. So you have conditional\\nexecution and loops. That\\\'s it. So you might be wondering, what\\nabout all the other Control Flow functions I know and\\nlove, like map or case? These are all built on those two\\nbase APIs, cond and while loop. They\\\'re sort of\\nwrappers around it that add useful functionality. So diving down\\ninto the stack, how are these primitives, cond and\\nwhile, actually implemented? How are they represented\\nin the graph? So in TensorFlow 1.x, we have\\nthese low-level Control Flow ops. You might have heard of them,\\nExit, Enter, Nextiteration, Switch, and Merge. We\\\'ll talk more\\nabout these in a bit. There\\\'s also an\\nalternate representation. That\\\'s what Control Flow\\nversion 2 is all about. These are the ""functional"" ops. And I put ""functional"" in\\nquotes because it\\\'s caused some confusion in the past. It\\\'s not like pure functional. In the programming sense,\\nthey\\\'re still state. But they\\\'re higher\\norder functions that take functions as input. So now, the cond branches will\\nbe represented as functions. So these sort of do the same\\nthing as the low-level ops, but the higher level\\nfunctionality is all wrapped up into a single op. Moving back up the\\nstack, you might be wondering what\\\'s going to\\nhappen with TensorFlow 2.0. If you\\\'re using Eager\\nexecution, you just write Python and you just use\\nPython Control Flow. So if statements, or loops,\\nor list comprehensions, that kind of thing. So there\\\'s no arrow connecting\\nit to this graph mode stuff. But if you use tf dot\\nfunction, maybe some people have heard of Autograph,\\nwhich is automatically included in tf dot\\nfunction, and this attempts to take your eager\\nstyle, just Python code, and convert it into new Python\\ncode that calls the TensorFlow graph APIs. So it\\\'s going to\\ntry to rewrite all that Python Control Flow, your\\nif statements and while loops, into tf dot cond and\\ntf dot while loop. So note that Autograph\\nis just dealing at this abstraction layer of\\nthe public TensorFlow API. It doesn\\\'t have to dive\\ndown into the low-level ops or anything like that. So that\\\'s kind of\\nwhere we\\\'re at. We have the 2.0 world where you\\njust write Python that maybe it can get converted into our\\npublic Graph APIs, which in turn are producing these\\nvarious operators in the graph. And one more thing. Right now, in this\\nnew implementation of Control Flow,\\nControl Flow version 2, we are still converting\\nthe functional ops back into the low-level ops. This is basically a\\nperformance optimization. I hope we don\\\'t have\\nto do it in the future. That\\\'s why it\\\'s this\\nfaded-dash arrow. So this talk, we\\\'re gonna\\nfocus on the base API and how it\\\'s implemented. I think there\\\'ll be another\\ntalk about Autographs, so hopefully they can talk\\nabout Control Flow there. Maybe there\\\'s also talk\\nabout Eager execution and the high-level APIs\\nthat are not so complicated. So leave that as an\\nexercise to the viewer. OK. So I\\\'m going to start with\\ngoing over Control Flow v1, the original\\nlow-level representation. You might be asking, why? Why do we care at all? So like I showed\\nin the diagram, we do still convert the functional\\nops to this representation. So this is basically how\\nit\\\'s executed today, always. Furthermore, this is still\\nwhat we use in TensorFlow 1.x. So all 1.x code is\\nusing Control Flow v1. Still very much alive. And I hope it provides a\\nlittle bit of motivation for why we wanted to\\nimplement Control Flow using the functional ops. So I\\\'m going to start\\nwith these low-level ops. So up here, Switch and Merge are\\nused for conditional execution, this is tf dot cond. Also in while loops to determine\\nwhether we need to keep iterating or we\\\'re done. And then Enter, Exit,\\nand Nextiteration are just used while loops\\nto manage the iterations. So let\\\'s dive in. So Switch and Merge, these\\nare for conditionals. Let\\\'s just start with Switch. The idea is you get your\\npredicate tensor in, this is a Boolean, that tells\\nyou which conditional branch you want to take. And then it has a\\nsingle data input, so [INAUDIBLE] some tensor. And it\\\'s just going to\\nforward that data input to one of its two outputs\\ndepending on the predicate. So in this picture, the\\npredicate must be false. And so the data\\\'s coming\\nout of the false output. Merge basically\\ndoes the opposite. It takes two inputs,\\nbut it only expects data from one of its inputs. And then it just\\noutputs a single output. So Switch is how you start\\nyour conditional execution, because it\\\'s going to divert\\nthat data into one branch. And then Merge brings\\nit back together into your mainline execution. It\\\'s not conditional anymore. One implementation detail\\nI\\\'m going to mention here is dead tensors. So you might think\\nthat nothing is going to come out of the\\ntrue output of the Switch, but it actually does output\\na special dead tensor, which is just like a sentinel value. Like a little tiny thing. And dead tensors flow\\nthrough the whole untaken conditional branch. And eventually, you\\\'re\\ngoing to get a dead tensor into this Merge. It just ignores it and outputs\\nwhatever data tensor it gets. So dead tensors are needed\\nfor distributed Control Flow, which I\\\'m actually not\\ngoing to cover in this talk. Because it\\\'s kind\\nof technical and I haven\\\'t found it that important\\nto know the details of it. It\\\'s covered in Yuan\\\'s paper. But I\\\'m mentioning dead\\ntensors because they do show up a lot in the execution. Like, if you look at\\nthe executor code, there\\\'s all this special\\ncase for dead tensors. This is what they\\\'re about,\\nit\\\'s for conditional execution so we can do distribution. SPEAKER 1: And retval\\nzero doesn\\\'t help any. SKYE WANDERMAN-MILNE: Oh, yeah. And that famous\\nerror message I want to put on a t-shirt, retval\\nzero does not have a value. That means you\\\'re trying\\nto read a dead tensor, or it probably\\nmeans there\\\'s a bug. OK. Moving on to the low-level\\nops we use for while loops. These manage\\niterations, basically. The concept you need to know\\nabout in execution is frames. So you have one\\nframe per execution. And this is what\\nallows the executor to keep track of\\nmultiple iterations, and allows a single op to\\nbe run multiple times as you do multiple iterations. So a frame defines a name, which\\nis for the whole while loop. And then it also has\\nan iteration number. So the Enter op, that just\\nestablishes a new frame. It means we\\\'re starting\\na new while loop. So it just forwards its input. It\\\'s like an identity,\\nexcept that output is now in this new frame. And it has an attribute\\nthat\\\'s the frame name, starts at frame 0. Exit\\\'s the opposite. It just it\\\'s like an\\nidentity, except it strips the frame from its input. So output is now not\\nin that frame anymore. And these can be stacked. So if you have a bunch of\\nEnters on a bunch of frames, you have a bunch of Exits, it\\\'ll\\npop them off one at the time. The Nextiteration\\\'s just\\nthe final piece in order to increment that\\niteration count. This might make more sense\\nwhen we put it all together, so let\\\'s do that. Starting with tf cond again. Let\\\'s just work through this. So down here, you have the\\nAPI call that we\\\'re using. So we start, we\\nhave this predicate. Note that the predicate isn\\\'t\\nactually part of the cond. It happens outside here,\\nbut then we feed it into the Switch operators. So the Switches and\\nMerges mark the boundary of the conditional\\nexecution, remember. So we\\\'ll feed this predicate\\nand then, the true branch is an Add. So we have a Switch\\nfor each input, for x and z, which is\\nthe external tensors we use in that branch. You\\\'ll note that they\\nare only being emitted from the true side of it. So if the false branch is taken,\\nnothing\\\'s connected to that. That comes out of Add, then\\nsimilarly on the other side, we\\\'re Squaring y, so we\\nhave a Switch for the y. This time, it\\\'s going to be\\nemitted from the false branch into the Square. And then, we only\\nhave one output from this cond so we\\nhave a single Merge. Either the Square or the\\nAdd, only one of those is going to actually have data,\\nand that\\\'s what will be output. So note that there is\\na Switch for each input and a Merge for each output,\\nthey don\\\'t have to match. And in this example,\\nthe two branches are using disjoint tensors. But say, we did the\\nSquare of x instead of y, then you would have\\nan edge from both the true output and the\\nfalse output, depending. Go to the Add or the Square. Let\\\'s quickly, actually,\\ngo over the while loop API, just to make\\nsure we all remember. So the first argument,\\nis a function. That\\\'s the predicate function. The second function is the body\\nthat we\\\'re going to execute. And this is where it\\\'s\\nkind of interesting. So you have some inputs, these\\nare called the loop variables, the input to the while loop. And then it\\\'s going to\\noutput updated versions of those same loop variables. So the inputs of the body\\nmatch the outputs of the body. Like, same number-type shape\\nof tensors because they\\\'re just the updated variables. SPEAKER 2: Can\\\'t the\\nshape-type [INAUDIBLE] SKYE WANDERMAN-MILNE: The\\nshape can change, you\\\'re right. Same number and types. And then the final, we\\\'d\\nprovide some initial input to start it off. So that\\\'s the 0,\\nthe final argument. And then the output\\nis going to be whatever the final value\\nof the loop variables are. And then the predicate function\\ntakes those same loop variables as input but just\\noutputs a Boolean, like, do we continue execution or not? So now we\\\'ll start\\nwith the inter-node. This, remember,\\nestablishes the new frame. We\\\'re starting a new while loop. I guess it\\\'s called L for loop. We go through a Merge now,\\nkind of reversed from the cond where you start with the Switch. Now you start with a Merge. Because it\\\'s choosing is\\nthis the initial value or is this the new, updated\\nvalue from an iteration? That feeds into the predicate. Note that the predicate\\nis inside the while loop now because it has to\\nexecute multiple times. The output goes\\ninto the Switch node to choose whether if\\nit\\\'s false, and we\\\'re going to exit the while\\nloop with that exit node. Otherwise, we go into the body,\\nwhich is an Add in this case, take the output of the body,\\nfeed it to the next iteration. Because we have to bump\\nthat frame count, remember? And then feed it\\nback into the Merge, which will forward it\\nback again and again, until we get to the Exit. So, hopefully, this\\nkind of makes sense. You can see there\\\'s\\na loop in there. That\\\'s the while loop. SPEAKER 3: For sequential\\nones, how does the Merge know to select the z or [INAUDIBLE]? Because wouldn\\\'t neither of them\\nbe dead tensors at that point? SKYE WANDERMAN-MILNE: I\\ndon\\\'t know the details of how this is implemented. But I think because\\nthe frame is different, z only is in the first frame. Because each frame\\nis conceptually like you made a\\ncopy of the body, it\\\'s going to keep track\\nof different pending counts for each node in\\nthe body, or the Merge, or the Switch. So I think that\\\'s why. OK. All right, so that\\\'s\\nall I\\\'m going to go over with Control Flow v1. It does have some advantages. It all, kind of,\\nfalls out of the fact that these low-level operators\\nare designed to naturally fit within the dataflow model,\\nbecause data graphs are dataflow graphs. So you get nice\\nfeatures like pruning, works pretty naturally,\\nbecause it\\\'s all regular nodes, sort of, for pruning. You can have parallel execution\\nof while loop iterations, which is actually pretty\\ncool, I think. Because once you add\\nin this frames logic, it kind of naturally keeps\\ntrack of all the pending counts. It runs just like a regular-- like, if you unrolled\\nthe loop and the data will flow through\\nas far as it can. Ops will be executed\\nas soon as they can. It just kind of works. However, there are\\nsome disadvantages. It\\\'s very complicated. Like, you can see that\\nthis is a bunch of nodes to express what in most\\nprogramming languages is like one line, like while. This shows up\\nespecially in gradients and nested Control Flow. You end up with all\\nthese crazy edge cases where you didn\\\'t hook\\nup the inner Merges correctly or whatever. As a result of this complexity,\\nhigher order derivatives are not implemented. This is not like a\\ndesign problem, per se. It\\\'s just it\\\'s so\\ncomplicated and there\\\'s so many edge cases no one\\nhas been able to do it, or has wanted to do it. Similarly to graph\\nconstruction being complicated, the runtime is complicated. Because you have to have\\nall this dead tensor logic, all this firm logic, and\\nit\\\'s very intricately baked into the executor. And this makes it hard\\nto read and maintain, and also, adds\\nperformance overhead. It\\\'s hard for other\\ndownstream things to analyze and make sense of. An example of this\\nis [INAUDIBLE] has been trying to do\\n[? auto ?] clustering for XLA, and so he has like\\nwhole docs written on how to handle dead\\ntensors, because they can show up anywhere. Similarly, XLA actually\\nrepresents Control Flow in a functional way\\nif in while ops. So when they consume\\nTensorFlow graphs, they have to pattern-match\\nthis crazy stuff back into just the while op that\\noriginally produced it. And especially with gradients\\nand nested Control Flow, it gets very complicated. There is a number of edge cases. This was actually one\\nof the main motivations for building Control Flow v2. Because we were fixing\\nso many bugs and how this was represented in so many\\nedge cases, that it\\\'s like, we just need a simpler\\nrepresentation. OK. So, hopefully, this\\nwill be simpler. I can fit it on\\none slide for both. [LAUGHTER] So tf dot cond, it\\\'s\\njust an if op now. You have the Boolean\\npredicate coming in. These arrows represent the\\ntype signature of the op, not individual tensors per se. So then this could be\\nany number and type of tensors coming into input. And then similarly, any number\\nof type tensor is coming out. They don\\\'t have to match. Then these represent,\\nthey\\\'re technically function attributes,\\nbut they\\\'re basically functions attached to this op\\nrepresenting the true branch and the false branch. So they\\\'re like,\\nlittle subgraphs. One thing to note that\\\'s\\nimportant with these functions is that the function\\nsignatures have to match. So the functions have the same\\ninputs and the same outputs. The inputs and\\noutputs don\\\'t have to match, what but they have to\\nmatch across the two branches. SPEAKER 4: [INAUDIBLE]\\nthe type, not values? SKYE WANDERMAN-MILNE: Yes. Sorry. Well, we\\\'re just talking\\nsignatures right now. So just type and possibly\\nshape in some cases. Yeah, it doesn\\\'t even have\\nto be implemented this way, but it is. It makes somethings\\nsimpler to think about. But keep that in mind. Similarly, tf dot while loop\\njust turns into a while op now. Now all our inputs and outputs\\nare just the loop variables. Because, remember, the predicate\\ntakes those loop variables as inputs. So you have a cond function\\nor a predicate function, takes a loop verbals as\\ninput, output, or Bool. And then the body function that\\ntakes the loop variable inputs and outputs, the updated\\nversion, which will eventually be-- the final value will be\\nupdated output from the op. So does this make sense? This picture. SPEAKER 4: One thing to clarify\\nis, in tf cond it doesn\\\'t have, actually, any concept of\\nvariables in the higher level API. So this is things we\\ncapture and we take care of making sure they match. So from the user\\\'s\\npoint of view, they don\\\'t have to\\ndo anything special. SKYE WANDERMAN-MILNE: Right. That\\\'s, kind of, like the\\nwhile op very closely matches the TensorFlow semantics. But the if op is a\\nlittle bit different. They have to match [INAUDIBLE]\\ninputs at all, because we do it through closures and API. That\\\'s like, you do\\nit within your code. So if this is good\\nfor everyone, I\\\'m going to move on to\\ngoing over gradients. I\\\'m going over how gradients\\nwork in Control Flow v2. It is somewhat general. It\\\'s much simpler to think\\nabout with the functional ops. So let\\\'s start at a high level. Just conceptually, what\\nis the gradient of a cond? It\\\'s basically,\\njust another cond. And you take the same\\npredicate, and you take the gradient of both sides. So if we took the\\nforward true branch, then we want to take the\\ngradient of the true branch on the way back. Make sense? Hopefully, this is good. While loops, a little bit\\nmore complicated, not too bad. So say we have this\\nforward while loop, you have your cond\\nand body functions. Just assume it executes end\\ntimes for now, we just know. So now the gradient, we\\nhave to execute the gradient of the body function N times. Like we just have\\nto do the reverse. Imagine an unrolled loop, we\\ndid N invocations of the body. Now we\\\'re going to\\ndo N invocations of the gradient of the body. And you pass in the grad y\\\'s\\nor cotangents or whatever. And those are your\\nloop variables. Then your predicate,\\nnow, is just this counter to make\\nsure we execute N times. So, hopefully, this makes sense. The big question is, how\\ndo we know what N is? The answer is that, at\\nleast in Control Flow v2, we just add a little counter\\nto every a while loop. That just outputs the\\ntotal number of iterations. And we don\\\'t return\\nthis to the user, but we can wire it through to\\nthe gradient when we need it. Does this make sense\\nat a high level? We\\\'re going to dive\\ninto the details. But this is concept. OK. So I\\\'m about to go into\\nmore concrete examples. And I\\\'m also going to\\ndiscuss the tricky part about gradients, which\\nis intermediate values. Basically, when you\\nhave a data dependency from the forward pass\\nto the backwards pass. So start with cond. Here is a similar diagram. I rearranged it to\\nmake it fit nicer. But one important\\nthing to notice is that now the arrows\\nare actual tensors. They\\\'re not just type\\nsignatures anymore. So the predicate is a Boolean. In this example, there\\\'s only\\none input and one output, maybe they\\\'re different\\ntypes, who knows. Doesn\\\'t matter for this example. And then you have the\\ntrue and false functions with the same types. OK. So here\\\'s the gradient function. It\\\'s just another if. This time we\\\'re dealing\\nwith the cotangents instead of the initial forward values. And we have the gradient\\nof the true function and the gradient of\\nthe false function. Looks good so far. Hopefully. If there was no\\ndata dependencies between the forward and backward\\npass, like if you\\\'re doing y equals x plus 1,\\nthis is all you need. But what if somewhere in\\nthe forward pass, let\\\'s say the true function,\\nthere\\\'s an op? And we need to use its\\noutput in the backwards pass? So this is conceptually\\nwhat we need to do. We need z in the\\ngradient function. This is a problem,\\nbecause you can\\\'t just have an edge between two\\nfunction definitions. You need to have\\ninputs and outputs. Like, they need to go-- The If ops need to be attached\\nto each other with an edge. This doesn\\\'t make\\nsense by itself. So we\\\'re, basically,\\ngoing to do just that. We\\\'re going to make\\ninputs and outputs. We\\\'re going to add\\nthem to the if op. So let\\\'s do that. So we\\\'re going to output\\nz from true function. And then similarly,\\nadd it as an output from the if op, because the if\\nop is calling true function. And then we\\\'re going to add\\nit as an input to the gradient if op. And add it as an input to\\nthe gradient true function. OK, there\\\'s still\\none problem, though. And that\\\'s that now the true\\nand false branches of both if op don\\\'t match anymore. We need them to have\\nthe same signature. So let\\\'s just add some\\ninputs and outputs. Starting on the gradient\\nside, this is fine. We can just add z as an\\ninput to the false function. It\\\'s just going to ignore\\nit, it\\\'s an unused input. But on the forward\\npass, this is a problem. Because we need to add z as an\\noutput to the false function, but we don\\\'t actually\\nhave anything to output. It\\\'s like, what is\\nthis question mark op? And it needs to be the same\\ntype, and possibly shape, if we want to keep a strong\\nshape, or a fully known shape. And we might not know\\nthe shape until runtime. So what we do? I had to think about\\nthis for a long time and came up with many\\ndifferent solutions. And I partially\\nimplemented all of them before coming up\\nwith using Optionals. Optionals are maybe types. You\\\'ve heard of that? It\\\'s a special\\nkind of tensor that can hold another tensor\\ninside of it or not. So it\\\'s just a wrapper that may\\nor may not have another tensor inside of it. And it\\\'s also a tensor. It\\\'s like a variant tensor. So the true function is\\ngoing to return an Optional with the z value inside of it. The false function is\\ngoing to return an Optional with no value inside of it. OK, great. Now they\\\'re the\\nsame type, Optional. Could have the same\\nthing inside them. In a gradient true\\nfunction, we can unwrap that Optional\\nto get the raw z value. And then the false\\nfunction still just ignores it, which\\nis great, because there\\\'s nothing inside of it. I didn\\\'t know how to draw\\nthis, but that\\\'s what we do. So all the intermediate\\nvalues that are needed by the\\ngrading computation are added as Optional\\noutputs of the forward pass. Does this make\\nsense to everyone? That\\\'s it for cond gradients. SPEAKER 3: Conceptually, what\\\'s\\nthe difference between doing this and the dead tensor stuff? SKYE WANDERMAN-MILNE: Oh. Yeah. Great question. I meant to go over that,\\nso thank you for asking. At a high level,\\nthis is just how it works in Control Flow v1. The gradient if cond\\nis another cond. You can express that\\ninto low-level ops. But the dead tensors\\nare the big difference. So v1 was, kind of, using dead\\ntensors instead of Optionals. And you would just\\nhave that edge because there\\\'s no\\nfunctions [INAUDIBLE].. You could just draw\\nthat edge between the forward and backward pass. And if it\\\'s the\\nuntaken branch, you\\\'ll have a dead tensor\\nflowing across that edge. There\\\'s none of this\\nmatching business, you just draw the edge. SPEAKER 3: The interesting\\nthing with the Optional is that it tells you in the type\\nof it that it might be that. Where in the dead tensor you\\nhad no such information around. SKYE WANDERMAN-MILNE: Right. SPEAKER 3: So someone\\nlike [INAUDIBLE] doesn\\\'t have to spend as much\\ntime reverse engineering. [INAUDIBLE] exactly what it was\\nmeant to do complicated cases. So now what tensors\\nmight be dead or not? SPEAKER 3: So this\\nis, essentially, a much more explicit way\\nof making it clear what it be done versus what might now. SKYE WANDERMAN-MILNE: It\\\'s\\nkind of like, more complicated. Like, this was actually\\nsimpler in Control Flow v2, because you\\\'re just\\nlike, draw the edge, and the executor will take care\\nof all this dead tensor stuff. Yeah, it made the whole system\\nmore complicated as a whole to support that. OK, so let\\\'s move on\\nto while gradients. So again, we\\\'re dealing,\\nnow, with concrete tensors. So input x, output y. They have the same type but\\nthey are different values. The body function--\\nnote that I used xi because it\\\'s run multiple times. And each time it\\ntakes, it might be x or it might be an\\nintermediate value and outputs the updated\\nvalue of y of i. Then I drew the\\ncond function small. And I didn\\\'t draw as\\ninputs and outputs, because they don\\\'t really matter\\nthat much for the gradient, but they\\\'re there. It does have them. So same thing for the gradient. Very similar to the\\ncond case, now we\\\'re dealing with the cotangents. Hoping this makes sense. We took the gradient of the\\nbody and we\\\'re running N times. I forgot to draw N,\\ntoo, but it\\\'s there. Same scenario. Oh, no. What are we going to do? We can\\\'t just draw this edge\\nbetween the two function definitions. So this time, we don\\\'t have to\\nworry about the matching thing anymore. Thank goodness. We\\\'ll add the input\\nto the grad body function and the\\ngrad cond function, but that\\\'s fine because\\nwe can ignore inputs. But we have a new problem,\\nwhich is that there\\\'s actually multiple values of z. Because the body\\nfunction is going to execute multiple times,\\nthere\\\'s no guarantee that this op that\\noutputs z is going to output the same value\\non every iteration. So we actually have to\\noutput all the values of z from the forward\\npass, and we don\\\'t know how many that\\nwill be until we run it and take them as input\\nto the gradient function. So we use stacks,\\notherwise known as accumulators in\\nthe code sometimes. So we\\\'re going to\\nstart with an empty-- we use tensor lists, which are\\nkind of like tensor arrays, but not stateful. You can see in these\\nlittle function signatures, we\\\'re going to start\\nwith an empty tensor list that we pass through the while. And then in the\\nforward pass, we\\\'re going to push values onto\\nthat stack, or that list. And since it\\\'s stateless,\\nyou take the list in as input and the value\\nyou want to add to it and it, conceptually, returns\\nyou a new list that has that new element added to it. Under the hood it\\ndoesn\\\'t actually have to make all\\nthese copies, I hope. Similarly in the backwards. So then we\\\'re going to\\nkeep pushing values, outputting these new lists,\\nand keep pushing to them until we get the full list\\nwith all the values in it. That\\\'s output from\\nthe while loop. Actually, I have a\\npicture for this. So I guess the point is\\nthat, in the backwards pass you just pop,\\nopposite of push, to get the value out again. And so, this is a\\nlittle bit complicated. But you start with the\\nempty list as input, now these lists are\\nactually loop variables. So the stateless tensor list\\nworks quite nicely with this, because the loop\\nvariable is going to have whatever has accumulated\\nso far as input to the body function. And it adds the\\nnew z and outputs that as the updated version. And so the final\\nlist is going to be the full list, which you pass\\ninto the gradient function. It\\\'s going to do the same\\nthing, except popping to pass, to get that raw value of z. And then finally, the list\\nshould be empty at the end. And then, since it\\\'s\\na loop variable, we end up outputting\\nan empty list, but we don\\\'t actually\\nneed that output. That\\\'s just how it works. SPEAKER 2: I have a question. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 2: Are you saying\\nthe gradient values always [INAUDIBLE]? SKYE WANDERMAN-MILNE: It\\\'s only\\nwhen you when you need them. SPEAKER 2: It\\\'s just\\nalways [INAUDIBLE].. OK. Thank you. SKYE WANDERMAN-MILNE: Yeah. That\\\'s a good question. SPEAKER 4: Now you\\ncould [INAUDIBLE] in the normal TensorFlow\\ngraph probably is able to remove them. SKYE WANDERMAN-MILNE:\\nYeah, that\\\'s the way it actually used to do. Although, that\\\'s a little\\nweird through functions so we changed it. SPEAKER 3: Another question. Does this imply that\\nin your while loop, your memory consumption\\nis, basically, linear in the number of\\nvariations you go through? SKYE WANDERMAN-MILNE: Yeah, if\\nyou have a gradient like this. That\\\'s some future work. I would love to see\\ndoing re-materialization, or check-pointing, I think\\nit\\\'s called in the literature. But we don\\\'t do that. SPEAKER 2: Can explain\\nagain, in the if, why can\\\'t you draw a line\\njust from the original-- SKYE WANDERMAN-MILNE: Oh, yeah. The blue boxes are\\nfunction definition. And then the while op is\\ngoing to call that function many times. So it\\\'s sort of like, if you\\\'re\\nwriting two functions in Python and they\\\'re not\\nnested or anything, they\\\'re just side by side. You can\\\'t take an intermediate\\nvariable from one function and use it in another one. It\\\'s going to be like, I\\ndon\\\'t know what this is. You have to output\\nit then have it as input to the other function. Or at least in TensorFlow we\\ndon\\\'t have closures or anything fancy like that. So that\\\'s how we do it. Does that make sense? SPEAKER 2: Kind of. SPEAKER 3: The value for\\na particular execution of a function of particular\\nintermediate value of a particular\\nfunction execution doesn\\\'t have a name that\\ncan be addressed in order-- And if it had a name,\\nit would greatly complicate the lifetime issues. We wouldn\\\'t be\\nable to [INAUDIBLE] intermediate\\n[INAUDIBLE] functions. SKYE WANDERMAN-MILNE:\\nOr maybe another way is that these\\nfunction definitions aren\\\'t actually in the graph. I draw them as if they are,\\nbut they\\\'re off to the side. All you see are the while ops. And then when you call the\\nfunction, then you see that. But you only see\\nit for that call. So it\\\'s like this z op in\\nhere doesn\\\'t exist out here in the main graph where this\\ngradient while op can see it, or in this other\\nfunction definition. Oh, and to compare to\\nControl Flow v1 again, same general idea. These while ops could be the\\nwhole mess of low-level ops and, due to some true while\\nloops, represent it that way. The big difference, this\\ntime, is in the stacks. They use the old resource\\nback tensor arrays, which were stateful. SPEAKER 4: We actually use the\\nresource [INAUDIBLE] stack. SKYE WANDERMAN-MILNE:\\nOh, you\\\'re right. You\\\'re right. SPEAKER 4: Separate nests. SKYE WANDERMAN-MILNE: OK, yeah. But they were\\nstateful, is the point. So they were\\nactually just inputs. They weren\\\'t outputs. And you just modify that state. One big disadvantage of\\nthis was that you couldn\\\'t take higher-order derivatives\\nbecause you would exhaust the stack once,\\nand it\\\'s stateful and you can\\\'t get\\nit back anymore. Whereas these, it\\\'s\\nthis full list. Because it\\\'s a\\nstateless thing, I can pass it to another\\nwhile op, no problem. So coming back to\\nControl Flow v2. Let\\\'s recap what\\\'s\\ngood and bad about it. So now we can take\\nhigher-order derivatives because it\\\'s very simple. The gradient code, when\\nit\\\'s looking at an if op, it doesn\\\'t know if\\nthat if op was actually the first derivative\\nof some other if op. They\\\'re are all the same. Inputs and outputs\\njust are normal. It\\\'s much easier to\\nconvert to the XLA if and while ops and\\ndownstream TPU integration. Graph construction\\nlogic, I hope is simpler. Take a look for yourself. So besides being\\neasier to maintain, this lets us give\\nbetter error messages, and hopefully there\\\'ll\\nbe fewer bugs. OK. So now assuming that we\\njust run the functional ops, even though I said\\nwe don\\\'t, assume we do. The execution could\\nbe much simpler, because we don\\\'t\\nhave dead tensors or because we use Optionals now. And we don\\\'t have frames because\\nit\\\'s managed by the while op. But the disadvantage\\nof running these ops is that they aren\\\'t as\\nperformant for a number of reasons listed there. So we could fix this\\nwith the functional ops. And it would make sense to do\\nthis because a lot of these also apply to just regular\\nfunction calls, which are kind of a big deal now. But for now, we decided to\\njust take the functional op. So right before you run it--\\nso you\\\'ve already constructed the graph, you\\\'re\\nready to run it-- we\\\'re going to convert it\\nback into the old low-level representation. So now we get rid\\nof the disadvantages because we\\\'re, hopefully,\\njust running the same thing. But we also don\\\'t get our\\nsimpler execution because we\\\'re still running the old thing. So we call this\\nlowering, because they\\\'re sort of lowering to this\\nmore low-level form. This was, basically,\\na staging trick so that we can do all the\\ngraph construction stuff, which is taking quite some time,\\nwithout having to worry about the execution as much. Because there were\\nstill some issues. It\\\'s very similar to\\nfunction in-lining. An if op and a while op are kind\\nof very fancy function calls. And so this is how\\nyou in-line them, with these low-level\\nlevel dataflow operators. And so it runs with in-lining\\nbefore anything else happens, and this is so we\\ncan take advantage of any downstream optimization\\nor placement or whatever. In the case of\\nControl Flow, we want it to work the same as it did\\nbefore in Control Flow v1. And I think Eugene is\\nfixing this all up, so this is actually true now. As of, like, last week. SPEAKER 5: So this converting\\nwill be removed eventually? SKYE WANDERMAN-MILNE: I\\nwould love to see it removed. Oh, yeah. So right now we\\nin-line everything, including function calls,\\nbecause similar story for functions, it makes\\na lot of things easier. I hope that we don\\\'t\\ndepend on this forever. That we sort of\\ndo try to make it so function calls are just\\nas performant and as good not in-line. Because it\\\'s the same\\nfor Control Flow. If we always assume\\neverything\\\'s in-line, then we\\\'re never going\\nto be able to get our simpler execution and\\njust run the functional ops. Because they\\\'re very, very\\nsimilar function calls, they have the same problems. So if you fix it\\nfor functions it\\\'s not a huge step to, then,\\nfix it for Control Flow. Where are we at with\\nControl Flow v2? It\\\'s still under development. There\\\'s bugs and features\\nthat need to be implemented. But it\\\'s basically on in tf 2.0,\\nif you\\\'re using pure 2.0 code. So remember Eager, doing his\\nown thing, just use Python. And then, Control Flow v2 is\\nalways on in tf dot functions. There\\\'s no way to\\nget old Control Flow. If you want to run new Control\\nFlow in either 1.x code or you\\\'re using a\\ncompact dot v1 dot graph, those still use the\\nold Control Flow, you can use this environment\\nvariable to turn it on. So now when people ping\\nme in and are like, I have this horrible\\nControl Flow bug. I\\\'m like, try the\\nenvironment variable. And sometimes it fixes it. Or sometimes it at least\\ngives an easier to debug error message. Unfortunately, I\\nwould love to have realized the glorious future,\\nwhere it\\\'s all new Control Flow. Old Control Flow doesn\\\'t exist. We can delete that code. I don\\\'t know if it makes\\nsense to do the work to make it so we can\\nturn it on in 1.x code because there\\\'s a\\nfew big blockers. Namely, functions don\\\'t\\nwork with ref variables. And so by extension,\\nthese functional ops don\\\'t work with ref variables. That would be a lot\\nof work to implement. And the question that you asked\\nabout how we add the gradient outputs when you\\nrequest a gradient, only when they\\\'re needed,\\nwhich it will only know after you build\\nthe gradient graph and see what incoming\\nedges you have. This actually breaks sessions. Sessions do not like it when you\\nadd inputs and outputs to ops. And will potentially make\\nyour session unusable. You\\\'ll have to\\nmake a new session. So in 2.0 we don\\\'t\\nhave sessions, great. But in 1.x we definitely\\nhave sessions. Another little note. In addition to Control\\nFlow V2, there\\\'s a new effort to\\nre-implement tensor arrays. And I sort of hinted\\nat this by incorrectly stating the old tensor array as\\nstacks but it\\\'s the same idea. Tensor arrays were these\\nresource back stateful things. Now we\\\'re going to\\nmake tensor arrays. It\\\'s still the same\\nAPI, so nothing should change for the\\nuser, but under the hood, we\\\'re going to use immutable\\ntensor lists, which are variants instead of resources. And so you get\\nhigher-order derivatives, it\\\'s easier to reason\\nabout something that\\\'s dataflow style instead\\nof stateful in our dataflow graphs. It\\\'s nicer. And then in particular, an\\narea of active development is that we do need to make these\\nnew tensor arrays work in XLA. So this is kind of annoying,\\nbecause we\\\'ve kept saying, oh, the new Control\\nFlow [INAUDIBLE],, it\\\'s going to make XLA so easy. It\\\'s just going to work. But we do have to\\nimplement this one thing. [? Sarab\\\'s ?] working on this. I think it\\\'s almost there. We\\\'ll see. SPEAKER 4: Getting there. Question. So is it true that\\nTensorFlow [INAUDIBLE] where you only use\\nthe [INAUDIBLE]?? SKYE WANDERMAN-MILNE: Yes. Yeah, so it\\\'s\\nmaybe theoretically different from Control Flow,\\nbecause it\\\'s tensor arrays. But tensor arrays are so\\ntightly linked to Control Flow. And we only support\\nthe new tensor arrays in new Control Flow\\nbecause we don\\\'t want to deal with\\nthe stateful thing. SPEAKER 2: You don\\\'t know\\nwhat tensor array is. Usually when you do\\nControl Flow and it models, you have something like an\\nRNN, that computes something for [INAUDIBLE]. And you often want to\\ntake a single tensor that represents the results of\\nall time steps together. And tensor array is\\nthe data structure that lets you do that. SKYE WANDERMAN-MILNE: Yeah. I don\\\'t think there\\\'s too\\nmuch use for tensor array outside of while loops,\\nI\\\'m sure I would stand corrected if I looked into it. So these are some details\\non what\\\'s going on here. That\\\'s all I have. I\\\'m going to end on\\nthis slide so you can look at the beautiful picture. And I guess we have plenty\\nof time for questions. So what was your Control\\nFlow v1 question? SPEAKER 3: How does it work\\nwith the branches [INAUDIBLE]?? SKYE WANDERMAN-MILNE:\\nOh, good question. So this is when you\\nhave a tf dot cond, remember just takes lambdas and\\ncaptures everything by closure. So you could just not\\nclose over anything. Like, return one or two. SPEAKER 1: Or like, it\\\'s a\\nsourceless op like [INAUDIBLE].. SKYE WANDERMAN-MILNE: Yeah. It uses the predicate. It wires together all the\\ndataflow using the predicate. And in particular,\\nyou can also have a cond that doesn\\\'t\\nreturn anything, it just has side effects. And I think in\\nControl Flow v1, it will return to predicate value. I thinl it does that\\nin Control Flow v2 because I wanted to test\\nthe pass in both cases. But it\\\'s a little arbitrary. SPEAKER 4: So the\\nway to do this is you have ops that have a control\\ndependency on something that depends on the Switch. Because [INAUDIBLE] propagates\\nthrough [INAUDIBLE] as well. So this is how it\\\'s actually\\nimplemented in Control Flow v1. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 1: Well, it can\\\'t\\ndepend on the Switch. It has to depend\\non like one output. SPEAKER 4: Yeah. So you have a Switch\\nof the predicate. And on each side\\nof that [INAUDIBLE] that takes the predicate twice. Then you have an identity\\nop on each branch. And every op that\\\'s inside\\none of the Switch branches has a control dependency on\\nthat corresponding identity. So because, then, this\\npropagates through control edges, it makes things work. SPEAKER 1: That makes sense. SKYE WANDERMAN-MILNE: That\\\'s a\\npart of why we were able to do [INAUDIBLE]. There\\\'s a lot of storage. Yeah? SPEAKER 2: So when you\\ndescribed the graph modification for taking gradients of if, when\\ndoes this modification happen? Does it happen when\\nyou construct the if op or when you\\\'re taking gradients? SKYE WANDERMAN-MILNE:\\nGreat question. It happens when you\\ntake the gradient. SPEAKER 2: The gradient. So for those-- SPEAKER 3: Does that depend\\non whether you\\\'re using tape gradients or tf dot gradients? SKYE WANDERMAN-MILNE: No. SPEAKER 2: We could\\n[INAUDIBLE] early if you\\\'re doing tape gradients. We currently do not. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 4: So that means for\\nthose function arguments, or functional attributes, you\\ncannot draw lines between two, but you can modify one. SKYE WANDERMAN-MILNE:\\nYeah, you can modify them to add\\ninputs and outputs, which you\\\'re not really supposed\\nto do with sessions. But we do it. The reason we do it when you\\nrequest a gradient is that, a, if you never take\\nthe gradient we don\\\'t want to add extra stuff,\\nalthough it could get pruned. SPEAKER 4: You want\\nto look [INAUDIBLE].. SKYE WANDERMAN-MILNE: It makes\\nyour graph look nice at least, to not have all\\nthe extra outputs. And also, you don\\\'t\\nknow which intermediates you\\\'re going to need until\\nyou build the gradient graph. So if we did it\\nwith the tape, we could say, oh,\\npresumably because you\\\'re running with a\\ntape, you are going to want to take the\\ngradient at some point. SPEAKER 4: We can\\nactually ask the tape if the tape is\\ngoing to integrate into one of those outputs. We can\\\'t answer their questions. SKYE WANDERMAN-MILNE: So\\nthen we could proactively create the gradient\\nat the same time as you create the forward pass\\nand add the outputs there, all at once. But since we have\\nthe two code pass, we just do it the same\\nin a two code pass. Because with tf\\ndoc gradients, you have no idea if\\nyou\\\'re gonna call it or not until it happens. That\\\'s a good question. Functions work the same\\nway too, because they have like a similar-- if you just have\\na function call, you\\\'ll have the same\\nthing with intermediates and you\\\'ll have to add\\ninputs and outputs. So we\\\'re back in\\nControl Flow v1, right? This is what it looks\\nlike, this stuff. What if you want to run your\\nbranch functions or your body or whatever on multiple devices? So I don\\\'t totally\\nunderstand this myself. It\\\'s going to be brief. Cond, it\\\'s pretty simple. You just do it like\\nnormal, I guess. You add the sends and\\nreceives, dead tensors can flow through these. So this is why you\\nneed the dead tensors. Because for the untaken\\nbranch, you basically need to tell other\\ndevice, this isn\\\'t taken. Stop waiting for inputs on this. So you can shut\\ndown or whatever. SPEAKER 4: Another,\\nwe could have chosen to send the predicate instead. But was a simple modification\\nof the existing TensorFlow that had a huge cost. If I had chosen to\\nsend the predicate, we wouldn\\\'t need so much of\\nthat tensor propagation and all the bugs associated with it. SKYE WANDERMAN-MILNE: Dead\\ntensors are kind of crazy. In really big graphs, you will\\nspend time just propagating all the dead tensors, and\\nsend data across the network, or whatever. It\\\'s one of those things. We added all this\\nstuff and now this is very conceptually simple. You just add the\\nsend and receive. It just works. Can we do the same\\nthing for while loops? Just add the sends and receives. This time it\\\'s going\\nto be in a loop. Seems fine. It\\\'s not fine. The problem is that\\nthis device doesn\\\'t know that this op is supposed\\nto be run multiple times. I guess we didn\\\'t forward\\nthe frame information. SPEAKER 3: It doesn\\\'t know\\nhow many times it should run. SKYE WANDERMAN-MILNE:\\nWell, it\\\'s going to run once or like 0\\ntimes, then you\\\'ll have-- or maybe the dead\\ntensor will work. But if you run it\\nonce, it\\\'s just going to immediately shut down\\nbecause it thinks that it has to run once, like a regular op. So the solution, you, basically,\\nbuild a tiny little while loop on the other device. And so you can see\\nthere\\\'s no real data going through this computation. But it\\\'s just used through\\ncarefully placed control dependencies to drive this\\nop as many times as you need. So this is like a whole\\nlittle while loop built just to run this op n times. This while loop is indirectly\\ndriven by the real one. SPEAKER 3: It\\\'s driven\\nby the predicate. SKYE WANDERMAN-MILNE: Yeah. Right, exactly. You can see that this guy\\ndoes not have a predicate. SPEAKER 4: So we\\\'re essentially\\nsending the predicate around for the while loop case but\\nnot doing it for the cond case. SKYE WANDERMAN-MILNE: And we\\nbuild a little tiny while loop to actually use that predicate. SPEAKER 4: And essentially, if\\nwe wanted to partition into two ops, we would have\\nto build something like this for both the\\ncond and [INAUDIBLE].. Or it would at least\\nlook simpler, I think. SPEAKER 1: Well, the control\\ncould be centralized. SPEAKER 4: Well, you\\ncould send the predicate to other places, yes. SPEAKER 1: [INAUDIBLE]\\nexecution, yeah. SKYE WANDERMAN-MILNE: Yeah. SPEAKER 4: You would need a\\nwhile loop [INAUDIBLE] device, but the predicate computation\\nonly needs to happen once. SKYE WANDERMAN-MILNE: Do we? Because we have\\nmulti-device functions, you could just call that\\nmultiple times, right? SPEAKER 4: Yeah. I mean, sure. SKYE WANDERMAN-MILNE: You won\\\'t\\nget like parallel iterations and everything. So that\\\'s distribution. SPEAKER 6: I\\\'m glad\\nyou speak clear. SPEAKER 3: How did the\\nintermediate value sharing work with distribution [INAUDIBLE]? SPEAKER 1: It\\nworks the same way, except there\\\'s a\\nlot more arrows. [LAUGHTER] Conceptually, they do not\\ninterfere with [INAUDIBLE].. But you end up with the diagram\\nto show both at the same time would be overwhelming. SKYE WANDERMAN-MILNE: Yeah,\\nthat\\\'s a good point, though. I feel like it\\\'s not\\nimmediately obvious that it works with all\\nthe dead tensors and stuff between the forward\\nand backwards pass. Because now you\\\'re like\\nmixing [INAUDIBLE].. But it does somehow work. SPEAKER 4: You need to\\nthink of the intermediates as happening before you\\ndo the partitioning, and then you can see\\nwhat should happen. SKYE WANDERMAN-MILNE: I\\\'ll\\ngo back to my pretty picture. Well, thanks, everyone. SPEAKER 6: Thank you. [APPLAUSE]\', metadata={\'source\': \'IzKXEbpT9Lg\'})]""""""']","{'https://stackoverflow.com/questions/53079436/tensorflow-tf-cond-giving-unexpected-output', 'https://stackoverflow.com/questions/37063952/confused-by-the-behavior-of-tf-cond', 'https://stackoverflow.com/questions/60307584/generating-random-integers-in-tensorflow', 'https://stackoverflow.com/questions/68444180/tf-case-and-tf-cond-executes-all-the-functions-within-in-tensorflow'}","['""""""Share Your Experience: `tf.case` and `tf.cond` executes all the functions within in TensorFlow\n\nAsked 2 years, 10 months ago\n\nModified 2 years, 10 months ago\n\nI\'m trying to execute some condition-dependent functions where each function needs to contract tensors differently depending on their shapes, for instance. However, I realised that tf.cond and tf.case is executing all functions regardless of the condition. Prepared the following code as an example;\n\ndef a(): print(""a"") return tf.constant(2) def b(): print(""b"") return tf.constant(3) def c(): print(""c"") return tf.constant(4) def d(): print(""default"") return tf.constant(1) x = tf.constant(1) @tf.function def f(): return tf.case([ (tf.equal(x,1), a), (tf.equal(x,2), b), (tf.equal(x,2), c) ], default=d, exclusive=True) @tf.function def f1(): def cond3(): return tf.cond(tf.equal(x,2), c, d) def cond2(): return tf.cond(tf.equal(x,2), b, cond3) return tf.cond(tf.equal(x,1), a, cond2) print(f()) print(f1()) # Output: # a # b # c # default # tf.Tensor(2, shape=(), dtype=int32) # a # b # c # default # tf.Tensor(2, shape=(), dtype=int32)\n\nas you can see for both of the cases, the result is as expected but each function is executed while reaching the conclusion. Hence in my particular case, since I\'m doing different calculations depending on the tensor\'s shape, I get a multitude of errors. I\'ve seen many such bug reports but haven\'t found a solution. Is there another way to do conditional execution that I\'m not aware of where different functions can be executed depending on the condition? Note that I tried simply using if tf.equal(x,2): ... but in that case, I\'m getting an error saying that tensor output can not be used as python boolean. Note that this example is much-simplified version of my problem, my conditions are based on tensor shapes such as tf.equal(tf.size(tensor), N) so I really need a way to execute different things for different cases. After @LaplaceRicky \'s answer I realised that the code that I provided was not representative enough so I\'m providing a better example showing what I need to do;\n\nx = tf.ones((3,2,1)) y = tf.ones((1,2,3)) z = tf.ones((4,3,5)) k = tf.ones((3,5,5)) def a(t): def exe(): return tf.einsum(""ijk,lmi"", t, y) return exe def b(t): def exe(): return tf.einsum(""ijk,ljm"", t, z) return exe def d(t): def exe(): return tf.einsum(""ijk,klm"", t, z) return exe c = tf.constant(1) @tf.function def f(t): y = tf.case([ (tf.equal(tf.shape(t)[0], 3), a(t)), (tf.equal(tf.shape(t)[1], 3), b(t)), ], default=d, exclusive=True) return y print(f(x))\n\nThis function will execute properly without tf.function decorator leading to\n\ntf.Tensor( [[[[3. 3.]]] [[[3. 3.]]]], shape=(2, 1, 1, 2), dtype=float32\n\nHowever, when the decorator is included I got a ValueError which shows that all the cases are executed. TensorFlow version: 2.4.1\n\nPython version: 3.8.2\n\nShort answer: use tf.print instead of print to check whether a particular branch is really being executed in tensorflow graph mode. Explanations: print does not work and won\'t print in graph mode but it will print during tracing. The printed messages actually implies all of the branches were added to the tensorflow graph but it does not imply all branches will be executed all the time in graph mode. tf.print should be used instead for the debugging. For more information: https://www.tensorflow.org/guide/function#conditionals\n\ndef a(): tf.print(\'a\') return tf.constant(10) def b(): tf.print(\'b\') return tf.constant(11) def c(): tf.print(\'c\') return tf.constant(12) @tf.function def cond_fn(x): return tf.switch_case(x, {0:a,1:b}, default=c) print(cond_fn(tf.constant(0))) print(cond_fn(tf.constant(1))) print(cond_fn(tf.constant(2)))\n\na tf.Tensor(10, shape=(), dtype=int32) b tf.Tensor(11, shape=(), dtype=int32) c tf.Tensor(12, shape=(), dtype=int32)\n\nThe ValueError error message is because tensorflow graph does not support this kind of feature very well, at least not with tf.einsum. One way of the workarounds is to have a graph that supports variable-shaped inputs by using tf.function(f).get_concrete_function(tf.TensorSpec(shape=[None,None,None])). Besides, tf.einsum is problematic in the process and have to be replaced by tf.transpose and tf.tensordot. x = tf.random.normal((3,2,1)) y = tf.random.normal((1,2,3)) z = tf.random.normal((4,3,5)) k = tf.random.normal((3,5,5)) #for checking the values def f2(t): p = tf.case([ (tf.equal(tf.shape(t)[0], 3), lambda:tf.einsum(""ijk,lmi"", t, y)), (tf.equal(tf.shape(t)[1], 3), lambda:tf.einsum(""ijk,ljm"", t, z)), ], default=lambda:tf.einsum(""ijk,klm"", t, k), exclusive=True) return p #work around def f(t): if tf.shape(t)[0] == 3: tf.print(\'branch a executed\') return tf.tensordot(tf.transpose(t,[1,2,0]), tf.transpose(y,[2,0,1]),1) elif tf.shape(t)[1] == 3: tf.print(\'branch b executed\') return tf.tensordot(tf.transpose(t,[0,2,1]), tf.transpose(z,[1,0,2]),1) else: tf.print(\'branch c executed\') return tf.tensordot(t, k,1) graph_f=tf.function(f).get_concrete_function(tf.TensorSpec(shape=[None,None,None])) print(np.allclose(graph_f(x),f2(x))) print(np.allclose(graph_f(y),f2(y))) print(np.allclose(graph_f(z),f2(z)))\n\nbranch a executed True branch c executed True branch b executed True\n\nLaplace RickyLaplace Ricky\n\n1,4\n\nSorry, you are correct I didn\'t provide a proper example, thanks for your answer. I updated the code that I provided which I believe exemplifies my situation better.""""""', '""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Share Your Experience: Confused by the behavior of `tf.cond`\n\nModified 2 years, 9 months ago\n\nI need a conditional control flow in my graph. If pred is True, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:\n\npred = tf.constant(True) x = tf.Variable([1]) assign_x_2 = tf.assign(x, [2]) def update_x_2(): with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nHowever, I find that both pred=True and pred=False lead to the same result y=[2], which means the assign op is also called when update_x_2 is not selected by tf.cond. How to explain this?""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\ntensorflow Tf.cond giving unexpected output\n\nAsked 5 years, 8 months ago\n\nModified 5 years, 8 months ago\n\nI seem to be having a misunderstanding on how tf.cond works. In the tensorflow documentation, it gives the following example:\n\nz = tf.multiply(a, b) result = tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))\n\nThe result of the example, if x<y is True is tf.add(x,z) else tf.square(y)\n\nFollowing this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation. in my example, deterministic_action = 4, random_action = 11, chose_random=False.""""""', '""""""And how to solve this problem? TL;DR: If you want tf.cond() to perform a side effect (like an assignment) in one of the branches, you must create the op that performs the side effect inside the function that you pass to tf.cond(). The behavior of tf.cond() is a little unintuitive. Because execution in a TensorFlow graph flows forward through the graph, all operations that you refer to in either branch must execute before the conditional is evaluated. This means that both the true and the false branches receive a control dependency on the tf.assign() op, and so y always gets set to 2, even if pred is False. The solution is to create the tf.assign() op inside the function that defines the true branch. For example, you could structure your code as follows:\n\npred = tf.placeholder(tf.bool, shape=[]) x = tf.Variable([1]) def update_x_2(): with tf.control_dependencies([tf.assign(x, [2])]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval(feed_dict={pred: False})) # ==> [1] print(y.eval(feed_dict={pred: True})) # ==> [2]\n\n\n\n 4\n\nYeah, that\'s the one that confuses me also. My understand is that before executing tf.cond, the runtime makes sure all the dependencies are executed. Dependencies of ops in True and False branches are also dependencies of cond, so even though an op in a branch may never be executed, all of it\'s dependencies are executed, does that that sound right? â€“ Yaroslav Bulatov May 6, 2016 at 18:12\n\nYep - the graph pruning considers all potential dependencies (of either branch) for execution, and only inhibits their execution if they were defined inside one of the branches, because the CondContext adds a control dependency on the pivot and that dependency will be a dead tensor (preventing the op from executing) if it is in the branch not taken. What was the reasoning doing it this way? Why not prune the subgraph behind the non-active branch? â€“ Lenar Hoyt Jul 1, 2017 at 16:15\n\n@LenarHoyt: The pruning happens before the value for pred has been computed. This enables TensorFlow to cache a single pruned graph based on a simple key (essentially the arguments to Session.run()), and makes the implementation of conditional execution simple and lightweight. The same mechanism is used to implement tf.while_loop(), where the advantages of performing the control flow at this level are more evident. pred = tf.constant(False) x = tf.Variable([1]) def update_x_2(): assign_x_2 = tf.assign(x, [2]) with tf.control_dependencies([assign_x_2]): return tf.identity(x) y = tf.cond(pred, update_x_2, lambda: tf.identity(x)) with tf.Session() as session: session.run(tf.initialize_all_variables()) print(y.eval())\n\nThis will get the result of [1]. This answer is quite the same as the above answer.""""""', '""""""Where did the value 1 come from? #!/usr/bin/env python3 import tensorflow as tf import numpy as np with tf.Graph().as_default(): with tf.device(\'/cpu:0\'): stochastic_ph = tf.placeholder(tf.bool, (), name=""stochastic"") eps = tf.get_variable(""eps"", (), initializer=tf.constant_initializer(0)) with tf.variable_scope(\'test_cond\') as sc: deterministic_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=0) # 4 random_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=1) # 11 chose_random = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32) < eps # False because eps = 0 stochastic_action = tf.cond(chose_random, lambda: random_action, lambda: deterministic_action) # S_action should be 4 but it is 1 #output_action = tf.cond(stochastic_ph, lambda: stochastic_action, lambda: deterministic_action) init = tf.global_variables_initializer() sess = tf.Session() sess.run(init, feed_dict={stochastic_ph: True}) print (""s_ph = "", stochastic_ph) d_action = sess.run(deterministic_action) print (""det_action= "", d_action) r_action = sess.run(random_action) print (""rand_action= "", r_action) e = sess.run(eps) c_action = sess.run(chose_random) print (""chose_rand= "", c_action) s_action = sess.run(stochastic_action) print (""s_action= "", s_action) #output = sess.run(output_action)\n\npython random_vec.py 2018-10-31 09:46:15.028376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA s_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 rand_action= 11 chose_rand= False s_action= 1\n\n\n\nThis is because you are evaluating again in a new sess.run. Since you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1. Here is the result of your code, when I extract the value of deterministic_action as well in the last step. print (""s_ph = "", stochastic_ph) d_action = sess.run(deterministic_action) print (""det_action= "", d_action) r_action = sess.run(random_action) print (""rand_action= "", r_action) e = sess.run(eps) c_action = sess.run(chose_random) print (""chose_rand= "", c_action) s_action, d_action = sess.run([stochastic_action, deterministic_action]) print (""s_action= "", s_action) print (""det_action= "", d_action)\n\ns_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 rand_action= 11 chose_rand= False s_action= 1 det_action= 1\n\nNow all you need to do is run everything in one sess.run\n\nd_action, r_action, e, c_action, s_action = sess.run([deterministic_action, random_action, eps, chose_random, stochastic_action]) print (""det_action= "", d_action) print (""rand_action= "", r_action) print (""chose_rand= "", c_action) print (""s_action= "", s_action)\n\ns_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 rand_action= 11 chose_rand= False s_action= 4\n\nI was not clear on why the random_uniform generates different values when seed is set. This is because the code is running with the same session object that it initialized the variables with. Modifying the code with a new session object, this is what happens:\n\nprint (""s_ph = "", stochastic_ph) d_action = sess.run(deterministic_action) print (""det_action= "", d_action) sess.close() sess = tf.Session() sess.run(init, feed_dict={stochastic_ph: True}) s_action = sess.run(stochastic_action) print (""s_action= "", s_action)\n\ns_ph = Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0) det_action= 4 s_action= 4\n\n 4\n\nThe seed is fixed. So, irrespective of the session you run in, the random value should always be the same. @tandem the sequence of numbers you get would be the same, but not the value every time. If you notice my first result, where I\'m just reading out the value of deterministic_action along with stochastic_action that you are getting in your last step. Your deterministic_action is 1, which means your result is also 1. When I put all the evaluations together in a single session run, your deterministic_action is 4, and hence your result is also 4. Seed should always give the same random number. as long as it is set. That explanation doesnt still make sense\n\n\n\n@tandem tensorflow computation graphs depend on your initialization. In the above example, you are still using the session object that is initialized at the beginning. This means tensorflow is keeping a track of the state of its variables in the session object, and thus does not reinitialize the random_uniform. Close the session object with sess.close() and then open a new session object and run your stochastic_action variable, it will produce the result 4 as expected. """"""']"
61305781,tf.feature_column.categorical_column_with_vocabulary_list,example required,Using Tensorflow embedded columns raises All feature_columns must be _FeatureColumn instances error,"<p>I am new to tensorflow and I was trying to follow the official documentation where I came across 
tf.feature_column.categorical_column_with_vocabulary_list</p>

<p>The code I tested is: </p>

<pre><code>key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), default_value=0)
columns = [[tfc.embedding_column(colors, 3)], ...]
features = tf.io.parse_example(..., features=tfc.make_parse_example_spec(columns))
dense_tensor = tfc.input_layer(features, columns)
</code></pre>

<p>However , when I run this sample code I get the following error : 
 ValueError: All feature_columns must be _FeatureColumn instances. Given: [EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), dtype=tf.string, default_value=0, num_oov_buckets=0), dimension=3, combiner='mean', initializer=, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]</p>

<p>What I am doing wrong?  </p>
","<p><code>make_parse_example_spec</code> expects <code>FeatureColumn instances</code>. You can create the FeatureColumn instance using the below method for the category list.</p>

<pre><code>colors = feature_column.categorical_column_with_vocabulary_list(key='colors',vocabulary_lis=('R', 'G', 'B', 'Y'),num_oov_buckets=2)
my_feature_columns = [feature_column.indicator_column(colors)]
feature_column.make_parse_example_spec(my_feature_columns)
</code></pre>

<p>Output :</p>

<pre><code>{'colors': VarLenFeature(dtype=tf.string)}  
</code></pre>

<p>If you want to create a dense embedding tensor on your categorical column, you can follow the below example.  </p>

<pre><code>data = {'colors': ['X', 'R', 'G', 'B', 'Y']}

df = pd.DataFrame(data)

colors = feature_column.categorical_column_with_vocabulary_list('colors', df['colors'].unique())

colors_embedding = feature_column.embedding_column(colors, dimension=4)

dense_tensor = tf.keras.layers.DenseFeatures(colors_embedding)(data)
</code></pre>

<p>Result: </p>

<pre><code>tf.Tensor(
[[ 0.17071894  0.29407692 -0.26661882  0.07768019]
 [ 0.26196313  0.14372464 -0.41102907 -0.7207164 ]
 [-0.7888006  -0.07049363 -0.49007863  0.45744416]
 [ 0.56329435 -0.7051675   0.04742934 -0.69377   ]
 [-0.52031726  0.488502   -0.37031132 -0.44338205]], shape=(5, 4), dtype=float32)
</code></pre>
",<code>make_parse_example_spec</code> expects <code>FeatureColumn instances</code>. You can create the FeatureColumn instance using the below method for the category list.,"<pre><code>data = {'colors': ['X', 'R', 'G', 'B', 'Y']}

df = pd.DataFrame(data)

colors = feature_column.categorical_column_with_vocabulary_list('colors', df['colors'].unique())

colors_embedding = feature_column.embedding_column(colors, dimension=4)

dense_tensor = tf.keras.layers.DenseFeatures(colors_embedding)(data)
</code></pre>

<p>Result: </p>

<pre><code>tf.Tensor(
[[ 0.17071894  0.29407692 -0.26661882  0.07768019]
 [ 0.26196313  0.14372464 -0.41102907 -0.7207164 ]
 [-0.7888006  -0.07049363 -0.49007863  0.45744416]
 [ 0.56329435 -0.7051675   0.04742934 -0.69377   ]
 [-0.52031726  0.488502   -0.37031132 -0.44338205]], shape=(5, 4), dtype=float32)
</code></pre>","['How to use tf.feature_column.categorical_column_with_vocabulary_list in TensorFlow?', 'Common errors with tf.feature_column.categorical_column_with_vocabulary_list and how to fix them', 'How to create and use embedding columns in TensorFlow?', 'Understanding tfc.embedding_column and its parameters', 'How to use tf.io.parse_example and tfc.make_parse_example_spec in TensorFlow?', 'How to use tfc.input_layer with feature columns in TensorFlow?', ""Troubleshooting 'All feature_columns must be _FeatureColumn instances' error in TensorFlow""]","['How to use tf.feature_column.categorical_column_with_vocabulary_list in TensorFlow?', 'What are the common errors when using tf.feature_column.categorical_column_with_vocabulary_list?', 'How to correctly define feature columns in TensorFlow?', 'What is the correct way to use tfc.embedding_column with tf.feature_column.categorical_column_with_vocabulary_list?', ""How to resolve 'All feature_columns must be _FeatureColumn instances' error in TensorFlow?""]",set(),[],"{'https://stackoverflow.com/questions/48697799/tensorflow-feature-column-for-variable-list-of-values', 'https://stackoverflow.com/questions/34870614/what-does-tf-nn-embedding-lookup-function-do', 'https://stackoverflow.com/questions/46834680/creating-many-feature-columns-in-tensorflow'}","['""""""Share Your Experience: Tensorflow feature column for variable list of values\n\nAsked 6 years, 3 months ago\n\nModified 5 years, 9 months ago\n\nFrom the TensorFlow docs it\'s clear how to use tf.feature_column.categorical_column_with_vocabulary_list to create a feature column which takes as input some string and outputs a one-hot vector. For example\n\nvocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list( key=""vocab_feature"", vocabulary_list=[""kitchenware"", ""electronics"", ""sports""])\n\nLet\'s say ""kitchenware"" maps to [1,0,0] and ""electronics"" maps to [0,1,0]. My question is related to having a list of strings as a feature. For example, if the feature value was [""kitchenware"",""electronics""] then the desired output would be [1,1,0]. The input list length is not fixed but the output dimension is. The use case is a straight bag-of-words type model (obviously with a much larger vocabulary list!). What is the correct way to implement this? GratefulGuestGratefulGuest\n\nHere is an example how to feed data to the indicator column:\n\nfeatures = {\'letter\': [[\'A\',\'A\'], [\'C\',\'D\'], [\'E\',\'F\'], [\'G\',\'A\'], [\'X\',\'R\']]} letter_feature = tf.feature_column.categorical_column_with_vocabulary_list( ""letter"", [""A"", ""B"", ""C""], dtype=tf.string) indicator = tf.feature_column.indicator_column(letter_feature) tensor = tf.feature_column.input_layer(features, [indicator]) with tf.Session() as session: session.run(tf.global_variables_initializer()) session.run(tf.tables_initializer()) print(session.run([tensor]))\n\n[array([[2., 0., 0.], [0., 0., 1.], [0., 0., 0.], [1., 0., 0.], [0., 0., 0.]], dtype=float32)]\n\n 3\n\nin above example the features is passed as dict. How do I get the same results when I have a column in csv file which is space separated and I need to multi-hot encode using the example above ? â€“ Kundan Kumar Feb 7, 2019 at 22:14\n\nCan we use Embedding column here? In case we have large number of values in the column (a very common case), we may end up with a sparse column if we use indicator column. Any thoughts? tensorflow.org/tutorials/structured_data/feature_columns .. Check out this tutorial from Tensorflow, they use Embedding columns here. :)\n\nyou should use tf.feature_column.indicator_column see https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column\n\nSpirit_DongdongSpirit_Dongdong\n\n1\n\nCould you give an example of what the structure of the training data should look like in this case. The doc you post to show what the input data inso converted into but not what you feed it.""""""', '""""""Share Your Experience: Tensorflow feature column for variable list of values\n\nAsked 6 years, 3 months ago\n\nModified 5 years, 9 months ago\n\nFrom the TensorFlow docs it\'s clear how to use tf.feature_column.categorical_column_with_vocabulary_list to create a feature column which takes as input some string and outputs a one-hot vector. For example\n\nvocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list( key=""vocab_feature"", vocabulary_list=[""kitchenware"", ""electronics"", ""sports""])\n\nLet\'s say ""kitchenware"" maps to [1,0,0] and ""electronics"" maps to [0,1,0]. My question is related to having a list of strings as a feature. For example, if the feature value was [""kitchenware"",""electronics""] then the desired output would be [1,1,0]. The input list length is not fixed but the output dimension is. The use case is a straight bag-of-words type model (obviously with a much larger vocabulary list!). What is the correct way to implement this? GratefulGuestGratefulGuest\n\nHere is an example how to feed data to the indicator column:\n\nfeatures = {\'letter\': [[\'A\',\'A\'], [\'C\',\'D\'], [\'E\',\'F\'], [\'G\',\'A\'], [\'X\',\'R\']]} letter_feature = tf.feature_column.categorical_column_with_vocabulary_list( ""letter"", [""A"", ""B"", ""C""], dtype=tf.string) indicator = tf.feature_column.indicator_column(letter_feature) tensor = tf.feature_column.input_layer(features, [indicator]) with tf.Session() as session: session.run(tf.global_variables_initializer()) session.run(tf.tables_initializer()) print(session.run([tensor]))\n\n[array([[2., 0., 0.], [0., 0., 1.], [0., 0., 0.], [1., 0., 0.], [0., 0., 0.]], dtype=float32)]\n\n 3\n\nin above example the features is passed as dict. How do I get the same results when I have a column in csv file which is space separated and I need to multi-hot encode using the example above ? â€“ Kundan Kumar Feb 7, 2019 at 22:14\n\nCan we use Embedding column here? In case we have large number of values in the column (a very common case), we may end up with a sparse column if we use indicator column. Any thoughts? tensorflow.org/tutorials/structured_data/feature_columns .. Check out this tutorial from Tensorflow, they use Embedding columns here. :)\n\nyou should use tf.feature_column.indicator_column see https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column\n\nSpirit_DongdongSpirit_Dongdong\n\n1\n\nCould you give an example of what the structure of the training data should look like in this case. The doc you post to show what the input data inso converted into but not what you feed it.""""""', '""""""Share Your Experience: Tensorflow feature column for variable list of values\n\nAsked 6 years, 3 months ago\n\nModified 5 years, 9 months ago\n\nFrom the TensorFlow docs it\'s clear how to use tf.feature_column.categorical_column_with_vocabulary_list to create a feature column which takes as input some string and outputs a one-hot vector. For example\n\nvocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list( key=""vocab_feature"", vocabulary_list=[""kitchenware"", ""electronics"", ""sports""])\n\nLet\'s say ""kitchenware"" maps to [1,0,0] and ""electronics"" maps to [0,1,0]. My question is related to having a list of strings as a feature. For example, if the feature value was [""kitchenware"",""electronics""] then the desired output would be [1,1,0]. The input list length is not fixed but the output dimension is. The use case is a straight bag-of-words type model (obviously with a much larger vocabulary list!). What is the correct way to implement this? GratefulGuestGratefulGuest\n\nHere is an example how to feed data to the indicator column:\n\nfeatures = {\'letter\': [[\'A\',\'A\'], [\'C\',\'D\'], [\'E\',\'F\'], [\'G\',\'A\'], [\'X\',\'R\']]} letter_feature = tf.feature_column.categorical_column_with_vocabulary_list( ""letter"", [""A"", ""B"", ""C""], dtype=tf.string) indicator = tf.feature_column.indicator_column(letter_feature) tensor = tf.feature_column.input_layer(features, [indicator]) with tf.Session() as session: session.run(tf.global_variables_initializer()) session.run(tf.tables_initializer()) print(session.run([tensor]))\n\n[array([[2., 0., 0.], [0., 0., 1.], [0., 0., 0.], [1., 0., 0.], [0., 0., 0.]], dtype=float32)]\n\n 3\n\nin above example the features is passed as dict. How do I get the same results when I have a column in csv file which is space separated and I need to multi-hot encode using the example above ? â€“ Kundan Kumar Feb 7, 2019 at 22:14\n\nCan we use Embedding column here? In case we have large number of values in the column (a very common case), we may end up with a sparse column if we use indicator column. Any thoughts? tensorflow.org/tutorials/structured_data/feature_columns .. Check out this tutorial from Tensorflow, they use Embedding columns here. :)\n\nyou should use tf.feature_column.indicator_column see https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column\n\nSpirit_DongdongSpirit_Dongdong\n\n1\n\nCould you give an example of what the structure of the training data should look like in this case. The doc you post to show what the input data inso converted into but not what you feed it.""""""', '""""""Share Your Experience: Tensorflow feature column for variable list of values\n\nAsked 6 years, 3 months ago\n\nModified 5 years, 9 months ago\n\nFrom the TensorFlow docs it\'s clear how to use tf.feature_column.categorical_column_with_vocabulary_list to create a feature column which takes as input some string and outputs a one-hot vector. For example\n\nvocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list( key=""vocab_feature"", vocabulary_list=[""kitchenware"", ""electronics"", ""sports""])\n\nLet\'s say ""kitchenware"" maps to [1,0,0] and ""electronics"" maps to [0,1,0]. My question is related to having a list of strings as a feature. For example, if the feature value was [""kitchenware"",""electronics""] then the desired output would be [1,1,0]. The input list length is not fixed but the output dimension is. The use case is a straight bag-of-words type model (obviously with a much larger vocabulary list!). What is the correct way to implement this? GratefulGuestGratefulGuest\n\nHere is an example how to feed data to the indicator column:\n\nfeatures = {\'letter\': [[\'A\',\'A\'], [\'C\',\'D\'], [\'E\',\'F\'], [\'G\',\'A\'], [\'X\',\'R\']]} letter_feature = tf.feature_column.categorical_column_with_vocabulary_list( ""letter"", [""A"", ""B"", ""C""], dtype=tf.string) indicator = tf.feature_column.indicator_column(letter_feature) tensor = tf.feature_column.input_layer(features, [indicator]) with tf.Session() as session: session.run(tf.global_variables_initializer()) session.run(tf.tables_initializer()) print(session.run([tensor]))\n\n[array([[2., 0., 0.], [0., 0., 1.], [0., 0., 0.], [1., 0., 0.], [0., 0., 0.]], dtype=float32)]\n\n 3\n\nin above example the features is passed as dict. How do I get the same results when I have a column in csv file which is space separated and I need to multi-hot encode using the example above ? â€“ Kundan Kumar Feb 7, 2019 at 22:14\n\nCan we use Embedding column here? In case we have large number of values in the column (a very common case), we may end up with a sparse column if we use indicator column. Any thoughts? tensorflow.org/tutorials/structured_data/feature_columns .. Check out this tutorial from Tensorflow, they use Embedding columns here. :)\n\nyou should use tf.feature_column.indicator_column see https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column\n\nSpirit_DongdongSpirit_Dongdong\n\n1\n\nCould you give an example of what the structure of the training data should look like in this case. The doc you post to show what the input data inso converted into but not what you feed it.""""""']"
49987839,tf.clip_by_global_norm,example required,How to handle None in tf.clip_by_global_norm?,"<p>I have read in answers to <a href=""https://stackoverflow.com/questions/36498127/how-to-apply-gradient-clipping-in-tensorflow"">this question here</a> that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws </p>

<p>ValueError: None values not supported.</p>

<pre><code>tf.reset_default_graph()
z = tf.get_variable(name = 'z', shape = [1])
b = tf.get_variable('b', [1])
c = b*b - 2*b + 1
optimizer = tf.train.AdamOptimizer(0.1)
gradients, variables = zip(*optimizer.compute_gradients(c))
gradients = tf.clip_by_global_norm(gradients, 2.5)
train_op = optimizer.apply_gradients(zip(gradients, variables))
</code></pre>

<p>Can somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually</p>

<p>The official documentation seems to agree with @danijar's comments. see <a href=""https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/clip_by_global_norm"" rel=""nofollow noreferrer"">here</a></p>

<blockquote>
  <p>Any of the entries of t_list that are of type None are ignored.</p>
</blockquote>
","<p>There's a small problem in your code: you're assigning the return value of <code>tf.clip_by_global_norm</code> to a single variable, when this function returns a pair of values.</p>

<p>The documentation says:</p>

<blockquote>
  <p>Returns:</p>
  
  <p>list_clipped: A list of Tensors of the same type as list_t.</p>
  
  <p>global_norm: A 0-D (scalar) Tensor representing the global norm.</p>
</blockquote>

<p>Hence, the problem arises when you try to apply the gradients to the variables, in the next line.</p>

<p>You can easily fix your code ignoring the global_norm returned value.</p>

<pre><code>gradients, _ = tf.clip_by_global_norm(gradients, 2.5)
</code></pre>
","There's a small problem in your code: you're assigning the return value of <code>tf.clip_by_global_norm</code> to a single variable, when this function returns a pair of values.
The documentation says:
<blockquote>
  Returns:
  list_clipped: A list of Tensors of the same type as list_t.
  global_norm: A 0-D (scalar) Tensor representing the global norm.
</blockquote>

Hence, the problem arises when you try to apply the gradients to the variables, in the next line.
You can easily fix your code ignoring the global_norm returned value.

<pre><code>gradients, _ = tf.clip_by_global_norm(gradients, 2.5)
</code></pre>",,"['How to handle None gradients in TensorFlow using tf.clip_by_global_norm?', 'Common issues and solutions when using tf.clip_by_global_norm in TensorFlow', 'Step-by-step guide to using tf.clip_by_global_norm with AdamOptimizer in TensorFlow', 'How to manually handle None gradients in TensorFlow', 'Best practices for gradient clipping in TensorFlow']","['How to handle None gradients in TensorFlow when using tf.clip_by_global_norm()?', 'Does tf.clip_by_global_norm() ignore None gradients in TensorFlow?', ""Why does tf.clip_by_global_norm() throw 'ValueError: None values not supported' in TensorFlow?"", 'How to manually handle None gradients in TensorFlow before using tf.clip_by_global_norm()?', 'What is the correct way to use tf.clip_by_global_norm() with AdamOptimizer in TensorFlow?']",{'https://www.youtube.com/watch?v=KrQp1TxTCUY'},"['""""""[Document(page_content=""unstable gradients are one of the main problems of deep neural networks and most of the time batch normalization is the answer to deal with this problem but when you\'re dealing with recurrent neural networks batch normalization is a little bit tricky to implement so instead we might use something else called gradient clipping so in this video let\'s learn what gradient clipping is and how we can apply it so gradient clipping is used for the exploding gradients problem and what you do is quite simple it\'s just that there are a bunch of approaches to it that we will cover in this video so basically with gradient clipping you very simply clip the gradients to be in a certain threshold so for example if you determine that you want your gradients to be between one and one you can easily set the parameter to be one and then from then on whatever your gradients are calculated to be that means whatever your weights were going to be updated with they will be clipped to be between minus one and one the tricky part here is that when you clip some of the gradients and some not the direction of your gradient is going to change so let\'s take this for example let\'s say this is the graph that we have and this is kind of the graph of how we can change the weight 1 and weight 2 and how the cost is going to change from then on so if you let\'s say out of a gradient vector like this that has 0.9 3.2 150 minus 2.1 and 0.0.23 what you\'re going to do if you apply gradient clipping here is that you\'re going to clip the gradients that are higher than 1 and also lower than minus one to be between one and minus one and you\'re going to bring them to be one and minus one so let\'s say in the original vectors the vector\'s direction the direction and the graph was going to look this way but if you clip the gradients the vector is going to change and what\'s going to happen is that your vector is going to be pointing in a completely different direction something you can do to maintain the direction of the gradient is what we call clipping by norm so basically instead of only clipping the ones that are outside of the ranges that you\'re aiming for you can just lower all of your gradient values all of the values that are in your gradient vector to be in between -1 and 1. this way you\'re keeping the proportion of the numbers in your gradient vector and thus keeping the direction of your original gradient vector the main problem with this approach is that this time some of your gradient values are going to become very very very small and at the end they might not actually be effective in updating the parameters of your network unfortunately there are no hard rules when it comes to gradient clipping you\'re going to have to try grading clipping and also grading clipping with norm and see which one works better for you you might also need to try different threshold values to see which one gives you a better result but at the end of the day this is a very effective way of solving the exploding gradients problem and luckily it is very simple to implement using the keras deep learning library but that is all you need to know about grading clipping as i said it\'s a very easy to use and effective way of dealing with the exploding gradients problem and lucky for you and me it is very simple to implement it using the keras deep learning library i hope you enjoyed this video if you liked it don\'t forget to give us a like and maybe even subscribe to show us your support we would also love to hear any of your comments or questions in the comment section below but for now thanks for watching again and i will see you in the next video"", metadata={\'source\': \'KrQp1TxTCUY\'})]""""""']","{'https://stackoverflow.com/questions/36498127/how-to-apply-gradient-clipping-in-tensorflow', 'https://stackoverflow.com/questions/49987839/how-to-handle-none-in-tf-clip-by-global-norm'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nHow to handle None in tf.clip_by_global_norm? Asked 6 years, 2 months ago\n\nModified 6 years, 2 months ago\n\nI have read in answers to this question here that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws\n\nValueError: None values not supported. tf.reset_default_graph() z = tf.get_variable(name = \'z\', shape = [1]) b = tf.get_variable(\'b\', [1]) c = b*b - 2*b + 1 optimizer = tf.train.AdamOptimizer(0.1) gradients, variables = zip(*optimizer.compute_gradients(c)) gradients = tf.clip_by_global_norm(gradients, 2.5) train_op = optimizer.apply_gradients(zip(gradients, variables))\n\nCan somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually\n\nThe official documentation seems to agree with @danijar\'s comments. see here\n\nAny of the entries of t_list that are of type None are ignored.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nHow to handle None in tf.clip_by_global_norm? Asked 6 years, 2 months ago\n\nModified 6 years, 2 months ago\n\nI have read in answers to this question here that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws\n\nValueError: None values not supported. tf.reset_default_graph() z = tf.get_variable(name = \'z\', shape = [1]) b = tf.get_variable(\'b\', [1]) c = b*b - 2*b + 1 optimizer = tf.train.AdamOptimizer(0.1) gradients, variables = zip(*optimizer.compute_gradients(c)) gradients = tf.clip_by_global_norm(gradients, 2.5) train_op = optimizer.apply_gradients(zip(gradients, variables))\n\nCan somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually\n\nThe official documentation seems to agree with @danijar\'s comments. see here\n\nAny of the entries of t_list that are of type None are ignored.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nHow to handle None in tf.clip_by_global_norm? Asked 6 years, 2 months ago\n\nModified 6 years, 2 months ago\n\nI have read in answers to this question here that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws\n\nValueError: None values not supported. tf.reset_default_graph() z = tf.get_variable(name = \'z\', shape = [1]) b = tf.get_variable(\'b\', [1]) c = b*b - 2*b + 1 optimizer = tf.train.AdamOptimizer(0.1) gradients, variables = zip(*optimizer.compute_gradients(c)) gradients = tf.clip_by_global_norm(gradients, 2.5) train_op = optimizer.apply_gradients(zip(gradients, variables))\n\nCan somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually\n\nThe official documentation seems to agree with @danijar\'s comments. see here\n\nAny of the entries of t_list that are of type None are ignored.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nHow to handle None in tf.clip_by_global_norm? Asked 6 years, 2 months ago\n\nModified 6 years, 2 months ago\n\nI have read in answers to this question here that tf.clip_by_global_norm() handles None values by simply ignoring them (comment by danijar in comments to the answer by @danijar) but when i try to apply it i seem to be doing something wrong as it throws\n\nValueError: None values not supported. tf.reset_default_graph() z = tf.get_variable(name = \'z\', shape = [1]) b = tf.get_variable(\'b\', [1]) c = b*b - 2*b + 1 optimizer = tf.train.AdamOptimizer(0.1) gradients, variables = zip(*optimizer.compute_gradients(c)) gradients = tf.clip_by_global_norm(gradients, 2.5) train_op = optimizer.apply_gradients(zip(gradients, variables))\n\nCan somebody please tell me what am i doing wrong or if tf.clip_by_global_norm() does not handle None gradients and i have to take care of them manually\n\nThe official documentation seems to agree with @danijar\'s comments. see here\n\nAny of the entries of t_list that are of type None are ignored.""""""']"
55560676,tf.while_loop,example required,How to use tf.while_loop with eager execution?,"<p>In the documentation, the body of a tf.while_loop needs to be a python callable.</p>

<pre><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>works but</p>

<pre><code>def b(i):
    tf.add(i,1)

i = tf.constant(0)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
</code></pre>

<p>throws a ValueError: Attempt to convert a value (None) with an unsupported type() to a Tensor</p>

<p>In 2.0, eager execution is default, I wonder what's the problem?!</p>
","<p>You forgot to add return statement to your function:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def b(i):
    return tf.add(i, 1)

i = tf.constant(0)
c = lambda i: tf.less(i, 10)
tf.while_loop(c, b, [i]) # &lt;tf.Tensor: id=51, shape=(), dtype=int32, numpy=10&gt;
</code></pre>

<p>Note that in your first example function <code>b</code> does return incremented value:</p>

<pre class=""lang-py prettyprint-override""><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
print(b(1).numpy()) # 2
</code></pre>
",,"<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

def b(i):
    return tf.add(i, 1)

i = tf.constant(0)
c = lambda i: tf.less(i, 10)
tf.while_loop(c, b, [i]) # &lt;tf.Tensor: id=51, shape=(), dtype=int32, numpy=10&gt;
</code></pre>
<pre class=""lang-py prettyprint-override""><code>i = tf.constant(0)
b = lambda i: tf.add(i,1)
c = lambda i: tf.less(i,10)
tf.while_loop(c,b, [i])
print(b(1).numpy()) # 2
</code></pre>","['Understanding tf.while_loop in TensorFlow 2.0', 'How to use tf.while_loop with Python functions in TensorFlow', 'Common errors with tf.while_loop in TensorFlow 2.0', 'Differences between lambda functions and def functions in TensorFlow 2.0', 'Eager execution in TensorFlow 2.0 and its impact on tf.while_loop', 'How to properly define the body function for tf.while_loop in TensorFlow 2.0']","['Why does tf.while_loop require the body to be a Python callable?', 'How to correctly define the body function for tf.while_loop in TensorFlow 2.0?', 'What are common errors when using tf.while_loop in TensorFlow 2.0?', 'How does eager execution affect tf.while_loop in TensorFlow 2.0?', 'What is the correct way to return a value from a function used in tf.while_loop?']","{'https://www.youtube.com/watch?v=KrS94hG4VU0', 'https://www.youtube.com/watch?v=RPocW_aMZKE', 'https://www.youtube.com/watch?v=iFZRUwGcrxQ'}","['""""""[Document(page_content=\'SHANQING CAI: We\\\'re going to\\ndo this presentation about how to debug TensorFlow programs. We\\\'re going to focus\\nspecifically on TF 2, because TF 2 is\\nthe stable release, and it will have long-term\\nsupport going forward. But there are also places where\\nwe\\\'re going to mention TF 1. And when we do,\\nwe\\\'ll make that clear so you know which version of\\nTensorFlow we\\\'re talking about. So first of all, I want to\\ndefine a scope of debugging. And the reason why\\nyou should do this is because the word ""debugging""\\nis an overloaded term in machine learning. Different people use it to\\nrefer to different things, sometimes in confusing ways. So in the scope of\\nthis talk, debugging refers to specific\\nthings, really, that mainly have to do with the\\ncorrectness of your TensorFlow program, like mathematical\\nimplementation bugs. For example, when you are\\nimplementing a new [INAUDIBLE] type or a new loss\\nfunction, you may run into DType issues\\nor shape issues, or just straight bugs in the math. And the techniques\\nwe\\\'ll cover will also be useful for debugging\\npre-processing and post-processing parts\\nyour TensorFlow program. And one big focus\\nwill be the debugging of the issues like\\nNaN and infinity in our models, which happen\\nvery frequently during TF model training. [INAUDIBLE] will talk\\nabout a specific tool called TensorTracer, which\\nis very useful for catching the root cause of\\nNaNs and infinities on TPUs and other devices. And we\\\'re not going\\nto talk about how to debug bugs in op kernels\\nthemselves or bugs in hardware, because it\\\'s more\\nspecific to the hardware and for the op kernel\\nthat you\\\'re using. However, the methods we\\\'ll\\ncover will be useful for you to debug models that are\\naffected by those kernel or hardware bugs. At least, it will be useful\\nfor you to narrow down the cause of the\\nmodel bug to the level of op kernels or hardware. And the tools and\\ntechniques we\\\'ll cover will also be useful in\\ncase you want to just peek into a model to understand\\nwhat\\\'s going on. And so one example would be\\nanswering a question like, why is my model making a wrong\\nprediction on a [INAUDIBLE] for example? So you will be able\\nto peek into the model and look at the\\nlayer activations and the intermediate tensors\\nand answer that question. So one use case that\\\'s\\nkind of relevant to that is when you\\nare porting model from one version of\\nthe library to another, or from one library to another,\\nlike from TensorFlow to TFLite, or from TensorFlow to TF.js,\\nor from TensorFlow to PyTwitch or more from PyTwitch\\nto TensorFlow. You will often see divergence\\nbetween the two implementations of the same model, and you want\\nto quickly identify the root cause of the divergence. And the tools and\\ntechniques we\\\'ll cover will also be useful\\nfor that purpose. What we\\\'re not going\\nto cover, however, are the debugging cases like\\ndebugging the model performance and looking at the\\naccuracy of models after training, like model\\nevaluation and analysis. We\\\'re not going to cover\\nhow to debug fairness issues in models,\\neither Those are also important kinds of\\nTensorFlow debugging, but those are outside\\nthe scope of this talk. There are great tools for\\nthose, like some dashboards in TensorBoard and What-If\\nTool, and fairness indicator, and so forth. But I\\\'m not going to\\ntalk about those here. Any questions so far? OK. So here\\\'s a brief outline\\nof this presentation. We\\\'re going to talk about\\nhow to debug tensor values. We\\\'re going to talk about how\\nto look at the placement of ops on different devices,\\nlike CPUs and GPUs. It\\\'s a very commonly\\nasked question. We\\\'re going to look at how to\\ndebug the structures of graphs in TensorFlow 2, including\\nthe graphs from tf.function and graphs that are\\noptimized for the runtime. And then in section\\n4, we\\\'re going to cover the special topic\\nof step debugging, which is to use an IDE to step\\nover your code line by line. And then in the\\nfifth section, we\\\'re going to move from low-level\\nAPI to high-level API. And the specific\\nhigh-level I will focus is on tf.keras,\\nbecause tf.keras is the official\\nhigh-level API in TF 2, and also because\\nI\\\'m not as familiar with other high-level APIs\\nlike [INAUDIBLE] and so forth. And in section 6,\\nwe\\\'re going to talk about the debugging of numerical\\nissues like NaNs and infinity. And finally, I\\\'m\\ngoing to present to work on TensorFlow Debugger,\\nincluding the existing V1 features and the V2 features\\nthat we\\\'re currently working on. So first, let\\\'s take a look\\nat how to debug tensor values. So here\\\'s a very simple example. So it\\\'s very straightforward. You are not decorating\\nyour functions with tf.function decorator. So everything is\\nexecuted eagerly in TF 2. And there you can simply\\nuse the print statements to look at the\\nvalues of tensors, like in this simple\\nexample here. So y is an eager tensor. If you do print, you\\nwill see the value in the stdout printout. So it\\\'s very similar to print\\nthe value of the numpy arrays, with the caveat that if the\\ntensor lives on the GPU, then printing it will\\ninvolve copying from the GPU to your host, which may\\nbe a little bit costly. And oftentimes, when the size\\nof the tensor is too big, you probably don\\\'t want to\\nlook at the entire tensor, because there are going to\\nbe millions of elements. What you sometimes want is\\nto do a reduce operation on the tensor and then look\\nat some numerical summaries of the tensor, like what\\\'s\\nthe minimum value, what\\\'s the maximum value,\\nand what\\\'s the mean. It\\\'s also a useful\\ntechnique that\\\'s fully supported in eager mode. So EagerTensor str\\nand repr methods use numpy under the\\nhood, which means that you can use the\\nset_printoptions function from numpy to control\\nthe details of how the values of\\ntensors are printed. For instance, if you use\\nthe precision [INAUDIBLE] arguments, you can\\nadjust basically how many decimal points are\\nprinted in the floats type tensors. You can also adjust the\\nthreshold element count beyond which ellipses will be\\nused in the printing, which is useful for cases\\nwhere you want to look at the values\\nof huge tensors, like thousands of elements. Of course, the story is not\\nalways as straightforward as this. The program is often not\\nexecuting purely eagerly. And sometimes you\\nhave tf.function, sometimes your function is\\ndecorated by TensorFlow itself and converted into a graph. So there, if you use\\nthe print statements, then the results of\\nthe printing may not be what you would expect. So here the user intends\\nto look at the value of n as each iteration\\nof the while loop. So the user puts a print\\nstatement here naively. And the result has\\nonly one printed line, even though the while loop\\nis executed multiple times. And the contents\\nof the printed text is also kind of confusing\\nto a naive user. And the reason is that\\nwhen tf.function is used, the code here is\\ntransformed into a tf.Graph. And the print\\nstatement gets executed during that function-to-graph\\ntransformation. And the contents you\\nsee here is actually a node in the graph\\ninstead of the value of the tensor at runtime. So the correct approach\\nis to use tf.print. So tf.print will\\nmodify the graph. It will actually add a\\ncouple of nodes to the graph so you can look at the value of\\nthe n inside the tf.function. So here at the bottom here,\\nyou can see the value of n as each iteration of the\\nwhile loop is printed. So it\\\'s quite useful. So here is a homework\\nproblem for you. So the examples I\\\'ve shown so\\nfar are all for simple tensors, like float32 tensor\\nor an integer tensor. What if the tf.print\\nstatement is used on a ragged tensor\\nor a sparse tensor? So those are the major composite\\ntensor types in TensorFlow. So you can try that. By the way, I inserted a\\nlink to the Colab Notebook for all the code examples\\nin this presentation. So you can look at the slides. And if you want to play\\nwith a code examples, you can use that Notebook. So here is a second\\nhomework code. You can use the code to see\\nwhat happens if you use tf.print on a sparse tensors. OK. So sometimes, the user\\ndoesn\\\'t want to just print the value of the tensors. The user wants to\\nprogrammatically extract the value of the\\ntensors so they can be used for like\\nprogrammatic debugging or downstream computation. This code snip here shows\\nhow you can pull out intermediate tensors from a toy\\nimplementation of a TF Dense layer. So the function originally\\nreturns only the final outputs of the Dense layer. But maybe for some\\nreason you want to look at the\\nintermediate steps, like the results of the\\nmatmul or the results of adding with a bias. So what you can do here\\nis you can actually append these two\\ntensors to the return values of the tf.function. And then you\\\'ll\\nbe able to access these intermediate values\\nwhen you call the layer. What\\\'s slightly\\nmore complicated is if those tensors are inside\\nthe control flow structures. So for instance, if you\\nwant to programmatically access the value of n at every\\niteration of the while loop, you can\\\'t simply just add\\nn to the return value here. What you need to do here is\\nto use tf.TensorArray and then append that tf.TensorArray as\\neach iteration of the while loop. And then you be able to see the\\nfull history of how n changes. It\\\'s slightly complicated. So the TensorFlow\\nDebugger tool I will present at the end\\nof this talk hopefully will make this simpler. So having covered\\ntensor values, I\\\'m going to talk about how to\\ndebug the placement of ops on different devices,\\nmainly CPUs and the GPUs. So it\\\'s a very frequently\\nasked question, because the users\\nwant to make sure that their heavy computation\\nis computed on the GPU, not on the CPU. So again, if the program\\nis running purely eagerly, then it\\\'s pretty\\nstraightforward. You can just call an API called\\ntf.debugging.set log device placement equal True. And then when those operations\\nare executed eagerly, you will see lines being\\nprinted to the stdout. For instance, when the\\nmultiplication operation areas run, you will see a line\\nthat tells you that the log op is running on a GPU. And when the print\\nstatement here is running, it\\\'s actually running a\\nPrint-V2 op on the CPU. So here you can see clearly\\nwhere the ops are running, whether it\\\'s on CPU or GPU,\\nand if you have multiple GPUs, which GPU is running an op. So one thing you\\nneed to know here is that it\\\'s only going to\\nlog information when the op is placed for the first time. If you have the same op\\nexecuting multiple times eagerly, it\\\'s not going to\\nprint it multiple times. So that mechanism prevents\\na flood of information to your stdout. So a more realistic\\nscenario is where you have tf.functions and graphs. So there,\\nset_log_device_placement equal to True will still work. You will see not\\nonly the placement for the eager ops, like\\nin the green box here, but you will also\\nsee the placement of the graph ops in the\\npurple box on the bottom here. But one caveat here\\nis that you need to be aware that, even though\\nthe eager lines are printed to stdout, currently the graph\\nlogs are printed to info log. The implication of\\nthat is that if you\\\'re doing this in a Jupyter\\nNotebook or Colab, then you will not be able to\\nsee the bottom parts of the log. But there is actually\\na way in Colab to capture the log\\nso you can see both. It\\\'s just something you\\nneed to be aware of. So in the graph placement logs,\\nthe text inside the parentheses are for the op\\ntype, and the text outside the parentheses to\\nthe left of the parentheses are for the name of the op. So here are some\\nother important things to know about\\nset_log_device_placement. So it works for both\\neager operations and for graph operations. But they\\\'re allotted\\nto different places, as I mentioned. And also, be aware that the fact\\nthat an op is logged at graph construction time does not\\nguarantee that the op will be executed at runtime. And that\\\'s because TensorFlow\\nhas its built-in graph optimization step\\ncalled Grappler, and Grappler may\\nchange the placement, or it may prune the op\\naway from the graph, or it may fuse the op into\\na larger op, and so forth. I\\\'m going to talk about\\nthat in a coming slide. And also, be aware that\\nset_log_device_placement currently does not\\nwork fully for TPUs. So it\\\'s mainly useful for\\ndebugging CPUs and GPUs currently. OK. So I\\\'m going to move on to the\\nsection about debugging graph structures. So here you have a tf.function. And then how do you look at\\nthe graph of the compilation of that tf.function? So the answer to that\\nis to use the method called get_concrete_function\\non that function object. So get_concrete_function\\nshould be called only after\\nthat tf.function is called for the first time. If you call that before\\nthe function is compiled, then that method\\nwill not even exist. And when you call\\nget_concrete_function, you need to pass an argument. So the argument can\\nbe the same argument as you pass when you are\\ncalling the function. And the reason why you\\nneed to pass that argument is because the same\\nPython function can be compiled into\\ndifferent tf.Graphs, depending on the DTypes and\\nshapes of the [INAUDIBLE] arguments. You can also pass tensor\\ntext as the arguments. And the return value of\\nget_concrete_function here is an object that\\nhas a graph property. The graph property is a\\ntf.Graph on a Python level. To see its structure,\\nyou can call as_graph_def on a method of the graph object. And the returned\\nvalue is a text float for the graph, as shown\\non the right here. So the text float\\nhere is basically a repeated fields of nodes. It tells you which nodes\\nthere are in the graph and how they\\\'re\\nconnected to each other. So there are properties like\\nname, and op, and attributes, and so forth. So if you\\\'re not\\nfamiliar with the format, you should spend some time\\nlooking at some examples, because it\\\'s very critical, very\\nimportant for TensorFlow code. But the important thing here is\\nthat, for any realistic models and realistic tf.functions,\\nthe size of the graph then is going to be too big. It\\\'s not going to be\\nfriendly to reading a text. And that\\\'s why graphical\\ntools like TensorBoard will be important. So you can start\\nTensorBoard, the binary. So even if you have\\nan empty logdir, you can still switch\\nto the Graph Dashboard by using the dropdown menu. And then inside the\\nGraph Dashboard, you should be able to see a\\nbutton called Choose File. And you can use Choose\\nFile to upload the contents of the pbtxt of graph. And then TensorBoard\\nwill be able to show you the structure of the graph,\\nas shown in this example here. So some important properties to\\nknow about TensorBoard\\\'s Graph Dashboard is that that\\ninformation flow is generally from bottom to top. So the inputs are\\nusually on the bottom. And at the top, you\\\'re\\nseeing the outputs. And also, TensorBoard\\\'s graph\\nvisualizer will group nodes by name scope by default. So\\nthat\\\'s the reason why you often see those big, colorful boxes. And you can double-click\\neach box to expand into it. So it\\\'s quite handy for\\ndebugging large models. And it also handles\\nFunctionDefLibrary correctly. So FunctionDefLibraries are\\nbasically nested graphs. So it\\\'s used frequently in\\nTF 2, like in control flow structures. So a TF 2 while loop will\\ncontain two functions, like one for the condition\\nof the while loop and the other for the\\nbody of the while loop. Those are also color\\nboxes that you can double-click to expand into. If you\\\'re Google\\ninternal, then you should be able to use a\\nspecial import from Colab. And that will enable you to look\\nat the graph inside the Colab Notebook. So I find that to be\\nslightly handier than looking at graph structures\\nin TensorFlow itself, because that means I\\ndon\\\'t have to switch back and forth between two\\ndifferent tabs of your browser. So here is an example. So, as we mentioned before,\\nyou can append variables to the return list\\nof the tf.function to access intermediate tensors. And in this graph being\\nvisualized by our TensorBoard, you can see two extra\\nidentity nodes that correspond to the added return values. And that\\\'s because\\nTF 2 currently uses identity nodes to mark the\\nreturn values of tf.functions. So here\\\'s a graph\\nfor a function that\\\'s slightly more complicated. So it involves control\\nflow structures, including while loops\\nand if-else conditions. So these are the boxes that\\nare the FunctionDefLibraries that I mentioned before. So you can see a box\\nfor the true branch of the if-else condition. You can see another box\\nfor the false branch of the if-else condition. And the box here in red is the\\ncondition of the while loop, and so forth. So if you are very careful\\nand if you spend some time, you can see the correspondence\\nbetween these ops in the graph and also the operations\\nin the Python code. But that\\\'s in\\ngeneral how to do it. And it requires an\\nexpertise to see the correspondence\\nbetween the graph nodes and the Python operators\\nor Python functions. So that\\\'s one gap where\\nthe TF Debugger tool that I will talk about tries to fill. So in TF Debugger\\ntool, you will be able to look at the graph\\nstructures and the source code side by side. So it will be easier\\nfor you to establish the correspondence between\\nthe Python functions or Python operators and the\\nnodes of the graph. OK. So what if the function is not\\nexecuting on a single device but it\\\'s executing on multiple\\ndevices or multiple hosts using distribution strategy? So before I talk\\nabout that, I\\\'m going to tell you about a\\nuseful API for mocking out virtual devices. So for instance, if you\\nhave only one physical GPU on your machine,\\nand you want to do some testing or some debugging\\non a distribution strategy that involves four different\\nGPUs, then you can use the API called\\nset_virtual_device_configuration to create four logical GPUs. And you can use the API called\\nlist_logical_device to confirm that. It\\\'s a very useful technique\\nfor testing and debugging TensorFlow functions that\\ninvolve multiple devices. So once we have set\\nthe four logical GPUs, we can use MirroredStrategy\\nto basically create a variable on the four GPUs. And we can construct\\na function that will basically\\nincorporate and take that variable on the four GPUs. So the function here comes-- dist_f is the function that\\ninvolves the replication. And you can use the\\nget_concrete_function method as before to look\\nat graph structure. So you can upload\\nthe graph pbtxt to TensorBoard to\\nsee its structure. And in the structure,\\nyou can see four boxes. And those four boxes\\ncorrespond to the four GPUs. So the technique here is\\nuseful for debugging graphs in mirrored strategies and\\nother distribution strategies. So this slide here\\nshows you how tf.print works in terms of the graph. So each time you call\\ntf.print inside a tf.function, it will append a pair\\nof nodes to your graph. So the first node here will\\nconverge your tensor, the input tensor, into a string. And the second one will\\nactually print that string into stdout or info out\\nor whatever output stream the printout is configured to. So here\\\'s an example for you. It\\\'s also available\\nin the Colab Notebook, so you can play\\nwith it a little. It is very interesting. So the question here is, what\\nhappens if there is no return value from the function? So I forgot to mention\\nthat the reason why these PrintV2 ops get executed\\nat runtime because they are attached as\\ncontrol dependencies to the final output\\nidentity node of the graph. So these correspond to the\\ndashed lines in the graph. So the homework problem\\nis about finding out how the print op gets executed\\nwhen the tf.function does not involve a return value. So when you use\\ntf.print, you need to be aware that it\\nmay inadvertently change how graph optimization\\nworks at runtime. So in the code snippet\\non the left here, we\\\'re computing the\\nharmonic mean of a tensor. However, there is a line in the\\ncode which constructs an op. But the output tensor of\\nthat op, which is a Min op, there\\\'s not usually any\\ndownstream computation. Now, when the tf.function\\nis actually at runtime, Grappler is going to\\ndo its job, and it\\\'s going to prune out that Min op. So the Min op will not actually\\nget executed at runtime. However, if you\\nuse tf.print, you will change the optimization. And you\\\'re basically\\ngoing to attach the output tensor of the Min op to the\\nstring format from the PrintV2, as I mentioned before. But the important\\nthing to note here is that if you use the\\nget_concrete_function method to debug the\\ngraph structure, you will always see a Min op. And that\\\'s because\\nat the Python level, TensorFlow AutoGraph faithfully\\nonly converts the Python function into a graph. It\\\'s not trying to\\ndo any optimization. Instead, it will hand\\nthe graph to Grappler for downstream optimization. So the question\\nhere is, how can we debug the optimized graph that\\nare generated by Grappler? So that leads us to\\nthe next section. So in order to see the\\nGrappler output graph, you need to use Bazel build. So when you call this, you\\nneed to specify an environment variable called\\nTF_DUMP_GRAPH_PREFIX and point it to any directory\\nyou have write access to. And then you have to specify\\nthe flag called vmodule. So that tells the\\nmeta_optimizer, which is a part of Grappler, to\\nbe verbose and dump information to the folder. And after the program\\nruns, you will see a bunch of files in the folder. So those are the outputs\\nfrom each pass of Grappler. So Grappler performance\\ngraph optimization in steps, kind of like a compiler. So the final output,\\nwhich is usually called after_MetaOptimizer\\nsomething, is using the graph of interest. So it will tell you the\\nstructure of the graph that gets executed at runtime. So using the technique\\nhere, you will be able to compare the runtime\\ngraph of the two code snippets that we have seen before. So in the code\\nsnippet on the left, and also the graph\\non the left, you see that the Min\\nop is not present, because it\\\'s pruned\\naway by Grappler. However, in the code\\nsnippet on the right here, and also the graph\\non the right here, you can see that the\\nMin op is present. And it feeds input\\ninto the two ops that correspond to tf.print. So as you can see,\\nthe process here is convoluted and complicated. So TF Debugger will try to\\npresent both the Python graph and the runtime\\ngraph to you, so you don\\\'t have to do any Bazel\\nbuilds or any special flags or environment variables. OK. So now let\\\'s talk about\\nthe interesting topic of step debugging. So by step debugging,\\nI mean using a Python IDE or [INAUDIBLE]\\nto step over lines of the source code one by one. Some people prefer that\\nover print debugging. So the useful API here if\\nyou want to start debugging is the tf.config.experimental\\nrun functions eagerly. So if you call that function\\nwith the eager element True, then you\\\'re basically\\ntelling the tf.function to not compile\\nfunctions into graphs. And all the code here\\nwill run eagerly. And you will be able\\nto use either print, or you can use step debugging,\\nor can use breakpoints in your favorite IDE. But one important caveat\\nyou want to keep in mind is that it works for all\\ncases except tf.data. Because tf.data works\\nin a special way, it always converts Python\\nfunctions into graphs before it runs them. So I\\\'m going to show an example\\nfor that in an upcoming slide. This slide here shows\\nan example of using VSCode to do step\\ndebugging on a tf.function after you call experimental\\nrun functions eagerly True. However, if you don\\\'t\\ncall that function-- I mean, if you don\\\'t call\\nexperimental run functions eagerly, or if\\nyou call it False, then it\\\'s not a good idea to\\nstep debug your tf.function. And for some IDEs, if\\nyou add a breakpoint, it\\\'s not even going to\\nhit that breakpoint. And in other IDEs, it\\nwill hit that breakpoint, but the stepping pattern\\nafter that breakpoint will be very confusing. And the reason for that has to\\ndo with the internal details of how AutoGraph works. And I refer you to\\nthe presentation made by Dan Moldovan\\non AutoGraph last year. I think it\\\'s publicly available. So understanding that,\\nit will probably not be too hard for\\nyou to understand why this strange behavior\\nis happening here. So the strange behavior is\\nthat you\\\'re inserting a print statement in both branches\\nof the if-else condition, and you see that when\\nthe function is called, both branches get executed. Yeah. So the slide here\\nshows you an example in which experimental\\nrun functions eagerly does not work on a map function\\nthat you pass to tf.Dataset. So even if you comment out\\nthe tf.function decorator for the to_multi_hot\\nfunction, it\\\'s still going to be converted\\ninto a graph, and it will run\\nin a graph fashion instead of running eagerly. So in order to debug\\nintermediate tensors inside a function,\\nyou must use tf.print. If you do print,\\nyou\\\'re only going to print the symbolic\\ntensors in the graph. But TensorFlow\\nDebugger will also make it easy for you to\\ndebug the values insides a tf.function passed\\nto tf.Dataset. OK. So so far, we have\\nbeen talking about how to debug low-level constructs\\nof TensorFlow, including ops, and tensors, and graphs. But many users also use\\nhigh-level APIs like tf.keras. And then they also want\\nto peek into their models. So in the following\\nslides, I\\\'m going to talk about some\\ntools and techniques available for\\ndebugging Keras models. So one very frequently\\nasked question is, how do I get the\\nintermediate layer outputs, meaning the\\nintermediate layer activation from a tf.keras model? So one way to do\\nit is to construct a second model, which is the\\ndebug_model in the example here. The second model has the same\\ninputs as the original model. But the outputs will be\\nthe original model\\\'s output plus the outputs from the\\nlayers you\\\'re interested in. And then when you call\\ndebug_model.predict or simply call debug_model\\nas a tf.function, you\\\'ll be able to see not only\\nthe final output of the Keras model, but also the\\nintermediate outputs. So this approach is useful\\nto look at the final outputs of each layer. If you want to have the\\nintermediate tensors inside each layer,\\nit\\\'s not that useful. You have to use tf.print\\nmethod or the other techniques mentioned in earlier\\nparts of the presentation. And TF Debugger will\\nalso make it easier for you to look at\\nlayer internal tensors. So one other useful\\nthing to know when you are debugging\\na tf.keras model is to use the\\nTensorBoard callback. So the TensorBoard\\ncallback, which is under the\\ntf.keras.callbacks namespace, is a callback you can\\npass to your model.fit. What it will do is it\\\'s\\ngoing to log loss functions and metrics to the logdir\\nwhen the model is training. But for debugging\\npurposes, it will also log the graph of the\\nmodel to the logdir. So you can just open the\\nGraph Dashboard of TensorBoard and look at the graph structure. So there you see that\\nthe layers of the model are organized in\\nthose boxes that you can double-click to expand. And that\\\'s thanks\\nto the work done by the authors of\\ntf.keras, who have been very careful in\\nspecifying the correct name scopes for each layer. But the other important\\nand useful thing to note is that the tensors are\\nmarked as those arrows that connect the layers. And if you look carefully, you\\ncan see those very small fonts. Those small fonts are the shapes\\nof the tensors to the extent known at graph\\nconstruction time. So for instance,\\nthe dropout layer here outputs\\ntwo-dimension tensor of size question mark times 5. So the question mark is the\\nundetermined batch dimension. OK. So having covered\\nhigh-level API debugging, let\\\'s move on to\\nthe next section, which is about how to debug NaNs\\nand infinities you\\\'re running. So that\\\'s a very frequently\\noccurring debugging task in TensorFlow, and probably\\naccounts for about half of the questions\\nthat we get asked. So if we\\\'re talking\\nabout the tools, I want to show you some common\\ncauses for NaNs and infinities in TensorFlow models. So they can be caused by\\na lack of value clipping. Like when you have a division\\noperation in your TensorFlow program, like some\\nsort of normalization, if you forget to add an\\nepsilon or very small positive value to\\nyour denominator, it\\\'s likely to run into\\ninfinities at runtime, especially in the face of\\nvariability of input stream data. And that also applies to\\nthe math log operation. And sometimes,\\nNaNs and infinities in your TensorFlow\\nmodel can be caused by bugs in op kernels\\nthemselves or even in hardware. So for instance, we\\nhave seen a bug recently that involves [INAUDIBLE] kernel\\non TPUs outputting infinities and NaNs, even when the\\ninputs are totally valid. And sometimes, the\\nNaNs and infinities can be also caused by exploding\\ngradients, especially when your learning rate is too high. So in that case, to\\nquote the famous meme-- just keep calm and\\ndecrease the learning rate. And then as [INAUDIBLE]\\nwill tell us about, sometimes the NaNs\\nand infinities can also be caused by\\nproblematic training examples. So debugging, then, the root\\ncause of the NaN and infinity is different from the print\\ndebugging and the graph structure debugging we have\\ntalked about in earlier parts of the presentation. And that\\\'s because, to\\nfind the root cause of NaNs and infinities, you\\ndon\\\'t know where to look, because that\\\'s exactly what\\nyou\\\'re trying to find out. You could insert\\ntf.print statements to every single\\ntensor in your model. But it\\\'s not going to work\\nfor a realistic model, which can include up to tens\\nof thousands of tensors. So that\\\'s why we need\\nspecialized tools to help you debug the root\\ncause of NaNs and infinities. So I\\\'m going to\\npresent two tools here. The first one is a new API. It\\\'s called tf.debugging.enable\\ncheck numerics. So it\\\'s a relatively new API. It just came into\\nexistence in TF 2.1, which was released\\nabout a month ago. So what the API does here\\nis that you can simply add one line of code\\nto your TF program. And when the TF program runs,\\nlike when the model trains, it\\\'s going to check every\\nfloating type tensor in our TF program, including the eagerly\\ncomputed tensors and tensors inside graphs and tf.functions. And as soon as any floating\\ntype tensor contains NaNs or infinity\\nin their output, then the program will error out\\nwith a helpful error message, as the one shown\\non the right here. So the error message\\nhere contains a bunch of useful information\\nfor debugging, including the name of the op,\\nthe runtime DType and the shape of the tensor,\\nas well as a stack trace. So we know that the stack trace\\nfrom TensorFlow error messages are usually very verbose\\nand hard to understand. And the API here\\ntries to infer, or try to guess which frames\\nof the stack trace correspond to the\\nuser\\\'s own program. And it highlights those\\nframes with an arrow. So hopefully it will\\nbe easier for you to find the important\\nframes in the stack trace. And the API here is also\\ngeneral in the sense that it works for both forward\\npass and backward pass. It works for low-level\\nAPI and high-level APIs, including Keras. It also works if you are\\nstuck with an old TF 1 API. And it should work on\\nCPU and GPU and TPU. So one question you\\nmight want to ask is, what\\\'s the performance\\noverhead of this? And it\\\'s an important question,\\nbecause to find the root cause of NaNs and\\ninfinities, the overhead needs to be as low as possible. Sometimes, the\\nNaNs and infinities don\\\'t happen until like a\\nfew hours or even a few days into training. So thanks to the work\\nof an intern, Anthony, the overhead of this API is low. So we have benchmarked the\\nAPI on a bunch of models. So here\\\'s an example from\\nthe transformer v2 model. When it\\\'s training\\non the CPU, if you enable [INAUDIBLE] check, then\\nit\\\'s going to get about 30% overhead. If the model is trained\\non GPU, then overhead is slightly higher. It\\\'s about 75%. But it\\\'s not that high. So it may be even\\na good idea for you to turn this API on in your\\ntests for [INAUDIBLE] checks. So this API here is useful, but\\nit\\\'s also limited in the sense that it only tells\\nyou what happens when the NaN or infinity happens. It tells you about op. But it has no information\\nabout the moments or the history of the execution\\nleading up to that moment. OK. So what TensorFlow\\nDebugger is can be thought of as basically\\na combined tool that will help you achieve almost\\nall the debugging tasks that we have\\nmentioned in earlier parts of the presentation,\\nincluding looking at tensor values, the placement of ops\\nand devices, graph structures, also step debugging\\nand numerical issues like NaNs and infinities. So far, we haven\\\'t\\nput a lot of thought into high-level API\\nsupport like Keras. But it\\\'s on our radar. So there are two\\ndifferent versions of TF Debugger, V1 and V2. So V1 was a part of TF 1. So it\\\'s centered around\\nthe old tf.Session API. So it\\\'s basically a set of\\nwrappers for your sessions. So it\\\'s still available\\nin TensorFlow. If you are still\\nusing TF 1 APIs, it might be useful to you. So there are two\\ndifferent wrappers-- the command line interface\\ninterface wrapper and the TensorBoard wrapper. When you wrap the\\nsession objects, you don\\\'t have to make any\\nother changes to your TensorFlow code. When Session.run runs,\\nit\\\'s going to present you with debugging information. If you use the command line\\ninterface interface wrapper, then Session.run\\nwill basically drop into an interactive terminal\\nbased program in your terminal. And these screenshots\\nare showing you that the command line\\ninterface will show you the list of tensors\\nthat are executed. And you can click\\nthose tensor names to look at the details\\nof the tensors, like the op placement,\\nthe values of the tensors, and so on. It will also show\\nyou on source code and annotate each line\\nin the source code with the ops that are\\ncreated at that line. So currently, we\\\'re working\\non V2 of TF Debugger. The reason why we want to\\ninvest in is are obviously, first we want to\\nbring the tool up to speed with our current\\nAPI which has no tf.Session, but it involves eager\\nexecution and tf.function. And also, in earlier\\nparts of the presentation, you have seen that print\\ndebugging and tf.print are useful for a lot\\nof debugging cases, but it\\\'s not useful in all\\ncases, especially when you want to debug some code deep\\ninside the TensorFlow codebase itself. So we also want to\\nincorporate some lessons we learned from V1 of the tool. First, we want the tool\\nto be general enough to work on all hardware types. TF Debugger V1, because it\\npredates TPU in TensorFlow, it does not work for TPU. It only works for CPU and GPU. But TF Debugger V2 will work for\\nall the major hardware types-- CPUs, GPUs, and TPUs. And secondly, we\\nwant the overhead to be as low as possible. And also, we learned that\\nthere are some improvements that we can make to\\nthe UX of the frontend. So TF Debugger V2 in a nutshell\\nwill involve this process. So the user has a TF program\\nthat he or she wants to debug. Then they can just\\ninsert one-line call into their tf.function\\nand specify a logdir. So the logdir can be the same\\nlogdir as your TensorBoard logdir. And then if your\\nTensorBoard has started, then you can switch\\nto the Debugger V2 Dashboard in TensorBoard to\\nlook at the debug information. So the frontend work\\nis currently underway. So I\\\'ve been reaching\\nout to various people, like people at the TensorFlow\\nteam and outside TensorFlow team at Google to\\nget their feedback. If you\\\'re interested\\nin [INAUDIBLE] this or telling us about your\\nspecific debugging use case, please reach out to me. And I will be more than happy\\nto work with you to make sure that the new tool will be\\nuseful for your problem. So here are some UI mocks that\\nUX researchers helped us make. So it\\\'s going to be the\\nlook of the new Debugger V2 plugin in TensorBoard. It\\\'s going to show you the\\nexecution history on the top. It\\\'s going to show you\\nboth eager execution ops and of tf.functions. And you can zoom\\ninto tf.functions to look at the graph structure\\nand the list of tensors that are computed\\ninside the tf.function. And the top left section will\\nhighlight important events, like the generation of\\nNaNs and infinities, and the repeated\\nfunction compiles which might hurt your\\nperformance, and so forth. And more importantly,\\non the bottom section you will be able to associate\\nyour graph ops with your source code or associate\\neager execution events with your source code. This will make it\\neasier for you to find the way back from your\\nbug into your source code. And it should speed up\\nyour bug fixing process. And finally, some advice. So the authors of TensorFlow\\nhave done a lot of work recently to improve\\nthe error messages. So next time you get an\\nerror message in TensorFlow, be patient and read\\nthrough the error message, especially the sections\\nlabeled as ""in user code."" It may contain some surprisingly\\nuseful information for you to debug your problems. And lastly, some\\nmachine learning bugs are not machine learning\\nbugs, but they\\\'re just general programming bugs. So here is a puzzle\\nfor you to chew on. It\\\'s a small problem. So here, the user is trying\\nto code two of the files for the features\\nand for the labels. And the user feeds\\nthem into a function to construct a data set. And the data set is fed into\\nthe fit call to train the model. But for some reason, the model\\ntraining is not very good. The accuracy is much\\nworse than expected. And what\\\'s the reason for that? So it\\\'s a puzzle for you. If you\\\'re interested in the\\nanswer, reach you to me, and I\\\'ll be happy to\\ntell you the answers. But the point is that\\nsome bugs are just general problem bugs, not\\nmachine learning bugs per se. Thank you very much\\nfor your attention. [MUSIC PLAYING]\', metadata={\'source\': \'RPocW_aMZKE\'})]""""""', '""""""[Document(page_content=""some time ago i was walking one of my co-workers through how to do custom training loops and weird loss functions in tensorflow for models that have multiple outputs each with their own mini neural net but share the proceeding body these are called multi-head models my co-worker was only familiar with using the fit function and so i made up a simple toy problem to quickly work through everything and i\'m going to show that same process in this video let\'s start off with the necessary imports note that we\'re using tensorflow 2 here let\'s define an input layer where the shape would just be a vector of length 1 then we can define the shared part of the network which i\'m calling a backbone here it\'s a dense layer of size 4 which is already overkill for this problem but whatever we define each head with its own dense layer of size 4 and then a final dense layer of size 1 for the output oops i use the wrong name space here okay now we can define the structure of the model put the input through the backbone to get an intermediate representation put that through each of the heads to get the two outputs we can then use the keras model constructor to define the model fully with one input and two outputs if i can just get my variable names right looking through a summary of the model we see that it has 58 glorious parameters that feels too little and too much at the same time doesn\'t it training loop time let\'s get an optimizer ready i\'m going to use adam like 95 of the deep learning community and then get started on a training loop i\'m going to do a thousand iterations for now and within the loop we need this context manager to signal the tensorflow that we want to track gradients in the loop let\'s grab a random input between zero and one prepare the two outputs one of course is just multiplied by two and the other one is divided by two and then run the model on the input to get predictions compute the losses i\'m using two different losses here just for the heck of it just for demonstration and then we can add the losses together to get a final loss and i\'ll print it here in the training loop and in the future we\'ll regret that choice outside the context manager we can compute the gradients using this tape variable and calling this gradient method on it tape keeps track of all the variables involved in the computation inside the context manager and we need to pass both the loss output and the list of those variables to compute the loss finally we can apply these gradients using the optimizer by passing it the variables as well as the gradients themselves so i made two mistakes here one was i spelled the function gradient which is incorrect and two i forgot to zip the gradients and the washed variables together when passing them to the optimizer also three printing the loss wasn\'t very useful so let\'s store it in a list instead and plot nice the loss decreases and starts to plateau let\'s do some ad-hoc testing on the model we see that it does a decent job the first output gets pretty close to twice the input and the second output is a bit less accurate it could have something to do with us using a different loss for this output i\'m not quite sure i didn\'t really investigate so now we finally come to the original question that my colleague had which was how to train only on one loss at a time once you have things set up the way i\'ve shown here that part becomes super easy just don\'t include that loss in the final loss here i\'m commenting out loss 2 and removing it from the final sum but this can be done using if statements and flags as well you can have a lot of control once you\'ve written out your training loop explicitly this runs fine actually but it produces a lot of warnings because some of the washed variables by gradient type do not have a gradient this warning is harmless but it\'s pretty annoying and it can actually slow things down in certain cases just because of all the console spam that\'s being printed we can get rid of it by changing the apply gradients function call and explicitly picking only those variables that actually have a gradient computed and now the errors go away so we can go ahead and train we just lost one we get a proper output for head one but a random output for head two that makes sense we can then stop using loss one and only use loss two and continue training and we see that the second output is starting to work well but the first output has gotten a bit worse which is to be expected because the weights of the backbone are starting to drift away from that problem alrighty that is all i got for today hope this video was useful like subscribe tell your friends and i\'ll see you next time bye"", metadata={\'source\': \'KrS94hG4VU0\'})]""""""', '""""""[Document(page_content=""in this video we\'ll look at pf dot functions so let\'s go ahead and import the libraries first import tensorflow as tf and as we have seen in the previous video we\'ll try to create a function in python and then use the tf dot function decorator so tf so here we have def and the function let\'s say it\'s f which takes in two input well arguments x and y and what it returns is a square of x plus square of y and to this we are going to add the decorator tf dot function and so when the tensorflow executes this it will create a graph for this function now we can define the input values for x and y so x is equal to tf dot constant and let\'s say we have the values 1 and 2 and similarly for y i will create another variable here and the values would be minus 1 and minus 2. now when we call f with the input arguments x and y what we get in the output is the tensor which is shown over here which is a rank one tensor it has a shape of two and these are the values in the numpy array two and eight now we know that this is how the function is used in tensorflow let\'s look at a variation where we are trying to append a value to a list using function in python and let\'s see how tensorflow works with this so let\'s give this a heading called append and now here we\'ll create a function we\'ll first initialize the list so let\'s initialize the empty list and let\'s call this list as x list now we\'ll create a function and this would be df and let\'s call it f of x and within this function now we will create a for loop which such as like this for i in x print i colon i and then we are going to append so x list dot append i plus 1 so that\'s the function we have and to work with tensorflow we are going to add the decorator at tf dot function on top of this so with this then we can now create the input argument values so x is equal to tf dot constant and these values could be an array one dimensional so let\'s need the square bracket one two and three and now if we call f of x here and then if we try to print the value for our x list here we should see so what we see here is we have the uh tensor in the output which is this type as we can see here now the difference here is that the x list is outside of this function where we have the decorator and f of x and the for loop what the document suggest is instead of doing it like this there is an alternative way to do this using t t dot write so [Music] let\'s see how that would work we will create a function def function this is again f of x and here we\'ll create and tensor array t is equal to tf dot tensor array and we\'ll give it a data type the type is equal to tf dot in 32 and let\'s give it a size of zero and dynamic size is equal to true as new values get added it will change the size of t automatically and then we have the for loop here for i in range length of x which is the input argument we have and now to write to this tensor array that we initialized here we would simply write t is equal to t dot right and within this we specify i which is the value that we are getting in the for loop comma x i plus 1 so at each of these index we are going to add value of x i incremented by 1 and once that for loop is done we can then return this value t dot stack and now and finally we need to decorate this add tf dot function now if we initialize value of x such that x is equal to t f dot constant and here we specify values such as 1 2 and 3. now if we call f of x we get this output where we have a tensor as output and because everything here is in tensorflow uh this is the recommended way to perform append inside a function just using this dot write next let\'s let\'s look at concrete functions again we looked at this briefly in previous video we\'ll look at one example again in this video concrete functions and what concrete functions are are the few characteristics about the concrete functions are they\'re build on fly as the generic function is called as the generic function is called and again uh it is called every time that either the type changes or the shape changes or the python values then a new concrete function is created python arguments now let\'s see examples of these so we\'ll create a function again f of x and we\'ll start by decorating it with the tf dot function and then initialize sorry call it t f space f of x and then return the value of absolute value of x now with this if we call this function if we create uh f1 is equal to f dot get underscore concrete underscore function so we get the concrete function for f what this means is when we the when a tensorflow runs this particular function it creates a it will create a graph and the conc get concrete function will get the concrete function that is within that graph so we have done that for f1 and what we\'ll do next is we\'ll put a value here just an integer value of 1 within this as an input argument and then we\'ll create another function right here which is f2 we have f dot get underscore concrete underscore function and let\'s input a value of 2 now if we print with print if f1 is equal to f2 if then if f1 is f2 is it the same concrete function then in the output we see that it\'s set it\'s false and that tells us that when tensorflow created a graph while executing this function when the input value was 1 it was a different graph different concrete function within the graph and when the input value was 2 it was another concrete function in the graph now what happens when using in these situations is this particular execution becomes slow because a new graph is created a new concrete function is created within the graph so to make this work faster alternative is to input arguments that are tensorflow arguments so instead of input as of 1 we will say input where tf dot constant and here we have this rank 0 tensor so here we have tf dot constant and we specify 2 and this is now faster because the only one concrete function is created and that same concrete function is used in the second operation where we are trying to get the value for f2 additionally there are something called as input signatures and let\'s look at an example of that and again input signatures are another way to tell tensorflow that you can automatically convert some of the python items into tensorflow to make the quadrant faster create less concrete functions so let\'s create an uh function df f of x and we\'ll return a value of x plus one and here we\'ll add the decorator tf dot function now with this we\'ll create input values of x so let\'s first pass a vector and let\'s create that by calling tf dot constant and we can have values such as 1.0 and 2.0 next is equal to tf dot constant and we have two square records this time now if we try to get the concrete function f dot get underscore concrete underscore function using the x vector and then check if that is indeed the same from concrete function as we would get with the x matrix so f dot get underscore concrete underscore function x underscore matrix and here we see that that is not the case these two input arguments create different concrete functions within the tensorflow graph and that\'s because we have two different functions or two different shapes right here let\'s look at another example where we can update a tensorflow variable from within a function and this is a recommendation from tensorflow docs that the tf dot variable we defined outside of a function so let\'s see how we can do that tf dot variable is outside tf dot function and for let\'s say we define a variable var is equal to tf dot variable with the value of one and then we create the function add tf dot function and df f of x and here we have var dot assign add x so we are adding the value from x to the tf.variable and by doing this we should be able to update the tf dot variable that outside this function so now if we call f and we pass in the input argument tf dot constant let\'s say we pass in a value of 1 and now if we print var here we see that the value is updated to 2 so we incremented the value of 1 by adding this 1 to 2 and this is a recommended way of working with a variable other way that is also possible is the regular using a return statement within the function so let\'s say we have we defined c is equal to tf dot constant and assigned a value of 1 and then we create a function tf dot function and here we have we define f which takes into our input argument c and one so we have to pass in this as well as the incrementer that need to be added to c and within the inside the function then we can perform the operation and then return the value of c so here if we look at if we call this function f and we pass in the value c and then pass in the value of tf dot constant and value of 1 there now when we run this we get again the output 2 but the difference is that here the tensorflow variable is outside this function and in the output what we get is a variable whereas in this case the output that we get is a tensor now a couple of items to note as we move forward is tracing so in when the python is when tensorflow is computing a graph for a function the python operations are executed only once a python operations are executed only once and that\'s during the first time the code is run and for to test that let\'s try this function tf dot function and all these functions are directly from the docs so if you need more information you can always refer to the user guide df and here we can define f of a and b and sorry about that now if we print so printing at trace time and here we print the value of a is equal to a and then we print value of b is equal to is equal to b and then we return value of b so the first item let\'s say we said the value of a is equal to 1 and we said the value of b is equal to tf dot constant and let\'s say the value is again 1. now if we call the function with the input arguments a and b and when we look at the output we see that during the during tracing in the first cycle this was print the print statement was executed we have the value of a is equal to one assigned and b is equal to this particular tensor which is what we had passed here tf dot constant 1 and we have the value of 1 right here in the output that is returned by b now if we change the input values a little bit if we now say that we have the value of a is equal to 2 and if we have the value of b as the same as tf dot constant 1 and now if we run this this time again because we have this value that is different it will create another graph and therefore this line is printed again and so we have a is equal to 2 in the output and for b the return value of b we have 1 in the output now however if we now take this copy this uh let\'s say copy selection and now instead of changing the integer value of a if we change the value of b and now if you run this it uses the same graph as before so the print statement is not exactly executed python statement is ignored because the graph is already created and the reason why it is using the same graph is because the value of a is the same and the value for the tensor is the same shape and it\'s the same type so all we have done is replaced changed 1 by 2 and so in the output we get the value of b written as 2 as we can see here now let\'s look at a few ways in which tensorflow has provisions where we can allow it to automatically decide what atoms could be converted to tensorflow on data types so let\'s create a heading here using type annotations this is to improve performance the very first thing we\'ll try it is we\'ll create a function df and this is with hints and these examples again are directly from the docs here we specify x is equal to tf dot tensor as an input so that\'s could be the hint to tensorflow that incoming value could be represented as a tensor and here we can say tracing i\'m going to give this an arrow pointing left side and then we\'ll return a value of x and on top of this so let\'s try one more thing here we can use the tf dot function decorator this is the usual way we would write this but now for allowing annotations what we need to also input ntf dot function is experimental follow type hints is equal to true so that\'s why we have the name of the function with hints and copy this paste it here and what we\'ll do we\'ll also copy this line and we\'ll set it to false right here and rest of it stays the same and with will change the name of the function to no hints now with this setup let\'s run this uh with and with hints and no ends and see if what difference it makes the first item will try to run it will try to print f no hints and we\'ll pass in a value one and let me copy this and paste it here again we\'ll create a new line and similarly copy this and paste it here we have value of 2 and again a value of 2 here and we\'ll copy this entire block paste it down below and here we\'ll use the function with instead of no and here we have width and what i\'m going to do now is change all of these and now if we run this we should see the difference so as we can see here we have when we run without hints as we can see in the first two cases we have the value of tensor tf.tensor is one and we have the print statement executed in the second case also we have the print statement executed because we are not going giving tensorflow any hint that the values that are coming in could be represented as a tensor but when we specify a hints is equal to true in those cases when we pass in a value of 1 the tensorflow interprets it as a tensor and not just an integer and so while tracing while creating a graph it is it does print the print statement very first time but then second time it automatically detects these two as a tensor considers these two as a tensor and therefore it doesn\'t bother creating a new graph it uses the previous graph and therefore the tracing print statement is ignored and we just have this output right here so that was it for this video i hope in this video you got some additional information about how the tf dot function works in tensorflow we\'ll continue with other topics in tensorflow in following videos please like share and subscribe i hope to see you all in the next video thank you"", metadata={\'source\': \'iFZRUwGcrxQ\'})]""""""']","{'https://stackoverflow.com/questions/37441140/how-to-use-tf-while-loop-in-tensorflow', 'https://stackoverflow.com/questions/59332392/tf-function-and-tf-while-loop-in-tensorflow-2-0', 'https://stackoverflow.com/questions/41604686/how-to-use-tf-while-loop-for-variable-length-inputs-in-tensorflow', 'https://stackoverflow.com/questions/37571017/tensorflow-stuck-into-endless-loop-using-tf-while-loop', 'https://stackoverflow.com/questions/46768386/while-loop-error-in-tensorflow'}","['""""""How to use tf.while_loop() for variable-length inputs in tensorflow? Asked 7 years, 2 months ago\n\nModified 4 years, 4 months ago\n\nI am trying to use tf.while_loop() to process variable-length inputs. However, I can only use it for fixed length. The code no longer works after I change shape=(4) to shape=(None). tf.dynamic_rnn seems to handle variable-length inputs. I am not sure how tf.dynamic_rnn achieves this with tf.while_loop(). import tensorflow as tf import numpy as np from tensorflow.python.ops import tensor_array_ops from tensorflow.python.ops import array_ops with tf.Graph().as_default(), tf.Session() as sess: initial_m = tf.Variable(0.0, name=\'m\') inputs = tf.placeholder(dtype=\'float32\', shape=(4)) #The code no longer works after I change shape=(4) to shape=(None) #inputs = tf.placeholder(dtype=\'float32\', shape=(None)) time_steps = tf.shape(inputs)[0] initial_outputs = tf.TensorArray(dtype=tf.float32, size=time_steps) initial_t = tf.constant(0, dtype=\'int32\') def should_continue(t, *args): return t < time_steps def iteration(t, m, outputs_): cur = tf.gather(inputs, t) m = m * 0.5 + cur * 0.5 outputs_ = outputs_.write(t, m) return t + 1, m, outputs_ t, m, outputs = tf.while_loop( should_continue, iteration, [initial_t, initial_m, initial_outputs]) outputs = outputs.pack() init = tf.global_variables_initializer() sess.run([init]) print sess.run([outputs], feed_dict={inputs: np.asarray([1,1,1,1])})\n\noutput (before change):\n\n[array([ 0.5 , 0.75 , 0.875 , 0.9375], dtype=float32)]\n\noutput (after change):\n\nTraceback (most recent call last): File ""simple.py"", line 26, in <module> [initial_t, initial_m, initial_outputs]) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2636, in while_loop result = context.BuildLoop(cond, body, loop_vars, shape_invariants) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2469, in BuildLoop pred, body, original_loop_vars, loop_vars, shape_invariants) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2450, in _BuildLoop _EnforceShapeInvariant(m_var, n_var) File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 586, in _EnforceShapeInvariant % (merge_var.name, m_shape, n_shape)) ValueError: The shape for while/Merge_1:0 is not an invariant for the loop. It enters the loop with shape (), but has shape <unknown> after one iteration. Provide shape invariants using either the `shape_invariants` argument of tf.while_loop or set_shape() on the loop variables. 0\n\nIt works if you remove shapes from all the variables:\n\nimport tensorflow as tf import numpy as np config = tf.ConfigProto(graph_options=tf.GraphOptions( optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0))) tf.reset_default_graph() sess = tf.Session("""", config=config) #initial_m = tf.Variable(0.0, name=\'m\') #The code no longer works after I change shape=(4) to shape=(None) inputs = tf.placeholder(dtype=\'float32\', shape=(None)) time_steps = tf.shape(inputs)[0] initial_outputs = tf.TensorArray(dtype=tf.float32, size=time_steps) initial_t = tf.placeholder(dtype=\'int32\') initial_m = tf.placeholder(dtype=tf.float32) def should_continue(t, *args): return t < time_steps def iteration(t, m, outputs_): cur = tf.gather(inputs, t) m = m * 0.5 + cur * 0.5 outputs_ = outputs_.write(t, m) return t + 1, m, outputs_ t, m, outputs = tf.while_loop(should_continue, iteration, [initial_t, initial_m, initial_outputs]) outputs = outputs.stack() init = tf.global_variables_initializer() sess.run([init]) print(sess.run([outputs], feed_dict={inputs: np.asarray([1, 1, 1, 1]), initial_t: 0, initial_m: 0.}))\n\n\n\nYaroslav BulatovYaroslav Bulatov\n\n 4\n\nBTW, is it possible to avoid using placeholder? initial_t and initial_m are are alway zeros.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nHow to use tf.while_loop() in tensorflow\n\nAsked 8 years, 2 months ago\n\nModified 5 years, 7 months ago\n\nThis is a generic question. I found that in the tensorflow, after we build the graph, fetch data into the graph, the output from graph is a tensor. but in many cases, we need to do some computation based on this output (which is a tensor), which is not allowed in tensorflow. for example, I\'m trying to implement a RNN, which loops times based on data self property. That is, I need use a tensor to judge whether I should stop (I am not using dynamic_rnn since in my design, the rnn is highly customized). I find tf.while_loop(cond,body.....) might be a candidate for my implementation. But the official tutorial is too simple.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nHow to use tf.while_loop() in tensorflow\n\nAsked 8 years, 2 months ago\n\nModified 5 years, 7 months ago\n\nThis is a generic question. I found that in the tensorflow, after we build the graph, fetch data into the graph, the output from graph is a tensor. but in many cases, we need to do some computation based on this output (which is a tensor), which is not allowed in tensorflow. for example, I\'m trying to implement a RNN, which loops times based on data self property. That is, I need use a tensor to judge whether I should stop (I am not using dynamic_rnn since in my design, the rnn is highly customized). I find tf.while_loop(cond,body.....) might be a candidate for my implementation. But the official tutorial is too simple.""""""', '""""""tf.function and tf.while loop in Tensorflow 2.0\n\nAsked 3 years, 5 months ago\n\nModified 3 years, 5 months ago\n\nI am trying to parallelize loop using tf.while_loop. As suggested here, the parallel_iterations argument doesn\'t make a difference in the eager mode. So I attempted to wrap tf.while_loop with tf.function. However, after adding the decorator,the behavior of the iteration variable changes. For example, this piece of code works. result = np.zeros(10) iteration = tf.constant(0) c = lambda i: tf.less(i, 10) def print_fun(iteration): result[iteration] = iteration iteration += 1 return (iteration,) tf.while_loop(c, print_fun, [iteration])\n\nIf I add the decorator, bug occurs. result = np.zeros(10) iteration = tf.constant(0) c = lambda i: tf.less(i, 10) def print_fun(iteration): result[iteration] = iteration iteration += 1 return (iteration,) @tf.function def run_graph(): iteration = tf.constant(0) tf.while_loop(c, print_fun, [iteration]) run_graph()\n\nFrom my debugging process, I found that variable iteration changes from a tensor to a placeholder. Why is that?""""""', '""""""tf.function and tf.while loop in Tensorflow 2.0\n\nAsked 3 years, 5 months ago\n\nModified 3 years, 5 months ago\n\nI am trying to parallelize loop using tf.while_loop. As suggested here, the parallel_iterations argument doesn\'t make a difference in the eager mode. So I attempted to wrap tf.while_loop with tf.function. However, after adding the decorator,the behavior of the iteration variable changes. For example, this piece of code works. result = np.zeros(10) iteration = tf.constant(0) c = lambda i: tf.less(i, 10) def print_fun(iteration): result[iteration] = iteration iteration += 1 return (iteration,) tf.while_loop(c, print_fun, [iteration])\n\nIf I add the decorator, bug occurs. result = np.zeros(10) iteration = tf.constant(0) c = lambda i: tf.less(i, 10) def print_fun(iteration): result[iteration] = iteration iteration += 1 return (iteration,) @tf.function def run_graph(): iteration = tf.constant(0) tf.while_loop(c, print_fun, [iteration]) run_graph()\n\nFrom my debugging process, I found that variable iteration changes from a tensor to a placeholder. Why is that?""""""', '""""""I will edit my question based on your answer here\n\nWhat\'s the expected answer for your code? The global summ and ignoring the second body argument is suspicious: you probably want to pass 0. as the initial value for the second loop variable, and use the second body argument instead of the global summ as the accumulator. If you see this error: ValueError: The two structures don\'t have the same number of elements. If you see it in a while_loop, that means your inputs and outputs out of the while loop have different shapes. I solved it by making sure that I return the same structure of loop_vars from my while loop function, the condition function must also accept same loop vars. Here is an example code\n\nloop_vars = [i, loss, batch_size, smaller_str_lens] def condition(*loop_vars): i = loop_vars[0] batch_size = loop_vars[2] return tf.less(i, batch_size) def body(*loop_vars): i, loss, batch_size, smaller_str_lens = loop_vars tf.print(""The loop passed here"") ## logic here i = tf.add(i, 1) return i, loss, batch_size, smaller_str_lens loss = tf.while_loop(condition, compare_strings, loop_vars)[1]\n\nThe body func must return loop vars, and the condition func must accept loop vars\n\nbigGuy ubuntubigGuy ubuntu\n\n""""""']"
59531864,tf.nn.conv1d,example required,Why does TensorFlow calculate 2D convolutions when 1D convolution is called?,"<p>In the documentation of tf.nn.conv1d, it is stated that</p>

<blockquote>
  <p>Internally, this op reshapes the input tensors and invokes tf.nn.conv2d. For example, if data_format does not start with ""NC"", a tensor of shape [batch, in_width, in_channels] is reshaped to [batch, 1, in_width, in_channels], and the filter is reshaped to [1, filter_width, in_channels, out_channels]. The result is then reshaped back to [batch, out_width, out_channels] (where out_width is a function of the stride and padding as in conv2d) and returned to the caller.</p>
</blockquote>

<p>I get that the operations are equivalent, but I am a bit confused about the implications of this implementation detail. </p>

<p>Does the reshaping create some computational overhead? 
The 3D convolution has its own implementation, so why not the 1D convolution?</p>

<p>Thanks for any explanation that helps me and others to understand this implementation detail of TensorFlow!</p>
","<p>Digging through the source code, I conclude that it's likely done for convenience and minimalism of implementation - details below. </p>

<p>First, there is no ""reshaping"", only expanding, squeezing, and re-ordering dims, which bears a tiny overhead; no array elements are actually being moved in memory - only the tensor object's indexing specifiers are changed.</p>

<p>Second, all <code>conv</code> ultimately route to <a href=""https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/nn_ops.py#L942"" rel=""nofollow noreferrer""><code>tf.nn_ops.convolution_internal</code></a>, which then routes to either <code>gen_nn_ops.conv2d</code> or <code>gen_nn_ops.conv3d</code>; a <code>conv1d</code> does not exist in <code>gen_nn_ops.py</code>. Note that for some reason, you won't find that file in the Git respository - but it should be in your local install, <code>/python/ops/gen_nn_ops.py</code>.</p>

<p>Lastly, to get a real answer on why there isn't a dedicated <code>conv1d</code> implementation, you'll need to ask the cuDNN developers behind the convolution algorithms found in <code>gen_nn_ops.py</code>; it's possible that they found no performance improvements, and that <code>conv2d</code> works just as fast. From a low-level standpoint, this makes sense, as the number of matrix multiplications in sliding a kernel with <code>N x 1</code> elements along an <code>M x 1</code> input is identical to that of <code>N</code> along <code>M</code> - again, the only difference is in indexing.</p>

<p>Unfortunately devs decided to encapsulate the ultimate call, that is to <code>_pywrap_tensorflow_internal.TFE_Py_FastPathExecute</code>; the module consists of a <code>.lib</code> and a <code>.pyd</code> file - basically, compiled C (Cython) code that requires disassembly for introspection. </p>

<hr>

<p>TL;DR (1) the ""reshaping"" has a trivial overhead; (2) lack of a dedicated <code>conv1d</code> implementation is likely per sparing redundancy as <code>conv2d</code> is just as fast; (3) I'm not a cuDNN expert, so if you need to be sure, better ask over at <a href=""https://developer.nvidia.com/cudnn"" rel=""nofollow noreferrer"">cuDNN</a>, or read their <a href=""https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html"" rel=""nofollow noreferrer"">SDK Documentation</a>. Alternatively, a dev at <a href=""https://github.com/tensorflow/tensorflow/issues"" rel=""nofollow noreferrer"">TF Github</a> may help. I haven't seen cuDNN devs answer on SO for years now, so posting here may not be the best bet.</p>

<hr>

<p><strong>Dim reordering performance demo</strong>:</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
from time import time

x = np.random.randn(700, 800, 900) # 504,000,000 elements

t0 = time()
for i in range(1000):
    if i % 2 == 0:
        x = x.reshape(700, 900, 800)
    else:
        x = x.reshape(700, 800, 900)
print(time() - t0)
</code></pre>

<pre><code>0.0009968280792236328
</code></pre>
","Digging through the source code, I conclude that it's likely done for convenience and minimalism of implementation - details below.

First, there is no ""reshaping"", only expanding, squeezing, and re-ordering dims, which bears a tiny overhead; no array elements are actually being moved in memory - only the tensor object's indexing specifiers are changed.
Second, all <code>conv</code> ultimately route to <code>tf.nn_ops.convolution_internal</code>, which then routes to either <code>gen_nn_ops.conv2d</code> or <code>gen_nn_ops.conv3d</code>; a <code>conv1d</code> does not exist in <code>gen_nn_ops.py</code>. Note that for some reason, you won't find that file in the Git respository - but it should be in your local install, <code>/python/ops/gen_nn_ops.py</code>.

Lastly, to get a real answer on why there isn't a dedicated <code>conv1d</code> implementation, you'll need to ask the cuDNN developers behind the convolution algorithms found in <code>gen_nn_ops.py</code>; it's possible that they found no performance improvements, and that <code>conv2d</code> works just as fast. From a low-level standpoint, this makes sense, as the number of matrix multiplications in sliding a kernel with <code>N x 1</code> elements along an <code>M x 1</code> input is identical to that of <code>N</code> along <code>M</code> - again, the only difference is in indexing.

Unfortunately devs decided to encapsulate the ultimate call, that is to <code>_pywrap_tensorflow_internal.TFE_Py_FastPathExecute</code>; the module consists of a <code>.lib</code> and a <code>.pyd</code> file - basically, compiled C (Cython) code that requires disassembly for introspection.

(1) the ""reshaping"" has a trivial overhead; (2) lack of a dedicated <code>conv1d</code> implementation is likely per sparing redundancy as <code>conv2d</code> is just as fast; (3) I'm not a cuDNN expert, so if you need to be sure, better ask over at cuDNN, or read their SDK Documentation. Alternatively, a dev at TF Github may help. I haven't seen cuDNN devs answer on SO for years now, so posting here may not be the best bet.","<pre class=""lang-py prettyprint-override""><code>import numpy as np
from time import time

x = np.random.randn(700, 800, 900) # 504,000,000 elements

t0 = time()
for i in range(1000):
    if i % 2 == 0:
        x = x.reshape(700, 900, 800)
    else:
        x = x.reshape(700, 800, 900)
print(time() - t0)
</code></pre>

<pre><code>0.0009968280792236328
</code></pre>","['What is the internal implementation of tf.nn.conv1d in TensorFlow?', 'Does reshaping tensors in TensorFlow create computational overhead?', 'Why does TensorFlow use tf.nn.conv2d for implementing tf.nn.conv1d?', 'What are the performance implications of using tf.nn.conv1d compared to tf.nn.conv2d?', 'Are there any specific optimizations for 1D convolutions in TensorFlow?', 'How does TensorFlow handle data_format in tf.nn.conv1d and tf.nn.conv2d?', 'What are the best practices for using tf.nn.conv1d in TensorFlow?']","['Does reshaping tensors in tf.nn.conv1d create computational overhead?', 'Why does TensorFlow use tf.nn.conv2d internally for tf.nn.conv1d instead of having a separate implementation for 1D convolution?', 'What are the performance implications of using tf.nn.conv2d for 1D convolution in TensorFlow?', 'Are there any benefits to using tf.nn.conv2d for implementing tf.nn.conv1d in TensorFlow?', 'How does the reshaping of tensors in tf.nn.conv1d affect memory usage and computational efficiency?']",set(),[],{'https://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow'},"['"""""" What does tf.nn.conv2d do in tensorflow? Asked 8 years, 5 months ago\n\nModified 3 years, 1 month ago\n\nI was looking at the docs of tensorflow about tf.nn.conv2d here. But I can\'t understand what it does or what it is trying to achieve. It says on the docs,\n\n#1 : Flattens the filter to a 2-D matrix with shape\n\n[filter_height * filter_width * in_channels, output_channels]. Now what does that do? Is that element-wise multiplication or just plain matrix multiplication? I also could not understand the other two points mentioned in the docs. I have written them below :\n\n# 2: Extracts image patches from the the input tensor to form a virtual tensor of shape\n\n[batch, out_height, out_width, filter_height * filter_width * in_channels]. # 3: For each patch, right-multiplies the filter matrix and the image patch vector. It would be really helpful if anyone could give an example, a piece of code (extremely helpful) maybe and explain what is going on there and why the operation is like this. I\'ve tried coding a small portion and printing out the shape of the operation. Still, I can\'t understand. I tried something like this:\n\nop = tf.shape(tf.nn.conv2d(tf.random_normal([1,10,10,10]), tf.random_normal([2,10,10,10]), strides=[1, 2, 2, 1], padding=\'SAME\')) with tf.Session() as sess: result = sess.run(op) print(result)\n\nI understand bits and pieces of convolutional neural networks. I studied them here. But the implementation on tensorflow is not what I expected. So it raised the question. EDIT: So, I implemented a much simpler code. But I can\'t figure out what\'s going on. I mean how the results are like this.""""""']"
55422537,tf.estimator.DNNClassifier,example required,Testing TF serving model fails with bytes as strings and strings as bytes confusion,"<p>I'm having a problem serving my text classification model on <code>Tensorflow 1.12</code>. I'm using <code>tf.estimator.inputs.pandas_input_fn</code> to read in my data, and <code>tf.estimator.DNNClassifier</code> to train/evaluate. I'd then like to serve my model.
(Apologies in advance, it's tough to provide a full working example here, but it's very much like the example TF provides at <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier</a>  )</p>

<p>I'm currently saving my model with ...</p>

<pre class=""lang-py prettyprint-override""><code>...
estimator.export_savedmodel(""./TEST_SERVING/"", self.serving_input_receiver_fn, strip_default_attrs=True)
...
def serving_input_receiver_fn(self):
      """"""An input receiver that expects a serialized tf.Example.""""""

      # feature spec dictionary  determines our input parameters for the model
      feature_spec = {
          'Headline': tf.VarLenFeature(dtype=tf.string),
          'Description': tf.VarLenFeature(dtype=tf.string)
      }

      # the inputs will be initially fed as strings with data serialized by
      # Google ProtoBuffers
      serialized_tf_example = tf.placeholder(
          dtype=tf.string, shape=None, name='input_example_tensor')
      receiver_tensors = {'examples': serialized_tf_example}

      # deserialize input
      features = tf.parse_example(serialized_tf_example, feature_spec)
      return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)


</code></pre>

<p>This actually fails to run with the error:</p>

<pre class=""lang-sh prettyprint-override""><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt; to Tensor. Contents: SparseTensor(indices=Tensor(""ParseExample/ParseExample:0"", shape=(?, 2), 
dtype=int64), values=Tensor(""ParseExample/ParseExample:2"", shape=(?,), dtype=string), dense_shape=Tensor(""ParseExample/ParseExample:4"", shape=(2,), dtype=int64)). Consider casting elements to a supported type.

</code></pre>

<p>I tried to save a second way doing:</p>

<pre class=""lang-py prettyprint-override""><code>def serving_input_receiver_fn(self):
  """"""Build the serving inputs.""""""
  INPUT_COLUMNS = [""Headline"",""Description""]
  inputs = {}
  for feat in INPUT_COLUMNS:
    inputs[feat] = tf.placeholder(shape=[None], dtype=tf.string, name=feat)
  return tf.estimator.export.ServingInputReceiver(inputs, inputs)
</code></pre>

<p>This actually works, until I try testing it with the <code>saved_model_cli</code>.
Some output for <code>saved_model_cli show --all --dir TEST_SERVING/1553879255/</code>:</p>

<pre class=""lang-sh prettyprint-override""><code>MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['predict']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['Description'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Description:0
    inputs['Headline'] tensor_info:
        dtype: DT_STRING
        shape: (-1)
        name: Headline:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['class_ids'] tensor_info:
        dtype: DT_INT64
        shape: (-1, 1)
        name: dnn/head/predictions/ExpandDims:0
    outputs['classes'] tensor_info:
        dtype: DT_STRING
        shape: (-1, 1)
        name: dnn/head/predictions/str_classes:0
    outputs['logits'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/logits/BiasAdd:0
    outputs['probabilities'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 3)
        name: dnn/head/predictions/probabilities:0
  Method name is: tensorflow/serving/predict

</code></pre>

<p>But now I can't seem to test it.</p>

<pre class=""lang-sh prettyprint-override""><code>&gt;&gt;&gt; saved_model_cli run --dir TEST_SERVING/1553879255/ --tag_set serve --signature_def predict --input_examples 'inputs=[{""Description"":[""What is going on""],""Headline"":[""Help me""]}]'
Traceback (most recent call last):
 ...
  File ""/Users/Josh/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py"", line 489, in _create_example_string
    feature_list)
TypeError: 'What is going on' has type str, but expected one of: bytes

</code></pre>

<p>Ok, lets turn it into a bytes object by changing to <code>b[""What is going on""]</code> and <code>b[""Help me""]</code>...</p>

<pre class=""lang-sh prettyprint-override""><code>ValueError: Type &lt;class 'bytes'&gt; for value b'What is going on' is not supported for tf.train.Feature.
</code></pre>

<p>Any ideas/thoughts??
Thanks!</p>
","<p>Ok, so eventually I found the answer, quoted in <a href=""https://stackoverflow.com/questions/51482730/tensorflow-how-to-export-estimator-using-tensorhub-module"">TensorFlow: how to export estimator using TensorHub module?</a> </p>

<p>The problem was with serialization stuff I don't really understand. The solution allows to pass raw strings to <code>tf.estimator.export.build_raw_serving_input_receiver_fn</code> instead.</p>

<p>My saving funciton now looks like this:</p>

<pre class=""lang-py prettyprint-override""><code>  def save_serving_model(self,estimator):
      feature_placeholder = {'Headline': tf.placeholder('string', [1], name='headline_placeholder'),
      'Description': tf.placeholder('string', [1], name='description_placeholder')}
      serving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholder)

      estimator.export_savedmodel(""TEST_SERVING/"", serving_input_fn)
</code></pre>

<p>where using the <code>saved_model_cli</code> works. I.e.:</p>

<pre class=""lang-sh prettyprint-override""><code>saved_model_cli run --dir /path/to/model/ --tag_set serve --signature_def predict --input_exprs=""Headline=['Finally, it works'];Description=['Yay, it works']"" 

</code></pre>

<pre class=""lang-sh prettyprint-override""><code>Result for output key class_ids:
[[2]]
Result for output key classes:
[[b'2']]
Result for output key logits:
[[-0.56755465  0.31625098  0.39260274]]
Result for output key probabilities:
[[0.16577701 0.40119565 0.4330274 ]]
</code></pre>
",,"<pre class=""lang-py prettyprint-override""><code>  def save_serving_model(self,estimator):
      feature_placeholder = {'Headline': tf.placeholder('string', [1], name='headline_placeholder'),
      'Description': tf.placeholder('string', [1], name='description_placeholder')}
      serving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholder)

      estimator.export_savedmodel(""TEST_SERVING/"", serving_input_fn)
</code></pre>

<p>where using the <code>saved_model_cli</code> works. I.e.:</p>

<pre class=""lang-sh prettyprint-override""><code>saved_model_cli run --dir /path/to/model/ --tag_set serve --signature_def predict --input_exprs=""Headline=['Finally, it works'];Description=['Yay, it works']"" 

</code></pre>

<pre class=""lang-sh prettyprint-override""><code>Result for output key class_ids:
[[2]]
Result for output key classes:
[[b'2']]
Result for output key logits:
[[-0.56755465  0.31625098  0.39260274]]
Result for output key probabilities:
[[0.16577701 0.40119565 0.4330274 ]]
</code></pre>","['How to use tf.estimator.inputs.pandas_input_fn in TensorFlow 1.12', 'How to train and evaluate a text classification model using tf.estimator.DNNClassifier', 'How to export a TensorFlow model for serving using tf.estimator.export_savedmodel', 'How to define a serving_input_receiver_fn for text data in TensorFlow', 'How to handle SparseTensor in TensorFlow serving input functions', 'How to test a TensorFlow SavedModel using saved_model_cli', 'How to format input examples for saved_model_cli in TensorFlow', 'Common issues and solutions when serving TensorFlow models with text inputs']","['How to properly use tf.estimator.export.ServingInputReceiver with tf.VarLenFeature in TensorFlow 1.12?', 'How to handle SparseTensor conversion error in TensorFlow 1.12 when using tf.estimator.export.ServingInputReceiver?', 'How to test a TensorFlow model saved with tf.estimator.export.ServingInputReceiver using saved_model_cli?', 'How to format input examples for saved_model_cli when using tf.estimator.export.ServingInputReceiver?', 'How to convert string inputs to bytes for tf.train.Feature in TensorFlow 1.12?']",set(),[],"{'https://stackoverflow.com/questions/46098863/how-to-import-an-saved-tensorflow-model-train-using-tf-estimator-and-predict-on', 'https://stackoverflow.com/questions/42835809/how-to-export-estimator-model-with-export-savedmodel-function'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nThe 2024 Developer Survey results are live! See the results\n\nHow to export Estimator model with export_savedmodel function\n\nAsked 7 years, 4 months ago\n\nModified 5 years, 9 months ago\n\nare there any tutorials available about export_savedmodel ? I have gone through this article on tensorflow.org and unittest code on github.com, and still have no idea about how to construct the parameter serving_input_fn of function export_savedmodel\n\n 2\n\nExample of export_savedmodel function\n\n\n\nCheck sol provided here stackoverflow.com/questions/58959582/â€¦\n\n\n\nyour_feature_spec = { ""some_feature"": tf.FixedLenFeature([], dtype=tf.string, default_value=""""), ""some_feature"": tf.VarLenFeature(dtype=tf.string), } def _serving_input_receiver_fn(): serialized_tf_example = tf.placeholder(dtype=tf.string, shape=None, name=\'input_example_tensor\') # key (e.g. \'examples\') should be same with the inputKey when you # buid the request for prediction receiver_tensors = {\'examples\': serialized_tf_example} features = tf.parse_example(serialized_tf_example, your_feature_spec) return tf.estimator.export.ServingInputReceiver(features, receiver_tensors) estimator.export_savedmodel(export_dir, _serving_input_receiver_fn)\n\nThen you can request the served model with ""predict"" signature name by batch. Source: https://www.tensorflow.org/guide/saved_model#prepare_serving_inputs\n\n2\n\nusing feature_spec = {\'x\': tf.FixedLenFeature([224, 224, 3], dtype=tf.float32)} i got the error: TypeError: Failed to convert object of type <type \'dict\'> to Tensor\n\n\n\nThe signature is \'predict\', is there a way to specify custom signature? Or set back to the \'serving_default\'. if you are using tensorflow straight from the master branch there\'s a module tensorflow.python.estimator.export that provides a function for that:\n\nfrom tensorflow.python.estimator.export import export feature_spec = {\'MY_FEATURE\': tf.constant(2.0, shape=[1, 1])} serving_input_fn = export.build_raw_serving_input_receiver_fn(feature_spec)\n\nUnfortunately at least for me it will not go further than that but I\'m not sure if my model is really correct so maybe you have more luck than I do. Alternatively, there are the following functions for the current version installed from pypi:\n\nserving_input_fn = tf.contrib.learn.utils.build_parsing_serving_input_fn(feature_spec) serving_input_fn = tf.contrib.learn.utils.build_default_serving_input_fn(feature_spec)\n\nBut I couldn\'t get them to work, too. Probably, I\'m not understanding this correctly so I hope you\'ll have more luck. Christian SchneiderChristian Schneider\n\nExport your model to work with JSON dictionaries\n\nIn my mlengine-boilerplate repository, I use this to export estimator models to Cloud ML Engine to easily use this with online predictions (sample code for the predictions). Essential part:\n\ndef serving_input_fn(): feature_placeholders = { \'id\': tf.placeholder(tf.string, [None], name=""id_placeholder""), \'feat\': tf.placeholder(tf.float32, [None, FEAT_LEN], name=""feat_placeholder""), #label is not required since serving is only used for inference } return input_fn_utils.InputFnOps( feature_placeholders, None, feature_placeholders)\n\nExport your model to work with Tensorflow Examples\n\nThis tutorial shows how you can use export_savedmodel to serve the Wide & Deep Model implemented with estimators and how to feed Tensorflow examples into the exported model. The essential part:\n\nfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utils serving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\n\n\n\n1,4\n\nI updated the tutorial to support r1.3. You should probably update your answer to reflect new changes.""""""', '""""""MarquesDeCampoMarquesDeCampo\n\n1\n\nCould you add the Java side of the prediction to this answer, please? Mainly to see how you are preparing the input for build_parsing_serving_input_receiver_fn in Java. â€“ Stephen Newell Apr 17, 2018 at 16:04\n\nIt appears that the TensorFlow team does not agree that there is a bug in version 1.3 using canned estimators for exporting a model under use case #2. I submitted a bug report here: https://github.com/tensorflow/tensorflow/issues/13477\n\nThe response I received from TensorFlow is that the input must only be a single string tensor. It appears that there may be a way to consolidate multiple features into a single string tensor using serialized TF.examples, but I have not found a clear method to do this. If anyone has code showing how to do this, I would be appreciative. Ben FowlerBen Fowler\n\nYou need to export the saved model using tf.contrib.export_savedmodel and you need to define input receiver function to pass input to. Later you can load the saved model ( generally saved.model.pb) from the disk and serve it. TensorFlow: How to predict from a SavedModel? sudharsan tksudharsan tk\n\n""""""']"
52572275,tf.scatter_nd,example required,tensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)?,"<p>I've read the <a href=""https://www.tensorflow.org/api_docs/python/tf/manip/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_nd documentation</a> and run the example code for 1D and 3D tensors... and now I'm trying to do it for a 2D tensor.  I want to 'interleave' the columns of two tensors.  For 1D tensors, one can do this via</p>

<pre><code>'''
We want to interleave elements of 1D tensors arr1 and arr2, where
arr1 = [10, 11, 12]
arr2 = [1, 2, 3, 4, 5, 6]
such that
desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12]
'''

import tensorflow as tf

with tf.Session() as sess:

    updates1 = tf.constant([1,2,3,4,5,6])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)

    updates2 = tf.constant([10,11,12])
    indices2 = tf.constant([[2], [5], [8]])
    scatter2 = tf.scatter_nd(indices2, updates2, shape)

    result = scatter1 + scatter2

    print(sess.run(result))
</code></pre>

<p>(aside: is there a <em>better</em> way to do this?  I'm all ears.)</p>

<p>This gives the output</p>

<p><code>[ 1  2 10  3  4 11  5  6 12]</code></p>

<p>Yay! that worked!</p>

<p>Now lets' try to extend this to 2D.</p>

<pre><code>    '''
    We want to interleave the *columns* (not rows; rows would be easy!) of

    arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]
    arr2 = [[10 11 12], [10 11 12], [10 11 12]]
    such that
    desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]]
    '''

    updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([3, 9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)
</code></pre>

<p>This gives the error
<code>ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1
dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but
are 6 and 3. Shapes are [6] and [3]. for 'ScatterNd_2' (op: 'ScatterNd') with
input shapes: [6,1], [3,6], [2].</code></p>

<p>Seems like my <code>indices</code> is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean
I need to <em>explicitly</em> specify every single pair of indices for every element in <code>updates1</code>?
Or is there some kind of 'wildcard' specification I can use for the rows? (Note <code>indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]])</code> gives syntax errors, as it probably should.)</p>

<p>Would it be easier to just do a transpose, interleave the rows, then transpose back?
Because I tried that...</p>

<pre><code>scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))
print(sess.run(tf.transpose(scatter1)))
</code></pre>

<p>...and got a <em>much</em> longer error message, that I don't feel like posting unless someone requests it. </p>

<p>PS- I searched to make sure this isn't a duplicate -- I find it hard to imagine that someone else hasn't asked this before -- but turned up nothing. </p>
","<p>This is pure slicing but I didn't know that syntax like <code>arr1[0:,:][:,:2]</code> actually works. It seems it does but not sure if it is better.</p>

<p>This may be the <em>wildcard</em> slicing mechanism you are looking for.</p>

<pre><code>arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]])
arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]])

with tf.Session() as sess :
    sess.run( tf.global_variables_initializer() )
    print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1],
                              arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2],
                              arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))
</code></pre>

<p>Output is</p>

<pre><code>[[ 1  2 10  3  4 11  5  6 12]
 [ 1  2 10  3  4 11  5  7 12]
 [ 1  2 10  3  4 11  5  8 12]]
</code></pre>

<p>So, for example,</p>

<p><code>arr1[0:,:]</code> returns</p>

<pre><code>[[1 2 3 4 5 6]
 [1 2 3 4 5 7]
 [1 2 3 4 5 8]]
</code></pre>

<p>and <code>arr1[0:,:][:,:2]</code> returns the first two columns</p>

<pre><code>[[1 2]
 [1 2]
 [1 2]]
</code></pre>

<p>axis is 1.</p>
","This is pure slicing but I didn't know that syntax like <code>arr1[0:,:][:,:2]</code> actually works. It seems it does but not sure if it is better. This may be the <em>wildcard</em> slicing mechanism you are looking for.","<pre><code>arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]])
arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]])

with tf.Session() as sess :
    sess.run( tf.global_variables_initializer() )
    print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1],
                              arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2],
                              arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))
</code></pre>","['How to use tf.scatter_nd for 2D tensors in TensorFlow?', 'Interleaving columns of two 2D tensors using TensorFlow', 'Handling indices for tf.scatter_nd with 2D tensors', 'Efficient ways to interleave columns of 2D tensors in TensorFlow', 'Using tf.scatter_nd with multi-dimensional tensors', 'Common errors and solutions when using tf.scatter_nd for 2D tensors', 'Alternatives to tf.scatter_nd for interleaving columns in TensorFlow', 'Step-by-step guide to interleave columns of 2D tensors in TensorFlow']","['How to interleave columns of two 2D tensors using TensorFlow?', 'How to use tf.scatter_nd for 2D tensors in TensorFlow?', 'Is there a way to specify wildcard indices in tf.scatter_nd for TensorFlow?', 'How to handle indices for column-wise operations in TensorFlow?', 'Best practices for interleaving columns of 2D tensors in TensorFlow', 'How to transpose tensors for interleaving columns and then transpose back in TensorFlow?', 'Common errors and solutions when using tf.scatter_nd for 2D tensors in TensorFlow']","{'https://www.youtube.com/watch?v=e1B7l3smXFE', 'https://www.youtube.com/watch?v=9buk4Z_JlXk'}","['""""""[Document(page_content=""hey it\'s no no and I\'m gonna show you how to do some operations with tensorflow in Python so first thing we\'re gonna do is make sure we can run Python code so the easiest way that I know of you can go to collab dot research google.com so you can use Google collab which is a version of I think it\'s a version of Jupiter lab in size Google servers so you can run a notebook in no time and they even have support for not only CPU but GPU and TPU for free so if you go here change the run type and click on GPU you can to get the most out of color about using GPU unless you need one learn more let\'s see what they say here in order to be able to offer computational research for free kolja maintains flexibility to adjust on the fly we have heard for many users who want faster GPUs longer running notebooks and memory as well as usage limits are higher and don\'t flip to it as much introducing call approach the first step we\'re taking towards having users want to do more in collab so there seems to be plans for Google to scale this so there is $10 a month recurring billing and you can get access to that faster if you use longer time more memory what kinds of GP are available call a pro ka DSP 100 T fors and I\'m looking to connect up to 24 hours and little time ups are relatively lenient in the free version they can run for at most 12 hours needle time is much stricter than in color Pro so this seems to be a good alternative we can use the free version and that will let us run with whatever we want right now so first thing that we can do let\'s just make this a bit bigger so we import tensorflow TF execute that and then we can just print TF version to see what version of tensorflow we\'re gonna have available ones our kernel initialize you see now we\'re connected this is going to be executed we have to point to release candidate three so not even two point one we have two point two we can also run a command to see the version that we\'re running with Python so this might be I don\'t know I would guess three point yeah three point six point nine and now we can start going so we could do a simple operation with tensor so easiest thing is like we can create a tensor from an array so for instance we have this data and we want to make a tensor so that tensor that we got here I don\'t know why this is taking so long right now yeah we have a tensor shape three integer 32 with that we can perform simple operations within a tensor as if we were just performing math so we can do tensor plus one for instance and that you see just adds one to each member if we log the tensor once again we have the original if we want to modify it we will have to do this or with better syntax we can just do that so now our tensor has changed to two three four if we want to preview that ten Serena or human-readable wave and though we\'re losing information we do tensor numpy so you can just see the actual array with the contents of that tensor and let\'s see what else can we do so we can perform multiplications so let\'s say we do let\'s see if we can work out with this so supply by 2 and then numpy yep so yeah so let\'s see if we do that yeah so we just get the valley is there execution yeah so that\'s multiplying this by 2 you can see each component of course we can also do division but that that\'s a still a bit boring so let\'s go back to let\'s say we multiply by 0.5 so we get back our whoo integer so maybe we define I\'m gonna do that so huh so we cannot divide by 2 so we can do tensor equals tensor maybe that that\'s a bit better okay so let\'s go back so now we\'ve seen some operations let\'s go back and define that\'s with it before our tensor as 1 2 3 so we can do for example run TF squeeze our tensor that\'s not gonna do anything because our tensor is already flattened we can try TF gather and we tell we won from that tensor we want element 0 right what this is gonna do to see these index is getting this item and if we do 0 1 2 we\'re gonna get element 0 1 and 2 we get the same tensor but if we have values here we could get you see for example element 0 element 1 then element 0 then Y element 1 dang element 2 for x and we gathered those elements in a new tensor and we\'ll have a comment there it\'s you see we have these numbers here so we\'ve gathered the values at these indices from this tensor that were specifying here in a new tensor so that\'s a really good way to to just grab values from another tensor so let\'s try to do so this has shape so it\'s 8 so let\'s make it shape 9 so for instance to make it more apparent let\'s just make this be this so 1 1 1 2 2 2 so we\'re gonna get you know 0 0 0 so 1 1 1 2 2 2 3 3 3 so we can do now to convert this into an image right something that would be represented a tensor that represents a 3d image we can do now so let\'s say our tensor with gather right it\'s gonna be this and we now you know we have this tensor but we want it to be on the shape of 3 by 3 by 3 right so this means that we have three items in the in the X 3 items on the Y with three items each right so let\'s see let\'s see how we can get that we are looking for a tensor with shape so at any time you can say okay what\'s your shape right so we print and just note that in any notebook the last statement that you put is printed here but if you have more code below so let\'s say I define a variable that\'s gonna get printed so if you want to print multiple things where things are not the last line of a block in a Jupiter notebook you have to print for sure okay so we have a tensor that is shaped 9 and what we want to do is use the function reshape then start gather and the shape that we want to try to to do is so let\'s specify here and shape is going to be 3 3 3 let\'s see what it says okay input to reshape an internship with 9 values by the request it has 27 so here what we actually would be able to get is the tensor that you know has this shape I just mock it up here so X Y Z 3 x right so the shape of this tensor is actually let\'s actually debug that so we would get right so let\'s say that we have this and then our tensor or this is an array has that value we can print our array so that\'s our array right so we can actually do DF convert to tensor array and then ask for its shape so wait sir so we\'re gonna print that shape okay so it\'s three three so what we can actually do in the tensor that we had here is that we can do reshape tensor gather and now specify our shape is gonna be three three you know so now these tensor here that was a flat array has been reshaped into three by three matrix and what do we need to make it an image right so let\'s say we can just add another code block here and our tensor image maybe we can do gather mmm tensor gather well we want to keep this reshape right so tensor gather reshaped I\'m naming these things too long but you know you can just name the tensor the same way all the way down and just have one variable we\'re replacing its value so we have this here and we\'re gonna pick now so you can see how if I do here in this tends to reshape gather we have to run that block so now if I print tensor gather reshaped you see this value here right and the shape is three three let\'s see if we can get well can we get so DF yeah so we have here perfect power thanks very much so we\'re gonna gather maybe a element zero right so that gives us this so let\'s see we make this okay we get it inside of another race or the shape this is one one three so this is actually an image with just one row right x equals 1 y equals 3 3 you can see so what we\'re gonna do is well actually it\'s 1 1 so sorry so the image the image would be with equals 1 height equals 1 right there is 1 1 there is only one element 1 pixels with 3 RGB colors and those are RGB is 1 1 1 so our in that pixel we have our G B equals 1 1 1 okay so what we want to do is get an image that is not 1 pixel but 9 pixels so 3 by 3 how do we do that so we can do instead of doing this reshaping what we can do is we can get 3 pixels with the first color so 1 1 1 and now 3 pixels with the first color and later okay so we have 1 array second array and then the third array is gonna be the third color we\'re going to see how that looks axis must be color okay so let\'s wrap this up on an array all right so now we have I think we over we overdid it but we are going to do a different thing so we\'re going to take out this elements have this look all right so maybe we just needed to do this yeah let\'s just make it from scratch so we specify we want three rows right and we\'re gonna have 0 1 & 2 ok so now we have an array for the first row 1 pixel an array so this is 3 by 1 ok and now we have 3 1 & 2 so that\'s gonna give us a 3 by 3 matrix right you see so we have 3 by 3 the 3 pixels on the top row are RGB 1 1 1 then RGB - to 210 RGB 3 3 3 this is already animated how do we visualize it let\'s just load hmm mat lot live pipe lot oh that was a Randy\'s help and now we can do easily is PLT in the show and we haven\'t really oh yeah tensor image we have a variable there and PLT show I\'m sure I\'m missing something but let\'s see if this visualizes alright so we actually have it right we can take out the the axis if we want by running axis off and we can do a bunch of things with pie plot you can see you there\'s nothing really there because the pixel colors that were using our 1 1 1 2 2 2 & 3 2 3 but we can go to something like Photoshop or the color picker here in Google and I\'m gonna get this color so this is these 3 values which is before getting more colors from there right yeah so all right so what we need to do is we need to define our colors here so we\'re gonna have our first color it\'s gonna be that one second we\'ll change it later now so these are three colors I\'m just gonna get two more so let\'s say we get blue and then some yellow all right let\'s clean this up a bit so we have our colors so colors here that works so let\'s see colors I\'m not sure if this is gonna work with this that is say an array is not a tensor we\'ll just try it so from colors I\'m gonna do that gathering you see so we have a row with three pixels with bread three pictures with blue three pixels with yellow now we render this whoa nice so we actually get that working it\'s such a simple image I think this is the flag of some country again remember so you know the image what makes the tensor an image is just its dimensions so here we have a three by three by three matrix so this means that we have three rows on the x3 so actually there will be three columns in the x3 rows on the Y and then three three values per per pixel that represent the color for that pixel this image could actually be easily turned into RGB if we just specify one one value per image right so we have a three one three so that\'s actually not what I wanted so that would be I don\'t know if I can do it like this not really okay so I\'m not sure right now because we want it to be three by three oh okay so actually what we need to do is make because you know the the shape of the array is being inferred by the data we\'re feeding into right and these colors are RGB colors right so these are RGB colors what we will need to do is have gray sky colors which you know the only difference is that we instead of three elements RGB which is have one so the brightness so zero would be black and then 27 would be gray and 255 would be white and now this would be our element zero element 1 and element 2 of our colors array so we\'re going to go to say that our colors are going to be the the grayscale colors and when we do this gather operation now we get a 3 by 3 matrix but without any depth in the in the Y so in the third dimension so if we try to plot this you see what what happens here this is actually already a grayscale image the only problem or no problem the good thing is this color palette is a color palette that mudblood leaf adds when we have black and white color map that the black and white color map gets represented with whatever color map we specify here so for example you know that Inferno has diagram that is with red colors and they\'re they\'re a ton of colors that you can use here so see map my plot live and I don\'t know there dozens if not hundreds of of gamuts let\'s see you you see so you can use any of these names here so cool for example we use cool you see that\'s gonna use this color palette here but you know you might not want a color palette because we were saying that we had a black and white image we didn\'t really have a color image so what can we do there we can pre-process the image so real image let\'s say there are a few things we can do so we can I think the easiest is if we do TF Kara\'s pre-processing image and then array to image function and we pass our tensor image through there so that\'s our real image and then we show the real image who expected image to have rank three single image color right with shape three three right so what\'s happening here is that this image even though madly plot plot said that\'s an image is not having the dimensions of a three by three image with a single channel that would be three three one so what we\'re gonna try to do is reshape so black and white image let\'s call it image black and white we\'re just gonna do a reshape of our tensor image and we\'re gonna put it the shape of so three three one let\'s see what happens okay so that works let\'s see what Apple we\'re getting you see so that\'s three three one what happened is that those pixels go flat got flattened on the x-axis to be independent components and but we still have the zero 127 and two to five what happens here I think if we run this visualization with the tensor image we\'re going to get the same that before right Matt leaves still understands it\'s a black and white image but is rendering it with my map that you choose and but we said that\'s not what we wanted what we wanted is to render the actual black and white image so we pre process the image with Kerris so it transforms that black and white image into an actual image that can be rendered see the path see this we run that and okay again we don\'t get that and this is because I\'m not using it means black and white all right let\'s see okay so Kara\'s helps us process images sometimes but not always so last resource I\'m gonna try is tensor black and white is TF image grayscale to RGB and we\'re gonna pass our image black and white and this is what we are gonna try to render here okay and now that we\'re we\'ve done that all the way through so this is what we actually have that is rendering the actual image even though what we\'ve done and you can take a look at that here so if we print the tensor black and white you know what it\'s actually done is make those colors a three component one so we actually have a black and white image but we\'re wasting information because we\'re using two more components that we need to pair a pixel whereas you can encode that image in a three by three by one tensor so just to you know to the pic that this was working properly I\'m just gonna make let\'s see if we can make a more complex example where we we make a gradient right and an image that has a gradient in colors so let\'s say I don\'t know let\'s just make a loop here and make a tensor that has so X is going to be let\'s just start with 1 9 by 9 so 9 by 9 for e in range X tax we have the grey colors are going to stay the same and we\'re gonna put this in a different block so okay we get that there we just wanted this one okay so we\'re getting that and you know we would get here an image that is 3 3 by 3 by 3 because we\'re using one component we\'re just gonna do that and you know that way we\'ll get a tensor that has 9 by 9 so that\'s a big image well really small image in terms of real images but big for the amount of numbers we\'ve been working with in this in this notebook and you know I\'m just gonna do it the old way so we have an array of numbers that is empty and we\'re gonna append each of those numbers there and now we\'re gonna log our array right so we have a big array of numbers the first thing we\'re gonna do is get our so array as tensor so TF convert to tensor and we put that array in and we\'re not gonna see it because we didn\'t print it so we just want to bring that here alright so we have that how do we need to reshape it right so we just reshape our array as tensor us and then the shape is going to be what we said before right it\'s gonna be 3 by 3 by 1 but in this case is X by Y so whatever size we need it and now you see that you know we have that gradient where the tensor has is pleated has it split although values that we\'re gonna represent the scholars across the gamut so across the rows and columns of the of the pixels right from here we can see we\'re gonna go from black to some shade of dark gray and we\'re gonna try then we\'ll try to fix it later but we already have a tensor that we don\'t really need to map with any colors or anything so we can actually just delete all this stuff that we\'ve done to gather our tensors and stuff and we\'re just going to do the representation so we\'re just gonna show that a Reyes tensor let\'s see if that works okay invalid shape 81 for image data so we are going to try here to parse that as an image with carrots pre-processing spec the image have a rank okay this is the same problem we saw before I thought with this we will be able to not have it but we\'re gonna do a conversion of her image sensor and first game which was you to dimension okay let\'s actually inspect this element so we have a nine by nine by one which should be black and white image but we\'re not saving it okay so we didn\'t save it so my bad and we probably should have gone with doing this set of polling the numbers so nine by nine by one so as I said before I think this is something that Matt lives should be able to render directly invalid shape for image state okay so I\'m gonna repeat the steps that I did before ray to image so we have our ray Stantz ER and we have this here so we have okay nice so we got that gradient you know the or that we\'re doing here that in some way is cheating is that this map is being mapped on this on the color map that we select or the default one from zero to one right from the minimum color to the maximum color you can see that here we can see the full spectrum of a a color map or so here so you can see the full expectrum of a color map with with an operation like this but this is also because you know Chara\'s also helps us there and Matt load leaf remaps the image let\'s try what we were gonna do before so if we try rendering that image as black and white you see we can actually see the the actual values of the colors this is going from 0 to 80 and if we wanted to do our own remapping so our own mapping of those colors so they are going from 0 to 255 for whatever trivial size we choose to have on the image what we\'re gonna do is that you know this is the amount of pixels that we have so let\'s say this is pixel amount we put it here and we wanna do is we wanna see the total amount of pixels divided by 255 right so our scaling factor it\'s gonna be the pixel amount divided by 255 right so that way so let\'s see if we do for example 255 divided 80 right that\'s three point 18 so we do if we do here 3 oh you cannot probably see that so if we were to multiply that by Eddie will get 255 that\'s the maximum number we want so these are scale and what we\'re gonna do is that we\'re gonna pen not the number but the number scaled and now we should see a full spectrum from from black to gray [Music] so pixel amount scale let\'s inspect the values that we\'re actually getting there seems to be something failing here all right and those are not integers right let\'s try to do one thing so we got that the way I expected them to be we convert the tensor we reshape and then we have this tensor this is actually what I was looking for so we are going to try to do this a cast 8 M let\'s inspect it again right that seems to be what I wanted to get to yeah okay so we\'ve remapped manually right so what we did before was we had colors that didn\'t and we can see we\'re not reaching 255 maybe because we\'re starting at zero just try this okay so now we\'re going from full black to full white we\'ve mapped it manually but as I was mentioned before if you don\'t do this remapping and you convert the image with Charis Charis would actually map it from 0 to 1 and then Matt loudly is represented using the color map that you choose and you know we can see that here for instance if I run with that cool that cool color map now we\'re getting the full spectrum so now that we have this done let\'s just play a little bit with it before we wrap up and you know what I\'m gonna do right now is I\'m just gonna set an image that\'s gonna be well first really small so 3 by 3 see what we get you get a 3 by 3 image in that spectrum of colors and now we\'re going to go to 256 by 256 nice so that\'s a perfect gradient and you know maybe if you go you can see but I cannot see any difference with the pixels so we\'ve made manually with me the tensor we\'ve learned how to you know this is a cool physical image so you know any then we can put this here right it\'s gonna be my my wrap-up background so I hope this was useful so this was an exercise to me to just remember some of the basic operations that you can use with tensorflow to to just manipulate arrays as tensors and change their shape and get a rate data and convert it into an image so an image is just basically a three by not not a three by three but like XY by three or X Y and the third dimension a one which represents an RGB image or a single channel image you can have a four channel image as well if you have RGB a so you can imagine that instead of having you know a three component color we\'ll have a 4 component color with the a so the fourth component is the Alpha so the transparency that might go from 0 to 255 or friend 0 to 1 depending on the mapping that you\'re doing so yeah this was a first video I\'ve done talking about tensor flow and how to manipulate tensors if you enjoyed the video leave some comments maybe like the video and also feel free to subscribe to get notifications when I ain\'t go live or when I make new videos for the channel thank you so much bye"", metadata={\'source\': \'e1B7l3smXFE\'})]""""""', '""""""[Document(page_content=""we import tensorflow as tf and then we print the tensorflow version we are using tensorflow 1.0.1 now we\'re going to create two tensorflow variables that will hold random numbers we use tensorflow variables so that they maintain the same state across multiple calls of the session run we\'re creating this tensorflow variable using the tensorflow random underscore uniform functionality we\'re gonna generate a tensor that is two by three by four has a minimum value of 0 a max value of 10 and the data type is tensorflow int 32 n32 is a 32 bit signed integer so that is random underscore tensor underscore var underscore one we define random underscore tensor underscore var underscore two the same way we use the tensorflow random underscore uniform we have a tensor that\'s two by three by four min value of 0 max value of 10 the data type is also n32 next we use tensorflow global underscore variables underscore initializer so that when we run the session we can initialize all the variables then we define our session variable and initialize all our variables so here we\'re going to have two variables remember random underscore tensor underscore var underscore one and random underscore tensor underscore var underscore two first let\'s print our random underscore tense around the score var underscore one to see what it looks like we see that it is integers and it is two by three by four next we print our second tensor and we see that it is also two by three by four it\'s all integers and it is a completely different tensor from the first one to concatenate tensors we\'re going to use tf.concat what we do is we pass a list of tensors and then we specify the dimension we want to concatenate across we are going to concatenate across the zeroth dimension remember python is zero based index and we\'re going to assign this concatenation to python variable can cat underscore tensor underscore dim underscore zero now we\'re going to print the result we evaluate the variable inside of the session and we print the result we see that it has the four matrices so 6 5 four one two three five eight three four nine zero they\'re all there and we can run tensorflow.shape on our concat underscore tensor underscore dem underscore zero variable run it in the session and print the result and we see that it is four by three by four this is expected we\'re concatenating the two tensors across the zeroth dimension so that would be the first dimension since each tensorflow tensor was two by three by four we see that it is four by three by four so we have these three by four matrices and there are four of them on top of each other we\'re going to do another concatenation between random underscore around the score var underscore 1 and random underscore tense around the score var underscore 2. this time we\'re concatenating across dimension 1. we use the tensorflow.concat functionality and we\'re going to assign it to the python variable can cat underscore tensor underscore dim underscore one we evaluate the variable inside of our session and print the result to see that we have one matrix here one matrix here and it is now one two three four five six rows by four columns so we have two matrices six rows four columns so when we use the tensorflow.shape to get the dimensions we can see that it is two by six by four which is what we expect because each tensor originally was two by three by four so when we concatenated it across dimension one we would expect the shape to be two by six by four the last concatenation we do is across the second dimension remember this tensor is two by three by four so it has three dimensions python is a zero based index so this two will be the last one we assign it to the python variable can cat underscore tensor underscore dim under score two we print the result and we see that we have two matrices with one two three rows and one two three four five six seven eight columns when we print out the shape using the tensorflow.shape functionality we can see that it is indeed two by three by eight which is expected each original tensor was two by three by four so when we concatenated across the second dimension we would expect this to be two by three by four plus four which is exactly what we got the last thing we do is we close the tensorflow session to release the tensorflow resources we used in this session as we no longer require them"", metadata={\'source\': \'9buk4Z_JlXk\'})]""""""']","{'https://stackoverflow.com/questions/56969703/how-to-use-tf-scatter-nd-with-multi-dimensional-tensors', 'https://stackoverflow.com/questions/52572275/tensorflow-how-to-interleave-columns-of-two-tensors-e-g-using-tf-scatter-nd', 'https://stackoverflow.com/questions/39684415/tensorflow-getting-elements-of-every-row-for-specific-columns', 'https://stackoverflow.com/questions/56491633/what-is-the-difference-between-tf-scatter-add-and-tf-scatter-nd-when-indices-is'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\ntensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)? Asked 5 years, 9 months ago\n\nModified 5 years, 9 months ago\n\nI\'ve read the tf.scatter_nd documentation and run the example code for 1D and 3D tensors... and now I\'m trying to do it for a 2D tensor. I want to \'interleave\' the columns of two tensors. For 1D tensors, one can do this via\n\n\'\'\' We want to interleave elements of 1D tensors arr1 and arr2, where arr1 = [10, 11, 12] arr2 = [1, 2, 3, 4, 5, 6] such that desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12] \'\'\' import tensorflow as tf with tf.Session() as sess: updates1 = tf.constant([1,2,3,4,5,6]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([9]) scatter1 = tf.scatter_nd(indices1, updates1, shape) updates2 = tf.constant([10,11,12]) indices2 = tf.constant([[2], [5], [8]]) scatter2 = tf.scatter_nd(indices2, updates2, shape) result = scatter1 + scatter2 print(sess.run(result))\n\n(aside: is there a better way to do this? I\'m all ears.)\n\nThis gives the output\n\n[ 1 2 10 3 4 11 5 6 12]\n\nNow lets\' try to extend this to 2D. \'\'\' We want to interleave the *columns* (not rows; rows would be easy!) of arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]] arr2 = [[10 11 12], [10 11 12], [10 11 12]] such that desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]] \'\'\' updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([3, 9]) scatter1 = tf.scatter_nd(indices1, updates1, shape)\n\nThis gives the error ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1 dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but are 6 and 3. Shapes are [6] and [3]. for \'ScatterNd_2\' (op: \'ScatterNd\') with input shapes: [6,1], [3,6], [2]. Seems like my indices is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean I need to explicitly specify every single pair of indices for every element in updates1? Or is there some kind of \'wildcard\' specification I can use for the rows? (Note indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]]) gives syntax errors, as it probably should.)\n\nWould it be easier to just do a transpose, interleave the rows, then transpose back? Because I tried that... scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape)) print(sess.run(tf.transpose(scatter1)))\n\n...and got a much longer error message, that I don\'t feel like posting unless someone requests it. PS- I searched to make sure this isn\'t a duplicate -- I find it hard to imagine that someone else hasn\'t asked this before -- but turned up nothing. 2\n\nOk, the following lines actually work, but I have no idea why... shape = tf.constant([9, 3]), scatter1 = tf.transpose(tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))) ...Particularly strange that I have to define shape as [9,3] and take its transpose, whereas just defining it as [3,9] and using it that way gives an error. I would have thought I need to use a shape of [9,3] if I\'m using the traspose, or else define [3,9] and then take its transpose. ? ...So, while I now have \'working code\', I\'d rather not \'answer my own question\': If you can either explain why this is necessary, or offer a better way to do what I want to do, then the prize is yours! ;-)\n\n\n\nThis is pure slicing but I didn\'t know that syntax like arr1[0:,:][:,:2] actually works. It seems it does but not sure if it is better. This may be the wildcard slicing mechanism you are looking for. arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]]) arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]]) with tf.Session() as sess : sess.run( tf.global_variables_initializer() ) print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1], arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2], arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))\n\n[[ 1 2 10 3 4 11 5 6 12] [ 1 2 10 3 4 11 5 7 12] [ 1 2 10 3 4 11 5 8 12]]\n\n[[1 2 3 4 5 6] [1 2 3 4 5 7] [1 2 3 4 5 8]]\n\nand arr1[0:,:][:,:2] returns the first two columns\n\nMohan RadhakrishnanMohan Radhakrishnan\n\n 1\n\nThanks! I was using scatter_nd instead of concatenate because I need the solution to scale up to hundreds of columns, which I can\'t count on being able to specify ""by hand"". Still, if there\'s a way to make this ""scale"", i.e. programatically specifying the columns (without a hundred concat operations which would be slow), then this answer wins. I also hit upon a different (non-scatter_nd) answer using permutation matrices, which I\'ll post in a bit... Some moderators might have regarded my question as a duplicate of this one, not because the questions are the same, but only because the answers contain parts one can use to answer this question -- i.e. specifying every index combination by hand. A totally different method would be to multiply by a permutation matrix as shown in the last answer to this question. Since my original question was about scatter_nd, I\'m going to post this solution but wait to see what other answers come in... (Alternatively, I or someone could edit the question to make it about reordering columns, not specific to scatter_nd --EDIT: I have just edited the question title to reflect this). Here, we concatenate the two different arrays/tensors... import numpy as np import tensorflow as tf sess = tf.Session() # the ultimate application is for merging variables which should be in groups, # e.g. in this example, [1,2,10] is a group of 3, and there are 3 groups of 3 n_groups = 3 vars_per_group = 3 # once the single value from arr2 (below) is included arr1 = 10+tf.range(n_groups, dtype=float) arr1 = tf.stack((arr1,arr1,arr1),0) arr2 = 1+tf.range(n_groups * (vars_per_group-1), dtype=float) arr2 = tf.stack((arr2,arr2,arr2),0) catted = tf.concat((arr1,arr2),1) # concatenate the two arrays together print(""arr1 = \\n"",sess.run(arr1)) print(""arr2 = \\n"",sess.run(arr2)) print(""catted = \\n"",sess.run(catted))\n\narr1 = [[10. 11.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\ntensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)? Asked 5 years, 9 months ago\n\nModified 5 years, 9 months ago\n\nI\'ve read the tf.scatter_nd documentation and run the example code for 1D and 3D tensors... and now I\'m trying to do it for a 2D tensor. I want to \'interleave\' the columns of two tensors. For 1D tensors, one can do this via\n\n\'\'\' We want to interleave elements of 1D tensors arr1 and arr2, where arr1 = [10, 11, 12] arr2 = [1, 2, 3, 4, 5, 6] such that desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12] \'\'\' import tensorflow as tf with tf.Session() as sess: updates1 = tf.constant([1,2,3,4,5,6]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([9]) scatter1 = tf.scatter_nd(indices1, updates1, shape) updates2 = tf.constant([10,11,12]) indices2 = tf.constant([[2], [5], [8]]) scatter2 = tf.scatter_nd(indices2, updates2, shape) result = scatter1 + scatter2 print(sess.run(result))\n\n(aside: is there a better way to do this? I\'m all ears.)\n\nThis gives the output\n\n[ 1 2 10 3 4 11 5 6 12]\n\nNow lets\' try to extend this to 2D. \'\'\' We want to interleave the *columns* (not rows; rows would be easy!) of arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]] arr2 = [[10 11 12], [10 11 12], [10 11 12]] such that desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]] \'\'\' updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([3, 9]) scatter1 = tf.scatter_nd(indices1, updates1, shape)\n\nThis gives the error ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1 dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but are 6 and 3. Shapes are [6] and [3]. for \'ScatterNd_2\' (op: \'ScatterNd\') with input shapes: [6,1], [3,6], [2]. Seems like my indices is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean I need to explicitly specify every single pair of indices for every element in updates1? Or is there some kind of \'wildcard\' specification I can use for the rows? (Note indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]]) gives syntax errors, as it probably should.)\n\nWould it be easier to just do a transpose, interleave the rows, then transpose back? Because I tried that... scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape)) print(sess.run(tf.transpose(scatter1)))\n\n...and got a much longer error message, that I don\'t feel like posting unless someone requests it. PS- I searched to make sure this isn\'t a duplicate -- I find it hard to imagine that someone else hasn\'t asked this before -- but turned up nothing. 2\n\nOk, the following lines actually work, but I have no idea why... shape = tf.constant([9, 3]), scatter1 = tf.transpose(tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))) ...Particularly strange that I have to define shape as [9,3] and take its transpose, whereas just defining it as [3,9] and using it that way gives an error. I would have thought I need to use a shape of [9,3] if I\'m using the traspose, or else define [3,9] and then take its transpose. ? ...So, while I now have \'working code\', I\'d rather not \'answer my own question\': If you can either explain why this is necessary, or offer a better way to do what I want to do, then the prize is yours! ;-)\n\n\n\nThis is pure slicing but I didn\'t know that syntax like arr1[0:,:][:,:2] actually works. It seems it does but not sure if it is better. This may be the wildcard slicing mechanism you are looking for. arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]]) arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]]) with tf.Session() as sess : sess.run( tf.global_variables_initializer() ) print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1], arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2], arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))\n\n[[ 1 2 10 3 4 11 5 6 12] [ 1 2 10 3 4 11 5 7 12] [ 1 2 10 3 4 11 5 8 12]]\n\n[[1 2 3 4 5 6] [1 2 3 4 5 7] [1 2 3 4 5 8]]\n\nand arr1[0:,:][:,:2] returns the first two columns\n\nMohan RadhakrishnanMohan Radhakrishnan\n\n 1\n\nThanks! I was using scatter_nd instead of concatenate because I need the solution to scale up to hundreds of columns, which I can\'t count on being able to specify ""by hand"". Still, if there\'s a way to make this ""scale"", i.e. programatically specifying the columns (without a hundred concat operations which would be slow), then this answer wins. I also hit upon a different (non-scatter_nd) answer using permutation matrices, which I\'ll post in a bit... Some moderators might have regarded my question as a duplicate of this one, not because the questions are the same, but only because the answers contain parts one can use to answer this question -- i.e. specifying every index combination by hand. A totally different method would be to multiply by a permutation matrix as shown in the last answer to this question. Since my original question was about scatter_nd, I\'m going to post this solution but wait to see what other answers come in... (Alternatively, I or someone could edit the question to make it about reordering columns, not specific to scatter_nd --EDIT: I have just edited the question title to reflect this). Here, we concatenate the two different arrays/tensors... import numpy as np import tensorflow as tf sess = tf.Session() # the ultimate application is for merging variables which should be in groups, # e.g. in this example, [1,2,10] is a group of 3, and there are 3 groups of 3 n_groups = 3 vars_per_group = 3 # once the single value from arr2 (below) is included arr1 = 10+tf.range(n_groups, dtype=float) arr1 = tf.stack((arr1,arr1,arr1),0) arr2 = 1+tf.range(n_groups * (vars_per_group-1), dtype=float) arr2 = tf.stack((arr2,arr2,arr2),0) catted = tf.concat((arr1,arr2),1) # concatenate the two arrays together print(""arr1 = \\n"",sess.run(arr1)) print(""arr2 = \\n"",sess.run(arr2)) print(""catted = \\n"",sess.run(catted))\n\narr1 = [[10. 11.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\ntensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)? Asked 5 years, 9 months ago\n\nModified 5 years, 9 months ago\n\nI\'ve read the tf.scatter_nd documentation and run the example code for 1D and 3D tensors... and now I\'m trying to do it for a 2D tensor. I want to \'interleave\' the columns of two tensors. For 1D tensors, one can do this via\n\n\'\'\' We want to interleave elements of 1D tensors arr1 and arr2, where arr1 = [10, 11, 12] arr2 = [1, 2, 3, 4, 5, 6] such that desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12] \'\'\' import tensorflow as tf with tf.Session() as sess: updates1 = tf.constant([1,2,3,4,5,6]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([9]) scatter1 = tf.scatter_nd(indices1, updates1, shape) updates2 = tf.constant([10,11,12]) indices2 = tf.constant([[2], [5], [8]]) scatter2 = tf.scatter_nd(indices2, updates2, shape) result = scatter1 + scatter2 print(sess.run(result))\n\n(aside: is there a better way to do this? I\'m all ears.)\n\nThis gives the output\n\n[ 1 2 10 3 4 11 5 6 12]\n\nNow lets\' try to extend this to 2D. \'\'\' We want to interleave the *columns* (not rows; rows would be easy!) of arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]] arr2 = [[10 11 12], [10 11 12], [10 11 12]] such that desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]] \'\'\' updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([3, 9]) scatter1 = tf.scatter_nd(indices1, updates1, shape)\n\nThis gives the error ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1 dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but are 6 and 3. Shapes are [6] and [3]. for \'ScatterNd_2\' (op: \'ScatterNd\') with input shapes: [6,1], [3,6], [2]. Seems like my indices is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean I need to explicitly specify every single pair of indices for every element in updates1? Or is there some kind of \'wildcard\' specification I can use for the rows? (Note indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]]) gives syntax errors, as it probably should.)\n\nWould it be easier to just do a transpose, interleave the rows, then transpose back? Because I tried that... scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape)) print(sess.run(tf.transpose(scatter1)))\n\n...and got a much longer error message, that I don\'t feel like posting unless someone requests it. PS- I searched to make sure this isn\'t a duplicate -- I find it hard to imagine that someone else hasn\'t asked this before -- but turned up nothing. 2\n\nOk, the following lines actually work, but I have no idea why... shape = tf.constant([9, 3]), scatter1 = tf.transpose(tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))) ...Particularly strange that I have to define shape as [9,3] and take its transpose, whereas just defining it as [3,9] and using it that way gives an error. I would have thought I need to use a shape of [9,3] if I\'m using the traspose, or else define [3,9] and then take its transpose. ? ...So, while I now have \'working code\', I\'d rather not \'answer my own question\': If you can either explain why this is necessary, or offer a better way to do what I want to do, then the prize is yours! ;-)\n\n\n\nThis is pure slicing but I didn\'t know that syntax like arr1[0:,:][:,:2] actually works. It seems it does but not sure if it is better. This may be the wildcard slicing mechanism you are looking for. arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]]) arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]]) with tf.Session() as sess : sess.run( tf.global_variables_initializer() ) print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1], arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2], arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))\n\n[[ 1 2 10 3 4 11 5 6 12] [ 1 2 10 3 4 11 5 7 12] [ 1 2 10 3 4 11 5 8 12]]\n\n[[1 2 3 4 5 6] [1 2 3 4 5 7] [1 2 3 4 5 8]]\n\nand arr1[0:,:][:,:2] returns the first two columns\n\nMohan RadhakrishnanMohan Radhakrishnan\n\n 1\n\nThanks! I was using scatter_nd instead of concatenate because I need the solution to scale up to hundreds of columns, which I can\'t count on being able to specify ""by hand"". Still, if there\'s a way to make this ""scale"", i.e. programatically specifying the columns (without a hundred concat operations which would be slow), then this answer wins. I also hit upon a different (non-scatter_nd) answer using permutation matrices, which I\'ll post in a bit... Some moderators might have regarded my question as a duplicate of this one, not because the questions are the same, but only because the answers contain parts one can use to answer this question -- i.e. specifying every index combination by hand. A totally different method would be to multiply by a permutation matrix as shown in the last answer to this question. Since my original question was about scatter_nd, I\'m going to post this solution but wait to see what other answers come in... (Alternatively, I or someone could edit the question to make it about reordering columns, not specific to scatter_nd --EDIT: I have just edited the question title to reflect this). Here, we concatenate the two different arrays/tensors... import numpy as np import tensorflow as tf sess = tf.Session() # the ultimate application is for merging variables which should be in groups, # e.g. in this example, [1,2,10] is a group of 3, and there are 3 groups of 3 n_groups = 3 vars_per_group = 3 # once the single value from arr2 (below) is included arr1 = 10+tf.range(n_groups, dtype=float) arr1 = tf.stack((arr1,arr1,arr1),0) arr2 = 1+tf.range(n_groups * (vars_per_group-1), dtype=float) arr2 = tf.stack((arr2,arr2,arr2),0) catted = tf.concat((arr1,arr2),1) # concatenate the two arrays together print(""arr1 = \\n"",sess.run(arr1)) print(""arr2 = \\n"",sess.run(arr2)) print(""catted = \\n"",sess.run(catted))\n\narr1 = [[10. 11.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\ntensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)? Asked 5 years, 9 months ago\n\nModified 5 years, 9 months ago\n\nI\'ve read the tf.scatter_nd documentation and run the example code for 1D and 3D tensors... and now I\'m trying to do it for a 2D tensor. I want to \'interleave\' the columns of two tensors. For 1D tensors, one can do this via\n\n\'\'\' We want to interleave elements of 1D tensors arr1 and arr2, where arr1 = [10, 11, 12] arr2 = [1, 2, 3, 4, 5, 6] such that desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12] \'\'\' import tensorflow as tf with tf.Session() as sess: updates1 = tf.constant([1,2,3,4,5,6]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([9]) scatter1 = tf.scatter_nd(indices1, updates1, shape) updates2 = tf.constant([10,11,12]) indices2 = tf.constant([[2], [5], [8]]) scatter2 = tf.scatter_nd(indices2, updates2, shape) result = scatter1 + scatter2 print(sess.run(result))\n\n(aside: is there a better way to do this? I\'m all ears.)\n\nThis gives the output\n\n[ 1 2 10 3 4 11 5 6 12]\n\nNow lets\' try to extend this to 2D. \'\'\' We want to interleave the *columns* (not rows; rows would be easy!) of arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]] arr2 = [[10 11 12], [10 11 12], [10 11 12]] such that desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]] \'\'\' updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]) indices1 = tf.constant([[0], [1], [3], [4], [6], [7]]) shape = tf.constant([3, 9]) scatter1 = tf.scatter_nd(indices1, updates1, shape)\n\nThis gives the error ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1 dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but are 6 and 3. Shapes are [6] and [3]. for \'ScatterNd_2\' (op: \'ScatterNd\') with input shapes: [6,1], [3,6], [2]. Seems like my indices is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean I need to explicitly specify every single pair of indices for every element in updates1? Or is there some kind of \'wildcard\' specification I can use for the rows? (Note indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]]) gives syntax errors, as it probably should.)\n\nWould it be easier to just do a transpose, interleave the rows, then transpose back? Because I tried that... scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape)) print(sess.run(tf.transpose(scatter1)))\n\n...and got a much longer error message, that I don\'t feel like posting unless someone requests it. PS- I searched to make sure this isn\'t a duplicate -- I find it hard to imagine that someone else hasn\'t asked this before -- but turned up nothing. 2\n\nOk, the following lines actually work, but I have no idea why... shape = tf.constant([9, 3]), scatter1 = tf.transpose(tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))) ...Particularly strange that I have to define shape as [9,3] and take its transpose, whereas just defining it as [3,9] and using it that way gives an error. I would have thought I need to use a shape of [9,3] if I\'m using the traspose, or else define [3,9] and then take its transpose. ? ...So, while I now have \'working code\', I\'d rather not \'answer my own question\': If you can either explain why this is necessary, or offer a better way to do what I want to do, then the prize is yours! ;-)\n\n\n\nThis is pure slicing but I didn\'t know that syntax like arr1[0:,:][:,:2] actually works. It seems it does but not sure if it is better. This may be the wildcard slicing mechanism you are looking for. arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]]) arr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]]) with tf.Session() as sess : sess.run( tf.global_variables_initializer() ) print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1], arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2], arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))\n\n[[ 1 2 10 3 4 11 5 6 12] [ 1 2 10 3 4 11 5 7 12] [ 1 2 10 3 4 11 5 8 12]]\n\n[[1 2 3 4 5 6] [1 2 3 4 5 7] [1 2 3 4 5 8]]\n\nand arr1[0:,:][:,:2] returns the first two columns\n\nMohan RadhakrishnanMohan Radhakrishnan\n\n 1\n\nThanks! I was using scatter_nd instead of concatenate because I need the solution to scale up to hundreds of columns, which I can\'t count on being able to specify ""by hand"". Still, if there\'s a way to make this ""scale"", i.e. programatically specifying the columns (without a hundred concat operations which would be slow), then this answer wins. I also hit upon a different (non-scatter_nd) answer using permutation matrices, which I\'ll post in a bit... Some moderators might have regarded my question as a duplicate of this one, not because the questions are the same, but only because the answers contain parts one can use to answer this question -- i.e. specifying every index combination by hand. A totally different method would be to multiply by a permutation matrix as shown in the last answer to this question. Since my original question was about scatter_nd, I\'m going to post this solution but wait to see what other answers come in... (Alternatively, I or someone could edit the question to make it about reordering columns, not specific to scatter_nd --EDIT: I have just edited the question title to reflect this). Here, we concatenate the two different arrays/tensors... import numpy as np import tensorflow as tf sess = tf.Session() # the ultimate application is for merging variables which should be in groups, # e.g. in this example, [1,2,10] is a group of 3, and there are 3 groups of 3 n_groups = 3 vars_per_group = 3 # once the single value from arr2 (below) is included arr1 = 10+tf.range(n_groups, dtype=float) arr1 = tf.stack((arr1,arr1,arr1),0) arr2 = 1+tf.range(n_groups * (vars_per_group-1), dtype=float) arr2 = tf.stack((arr2,arr2,arr2),0) catted = tf.concat((arr1,arr2),1) # concatenate the two arrays together print(""arr1 = \\n"",sess.run(arr1)) print(""arr2 = \\n"",sess.run(arr2)) print(""catted = \\n"",sess.run(catted))\n\narr1 = [[10. 11.""""""']"
71129505,tf.data.Dataset,example required,"Is it possible to split a tensorflow dataset into train, validation AND test datasets when using image_dataset_from_directory?","<p>I am using <code>tf.keras.utils.image_dataset_from_directory</code> to load a dataset of 4575 images. While this function allows to split the data into two subsets (with the <code>validation_split</code> parameter), I want to split it into training, testing, and validation subsets.</p>
<p>I have tried using <code>dataset.skip()</code> and <code>dataset.take()</code> to further split one of the resulting subsets, but these functions return a <code>SkipDataset</code> and a <code>TakeDataset</code> respectively (by the way, contrary to <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=stable#take"" rel=""nofollow noreferrer"">the documentation</a>, where it is claimed that these functions return a <code>Dataset</code>). This leads to problems when fitting the model - the metrics calculated on validation sets (val_loss, val_accuracy) disappear from model history.</p>
<p>So, my question is: is there a way to split a <code>Dataset</code> into three subsets for training, validation and testing, so that all three subsets are also <code>Dataset</code> objects?</p>
<p><strong>Code used to load the data</strong></p>
<pre><code>def load_data_tf(data_path: str, img_shape=(256,256), batch_size: int=8):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.2,
        subset=&quot;training&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    val_ds = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=0.3,
        subset=&quot;validation&quot;,
        label_mode='categorical',
        seed=123,
        image_size=img_shape,
        batch_size=batch_size)
    return train_ds, val_ds

train_dataset, test_val_ds = load_data_tf('data_folder', img_shape = (256,256), batch_size=8)
test_dataset = test_val_ds.take(686)
val_dataset = test_val_ds.skip(686)
</code></pre>
<p><strong>Model compilation and fitting</strong></p>
<pre><code>model.compile(optimizer='sgd',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])
history = model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=1)
</code></pre>
<p><strong>When using a normal <code>Dataset</code>, <code>val_accuracy</code> and <code>val_loss</code> are present in the history of the model:</strong></p>
<p><a href=""https://i.stack.imgur.com/Qn1Yf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qn1Yf.png"" alt=""Expected behaviour: when using a Dataset, validation metrics are calculated"" /></a></p>
<p><strong>But when using a <code>SkipDataset</code>, they are not:</strong></p>
<p><a href=""https://i.stack.imgur.com/GMnBM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GMnBM.png"" alt=""Using the SkipDataset produced by test_val_ds.take() leads to validation metrics disappearing from model history"" /></a></p>
<p><a href=""https://i.stack.imgur.com/omU5U.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/omU5U.png"" alt=""val_accuracy and val_loss are not present in history keys when using a SkipDataset or a TakeDataset"" /></a></p>
","<p>The issue is that you are not taking and skipping samples when you do <code>test_val_ds.take(686)</code> and <code>test_val_ds.skip(686)</code>, but actually batches. Try running <code>print(val_dataset.cardinality())</code> and you will see how many batches you really have reserved for validation. I am guessing <code>val_dataset</code> is empty, because you do not have 686 batches for validation. Here is a working example:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import pathlib

dataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;validation&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

test_dataset = val_ds.take(5)
val_ds = val_ds.skip(5)

print('Batches for testing --&gt;', test_dataset.cardinality())
print('Batches for validating --&gt;', val_ds.cardinality())

model = tf.keras.Sequential([
  tf.keras.layers.Rescaling(1./255, input_shape=(180, 180, 3)),
  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(5)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=1
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=1
)
</code></pre>
<pre><code>Found 3670 files belonging to 5 classes.
Using 2936 files for training.
Found 3670 files belonging to 5 classes.
Using 734 files for validation.
Batches for testing --&gt; tf.Tensor(5, shape=(), dtype=int64)
Batches for validating --&gt; tf.Tensor(18, shape=(), dtype=int64)
92/92 [==============================] - 96s 1s/step - loss: 1.3516 - accuracy: 0.4489 - val_loss: 1.1332 - val_accuracy: 0.5645
</code></pre>
<p>In this example, with a <code>batch_size</code> of 32, you can clearly see that the validation set reserved 23 batches. Afterwards, 5 batches were given to the test set and 18 batches remained for the validation set.</p>
","The issue is that you are not taking and skipping samples when you do <code>test_val_ds.take(686)</code> and <code>test_val_ds.skip(686)</code>, but actually batches. Try running <code>print(val_dataset.cardinality())</code> and you will see how many batches you really have reserved for validation. I am guessing <code>val_dataset</code> is empty, because you do not have 686 batches for validation.","<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import pathlib

dataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;training&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset=&quot;validation&quot;,
  seed=123,
  image_size=(180, 180),
  batch_size=batch_size)

test_dataset = val_ds.take(5)
val_ds = val_ds.skip(5)

print('Batches for testing --&gt;', test_dataset.cardinality())
print('Batches for validating --&gt;', val_ds.cardinality())

model = tf.keras.Sequential([
  tf.keras.layers.Rescaling(1./255, input_shape=(180, 180, 3)),
  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(5)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=1
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=1
)
</code></pre>","['How to split a TensorFlow Dataset into training, validation, and test sets using tf.data API?', 'How to use tf.keras.utils.image_dataset_from_directory to create three subsets: training, validation, and test?', 'How to handle SkipDataset and TakeDataset in TensorFlow for model training and validation?', 'How to ensure validation metrics are calculated when using SkipDataset and TakeDataset in TensorFlow?', 'Best practices for splitting image datasets into training, validation, and test sets in TensorFlow', 'How to use tf.data.Dataset.skip() and tf.data.Dataset.take() correctly for model validation in TensorFlow?', 'How to maintain validation metrics in TensorFlow model history when using custom dataset splits?']","['How to split a TensorFlow Dataset into training, validation, and test sets?', 'How to use tf.data.Dataset.skip() and tf.data.Dataset.take() without losing validation metrics in model history?', 'How to ensure validation metrics are calculated when using SkipDataset and TakeDataset in TensorFlow?', 'Best practices for splitting image datasets into training, validation, and test sets using tf.keras.utils.image_dataset_from_directory', 'How to maintain Dataset object type when splitting datasets in TensorFlow?']","{'https://www.youtube.com/watch?v=oW89weRFJj8', 'https://www.youtube.com/watch?v=U8Ixc2OLSkQ', 'https://www.youtube.com/watch?v=bqeUmLCgsVw'}","['""""""[Document(page_content=""hello explorers and welcome to another\\nvideo today I\'m gonna talk a little bit about TF data or tensorflow data and\\nthis come about because I watched the tensorflow summit and they talked a lot\\nabout tensorflow data and this new API that you can use to actually make\\nthings easy for yourself easily read data into a system and easily make\\nbetter performant models and I thought that that was really interesting so I\\nwanted to try it out so I went to their home page and looked at the\\ndocumentation and I thought it was quite hard to follow\\nso I actually wanted to make this video to give you an understanding on how you\\ncan set it up and how you can get started much quicker than I actually got\\nand everything that I will show today is up on my github so you can see it there\\nand let\'s get started we are talking about code and first off we have two\\nfeature functions here and these are just wrapper functions that will take\\nsome value and wrap it inside of a byte list or an int 64 list so an int of size\\n64 so these are just some simple functions to make features of data and\\nthen we have this little load image function it takes an image it resizes it\\nto one size and then changes the color to RGB so that\'s what I want my image to\\nbe when I actually are working with them and all the images that I load today\\ncome from a data set that were a competition of some sort to train cats\\nand dogs images and see if we can figure out what\'s a cat what\'s a dog and\\nyeah alone and this image set has a lot of different sizes of images and so on\\nso if you actually want make this viable set you should actually\\nlook at the images maybe filter some of them out maybe do some pre steps in\\nthe images to actually make the classification more viable and and get a\\nbetter trained model and usually when you\'re working with datasets you really\\nwant to find good solutions to actually clean up your datasets as much as\\npossible and of course if you want to find things in dirty datasets then you\\nmight might want to train with dirty datasets as well but as we don\'t build a\\nfunction that will find let\'s say a dog in an image we just want to see if this\\nis an image of a dog then it might be better to do that beforehand and then we\\nhave the next function here will actually create a data record and these\\nare the TF record files that the data TF data will use when it reads in TF data\\ncan read CSV files and other files but they are good at reading binary TF\\nrecords so these this is the way to create those and you create a\\nwriter from Python io TF record right there\\nand the output file name and then I have an little function here so I go through\\nall the addresses of all the images and I take a little print out each thousand\\nthat I do because there are think twenty five thousand images so we could be good\\nto have some progress you know how much you have actually read I load the image I\\ntake the label for that image if I didn\'t get any image then skip this one\\nand then I create a new feature with the wrapping of bytes for the image and then\\nI wrap the label with an int 64 and then I create an example so I wrap everything\\nin the feature with a which I wrap in an example\\nthat example I will serialize to the writer and write out the file and what\\nI\'ve done I close to the file and I\'m and flush everything out and when I\\ncreate this you will get three different files I will look at those\\nlater and those are in the range of eight gigabytes and to gigabytes so\\nthey\'re quite large so you need to have some space on your disk if you want to\\nrun this example and then I set up at path a glob to where my images are so in\\nmy directory pet images I have cats and dogs so this star here is the\\ncat directory and the dog directory and then I have some jpegs and all the\\njpegs are one two three four five dot jpg and I read the addresses from\\nthis glob command and the labels will actually take the address and then look\\nif the address has the word cat in it so if the directory is cat you will set 0\\nin the label else it will get a 1 in the label and we\'ll have created these I\\nwill actually zip these together and create a list I will shove that list and\\nthen I will unzip that list again so I will actually get the address and labels\\nback it\'s a really neat feature in Python actually I didn\'t know that you\\ncould do things like this I\'m not usually writing that much Python code so\\nit was really nice to see this another nice feature that you see down here is\\nwhere I split up my training set into 60%\\ntraining 20% validation and 20% test data it\'s very easily done with these\\narray ranges and when I\'ve done this I will create records for the training\\naddresses their validation addresses and the testing addresses and I will put\\nthose in different files with their labels\\nso what I\'ve done that prepared the data and have these large files then we will\\ngo into the training part of of this video so this is the training and we\\nfirst off look at setting up a new session and initializing the global\\nvariables and then I have this parse function I have up here and that will\\nactually take one record from the TF record file and parse it out so I\\nactually get the label and the image out so first off I need to say what kind of\\nfeatures I actually had in my file I have this image raw and the label and these\\nare strings and int 64 so this is just to define how the data structure in the\\nfile is set up and then I will read one record from the file and then I will\\ntake the image raw part out and take bites out of it and decode the raw image\\nhere I will cast the image to floats because that\'s what the model needs and\\nI will also reshape the image so it actually is in the shape of the size of\\nthe image so it\'s at 224 times 224 and three colors or a depth of three and\\nthen I will read out the label and I will cast that to int 32 because that\\nwill be used in the model as well and that I will return that from my parser\\nand the estimate I will use later will need an input function and I will create\\nthis input function from this helper function I have here and it will first\\noff create my data record so this is a dataset of the TF record so this is the\\nTF data we talked about earlier that you could do a lot of performance\\nenhancements on and so on since this is the API that I want to do showcase in\\nthis video and also I created my data set I will map it through my parser so I\\nactually will parse the labels and the images\\nand if I\'m in training that I will shuffle them up and if not in training I\\nwill only repeat ones and not shuffle them because I want to have a\\ngood evaluation every time the same and then I will repeat and setup the\\nbatch size the batch size is 32 in this case I make a one-shot in iterator and I\\nget the batch of the iterators and return that batch back to the training\\nfunction so then I set up a training function here with the train records and\\nthe test records and I set training to true and then I do the same with\\nthe validation records but I set training to false and so these are the\\ntrain input function and the validation input function and the first and you see\\nhere I have some code add commented out here it\'s just to print the image I\\nwanted to see that after had saved it down and read it again I want to see\\nthat I had this same image I can verify that I didn\'t do anything wrong in that\\nprocess and here I have feature columns that I want to run through a fully\\nconnected classifier so I set up this one and it has layers here 128 64 32\\nand 16 and so this is what was one of the networks that I tried and it has an\\nadam optimizer and I ran it through 100,000 steps and it ran I think four\\nthousand per 10 minutes so night I was able to run this little classifier and I\\ngot about forty nine fifty percent right so it was just like a coin flip\\nit was totally worthless or it wasn\'t it wasn\'t more wrong than if I just guessed\\nbut it wasn\'t good either and so that I wanted to try\\na little bit more sophisticated model so I have my model function here and I set\\nup in network that we have seen before it\'s one convolution with some\\npooling then a convolution again with some pooling we flatten the net and then\\nwe do two fully connected layers and then we take the predictions down here\\nif you want to actually do predict something so this is if we want to go\\ninto the predict mode of the estimator then we need to take out the prediction\\nand the prediction class and if not then we just put this result of the\\nnetwork into the sparse soft max cross entropy with logits function and we\\nreduce and find how much loss we have we run that through an adam optimizer and\\nwe return some metrics so we can see how accurate we are now and then we create\\nthis estimator specification down here that we actually return and in order to\\nset up a new estimate that we want to run we put our model function into it we\\ngive it a learning rate and that learning rate is used inside of the adam\\noptimizer we set the model dir so it knows where to save all the all the\\nfiles when it does snapshots and then we have a little function here while I go\\nthrough 100,000 times again but in this case I actually want to evaluate off the\\nthousand print the result and the accuracy and then I flush it out and\\nthen I try around another pass and I\'ve run this for a little while I was a\\nlittle bit pressed on time but the best it started somewhere around 70% and I\\nthink the best result I got was 71 or 72 something like that and that could\\neither mean that I have an unclean dataset so I\\nmight want to find a good function to clean it up and maybe another function\\nto crop the images so I don\'t lose that much when I actually resize them maybe I\\nused too little image maybe I want to use larger images but that will also\\nslow down the training and maybe I could fix my model maybe I can have a better\\nmodel I\'ve just tried with this model and but that could be tweaked as well to\\nget a better performance or accuracy in the model and but I think this is a good\\nstarting point so you can see how you can set up things and actually get the\\nTF record working with tensorflow data and everything else after that is\\noptimization I hope that you found this video interesting I hope that you\\nlearned something today if you have any questions about tensorflow data or this\\nset up then please ask in the comments below all the code you can find on\\ngithub I will leave the link below as well and if you like this video give it\\na like share it with your friends and colleagues and if you haven\'t subscribed\\nyet please do that and I really hope to see you in the next video"", metadata={\'source\': \'bqeUmLCgsVw\'})]""""""', '""""""[Document(page_content=""so this will be a tutorial on how to work with images in python and how to import images and how to download image data so you can actually use it for data analysis so i have an image in my files this time so if i run it i have this part so if i now say img i i say email.show dot open and specify the parts we can have a new image opened up here but this is not a point the main thing is the image data site that is actually available in google apis and then it can be useful of image analysis or data analysis using images so how do we get here so let me explain to you step by step so i\'m going to take this one away so that we can start right from the scratch so the first thing i like to do because the idea is that i want you to have ebay data site downloaded so i\'m going to open a new python notebook so the number of things you have to import the first one is always because we are going to be storing images in our file system so we also going to import p i l p i l is a library for managing images we also need to import pil or we can say from sorry let me just say from p i l import image okay so we need this to be able to open image and modify images and also we have another library called sk image that we are going to be using later in port io so i\'m going to show you two ways to actually uh use images um okay i\'m also going to say from times of flow sorry import times of law as time saw flow as tf and from times of flow the data sites from times of flow data sites imports uh known second so i\'m going to import things uploaded data sites as tiny soft law data sites okay so let me run it just make sure everything is fine now there is one thing about tensorflow and sk imagine pil this have to be installed uh in your system uh in the packages for python so if you go to your anaconda let me just go to anaconda if you go to anaconda to your base here you want to make sure that tensorflow is installed and all these other things are installed so if i go to install right now you can see tensorflow installed but if it\'s not installed you go here and search for it and then you have to install it so for instance if i go to check here okay so you can see sk image right here so this is how you install packages uh in your python or directory or as part of the packages so just in case something fails yeah know that that is exactly how you are going to use it install it using anaconda all right let\'s now download a set of images and to do that i\'ll have to also import one more library called path lib part slide now the image data site available uh as part of the uh tensorflow libraries is uh called flower photos and that is the one we are going to be using so i want to put the part here my click uh right here so let me just say data set the image data site url is going to be this let me just paste it because i copied it to my clipboard right oh sorry yeah so this is the url for the dataset for the images so you can actually check for it by actually searching for this in google okay so the next thing we want to do is to create a local directory i\'m going to say data directory now in my file system i\'m going to create a local directory tf.keras dot utils utils dot get file and save the origin of this file is going to be the data set url we created data set url and you are going to say f the name of the the name of the folder that\'s going to hold the images it\'s going to fold the name will be flower images so i\'m going to create a lookout for that called flower images and now this this folder here coming from the online repository is a tab folder so i\'m going to untie it or on zippy so i\'m going to say ontar is equal to true all right and finally uh i want to now yeah so this is what we have okay so i\'m going to say that i specify the data directory so this data directory now refers exactly to this part in my file system i\'m going to show you where this part is located so at this point the images is going to download uh to my local directory so the question you might be asking is where is this location this is the data directory where is it located so you can also you can just check for uh by entering it right here and you can see that it is located in this place all right so if i go to this directory my file system if i go to that directory uh i think it\'s a hidden directory so if i hit on my keyboard command enter dots i have the hidden directory open so if i go to keras and go to data site you can see that we have the flower photos right here and we have list of clouds downloaded to our local system right here so let\'s open some of them uh in python or code all right so let me get back here so how do we open uh this file so the first thing i\'d like to do is to get the the folder containing the roses remember we have a number of folders we have daisy we have then the neon we have roses we have some flowers we have tulips so let\'s get the roses so i\'m going to zero this is equal to the list of the data directory object data direct created and i\'m going to get the roses rosy slash star so getting all the uh all the file extension uh what is png or jpeg is going to be here so if you want to look at what is the roses here it\'s going to just be always giving us an empty directory all right so i\'m going to kind of repeat the same process so we have flower photos okay so let me see uh and here i have flower image um so that is a problem so let me just change it to flower photos flower photos okay so that\'s going to be my data directory so i\'m going to just kind of copy this i\'m going to just execute this one more time and i think i should have it at this point so let\'s see all right so if i run this and run this and run this now you can see that we have uh the result here so if i zero this you can see it gives us the directory to all the images in the roses directory all right so how do we then display the actual images right here there are a number of ways to do it let me show you the easy way first and later i\'m going to show you a different way so let\'s start by saying uh i\'m going to simply say i i\'m going to say image.open and specify the directory for a particular image so for one particular rose i\'m going to say str because to convert exposes parts to actual parts you\'re going to use a string so i\'m going to convert it by saying rows is specify zero so at this point i should be able to see one image so again i can just change this to one to see some other image and so we have the image of our roses showing up here that is fine now i would like us to display this image in a grid view okay so i\'m going to do now is i\'m going to create r1 is equal to io that i am read now if you use i am read it\'s going to get the image image meta metadata into this variable i\'m calling it r1 so img i am read is a library as part of the i o which we imported uh from sk image right here so it\'s for reading images installing your files in your files this time so uh it\'s going to be so basically we are going to be taking this right here so this is uh for the first one and we are going to be changing it up so this case we have zero and let\'s let me just create four different image images i\'m gonna be displaying them in a grid uh of four of a grid a grid of four images so it\'s going to be four and let me just change this one to one this one to two on base one to three so i\'m going to run and this is fine so i want to display this image in a grid view using matplotlib so i\'m going to create a figo i\'m going to say the figure i\'m going to create is they call the plt that\'s a mud plot like the pipeline figure i think you should know about this by now so i\'m going to use a fixed size of 15 and 20 okay so it\'s gonna be fixed size is equal to 1520 i don\'t want to make any mistake here so is this plt ah so so i\'m going to before i do that i\'m going to say imports mud plots live that\'s pi plots as plt i\'m gonna now run so we have this uh figure created so i\'m gonna create some plots i\'m gonna create a subplot ax one ax one is equal to f uh fig the art subplots so if you look at the link in the description box you\'ll see a link to be explained soft plots all right so we want one column and four rows so it\'s going to be four rows and i want to display image one i\'m going to say x one dot i am show and it\'s going to be our bump so i\'m going to run it now and it says add sub so i think there\'s an error add some plots add softwares okay so you can see it display the first image so basically you can just copy this on uh paste and just change the numbers so i\'m gonna paste paste paste so here i\'m gonna display this is r1 r2 it\'s gonna be r2 and here we have r3 and here i have r4 so one four one one four two and here one four three and this is going to be 1 4 4 and this is going to be ax 1 this is going to be x 2 2 and here is going to be a x 3 a x 3 and here it\'s going to be x 4 x x4 um yeah this is fine so i\'m going to run everything and now you can see display uh the images correctly so you can actually repeat the same process and display it in a second grid of several grid and frozen columns so check in this description box you\'ll see how to work with subplots and this is basically how to display images so how many ways have i showed you i\'ve showed you the first way simply use img.open and it\'s going to open this image or you can use img read i am read and then display the images using subplots using i am show all right i\'m going to be stopping here uh later on i\'m going to be showing you how to actually analyze images i\'ve done a bit of this in our previous tutorial i put the link in the description box on how to analyze handwriting uh images using tensorflow so please remember to subscribe to my channel and feel free to leave me a comment if this has been informative for you"", metadata={\'source\': \'oW89weRFJj8\'})]""""""', '""""""[Document(page_content=""hey I\'m maybe from deep lizard in this episode we\'ll demonstrate how we can use tensorflow scarus API to create a validation set on the fly during training before we demonstrate how to build a validation set using Kerris let\'s first talk about what exactly a validation set is so whenever we train a model our hope is that when we train it that we see good results from the training output that we have low loss and high accuracy but we don\'t ever train a model just for the sake of training it we want to take that model and hopefully be able to use it in some way on data that it wasn\'t necessarily exposed to during the training process and although this new data is data that the models never seen before the hope is that the model will be good enough to be able to generalize well on this new data and give accurate predictions for it we can actually get an understanding of how well our model is generalizing by introducing a validation set during the training process to create a validation set before training begins we can choose to take a subset of the training set and then separate it into a separate set labeled as validation data and then during the training process the model will only train on the training data and then we\'ll validate on the separated validation data so what do we mean by validating well essentially if we have the addition of a validation set then during training the model will be learning the features of the training set just as we\'ve already seen but in addition in each epoch after the model has gone through the actual training process it\'ll take what it\'s learned from the training data and then validate by predicting on the data in the validation set using only what it\'s learned from the training data though so then during the training process when we look at the output of the accuracy and loss not only will we be seeing that accuracy and loss computed for the training set we\'ll also see that computed on the validation set it\'s important to understand though that the model is only learning on or training on the training data it\'s not taking the validation set into account during training the validation set is just for us to be able to see how well the model is able to predict on data that it was not exposed to during the training process in other words it allows us to see how general our model is how well it\'s able to generalize on data that is not included in the training data so knowing this information will allow us to see if our model is running into the famous overfitting problem so overfitting occurs when the model has learned the specific features of the training set really well but it\'s unable to generalize on data it hasn\'t seen before so if while training we see that the model is giving really good results for the training set but less than good results for the validation set then we can conclude that we have an overfitting problem and then take the steps necessary to combat that specific issue if you\'d like to see the overfitting problem covered in more detail then there is an episode for that in the deep learning fundamentals course all right so now let\'s discuss how we can create and use a validation set with a Karass sequential model there\'s actually two ways that we can create and work with validation sets with a sequential model and the first way is to have a completely separate validation set from the training set and then to pass that validation set to the model in the fit function there is a validation data parameter and so we can just set that equal to the structure that is holding our validation data and there\'s a write-up in the corresponding blog for this episode that contains more details about the format that that data needs to be in but we\'re going to actually only focus on the second way of creating and using a validation set this step actually saves us a step because we don\'t have to explicitly go through the creation process of the validation set instead we can get carers to create it for us all right so we\'re back in our Jupiter notebook right where we left off last time and we\'re here on the model dot Fit function and recall this is what we use last time to train our model now I\'ve already edited this cell to include this new parameter which is validation split and what validation split does is it does what it sounds like it splits out a portion of the training set into a validation set so we just set this to a number between 0 and 1 so just a fractional number to tell Karis how much of the training set we need to split out into the validation set so here I\'m splitting out 10% of the training set so it\'s important to note that whenever we do this the validation set is completely held out of the training set so the training samples that we remove from the training set into validation set are no longer contained within the training data any longer so using this approach the validation set will be created on the fly whenever we call the fit function now there\'s one other thing worth mentioning here and remember last time I discussed this shuffle equals true parameter and I said that by default the training set is shuffled whenever we call fit so this shuffle equals true is already set by default but I was just bringing it up to let you know that that the training set is being shuffled so that is a good thing we want the training set to be shuffled but whenever we call validation split in this way this split occurs before the training set is shuffled meaning that if we created our training set and say we put all of the sick patients first and then the non sick patients second and then we say that we want to split off the last 10% of the training data to be our validation data it\'s going to take the last 10% of the training data and therefore it could just take all of the the second group that we put in the training set and not get any of the first group so I wanted to mention that because although the training data is being shuffled with the fit function if you haven\'t already shuffled your training data before you pass it to fit then you also use the split parameter it\'s important to know that your validation set is going to be the last X percent of your training set and therefore may not be shuffled and may yield some strange results because you think that everything has been shuffled when really it\'s only the training set has been shuffled after the validation set has been taken out so just keep that in mind the way that we created our training set before this episode we actually shuffled the training data before it\'s ever passed to the fit function so in the future whenever you\'re working with data it\'s a good idea to make sure that your data is also shuffled beforehand especially if you\'re going to be making use of the validation split parameter to create a validation set all right so now we\'ll run this cell one more time calling the fit function but this time not only will we see loss and accuracy metrics for the training set we\'ll also see these metrics for the validation set all right so the model has just finished running it\'s 30 epochs and now we see both the loss and accuracy on the left-hand side as well as the validation loss and validation accuracy on the right-hand side so we can see let\'s just look at the accuracy between the two they\'re both starting at around the same 50 percent mark and going up gradually around the same rate so we just scroll all the way to our last epoch we can see that the accuracy and validation accuracy are pretty similar with only one percent difference between the two and yeah the loss values are similar as well so we can see in this example that our model is not overfitting it is actually performing pretty well or just as well rather on the validation set as it is on the training set so our model is generalizing well if however we saw that the opposite case was true and our validation accuracy was seriously lagging behind our training accuracy then we know that we have a overfitting problem and we would need to take steps to address that issue alright so we\'ve now seen how to train the model how to validate the model and how to make use of both training and validation that\'s in the next episode we\'re going to see how to make use of a third data set the test data set to use the model for inference by the way we are currently in Vietnam filming this episode if you didn\'t know we also have a vlog channel where we document our travels and share a little bit more about ourselves so check that out at people\'s our vlog on YouTube also be sure to check out the corresponding blog for this episode along with other resources available on deep loser calm and check out the people\'s archive mine where you can gain exclusive access to perks and rewards thanks for contributing to collective intelligence I\'ll see you next time [Music] [Music]"", metadata={\'source\': \'U8Ixc2OLSkQ\'})]""""""']","{'https://stackoverflow.com/questions/71704268/using-tf-keras-utils-image-dataset-from-directory-with-label-list', 'https://stackoverflow.com/questions/48213766/split-a-dataset-created-by-tensorflow-dataset-api-in-to-train-and-test', 'https://stackoverflow.com/questions/41859605/split-tensor-into-training-and-test-sets', 'https://stackoverflow.com/questions/73044151/how-to-use-tf-keras-utils-image-dataset-from-directory-to-load-test-dataset'}","['""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nSplit a dataset created by Tensorflow dataset API in to Train and Test? Asked 6 years, 5 months ago\n\nModified 8 months ago\n\nDoes anyone know how to split a dataset created by the dataset API (tf.data.Dataset) in Tensorflow into Test and Train? 2\n\ntake(), skip(), and shard() all have their own problems.""""""', '""""""I hope it better answers your question. use Keras - model.fit(dataset,.., validation.split=0.7, ...) see its all possible arguments\n\n\n\nAssuming you have all_dataset variable of tf.data.Dataset type:\n\ntest_dataset = all_dataset.take(1000) train_dataset = all_dataset.skip(1000)\n\nTest dataset now has first 1000 elements and the rest goes for training. 1,3\n\nAs also mentioned in ted\'s answer, adding all_dataset.shuffle() allows for a shuffled split. Possibly add as code comment in answer like so? # all_dataset = all_dataset.shuffle() # in case you want a shuffled split\n\n\n\nTensorFlow 2.10.0 will have a utility function for splitting, see my answer: stackoverflow.com/a/73591823/1389680\n\n\n\ntake and skip return TfTakeDatasets/SkipDatasets which have less functionality than TfDatasets. Does anyone know how to map those to tfDatasets or split into train test splits and get back TfDataset objects? You may use Dataset.take() and Dataset.skip():\n\ntrain_size = int(0.7 * DATASET_SIZE) val_size = int(0.15 * DATASET_SIZE) test_size = int(0.15 * DATASET_SIZE) full_dataset = tf.data.TFRecordDataset(FLAGS.input_file) full_dataset = full_dataset.shuffle() train_dataset = full_dataset.take(train_size) test_dataset = full_dataset.skip(train_size) val_dataset = test_dataset.skip(val_size) test_dataset = test_dataset.take(test_size)\n\nFor more generality, I gave an example using a 70/15/15 train/val/test split but if you don\'t need a test or a val set, just ignore the last 2 lines. Creates a Dataset with at most count elements from this dataset. Creates a Dataset that skips count elements from this dataset. You may also want to look into Dataset.shard():\n\nCreates a Dataset that includes only 1/num_shards of this dataset. Disclaimer I stumbled upon this question after answering this one so I thought I\'d spread the love\n\n 7\n\nThank you very much @ted! Is there a way to divide the dataset in a stratified way? Or, alternatively, how can we have an idea of the class proportions (suppose a binary problem) after the train/val/test split? Thanks a lot in advance! Have a look at this blogpost I wrote; eventhough it\'s for multilabel datasets, should be easily usable for single label, multiclass datasets -> vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow\n\n\n\nThis causes my train,validation and test datasets to have overlap between them. Is this supposed to happen and not a big deal? I would assume it\'s not a good idea to have the model train on validation and test data. @c_student I had the same problem and I figured out what I was missing: when you shuffle use the option reshuffle_each_iteration=False otherwise elements could be repeated in train, test and val\n\n\n\nThis is very true @xdola, and in particular when using list_files you should use shuffle=False and then shuffle with the .shuffle with reshuffle_each_iteration=False. | Show 2 more comments\n\nMost of the answers here use take() and skip(), which requires knowing the size of your dataset before hand. This isn\'t always possible, or is difficult/intensive to ascertain. Instead what you can do is to essentially slice the dataset up so that 1 every N records becomes a validation record. To accomplish this, lets start with a simple dataset of 0-9:\n\ndataset = tf.data.Dataset.range(10) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nNow for our example, we\'re going to slice it so that we have a 3/1 train/validation split. Meaning 3 records will go to training, then 1 record to validation, then repeat. split = 3 dataset_train = dataset.window(split, split + 1).flat_map(lambda ds: ds) # [0, 1, 2, 4, 5, 6, 8, 9] dataset_validation = dataset.skip(split).window(1, split + 1).flat_map(lambda ds: ds) # [3, 7]\n\nSo the first dataset.window(split, split + 1) says to grab split number (3) of elements, then advance split + 1 elements, and repeat. That + 1 effectively skips the 1 element we\'re going to use in our validation dataset. The flat_map(lambda ds: ds) is because window() returns the results in batches, which we don\'t want. So we flatten it back out. Then for the validation data we first skip(split), which skips over the first split number (3) of elements that were grabbed in the first training window, so we start our iteration on the 4th element. The window(1, split + 1) then grabs 1 element, advances split + 1 (4), and repeats. Note on nested datasets: The above example works well for simple datasets, but flat_map() will generate an error if the dataset is nested. To address this, you can swap out the flat_map() with a more complicated version that can handle both simple and nested datasets:\n\n.flat_map(lambda *ds: ds[0] if len(ds) == 1 else tf.data.Dataset.zip(ds))\n\n 7\n\nDoesn\'t window just use skip under the hood? How does is the disadvantage The other disadvantage is that with skip() it has to read, and then discard, all the skipped records, which if your data source is slow means you might have a large spool-up time before results are emitted. adressed? If you have a dataset of 1000 records, and you want a 10% for validation, you would have to skip the first 900 records before a single validation record is emitted. With this solution, it only has to skip 9 records. It does end up skipping the same amount overall, but if you use dataset.prefetch(), it can read in the background while doing other things. The difference is just saving the initial spool-up time. Thinking about it a bit more, and I removed the statement.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nSplit a dataset created by Tensorflow dataset API in to Train and Test? Asked 6 years, 5 months ago\n\nModified 8 months ago\n\nDoes anyone know how to split a dataset created by the dataset API (tf.data.Dataset) in Tensorflow into Test and Train? 2\n\ntake(), skip(), and shard() all have their own problems.""""""', '""""""I hope it better answers your question. use Keras - model.fit(dataset,.., validation.split=0.7, ...) see its all possible arguments\n\n\n\nAssuming you have all_dataset variable of tf.data.Dataset type:\n\ntest_dataset = all_dataset.take(1000) train_dataset = all_dataset.skip(1000)\n\nTest dataset now has first 1000 elements and the rest goes for training. 1,3\n\nAs also mentioned in ted\'s answer, adding all_dataset.shuffle() allows for a shuffled split. Possibly add as code comment in answer like so? # all_dataset = all_dataset.shuffle() # in case you want a shuffled split\n\n\n\nTensorFlow 2.10.0 will have a utility function for splitting, see my answer: stackoverflow.com/a/73591823/1389680\n\n\n\ntake and skip return TfTakeDatasets/SkipDatasets which have less functionality than TfDatasets. Does anyone know how to map those to tfDatasets or split into train test splits and get back TfDataset objects? You may use Dataset.take() and Dataset.skip():\n\ntrain_size = int(0.7 * DATASET_SIZE) val_size = int(0.15 * DATASET_SIZE) test_size = int(0.15 * DATASET_SIZE) full_dataset = tf.data.TFRecordDataset(FLAGS.input_file) full_dataset = full_dataset.shuffle() train_dataset = full_dataset.take(train_size) test_dataset = full_dataset.skip(train_size) val_dataset = test_dataset.skip(val_size) test_dataset = test_dataset.take(test_size)\n\nFor more generality, I gave an example using a 70/15/15 train/val/test split but if you don\'t need a test or a val set, just ignore the last 2 lines. Creates a Dataset with at most count elements from this dataset. Creates a Dataset that skips count elements from this dataset. You may also want to look into Dataset.shard():\n\nCreates a Dataset that includes only 1/num_shards of this dataset. Disclaimer I stumbled upon this question after answering this one so I thought I\'d spread the love\n\n 7\n\nThank you very much @ted! Is there a way to divide the dataset in a stratified way? Or, alternatively, how can we have an idea of the class proportions (suppose a binary problem) after the train/val/test split? Thanks a lot in advance! Have a look at this blogpost I wrote; eventhough it\'s for multilabel datasets, should be easily usable for single label, multiclass datasets -> vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow\n\n\n\nThis causes my train,validation and test datasets to have overlap between them. Is this supposed to happen and not a big deal? I would assume it\'s not a good idea to have the model train on validation and test data. @c_student I had the same problem and I figured out what I was missing: when you shuffle use the option reshuffle_each_iteration=False otherwise elements could be repeated in train, test and val\n\n\n\nThis is very true @xdola, and in particular when using list_files you should use shuffle=False and then shuffle with the .shuffle with reshuffle_each_iteration=False. | Show 2 more comments\n\nMost of the answers here use take() and skip(), which requires knowing the size of your dataset before hand. This isn\'t always possible, or is difficult/intensive to ascertain. Instead what you can do is to essentially slice the dataset up so that 1 every N records becomes a validation record. To accomplish this, lets start with a simple dataset of 0-9:\n\ndataset = tf.data.Dataset.range(10) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nNow for our example, we\'re going to slice it so that we have a 3/1 train/validation split. Meaning 3 records will go to training, then 1 record to validation, then repeat. split = 3 dataset_train = dataset.window(split, split + 1).flat_map(lambda ds: ds) # [0, 1, 2, 4, 5, 6, 8, 9] dataset_validation = dataset.skip(split).window(1, split + 1).flat_map(lambda ds: ds) # [3, 7]\n\nSo the first dataset.window(split, split + 1) says to grab split number (3) of elements, then advance split + 1 elements, and repeat. That + 1 effectively skips the 1 element we\'re going to use in our validation dataset. The flat_map(lambda ds: ds) is because window() returns the results in batches, which we don\'t want. So we flatten it back out. Then for the validation data we first skip(split), which skips over the first split number (3) of elements that were grabbed in the first training window, so we start our iteration on the 4th element. The window(1, split + 1) then grabs 1 element, advances split + 1 (4), and repeats. Note on nested datasets: The above example works well for simple datasets, but flat_map() will generate an error if the dataset is nested. To address this, you can swap out the flat_map() with a more complicated version that can handle both simple and nested datasets:\n\n.flat_map(lambda *ds: ds[0] if len(ds) == 1 else tf.data.Dataset.zip(ds))\n\n 7\n\nDoesn\'t window just use skip under the hood? How does is the disadvantage The other disadvantage is that with skip() it has to read, and then discard, all the skipped records, which if your data source is slow means you might have a large spool-up time before results are emitted. adressed? If you have a dataset of 1000 records, and you want a 10% for validation, you would have to skip the first 900 records before a single validation record is emitted. With this solution, it only has to skip 9 records. It does end up skipping the same amount overall, but if you use dataset.prefetch(), it can read in the background while doing other things. The difference is just saving the initial spool-up time. Thinking about it a bit more, and I removed the statement.""""""', '""""""Does that make sense? from the document image_dataset_from_directory it specifically required a label as inferred and none when used but the directory structures are specific to the label name. I am using the cats and dogs image to categorize where cats are labeled \'0\' and dog is the next label. import os import tensorflow as tf """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" Variables """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" PATH = \'F:\\\\datasets\\\\downloads\\\\sample\\\\cats_dogs\\\\training\' train_dir = os.path.join(PATH, \'train\') validation_dir = os.path.join(PATH, \'validation\') BATCH_SIZE = 1 # 32 IMG_SIZE = (32, 32) train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE) validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE) class_names = train_dataset.class_names print(\'Number of training batches: %d\' % tf.data.experimental.cardinality(train_dataset).numpy()) print(\'Number of validation batches: %d\' % tf.data.experimental.cardinality(validation_dataset).numpy()) """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" DataSet """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" AUTOTUNE = tf.data.AUTOTUNE train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE) validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE) """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" : Model Initialize """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" model = tf.keras.models.Sequential([ tf.keras.layers.InputLayer(input_shape=( 32, 32, 3 )), tf.keras.layers.Reshape((32, 32 * 3)), tf.keras.layers.Bidirectional(tf.keras.layers.LSTM( 32, return_sequences=True, return_state=False )), tf.keras.layers.Bidirectional(tf.keras.layers.LSTM( 32 )), tf.keras.layers.Dense( 256 ), tf.keras.layers.Dropout(.2), tf.keras.layers.Dense( 256 ), ]) model.add(tf.keras.layers.Flatten()) model.add(tf.keras.layers.Dense(10)) model.summary() """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" : Optimizer """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" optimizer = tf.keras.optimizers.Nadam( learning_rate=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\'Nadam\' ) # 0.00001 """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" : Loss Fn """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" # 1 # lossfn = tf.keras.losses.MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.AUTO, name=\'mean_squared_logarithmic_error\') # 2 lossfn = tf.keras.losses.SparseCategoricalCrossentropy( from_logits=False, reduction=tf.keras.losses.Reduction.AUTO, name=\'sparse_categorical_crossentropy\') """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" : Model Summary """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" model.compile(optimizer=optimizer, loss=lossfn, metrics=[\'accuracy\', tf.keras.metrics.CategoricalAccuracy()]) """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" : Training """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" history = model.fit(train_dataset, epochs=15000 ,validation_data=(validation_dataset)) input(""Press Any Key!"")\n\nEpoch 1233/15000 1/14 [=>............................] - ETA: 0s - loss: 1.2278e-05 - accuracy: 1.0000 - categorical_accuracy: 0.0000e+0 3/14 [=====>........................] - ETA: 0s - loss: 0.7675 - accuracy: 1.0000 - categorical_accuracy: 0.3333 14/14 [==============================] - 1s 40ms/step - loss: 1.3322 - accuracy: 0.7857 - categorical_accuracy: 0.5000 - val_loss: 1.1513 - val_accuracy: 0.7857 - val_categorical_accuracy: 0.5000\n\n\n\nJirayu KaewprateepJirayu Kaewprateep\n\n0\n\n""""""', '""""""Share Your Experience: How to use tf.keras.utils.image_dataset_from_directory to load test dataset? Asked 1 year, 10 months ago\n\nModified 1 year, 9 months ago\n\nI am using tf.keras.utils.image_dataset_from_directory in my binary classification Mobilenet V2 model to split the dataset by defining training and validation subsets as following:\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(directory, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, validation_split=0.2, subset=\'training\', seed=42) validation_dataset = tf.keras.utils.image_dataset_from_directory(directory, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, validation_split=0.2, subset=\'validation\', seed=42)\n\nNow, I want to use model.predict() on a set of images to look at the predictions. How can I use image_dataset_from_directory considering that there won\'t be two different folders containing the respective classes but only one folder for which I want the predictions? In addition, what should be the parameters of the image_dataset_from_directory function now? aguycalledankitaguycalledankit\n\n1\n\nYou need to have a separate directory containing test images. Then do the same thing you did for train/val datasets but with shuffle=False and without validation_split. As mentioned by @Djinn, You can do it in the same way and no need to define validation_split while accessing the folder. For example, Suppose I have a binary_data folder inside the dogs_cats/binary_data folder where I have stored multiple class images (5-5 images for each cats and dogs), then you can give the path till dogs_cats. This will automatically fetch all images inside the binary_data folder by stating class 1 where you can have multiple class images(binary - as per model) stored. After training the model, you can pass this dataset in model.predict() and can check the predictions for each image. Please check the below code:\n\ntest_dataset = tf.keras.utils.image_dataset_from_directory( ""/content/GoogleDrive/My Drive/MY WORK/dataset/dogs_cats/"", shuffle=True, #or False batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n\nFound 10 files belonging to 1 classes. and the predictions part:\n\npredictions = model.predict(test_dataset) predictions = tf.where(predictions < 0.5,0, 1) print(\'Predictions:\\n\', predictions.numpy())\n\nPredictions: [[0] [1] [0] [0] [1] [1] [1] [1] [1] [1]]\n\nNote: Prediction\'s accuracy may depend on the model performance. user11530462user11530462\n\nGood to know that.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nSplit a dataset created by Tensorflow dataset API in to Train and Test? Asked 6 years, 5 months ago\n\nModified 8 months ago\n\nDoes anyone know how to split a dataset created by the dataset API (tf.data.Dataset) in Tensorflow into Test and Train? 2\n\ntake(), skip(), and shard() all have their own problems.""""""', '""""""I hope it better answers your question. use Keras - model.fit(dataset,.., validation.split=0.7, ...) see its all possible arguments\n\n\n\nAssuming you have all_dataset variable of tf.data.Dataset type:\n\ntest_dataset = all_dataset.take(1000) train_dataset = all_dataset.skip(1000)\n\nTest dataset now has first 1000 elements and the rest goes for training. 1,3\n\nAs also mentioned in ted\'s answer, adding all_dataset.shuffle() allows for a shuffled split. Possibly add as code comment in answer like so? # all_dataset = all_dataset.shuffle() # in case you want a shuffled split\n\n\n\nTensorFlow 2.10.0 will have a utility function for splitting, see my answer: stackoverflow.com/a/73591823/1389680\n\n\n\ntake and skip return TfTakeDatasets/SkipDatasets which have less functionality than TfDatasets. Does anyone know how to map those to tfDatasets or split into train test splits and get back TfDataset objects? You may use Dataset.take() and Dataset.skip():\n\ntrain_size = int(0.7 * DATASET_SIZE) val_size = int(0.15 * DATASET_SIZE) test_size = int(0.15 * DATASET_SIZE) full_dataset = tf.data.TFRecordDataset(FLAGS.input_file) full_dataset = full_dataset.shuffle() train_dataset = full_dataset.take(train_size) test_dataset = full_dataset.skip(train_size) val_dataset = test_dataset.skip(val_size) test_dataset = test_dataset.take(test_size)\n\nFor more generality, I gave an example using a 70/15/15 train/val/test split but if you don\'t need a test or a val set, just ignore the last 2 lines. Creates a Dataset with at most count elements from this dataset. Creates a Dataset that skips count elements from this dataset. You may also want to look into Dataset.shard():\n\nCreates a Dataset that includes only 1/num_shards of this dataset. Disclaimer I stumbled upon this question after answering this one so I thought I\'d spread the love\n\n 7\n\nThank you very much @ted! Is there a way to divide the dataset in a stratified way? Or, alternatively, how can we have an idea of the class proportions (suppose a binary problem) after the train/val/test split? Thanks a lot in advance! Have a look at this blogpost I wrote; eventhough it\'s for multilabel datasets, should be easily usable for single label, multiclass datasets -> vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow\n\n\n\nThis causes my train,validation and test datasets to have overlap between them. Is this supposed to happen and not a big deal? I would assume it\'s not a good idea to have the model train on validation and test data. @c_student I had the same problem and I figured out what I was missing: when you shuffle use the option reshuffle_each_iteration=False otherwise elements could be repeated in train, test and val\n\n\n\nThis is very true @xdola, and in particular when using list_files you should use shuffle=False and then shuffle with the .shuffle with reshuffle_each_iteration=False. | Show 2 more comments\n\nMost of the answers here use take() and skip(), which requires knowing the size of your dataset before hand. This isn\'t always possible, or is difficult/intensive to ascertain. Instead what you can do is to essentially slice the dataset up so that 1 every N records becomes a validation record. To accomplish this, lets start with a simple dataset of 0-9:\n\ndataset = tf.data.Dataset.range(10) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nNow for our example, we\'re going to slice it so that we have a 3/1 train/validation split. Meaning 3 records will go to training, then 1 record to validation, then repeat. split = 3 dataset_train = dataset.window(split, split + 1).flat_map(lambda ds: ds) # [0, 1, 2, 4, 5, 6, 8, 9] dataset_validation = dataset.skip(split).window(1, split + 1).flat_map(lambda ds: ds) # [3, 7]\n\nSo the first dataset.window(split, split + 1) says to grab split number (3) of elements, then advance split + 1 elements, and repeat. That + 1 effectively skips the 1 element we\'re going to use in our validation dataset. The flat_map(lambda ds: ds) is because window() returns the results in batches, which we don\'t want. So we flatten it back out. Then for the validation data we first skip(split), which skips over the first split number (3) of elements that were grabbed in the first training window, so we start our iteration on the 4th element. The window(1, split + 1) then grabs 1 element, advances split + 1 (4), and repeats. Note on nested datasets: The above example works well for simple datasets, but flat_map() will generate an error if the dataset is nested. To address this, you can swap out the flat_map() with a more complicated version that can handle both simple and nested datasets:\n\n.flat_map(lambda *ds: ds[0] if len(ds) == 1 else tf.data.Dataset.zip(ds))\n\n 7\n\nDoesn\'t window just use skip under the hood? How does is the disadvantage The other disadvantage is that with skip() it has to read, and then discard, all the skipped records, which if your data source is slow means you might have a large spool-up time before results are emitted. adressed? If you have a dataset of 1000 records, and you want a 10% for validation, you would have to skip the first 900 records before a single validation record is emitted. With this solution, it only has to skip 9 records. It does end up skipping the same amount overall, but if you use dataset.prefetch(), it can read in the background while doing other things. The difference is just saving the initial spool-up time. Thinking about it a bit more, and I removed the statement.""""""', '""""""Share Your Experience: How to use tf.keras.utils.image_dataset_from_directory to load test dataset? Asked 1 year, 10 months ago\n\nModified 1 year, 9 months ago\n\nI am using tf.keras.utils.image_dataset_from_directory in my binary classification Mobilenet V2 model to split the dataset by defining training and validation subsets as following:\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(directory, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, validation_split=0.2, subset=\'training\', seed=42) validation_dataset = tf.keras.utils.image_dataset_from_directory(directory, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, validation_split=0.2, subset=\'validation\', seed=42)\n\nNow, I want to use model.predict() on a set of images to look at the predictions. How can I use image_dataset_from_directory considering that there won\'t be two different folders containing the respective classes but only one folder for which I want the predictions? In addition, what should be the parameters of the image_dataset_from_directory function now? aguycalledankitaguycalledankit\n\n1\n\nYou need to have a separate directory containing test images. Then do the same thing you did for train/val datasets but with shuffle=False and without validation_split. As mentioned by @Djinn, You can do it in the same way and no need to define validation_split while accessing the folder. For example, Suppose I have a binary_data folder inside the dogs_cats/binary_data folder where I have stored multiple class images (5-5 images for each cats and dogs), then you can give the path till dogs_cats. This will automatically fetch all images inside the binary_data folder by stating class 1 where you can have multiple class images(binary - as per model) stored. After training the model, you can pass this dataset in model.predict() and can check the predictions for each image. Please check the below code:\n\ntest_dataset = tf.keras.utils.image_dataset_from_directory( ""/content/GoogleDrive/My Drive/MY WORK/dataset/dogs_cats/"", shuffle=True, #or False batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n\nFound 10 files belonging to 1 classes. and the predictions part:\n\npredictions = model.predict(test_dataset) predictions = tf.where(predictions < 0.5,0, 1) print(\'Predictions:\\n\', predictions.numpy())\n\nPredictions: [[0] [1] [0] [0] [1] [1] [1] [1] [1] [1]]\n\nNote: Prediction\'s accuracy may depend on the model performance. user11530462user11530462\n\nGood to know that.""""""', '""""""Advertising & Talent Reach devs & technologists worldwide about your product, service or employer brand\n\nOverflowAI GenAI features for Teams\n\nOverflowAPI Train & fine-tune LLMs\n\nAbout the company Visit the blog\n\nSplit a dataset created by Tensorflow dataset API in to Train and Test? Asked 6 years, 5 months ago\n\nModified 8 months ago\n\nDoes anyone know how to split a dataset created by the dataset API (tf.data.Dataset) in Tensorflow into Test and Train? 2\n\ntake(), skip(), and shard() all have their own problems.""""""', '""""""I hope it better answers your question. use Keras - model.fit(dataset,.., validation.split=0.7, ...) see its all possible arguments\n\n\n\nAssuming you have all_dataset variable of tf.data.Dataset type:\n\ntest_dataset = all_dataset.take(1000) train_dataset = all_dataset.skip(1000)\n\nTest dataset now has first 1000 elements and the rest goes for training. 1,3\n\nAs also mentioned in ted\'s answer, adding all_dataset.shuffle() allows for a shuffled split. Possibly add as code comment in answer like so? # all_dataset = all_dataset.shuffle() # in case you want a shuffled split\n\n\n\nTensorFlow 2.10.0 will have a utility function for splitting, see my answer: stackoverflow.com/a/73591823/1389680\n\n\n\ntake and skip return TfTakeDatasets/SkipDatasets which have less functionality than TfDatasets. Does anyone know how to map those to tfDatasets or split into train test splits and get back TfDataset objects? You may use Dataset.take() and Dataset.skip():\n\ntrain_size = int(0.7 * DATASET_SIZE) val_size = int(0.15 * DATASET_SIZE) test_size = int(0.15 * DATASET_SIZE) full_dataset = tf.data.TFRecordDataset(FLAGS.input_file) full_dataset = full_dataset.shuffle() train_dataset = full_dataset.take(train_size) test_dataset = full_dataset.skip(train_size) val_dataset = test_dataset.skip(val_size) test_dataset = test_dataset.take(test_size)\n\nFor more generality, I gave an example using a 70/15/15 train/val/test split but if you don\'t need a test or a val set, just ignore the last 2 lines. Creates a Dataset with at most count elements from this dataset. Creates a Dataset that skips count elements from this dataset. You may also want to look into Dataset.shard():\n\nCreates a Dataset that includes only 1/num_shards of this dataset. Disclaimer I stumbled upon this question after answering this one so I thought I\'d spread the love\n\n 7\n\nThank you very much @ted! Is there a way to divide the dataset in a stratified way? Or, alternatively, how can we have an idea of the class proportions (suppose a binary problem) after the train/val/test split? Thanks a lot in advance! Have a look at this blogpost I wrote; eventhough it\'s for multilabel datasets, should be easily usable for single label, multiclass datasets -> vict0rs.ch/2018/06/17/multilabel-text-classification-tensorflow\n\n\n\nThis causes my train,validation and test datasets to have overlap between them. Is this supposed to happen and not a big deal? I would assume it\'s not a good idea to have the model train on validation and test data. @c_student I had the same problem and I figured out what I was missing: when you shuffle use the option reshuffle_each_iteration=False otherwise elements could be repeated in train, test and val\n\n\n\nThis is very true @xdola, and in particular when using list_files you should use shuffle=False and then shuffle with the .shuffle with reshuffle_each_iteration=False. | Show 2 more comments\n\nMost of the answers here use take() and skip(), which requires knowing the size of your dataset before hand. This isn\'t always possible, or is difficult/intensive to ascertain. Instead what you can do is to essentially slice the dataset up so that 1 every N records becomes a validation record. To accomplish this, lets start with a simple dataset of 0-9:\n\ndataset = tf.data.Dataset.range(10) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nNow for our example, we\'re going to slice it so that we have a 3/1 train/validation split. Meaning 3 records will go to training, then 1 record to validation, then repeat. split = 3 dataset_train = dataset.window(split, split + 1).flat_map(lambda ds: ds) # [0, 1, 2, 4, 5, 6, 8, 9] dataset_validation = dataset.skip(split).window(1, split + 1).flat_map(lambda ds: ds) # [3, 7]\n\nSo the first dataset.window(split, split + 1) says to grab split number (3) of elements, then advance split + 1 elements, and repeat. That + 1 effectively skips the 1 element we\'re going to use in our validation dataset. The flat_map(lambda ds: ds) is because window() returns the results in batches, which we don\'t want. So we flatten it back out. Then for the validation data we first skip(split), which skips over the first split number (3) of elements that were grabbed in the first training window, so we start our iteration on the 4th element. The window(1, split + 1) then grabs 1 element, advances split + 1 (4), and repeats. Note on nested datasets: The above example works well for simple datasets, but flat_map() will generate an error if the dataset is nested. To address this, you can swap out the flat_map() with a more complicated version that can handle both simple and nested datasets:\n\n.flat_map(lambda *ds: ds[0] if len(ds) == 1 else tf.data.Dataset.zip(ds))\n\n 7\n\nDoesn\'t window just use skip under the hood? How does is the disadvantage The other disadvantage is that with skip() it has to read, and then discard, all the skipped records, which if your data source is slow means you might have a large spool-up time before results are emitted. adressed? If you have a dataset of 1000 records, and you want a 10% for validation, you would have to skip the first 900 records before a single validation record is emitted. With this solution, it only has to skip 9 records. It does end up skipping the same amount overall, but if you use dataset.prefetch(), it can read in the background while doing other things. The difference is just saving the initial spool-up time. Thinking about it a bit more, and I removed the statement.""""""']"
