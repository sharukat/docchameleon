,QuestionId,Title,Body,QuestionURL,UserId,DocRelated
0,64821948,Iterating on Tensorfow Dataset returns always a differently sorted array,"Suppose you have a tensorflow dataset that has values and labels. In my case I created it from a time series as: Now for evaluation purposes I want to get the ground truth values of the test, so I am running but this is returning each time an array differently sorted, so it cannot be compared with the models predicted by the model. For example when running the above line in jupyter notebook and printing the first 5 values of y as `y[:5], one time I get another I get but the length of y remains the same so I am assuming that the elements are just shuffled around. Anyway with this I cannot compared these values with the predicted ones, since their order is different : Furthermore, I get also different evaluation results. For example, each time the loop defining the arrays x and y is re-executed, I get different x and y arrays that result in a different evaluation result.",https://stackoverflow.com/questions/64821948,1714692.0,1
1,67184239,Tensorflow randomly won't load at all,"i have been trying to run the basic tensorflow quickstart, but can't manage to do it i followed closely the basic instructions, and randomly, i end up with : when importing the module (import tensorflow) i have python 3.6.8, and executing exactly these instructions : https://www.tensorflow.org/install/pip#virtual-environment-install it's extremely inconsistent, sometimes it loads, and i'm able to run the quickstart, but most of the time it returns the error above, for no apparent reason it is the right version of tensorflow installed (2.4.1), and keras is installed as well (2.4.3) can you help me ?",https://stackoverflow.com/questions/67184239,13310136.0,1
2,41120332,tensorflow initialize_all_variables() location,"I'm studying MLP with tensorflow, using under code. It's functions are readfile,build parameters, train, testing, make AOC but this location makes error How can I avoid this error?",https://stackoverflow.com/questions/41120332,5973576.0,1
3,51911324,How to get the output predictions in TensorFlow,"As the title says, I'm trying to grab the actual prediction in my TensorFlow model. The issue is that I don't understand how to grab the prediction even though there are multiple answers already. I don't understand what data the pred.eval or the session functions need, and I was hoping someone here could explain it. The code I'm using is here: What do I do in this situation? Any advice is appreciated and thanks in advance",https://stackoverflow.com/questions/51911324,7601445.0,1
4,75656053,Using TensorFlow to predict inital values for curve fitting,"I have a mass of data, which needs to have curves fitted to based on some complicated mathematical function, and want to use SciPy's curve_fit function to do so. My problem is, that finding or predicting the initial values for fitting based on some aspects of the data is extremely tedious to do manually, but crucial as fits will be nonsensical if the inital values are not relatively accurate. This is why I am hoping to train a neural network to do this relatively reliably using TensorFlow. To this end, I tried writing a custom loss function for training, that runs scipy.optimize.curve fit on the training data with the predicted inital parameters, to judge how closely the optimized parameters match with the true parameters used in generating the training data. However, since you are apparently only allowed to use tensorflows built-in math operations in the custom loss function, I am at a loss at how to actually implement this. Here is a small example of what I am trying to do, with a linear function: This just raises Since scipy can't handle Tensors. Suggestions on how to handle this are much appreciated!",https://stackoverflow.com/questions/75656053,18255482.0,1
5,67159270,Keras layer channel-wise multiplication of scalar and graph plotting,"I try to multiply scalar values to each channel in a tensor: yields which is correct. Now I am trying to wrap that operation inside a keras.layers.Layer, whereby w is a learnable parameter. I also try to plot my model using tf.keras.utils.plot_model(m). I encounter several problems. I plot this model using Problem: I encountered the following warning: Question: Can I savely ignore the warning and the weights are still learned? If yes, how can I suppress this warning? As suggested in the warning, I wrap the multiplication in its own subclassed layer: Problem: This works until the model is plotted. Then I encounter the following error: AttributeError: 'ResourceVariable' object has no attribute '_keras_history' Traceback: Question: How do I resolve that error? Is this a bug (I submitted an issue to the tf github repo, however it was deleted immediately)? I try to use keras.layers.Multiply instead: Problem: ValueError: Can not merge tensors with different batch sizes. Got tensors with shapes : [(10, 64, 64, 256), (256,)] To my understanding, the ValueError occurs because the internal _Merge layer checks for equal batch sizes. The internal Multiply layer however implements the multiplication with broadcasting (which should work!): I could use tf.broadcast_to and so on, however, to my understanding this would materialize the tensor and would occupy more memory which I try to avoid. Question: Is there another way to make keras.layers.Multiply work, so ultimately the model plotting works?",https://stackoverflow.com/questions/67159270,9134300.0,1
6,59939344,Cannot merge multiple inputs tf.keras model / Error: Graph disconnected: cannot obtain value for tensor Tensor,I cannot understand why the concatenate layer is not working with year_input when compiling the tf.keras model. Details: Function call Error,https://stackoverflow.com/questions/59939344,12794504.0,1
7,51210536,Tensorflow Eager False Postive/Negative Etc Rate,I have eager execution enabled and wasnt sure how to find specificity values or false postive etc values from my test or training data Here is the code and i have determined accuracy but it is 90 percent due to my test data so need another way to analyse data,https://stackoverflow.com/questions/51210536,10042472.0,1
8,50000400,Getting the result into a variable,I have the following example code. I'm able to see the correct result in the console from the print function. What I'd like to be able to do is to put answer into a number var so that I can use it elsewhere. The answer I get is: But I'd like to get the 4.9999 into a variable so that I can round it up to 5 and print it on screen (in html).,https://stackoverflow.com/questions/50000400,658493.0,1
9,42342022,Get random gamma distribution in tensorflow like numpy.random.gamma,Hi I am new to tensorflow and I am trying to generate random gamma distribution in tensorflow just like numpy.random.gamma My numpy code is :- where n_topic=240 and n_voca=198 My tensorflow code is :- Is it a correct implementation? I believe I failed to understand the parameters of tf.random_gamma became self._lambda &lt;&gt; self.tf_lambda.,https://stackoverflow.com/questions/42342022,5217799.0,1
10,40919706,Updating variable values in tensorflow,"I've have a basic question about updating the values of tensors via the tensorflow python api. Consider the code snippet: Now let's assume I want to implement some sort of algorithm that iteratively updates the value of W (e.g. some optimization algo). This will involve steps like: the problem here is that W on the LHS is a new tensor, not the W that is used in yhat = tf.matmul(x, W)! That is, a new variable is created and the value of W used in my ""model"" doesn't update. Now one way around this would be which results in the creation of a new ""model"" for each iteration of my loop ! Is there a better way to implement this (in python) without creating a whole bunch of new models for each iteration of the loop - but instead updating the original tensor W ""in-place"" so to speak?",https://stackoverflow.com/questions/40919706,3854058.0,1
11,68214726,How to reset optimizer state from loaded checkpoint,"I saved a model using the ModelCheckpoint callback using the save_weights_only option Then when I wanted to fine-tune on a smaller dataset I loaded it back up: And I recompiled the model with a new optimizer: But the optimizer is somehow still stuck on the decayed lr from before rather than being set at the much higher lr I want now, and I'm not sure about the other optimizer parameters.",https://stackoverflow.com/questions/68214726,4391249.0,1
12,43647029,Tensorboard embedding visualization hanging when passed metadata (class labels),"Working with the new embedding visualisation capability in tensorboard (TF v1.0.1) I am having difficulty adding labels to the points it displays. Basically when I try to add this metadata the embedding tool hangs and never loads. Unfortunately the documentation for this tool is, at present, quite minimal. I have a 250 class supervised classification being trained (on something like AlexNet) and I can visualise the final fc layer (fc8) fine during training using the embedding tool. But as soon as I add some code to add labels to the plot i.e. to get the points in different colours by class (rather than all blue) the tab never loads (stuck on a message stating 'loading points' forever) The code I add prior to the epoch/training loop is: where fc8 is the tensor I want to visualise obtained earlier from the default graph. All the checkpoints, tensorboard events and now the metadata (labels) itself are being written into a subfolder called 'snapshots' The config file is being written out as projector_config.pbtxt as it should be, and contains If I delete this file then the embedding tab will load fine and won't hang i.e. I get to the dimmed screen and little white central box with 'loading tensors..' etc in it and an (unlabelled) point cloud is shown. Am I misconfiguring this? I don't get any errors logged to the console in which I invoke the tensorboard server even when I raise the GLOG level. Many thanks for any pointers.",https://stackoverflow.com/questions/43647029,3561741.0,1
13,49922674,"Difference between `tf.reshape(a, [m, n])` and `tf.transpose(tf.reshape(a, [n, m]))`?","Actually, I'm doing the homework ""Art Generation with Neural Style Transfer"" of deeplearning.ai on coursera. In the function compute_layer_style_cost(a_S, a_G): Why does this code give the right answer, however, the following doesn't:",https://stackoverflow.com/questions/49922674,7060278.0,1
14,65902185,TFLiteConverter representative_dataset from keras.preprocessing.image_dataset_from_directory dataset,"I've got a dataset coming in via (Based around code from https://www.tensorflow.org/tutorials/load_data/images with very minor changes to configuration) I'm converting the eventual model to a TFLite model, which is working, but I think the model's too large for the end device so I'm trying to run post training quantization by supplying a representative_dataset (like https://www.tensorflow.org/lite/performance/post_training_quantization) However I can't work out how to turn the dataset generated from image_dataset_from_directory into the format expected by representative_dataset The example provided has I've tried things like but that wasn't it",https://stackoverflow.com/questions/65902185,4353505.0,1
15,42323640,Tensorflow: AttributeError: module 'tensorflow' has no attribute 'Supervisor',"I'm trying to use the Supervisor class to create checkpoints that can be used to save/load partial trainings, as mentioned in the TensorFlow documentation - https://www.tensorflow.org/programmers_guide/supervisor . But when I try to use it as mentioned in the docs - It throws the below error - Whats am I missing?",https://stackoverflow.com/questions/42323640,4993842.0,1
16,43804684,tensorflow basic word2vec example: Shouldn't we be using weights [nce_weight Transpose] for the representation and not embedding matrix?,"I am referreing to this sample code in the code snippet below: Now NCE_Loss function is nothing but a single hidden layer neural network with softmax at the optput layer [knowing is takes only a few negative sample] This part of the graph will only update the weights of the network, it is not doing anything to the ""embeddings"" matrix/ tensor. so ideally once the network is trained we must again pass it once through the embeddings_matrix first and then multiply by the transpose of the ""nce_weights"" [considering it as the same weight auto-encoder, at input &amp; output layers] to reach to the hidden layer representation of each word, which we are are calling word2vec (?) But if look at the later part of the code, the value of the embeddings matrix is being used a word representation. This Even the tensorflow doc for NCE loss, mentions input (to which we are passing embed, which uses embeddings) as just the 1st layer input activation values. A normal back propagation stops at the first layer of the network, does this implementation of NCE loss, goes beyond and propagates the loss to the input values (and hence to the embedding) ? This seems an extra step? Refer this for why I am calling it an extra step, he has a same explanation.",https://stackoverflow.com/questions/43804684,3670532.0,1
17,70766226,The below code is giving 'UnreadVariable' error in tensorflow,I am getting the following error : I have tried : tf.compat.v1.disable_eager_execution() to disable eager tensor execution but I can't extract the values of any tensor post that. Also I don't know whether disabling eagerTensor actually solves the issue since I can't print the gradients or losses.,https://stackoverflow.com/questions/70766226,6027557.0,1
18,48814591,Too many values to unpack in TensorFlow KMean Class,I'm currently using the KMeans Class from tensorflow.contrib.factorization module. My input is (assuming all variables are defined): I'm following the documentation at https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeans to unpack the values like: I get the error: I'm strongly guessing that the documentation in the link stated above isn't updated because the output of kmeans.training_graph() is : Please let me know what is the extra returned valued that I'm not aware of by reading the documentation.,https://stackoverflow.com/questions/48814591,3749292.0,1
19,48067854,Trouble understanding tensorflow shuffle_batch enqueue_many=False,"I am reading the Tensorflow documentation and the code for the Cifar10 example. This bit is currently racking my brain: We are passing in a single image, and somehow a batch of images results?? What is going on here?",https://stackoverflow.com/questions/48067854,2886575.0,1
20,48541940,how to reset the tf.estimator.Estimator parameters?,I tried tf.Graph() but can't get the variable to reset by new. The code is below: and it just return error: =============== old infomation cut line ========= I defined a tf.estimator.Estimator model A by model_fn handler. I want to change model A's parameter by same old model's parameters as ckpt file. I try to get model A's graph and then get the parameter's variable in Graph and then assigned it by my old model's parameter. Hope some advices! Thanks very much!,https://stackoverflow.com/questions/48541940,1696015.0,1
21,75365737,"When fine-tuning a pre-trained Model, how does tensorflow know that the base_model has been changed?","Ng's Convolutional Neural Network class's Week 2 Lab on using Transfer Learning with MobileNetV2 (summary: https://github.com/EhabR98/Transfer-Learning-with-MobileNetV2) and an additional tutorial (https://blog.roboflow.com/how-to-train-mobilenetv2-on-a-custom-dataset/) both begin like this: They then proceed to add a pooling layer(s), a Dropout layer and a Dense 1-unit layer to the end, apply a BinaryCrossentropy loss and some kind of optimizer, then train it on some custom data that has been inputted. Lets call this custom model ""model2"" as Ng's lab does Here's what my the Coursera class model looks like, its important to include here because the variable base_model is called in two different closures throughout the Coursera lab (previous to this it was called outside of a method, as base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=True, weights='imagenet'); base_model.trainable= False) This performs OK, getting as much as 80% accuracy Fine tuning -- Now in both the course lab and the tutorial, they then proceed to ""unfreeze"" some of the last layers of the internal network so that they can be trained, like so: Up until this point, I'm satisfied, I can clearly see what is going on, but then: This leads to a marked improvement in results. Which confused me, I was very much expecting base_model to get passed in somehow. I didn’t imagine that altering some other variable that hasn’t been passed into or been initially called would come into play. So given all of that context, the question is: How is altering the base_model affecting model2? If the above example from the Coursera lab is as confusing to you as it is to me, the example shown on https://blog.roboflow.com/how-to-train-mobilenetv2-on-a-custom-dataset/ as mentioned above is much simpler and contains much less ambiguity as base_model is defined only once. Regardless, the same dynamic applies and I'm equally confused on both. Thanks again for your time",https://stackoverflow.com/questions/75365737,1276506.0,1
22,69782818,Turn a tf.data.Dataset to a jax.numpy iterator,"I am interested about training a neural network using JAX. I had a look on tf.data.Dataset, but it provides exclusively tf tensors. I looked for a way to change the dataset into JAX numpy array and I found a lot of implementations that use Dataset.as_numpy_generator() to turn the tf tensors to numpy arrays. However I wonder if it is a good practice, as numpy arrays are stored in CPU memory and it is not what I want for my training (I use the GPU). So the last idea I found is to manually recast the arrays by calling jnp.array but it is not really elegant (I am afraid about the copy in GPU memory). Does anyone have a better idea for that? Quick code to illustrate:",https://stackoverflow.com/questions/69782818,17289463.0,1
23,40790009,Tensorflow generate random values unexpected behaviour,I want to generate a random Vector and don't understand tensorflows results.... Code: gives me this:,https://stackoverflow.com/questions/40790009,2513126.0,1
24,54492880,add a matrix to an array of matrices,If I had a matrix then an array of matrices how could I add the matrix A to all the matrices in B to produce then how could I sum each matrix in B to produce a vector like ? I new to Tensorflow and my experience so far makes me feel there's an elegant way of doing this with a few lines of code.,https://stackoverflow.com/questions/54492880,1842347.0,1
25,63155929,How can I train a TensorFlow Quantum model that outputs a state vector?,"I want to train a simple circuit in TFQ using a Sequential model as follows: But instead of performing a readout op, I'd like the model to output the state vector so I can do some post-processing on it before I feed it into my loss function. In principle, tfq.layers.State looks like it's appropriate for this task, but it is not clear to me from the examples how I would use the State layer in a model context, vs just using it to generate the state vector as shown in the docs: So my questions:",https://stackoverflow.com/questions/63155929,13568630.0,1
26,57115332,How to define a ReLU with TensorFlow custom_gradient?,"I'm practicing using TensorFlow's custom_gradient decorator and I tried to define a simple ReLU. One would think it would be as simple as defining the gradient to be 1 when x &gt; 0 and 0 otherwise. However, the following code does not yield the same gradients as a ReLU: Can someone explain to me why this standard definition of ReLU's gradient does not yield the same performance as:",https://stackoverflow.com/questions/57115332,10210261.0,1
27,49579103,Implementing with block manually produces different things,"Suppose I write My impression is that the with command starts by calling the __enter__() method on whatever is returned by some_method(). (I believe the thing returned by some_method() is called a ""context manager"", which just means it has methods called __enter__() and __exit__().) I tried calling __enter__() manually, and I got something different from what I expected. This specific example came up in the context of TensorFlow, but I'm pretty sure it doesn't have anything to do with TensorFlow as such. prints None, and prints None, but prints &lt;tensorflow.python.client.session.Session object at 0x114217a90&gt;. I have posted essentially the same question here, but I made the mistake of editing it too many times, until by the end it wasn't asking what it started out asking. So I'm just recreating the question.",https://stackoverflow.com/questions/49579103,8755792.0,1
28,52860103,Why does start_queue_runners() function use with shuffle_batch() function,I am new to TensorFlow and trying to understand the shuffle_batch() function.When I use the shuffle_batch() with following code it does not printing anything. But after adding the start_queue_runners() it gives me the expected output. So what is the relationship between these start_queue_runners() and shuffle_batch() ?,https://stackoverflow.com/questions/52860103,7447265.0,1
29,50625145,How to set the values of all the parameters of a tensorflow model?,"I have a big tensorflow model (not using Keras). I know I can save and restore a tensorflow model, but what I need is different. I want to store all the trainable parameters of the model in the memory, set all the trainable parameters to another set of values that I already have, and do predictions, and then restore the previously stored parameters back to the model. Pseudo code: Note that set_trainable_variables(vars) function is only hypothetical, My question is: How to implement set_trainable_variables(vars)?",https://stackoverflow.com/questions/50625145,956730.0,1
30,47913968,How to read all Example records from a TFRecord file in one go using Dataset API?,"I am using a Spark job to generate a TFRecord file which will be my vocabulary file of (word, count) pairs. I want to load the entire file at once using the Dataset API since my vocabulary file could be on HDFS and might be split across multiple physical files. That said, I am finding it pretty unintuitive. Here's my code so far: Using a huge, fixed up-front batch size is the only way I can think of slurping up all the data at once in a tensor of shape=(num_entries,). It seems to run pretty slow as well. Is there a better way?",https://stackoverflow.com/questions/47913968,2202478.0,1
31,68806135,"ValueError:Input 0 of layer lstm_45 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, None, None, 128)","I'm new to deep learning and have a problem with understanding embedding and passing sequence of 4 feature vectors (all floats) to an LSTM model. My model looks as following: I also had troubles with passing sequences of different length but ragged input solved it. This is the error I'm getting: ValueError: Input 0 of layer lstm_45 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, None, None, 128)",https://stackoverflow.com/questions/68806135,16680962.0,1
32,54703128,"No gradients provided for any variable, check your graph for ops that do not support gradients, between variables and loss","I am trying to build a Bayesian Softmax Regression model using the TensorFlow Probabilities Dense Flip-Out layer. This model is being trained on the MNIST dataset. TensorFlow is returning an error: I presume this is due to the fact that random variables are not differential, thus no gradient exists. However, Tensorflow provides a clear demonstration of this code on their website - here. Does anyone have a comprehensive answer as to why this is happening? My code is as below:",https://stackoverflow.com/questions/54703128,11055886.0,1
33,43748788,Tensorflow Exception in QueueRunner: Enqueue operation was cancelled,I'm new to Tensorflow adn are trying to read images and labels. The code below works fine but every time it has finished it ends with producing an massive error. I test it using: I can access the image but when the program finishes it produces the error: I don't am stuck on this so any help would be much appriciated,https://stackoverflow.com/questions/43748788,6073705.0,1
34,67275213,3d input for Dense Layer Keras,"Is there any example of how Keras Dense layer handles 3D input. The documentation explains the following: But I could not understand the internal matrix calculation For example: based on the documentation for a 3D input of shape (m,d0,d1), the shape of Layer's weight_matrix (or) kernel will have the shape (d1, units) which is (2,5) in this case. But I don't understand how the op is calculated to have the shape (m,d0, units)",https://stackoverflow.com/questions/67275213,5927701.0,1
35,37128652,Creating log directory in tensorboard,I am trying to learn how to use tensorboard and I would like to have it run in my program. I do not understand how to create a log directory. These are the lines I have for running tensorboard. The error message that I got was,https://stackoverflow.com/questions/37128652,5823453.0,1
36,62116136,Tensorflow Keras Metrics Not showing,"I have a simple Neural Network summary of model is and compilation as Now when I print Model attributes, it gives an empty list on metrics. Why is it so? This is output",https://stackoverflow.com/questions/62116136,10342778.0,1
37,57795697,tf.keras h5 to Tensorflow pb - resulting pb lacks output node even though input clearly has it?,"I am using Google Collab, training a sequence model (NASNet) with a custom output. I export my model to an h5 using the model.save() method. I use a separate ipynb to load my h5 and convert it to a pb, however, my resulting pb lacks a named output node, and I cannot get predictions from my resulting model. My model sequence definition: I am able to make compile my model, train, and make predictions in collab. I export my model like so: To convert to Tensorflow PB, I use a new ipynb and am able to 'successfully' run the conversion (ie, it doesn't fail). The conversion code seems widely used elsewhere. Here it is: This resulting pb appears well formed at first glance, but Netron and other tooling indicates it has no final output node in the graph. I am able to verify my tf.keras h5 model has inputs and outputs in my first ipynb via: Which returns: And when I load my saved h5 in prep to convert to Tensorflow protobuff, I also check the inout and output names: Which returns in TF naming convention: So clearly my h5 appears to have an output node named 'output' - as confirmed in Netron when I inspect the H5. Why does my conversion code appear to be removing the output node in the pb graph? Thank you!",https://stackoverflow.com/questions/57795697,5510818.0,1
38,63832318,"Keras, using a generator for the data (VAE)","I'm currently trying to implement a variational autoencoder but I'm quite stuck, I cannot understand how to use a datagenerator in Keras. What I have so far is: There is a lot of code, but it does work fine as long as I used my entire dataset, but as soon as I try to use my implemented ""train_generator"" it breaks down and I get the error message: NotImplementedError: When subclassing the Model class, you should implement a call method. So I know there is something wrong with my implementation of the train_generator, but I dont understand what I've missed, can someone provide me more information?",https://stackoverflow.com/questions/63832318,6496448.0,1
39,48132807,Why does tensor flow return NaN when running variables after training?,"I can't really understand why this is not working, basically I'm trying to retrieve values for m and q just to print them but I always get [nan, nan] train.csv and test.csv are both files with a header line and two columns of values, x and y First 10 lines of train.csv",https://stackoverflow.com/questions/48132807,7015035.0,1
40,37668485,Create an int list feature to save as tfrecord in tensorflow?,How can I create a tensorflow record from a list? From the documentation here it seems possible. There's also this example where they convert a numpy array into a byte array using the .tostring() from numpy. However when I try to pass in: I get the error: Which doesn't help me to figure out how to store a list of integers into the tfrecord. I've tried looking through the docs.,https://stackoverflow.com/questions/37668485,6416660.0,1
41,57304811,Why can't I use my dataset anymore after using InceptionV3?,"I'm currently working on video-captioning (frame-sequence to natural language). I recently started using tf.data.Dataset class instead of feed_dict argument in tensorflow. My goal is to feed this frames to a pretrained CNN (inceptionv3), extract the feature vector and then feed it to my RNN seq2seq network. I've got a problem of tensorflow types after mapping my Dataset with the inception model: the dataset is then totally unusable, neither via dataset.batch() or dataset.take(). I can't even make a one shot iterator ! Here is how I proceed to build my Dataset: Step 1: I first extract the same number of frames for every videos. I store all of it into a numpy array. Its shape is (nb_videos, nb_frames, width, height, channels) Note that in this dataset, every video has the same size and has 3 color channels. Step 2: Then I create a tf.data.Dataset object using this big numpy array Note that printing this dataset via python gives: With n_videos=2; width=240; height=320; channels=3 I already don't understand what ""DataAdapter"" stands for At this point; I can create a one shot iterator but using dataset.batch(1) returns: I don't understand why ""?"" and not ""1"" shape.. Step 3: I use the map function on dataset to resize all the frames of all the videos to 299*299*3 (required to use InceptionV3) At this point, I can use the data in my dataset and make a one shot iterator. Step 4: I use the map function again to extract every features using InceptionV3 pretrained model. The problem occurs at this point: Printing the dataset gives: Ok looks good However, it's now impossible to make a one shot iterator for this dataset Step1 : Step 2: Step 3: Step 4: Inception model: For the tf.reduce_mean; see how-to-get-pool3-features-of-inception-v3-model-using-keras (SO) Creating the iterator: Here is the output: I don't really get it: it asks me to use a initializable_iterator but this kind of iterator is dedicated for placeholder. Here, I've got raw data !",https://stackoverflow.com/questions/57304811,11839345.0,1
42,50308951,Understanding input/output tensors from tf.layers.conv2d,"I'm trying to understand the transformation performed by tf.layers.conv2d. The mnist tutorial code from the TensorFlow website includes the convolution layer: However, my expectation is that the 32 input images would be multiplied by the number of filters, as each filter is applied to each image, to give an output tensor of [batch_sz, 14, 14, 2048]. Clearly this is wrong, but I don't know why. How does the transformation work? The API documentation tells me nothing about how it works. What would be the output if the input tensor was [batch_size, 14, 14, 48]?",https://stackoverflow.com/questions/50308951,6077080.0,1
43,42856421,Tensorflow freezes on sess.run call using queues,"I am testing the tensoprflow queues system and I have a simple tensorflow program that use queues to process the input. The code of sample program is The problem is that it freeze at the first p = sess.run(model2layers(example_batch)), it stop there indefinitely. What is wrong in the sample program?",https://stackoverflow.com/questions/42856421,2197507.0,1
44,63337329,Adam optimizer - ValueError: tf.function-decorated function tried to create variables on non-first call,"I am using tensorflow 2.3 The code below gives exception Problem looks like tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N]) creates new variable on &gt; first call, while using @tf.function. If must wrap it under @tf.function, how should I modify it? (in real case run() is a much bigger function)",https://stackoverflow.com/questions/63337329,1497720.0,1
45,49419720,"TypeError: Value passed to parameter 'input' has DataType float64 not in list of allowed values: float16, bfloat16, float32","I have read many questions similar to mine, but all of them are different with mine. The question is: After I use my own data (vessel segmentation, which is a Two Classification Problems), the data read by using next_batch is float64, while feed_dict() needs float32. Commonly, codes like tf.cast or tf.tp_float can be used to convert my data to float32. However, after using those converting codes, I found the error changed to TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. Finally, I tried to use sess.run to off-set its tf.Tensor form. Erorr changed to the original one, which means my data was converted back to float64. Thus, it seems to be an endless loop. ""Without converting, float64 will not be accepted. After converting, Tf. Tensor will also not be accepted. To off-set the tf.Tensor form using sess run, data will be converted back to float64 simultaneously"" How can I fix this? I am looking forward to your reply !The similar question is here, TensorFlow TypeError: Value passed to parameter input has DataType uint8 not in list of allowed values: float16, float32",https://stackoverflow.com/questions/49419720,9532057.0,1
46,58427004,Tensorflow neural network doesn't optimize properly,"I am a beginner to neural networks and TensorFlow, I have tried the following code for handwritten digit classification (single layer perceptron model) I have downloaded the dataset from kaggle which contains the first column as the digit and the next 784 columns the pixel values. Output always shows: 0 42000.0 1 42000.0 2 42000.0 3 42000.0 4 42000.0 5 42000.0 6 42000.0 7 42000.0 8 42000.0 9 42000.0 10 42000.0 . . . etc So, I assume that the neural networks aren't working. I have tried learning rates 0.01, 0.2, 0.3, but it shows the same output. What's wrong here? Should I add hidden layers? EDIT: I have also tried to get the output for test samples. It shows the same output for every test sample:",https://stackoverflow.com/questions/58427004,12210196.0,1
47,38543850,How to Display Custom Images in Tensorboard (e.g. Matplotlib Plots)?,"The Image Dashboard section of the Tensorboard ReadMe says: I see how a pyplot image could be written to file, read back in as a tensor, and then used with tf.image_summary() to write it to TensorBoard, but this statement from the readme suggests there is a more direct way. Is there? If so, is there any further documentation and/or examples of how to do this efficiently?",https://stackoverflow.com/questions/38543850,5587428.0,1
48,59144938,How to loop over batch_size in keras custom layer,"I want to create a custom layer that takes in __init__ a internal tensor and a custom dot function so that it computes for a given batch the dot function over all possible pairs made with the batch and the internal tensor. If I were to use the natural inner product, I could write directly tf.matmul(inputs, self.internal_tensor, transpose_b=True) but I want to be able to give other kernel methods. MWE: For the sake of clarity, here is the target working layer in Numpy:",https://stackoverflow.com/questions/59144938,4444546.0,1
49,47952640,how to padded batch in dataset for each dimension padding to max length of all dimensions,"I already know dataset provide padded_batch function to padded batch as below: I want to padding each dimension in my batch to the max length of all dimensions, but the above function can't achieve this. for example: the element in my dataset is as below: if I apply the function like this: I got the result as below: this is not what I wanted, I am struggling with this problem for a long time, can any one help me?",https://stackoverflow.com/questions/47952640,9133804.0,1
50,55201647,How to use plt.hist() to plot a histogram out of a 1-D tensor without enabling eager execution?,"What I want to do is to write a function which can convert a one dimensional tensor to a numpy array and plot a histogram out of it using plt.hist(). Uptil now I have tried doing this: The above as is clearly visible will give an error telling that a placeholder cannot be fed value using a tensor as one_dimensional_tensor is a tensor. I do not initially know the value of one_dimensional_tensor, it is the intermediate output of some prior computation, so I cannot do this: I do not want to use tf.histogram_fixed_width() as it uses only one binning technique in which the bin widths are fixed unlike plt.hist() which provides a variety of binning techniques. Is there any way to do this without enabling eager execution?",https://stackoverflow.com/questions/55201647,7184172.0,1
51,63908516,Storing Trainable Values in TensorArray for While_loop - tensorflow,"I'm working on a small Tensorflow model using Tensorflow 2.3.0. in the model I use several tf.while_loops and TensorArray. The model is not working as expected. I tried to troubleshoot the issue but unfortunately not all Tensorflow behavior is documented and I'm not sure if there is a bug in my model or it is Tensorflow behavior I'm unaware of. For example in my model I multiply my data with some weights inside a tf.while_loop. I then store the result in TensorArray . The TensorArray content is again used in the same fashion until I minimize the loss to train the model. my problem is that the model does not train as expected . I suspect that tensorflow is freezing the weights and not updating them as I would expect. How can I make sure that the content of the last TensorArray remains trainable since it is produced using data with trainable weight variables . I'm trying to avoid the issue mentioned here but not sure if I have. below is a simple example ( dummy model ) just to clarify what I'm doing : In the above example the content of array2 should be the predictions. how can I make sure that the loops and the tensorArray did not affect the train-ability of my variables ? If what I did was incorrect. whats the best approach to achieve the same thing but keeps my result trainable. Update :: Ok , So I ran the my model for some times and monitored the loss, accuracy and other scaler metrics. And found a general trend in loss decrease and accuracy and other accuracy related metric increase. the Accuracy and loss are also inverse of each other , to my understanding this indicates that the updates are not random and the model is learning something. Additionally I monitored the weights and gradients distributions are changing which confirms that variables are being trained. Can you some please confirm my conclusion and understanding ? Thanks for your help in Advance.",https://stackoverflow.com/questions/63908516,4821136.0,1
52,70554665,How to convert 'GradientDescentOptimizer' in TensorFlow 2.7,I want to convert this code to work in TensorFlow 2.7 and here is what I got,https://stackoverflow.com/questions/70554665,17642993.0,1
53,43380484,TensorFlow: Linear Regression with multiple inputs returns NaNs,"This is my first attemp at TensorFlow: I am building a Linear Regression model with multiple inputs. The problem is that the result is always NaN, and I suspect that it is because I am a complete noob with matrix operations using numpy and tensorflow (matlab background hehe). Here is the code: And here is the output:",https://stackoverflow.com/questions/43380484,2597143.0,1
54,42487908,tensorflow tf.Operation run method usage,"I am exploring tensorflow. I have the following problem that I will illustrate in a small code fragment. I am not searching for the best way, I am just exploring all options So my question here is, what is the purpose of tf.Operation.run and how I should be using it. What is wrong with my code? Shouldn't c_operation.run return the value of the resulting operation. Does the associated tensor (c here) holds the values? I did not find a way to extract them (aside from using sess.run(c)",https://stackoverflow.com/questions/42487908,1392241.0,1
55,53291939,How do I use tensor2tensor's distillation.py to distill the knowledge from a teacher network to student network?,"Top Level Problem I want to use a teacher network and distill its performance/knowledge on a small subset of its power to another simpler model Attempted solution I am trying to get started with the T2T distillation code. https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/distillation.py Problems with Attempted solution I am struggling to understand how to use it for my teacher and my student. Are there any examples that show how it works I could get running first? How do I get it work on an existing model in T2T? How do I get it to work on a model defined in Keras? I understand how this block is what I'm supposed to use to register my model in T2T. But how do I start the training? I searched github for distill_resnet_32_to_15_cifar20x5, and the only hits were duplicate forks of the T2T repo with no examples of how to use this. Full Code: distillation.py",https://stackoverflow.com/questions/53291939,1018733.0,1
56,57435730,How to use RaggedTensor with tf.data API,"I would like to use RaggedTensor with the tf.data API, but it seems that the tensor shape is not correctly evaluated. Here's an example that converts the batches into RaggedTensor, and back into Tensor: This outputs: As the shape is unknown, I am unable to use this tensor in my model. How can I make it so the shape of the tensor converted from the RaggedTensor evaluates correctly? FYI, this is the shape of the tensor if not converting to Ragged and back again:",https://stackoverflow.com/questions/57435730,4979620.0,1
57,49912441,How to get batch size back from a tensorflow dataset?,"It is recommended to use tensorflow dataset as the input pipeline which can be set up as follows: I should be able to get the batch size (either from dataset itself or from an iterator created from it, i.e. both iterator and next_batch). Maybe someone wants to know how many batches there are in the dataset or its iterators. Or how many batches have been called and how many remain in the iterator? One might also want to get particular elements, or even the entire dataset at once. I wasn't able to find anything on the tensorflow documentation. Is this possible? If not, does anyone know if this has been requested as an issue on tensorflow GitHub?",https://stackoverflow.com/questions/49912441,7428659.0,1
58,41230644,Tensorflow matmul operation for rank>2 does not work,I find the following on the Tensorflow documentation homepage for using the matmul operation when rank&gt;2: https://www.tensorflow.org/api_docs/python/math_ops/matrix_math_functions#matmul It simply isn't working when I plug it in Python. I get Anyone know what is wrong?,https://stackoverflow.com/questions/41230644,7318197.0,1
59,42714097,distributed Tensorflow tracking timestamps for synchronization operations,"I am new to TensorFlow. Currently, I am trying to evaluate the performance of distributed TensorFlow using Inception model provided by TensorFlow team. The thing I want is to generate timestamps for some critical operations in a Parameter Server - Worker architecture, so I can measure the bottleneck (the network lag due to parameter transfer/synchronization or parameter computation cost) on replicas for one iteration (batch). I came up with the idea of adding a customized dummy py_func operator designated of printing timestamps inside inception_distributed_train.py, with some control dependencies. Here are some pieces of code that I added: I modified into hoping to print the timestamps before evaluating the apply_gradient_op and after finishing evaluating the apply_gradient_op by enforcing node dependencies. I did similar things inside sync_replicas_optimizer.apply_gradients, by adding two dummy print nodes before and after update_op: I understand that apply_gradient_op is the train_op returned by sync_replicas_optimizer.apply_gradient. And apply_gradient_op is the op to dequeue a token (global_step) from sync_queue managed by the chief worker using chief_queue_runner, so that replica can exit current batch and start a new batch. In theory, apply_gradient_op should take some time as replica has to wait before it can dequeue the token (global_step) from sync_queue, but the print result for one replica I got, such as the time differences for executing apply_gradient_op is pretty short (~1/1000 sec) and sometimes the print output is indeterministic (especially for chief worker). Here is a snippet of the output on the workers (I am running 2 workers and 1 PS): chief worker (worker 0) output worker 1 output",https://stackoverflow.com/questions/42714097,3117069.0,1
60,44381879,Training and Predicting with instance keys,"I am able to train my model and use ML Engine for prediction but my results don't include any identifying information. This works fine when submitting one row at a time for prediction but when submitting multiple rows I have no way of connecting the prediction back to the original input data. The GCP documentation discusses using instance keys but I can't find any example code that trains and predicts using an instance key. Taking the GCP census example how would I update the input functions to pass a unique ID through the graph and ignore it during training yet return the unique ID with predictions? Or alternatively if anyone knows of a different example already using keys that would help as well. From Census Estimator Sample Update: I was able to use the suggested code from this answer below I just needed to alter it slightly to update the output alternatives in the model_fn_ops instead of just the prediction dict. However, this only works if my serving input function is coded for json inputs similar to this. My serving input function was previously modeled after the CSV serving input function in the Census Core Sample. I think my problem is coming from the build_standardized_signature_def function and even more so the is_classification_problem function that it calls. The input dict length using the csv serving function is 1 so this logic ends up using the classification_signature_def which only ends up displaying the scores (which turns out are actually the probabilities) whereas the input dict length is greater than 1 with the json serving input function and instead the predict_signature_def is used which includes all of the outputs.",https://stackoverflow.com/questions/44381879,6520820.0,1
61,66316107,Unable to load model in Tensorflow CPU only version,"I'd like to apologise for asking another newbie question, but i'm trying to load model using load_model() method in Tensorflow (CPU only version). I tried setting environment variable link Or As per @kosa answer model.summary() giving me following output.",https://stackoverflow.com/questions/66316107,,1
62,53362642,What does the first value returned from tf.metrics.accuracy represent,"I'd like to understand the values returned from tf.metrics.accuracy Consider this minimal example: which outputs: The second value is what I'd expect (we have 5/6 values where predictions == labels so 5/6 ~= 0.83) but the first zero value is a mystery to me? The TensorFlow docs have this to say: but this suggests that both return ops should have value of 0.83, no? (but then what would be the point of returning 2 ops?!) Feel like I am missing something fundamental!",https://stackoverflow.com/questions/53362642,2455494.0,1
63,56478454,"In TensorFlow 2.0 with eager-execution, how to compute the gradients of a network output wrt a specific layer?","I have a network made with InceptionNet, and for an input sample bx, I want to compute the gradients of the model output w.r.t. the hidden layer. I have the following code: But, this will give None. I tried gtape.watch(bx) as well, but it still gives None. Before trying GradientTape, I tried using tf.keras.backend.gradient but that gave an error as follows: My model is as follows: Any solution is appreciated. It doesn't have to be GradientTape, if there is any other way to compute these gradients.",https://stackoverflow.com/questions/56478454,2191236.0,1
64,44672832,What does the 'training loss' mean in machine learning?,I found some sample code on the tensorflow website as follows. Would you let me know what the 'training loss' means?,https://stackoverflow.com/questions/44672832,8193393.0,1
65,50673196,keras triplet loss crashes when training,"I am trying to implement a simple face recognition application but I have been stuck with a problem for days now. Hopefully someone having more experience in the subject can help. Fingers crossed. Here is the program: When I call the function siamese_network.fit(...), it crashes and gives the following error, which tells me absolutely nothing!! Does anyone have any idea about how to solve this?",https://stackoverflow.com/questions/50673196,9328846.0,1
66,58121054,TensorFlow Keras SavedModel empty variables folder,"I have a TensorFlow keras model that looks like the following: I save it to a format servable with TensorFlow Serving, with the following code and inputs: I expect 6 outputs, each cooresponding to a class and their likelyhood. Using model.predict(), this seems to work fine: the model returns arrays like this [0.15914398 0.152271 0.18949589 0.14985411 0.17449048 0.1747446 ]. However, the SavedModel that I want to use with TensorFlow Serving that is produced by the code has an empty 'variables' folder upon generation, leaving only the saved_model.pb file. When I request the model with the saved_model_cli I get the following: Why is this the case and how can I get the behaviour I want? Thanks!",https://stackoverflow.com/questions/58121054,11765356.0,1
67,51329327,"Why the import ""from tensorflow.train import Feature"" doesn't work","That's probably totally noob question which has something to do with python module importing, but I can't understand why the following is valid: But the following statement causes an error: Can please somebody explain me why it doesn't work this way? My goal is to use more short notation in the code like this: tensorflow version is 1.7.0",https://stackoverflow.com/questions/51329327,3009130.0,1
68,64342985,Compute the Laplacian of Gaussian using tensorflow,"I've found an implementation which makes use of numpy and cv2 (link), but I'm having difficulties converting this code to tensorflow. The code for the numpy implementation: And my converted code: The laplacian filter values are taken from the cv2 docs. The results don't really look alike, and I'm having trouble finding the reason. The results from the laplacian convolution already greatly differ in cv2 and tensorflow, but I really can't see why. Any ideas?",https://stackoverflow.com/questions/64342985,4934061.0,1
69,45154470,Tensorflow step size incredibly small to prevent errors?,"I'm trying to do a simple linear regression problem using Gradient Descent with Tensorflow, but unless I set my step size really, really small, the weight and bias balloon and overflow almost immediately. Here's my code: So basically, when I run this, the outputs become ""NaN"" almost immediately. Any ideas? Thanks in advance!",https://stackoverflow.com/questions/45154470,646592.0,1
70,42464742,how to weight gradient in different examples,"Assume I have a dataset x_data, each row is an example with dim = 3, then I have a 3 * 2 weight matrix w, my output is x_data * w. Then I want to get the gradient of the weight matrix. So I use tf.gradients . But it seems to sum the gradients for each example directly. What I want is to sum the gradients of each example by a distribution. So I use a tf.constant coef as the distribution. It works well. However my problem is I don't know what to do if coef is also a tensorflow variable. When it also depends on w, I can't use tf.multiply(coef, res) simply.",https://stackoverflow.com/questions/42464742,3650053.0,1
71,56514673,Keras model.reset_states() does not work with tf.train.MonitoredTrainingSession,"I want to use tf.train.MonitoredTrainingSession() for training a model described in Keras. This model is a stateful model, so I want to reset the states after every epoch. One problem is that if I call model.reset_states(), it generates the following error. RuntimeError: Graph is finalized and cannot be modified. If tf.Session() is used instead of tf.train.MonitoredTrainingSession(), this error doesn't appear. For example, in the following sample code even though it is not a training code, the same error message is generated. I found two ways to resolve this problem: But I think both approaches are not ideal. Could you please suggest what would the best solution in this case?",https://stackoverflow.com/questions/56514673,735008.0,1
72,49093292,"In Tensorflow, what is the difference between the returned 'output' and 'h' of state tuple (c, h) in LSTMCell?","I've searched across many tutorials/blogs/guides and official Tensorflow documentation to understand this. For example, see below lines: Now if I unpack state, Both output and last_hidden_state have exact same dimensions of [batch_size, 512]. Can both be used interchangeably? I mean, can I do this? : and then feed last_state_tuple in lstm?",https://stackoverflow.com/questions/49093292,6664016.0,1
73,67224476,Tensorflow Input Dimension mismatch problem,"I have created an LSTM-NN. I am passing an input but I get the error: ValueError: Input 0 of layer lstm is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (7,) To resolve this, I have referred to a stack overflow post that mentions use of the argument: input_shape. I still have not been able to resolve my problem due to a lack of understanding. Kindly help. Here is my code",https://stackoverflow.com/questions/67224476,7971339.0,1
74,62861991,Minimizing the maximal loss in a batch of augmented data,"I'm trying to implement the MaxUp approach (https://arxiv.org/pdf/2002.09024v1.pdf) in order to improve my image classifier's generalization. As far as I understand, the essence of the method is that for each data point from our dataset we generate a small set of perturbed or augmented data points (in my case, I used augmentation) and get a batch of m augmented images. Then we pass this batch through the neural network and calculate losses for each example in the batch. After that, we optimize the network using only the maximum loss. We basically minimize the maximum loss. I'm using Imagenette dataset(https://github.com/fastai/imagenette) which I balanced beforehand. So, I built a simple convnet consisting of 3 VGG blocks. I defined a custom loss function so that it would return max loss instead of average loss. I made a generator that returns any number of augmented images based on one image. During training, I generate a batch of augmented images, do a forward pass, calculate max loss, and update the model by applying gradients. However, my neural network doesn't seem to train at all. I get the following output: I also tried the high-level model.fit method and got the same results. The problem is most likely in either my custom loss or data generator. Can you tell me what I'm doing wrong? I'm pretty sure there is a way to do it easier. Thank you in advance. UPD: I tried random gaussian perturbations instead of augmentation, and it didn't seem to change much... Also, as I continued exploring the problem, I noticed that when I replace the ""reduce_max"" operation with ""reduce_mean"", the training accuracy, as well as validation accuracy, starts increasing. However, the paper states that they somehow minimize the maximal loss. Is there some other method of minimizing the maximal loss?",https://stackoverflow.com/questions/62861991,13916754.0,1
75,73006051,how to get discrete values as output in Keras?,"I'm trying to get an output just like [3,4,0,2,1] (discrete values between 0 and 4) without repetition. this is the code of my model: ordre function is implemented : but I get as error",https://stackoverflow.com/questions/73006051,12153567.0,1
76,37379836,chain together tensorflow operations as user defined function,"I am wondering whether there is an easy way to define a user defined tensorflow operation if it consists only of chained tensorflow operations. This is just to make code from being unnecessarily long, especially if the same operations must be performed on similar objects: For example, if I want to define a feed forward mechanism on a neural network with 2 hidden layers, I will need to do this: However, this oftentimes needs to be done for validation and test sets also, so I would like to define a function which would let me do all the operations in a single swoop so I could get something like this: This seems like something simple to do, but I can't seem to find the documentation.",https://stackoverflow.com/questions/37379836,4408787.0,1
77,66926140,Why tf.keras loss becomes NaN when number of train images increases from 100 to 9000?,"I am following a CNN example in here. Here are my code to prepare the CNN model: And this is how I train the model: When trainGenerator has 80 images &amp; validationGenerator has 20 images, everything is ok for the val_loss &amp; loss like below from one of the epoch When the trainGenerator got 9817 images &amp; validationGenerator got 2454 images, the val_loss &amp; loss become NaN The batch size in trainGenerator &amp; validationGenertor is 32 (default value) in both scenarios above. I have rescaled the images when I import the images to trainGenerator &amp; validationGenertor using the After that I create trainGenerator using flow_from_dataframe like below: validationGenerator is created using the code above by replacing subset with validation A similar question has been asked but it does not apply to my case as the problem persists when number of train images increases &amp; I use sparce_categorical_crossentropy",https://stackoverflow.com/questions/66926140,4177530.0,1
78,54658635,How to randomly crop a batch of images,"I have a batch of 5 images, I want to randomly crop them for w_, h_ size Example: I get error: ValueError: Shape must be rank 4 but is rank 3 for 'concat' (op: 'ConcatV2') with input shapes:",https://stackoverflow.com/questions/54658635,2130515.0,1
79,45604951,tensorflow can't handle my sample correctly in linear regression,"This is a very simple linear regression algorithm from the sample. It works OK. The target function is y=1-x. But if I add x=35, and y=-34, the returned cost becomes very large:",https://stackoverflow.com/questions/45604951,5709305.0,1
80,38265061,"Tensorflow, missing checkpoint files. Does saver only allow for keeping 5 check points?","I am working with tensorflow and have been training some models and saving them after each epoch using the tf.saver() method. I am able to save and load models just fine and I am doing this in the usual way. My code is set up to save a model for each epoch which should be labelled accordingly. However, I have noticed that after fifteen epochs of training I only have check point files for the last five epochs (10, 11, 12, 13,14). The documentation doesn't say anything about this so I am at a loss as to why it is happening. Does the saver only allow for keeping five checkpoints or have I done something wrong? Is there a way to make sure that all of the checkpoints are kept?",https://stackoverflow.com/questions/38265061,6171980.0,1
81,50534057,Why is logit_dimension=1 for binary classification head in Tensorflow?,"I am having a hard time understanding how the binary classification head works in Tensorflow. I am trying to create a custom multi-head Estimator in Tensorflow. My code looks like the following: The problem is if I run the code as is, Tensorflow complains that logits_0 has the wrong dimensions, if I dig into the source code at tensorflow\contrib\estimator\python\estimator\multi_head.py, it is expecting the logits dimension of ""1' for ""logits_0"", but the clearly in a binary classifier there are two classes. What's going on? If I set the dimension to ""1"", the code will run but I will always get non-sensical results in the training. Basically the classifier can't learn the difference between a 1/0 target even with a single trivial feature. This code works perfectly for multiple, multi-class heads (n_class&gt;2). I am using Tensorflow 1.4. Am I simply misunderstanding something? Perhaps my input is formatted incorrectly? Update: I figured out what the problem is, which is that Tensorflow is expecting a tensor of type ""bool"", it is not enough to submit labels of 1, 0, 0, 1, etc, wrapping the label with tf.equal(label, 1) solved the issue. Now I understand why the logits_dimension is 1. However, this still does not solve my actual problem. Which is that the binary classifier just doesn't seem to be working when wrapped in a multi_head. The classification results are just always wrong. If we submit a simple trivial example involved a single categorical variable called: CAT_XXX where XXX is a number between 1 and 100. If we construct two target variables; we can construct a trivial multi-headed, multi-classification problem. In such a scenario, I obtain results like: you can see the multi-class target has been perfectly predicted but the binary problem is nonsense. The thing is the binary_classification head works fine as a standalone input to DNNEstimator. It's just when it is wrapped in a multi_head things seem to go wrong. Kuhan",https://stackoverflow.com/questions/50534057,9030661.0,1
82,62856917,What is the equivalence of tf.contrib.seq2seq.prepare_attention in TensorFlow 2,I've recently working on some code written in tensorflow 1.0.1 and i want to make it available on tenorflow 2. I am not very familiar with seq2seq. Thank you very much.,https://stackoverflow.com/questions/62856917,10533365.0,1
83,46934096,Why does my custom streaming metric always give different results when run on the same inputs?,"I am trying to learn how to create my own custom streaming metric in Tensorflow. I've started by trying to code my own function to compute the f1-score. Here's what I have so far: This is the output I get: The first line is the f1 score computed using sklearn's f1_score function, which is correct. The rest are from metric_fn. I do not understand the output from metric_fn. Why does the result from metric_fn always change even though I give it the same output? Also, none of its results are correct, even though the formula I coded is correct. What is going on and what changes do i need to make to get the correct result?",https://stackoverflow.com/questions/46934096,3775778.0,1
84,44332735,Deadlock in tensorflow's MonitoredTrainingSession and slice input producer,"The code below deadlocks: If however I comment out input_batch = tf.scatter_nd_update(tf.Variable(images), [[1, 2]], [77]) and uncomment the commented lines the program keeps printing:",https://stackoverflow.com/questions/44332735,281545.0,1
85,41796965,Tensorflow: How to use a trained model in a application?,"I have trained a Tensorflow Model, and now I want to export the ""function"" to use it in my python program. Is that possible, and if yes, how? Any help would be nice, could not find much in the documentation. (I dont want to save a session!) I have now stored the session as you suggested. I am loading it now like this: However, I get the error ""no Variables to save"" when I try to initialize the saver. What I want to do is this: I am writing a bot for a board game, and the input is the situation on the board formatted into a tensor. Now I want to return a tensor which gives me the best position to play next, i.e. a tensor with 0 everywhere and a 1 at one position.",https://stackoverflow.com/questions/41796965,6480160.0,1
86,49549521,Getting different Accuracy rates in convolutional neural networks while using tensorflow and tflearn,"So i was using tflearn to make a CNN and the accuracy was nice, but i tried to train the same kind of network with the same learning rates and other parameters. But for some reason i don't understand the accuracy i got when using tensorflow was lower. Is there any reason that this happened? Here is my Neural net layer: And here is my training function: PS I am using tflearn to build my network.",https://stackoverflow.com/questions/49549521,9442693.0,1
87,46820500,How to handle large amouts of data in tensorflow?,"For my project I have large amounts of data, about 60GB spread into npy files, each holding about 1GB, each containing about 750k records and labels. Each record is a 345 float32 and the labels are 5 float32. I read the tensorflow dataset documentation and the queues / threads documentation as well but I can't figure out how to best handle the input for training and then how save the model and weights for future predicting. My model is pretty straight forward, it looks like this: The way I was training my neural net was reading the files one at a time in a random order then using a shuffled numpy array to index each file and manually creating each batch to feed the train_op using feed_dict. From everything I read this is very inefficient and I should somehow replace it with datasets or queue and threads but as I said the documentation was of no help. So, what is the best way to handle large amounts of data in tensorflow? Also, for reference, my data was saved to a numpy file in a 2 operation step:",https://stackoverflow.com/questions/46820500,686572.0,1
88,75757772,problem with creating a sorted training dataset with a sliding window,"i was trying to modify a piece of code that i have been given in order to have a sorted training set with a sliding window. the function is this one: i tried defining a function and then adding right after splitting the training and test set , but I get the error the model is why does it raise an error and how can i solve it?",https://stackoverflow.com/questions/75757772,3882900.0,1
89,52144207,How to add preprocessing steps in TF Lite,"I use simple iris data which have 4 features. And I want to do some preprocessing steps before entering the network. For example, I want my NN only receive 3 features which are an average of two consecutive original features. I've tried to add those steps in input_function and change the definition of all feature_columns shape to 3: The way I train the classifier: my serving input function: It works when I run it, But if I freeze the model and then use it to predict, it doesn't work. it said: If I change feature_columns on my_serving_input_fn to [None, 4], it's still got an error after freezing the model: My question, If I need to include any preprocessing or feature engineering steps (like MFCC in signal preprocessing, etc.) to my model where should I put it? Is my approach correct? why did an error occur? or Is there a better solution? and an additional question, what if in my preprocessing steps I need to include external files (like stopwords list in text preprocessing, etc.), is it still possible to include those files for preprocessing using TF lite?",https://stackoverflow.com/questions/52144207,2147347.0,1
90,72159075,combine gather_nd with aggregation in tensorflow,"I have the following operation I want to perform on a tensor: I want to average values per row, but the number of values per row can be different as shown in the figure. I tried the following code but got stuck after gather_nd, how should I aggregate it now the way I want? P.S. - This should generalize to higher dimensions (the reason I used 2D matrices is that it is easier to convey). This means that data will be 3D instead of 2D and each element in indices will contain 3 items instead of 2. Thanks!",https://stackoverflow.com/questions/72159075,4404709.0,1
91,51377165,How does creating a new session affect initialization of variables in TensorFlow?,"I have a very simple graph with one fully connected layer as follows: My goal here is to test how the seed works, hence I added a seed in the xavier initializer in the fully connected layer. I was testing this with two different methods: The first one is the following: and it outputs ""BOTH ARE SAME"", i.e. it resets everything and reinitializes the weights, as I expected. The second test I did, with only 1 line deleted from the above code, reinitializes the variables, but in the same session, outputs ""THEY ARE NOT THE SAME"": I was wondering how creating a new session affects the initialization of variables, or is there something else I am not seeing going on here?",https://stackoverflow.com/questions/51377165,6708590.0,1
92,50061416,Freezing graph in tensorflow when using tf.image.Dataset,"I'm using tensorflow.python.tools.freeze_graph to freeze a tensorflow graph in the function below: Recently I switch to using tensorflow.image.Dataset to do preprocessing like so: After making the change, freezing the graph is taking forever. The size of input_graph.pbtxt has gone from 500kB to 150MB. Having a look, the culprit is two tensors with the same size and shape as my training data and with tensor_content defined. That is, the training data has been saved in the file. How can I save the graph without this data?",https://stackoverflow.com/questions/50061416,31045.0,1
93,63771148,Can't access keras model's weight with tensorflow's build error,"The log was like follow: I installed TensorFlow with pip install TensorFlow I will explain the problem with the example from the official site Code: Then the above error showed, my question is: How to complier TensorFlow with another flag? And with what kind of flag can I solve this problem?",https://stackoverflow.com/questions/63771148,14232877.0,1
94,40524009,Strange output of embedding_lookup_sparse,"Consider such code: Output: According to the documentation the shape of output must be [3, 3, 3], since shape(sp_id) = [3, 3, 2] and shape(w) = [4, 3], but it doesn't :( Can someone explain why it works in this way? Because I expected behavior simple embedding_lookup, but with aggregation on the last axes.. EDIT For each object I have 2 features and each represent by one word, since that I want represent each object with two concat embeddings, I can do this by: Output So, now I still have 2 features, but each one can be represent with several words, and I want to aggregate embeddings for words corresponding to one feature. It looks like embedding_lookup_sparse should work in such way, but I don't understand why my code doesn't work. Thanks!",https://stackoverflow.com/questions/40524009,6618884.0,1
95,73727919,Update shape of a Tensorflow Variable (TF 2.x),"I am using Tensorflow 2.9.1. I am creating a neural network which has a certain tf.Variable defined as: where This Variable is then trained through the training process and I have no problem with it. It works fine. The problem comes when, at a certain point of the training I need to update this variable by adding, let's say, 50 more values at the end of this variable, that is, I need to get the same Variable but with shape (25050,1), being the 25000 first ones the original variable and the 50 final ones the new values that are initialized in the same way as ""lam_r"". I am not being able to do it by using the tf.concat() function. This Variable is stored in model.lambdas[0], and I am trying to do the following: By doing this I get the following error: I tried even to give a name to both variables but I get the same error. I just need to ""concat"" several points to the original tf.Variable() in a way the new variable of new shape still remains trainable. Any help is appreciated. Thanks.",https://stackoverflow.com/questions/73727919,20001716.0,1
96,73791050,Changes to Dataset in for loop don't work,"I'm trying to augment my dataset by randomly changing the hue of its images within a for loop but the changes do not persist outside of the loop. I imported the dataset with tf.keras.utils.image_dataset_from_directory. The rest of the code looks as follows: When I print an image the first two times, the hue has changed as intended. When I print out more images later, however, none of them have a variation in hue. Any Ideas on why this occurs and how to fix it?",https://stackoverflow.com/questions/73791050,14818093.0,1
97,49306075,Why DNN with Dropout always predict one?,"I have implemented a pretty simple Deep Neural Network to perform multi-label classification. The overview of the model is (bias omitted for the sake of simple visualization): That is, a 3-layer deep neural network with ReLU units and Sigmoid as output unit. The loss function is Sigmoid Cross Entropy and the used optimizer is Adam. When I train this NN without Dropout I get the following results: Evaluation results on test data: When I train this NN adding Dropout layers I get the following results: Evaluation results on test data: As you can see with the Recall values in the Dropout version, the NN output is always 1, always positive class for every class of every sample. It's true that it's not an easy problem, but after applying Dropout I expected at least similar results as without Dropout, not worse result and of course not this saturated output. Why could be this happening? How could I avoid this behaviour? Do you see something strange or bad done in the code? Hyperparameters: Dropout rate: 0.5 @ training / 1.0 @ inference Epochs: 500 Learning rate: 0.0001 Dataset information: Number of instances: +22.000 Number of classes: 6 Thanks!",https://stackoverflow.com/questions/49306075,3343339.0,1
98,69068427,How can I build <feature_name : feature_weight> dict in Tensorflow v2.4,"I am new in tensorflow. I use tf.feature_column to finish feature_engineering task, including crossed_column operation. After a simple LR model, I can get the feature_weight for every feature, but how do I know the feature's name? For example: in feature_weight, it's one_hot feature size is 4(weight0, 1, 2, 3) in feature_vol, it's one_hot feature size is 4(vol0, 1, 2, 3) in feature_weight_X_vol, it's one_hot feature size is 16(weight0_vol0, weight0_vol1, ...., weight3_vol3) so my features_size is 4 + 4 + 16 = 24 After fit a simple LR model, I can get the 24 feature_weight by model.layers[1].get_weights(), but how can I build a dict to map feature_name(key) to the feature_weight(value)? For example: How can I map the key to the value? I just want to know every feature's weight for debuging.",https://stackoverflow.com/questions/69068427,4391869.0,1
99,53427362,Is there any method to 'combine layers' in tensorflow?,Let me explain my question: I assume that there are some(more than one) tensorflow layers like below: Is there any method to combine these layers to one tf.Layer object?That means: Currently I use a ugly method:,https://stackoverflow.com/questions/53427362,5596238.0,1
100,44549245,How to use TensorFlow tf.train.string_input_producer to produce several epochs data?,"When I want to use tf.train.string_input_producer to load data for 2 epochs, I used But then I found that this op did not produce what I want. It can only produce each sample in data.csv for 2 times, but the generated order is not clearly. For example, 3 line data in data.csv it will produce (which each sample just appear 2 times, but the order is optional) but what I want is (each epoch is separate, shuffle in each epoch) In addition, how to know when 1 epoch was done? Is there some flag variables? Thanks! my code is here. my data is like",https://stackoverflow.com/questions/44549245,5496463.0,1
101,43766594,Tensor Flow variable scope:,Why do we use tf.variable_scope: I know the basic idea that its something link creating an instance. But in the code below and many other codes the scope is not retrieved anywhere by using tf.get_variable. What purpose the scope is serving then? What will happen if I dont use it? I do not see the scope being used anywhere later. What purpose is it serving. I want to know what happens if I remove it,https://stackoverflow.com/questions/43766594,7270013.0,1
102,54425941,How to gather a tensor with unknown first (batch) dimension?,"I have a tensor of shape (?, 3, 2, 5). I want to supply pairs of indices to select from the first and second dimensions of that tensor, that have shape (3, 2). If I supply 4 such pairs, I would expect the resulting shape to be (?, 4, 5). I'd thought this is what what batch_gather is for: to ""broadcast"" gathering indices over the first (batch) dimension. But this is not what it's doing: Which results in &lt;tf.Tensor 'Reshape_3:0' shape=(4, 2, 2, 5) dtype=float32&gt; instead of the shape that I was expecting. How can I do what I want without explicitly indexing the batches (which have an unknown size)?",https://stackoverflow.com/questions/54425941,2461398.0,1
103,71879169,Tensorflow `y` argument is not supported when using dataset as input,"When I run this code for generating the dataset and training a GAN, It returns this error From what I've seen I need to make the input a tuple but I'm not sure of how to do that and I can't find anything that shows me how.",https://stackoverflow.com/questions/71879169,13895266.0,1
104,68341860,Why does the same Tensorflow model work with a list of arrays but doesn't work with tf.data.Dataset unbatched?,"I have the following simple set up: This works fine (although I get strange predictions), but when I uncomment the ds lines and change model.fit(X, y, epochs=10) to model.fit(ds, epochs=10), I get the following error: The error gets solved when I run model.fit(ds.batch(2), epochs=10) (I added a batch instruction to the dataset). I expect to be able to use a list of arrays and tf.data.Dataset interchangeably but, for some reason, I need to add a batch dimension to the dataset in order to use tf.data.Dataset. Is this expected behavior or am I conceptually missing something?",https://stackoverflow.com/questions/68341860,1397712.0,1
105,66694699,Is the number of second convolution layer parameters correct?,I have simple CNN for the MNIST data problem. and this is how summary looks like: I have skipped pool layers in the problem for the simplicity of the question. The first convolution layer has 240 parameters which is easy to calculate: (kernel size + bias) * number of filters: (3*3+1)*24. Please explain me why second convolution layer has 7812 parameters (36 * 217). The flatten layer has size of 20736. Which is the number of pixels produced by 36 filters of the previous layer: 24 * 24 * 36. But how can we obtain 36 images by 36 filters from 24 images of the previous layer? Shouldn’t the size of the flatten layer be 36 * 24 * 24 * 24 which is the number of filters from the previous layer * size of the bitmap from the previous layer * number of filters from the first convolution layer?,https://stackoverflow.com/questions/66694699,6193690.0,1
106,62031683,Ragged tensors as input for LSTM,"Learning about ragged tensors and how can I use them with tensorflow. My example The error I am not sure if I can use ragged tensors like this. All examples I found have embedding layer before LSTM, but what I don't want to create additional embedding layer.",https://stackoverflow.com/questions/62031683,5429288.0,1
107,68275008,BatchNormalization Layer causing error in converting from .h5 to .onnx,"I need to convert a .h5 model to a .onnx, but when I use a BatchNormalization layer, the code gives the following error: And gives the warning: If I don't use this layer, the code runs and the conversion will succeed, but I need this layer. The code for conversion is: And the line with BatchNormalization layer is:",https://stackoverflow.com/questions/68275008,12501475.0,1
108,49083680,How are the new tf.contrib.summary summaries in TensorFlow evaluated?,"I'm having a bit of trouble understanding the new tf.contrib.summary API. In the old one, it seemed that all one was supposed to do was to run tf.summary.merge_all() and run that as an op. But now we have things like tf.contrib.summary.record_summaries_every_n_global_steps, which can be used like this: And now come a few questions: By adding a control dependency in 3) I mean doing this:",https://stackoverflow.com/questions/49083680,72583.0,1
109,51508623,"Modify layers in Tensorflow, Keras or PyTorch","I want to modify output of every layer in tensorFlow before passing to next layer in this format for standard deep neural network (Not CNN necessarily): Say this is Pseudocode of layers during forward propagation prior to any modification, and X is input feature matrix: So outputs of each layer are in l1 and l2, where nonlin is the sigmoid activation function (or someother like ReLU). Syn0 and Syn1 are the corresponding weights which are initially randomized and then modified later by back-propagation using loss function like cross-entropy or l2 error etc. So far so good- all looks standard. Ofcourse, tensorflow allows for bias term etc in the standard sense along with epochs, batches, learning rate, variations of drop-out/regularization and other fancy features etc. What i instead want to do is the following modification to that pseudo-code in forward propagation steps: If you notice I updated l0, l1 and l2 with corresponding matrix multiplication (denoted by %*%) with matrices M0, M1, M2 respectively, which we can refer to in this pseudo-code as YoYoMats. All YoYoMats are square and symmetric and provided before hand along with dataset X and response or label column. how can this be implemented in Keras or TensorFlow? Ideally in RKeras or RtensorFlow. If not Python version or Pytorch etc is okay too! I can implement this change by implementing vanilla NN from scratch in Python, but I want to do it in TensorFlow or Keras to use this change with all of the other supercool features these matured tools give and I am not skilled to create TensorFlow of my own kind from scratch :). hence, this question of implementing this within TensorFlow or Keras code etc. Note as you see the modification is easy till layer l1 because the modified version is same as: So, its easy to just modify l0 as follows and use it in l1 the usual way. Nothing changes till here. So simple. The tricky part is only from layer l2 and onwards if we had more layers in implementing the multiplication with M2 or say M3, M4 etc. Do I need to modify output of tf.contrib.layers.fully_connected to get this done? If so how? If not, alternate way? Caveat-if the above pseudocode was modified for training. I need prediction function modified with corresponding YoYoMats as well for testing/out-of-sample prediction purposes as well.",https://stackoverflow.com/questions/51508623,2242636.0,1
110,53414168,"TensorFlow ExportOutputs, PredictOuput, and specifying signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY","I have a colab with a very simple demo Estimator for the purpose of learning / understanding the Estimator API with the goal of making a convention for a plug-and-play model with useful bells and whistles of the trade in tack (e.g. early stopping if the validation set stops improving, exporting the model, etc). Each of the three Estimator modes (TRAIN, EVAL, and PREDICT) return an EstimatorSpec. According to the docs: Of these named arguments I would like to bring attention to predictions and export_outputs, which are described in the docs as: Thus it should be clear why I bring up export_outputs; namely, as one would most likely like to use the model they trained in the future (by loading it from a SavedModel). To make this question a bit more accessible / add some clarity: e.g. this multi-headed model's input_fn (in accordance with the Estimator api) returns a tuple (features, labels) i.e. this model has two heads). How one specifies the signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is the core of this question. Namely, how does one specify it? (e.g. should it be a dict {signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: head}) Right, so in the colab you see that our model's export_outputs is actually defined in a multi-head manner (although it shouldn't be): From estimator functions &gt; model_fn of the colab: in this particular instance, if we expand the dictionary comprehension, we have the functional equivalent of: It works in this instance as our dictionary has one key and hence one PredictOutput, where in the colab our model_fn has only a single head and would be more properly formatted as: as it states in PredictOutput: where Thus my question is as follows:",https://stackoverflow.com/questions/53414168,5623899.0,1
111,50342680,Keras Sub classing api style,I'm stuck to make a model with a subclass method.The question is that in this subclass method where is our input shape method and where is our compilation step? Kindly help I have to do my assignments. Here is the link,https://stackoverflow.com/questions/50342680,9502872.0,1
112,43972949,TFlearn to categorical,"I`m using DNN of tflearn, and I want to change my features and lables to be categorical and not numeric. here is my net: I know about tflearn.data_utils.to_categorical but I dont know how to inject this method. thanks EDIT: I tried few things, like: and also change the loss: but I got loss more than 1: where is the problem?",https://stackoverflow.com/questions/43972949,6925731.0,1
113,60185290,Implementing a minimal LSTMCell in Keras using RNN and Layer classes,"I am trying to implement a simple LSTMCell without the ""fancy kwargs"" defaultly implemented in the tf.keras.layers.LSTMCell class, following a schematic model like this. It doesn't really have a direct purpose, I would just like to practice implementing a more complex RNNCell than the one described here in the Examples section. My code is the following: However, when I tried to test it an exception was raised with the following message: in the call function at the line where I set the value for self.stateC. Here, I thought that initially the statesargument of the call function is a tensor and not a list of tensors, so this is why I get an error. So I added a self.already_called = False line to the classes __init__ and the following segment to the call function: hoping that it will eliminate the problem. This resulted in another error at the merge_with_state function: which I genuinely do not get, since the RNN layer should only ""show"" the CustomLSTMCell tensors with shape (3) and not (None, 3), since axis 0 is the axis it should iterate along. At this point I was convinced that I am doing something really wrong and should ask the community for help. Basically my question is: what is wrong with my code and if ""almost everything"", then how should I implement an LSTMCell from scratch?",https://stackoverflow.com/questions/60185290,6715475.0,1
114,38788912,Tensorflow 'features' format,"I'm a total begginer with AI and tensorflow, so please forgive if this is a dumb question. I've trained a tensorflow network using a script based on this tutorial: https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html I believe training was ok. Now I whant to run this method to make a prediction for a single input: But I cannot find any documentation on how to build the ""x"" parameter... I tryed: Where: d_data is a dictionary containing about 150 key/value pairs. COLUMNS is a list with all the keys needed. This same setup was used to train the network. But got the error: So... x should not be a 'dict'... but what should it be then? Can anyone give me some directions? Thanks a lot.",https://stackoverflow.com/questions/38788912,6430078.0,1
115,62134394,Convert custom Convolution from PyTorch to Tensorflow (2.2.0),"I am currently attempting to convert a custom convolution from PyTorch to Tensorflow (V. 2.2.0). The convolution is defined in PyTorch as: where nq = 20, min = 0 and max = 1. My reimplementation looks like this: with these these functions as weight and bias initialization: The input is a matrix with shape 1681, 1, 1600 for PyTorch (as it uses channels first) and 1681, 1600, 1 for Tensorflow (as it uses channels last) and the out put is 1681, 40, 1600 or 1681, 1600, 40. So it should be correct, however, the output of both convolutions is different. Input, Output: Tensorflow on a random 100, 100 image: Input, Output: PyTorch on a random 100, 100 image:",https://stackoverflow.com/questions/62134394,5674666.0,1
116,52034983,how is total loss calculated over multiple classes in Keras?,"Let's say I have network with following params: Now, I know that the loss is calculated in the following manner: binary cross entropy is applied to each pixel in the image with regards to each class. So essentially, each pixel will have 5 loss values What happens after this step? When I train my network, it prints only a single loss value for an epoch. There are many levels of loss accumulation that need to happen to produce a single value and how it happens is not clear at all in the docs/code. To state it in a different way: how are the losses for different classes combined to produce a single loss value for an image? This is not explained in the docs at all and would be very helpful for people doing multi-class predictions on keras, regardless of the type of network. Here is the link to the start of keras code where one first passes in the loss function. The closest thing I could find to an explanation is from keras. So does this mean that the losses for each class in the image is simply summed? Example code here for someone to try it out. Here's a basic implementation borrowed from Kaggle and modified for multi-label prediction: The actual BCE-DICE loss function can be found here. Motivation for the question: Based on the above code, the total validation loss of the network after 20 epochs is ~1%; however, the mean intersection over union scores for the first 4 classes are above 95% each, but for the last class its 23%. Clearly indicating that the 5th class isn't doing well at all. However, this loss in accuracy isn't being reflected at all in the loss. Hence, that means the individual losses for the sample are being combined in a way that completely negates the huge loss we see for the 5th class. And, so when the per sample losses are being combined over batch, it's still really low. I'm not sure how to reconcile this information.",https://stackoverflow.com/questions/52034983,8100895.0,1
117,38915892,TensorFlow multithreading StatusNotOK,"I'm trying to implement a decoupled training queue in tensorflow at the very beginning im initilizing the graph In the main program I have two threads. the first enqueues new data that is generated by my main program: the training function is called by another thread or the mainprogram this doesnt matter because it generates the same error after a while it happens that if self.sess.run([tensor_a,tensor_b]) is called I'm getting the following error I believe it is some sort of race condition but I dont now how to fix it. any help would be really nice",https://stackoverflow.com/questions/38915892,6439891.0,1
118,43782767,How can I use tensorboard with tf.estimator.Estimator,"I am considering to move my code base to tf.estimator.Estimator, but I cannot find an example on how to use it in combination with tensorboard summaries. MWE: How can I display my two summaries in tensorboard? Do I have to register a hook in which I use a tf.summary.FileWriter or something else?",https://stackoverflow.com/questions/43782767,1037094.0,1
119,38306330,"TypeError: Fetch argument has invalid type float32, must be a string or Tensor","I'm training a CNN quite similar to the one in this example, for image segmentation. The images are 1500x1500x1, and labels are of the same size. After defining the CNN structure, and in launching the session as in this code sample: (conv_net_test.py) I hit upon the following TypeError (stacktrace below): I am stumped at this point. Maybe this is a simple case of converting the type, but I'm not sure how/where. Also, why does the loss have to be a string? (Assuming the same error will pop up for the accuracy as well, once this is fixed). Any help appreciated!",https://stackoverflow.com/questions/38306330,3267023.0,1
120,42193592,Difference in matrix multiplication tensorflow vs numpy,"I have a case where matrix multiplication of two matrices with certain dimensions work in numpy, but doesn't work in tensorflow. This works as expected and prints: However in tensorflow when I try to multiply placeholder and variable of the same shapes as the numpy arrays above I get an error Results in Why does this operation fail?",https://stackoverflow.com/questions/42193592,766551.0,1
121,52697996,Why is there a `Const` and a `Mean` operation in metrics node in keras?,"I try to implement a custom loss function using tensorflow's keras interface. I added the same function to the loss and to the metrics: In TensorBoard, I see the following as part of the network: Why is there a Mean and a Const before the training? What do they represent?",https://stackoverflow.com/questions/52697996,3830495.0,1
122,72783794,Tensorflow / Tensorboard missing output from one of hparams during profiling,"TF / TB running a profile with the following setup : with this model : It all seems to run fine and I do get outputs, however the outputs in tensorboard do not show the results for different values of the ""optimizer"", which I want also. Does it need to be treated/coded differently? Happy to supply more of the code if this is not clear. Thx. J",https://stackoverflow.com/questions/72783794,3182102.0,1
123,40923377,Why does gradient descent update 0-valued weights at all?,"I was reading this question and the discussion makes sense to me: when all weights are initialized to zero, gradient descent can't tell where the error came from, so it can't update those weights. What I don't understand is why I can't see this empirically. I'm running the following piece of code (runnable here): And the output I'm seeing is like: If the weights start out as zero, why is gradient descent able to update them at all? As a follow up question, if a weight is randomnly initialized to be positive, but the optimal value for that weight is negative, do we just have to trust that in an update step the optimizer won't accidentally update the weight to be 0 (and thus halt the weight's updatability)? I know the odds of weight + update step being exactly 0 are almost neglibible, but it could still be an issue, especially with millions of weights in a NN.",https://stackoverflow.com/questions/40923377,3783526.0,1
124,33943992,"In Tensorflow, how do I generate a scalar summary?","Does anyone have a minimal example of using a SummaryWriter with a scalar_summary in order to see (say) a cross entropy result during a training run? The example given in the documentation: Returns an error: TypeError: Fetch argument None of None has invalid type , must be a string or Tensor. (Can not convert a NoneType into a Tensor or Operation.) When I run it. If I add a: operation after my cross entropy calculation, then instead I get the error: InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float Which suggests that I need to add a feed_dict to the call, but I am not clear what that feed_dict should contain....",https://stackoverflow.com/questions/33943992,5609344.0,1
125,46219326,How to use tf.losses.log_loss in tensorflow?,What is the input of tf.losses.log_loss ? Anybody can show me some examples about it ? Official guide has no examples .,https://stackoverflow.com/questions/46219326,6407393.0,1
126,67971878,Random Seed for Tensorflow federated?,"I want to get reproducible results with my Tensorflow Federated code. For that I have implemented some seeds (random, numpy and tensorflow), but they aren't affecting Tensorflow Federated. The data processing steps are all reproducible, it has to be in the code snippet below. I have read that Tensorflow Federated doesn't provide a global seed function and that my only possibility is to save the state. But I don't understand this argumentation. Is anyone aware of a method/function that can help me out or explain to me why I can't use seeds with Tensorflow Federated? Appreciate every comment :) Thanks for your help.",https://stackoverflow.com/questions/67971878,16223516.0,1
127,55573891,How do I know if my tensorflow structure is good for my problem?,"There are two sets of very similar code below with a very simple input as an illustrative example to my question. I think an explanation to the following observation can somehow answer my question. Thanks! When I run the following code, the model can be trained quickly and can predict good results. However, when i run the following code, which is very similar to the one above, the model is trained very slowly and may not be well trained and give bad predictions (i.e. the loss becomes &lt;1 easily with the code above but stays at around 20000 with the code below) One more note: when I train my model with the second set of code, the model may be well trained occasionally (~8 out of 10 times it is not well trained, and loss remains &gt;10000 after 1000 epochs).",https://stackoverflow.com/questions/55573891,9193325.0,1
128,59596940,How to use Automatic Mixed Precision in tensorflow 2.0 with hub.KerasLayer,"According to the tensorflow documentation, I tried to use Automatic Mixed Precision (AMP) in tensorflow 2.0 in keras style. Here is my code: What I expect : bert_sequence_output.dtype should be float16, because it is the output of a layer (i.e. the bert_layer) that uses the mixed_float16 policy. But what I actually get: the code above tells me bert_sequence_output.dtype is float32, and here is the full log: When I change the policy to float32, the several print give me these info (other parts of log is the same as mixed_float16): According to the log, here is my conclusion: Personally, I think this is due to the layer definded in Bert have been hard-coded to have a dtype float32, so we cannot use mixed_float policy to change its behavior. Is it right? What else could have caused the problem and how to fix it? Thanks to all kindly help in advance!",https://stackoverflow.com/questions/59596940,11909692.0,1
129,49864214,Tensorflow : What is actually tf.nn.dropout output_keep_prob?,"I am trying to understand concept of output_keep_prob: So if my example is simple RNN : My confusion is if I am giving output_keep_prob=0.5 what actually it means? I know that it makes less prone to overfitting (called regularizing) by adding a dropout. It randomly turns off activations of neurons during training, ok I got this point but I am confused when I give output_keep_prob=0.5 and my no_of_nodes = 500 then 0.5 means it will randomly turn of 50% nodes at each iteration or it means it will keep only those connections which have more or equal probability of 0.5 or I tried to understand the concept by this stackoverflow answer but there is also same confusion that what actually 0.5 means? it should drop 50% nodes at each iteration or keep only those nodes which have probability more or equal to 0.5 if the answer is second keep only those nodes which have probability more or equal to 0.5 : then it means suppose I have given 500 nodes units and only 30 nodes have 0.5 probability so it will turn of rest 470 nodes and will use only 30 nodes for incoming and outgoing connections? Because this answer says : While other side this answer by @mrry says : can anyone give a clear explanation which one is correct and what actually this value represent in keep_prob?",https://stackoverflow.com/questions/49864214,5904928.0,1
130,54751348,How to use TensorFlow tf.data.experimental.group_by_reducer,"I have a 2D matrix which i want to aggregate based on a columns value. Effectively i want to do a map reduce on my data. I notice there is a function called tf.data.experimental.group_by_reducer which looks promising but there are no examples at all on how to use it or the functions you declare. Does anybody have an example on how to use this function to aggregate based on a column or, if this is not the most appropriate function then what would be another mechanism to achieve my result? Also i am reading my dataset in batches, so the reduce would be done on each batch. I am assuming the only way to apply a reduce across the entire dataset in this method is to then do a reduce on the reductions from each batch?",https://stackoverflow.com/questions/54751348,1371314.0,1
131,38400360,Working with tensorflow's shuffle_batch method,"I'm experimenting with tensorflow and I'm trying to read from a csv file and print out a batch of its data via shuffle_batch. I've gone throw the decode_csv docs and the shuffle_batch docs, but I'm still unable to get it working. Here's what I have: import tensorflow as tf Running this will generate this exception: I'm not sure what the issue is. I have a feeling it's due to the session and the way I'm handling it; I'm probably not doing it properly.",https://stackoverflow.com/questions/38400360,409865.0,1
132,52907362,tf.train.Saver instance does not close checkpoint files,"In my effort to obtaining the best checkpoint possible following the fitting stage for my model using the Estimator API, I ended up using a tf.train.SessionRunHook where I reference the tf.train.Saver instance created by the estimator to manually save the best checkpoint found so far in the fitting process, to a separate directory. My intention is to let the estimator instance follow it's course when it comes to doing the checkpoints, but if I find a better set of weights then checkpoint the model to a specific directory. Here is a code snippet to illustrate what i have in mind: In the model function for the estimator, the hook instance is passed to both train and evaluation hook arguments for the EstimatorSpec. The Estimator instance is created and used like so: What ends up happening is that even tho the estimator instance keeps at most 3 checkpoints in the model_dir as specified in the run config, alongside them it will pile up temporary metafiles. Here is a screenshot of the model_dir with these temp files The only way to get rid of them is to reboot the system, refreshing the file explorer GUI will not make any difference, leading me to think that there is something wrong with the way I am doing the checkpoints and I would appreciate if someone could point that out. Eventually it will end up using all the memory on the system yielding the following stack trace: 2018-10-21 04:07:10.571642: W tensorflow/core/framework/op_kernel.cc:1275] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Resource exhausted: /home/m232/catalinh/models/orange_juice/dtt/keurig_new_logo_160x160x1_with_negatives/ckpts/model.ckpt-19494.data-00000-of-00001; Too many open files Traceback (most recent call last): File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1278, in _do_call return fn(*args) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1263, in _run_fn options, feed_dict, fetch_list, target_list, run_metadata) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _call_tf_sessionrun run_metadata) tensorflow.python.framework.errors_impl.ResourceExhaustedError: /home/m232/catalinh/models/orange_juice/dtt/keurig_new_logo_160x160x1_with_negatives/ckpts/model.ckpt-19494.data-00000-of-00001; Too many open files [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/home/m232/.virtualenvs/ml/bin/tensor_dyve"", line 11, in sys.exit(main()) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/TensorDyve/tensor_dyve.py"", line 352, in main estimator.train( input_fn = train_input_pipe, steps = TRAIN_STEPS ) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 376, in train loss = self._train_model(input_fn, hooks, saving_listeners) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1145, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1173, in _train_model_default saving_listeners) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1448, in _train_with_estimator_spec log_step_count_steps=self._config.log_step_count_steps) as mon_sess: File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 421, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 832, in init stop_grace_period_secs=stop_grace_period_secs) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 555, in init self._sess = _RecoverableSession(self._coordinated_creator) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1018, in init _WrappedSession.init(self, self._create_session()) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1023, in _create_session return self._sess_creator.create_session() File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 712, in create_session self.tf_sess = self._session_creator.create_session() File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 483, in create_session init_fn=self._scaffold.init_fn) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session config=config) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py"", line 211, in _restore_checkpoint saver.restore(sess, ckpt.model_checkpoint_path) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1725, in restore {self.saver_def.filename_tensor_name: save_path}) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 877, in run run_metadata_ptr) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1100, in _run feed_dict_tensor, options, run_metadata) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1272, in _do_run run_metadata) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1291, in _do_call raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.ResourceExhaustedError: /home/m232/catalinh/models/orange_juice/dtt/keurig_new_logo_160x160x1_with_negatives/ckpts/model.ckpt-19494.data-00000-of-00001; Too many open files [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. Caused by op 'save/RestoreV2', defined at: File ""/home/m232/.virtualenvs/ml/bin/tensor_dyve"", line 11, in sys.exit(main()) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/TensorDyve/tensor_dyve.py"", line 352, in main estimator.train( input_fn = train_input_pipe, steps = TRAIN_STEPS ) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 376, in train loss = self._train_model(input_fn, hooks, saving_listeners) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1145, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1173, in _train_model_default saving_listeners) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1448, in _train_with_estimator_spec log_step_count_steps=self._config.log_step_count_steps) as mon_sess: File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 421, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 832, in init stop_grace_period_secs=stop_grace_period_secs) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 555, in init self._sess = _RecoverableSession(self._coordinated_creator) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1018, in init _WrappedSession.init(self, self._create_session()) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1023, in _create_session return self._sess_creator.create_session() File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 712, in create_session self.tf_sess = self._session_creator.create_session() File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 474, in create_session self._scaffold.finalize() File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 214, in finalize self._saver.build() File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1293, in build self._build(self._filename, build_save=True, build_restore=True) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1330, in _build build_save=build_save, build_restore=build_restore) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 772, in _build_internal restore_sequentially, reshape) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 450, in _AddShardedRestoreOps name=""restore_shard"")) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 397, in _AddRestoreOps restore_sequentially) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 829, in bulk_restore return io_ops.restore_v2(filename_tensor, names, slices, dtypes) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1463, in restore_v2 shape_and_slices=shape_and_slices, dtypes=dtypes, name=name) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper op_def=op_def) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 454, in new_func return func(*args, **kwargs) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3155, in create_op op_def=op_def) File ""/home/m232/.virtualenvs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1717, in init self._traceback = tf_stack.extract_stack() ResourceExhaustedError (see above for traceback): /home/m232/catalinh/models/orange_juice/dtt/keurig_new_logo_160x160x1_with_negatives/ckpts/model.ckpt-19494.data-00000-of-00001; Too many open files [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.",https://stackoverflow.com/questions/52907362,10277386.0,1
133,45223060,Two implementation of virtual batch norm lead to two differents results,"should both example code lead to different behavior on training (any loss / any optimizer) ? I'm trying to implement virtual batch norm, I have two implementations which doesn't behave the same way widely inspired by the improved gan repository. Both implementation shown here are simplified to keep mostly what is different between them. Everything seems to work ok, validation and training accuracy converge up, and loss going down. Here only training converge (but with slightly different curve than first implementation), while validation loss increase and accuracy stay at random guess. As a matter of details, I'm using GPU, tensorflow 1.2.1 with XLA enabled. Any clue of what I'm doing wrong ? So I tried to compare both output models, and also look at the gradients (using compute_gradients), to avoid weights (and then gradients) sharing I built the models in two different scopes and load separately the same weights (from a previously trained model) on both models. I have same output if I just use: but if I also look at the gradients (first element of each tuple return by Optimizer.compute_gradients(loss)) at the same time using: suddenly the model outputs are differents... How can the model output change just by looking at the gradients without using apply_gradients ? Also it doesn't seems to have changed the weights because if i'm running: the model outputs are still the same...",https://stackoverflow.com/questions/45223060,5908403.0,1
134,69622982,Using pre-trained models in transfer learning - how do I do this?,I'm trying to apply transfer learning using VGG16 but I'm struggling to find an example with multiple outputs. I've written my own architecture as below which I used to manually train my model - though I don't understand how I can compile the same metrics using a pre-trained model. How do I do this?,https://stackoverflow.com/questions/69622982,8199025.0,1
135,41071586,I got a error when I got the variables of convolution layers in tensorflow,I want to got variables of convolution layers and to visualize it. Then my code is and in test But I don't understand the conv_weights have a confusing dimensions,https://stackoverflow.com/questions/41071586,3886429.0,1
136,64063954,How do I multiply each vector in tensor by each element of vector,Hi so what I exactly want is if we have matrix W and vector V such as: we should got the result: I found this method on the website: which is exactly what I want but when I implement this on my model it also include the batch size of the vector in which result in error such which I assume is the same error which this can produce I wanted to know what is the standard procedure to get each element from the softmax output vector and multiply them as weight for each vector in the feature tensor,https://stackoverflow.com/questions/64063954,11344228.0,1
137,38296200,InvalidArgumentError: You must feed a value for placeholder tensor Placeholder,"I have started learning tensorflow and have difficulties understanding the placeholders/variables issues. I am trying to write a function for matrix multiplication. It works when using tf.constant but I have difficulties understanding how to use variables here is my code This works as expected: However, the following fails: with the following error Even after changing the last line in What am I doing wrong?",https://stackoverflow.com/questions/38296200,1043144.0,1
138,56695365,is there a way to customize my loss function to increase recall in one class only?,"First, thank you. I'm using Tensorflow 1.13 with Python 3. I'm trying to create a CNN classifier on data with 4 classes, one-hot encoded. However, the insights I need it to produce are really around spotting either classes 0 or 3. If it tells me a data row is of class 1 or 2, that's of little use to my goals. Output from sklearn classification_report is below and I want to increase recall on classes 0 and 3 during model training. Precision would be nice, too. I'm relatively new to both python and TF, having gone through several tutorials, and am just now starting to build my own models. I've not really been able to stretch myself out past capabilities discussed in any of the learning courses I've watched. I know that Keras, for example, has custom loss function capability, but I'm not sure I understand how to integrate it into what I've already done. Relevant bits from my existing project are below.",https://stackoverflow.com/questions/56695365,11678605.0,1
139,56168662,Set dual axes in Tensorboard for two different charts,"Here are the two examples: 1 perfectly worked as the scales was same: Got this figure which was understandable : But take a look at the second case where the values do not fit in the same range. In that case I need to have two different axes on same chart, so that I get a good and understandable image. Check the code: See the image obtained: Please help me with this query.",https://stackoverflow.com/questions/56168662,4948889.0,1
140,38992445,Tensorflow: Py_func returns unknown shape,"I have a simple question re the tf.py_func function. I have an image tensor my_img of shape (1,224,224,3). To test py_func, I feed the tensor to a python function return_tf that should give back the same tensor (after being converted to a numpy array as per docs). Here's the code: But when I checked the shape of the returned tensor called test, I get: I am also unable to run eval() on the tensor, since I get the error: Anyone knows how could I fix the tensor shape of the tensor returned by tf.py_func?",https://stackoverflow.com/questions/38992445,6720221.0,1
141,72774644,"Keras model returns high validation accuracy while training, but accuracy is very low while evaluating","I am trying to train a simple MobileNetV3Small under keras.applications as shown below When I train the model I got validation accuracy around 0.94. But when I call model.evaluate on the exact same validation data, the accuracy becomes 0.48. When I call model.predict with any data it outputs constant value 0.51... There is nothing wrong with learning rate, optimizer or metrics. What could be wrong here? EDIT: After training when I run it gives me the output for 1 epoch trained network: However, when I save and load the model with either model.save() or tf.keras.models.save_model(). The output becomes something like this: and output of the model.predict(validation_generator) is: What I've tried so far: First two moves do not have an effect, the after applying the third step, I get no longer same predictions for any input. However, evaluate() and predict() still have different accuracy values.",https://stackoverflow.com/questions/72774644,3235349.0,1
142,61300207,different results between tf.matmul and np.matmul,Consider the following (run on colab): This yields different results: Where the inputs to tf.matmul &amp; np.matmul are equal. Is there a logical explanation to this?,https://stackoverflow.com/questions/61300207,5151909.0,1
143,49875017,Tensorflow restore and use,"I created a simple tensorflow model: However, the result is not the one that I expect. I expected '6' but I got 'None'. Below is the re-use code, please can you tell me what's wrong with this code?",https://stackoverflow.com/questions/49875017,9657547.0,1
144,47674816,ImportError: numpy.core.multiarray failed to import and Failed to load the native TensorFlow runtime,I just started demo program in python using tensor. I am a beginner at python. I executed the command : But the output is like commandline screenshot of tensor program execution Here is code I have written : How can I resolve it? I am new to python and tensorflow. Thanks.,https://stackoverflow.com/questions/47674816,9061775.0,1
145,40074784,Supervisor loop and queue runner,"I'm trying to fill queue using an external thread loop. Here is a snippet of what I'm trying to do: This code is not complete but what I expect here is the following output This works as long as the line is commented. Once I decomment it, it doesn't work anymore. My next step is to put the queue inside my callable object in order to fill it. Any ideas on why it breaks ?",https://stackoverflow.com/questions/40074784,1259390.0,1
146,72423651,ValueError for Sequential model.fit,I'm learning Tensorflow and i tried out this program This program is from this Youtube Video at 4:40:00 But I get this error: What mistake have i done and what should i do to correct it? If I have to make some changes then how did it work in the video?,https://stackoverflow.com/questions/72423651,17002772.0,1
147,40577096,why loss changes value after I add additional inference with reuse = True,"In tensorflow example cifar10, the loss value changes after I add one more inference with reuse = True to the graph. Originally: After my change: I don't understand why. All the changes I made are as following, 1) In cifar10_train.py, I added a line, 2) In cifar10.py, I added reuse to inference() Then I found the loss value is quite different. Originally: After my change: Why is this?",https://stackoverflow.com/questions/40577096,6525333.0,1
148,62513518,How to save a tensor to TFRecord?,I want to save a tensor to the TFRecord format. I tried this: It gives me the error: I understand it's probably a basic question but I read a guide on TensorFlow site and searched in StackOverflow but didn't find the answer,https://stackoverflow.com/questions/62513518,13128362.0,1
149,49124814,What are the uses of tf.space_to_depth?,"I am reading this document on tf.space_to_depth. There, it says about the use of the function: However, I still don't get a clear understanding of this. Why is it sometimes necessary to resize the activations in a model?",https://stackoverflow.com/questions/49124814,8186293.0,1
150,52729117,Tensorflow With Context Manager vs. With Session,I'm trying to understand how a with block behaves in the above scenarios. I assume to always have one graph and one session only. I understand that I have (at least?) 2 ways to work using a session in a with block: Example 1 : using as_default() that creates a context manager: Same documentation says: Example 2 : with block on session as stated in same documentation in a lower section: I would like to understand what is the correct usage as I see GitHub examples of both cases but of course without the results. In my tests both Example 1 and 2 works for training. For evaluation it seems there is a difference that I can't understand. It exceeds my knowledge to browse the Tensorflow source. Can someone please explain?,https://stackoverflow.com/questions/52729117,6169238.0,1
151,50421555,Argmax function of Tensorflow does not print value when evaluated on a constant tensor,"I'm new at Tensorflow. I am having a litte trouble at understanding its constants. I have this simple code mentioned below: I expect this to return something like [4,7,8], as I understood from the documentation. Instead, I get this: So, i don't know what am I doing wrong.",https://stackoverflow.com/questions/50421555,7070099.0,1
152,60018234,Trying to understand shuffle within mini-batch in tensorflow Dataset,"From here I understand what shuffle, batch and repeat do. I'm working on Medical image data where each mini-batch has slices from one patient record. I'm looking for a way to shuffle within the minibatch while training. I cannot increase the buffer size because I don't want slices from different records to get mixed up. Could someone please explain how this can be done?",https://stackoverflow.com/questions/60018234,10554433.0,1
153,54832078,Using trained keras model in google ml-engine,"I am trying to use gcloud ml-engine with tensorflow, more precisely I would like to use an already trained keras model. I managed to do this with a sciktlearn model but this not the same here... First i train a simple model with Keras I read i need a SavedModel to use it in ml-engine here https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models It seems I have to transform it to an estimator I manage to make prediction with this estimator In order to export it to a SavedModel I need a serving_input_receiver_fn. I did not find on the internet an example of my situation, which seemed simple to me, so I tried this function and then I saved the model in the ""here_are_estimators"" folder my input.json looks like this I uploaded the content of the generated file, a variables folder and a saved_model.pb file to GCS in the directory DEPLOYMENT_SOURCE When I try to run a local prediction with gcloud with this command: I have this error I guess something is wrong with my input.json or the serving_input_receiver_fn, or both ?, but I cant find out what. If someone can tell me what is wrong it will be much appreciated :)",https://stackoverflow.com/questions/54832078,7081395.0,1
154,43262815,Using tensorboard histograms with tf.contrib.layers,"Im trying to understand if there is a way to get a histogram of the weights in a fully_connected layer from tf.contrib.layers. In the documentation there is no obv way to get the weights. So my question is, how can I visualise the weights from layers?",https://stackoverflow.com/questions/43262815,3139545.0,1
155,36612512,Tensorflow: How to get a tensor by name?,"I'm having trouble recovering a tensor by name, I don't even know if it's possible. I have a function that creates my graph: I want to access the variable S1_conv1 outside this function. I tried: But that is giving me an error: ValueError: Under-sharing: Variable scale_1/Scale1_first_relu does not exist, disallowed. Did you mean to set reuse=None in VarScope? But this works: I can get around this with but I don't want to do that. I think my problem is that S1_conv1 is not really a variable, it's just a tensor. Is there a way to do what I want?",https://stackoverflow.com/questions/36612512,3618299.0,1
156,67529645,"Matrix size-incompatible: In[0]: [15,15], In[1]: [675,128]",I'm training a model on a custom dataset with about 4600 images of different shapes. Here's a quick glimpse of the data: It's a very simple model: Here's the model's summary: Then I tried the following: Which fails to predict and gives the following error:,https://stackoverflow.com/questions/67529645,15877864.0,1
157,59078187,can't train Tensorflow on a simple dataset,"I'm trying to learn a bit about Tensorflow/Machine Learning. As a starting point, I'm trying to create a model that is trained on a simple 1-D function (y=x^2) and see how it behaves for other inputs outside of the training range. The problem I'm having is that the training function doesn't really ever improve. I'm sure it's due to a lack of understanding and/or misconfiguration on my part, but there really doesn't seem to be any sort of ""baby's first machine learning"" out there that deals with a dataset of a known form. My code is pretty simple, and is borrowed from TensorFlow's introduction notebook here and I get output like this: Like I said, I'm positive that this is a misconfiguration/lack of understanding on my part. I really learn best when I can take something this simple and incrementally make it more complex rather than starting on something whose patterns I can't readily identify, but I can't find any tutorials, etc that take this approach. Can anyone recommend either a good tutorial source, or just educate me on what I am doing wrong here?",https://stackoverflow.com/questions/59078187,3741834.0,1
158,62601746,How to troubleshoot TensorFlow error “Restoring from checkpoint failed.”,"I am new to Tensorflow, I have been using a trained model from a Git repository. The pre-trained model is saved in '../model/snapshot-38' directory. I have snapshot-38.index, snapshot-38.meta, snapshot-38.data-00000-of-00001 and checkpoint files here. I have my python script files and data in '../src' and I don't use any other location other than these in my code to save model. I am using Python 3.6, Tensorflow 1.12.2 I have backed these files and tried re-training using a different set of data and generating a new model output but aborted half way through. I have then restored my pre-trained model files from the back up as before but from since then I am getting error ""Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:"" delete saved model When I try either retrain or restore the model. Is there some temporary files that I need to remove ?? doubt if Tensorflow is trying to do something I am not aware, I don't really get an answer from any of the solutions in similar threads. Below is the detailed stack trace,",https://stackoverflow.com/questions/62601746,914114.0,1
159,38722799,Does Tensorflow reuse computation for every sess.run() node?,"In the documentation of Tensorflow's Session.run() function (link here) it is said that the fetches argument can be a list of nodes, to get the output of multiple graph nodes at the same time, instead of just one. My question is, if such nodes are related and have dependencies between them, will the computation be shared or each node will have it's own computation? Let my explain better with an example. Suppose we have the following computation graph: The output will be But will the computation to get b be reused to get c? Or will b and c be computed independently even though they share some operations? My guess is that the computation will be reused, but I can't find the answer in the documentation. Thanks!",https://stackoverflow.com/questions/38722799,1738214.0,1
160,48035125,Speed of Logistic Regression on MNIST with Tensorflow,"I am taking the CS 20SI: Tensorflow for Deep Learning Research from Stanford. I have question regarding the following code: On this code, logistic regression with MNIST dataset is performed. The author states: However, when I run it, each epoch takes around 2 seconds, giving a total execution time of around a minute. Is it reasonable that this example takes that time? Currently I have a Ryzen 1700 without OC (3.0GHz) and a GPU Gtx 1080 without OC.",https://stackoverflow.com/questions/48035125,8480308.0,1
161,71675036,Transformer tutorial with tensorflow: GradientTape outside the with statment but still working,"Applying the tensorflow tutorial on how to implement a transformer model I had some doubts on the training process. The train_step function is implemented as: We can see that tf.GradientTape() is defined as tape in a with statment. That works, but I don't understand how tape can be called outside the statement with: Shouldn't tape be closed at the end of the with statement? I implemented the code from the tutorial and it works as is.",https://stackoverflow.com/questions/71675036,18630256.0,1
162,49568041,Tensorflow: How do I convert a EagerTensor into a numpy array?,"With standard Tensorflow: With eager execution: If I try y.eval(), I get NotImplementedError: eval not supported for Eager Tensors. Is there no way to convert this? This makes Eager Tensorflow completely worthless. There's a function tf.make_ndarray that should convert a tensor to a numpy array but it causes AttributeError: 'EagerTensor' object has no attribute 'tensor_shape'.",https://stackoverflow.com/questions/49568041,9572907.0,1
163,64113696,Practical meaning of output in simple recurrent neural network,"I am trying to learn RNN model. Here is the model I built: I don't understand the meaning of Yhat. Here I consider X as sequential data: [data_point0...data_pointT], [data_point0...data_pointT], [data_point0...data_pointT] Each data point has D=3features. Here Yhat.shape==(1, 2). 2 doesn't equal to D which is a number of features. I guess, model.predict() doesn't make a prediction on the next data point. If model.predict() do prediction on the next data point, The shape of the result should be (1, D). Then what's the practical meaning of Yhat?",https://stackoverflow.com/questions/64113696,10035055.0,1
164,55876674,Keras Stuck on First Epoch,"I was trying to test out whether Keras and TensorFlow are working on my MacBook Pro on the latest Mojave with 32GB of RAM and apparently it is not! I tried installing them in a separate, new environment, and it worked fine, but I don't understand why it won't work in my base (root) environment. I expected to get this result, which I did in my clean environment: But instead, I only got this: I ran the exact same code on the exact same computer using the exact same installation method (pip). Any and all help would be greatly appreciated!",https://stackoverflow.com/questions/55876674,11173612.0,1
165,52702183,Difference of tf.Variable() and tf.get_variable(),"I have following lines of code in Tensorflow: First line creates &lt;tf.Variable 'y:0'&gt;. Second line creates &lt;tf.Variable 'y_1:0'&gt;. The last lines do not create variable and just reuse &lt;tf.Variable 'y_1:0'&gt;. Also, the following lines of code lead to ValueError message: How Tensorflow determines that it should reuse &lt;tf.Variable 'y_1:0'&gt; and not &lt;tf.Variable 'y:0'&gt;? How does Tensorflow store information about the way the Variable was created? Cause names of created Variables appear to have no information about this. Edit: The main question is how Tensorflow understands in the example above that one should reuse the latter Variable &lt;tf.Variable 'y_1:0'&gt; and not the former? I did not specify here variable scope - so maybe there is an implicit variable scope (that is not displayed in name of Variable) for Variables created with tf.get_variable()?",https://stackoverflow.com/questions/52702183,10472944.0,1
166,72703155,How to create a Keras layer from tf.math.segment_sum,"I would like to use the tf.math.segment_sum function in a Keras layer but I don't get the dimensions right. As an example, I would like to sum the values of x_1 grouped by id in the dataframe df: The 'model' I created looks as follows: I get an error about the rank: ValueError: Shape must be rank 1 but is rank 2 for 'segment_sum/SegmentSum' (op: 'SegmentSum') with input shapes: [?,1], [?,1]. What do I do wrong here?",https://stackoverflow.com/questions/72703155,5892273.0,1
167,51700477,Create new tensorflow image classification module using tensorflow hub,"I'm new in tensorflow, i am trying to create new image classification module, I tried below example using tensorflow hub. but its not created. Is any simple example for create image classification module",https://stackoverflow.com/questions/51700477,840438.0,1
168,75354818,Using attention in a CNN attention model,"I am very new to python and ML. I have a working CNN LSTM model as below: I want to add attention to it that is provided by Tensorflow. I am unsure about the inputs of this attention layer and whether to have a CNN LSTM Attention model or replace LSTM with Attention. I tried to add Attnetion after the LSTM layer with the input as [e[0],e[1]] but this contributes 0 parameters to the model and has a model summary as (not sure if this is the right way):",https://stackoverflow.com/questions/75354818,21153211.0,1
169,58265205,Iterate through irregular tensor slices without for loop,I am trying to iterate through a tensor using slices of different (but fixed) length. The following sample code shows my actual proceeding: Can anyone think on an optimal way of doing this without the for loop? It's creating a lot of unnecessary operations in the computation graph,https://stackoverflow.com/questions/58265205,8380638.0,1
170,51264199,How to run a hand coded TF network (no training),"I have created a small TF network where I have tried to initialize all the weights by hand. I am trying to give it a specific input (of all ones) and see what the network will generate. The reason I am doing it is that I am trying to reproduce a TF model in R and am having some differences and I would like to do a debug by trying to replicate a small model in TF and R and compare the results. So, the input to the model is created as: The network is very simple where we have a: So, I create the network as follows: I think I have created the network correctly. However, now I have no idea how to run this. The online examples that I have seen seem to train and tehn save the weights and reload the saved graph but I was wondering if there is an easy way to simply run the forward pass (I do not need to do any training and I have hard coded the weights) and get the 128 dimensional vector out, so that I can verify the output?",https://stackoverflow.com/questions/51264199,2713740.0,1
171,65470226,Understanding the GIoU loss function in tensorflow,The custom Loss function I am looking at is as follows: My questions:,https://stackoverflow.com/questions/65470226,14897937.0,1
172,47798492,Using Datasets to consume Numpy arrays,"I'm trying to use Numpy arrays within a graph, feeding in the data using a Dataset. I've read through this, but can't quite make sense of how I should feed placeholder arrays within a Dataset. If we take a simple example, I start with: Then I attempt to modify it to use a Dataset as follows: If I run this I get 'InvalidArgumentError: You must feed a value for placeholder tensor ...' The code until the for loop mimics the example here, but I don't get how I can then employ the placeholders a &amp; b without supplying a feed_dict to every call to sess3.run(c) [which would be expensive]. I suspect I have to somehow use the iterator, but I don't understand how. Update It appears I oversimplified too much when picking the example. What I am really trying to do is use Datasets when training a neural network, or similar. For a more sensible question, how would I go about using Datasets to feed placeholders in the below (though imagine X and Y_true are much longer...). The documentation takes me to the point where the loop starts and then I'm not sure. Trying the following only gets me a InvalidArgumentError",https://stackoverflow.com/questions/47798492,9094969.0,1
173,70745528,Fit tf.data.Dataset with from_generator,"I am training a NN to read 4 images and predict the next 4. Since I have a huge dataset, I have written this generator: Where obtain_data is just open the file, load 4 480x480 matrices and reshape to (4, 480, 480, 1). Then, following a post from here, I do: I am not sure about the necessity of using repeat... It is now commented in my code. The model, called rnc, goes here (omitted for brevity, ConvLSTM and Conv3D involved). I want to train 1 batch of data. In theory, 1 batch of data should be 4 matrices 480x480 with 1 channel, (4, 480, 480, 1) as input and also (4, 480, 480, 1) as output. But I don't obtain anythinig from the training and I am quite suspicious. I wonder if the preparation of the TF dataset is something I am doing correctly.",https://stackoverflow.com/questions/70745528,6010635.0,1
174,43158606,How to get weights from tensorflow fully_connected,"I'm trying to extract the weights from a model after training it. Here's a toy example I've looked at Get weights from tensorflow model and at the docs but can't find a way to retrieve the value of the weights. So in the toy example case, suppose that X_ has shape (1000, 5), how can I get the 5 values in the 1-layer weights after",https://stackoverflow.com/questions/43158606,3340344.0,1
175,44764887,How to restore trained LinearClassifier from tensorflow high level API and make predictions,"I have trained a logistic regression model model using tensorflow's LinearClassifier() class, and set the model_dir parameter, which specifies the location where to save metagrahps of checkpoints during model training: I've been reading about restoring models from metagraphs, but have found nothing about how to do so for models created using the high level api. LinearClassifier() has a predict() function, but I can't find any documentation on how to run prediction using an instance of the model that has been restored via checkpoint metagraph. How would I go about doing this? Once the model is restored, my understanding is that I am working with a tf.Sess object, which lacks all of the built in functionality of the LinearClassifier class, like this: How do I run the same prediction algorithm used by the high-level api to make predictions on a restored model? Is there a better way to approach this? Thanks for your input.",https://stackoverflow.com/questions/44764887,5540936.0,1
176,46983011,"Tensorflow: read variable length data, via Dataset (tfrecord)","Best I would like to read some TF records data. This works, but only for Fixed length data, but now I would like to do the same thing with variable length data VarLenFeature and result: here is the map function which i'm trying to use, but at the end it gives me some errors :'( error: Thus can you someone help me? Also, i'm using tensorflow nightly. I don't think that i'm missing a lot ...",https://stackoverflow.com/questions/46983011,1275087.0,1
177,61017227,Tensorflow 2: Customized Loss Function works differently from the original Keras SparseCategoricalCrossentropy,"I just started to work with tensorflow 2.0 and followed the simple example from its official website. The output for the above code is: However, if I change the lossFunc to the following: which just simply wrap the previous function, it performs totally differently. The output is: The loss values are very similar but the accuracy values are totally different. Anyone knows what is the magic in it, and what is the correct way to write your own loss function?",https://stackoverflow.com/questions/61017227,13213903.0,1
178,62405567,How to skip the current iteration of tf.while_loop()?,"I have only recently started working with Tensorflow2. I'm trying to re-program a script that randomly cuts squares out of images. The original code comes from this github repository: Link. I fail due to the tf.while_for() loop in Tensorflow2. But here is the code I wrote so far: My problem lies in the following line: I always get ""Exception has occurred: TypeError cond(): false_fn argument required"" messages. I want to call the function ""calculate_valid_boxes()"" in this line if the statement is true or if the statement is false I want to jump to a new iteration. In plain Python you could solve this either with ""break"" or ""continue"" statement (depending on the implementation) but with Tensorflow2 I'm not able to find a solution. If the information is relevant, the function works with a batch of images.",https://stackoverflow.com/questions/62405567,13460282.0,1
179,45779307,Difference between tf.assign and assignment operator (=),"I'm trying to understand the difference between tf.assign and the assignment operator(=). I have three sets of code First, using simple tf.assign The output is expected as Second, using assignment operator The results are still 2, 2, 2. Third, I use both tf.assign and assignment operator Now, the output becomes 2, 3, 4. My questions are Thanks.",https://stackoverflow.com/questions/45779307,8490020.0,1
180,47860237,how to use tf operations in keras models,I am trying to us tensorflow operations within a keras model and I am quite confused about the mechanism and what Lambda layers do to tf tensors. So this works: but this does not work: and it says: so is it always necessary to pack up tf operations within a layer? Question 2 (was why I came up the previous one): do we have to pack with a custom layer to do matrix multiplication in keras? thanks.,https://stackoverflow.com/questions/47860237,9050461.0,1
181,42845921,Why tesorflow changes predictions when not changing the code?,"I made a very simple xor predicting DNN. It goes as follows. Sometimes (more than average) it correctly predicts [0,1,1,0] but other times it predicts very wrongly. It could be because the choice it mades at first, which after making it the weights go in one direction of training which is not the correct one, but how can I be almost certain (95% up) that the predicted value will be the correct one?",https://stackoverflow.com/questions/42845921,6911731.0,1
182,56179409,what should I encode background class with tf.one_hot?,"When I do a classification job, I need to encode a classid with one_hot method. But shuold I encode background class with -1 or 0 with tf.one_hot function? For example:",https://stackoverflow.com/questions/56179409,988709.0,1
183,75648889,tf keras autokeras with early stopping returns empty history,"I am trying different models for the same dataset, being autokeras.ImageClassifier one of them. First I go for For getting the dataset with a predefined function and then I fit the model with an early stopping callback: The problem is that when train stops because of the callback, history is None type, what means is an empty object. I have not been able to find anything similar in the internet, for everyone it seems to work properly. I know the problem is with the callback because I fit the model without any callback it works properly. The output when the train is ended by the callback is this one:",https://stackoverflow.com/questions/75648889,15112321.0,1
184,53620581,Calculate F1 Score using tf.metrics.precision/recall in a tf.Estimator setup,"I'm trying to calculate F1 score in a tf.Estimator setup. I've seen this SO question, but couldn't distill a working solution from it. The thing with tf.Estimator is that it expects me to deliver a value and an update op, so right now, I have this piece of code at the end of my model: Now the precision and recall seem to be working just fine, but on the F1 score, I keep getting nan. How should I go about getting this to work? EDIT: A working solution can be achieved with tf.contrib.metrics.f1_score but since contrib is going to be deprecated in TF 2.0, I'd appreciate a contrib-less solution",https://stackoverflow.com/questions/53620581,5368083.0,1
185,44313202,What are the 'from' and 'to' dimensions of transition_params in tf.contrib.crf.crf_log_likelihood?,"On TensorFlow, I want to pass a transition_params matrix as argument to tf.contrib.crf.crf_log_likelihood (https://www.tensorflow.org/api_docs/python/tf/contrib/crf/crf_log_likelihood), in order to initialize the transitions matrix of the CRF. Although, in the documentation, it is not clear which dimension of this matrix corresponds to the first tag of the transition and which dimension corresponds to the second. So, let T be the transitions matrix, does T[i,j] represent the score of the transition from tag i to tag j, or is it the other way around?",https://stackoverflow.com/questions/44313202,1868775.0,1
186,41666964,model variables in Tensorflow's batch_norm,"The documentation online says moving_average and moving_variance are both model_variables, and tf.model_variables() returns tensors of the type local_variables. Does that mean model_variables are not saved when I save my state? I'm trying to apply batch normalization to a couple of 3D convolution and fully connected layers. I trained my network with batch_norm and saved a checkpoint file, but when I went to restore my saved state, it said moving_mean could not be located. The exact error was, when TF went to assign the restored value to moving_mean, the shape of the lhs tensor, [], could not be reconciled with the that of the rhs, [20]. The graph restores fine when I don't add batch_norm around my layers. I'm planning to add a global variable at the end of training that saves my moving_mean and moving_variance values. Is this the way TF intended for me to use batch_norm? Thanks!",https://stackoverflow.com/questions/41666964,3873000.0,1
187,55429816,How to compute f1 in tensorflow,"I have a code which computes the accuracy, but now i want to compute the f1 score. How to compute f1 equivalent for the above code. I'm finding it difficult as i am very new to tensorflow.",https://stackoverflow.com/questions/55429816,3312839.0,1
188,74670055,How to implement a numpy equation in the call of a tensorflow layer for a tensorflow model (Cannot convert a symbolic tf.Tensor to a numpy array),"I have this layer class in tensorflow where i want to implement a specific equation in numpy for the return in the call function. I have this following custom layer: This layer is then implement in a model in the following way: One of my first concern is if I'm doing this model class correctly as i just learnt how to do it. By trying to fit this model with the training set (which are numpy array, dtype = float32 and size is (72367, 50)) I obtain the following error: Thanks",https://stackoverflow.com/questions/74670055,9469603.0,1
189,47072821,What's the equivalent of this Keras code in TensorFlow?,"The code is as below and runs perfectly: I can't work out the code in TensowFlow, something I've written is like this: But I will got the following error while running, The main reason is the shape of W, must be the same as x in TensowFlow, but in Keras, the hidden Dense layer could have more nodes than the input(such as 64 in the example). I need help for the equivalent TensorFlow code instead of the Keras one. Thanks.",https://stackoverflow.com/questions/47072821,8545722.0,1
190,69821629,"Tensorflow: reshape [N,H,W,C] to [N*C,H,W,1] for convolution per channel","What I would like to achieve is applying a 2D convolution with one filter that is applied across all channels. Note that I am not looking for a depthwise convolution, but really one filter. In order to do this, my plan was to reshape [N,H,W,C] to [N*C,H,W,1], apply convolution, and then reshape back, so my output is [N,H,W,C] again. However, while implementing this, I noticed that the output of the first reshape contains some kind of interleave between the channels or batch or something (image from ImageNet): Before reshape, After reshape. My intuition was that this might be because batch and channels are not adjacent in memory. For this reason, I experimented by transposing the input first and then apply reshaping, convolution, reshaping and transposing back: This indeed seems to work like I would expect, but is quite a slow approach. I have a series of questions: Thanks in advance edit: I think I at least understand why the interleaving is happening. Let me try to explain by how I understand it, and format it as good as possible. The letters n,h,w,c here should help identifying to what a number belongs. Suppose I have 16 numbers which are contiguous in memory: If they are shaped NHWC: 2,2,2,2 Then if they are reshaped to NHWC: 4,2,2,1 and by keeping the underlying data contiguous, we get: In this way channels get mixed up in the spatial dimensions of the image.",https://stackoverflow.com/questions/69821629,17316671.0,1
191,48371783,Can I asynchronously prefetch to the GPU in tensorflow (1.4) using a two-variables approach?,"As far as I'm aware there is still no asynchronous prefetching of data between CPU/GPU in tensorflow 1.4. https://github.com/tensorflow/tensorflow/issues/5722 I am trying to code this functionality myself as an exercise in understanding. The following code attempts to implement this process: This doesn't appear to work. The TF profiler shows that myop is not asynchronously processed with the MEMCPYHtoD process as was hoped for. I had expected that the two OPs, myop, and prefetch_op would run asynchronously because there are no dependencies between them. Here is the code I used to run this test. It will run stand-alone.",https://stackoverflow.com/questions/48371783,4790871.0,1
192,59142761,The accuracy of basic Tensorflow model not increasing,"I am really new to Data Science/ML and have been working on Tensorflow to implement Linear Regression on California Housing Prices from Kaggle. I tried to train a mode in two different ways: In both cases, the loss of the model was really high and I have not been able to understand what are the ways to improve it.",https://stackoverflow.com/questions/59142761,1561188.0,1
193,60664810,"In TensorFlow 2.0 with eager-execution, how to compute the gradients of a network output wrt input layer?","I use network InceptionV3, I want to compute the gradients of the model output w.r.t. the input layer. I have the following code: but this code is running: How can tf.GradientTape be used to calculate the gradient of the output with respect to the input",https://stackoverflow.com/questions/60664810,7998707.0,1
194,59590766,How do I get the gradient of a keras model with respect to its inputs?,"I just asked a question on the same topic but for custom models (How do I find the derivative of a custom model in Keras?) but realised quickly that this was trying to run before I could walk so that question has been marked as a duplicate of this one. I've tried to simplify my scenario and now have a (not custom) keras model consisting of 2 Dense layers: Now I would like to know the derivative of outputs with respect to inputs for inputs = input_data. What I've tried so far: This answer to a different question suggests running grads = K.gradients(model.output, model.input). However, if I run that I get this error; I can only assume this is something to do with eager execution now being the default. Another approach was in the answer to my question on custom keras models, which involved adding this: What I don't understand about this approach is how I'm supposed to load the data. It requires x to be a variable, but my x is a tf.keras.Input object. I also don't understand what that with statement is doing, some kind of magic but I don't understand it. There's a very similar-sounding question to this one here: Get Gradients with Keras Tensorflow 2.0 although the application and scenario are sufficiently different for me to have difficulty applying the answer to this scenario. It did lead me to add the following to my code: That does work, but now what? I run model.predict(...), but then how do I get my gradients? The answer says I should run t.gradient(outputs, x_tensor).numpy(), but what do I put in for x_tensor? I don't have an input variable. I tried running t.gradient(outputs, model.inputs) after running predict, but that resulted in this:",https://stackoverflow.com/questions/59590766,1613983.0,1
195,60250039,Can't convert a tf.data.Dataset object to a numpy iterator,I am using Tensorflow 1.14.0 and tensorflow_datasets 1.2.0 When trying to run the following code I get the following error According to the tensorflow_datasets docs this should work. Why won't it? And why am I getting a DatasetV1Adapter object in the first place?,https://stackoverflow.com/questions/60250039,9261771.0,1
196,45959112,Get coefficients of a linear regression in Tensorflow,I've done a simple linear regression in Tensorflow. How can I know what are the coefficients of the regression? I've read the docs but I cannot find it anywhere! (https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) EDIT Code example,https://stackoverflow.com/questions/45959112,3070571.0,1
197,61585473,ValueError: An operation has `None` for gradient - Not using Custom,"As per the title, I get this common error when trying to use Keras to do some Image Classification training. Unlike nearly all of the other examples, I am not trying to customise anything and simply using bog-standard keras functionality! Like this, who asks a similar question, but doesn't appear to have followed up. I previously had an issue with this same project, but after having upgraded cudnn, and cudatoolkit (and relevant NVidia backends) I get this new error. Conda List: Code Log Edit 1: Following Matias' recommendation and removing the allows me to run one epoch, but now I get Edit 2: As Matias pointed out, my code was only set to run 1 epoch. So, removing the clear_session() worked to fix my problem.",https://stackoverflow.com/questions/61585473,6631893.0,1
198,54752287,Get input (filenames) from tensorflow dataset iterators,"I am using tensorflow datasets to train a model. A list of filenames is taken by the dataset to read them during the session, and I would like to get the filename together with the image. In more detail, I have something like this: I thought that this information could be included in the iterator, but I could not find it.",https://stackoverflow.com/questions/54752287,7780842.0,1
199,61817055,Why BinaryCrossentropy as loss and metrics are not identical in classifier training using tf.keras (Tensorflow 2.0)?,"I am using BinaryCrossentropy as both a loss and one of the metrics: Since they are the same thing, I think they should produce the same result. However they shows slightly different values on both training set and validation set respectively. Why is this? Shouldn't BinaryCrossentropy has the same value on the same data? Is it possible that, the loss value is the loss on the final batch, and the metric value is calculated on all batches of the epoch (average?)? I tried to find relevant information on tf.keras.Model.compile, but I couldn't confirm this yet.",https://stackoverflow.com/questions/61817055,1516331.0,1
200,59615096,Keras style lossless triplet loss,"I am trying to replicate the lossless tripler loss, but using the ""K."" syntax, like in my triplet loss below: My code Code from the article As I unterstand, all I have to do is to insert in my code. Is there a ""translation"" from ""tf."" style to ""K."" style for these lines? Thank you.",https://stackoverflow.com/questions/59615096,5079088.0,1
201,47806239,What is not feedable in tensorflow?,I've tried the following code. But I don't find what is not feedable in tensorflow. Could anybody show me what is not feedable?,https://stackoverflow.com/questions/47806239,1424739.0,1
202,48242585,"tf.gradients() won't work with 'tf.assign()', but works with '='","In a simple code below, gradient gets computed correctly. The result, as expected, is [array([ 2., 2., 2., 2.], dtype=float32)]. I get into problem when trying to use tf.assign for function computation. The below code: ... yields an error: Why is that so? Is the connection between x and y node somehow ""lost"" via the tf.assign operation?",https://stackoverflow.com/questions/48242585,7797315.0,1
203,51444526,How to forecast using the Tensorflow model?,"I have created tensorflow program in order to for the close prices of the forex. I have successfully created the predcitions but failed understand the way to forecast the values for the future. See the following is my prediction function: Here is the complete jupyter and datasets for test and train: My repository with code. Kindly, help me how I can forecast the close values for the future. Please do not share something related to predictions as I have tried. Kindly, let me know something that will forecast without any support just on the basis of training what I have given. I hope to hear soon.",https://stackoverflow.com/questions/51444526,4948889.0,1
204,36354101,Linear regression with tensorflow is very slow,"I am trying to implement a simple linear regression in tensorflow (with the goal of eventually extending it to more advanced models). My current code looks as follows: The code works, and finds the correct coefficients. However, it is extremely slow. On my MacBook Pro, it takes several minutes just to run a few training epochs for a data set with 1000 data points and 10 features. Since I'm running OSX I don't have GPU acceleration, which could explain some of the slowness, but I would think that it could be faster than this. I have experimented with different optimizers, but the performance is very similar. Is there some obvious way to speed up this code? Otherwise, it feels like tensorflow is pretty much useless for these types of problems.",https://stackoverflow.com/questions/36354101,3468216.0,1
205,62357678,How to define a custom loss function for a model with multiple inputs and outputs in Keras?,"I'm working on Keras implementation of an architecture that takes 2 inputs (input_im_low, input_im_high) and passes them separately to one architecture and gets 2 outputs. The network is using a custom loss function defined based on these 2 outputs and the inputs, and there is not any ground truth, as the goal of the training is to reduce the custom loss. I tried to create the loss function according to Keras documentation (https://keras.io/api/losses/), but it doesn't work properly. I wasn't sure if I need to use the add_loss() API, and if yes, how it should be adjusted for my case? Can anyone advise me how to adjust the loss function? I get the following error by running the code: Here is the code: P.S. - A Tensorflow 1.x implementation of this network can be found at https://github.com/weichen582/RetinexNet.",https://stackoverflow.com/questions/62357678,13551661.0,1
206,76325816,Why is the result changing every time I run my TensorFlow model in my code?,"such a problem I wrote this code, but I can’t understand when I run the code every time, the result changes, then: (1,0,0), (0,1,0), (1,1,1) and so on, can you tell me please what the problem is? even on the data on which the model was trained, the result is still not what is expected. Thanks result must be 1, 0, 0",https://stackoverflow.com/questions/76325816,16761544.0,1
207,47473996,Variable substitution without duplicating the tensor (or having the graph accepting two different input),I think it is easier to clarify what I need with a MWE (question is in the comment).,https://stackoverflow.com/questions/47473996,754136.0,1
208,75941954,Input shape for functional Tensorflow api,What would be an example of properly shaped inputs for the following nn?,https://stackoverflow.com/questions/75941954,417896.0,1
209,59353238,How to read a Protobuf that was written by a TFRecordWriter,I am trying to read data that was written with tf.io.TFRecordWriter as shown below: I am then using the schema as given by: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto along with protoc to decode it. The reading program is: Using the ParseFromString method I expect to be able to recover the data written after executing the above program but I consistently get: What am I doing wrong?,https://stackoverflow.com/questions/59353238,2217539.0,1
210,69541120,strange behavior of tensorflow decorator @tf.function,"Can somebody explain the behavior of this code: which returns 1,1,1,1,1... (the counter does not increase). The next code works : it returns 1,2,3,...",https://stackoverflow.com/questions/69541120,17134780.0,1
211,51192489,Tensorflow CustomEstimator DNNRegressor label_dimensions,"I am currently fairly new to tensorflow and I'm trying to predict the position of a particle based on it's position in past time steps. my features looks like this: and my labeles look like this: as you can see my Labels are 2-Dimensional. My first attempt uses tensorflows premade estimator tf.estimator.DNNRegressor and by giving it the argument label_dimension=2 during creation this works well. Now I'd like to do the same with a custom estimator. Sadly the tutorials on the tensorflow site are all using Classifier instead of Regressors and the only example I've been able to find online is this, but they only use a one-dimensional output. I've been experimenting quite a bit, but I wasn't able to get any progress. I'm fairly certain that I have to change line 41 But if I do that, I can't get the rest of the file to function.",https://stackoverflow.com/questions/51192489,5836995.0,1
212,58188750,"Discrete Bayesian network on Tensorflow Probability, Edward2, and Python","I have a simple Bayesian network: with random variables ""state"", ""signal_1"", and ""signal_2"" with corresponding discrete values: Val(state) = {0, 1, 2, 3}, Val(signal_1) = {0, 1}, and Val(signal_2) = {0, 1}. I have marginal probability distribution P(state) and conditional probablity distributions P(signal_1|state) and P(signal_2|state) as tables. Joint probability P(state, signal_1, signal_2) is equal to P(state) * P(signal_1|state) * P(signal_2|state) and log P(state, signal_1, signal_2) = log P(state) + log P(signal_1|state) + log P(signal_2|state). I'm trying to construct this model in TensorFlow Probability: Variant 1: My evidence is, for example, ""signal_1 = 1"" and ""signal_2 = 0"" and I want to get a probability of ""state = 0"", i.e. P(state=0|signal_1=1, signal_2=0) I define the function: Variant 2 via Edward2: Then I get the joint log-probability function which can be used via lambda-expression: Did I define the model correctly? The question is how do I continue to use MCMC? Which MCMC method can I use for this discrete model? Can someone show a MCMC code for my model? How can I tell the MCMC algorithm to take samples for ""state"" only from the set {0, 1, 2, 3}? Thank you!",https://stackoverflow.com/questions/58188750,12149276.0,1
213,70615673,"Use of tf.GradientTape() exhausts all the gpu memory, without it it doesn't matter","I'm working on Convolution Tasnet, model size I made is about 5.05 million variables. I want to train this using custom training loops, and the problem is, This part exhausts all the gpu memory (24GB available).. When I tried without tf.GradientTape() as tape, This uses a reasonable amount of gpu memory(about 5~6GB). I tried the same format of tf.GradientTape() as tape for the basic mnist data, then it works without problem. So would the size matter? but the same error arises when I lowered BATCH_SIZE to 32 or smaller. Why the 1st code block exhausts all the gpu memory? Of course, I put this code at the very first cell.",https://stackoverflow.com/questions/70615673,7820717.0,1
214,49366765,How can I read endlessly from a Tensorflow tf.data.Dataset?,"I'm switching my old datalayer (using Queues) to the ""new"" and recommended Dataset API. I'm using it for the first time, so I'm providing code examples in case I got something fundamentally wrong. I create my Dataset from a generator (that will read a file, and provide n samples). It's a small dataset and n_iterations &gt;&gt; n_samples, so I simply want to read this dataset over and over again, ideally shuffled. with datagenerator: To actually use the data, I got that I need to define an Iterator and then we are set to read data But all available Iterators seem to be ""finite"", in the way that they read a dataset only once. Is there a simple way to make reading from the Dataset endless?",https://stackoverflow.com/questions/49366765,6409572.0,1
215,75290762,What can I do to help make my TensorFlow network overfit a large dataset?,"The reason I am trying to overfit specifically, is because I am following the ""Deep Learning with Python"" by François Chollet's steps to designing a network. This is important as this is for my final project in my degree. At this stage, I need to make a network large enough to overfit my data in order to determine a maximal capacity, an upper-bounds for the size of networks that I will optimise for. However, as the title suggests, I am struggling to make my network overfit. Perhaps my approach is naïve, but let me explain my model: I am using this dataset, to train a model to classify stars. There are two classes that a star must be classified by (into both of them): its spectral class (100 classes) and luminosity class (10 classes). For example, our sun is a 'G2V', it's spectral class is 'G2' and it's luminosity class is 'V'. To this end, I have built a double-headed network, it takes this input data: DataFrame containing input data It then splits into two parallel networks. In the code above you can see me attempting a model with two hidden layers in both branches, one layer with a shape of 100 000, following into another layer with 500, before going to the output layer. The training targets are one-hot encoded, so there is one node for every class. I have tried a wide range of sizes with one to four hidden layers, ranging from a shape of 500 to 100 000, only stopping because I ran out of RAM. I have only used dense layers, with the exception of trying a normalisation layer to no affect. Graph of losses They will all happily train and slowly lower the loss, but they never seem to overfit. I have run networks out to 100 epochs and they still will not overfit. What can I do to make my network fit the data better? I am fairly new to machine learning, having only been doing this for a year now, so I am sure there is something that I am missing. I really appreciate any help and would be happy to provide the logs shown in the graph.",https://stackoverflow.com/questions/75290762,17881427.0,1
216,64713721,Feeding multiple inputs and outputs in the tensor model?,"I have created multiple layer model, and now I would like to teach it with hundreds of values, so it can predict outputs from different inputs. But how should I implement those inputs? I tried now to make some array in array. And feed inputs and outputs one by one using training function. But it seems that on the second time its reteaching itself and it predicts only second answer rightly. Maybe I dont understand the concept?",https://stackoverflow.com/questions/64713721,12125348.0,1
217,41268447,Dynamic tensor shape for tensorflow RNN,"I'm trying a very simple example for tensorflow RNN. In that example, I use dynamic rnn. The code is as follows: Actually, the code is taken from this tutorial. The input to this RNN network is a sequence of binary numbers. Each number is put into an array. For example, a seuquence has format: [[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]] The shape of the input is [None,10,1] which are batch size, sequence size and embedding size, respectively. Now because dynamic rnn can accept variable input shape, I change the code as follows: Basically, I want to use variable-length sequences (of course same length for all sequences in the same batch, but different between batches). However, it throws the error: I understand that the second dimension is None, which cannot be used in get_shape()[0]. However, I believe that there must be a way to overcome this because RNN accepts variable lenth inputs, in general. How can I do it?",https://stackoverflow.com/questions/41268447,2241766.0,1
218,39112622,How do I set TensorFlow RNN state when state_is_tuple=True?,"I have written an RNN language model using TensorFlow. The model is implemented as an RNN class. The graph structure is built in the constructor, while RNN.train and RNN.test methods run it. I want to be able to reset the RNN state when I move to a new document in the training set, or when I want to run a validation set during training. I do this by managing the state inside the training loop, passing it into the graph via a feed dictionary. In the constructor I define the the RNN like so The training loop looks like this x and y are batches of training data in a document. The idea is that I pass the latest state along after each batch, except when I start a new document, when I zero out the state by running self.reset_state. This all works. Now I want to change my RNN to use the recommended state_is_tuple=True. However, I don't know how to pass the more complicated LSTM state object via a feed dictionary. Also I don't know what arguments to pass to the self.state = tf.placeholder(...) line in my constructor. What is the correct strategy here? There still isn't much example code or documentation for dynamic_rnn available. TensorFlow issues 2695 and 2838 appear relevant. A blog post on WILDML addresses these issues but doesn't directly spell out the answer. See also TensorFlow: Remember LSTM state for next batch (stateful LSTM).",https://stackoverflow.com/questions/39112622,1120370.0,1
219,48637688,How to get better prediction (lower Mean Absolute Error) with TF NN?,"this is more strictly individual question, but I hope someone will help me here. I am having this TF model which has to predict as accurately as possible a some continuous numbers. I am trying to get the result to be with MAE accuracy bellow 6400 but my closest MAE prediction was 79000. I have 90 input features. 130000 rows of training data. 10000 rows of validation data. My model: My cost function: My optimizer: I am also preprocessing my test and validation data: I tried many variation, more layers more neurons, different optimizations, normalization, cost, learning rates, epochs, batch sizes function but I cannot get more that: Do you have any suggestions how to do it better? Thank you!",https://stackoverflow.com/questions/48637688,4898951.0,1
220,39703789,TensorFlow unexpected behaviour,"I am running the following code: Gives: [100,2] However, after that: Gives the origianl value of y: [1,2]. Why doesn't the: updates the value of y, and saves it?",https://stackoverflow.com/questions/39703789,6857504.0,1
221,76103475,tensorflow dataset builder that runs download_and_prepare with multiprocessing,"The TensorFlow Datasets guide on creating a dataset suggests subclassing the tfds.core.DatasetBuilder. Below is my subclass; it reads NetCDF files and extracts the relevant variables as examples. How can I improve performance with parallel processing? When executing the download_and_prepare pethod, I'm only ever at 100% CPU and can't find any documentation on using multiple threads or cores. The fact that the class utilizes iteration in Python over a generator makes me afraid it's not possible. Is there an alternative approach?",https://stackoverflow.com/questions/76103475,687112.0,1
222,44134353,Input to the command tf.nn.conv2d,"I type the following lines in Syder (Anaconda): 'inlay' suppose to be the input for tf.nn.conv2d. However, I got the following ValueError: I do not understand. The input np.array, 'inlay', is a 4D tesnor, so what is the problem?",https://stackoverflow.com/questions/44134353,7864161.0,1
223,55095907,how to save tensorflow model with tf.estimator,I have the following example code to train and evaluate a cnn mnist model using tensorflow's estimator api: How can I use the estimator.export_savedmodel to save the trained model for later inference? How should I write the serving_input_receiver_fn? Thank you very much for your help!,https://stackoverflow.com/questions/55095907,10129585.0,1
224,38190365,How does one initialize a variable with tf.get_variable and a numpy value in TensorFlow?,I wanted to initialize some of the variable on my network with numpy values. For the sake of the example consider: when I do that I get an error: why is it that I am getting that error? To try to fix it I tried doing: which yielded a even weirder error: I tried reading the docs and examples but it didn't really help. Is it not possible to initialize variables with numpy arrays with the get_variable method in TensorFlow?,https://stackoverflow.com/questions/38190365,1601580.0,1
225,47816188,Tensor Flow - MetaGraphDef Protobuf: Difference between node_list and bytes_list in collection_def,I'm currently working on Tensor Flow and I need to get a better understanding on how framework Python API serializes the tf.Variables during the saving operation. The model has been saved during a distributed computation (I don't know if this information can be useful). In order to be clear creating a tf.Variable in this way: I get this kind of collection_def inside the protobuf. While if I create a tf.Variable with this line of code: I'll get that collection_def inside the protobuf of the model I saved: Why the first collection_def has a bytes_list while the second one has a node_list ? Which are the difference between these two situations regarding the storing and the restoring of the model?,https://stackoverflow.com/questions/47816188,9099269.0,1
226,63877806,Tensorflow Keras custom metrics error on update_state(),"Using TF 1.15 with tf.Estimator interface to train and evaluate models. Trying to write a custom TF metric, using tf.keras.metric.Metric for that. I wrote a custom metric and included that in the eval_metrics_ops (example below). If I define an estimator with the metrics, I get the following error. The wording of the error looks clear (I have to call update_state()) but I am not sure where do I call update_state() on the metric (not sure if I even should call). Not a minimal example, but this is a demo metric I wrote. Creating a dict where metric name is the key and the metric instance is the value. This is where it mentions how to create a dict for eval_metrics_ops. Any idea how I can get rid of that error?",https://stackoverflow.com/questions/63877806,1586200.0,1
227,59626966,Using tensors are dictionary keys in tensorflow,i have seen the answer here. It is not what i am looking for. I am running this on tensorflow2.0 I read the following sentence in the TensorFlow documentation: I tried using tensors as a dictionary key and i get the following error:,https://stackoverflow.com/questions/59626966,6546694.0,1
228,61478301,What is the equivalent API of tf.contrib.factorization.KMeans in TensorFlow 2.0?,"In Tensorflow 1.13.1 the clustering models can be built using KMeans alogithm using tf.contrib.factorization.KMeans but after upgrading to TensorFlow 2.0, I'm finding it difficult to locate a suitable API for building a clustering model. I found an estimator API for K-Means tf.compat.v1.estimator.experimental.KMeans. However, it is not as developer friendly as the former one. I need to implement a clustering model using TensorFlow but not sure which API would be a right fit.",https://stackoverflow.com/questions/61478301,13403358.0,1
229,58702695,Differentiating user-defined Variables when using Keras layers,"I want to multiply a Keras layer with my own Variable. Then, I want to compute the gradients of some loss relative to the variables I have defined. Here is a simplified MWE of what I am trying to do: The print prints None... why? Notice that I am using eager-execution (TF version 2.0.0).",https://stackoverflow.com/questions/58702695,2680707.0,1
230,56939854,nyoka AttributeError: The layer has never been called and thus has no defined input shape,"I'm trying to output a trained Tensorflow 2.0 model to PMML using the nyoka package. When I do so, it errors out. The problem seems to be different from that in this answer, even though the error is the same, because my model does not have a complicated creation function and does, in fact, train appropriately and transform appropriately. Instead of a PMML file, I'm getting",https://stackoverflow.com/questions/56939854,11477392.0,1
231,42995019,TensorFlow example save mandelbrot image,"Learning how to use tensorflow, first tutorial code on mandelbrot set below returns this on shell It doesn't display the image and I'd prefer if it saved the image. How can I save the result as an image?",https://stackoverflow.com/questions/42995019,7399312.0,1
232,45273461,how to copy variable to another graph in tensorflow,"I hope to copy tensorflow variable from an old graph to a new graph, then delete the old graph and make the new graph as default. Below is my code, but it raises an AttributeError: 'Graph' object has no attribute 'variable1'. I am new to tensorflow. Can any one give me a specific example?",https://stackoverflow.com/questions/45273461,4895705.0,1
233,45150128,Restore AND share trained variables: Key not found,"I'm borrowing the example from the sharing variables tutorial: Say I trained these variables and save all four variables: weights and biases from conv1 and conv2 layers by passing var_list to tf.train.Saver. Now I want to restore and use them twice: But the variables' names now have image_filters as prefix, i.e image_filters/conv1/weights, so the saver can't restore them: Key image_filters/conv1/weights not found in checkpoint How do I restore the all the trained variables and reuse them multiple times?",https://stackoverflow.com/questions/45150128,3813674.0,1
234,65449280,Tensorflow giving Unknow Dtype Policy,I Am trying to train a model in Colab and then transferring it to Kaggle. The Model seems to Work fine in Colab as a .h5 model. The problem seems to be with Efficient net B4 and after in Kaggle. There is No Documentation about This. I am training this model on a TPU and doing the inference on a GPU but even if i train the model on GPU this problem is There. My error Log My model Training Code: Inference Code,https://stackoverflow.com/questions/65449280,14750340.0,1
235,47058158,restoring two Tensorflow models,"I have trained two separate Tensorflow models and would like to use them both in one Jupyter notebook. I am following the following SO post. However, I would like to avoid using with statement as it obscures my understanding of what is happening. Here is my code and error messages: Here is error message: How can I fix it? I already re-read multiple times google docs on interaction between graph and session, but I am still unclear what is missing. Inserging as_default() as some places produced different errors (too many to reproduce here)",https://stackoverflow.com/questions/47058158,1700890.0,1
236,57202668,Keras BatchNormalization only works for constant batch dim when axis=0?,The following code shows one way that works and the other that fails. The BatchNorm on axis=0 should not depend on the batchsize or if it does it should be explicitly stated as such in the docs. EDIT: The axis in the args is not the axis you think it is.,https://stackoverflow.com/questions/57202668,287238.0,1
237,55298562,TensorBoard error - [WinError 2] The system cannot find the file specified,I am trying to run TensorBoard with the following code This displays Launching tensorboard and then run into a [WinError 2] The system cannot find the file specified error. What am I doing wrong?,https://stackoverflow.com/questions/55298562,6547985.0,1
238,48466584,How to determine an appropriate `scale` in tf.contrib.layers.l2_regularizer?,"I saw a wide range of the scale values set for tf.contrib.layers.l2_regularizer in different applications. Is there a general rule to determine the value of scale? For example, (1) Do we need to consider the number of elements in weights and normalize it using scale? (2) If the mean square error (MSE) is part of the loss, what is the appropriate ratio between MSE and the l2 loss?",https://stackoverflow.com/questions/48466584,8179854.0,1
239,49538940,"Keras: input_shape=train_data.shape produces ""list index out of range""","I want to use Keras to build a CNN-LSTM network. However, I have trouble finding the right shape for the first layer's input_shape parameter. My train_data is a ndarray of the shape (1433, 32, 32); 1433 pictures of size 32x32. As found in this example, I tried using input_shape=train_data.shape[1:], which results in the same error as input_shape=train_data.shape: The relevant code is: All the results I found for this error were produced under different dircumstances; not through input_shape. So how do I have to shape my Input? Do I have to look for the error somewhere completely different? Update: Complete error:",https://stackoverflow.com/questions/49538940,9545531.0,1
240,50975255,Tried to convert 'x' to a tensor and failed. Error: None values not supported,"I'm trying to attack a simple feedforward neural network with attakcs implemented in cleverhans.attacks. The network is a very basic network implemented in tensorflow implementing the abstract class cleverhans.model.Model: import tensorflow as tf import numpy as np from cleverhans.model import Model class TFModel(Model): # A basic 2 layer NN. def __init__(self): self.x = tf.placeholder(tf.float32, shape=(None, 3), name='x') self.y = tf.placeholder(tf.float32, shape=(None, 2), name='y') self.w1 = tf.Variable(initial_value=[[1., 2.], [1., 2.], [1., 2.]], name='w1') self.b1 = tf.Variable(initial_value=[1., 2.], name='b1') self.dense1 = tf.add(tf.matmul(self.x, self.w1), self.b1, name='dense1') self.out1 = tf.nn.softmax(self.dense1, name='out1') self.w2 = tf.Variable(initial_value=[[1., 2.], [1., 2.]], name='w2') self.b2 = tf.Variable(initial_value=[1., 2.], name='b2') self.dense2 = tf.add(tf.matmul(self.out1, self.w2), self.b2, name='dense2') # should be called 'logits' self.out2 = tf.nn.softmax(self.dense2, name='out2') self.outputs = {'layer1': self.out1, 'logits': self.dense2, 'softmax': self.out2} def get_layer_names(self): """""" :return: a list of names for the layers that can be exposed by this model abstraction. """""" return list(self.outputs.keys()) def fprop(self, x): """""" Exposes all the layers of the model returned by get_layer_names. :param x: A symbolic representation (Tensor) of the network input :return: A dictionary mapping layer names to the symbolic representation of their output. """""" return self.outputs Attack implemented with FastGradientMethod works well as shown in the following: model = TFModel() sess = tf.Session() from cleverhans.attacks import FastGradientMethod fgsm_params = {'eps': 0.3, 'clip_min': 0., 'clip_max': 1.} fgsm = FastGradientMethod(model, sess=sess) adv_x = fgsm.generate(model.x, **fgsm_params) But attack with BasicIterativeMethod does not work: from cleverhans.attacks import BasicIterativeMethod bim_params = {'eps_iter': 0.01, 'nb_iter': 100, 'clip_min': 0., 'clip_max': 1.} bim = BasicIterativeMethod(model, sess=sess) adv_x = bim.generate(model.x, **bim_params) Here is the full error message: rror Traceback (most recent call last)~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords) 509 as_ref=input_arg.is_ref, --&gt; 510 preferred_dtype=default_dtype) 511 except TypeError as err: ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) 1103 if ret is None: -&gt; 1104 ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) 1105 ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref) 234 _ = as_ref --&gt; 235 return constant(v, dtype=dtype, name=name) 236 ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\constant_op.py in constant(value, dtype, shape, name, verify_shape) 213 tensor_util.make_tensor_proto( --&gt; 214 value, dtype=dtype, shape=shape, verify_shape=verify_shape)) 215 dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype) ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape) 419 if values is None: --&gt; 420 raise ValueError(""None values not supported."") 421 # if dtype is provided, forces numpy array to be the type ValueError: None values not supported. During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last)~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords) 523 observed = ops.internal_convert_to_tensor( --&gt; 524 values, as_ref=input_arg.is_ref).dtype.name 525 except ValueError as err: ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx) 1103 if ret is None: -&gt; 1104 ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) 1105 ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref) 234 _ = as_ref --&gt; 235 return constant(v, dtype=dtype, name=name) 236 ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\constant_op.py in constant(value, dtype, shape, name, verify_shape) 213 tensor_util.make_tensor_proto( --&gt; 214 value, dtype=dtype, shape=shape, verify_shape=verify_shape)) 215 dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype) ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape) 419 if values is None: --&gt; 420 raise ValueError(""None values not supported."") 421 # if dtype is provided, forces numpy array to be the type ValueError: None values not supported. During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last)&lt;ipython-input-7-8ab4a61acce1&gt; in &lt;module&gt;() 8 print('hello') 9 ---&gt; 10 adv_x = bim.generate(model.x, **bim_params) c:\users\mjafarnia\src\cleverhans\cleverhans\attacks.py in generate(self, x, **kwargs) 400 sess=self.sess) 401 # Compute this step's perturbation --&gt; 402 adv_x = FGM.generate(x + eta, **fgm_params) 403 404 # Clipping perturbation according to clip_min and clip_max c:\users\mjafarnia\src\cleverhans\cleverhans\attacks.py in generate(self, x, **kwargs) 284 ord=self.ord, clip_min=self.clip_min, 285 clip_max=self.clip_max, --&gt; 286 targeted=(self.y_target is not None)) 287 288 def parse_params(self, eps=0.3, ord=np.inf, y=None, y_target=None, c:\users\mjafarnia\src\cleverhans\cleverhans\attacks_tf.py in fgm(x, preds, y, eps, ord, clip_min, clip_max, targeted) 65 if ord == np.inf: 66 # Take sign of gradient ---&gt; 67 normalized_grad = tf.sign(grad) 68 # The following line should not change the numerical results. 69 # It applies only because `normalized_grad` is the output of ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\ops\math_ops.py in sign(x, name) 451 indices=x.indices, values=x_sign, dense_shape=x.dense_shape) 452 else: --&gt; 453 return gen_math_ops.sign(x, name=name) 454 455 ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\ops\gen_math_ops.py in sign(x, name) 6874 if _ctx is None or not _ctx._eager_context.is_eager: 6875 _, _, _op = _op_def_lib._apply_op_helper( -&gt; 6876 ""Sign"", x=x, name=name) 6877 _result = _op.outputs[:] 6878 _inputs_flat = _op.inputs ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords) 526 raise ValueError( 527 ""Tried to convert '%s' to a tensor and failed. Error: %s"" % --&gt; 528 (input_name, err)) 529 prefix = (""Input '%s' of '%s' Op has type %s that does not match"" % 530 (input_name, op_type_name, observed)) ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.",https://stackoverflow.com/questions/50975255,4678080.0,1
241,76328191,Tensorflow in Pyinstaller on MacOS. Saving model fails with TensorShapeProto error,"I have a simple test script that just saves and loads a tensorflow model. I passes when run from python on my system. But fails to load the model when I run it from a pyinstaller package, it fails with TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.TensorShapeProto got tensorflow.TensorShapeProto. The full script is When run from pyinstaller, it first gets the error message Then outputs: Oddly this does not seem to happen on Windows - only Mac. If I do the saving outside of Pyinstaller and only do the loading from pyinstaller, I get an error on load AttributeError: as_proto, which I'm guessing has the same route-cause. What is going on, and how can I save/load tensorflow models in a pyinstaller app?",https://stackoverflow.com/questions/76328191,851699.0,1
242,56154391,Is it possible to run python tensorflow code on TPU without using the Estimator API?,I have spent weeks now trying to write a Python level Tensorflow code that could communicate with TPUs directly. How would it be possible to implement the system that could run on a TPU without the Estimator API? Resources I tried: Ways I tried: Problems I have with the Estimator API implementation:,https://stackoverflow.com/questions/56154391,3815403.0,1
243,62603447,"Tensorflow Keras - High accuracy during training, low accuracy during prediction","I have a very basic multiclass CNN model for classifying vehicles into 4 classes [pickup, sedan, suv, van] that I have written using Tensorflow 2.0 tf.keras: I use the following configuration for training: I have an unbalanced dataset, which has the following distribution: For this reason I have used class weights to mitigate this imbalance: This seems like a small dataset but I am using this for fine tuning since I first train the model on a larger dataset of 16k images of these classes, though with images of vehicles taken from different angles as compared to my fine tune dataset. Now the questions that I'm having stem from the following observations: At the end of the final epoch, the results returned by model.fit gave: The results returned by model.evaluate on my hold-out test set after training gave similar accuracy and loss values as the corresponding validation values in the last epoch and the precision values for each class were also nearly identical to the corresponding validation precisions. The lower, but still high enough, validation accuracy leads me to believe there is no overfitting problem as the model can generalize. My first question is how can the validation loss be so much lower than the training loss? Furthermore, when I created a confusion matrix using: The results I got back were: This shows an accuracy of only 35%!! My second question is therefore this: how can the accuracy given by model.predict be so small when during training and evaluation the values seemed to indicate that my model was quite precise with its predictions? Am I using the predict method wrong or is my theoretical understanding of what's expected to happen completely off? I am at a bit of a loss here and would greatly appreciate any feedback. Thanks for reading this.",https://stackoverflow.com/questions/62603447,11204734.0,1
244,41212599,"TensorFlow: Is there a way to initialize variables in variable scope if they're not initialized, and reuse them if they are?","I'm trying to write ""clean"" code. What I want to do is I tried doing this with a try-except, like so: But that doesn't seem to work. I've tried looking for examples online, but haven't found anything close to the case I'm trying to solve, which is to cleanly use a large network where almost every variable is under a different scope.",https://stackoverflow.com/questions/41212599,7147097.0,1
245,49698567,How to Save TensorFlow model using estimator.export_savemodel(),"How can i Save the TensorFlow model using estimator.export_savedmode() ? Especially, what should i put inside the serving_input_receiver_fn()? I have created a Custom Estimator based on VGGNet Architecture, i am using my own images and doing some transformation (you can see them in _parse_function()) on the images. I have read the documentation here, but i am exactly not sure what to write for my code (please see below). Ultimately i want to save the model and use TensorFlow Serving.",https://stackoverflow.com/questions/49698567,8549932.0,1
246,39492157,Tensorflow batching arguments,"Batching looks cleaner than feed_dicts, so I'm trying to understand batching in Tensorflow. Does the below block of code create 32 identical images in the batch that it then feeds to the queue? A bit of context: I currently have a single file containing around 50K rows. I'm using tf.train.string_input_producer and tf.decode_csv to read rows from the csv, but am confused as to what to supply to tf.train.shuffle_batch as an argument, the individual rows or a tensor containing all the rows read from the file.",https://stackoverflow.com/questions/39492157,4976362.0,1
247,51845480,Error when using tf.get_variable as alternativ for tf.Variable in Tensorflow,"Hi I'm new to neural networks and I'm currently working on Tensoflow. First I did the MNIST tutorial which worked quite well. Now I wanted to deepen the whole by means of an own network for Cifar10 in Google Colab. For this purpose I wrote the following code: For the definition of the tensorflow variables I first used variant1 (tf.variable). This caused an overflow of the graphics memory after repeated execution. Then I used variant2 (tf.get_variable). If I have understood the documentation correctly, this should use already existing variables if they exist. But as soon as I do this I get the following error message: I've been looking the hole day, but I haven't found an explanation for this. Now I hope that there is someone here who can explain to me why this is not possible, or where I can find further information. The error message is getting me nowhere. I don't want a solution because I want to and have to understand this, because I want to write my bachelor thesis in the field of CNN. Why can I use tf.variable but not tf.get_variable which should do the same? Thanks for the help, best regards, Pascal :)",https://stackoverflow.com/questions/51845480,10225343.0,1
248,68847330,Why tensor shape is difference when i use tf.print?,"I made simple dataset like below. And I slice it by using from_tensor_slices: (I don't know exact role of tensor slice function...) when I print dataset using print function, it shows like below: and when I print it using for loop it show like below: Here is question: In my idea, tensor shape should be (4,2) and (4,1) because row of matrix is 4. Why when I use print, it shows (None,2) and (None,1)? And how to print value of tensor without for loop?",https://stackoverflow.com/questions/68847330,16366779.0,1
249,64023070,tensorflow control dependency,"I'm trying to run a very simple example of code that I found online: This is supposed to give me the mean iou of this dummy example. However, if I run this multiple times, I get different results. I've noticed that running up_opt manually fixes it: However, I wonder why the control_dependencies doesn't work. Isn't this supposed to run the operators automatically?",https://stackoverflow.com/questions/64023070,9074671.0,1
250,34283090,"When using tensorboard, how to summarize a loss that is computed over several minibatches?","I would like to use Tensorboard to visualize the evolution of the loss over a validation sample. But the validation set is too large to compute in one minibatch. Therefore, to compute my validation loss, I have to call session.run several times over several minibatches covering the validation set. Then I sum the loss (in python) of each minibatches to obtain the full validation loss. My problem is that tf.scalar_summary seems to have to be attached to a tensorflow node. But I would need to somehow ""attach"" it to the sum of the values of a node over several run of session.run. Is there a way to do that? Maybe by directly summarizing the python float that contains the sum of the minibatch losses? But I have not seen in the docs a way to ""summarize"" for tensorboard a python value that is outside of a computation. The example in the ""How-To"" section of the doc is only concerned with losses that can be computed in a single call to session.run.",https://stackoverflow.com/questions/34283090,1841986.0,1
251,46917459,Save same image pair over epochs with tf.summary.image for semantic segmentation,"When training a deep network for semantic segmentation we can get a qualitative understanding of network performance by looking at the triad of image/ground truth/prediction. During training, I would like to be able to view this set in tensorboard but keep the same triad throughout training. If one naively uses tf.summary.image for each of input/ground truth/prediction tensorflow changes the saved image/ground truth/prediction set with each epoch. I.e. right now I have which does save 3 images from each epoch, but because they change with each epoch its hard to keep track of progress. This would be useful just to get a crude qualitative understanding of what the network is learning in the process of training.",https://stackoverflow.com/questions/46917459,2426955.0,1
252,39337691,Tensorflow slim train and validate inception model,"I'm trying to fine tune inception models, and validate it with test data. But all the examples given at tensorflow slime web page only either fine-tuning or testing, there is not any example that doing both at same graph and session. Basically I want to this. this code fails As it can be seen, I don't have loop separately to call my test models, I want to test my model on my test data at each 10th batch.",https://stackoverflow.com/questions/39337691,797880.0,1
253,45347437,Does TensorFlow recompute nodes even if there are exactly the same computations already defined elsewhere in the graph?,Consider for example this example: Are the gradients computed twice or just once? Or this example: Is the addition y + z computed twice or just once?,https://stackoverflow.com/questions/45347437,852592.0,1
254,63069555,Input 0 of layer sequential is incompatible with the layer,"I created a model and then loaded it in another script and try to perform a prediction from it however I can not understand why the shape being passed to the function is incorrect. This is how the model is created: And this is how I'm trying to make a prediction: When printing the shape of the test image the output is: (400, 400, 3) I also tried using the numpy operation reshape when passing the test image to predict. However the error is always:",https://stackoverflow.com/questions/63069555,10802706.0,1
255,46450208,Tensoflow: Calling prediction from a function returns 'RuntimeError: Attempted to use a closed Session',"I have implemented a simple MLP in tensorflow. The structure is a class NeuralNet: It has 3 different function: When running the predict method, It returns a RuntimeError: ('Attempted to use a closed Session.') My question is: Why does the test method run smoothly, while calling the session the same way in the predict method fails? Would I have to create a tf object and evaluate it? If yes, which object should it be?",https://stackoverflow.com/questions/46450208,4449593.0,1
256,63574871,How to get the Keras history object when you abort training?,"When I train with tensorflow 2.0 / Keras APIs, I usually do something like this But sometimes things in life don't work out how I planned and I need to abort with ctrl-c or pressing stop in Jupyter notebook. How can I still get the history object when I abort training early? I can't find any detailed documentation for how to get history.",https://stackoverflow.com/questions/63574871,8202708.0,1
257,52147085,Why tf manipulations are working only in the arbitrary function?,"When I build a series of tensors, the manipulation functions of tensorflow, such as tf.transpose(~) or tf.split(~) returns an error. Code Error However, if I build an arbitrary function such as: it works well. What makes this difference?",https://stackoverflow.com/questions/52147085,10309582.0,1
258,65705842,"""Using a tf.Tensor as a Python bool is not allowed"" when using tf.keras.metrics.Accuracy",I have tensorflow 1.14 and I want to compute some classification metrics. I am using tf.keras.metrics and I am using it in the follwoing manner: This gives me the error: I tried to use instead tf.contrib.metrics but it only has precision_at_recall and recall_at_precision instead of stand alone precision and recall. EDIT 1 I have tried the following but it did not work: It gave me the following error:,https://stackoverflow.com/questions/65705842,11212687.0,1
259,61588458,what is the best practices to train model on BIG dataset,"I need to train a model on a dataset that required more memory than my GPU has. what is the best practice for feeding the dataset to model? here is my steps: but at step 2 I prepared data for the first batch and missed the rest batches because the model.fit is out of the loop scope (which, as I understand, works for one, first batch only). On the other hand, I can't remove take(1) and move the model.fit method under the cycle. Because yes, in this case, I will handle all batches, but at the same time model.fill will be called at the end on each iteration and in this case, it also will not work properly so, how I should change my code to be able to work appropriately with a big dataset using model.fit? could you point article, any documents, or just advise how to deal with it? thanks Update In my post below (approach 1) I describe one approach on how to solve the problem - are there any other better approaches or it is only one way how to solve this?",https://stackoverflow.com/questions/61588458,13175435.0,1
260,70709785,Creating input tensors with the right dimensions from data,"I have 4 features, 2 continous ones taking the form of And 2 categoric in the form of My labels take the same form as continous features, from 0 to 8 for multiclassification. My goal is to predict the label class based on the 4 features. I extract my data from a json file into a Pandas dataframe that looks like this: From my understanding of the ragged tensor documentation I can directly feed all of these features into my model like so: After that I normalize f1 and f2, and use a StringLookup, Embedding and Flatten layer for f3 and f4. Then I concatenate and feed them into a couple of Dense layers and then into a final dense layer using a softmax. My model builds sucesfully. However when I pass my dataframe to my training function like so: I get the following error Next I tried manually turning my dataframe into NumPy arrays with the right type: Which produces the same error: It seems to me like instead of Numpy Arrays I should convert the data to tensors and feed that into the fit method. If I interpret the tf.Data documentation correctly this should be possible? In trying to do so I got stuck at getting the dimensions to be right, e.g : What am I doing wrong?",https://stackoverflow.com/questions/70709785,4937747.0,1
261,51163280,Tensorflow Optimizer On Multi-valued Tensor,"By mistake I forgot to reduce the mean of the output from the cross entropy before I fed it as the loss, but the training ran anyways and produced reasonable results. Now I'm wondering if what I did: Is the same as: I was under the impression that the optimization of the cost function required a single value tensor, but I'm confused why the training ran despite passing a tensor with more than one value.",https://stackoverflow.com/questions/51163280,3889510.0,1
262,74867671,When is the watch() function required in Tensorflow to enable tracking of gradients?,"I'm puzzled by the fact that I've seen blocks of code that require tf.GradientTape().watch() to work and blocks that seem to work without it. For example, this block of code requires the watch() function: But, this block does not: What is the difference between these two cases?",https://stackoverflow.com/questions/74867671,1245262.0,1
263,48181203,Applying tf.gather to all rows of two tensors,"I want to apply tf.gather() to all the rows of a given parameters tensor and an indices tensor. I can apply tf.gather() on two 1D tensors to extract a 1D tensor: Now what if I have two 2D tensors, and want to apply tf.gather() on them row-wise? I want something like this: The closest I've come so far is using tf.gather() with axis=1, which yields a 3D tensor, and then index the result with gather_nd(): (I'd call other functions instead of giving literal values, but that's beside the point and not an issue) This is very clumsy. Is there a more efficient way to do this? By the way, the indices I use are always values increasing one by one; each row just has a different start and end value. That might make the problem easier.",https://stackoverflow.com/questions/48181203,348412.0,1
264,48272035,Tensorflow how to generate unbalanced combined data sets,"I have a question about the new dataset API (tensorflow 1.4). I have two data sets and I need to create a combined unbalanced data set, i.e. each batch should contain a certain number of elements from the first and a certain number of elements from the second data set. For example, assuming a batch size of 4 I want a batch in the combined data set to look like [1,1,1,2]. I know how to generate a balanced data set using zip and flat_map but I'm at a loss with this one. Thanks in advance!",https://stackoverflow.com/questions/48272035,9221634.0,1
265,50164572,BatchNormalization in Keras,"How do I update moving mean and moving variance in keras BatchNormalization? I found this in tensorflow documentation, but I don't know where to put train_op or how to work it with keras models: No posts I found say what to do with train_op and whether you can use it in model.compile.",https://stackoverflow.com/questions/50164572,8748308.0,1
266,35114024,Loss functions in tensorflow (with an if - else),"I am trying a different loss functions in tensorflow. The loss function I want is a kind of an epsilon insensitive function (this is componentwise): I tried this solution: I also used I do not find any error in the implementation. However, it does not converge, while the loss = tf.square(yData-yModel) converges and loss=tf.maximum(tf.square(yData-yModel)-epsilonTensor,tf.zeros_like(yData)) also converges. So, I also tried something simpler loss=tf.abs(yData-yModel) and it also does not converge. Am I making some mistake, or having problems with the non-differentiability of the abs at zero or something else? What is happenning with the abs function?",https://stackoverflow.com/questions/35114024,2065691.0,1
267,55619070,GraphKeys.TRAINABLE_VARIABLES vs tf.trainable_variables(),Is GraphKeys.TRAINABLE_VARIABLES is the same as tf.trainable_variables() ? Is GraphKeys.TRAINABLE_VARIABLES actually tf.GraphKeys.TRAINABLE_VARIABLES? Looks like networks successfully trains with: but not with According to documentation: Also as I can see in batch normalization example code var_list is omited:,https://stackoverflow.com/questions/55619070,1179925.0,1
268,62105896,How to use tf.data.Dataset.interleave() in TF 2 with a custom function?,I'm using TF 2.2 and I'm trying to use tf.data to create a pipeline. The following works fine: I would like to use the load_image() with the Dataset.interleave(). Then I tried: But I'm getting the following error: How can I adapt my code to have the Dataset.interleave() working with the load_image() to read the images in parallel ?,https://stackoverflow.com/questions/62105896,2135819.0,1
269,59305940,@tf.function is slowing down training step,"I am using the following tf.function decorated training step: It's a little quirky, but basically, my network has multiple outputs, which means that there are cases where returning a gradient of None for certain weights is correct, so I am replacing those gradients with zero, and I'm calculating the loss at each of these outputs separately and then propagating each of them at each step. When I run this as written, it takes an extremely long time (10min+) to run a single training step, and I see the following message in the logs: When I remove the @tf.function decorator, it runs in about 10% of the time, and I do not see this log warning. Is this warning a red herring or does it legitimately point to an issue created by adding @tf.function? Additional Details:",https://stackoverflow.com/questions/59305940,5370186.0,1
270,72484718,"Tensorflow tf.dataset won't iterate with multiple inputs of different sizes ""Shapes of all inputs must match""","I am trying to make a tensorflow model with two different inputs, one will have shape [9,10], the other will just have shape [8]. I am furthermore trying to use tf.dataset to iterate over my inputs. However, whenever I try to do so it fails with the following error: But surely it is possible to have differently sized inputs into different branches! This is exactly the case in the example in tensorflow's functional API guide, however they do not use tf.dataset so I can't simply follow their example. To give a little more specifics into the problem I am trying to solve and why I am using the tf.dataset api: I am doing a time-series problem over multiple sites where my inputs are of two types: those that vary with time, and those that do not but do vary by site. For the time being, I'm just trying to estimate the next time step. First, I get my dynamic covariates and targets in a sliding window using the timeseries_dataset_from_array util. This works perfectly and I can train models using this dataset as is. However, I want to also use the static covariates from the specific site that the time series data is coming from. The site id is included in the window input data in its own column, though it gets removed before training. Thus, what I am trying to do is grab the static covariates for the site and attach it as a separate input to my dataset. The code for the attach_static_covariates method is: I've confirmed that my code can run and train on multiple inputs provided by the above method provided they are the same size (e.g. if I return (x, x) I can run my model on two copies of the dynamic covariates inputted into two different branches of my model). The problem is not due to a mismatch or a bad model definition because I get the same error from the following code: I've looked everywhere on google and the tensorflow git and I can't find anyone else with this problem, and yet it surely MUST be possible to have differently shaped inputs using tf.dataset! I can't imagine that such an incredibly common use case would be completely unsupported. However, I can't find any examples online where someone has multiple inputs of different shapes and uses tf.dataset api. Any help or links to such examples would be greatly appreciated. Colab notebook to illustrate issue: https://colab.research.google.com/drive/1EnaJoUULl-fyAwlcG_5tcWfsRFVCOMtv#scrollTo=PHvsIOx6-Uux",https://stackoverflow.com/questions/72484718,15913381.0,1
271,46066124,Data not being written in csv,"Im using the following code to populate csv print(x) prints the following however the data is not being written in csv. why so? UPDATE: I tried using dictwriter as follows, but still im getting the following error,",https://stackoverflow.com/questions/46066124,,1
272,43736089,How to use tf.contrib.seq2seq.BahdanauAttention,"I am trying to produce a simple code for a seq2seq model with attention in tf 1.1. I am not sure what is the parameter ""depth of query mechanism "". I am getting an error on creation of Attention Mechanisms saying that: Here is my code. Am I on a right track? I could not find any detailed documentation.",https://stackoverflow.com/questions/43736089,5579493.0,1
273,58369040,When and why do we use tf.reduce_mean?,"In setting up the model I sometimes see the code: or The definition of tf.reduce_mean states that it ""calculates the mean of tensor elements along various dimensions of the tensor."" I am confused about what it does in simpler language? When do we need to use it, maybe with reference to # Scenario 1 &amp; 2 ? Thank you",https://stackoverflow.com/questions/58369040,11901732.0,1
274,60211521,TF2 padded_batch on supervised dataset,"I am following this tutorial. The tutorial first loads a supervised dataset (using tfds.load with as_supervised=True): Then the tutorial suggests to shuffle and pad the dataset like this: ... but unfortunately the padded_batch method needs an extra argument that the tutorial seems to have forgotten: Although the errors stack says that padded_shapes is the missing argument, from the tutorial I think it's fair to deduce that the missing argument is in fact batch_size (that should precede padded_shapes). I thought this might be easily fixed like this: ... but my solution is apparently wrong: Substituting None with () gives me ValueError: Padded shape [()] must be a 1-D tensor of tf.int64 values, but its shape was (1, 0). Substituting None with 1 gives me ValueError: The padded shape (1,) is not compatible with the corresponding input component shape (). What value should I give to the padded_shapes argument? Or, more generally, what am I doing wrong here? Thank you very much for your help.",https://stackoverflow.com/questions/60211521,3272066.0,1
275,62992050,Is it possible to parse dictionary of list to TFRecord file?,"I want to create a TFRecord file which looks something like this: where dataset dictionary has regions and image_raw, and regions is a list of dictionary of bounding boxes data - width, height, x, y. I tired doing this: Here, file[0][i] represents the ith bounding box data of 0th image. Parsing this into throws a error saying Is there a way to correct this error or to do this in some other way?",https://stackoverflow.com/questions/62992050,11698087.0,1
276,45140806,How to get started with Tensorflow,"I am pretty new to Tensorflow, and I am currently learning it through given website https://www.tensorflow.org/get_started/get_started It is said in the manual that: this is the code: this may be simple questions, but I am a beginner to Tensorflow and having a hard time understanding it.",https://stackoverflow.com/questions/45140806,8318283.0,1
277,44685228,How to get loss function history using tf.contrib.opt.ScipyOptimizerInterface,"I need to get the loss history over time to plot it in graph. Here is my skeleton of code: With append_loss_history definition: When I see the verbose output of ScipyOptimizerInterface, the loss is actually decrease over time. But when I print loss_history, the losses are nearly the same over time. Refer to the doc: ""Variables subject to optimization are updated in-place AT THE END OF OPTIMIZATION"" https://www.tensorflow.org/api_docs/python/tf/contrib/opt/ScipyOptimizerInterface. Is that the reason for the being unchanged of the loss?",https://stackoverflow.com/questions/44685228,8196247.0,1
278,65988276,fail to train a model using tf.function,"I tried to use tf.function to decorate the gradient update function as below. I can train a model successfully the first time I call the code below. But it fail when I train to train another model using the same code, with error message ValueError: tf.function-decorated function tried to create variables on non-first call.",https://stackoverflow.com/questions/65988276,10545499.0,1
279,73691788,Tensorflow dataset not saved in multiple shards,"I want to use the tensorflow dataset saving and loading functions but I am not sure to understand the sharding method. The documentation indicates : But when I save a dataset through the save function, it seems that only one huge shard is generated. generated dataset screenshot Am I missing something ? I use Tensorflow 2.10.0 and Python 3.9.7",https://stackoverflow.com/questions/73691788,5130199.0,1
280,51422833,Why does tf.Print() not work?,"I have this code snippet: I have two tf.Print statements in the function that I pass to the tf.scan, but when I run the cumulative sum, I do not get any print statements. Am I doing something wrong?",https://stackoverflow.com/questions/51422833,2812237.0,1
281,62799237,TensorFlow: How to feed a dataset that doesn't fit into memory?,"DataSet documentation claims that it Represents a potentially large set of elements. as well as Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.. I spent several hours in the official docs trying to find out how to feed a large dataset in a streaming fashion. No success. All examples use either from_tensor_slices or generator, both methods are not recommended by TensorFlow themselves because of 2GB limit for the tf.GraphDef protocol buffer and it has limited portability and scalability. It must run in the same python process that created the generator, and is still subject to the Python GIL.. The only documented way I found to make it work in a streaming fashion is to use TFRecord. It allows to stream file by file. The only huge problem: my feature input shape is (200000, 2) (all float32). To flatten and convert it to FloatList is not an option because I feed it to Conv1D with 2 parallel sequences. It feels like either I overlooked something, or it's just poorly documented, or tf.Dataset doesn't do what it claims to do. Is there a way to make DataSet work in a streaming fashion for a large set of elements?",https://stackoverflow.com/questions/62799237,1742204.0,1
282,65025263,Accessing gradient of multiple variables when applying resource [Tensorflow],"I am currently trying to implement custom optimization for a custom tensorflow layer. Without going in to much detail I have added a small code sample which illustrates how my current code works. The important part is that calculate_gradients(variables, gradients, momentum) is a function that requires the variable values and gradients of all the variables in the layer. Furthermore this calculation contains intermediate results which have to be stored during optimization. This explains the illustrative momentum variable. This behaviour to me makes using @custom_gradient not possible since this does not allow me to propagate this intermediate results to the optimizer which would then have to return it to the custom gradient function for use in the calculation of the next set of gradients. Unless someone knows how this would work (question one) i have not found a way around this. Trying to implement this in the tensorflow optimizer particularly by replacing _resource_apply_dense as shown in the documentation [1] i am running into some trouble with the layer-wise behaviour. Particularly since _resource_apply_dense takes a variable and a gradient. The second code snippet illustrates what i am trying to to, but have currently not found a way to do the get_other_variables_and_gradients(var) behaviour. Furthermore this solution would calculate the gradients three times for each layer which is very suboptimal. In short, my second question is: Does anyone have an idea how to implement this behaviour and maybe even better do it without redundant calculations or even a whole new better way. Currently the optimization works when i do everything in a training loop as shown in code snippet one. So this is merely a case of integration with the tensorflow optimizer paradigm and performance since doing everything very 'pythony' with lists in a large for loop is slow. [1] https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer",https://stackoverflow.com/questions/65025263,14691925.0,1
283,43324829,"Tensorflow - Restoring model fail with message "" Attempting to use uninitialized value""","I am really new to the TensorFlow so bear with me plz even if this question is a total nonsense... I have a code which 1) defines the network like 2) then restoring the model with this code, which restores the model, works perfectly fine when run in the separate file. however, when run on this, it aborts with the following error message after I saw this message for the first time, I uncommented the line under #NOTE, which is it did not show such error, but the pretrained variables were not restored and was initialized by how I defined it while defining the network. So I have two questions! First, I don't get what the difference is between running the code in a separate file and running it in one file to get such HORRIFYING error message Second, I don't get why initializing the variables then restoring the model with the code written above does not restore the previously trained variables. Thnx in advance",https://stackoverflow.com/questions/43324829,5888016.0,1
284,40307103,Get Predicted result from tensorflow,I am doing my first tensor flow example with following code. It give me accuracy on test data. What i want is to give an input sentence to my train model and it returns me predicted label. i tried following form this example it gives me following error.,https://stackoverflow.com/questions/40307103,1656918.0,1
285,68488385,Why is Tensorflow 2 custom Bijector / flow yielding the wrong number of samples?,"I am building a Tensorflow 2 Probability Normalizing Flow that contains a ""custom Bijector"". The definition of that Bijector is: When I use this in a TransformedDistribution thus: I see the following weird results: What's weird is that the first ""sample(3)"" correctly returns 3 bivariate samples, but the second ""sample(3)"" applied to the TransformedDistribution yields only two samples. Where's my missing sample?",https://stackoverflow.com/questions/68488385,2417922.0,1
286,43232566,Error - Cannot feed value of shape X for Tensor,"I've run all the examples on the Tensorflow page, using the MNIST database. Now I'm trying to run my own example and I really just don't get it. Say I have this csv table: It has like 5000 rows. and the last column is the label for each row, this one is composed of multiple features. Now for my first concrete example. I want to train a NN on this data, for that here what I've done: Here is there error that I get : I've change the value of the index but it didn't solve it so I guess I'm misunderstanding something. will be grateful for any explanation.",https://stackoverflow.com/questions/43232566,1563123.0,1
287,54180658,How to use the 3d convolution in Tensorflow?,"I am not sure, how to use the conv3d in tf: https://www.tensorflow.org/api_docs/python/tf/layers/conv3d I want to have a kernel size of [depth, height, widht]=[3,3,3], that convoles over my input tensor that as a shape [1,21,1,6,7] and ought to have an output shape of [1,19,4,5] = [batch,channels,height,width]. but I get this error: I am not sure about the parameters depth and filters and I guess that I mix something up.",https://stackoverflow.com/questions/54180658,4355878.0,1
288,44378654,Explanation for tf.contrib.framework.get_global_step(),"I was trying out programming with tensorflow and I came across this function: Could anyone explain to me what exactly is happening here? I found this explanation in tensorflow's documentation, but it wasn't very clear to me. where get_global_step returns the global tensor. Thank you very much!",https://stackoverflow.com/questions/44378654,5538474.0,1
289,70847148,"How do i interpret the weights, in this branched tf model?","I did not find a suitable question that answers this scenario, if it is already answered someplace else, please feel free to point me to the question. I have a tensorflow model (At the end of the question i have a minimal reproducible code, for anyone to test it out. ) with these specs I am not able to understand why the weight matrices of a convolution layer in the new branch still has the shape ((3, .. .. )). My Model: Shapes of each element (s,t,r) after the unstack: Shapes of the weights and biases only for the conv layers: Please feel free to ask any further questions, because i know i might not have been clear enough for everybody. P.S. I am aware of how channels_first and channels_last are to be used.",https://stackoverflow.com/questions/70847148,7317733.0,1
290,50998702,How is embedding matrix being trained in this code snippet?,"I'm following the code of a coursera assignment which implements a NER tagger using a bidirectional LSTM. But I'm not able to understand how the embedding matrix is being updated. In the following code, build_layers has a variable embedding_matrix_variable which acts an input the the LSTM. However it's not getting updated anywhere. Can you help me understand how embeddings are being trained?",https://stackoverflow.com/questions/50998702,236106.0,1
291,62654908,"""Layer is not connected, no input to return"" error while trying to get intermediate layer prediction using tensorflow custom callback",I'm trying to access predictions of intermediate layers of a model during training using custom callback. Following stripped down version of the actual code demonstrates the issue. The callback is written as suggested in this answer. Getting following error: What's causing this? How to resolve it?,https://stackoverflow.com/questions/62654908,2679778.0,1
292,50310511,Reassigning Variables in Tensorflow and scope,"I'm trying to understand the difference between why one of these implementations works, and one doesn't. I'm trying to represent some geometry in tensorflow. First, a helper file, d_math.py import numpy as np import tensorflow as tf dtype = tf.float64 Here is implementation 1: The above version updates theta, and then I get the evaluation of two rotation matrices, one for theta = 0, and one for theta = pi/4. I then tried to refactor my code a bit, adding a global session variable, created in a separate file, and hiding away as much about tensorflow as I could for now in the API: version 2: session.py can be seen here: This gives the R matrix with theta = 0 for both evaluations. Can someone please explain to me why implementation 2 isn't working?",https://stackoverflow.com/questions/50310511,650261.0,1
293,73257011,"After Loading TensorFlow dataset, My GPU memory is almost full","I am new to Tensorflow, if the question is too fundamental please forgive me. My desktop is using GPU Geforce 3060 which has a 12 Gb memory. But when I use the following code to load the dataset, even as small as 'mnist'. I was using the task manager to monitor the GPU memory storage, the picture shows the GPU memory is going to exhaust. And if I load a model like vgg16 and do some forward propagation, Vscode will crush and prompt me 'the memory is full'. And even if I only load 50% of the training data, nothing will change, the memory usage purges to almost full. But in the TensorFlow document dataset performance, In the 'Auto-shard your data across workers (TF)' session, if I set multiple input_pipeline, the situation won't change at all.",https://stackoverflow.com/questions/73257011,11847386.0,1
294,55146597,Import Keras directly or through TensorFlow? Should I uninstall either one?,"I have some working Python3 sources gotten from the internet where initial Keras imports are direct like this: In TensorFlow documentation instead I see the following indirect form: To me they seem to mean respectively, that Keras can be used without knowing that TensorFlow is behind, and, that Keras is provided (again?) as a part of TensorFlow. (I kind of expect that also Keras similarly provides references to TensorFlow in the former case) What is the difference? Does it depend on how Keras and TensorFlow are installed, or rather on the way they are used? Is it a potential source of confusion that I have to get rid of? In other words, should I fix my installation, and how? Or should I just accept that there are two, and manage their respective usages to live with them safely? Background: my installation is under Ubuntu Linux, with Python3.5.2, where pip3 list shows the following packages: BTW, I have checked that they are really different: and indeed it seems that I have two different Keras and that the former is higher versioned and richer. Related readings, useful but not enough to solve the ""does it need a fix?"" question: Thanks!",https://stackoverflow.com/questions/55146597,5341377.0,1
295,48514123,"Tensorflow: SavedModelBuilder, How to save model with best validation accuracy","I have gone through tensorflow documentation but couldn't find the way of saving model with best validation accuracy, using SavedModelBuilder class. I am using tflearn for model building and below is the work around i have tried but it is taking lot of time, where i am running fit method for each epoch separately and saving model Please suggest if there is a better approach.",https://stackoverflow.com/questions/48514123,2398191.0,1
296,50705859,python sum on array of tensors vs tf.add_n,So I've got some code if I change that last line to then the code produces the same output but runs much more slowly and soon causes an out-of-memory exception. Whats going on here? Can someone explain how pythons built in sum function and tf.add_n interact with an array of tensors respectively and why pythons sum would seemingly just be a better version?,https://stackoverflow.com/questions/50705859,2458126.0,1
297,58556857,Implementing an l2 loss into a tensorflow Sequential regression model,"I created a keras- tensorflow model, much influenced by this guide which looks like It is a regression model and instead of the loss = 'mse' I would like to use tf keras mse loss together with an L2 regularization term. The question is",https://stackoverflow.com/questions/58556857,9452512.0,1
298,50530576,How does Tensorflow know which trainable variables need to be minimised?,"I'm trying to understand the GradientDescentOptimizer API in isolation and have created a minimal example to figure out what is going on: Which outputs ... The minimize method is described in the API docs as: If I add some code to output the TRAINABLE_VARIABLES: I see: If I add another Variable to my code, it also gets output as a trainable variable, but only the x variable seems to be used by my minimize() method. I have seen on another question that it is possible to pass 'trainable=false' to variable declarations, but that doesn't seem to be needed. Does Tensorflow inspect the minimize operation to identify which trainable variables are part of the function and then only update those variables?",https://stackoverflow.com/questions/50530576,1033422.0,1
299,37054349,"Python, Tensorflow Regression",I would like to solve regression problem via tensorflow. I would like to predict picture of cat / dog. and output is always the same: My net returns only this value. Is it possible to learn nnet correctly? If there is a cat nnet should return 1 If there is a dog nnet should return 0 Is it possible?,https://stackoverflow.com/questions/37054349,5635269.0,1
300,63122680,Correct way to apply Minibatch Standard Deviation to Keras GAN layer,"I'm trying to improve the stability of my GAN model by adding a standard deviation variable to my layer's feature map. I'm following the example set in the GANs-in-Action git. The math itself makes sense to me. The mechanics of my model and the reasons why this addresses mode collapse makes sense to me. However, a shortcoming from the example is that they never actually show how this code is executed. No matter how I structure it, I can't get the discriminator to build. It continues to return different types of AttributeErrors but I've been unable to understand what it wants. Searching the issue, there were lots of Medium posts showing a high level overview of what this does in a progressive GAN, but nothing I could find showing its application. Does anyone have any suggestions about how the above code is added to a layer?",https://stackoverflow.com/questions/63122680,10147489.0,1
301,60833149,tensorflow2.1 inside docker report OOM when creating tf.Variable,I am new to docker tensorflow2.1. Below works: But this one reports OOM:,https://stackoverflow.com/questions/60833149,531116.0,1
302,44883861,Initial bias values for a neural network,"I am currently building a CNN in tensorflow and I am initialising my weight matrix using a He normal weight initialisation. However, I am unsure how I should initialise my bias values. I am using ReLU as my activation function between each convolutional layer. Is there a standard method to initialising bias values?",https://stackoverflow.com/questions/44883861,8149948.0,1
303,50169149,get the next tensor from dataset in a tf.while_loop,"I want to iterate through a dataset until certain condition is met, but I don't know how to ""iterate"". Below is my code. In response to Alex's answer below, below is a more realistic example of what I want to achieve. I could move the while loop logic to python as Alex suggested, but I'm guessing leaving it in the dataflow graph will have better performance.",https://stackoverflow.com/questions/50169149,4696339.0,1
304,45231405,What is tensorflow.Summary used for?,I am confused about tensorflow.Summary class. I found the following piece of code as part of tensorflow.models.textsum.seq2seq_attention._RunningAvgLoss function what dose Summary() return?,https://stackoverflow.com/questions/45231405,8000479.0,1
305,40926533,reduce_mean/reduce_sum axis effect on training?,"When calculating loss, does optimization somehow take into account the axis by which the reduced mean or sum is calculated? For example... A shows the sum of the samples per channel, while B shows the sum of the channels per sample, which generates a different mean err. however if one were to use reduce_mean() for the loss calculation the final mean errors are equal. regardless of using mean/sum I'm wondering if the optimizer will distribute the error differently to the weights depending on which axis I've indicated. Or is this simply not taken into account during backprop? My intuition is that by reducing the sum along the 0 axis the optimizer would know better which path to pass a larger portion of the error along through backprop. But I may have just thoroughly confused myself and this isn't actually relevant to the backprop calculation.",https://stackoverflow.com/questions/40926533,1725944.0,1
306,45811707,Tensorflow: feature length reading from TFRecord file is different from writing to it,"My source code is below , i can convert image data to tf-record successfully while i can't parse the example reading from tf-record correctly,I'm really confused. Run info show the feature length reading from tf-record(Input to DecodeRaw has length 55) is different from that writing to it([227,227,3]).I would really appreciate it if anyone can explain it.",https://stackoverflow.com/questions/45811707,7964238.0,1
307,44794237,Tensorflow: Simple Linear Regression using CSV data,"I am an extreme beginner at tensorflow, and i was tasked to do a simple linear regression using my csv data which contains 2 columns, Height &amp; State of Charge(SoC), where both values are float. In CSV file, Height is the first col while SoC is the second col. Using Height i'm suppose to predict SoC I'm completely lost as to what i have to add in the ""Fit all training data"" portion of the code. I've looked at other linear regression models and their codes are mind boggling, such as this one: I've just been able to get data from my CSV file without error using this guide: Full Code: Error:",https://stackoverflow.com/questions/44794237,8130059.0,1
308,45180109,Neural Networks - Softmax Cross Entropy Loss Decrease Corresponds to Accuracy Decrease,"I've been training a neural network and using Tensorflow. My cost function is: Training my neural network has caused the cross entropy loss to decrease from ~170k to around 50, a dramatic improvement. Meanwhile, my accuracy has actually gotten slightly worse: from 3% to 2.9%. These tests are made on the training set so overfitting is not in the question. I calculate accuracy simply as follows: What could possibly be the cause for this? Should I use the accuracy as a cost function instead since something is clearly wrong with the cross entropy (softmax) for my case. I know there is a similar question to this on StackOverflow but the question was never answered completely.",https://stackoverflow.com/questions/45180109,7203414.0,1
309,45383995,Tensorflow Shuffle Batch - Batch size,"I am trying to better understand the behavior of queues and batches. I have 1,000,000 records in my training set and I want to train on batches of 1000. Right now my code is creating a queue using string_input_producer and then doing a read_up_to based on my batch size (in this case 1000). What will be the behavior if I set the batch size in the corresponding shuffle_batch to be smaller? Is it going to throw out the other 900 records or dequeue 100 at a time but still ultimately process all of the records?",https://stackoverflow.com/questions/45383995,6520820.0,1
310,57651678,ValueError: No variables to optimize in GradientDescentOptimizer,I am trying to make a simple tensorflow 2.0 code for a linear regression It returns ValueError: No variables to optimize.,https://stackoverflow.com/questions/57651678,11976470.0,1
311,71408135,"Tensorflow 2.8.0 - Custom layer doesn't work out with tf.map_fn(tf.range,...)","Dear stackoverflow community, I am currently trying to create a custom layer that transforms every value of an input with integers into a vector with length ""omega"". Currently I combine the tensorflow functions tf.map_fn with the function tf.range to create a ragged tensor and fill that tensor up with zeros afterwards. The Custom layer is defined as follows: The error message I get is the following: What I have tried was the following: -) I tried to change inputs -&gt; inputs[:,1], but this only changes the error message to Example: The input should be of the form (shape=[None,1]): Example: Does anyone know a solution to this problem?",https://stackoverflow.com/questions/71408135,17375306.0,1
312,60580508,TensorFlow 2.0 - Learning Rate Scheduler,"I am using Python 3.7 and TensorFlow 2.0, I have to train a neural network for 160 epochs with the following learning rate scheduler: Decreasing the learning rate by a factor of 10 at 80 and 120 epochs, where the initial learning rate = 0.01. How can I write a function to incorporate this learning rate scheduler: Is this a correct implementation? Thanks!",https://stackoverflow.com/questions/60580508,3616293.0,1
313,57420773,Training custom tf.keras.model with model.fit() InvalidArgumentError,"I'm tying to get a hang of the Keras API in Tensorflow 2.0 by implementing a simple model which finds the 4 coefficients of a 3rd degree polynomial. This code works fine: However if I try to extend tf.keras.Model and make my custom class, it fails: with error:",https://stackoverflow.com/questions/57420773,6641872.0,1
314,45912760,Understanding why results between Keras and Tensorflow are different,"I am currently trying to do some work in both Keras and Tensorflow, I stumbled upon a small thing I do not understand. If you look at the code below, I am trying to predict the responses of a network either via Tensorflow session explicitly, or by using the model predict_on_batch function. My issue is that I got two different results, even though I tried to remove any kind of sources of randomness by setting the seeds to 1 and running the operations on CPU. Even then, I get the following results: and Does anybody have an idea what could be going on in the background that could change the results? (These results do not change if one runs them again) The difference gets even bigger if the network runs on a GPU (Titan X), e.g. the second output is: whereas in the first one, the differences only occur in the 5th and latter decimal places:",https://stackoverflow.com/questions/45912760,6377076.0,1
315,46326376,tensorflow confusion matrix in Experimenter during evaluation,"I've got some troubles during the model evaluation using Tensorflow with the Experimenter API. I used to work using 2-classes NN, but this time I manage to train a 4-classes one and I need to figure out how to build a confusion matrix in this case. I tried using the tf.confusion_matrix function, but it doesn't work at all. This is the fragment of code that I used: And this is the error that I got: I read other answers about to create a confusion matrix in Tensorflow and I understood how to do it, but I think that my question is more related to the Estimator/Experimenter API.",https://stackoverflow.com/questions/46326376,4735866.0,1
316,72597046,keras - cannot concatenate Embedding and CategoryEncoding layers,Following the GCP Vertex AI example with the code below. The code causes the error of not being able to concatenate layers. What is the cause and how to fix?,https://stackoverflow.com/questions/72597046,4281353.0,1
317,76085946,Problem training a TensorFlow model for captchas with LSTM,"I have a problem with this TensorFlow model and I don't know what to do to make it accept the data correctly and start working. This is a model intended to respond to captchas, but it is not working correctly. I think my method for collecting the data is correct, but I'm not sure. I'm relatively new to this. Method for model: ` Method for collecting data. ` def load_date2(self): Method for training ` ` Error message: If someone could help me with this problem, I would be very grateful.",https://stackoverflow.com/questions/76085946,19762692.0,1
318,51264291,How to define cross entropy for equal logits and labels?,"So basically we usually define cross entropy like this: output: Now if my logits are : And my labels are same shape of logits like : So each value in logits have a 0 or one ( One hot encoding ) , How can i achieve that ? I tried with and But it's giving Error . For more explanation : So suppose my input is . [ [12 , 14 , 15 ] . , [23 ,24 , 25 ] ] . now i will get logits for this input like . [ [ 0.11 , -0.1 , 0.2 ] , [0.91 0.2 0.12] ] . now my labels are for this logits . [ [ 0, 0 , 1 ] , [ 1 , 0 ,1 ] ] . it means i want . [0.2] from first and [0.91 , 0.12] from second from this vector [ 0.11 , -0.1 , 0.2 ] . i wan last one so my label are [ 0 , 0 ,1 ] from this vector [0.91 0.2 0.12] . i want first and last so i want [ 1, 0, 1]",https://stackoverflow.com/questions/51264291,5904928.0,1
319,50987530,"Tensorflow tf.trainable_variables(scope="""") function","I tried to simplify my tensorflow code with the following replacement: instead of the prior syntax: Before, i tried to update tensorflow to the newest version with : in jupyter notebook. Checking the version, it returned When i tried to run it, tensorflow returned the following error. What's wrong here? In the tensorflow documentation, you can insert an argument for scope for the tf.trainable_variables() command. --&gt; https://www.tensorflow.org/api_docs/python/tf/trainable_variables",https://stackoverflow.com/questions/50987530,8092502.0,1
320,52408867,Angles Comparasion Loss Function for Tensorflow in Python,"I have a CNN, takes in an image, outs a single value - an angle. The data set is made of (x = image, y = angle) couples. I want the network for each image, to predict an angle. I have found this suggestion: https://stats.stackexchange.com/a/218547 But I can't seem to understand how to translate it into a working Tensorflow in Python code.",https://stackoverflow.com/questions/52408867,1525654.0,1
321,44336822,simple Recurrent Neural Net from scratch using tensorflow,"I've build a simple recurrent neural net with one hidden layer with 4 nodes in it. This is my code: I'm getting output: With input 1, it should output 0 and vice versa. I'm also confused regarding the 'previous value'. Should it be a placeholder? I'd really appreciate your efforts to fix the code.",https://stackoverflow.com/questions/44336822,6288172.0,1
322,76196265,How to apply a tokenizer to a tf.data.Dataset object?,"I'm currently working on sequence classification task where I'm trying to classify a sentence into a 0/1/2 label using Transfer Learning. I download the financial_phrasebank as a HuggingFace dataset object and I want to convert this object to a tf.data.Dataset object and then perform my preprocessing tasks - shuffling, train-test split, tokenization and then passing it on to a model. How do I send my tfds object to the tokenizer? I'm thinking of implementing the .map() method on the object, but not sure how to proceed.",https://stackoverflow.com/questions/76196265,20278669.0,1
323,48092772,Add operation to graph without with-as-clause,"Since you are able to do a but also I was wondering whether it is possible to do a similar thing with Graph creation, like: The conventional way to add a node/operation to a graph is of course... I couldn't read anything about this in the docs.. and dir(a_graph) does not show me a simple .add() method. The only thing I could think of are add some operation to a collection... but I am not sure how to do that.",https://stackoverflow.com/questions/48092772,6329284.0,1
324,42960304,Basic StopAtStepHook & MonitoredTrainingSession usage,"I want to setup a distributed tensorflow model, but fail to understand how MonitoredTrainingSession &amp; StopAtStepHook interact. Before I had this setup: Now I have this setup (simplified): Is this wrong? It throws: Can somebody explain to me how tensorflow is coordinating here? How can I use the stepcounter to keep track of the training? (before I had this handy epoch variable)",https://stackoverflow.com/questions/42960304,6591278.0,1
325,52636869,How to display the contents of a tf.Variable,"I am new to Tensorflow and I appreciate knowing how to visualize the contents of a tf.Variable, tried% f,% s but it is not shown, where is my mistake. I put the code that I am using, I appreciate your response. This result is displayed but I would like to visualize a value, of course if it is possible. I understand that they are AdamOptimizer slots, and I seek to show the learning rate in each step. I have reviewed other answers but they do not work. Use: before the print and the same result.",https://stackoverflow.com/questions/52636869,8402528.0,1
326,71211053,What tensorflow's flat_map + window.batch() does to a dataset/array?,"I'm following one of the online courses about time series predictions using Tensorflow. The function used to convert Numpy array (TS) into a Tensorflow dataset used is LSTM-based model is already given (with my comment lines): This code work fine but I want to understand it better to modify/adapt it for my needs. If I remove dataset.flat_map(lambda window: window.batch(window_size + 1)) operation, I receive the TypeError: '_VariantDataset' object is not subscriptable pointing to the line: lambda window: (window[:-1], window[-1])) I managed to rewrite part of this code (skipping shuffling) to Numpy-based one: Syntax of fitting of the model looks a bit differently but it works fine. My two questions are:",https://stackoverflow.com/questions/71211053,8179672.0,1
327,66114393,Print tensor value tensorflow 2.4,"I tied to print one value while i train my Transformer. But tf.print doesn't print anything. However my first print('_') works What did I do wrong? Pls, help me to print my tensors. UPDATE: U also could explain to me the structure of tar_inp and tar_real instead of fixing tf. print.",https://stackoverflow.com/questions/66114393,14182533.0,1
328,36339059,Exporter classification_signature,"I'm trying to modify the serving tutorial to work with my model, which is basically the CIFAR example modified to work with a CSV file and JPEGs. I can't seem to find the documentation for the Exporter class, but here is what I have so far. It's in the train() function in the cifar10_train.py file: Here is the code I use to train the model: Any ideas how I can set up Exporter correctly?",https://stackoverflow.com/questions/36339059,563762.0,1
329,50282420,Tensorflow confusion matrix for multiclass classification,"Thanks for your help. I am coding a multiclass binary classifier for facial actions (such as raised eyebrow, parted lips), and I want to make a confusion matrix. There are 6 facial actions and 593 samples. I'm getting this error: I'm getting this error: ""Shape (?, 2, 6) must have rank 2"". From documentation, tf.confusion_matrix takes 1-D vectors, but I think there should be a way to shape the input data from the feed_dict so that it works, based on Tensorflow Confusion Matrix in TensorBoard. The labels and predictions look like: I'm using a feed-forward MLP and the variable 'pred' is the prediction, with a threshold forcing a choice of 0 or 1. I tried multiplying predictions and labels by np.arange(1,7) to have the positive values match the indices but I got stuck on the shape of the arguments. There's more code, but I'm showing what I think is relevant. Thank you!",https://stackoverflow.com/questions/50282420,2723224.0,1
330,59055872,"How to run single-node, multi-device data-parallel training with Keras?","Keras used to feature a multi_gpu_model that made it very easy to do data-parallel training on a single node with multiple GPUs. I see that this function will unfortunately be deprecated - its doc saying that ""Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2020-04-01. Instructions for updating: Use tf.distribute.MirroredStrategy instead."" This warning points to the tf.distributed.MirroredStrategy page which shows something much more verbose that what Keras users are used to and with zero mention to keras. Hence the question: What is the compact and intuitive way to do single-node, multi-device data-parallel training with Keras, if any? I'm looking for something as simple as multi_gpu_model was, or as intuitive as gluon's multi-device SGD is",https://stackoverflow.com/questions/59055872,5331834.0,1
331,61375125,Keras tuner: mismatch between number of layers used and number of layers reported,"Using example from Keras Tuner website, I wrote simple tuning code However, when I run it with varying number of layers, but it shows mismatch between number of layers reported and value of num_layers. For example it reports three Conv2D layers and yet it shows num_layers as 1. Why ?",https://stackoverflow.com/questions/61375125,238038.0,1
332,66889296,"GPflow 2 custom kernel construction: fine upon construction, but kernel of size None in optimization","I'm creating some GPflow models in which I need the observations pre and post of a threshold x0 to be independent a priori. I could achieve this with just GP models, or with a ChangePoints kernel with infinite steepness, but both solutions don't work well with my future extensions in mind (MOGP in particular). I figured I could easily construct what I want from scratch, so I made a new Combination kernel object, which uses the appropriate child kernel pre- or post x0. This works as intended when I evaluate the kernel on a set of input points; the expected correlations between points before and after threshold are zero, and the rest is determined by the children kernels: However, when I want to train a GPflow model with this kernel, I receive the error message TypeError: Expected int32, got None of type 'NoneType' instead. This appears to result from the sub-kernel matrices K_pre and K_post to be of size (None, 1), instead of the expected squares (which they correctly are if I evaluate the kernel 'manually'). What can I do to make the kernel properly trainable? I am using GPflow 2.1.3 and TensorFlow 2.4.1.",https://stackoverflow.com/questions/66889296,15522786.0,1
333,72045334,Unexpected behavior in tf.data.Dataset map function,"I am working on a problem where I need to apply some transformation to my dataset using the map function that tf.data.Dataset provides. The idea is to apply this transformation that rely on some random number and then chain this transformation with another function. The idea is something like that: I thought that if I print dataset twice I should expect the same values, however, the result is the following. Any clues on how can I get exactly the same values after a .map transformation which relies on random numbers? It seems that the map function is done twice instead of once as I declared in the code snippet. P.D: Using a random seed does the trick but its just hidding the problem. [EDITED] What I need is to perform an operation like this: As you can see, x depends on y, and it doesn't seem that this behavior is happening. That's why I asked how to apply the random operation first and then apply the map to illustrate this.",https://stackoverflow.com/questions/72045334,11139889.0,1
334,48053907,Why do I need to initialize variables in TensorFlow?,"I primarily develop my models in R and I am currently learning TensorFlow. I'm going through a tutorial with the following code From a layman's perspective, why do I need to initialize and Variabalize in TensorFlow? I know this may be a basic question but it's something not dealt with in R.",https://stackoverflow.com/questions/48053907,2962786.0,1
335,55878846,Which API can implement tensor expansion in tensorflow ？,"If I have a tensor of (30,40,50), and I want to expand it out to the first order, then I get a second order tensor of (30,2000), and I don't know if tensorflow has an API that implements it. This gives: How do I get data9 directly?",https://stackoverflow.com/questions/55878846,11419026.0,1
336,58049485,How does Tensorflow construct a graph from your code arguments?,"I am trying to understand how Tensorflow is able to accept an expression as an argument and turn it into a graph in Python I have tried looking at the Tensorflow code base (e.g. https://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/python/ops/nn_ops.py), and maybe I'm just being dense but I can't see how they are doing it from this. An example might be: It is the definition of 'h' here that interests me. How does tf/Python facilitate turning matmul + b into 2 operands and an add operation in the graph? I haven't found any declaration for Python that allows tf.matmul(x, W) + b to be tokenized and registered as graph elements as I thought I might expect to see in the declaration of tf.nn.relu().",https://stackoverflow.com/questions/58049485,6077080.0,1
337,42958531,Tensorflow tf.size not working with dynamic length tensor from tf.unique,"This seems simple, but I've been stuck on it for a while. I have a list, and want to create a variable that's equal to the length of unique items in that list. A simple example looks like this: I get an error saying that inital value must have a shape specified. I have also tried, tf.shape, tf.zeros_like, and even tf.reduce_max(item_idxs) all to no avail. I am able to do it by creating a session and running the results from tf.unique and using the values from there, but it feels like bad practice, but let me know if i'm wrong about that. EDIT- Adding shape to the constant didn't help, using placeholder instead of tf.constant also didn't help.",https://stackoverflow.com/questions/42958531,3791794.0,1
338,57236922,What does reshape on an image actually do?,"What does the reshape below actually do in detail? I have seen the sample tensorflow code but I'm not sure what the (60000,28,28,1) does, can anyone help to explain it in detail?",https://stackoverflow.com/questions/57236922,9845070.0,1
339,51109914,NotFoundError in TensorFlow when restoring a model,"I built and saved a TensorFlow model, and then I'm trying to restore this model and use it. I'm using old methods, due to the fact that this code has been written in older versions of tensorflow (now I'm using python 3.5 and tensorflow 1.8.0). This is the piece of code where I'm saving the model: And this is how I'm restoring the model: When I run this code I'm running into the following error: I saw some similar problems that were solved and tried the solutions. No one works. The directory name is the same in both codes (as far as I can see, can you give me an advise how to confirm?), and also the model is saved properly (same note). I will really appreciate your help! Thanks!! Full error log below:",https://stackoverflow.com/questions/51109914,6182430.0,1
340,63748890,"ValueError: Input 0 of layer lstm_34 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 25]","I am a newbie with lstm, can anyone please explain why I am getting this error? my lstm model - def NNStructure(): model_glove1=NNStructure() model_glove1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) model_glove1.fit(x=[pad_seq,X_meta_train], y=np.array(Y_train), batch_size=32,epochs=4,verbose=1,validation_split=0.2,shuffle=True)",https://stackoverflow.com/questions/63748890,8501211.0,1
341,57791851,cast tensorflow 2.0 BatchDataset to numpy array,"I have this code: And I want to cast these two BatchDataset variables to numpy arrays, can I do it easily? I am using TF 2.0, but I just found code to cast tf.data with TF 1.0",https://stackoverflow.com/questions/57791851,6621346.0,1
342,51460835,Tensorflow can't determine why size of tensor is changing and can't debug directly,"I am creating a convolutional neural network class using tensorflow and have run into an error where, during optimization, one tensor has 40000 elements when it should only have 10000. The problem arises in the line: giving the error: so basically it's saying that the output of my network is 4x larger than the test labels I provided it. My question is how do I view the size of my output tensor as it changes? It seems like everything happens behind the scenes via the single line of code session.run('model-name') which prevents me from being able to debug it. How do I peek inside and figure out what's going on? Here is the full code: main file:",https://stackoverflow.com/questions/51460835,4655531.0,1
343,55389913,"ValueError: Input 0 of layer dense is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: [None]",I am new to Tensorflow and trying to work on it using the sample code below: The training_dataset is as below with 179 rows: And I got the following error when running it: Can anyone advise on how to fix it?,https://stackoverflow.com/questions/55389913,11124070.0,1
344,56047379,Problem with Tensorflow iterator returning tuples,"I want to iterate over a TF dataset in order to convert the obtained data to numpy tensors. Being new to tensorflow, this is what my code looks like The apparent problem is that every call to eval() iterates both over exampleTF and labelsTF, thus skipping half of the entries. Any help? I also tried something like but this results only in errors of the form",https://stackoverflow.com/questions/56047379,11471813.0,1
345,63549485,is there cv2 findcontours and boundingRect in tensorflow 2.0?,"This is the same functionality as cv2.findContours and cv2.boundingRect, I tried googling and looking at tf.image.* but it doesn't seem to be implemented. Any advice? I like to do this in batch of binarized images and output bounding rectangles back with shape (batch_num, n_boxes, 4), the last dim corresponds to (x1, y1, x2, y2) of the boxes. Currently, I can accomplish this using cv2.findContours(...) follow by cv2.boundingRect(...) and with a for-loop if I have a batch of images. My goal is to have this done in pure tf (graph?) so it can be part of either training, or inference workflow. The performance is too slow if I can't integrate this in TF.",https://stackoverflow.com/questions/63549485,1762295.0,1
346,58922889,How to batch a transformed (scaled and quantized) Beta distribution in tensorflow probability,"I'm trying to fit a beta distribution to the results of a survey with discrete scores (1, 2, 3, 4, 5). For that to work I need a working log_prob of a Beta in TensorFlow probability. However, there is a problem with how batching is handled in Beta. Here is a minimal example that gives me an error: The same code seems to work ok with Normal distribution... What am I doing wrong here? TensorFlow 2.0.0 tensorflow_probability 0.8.0 EDIT: As suggested by Chris Suter. Here is broadcasting by hand solution: EDIT2: The above solution does not work when I try to apply it in MCMC sampling. The new code looks like this: This ends up with an error message:",https://stackoverflow.com/questions/58922889,2295564.0,1
347,53173449,Is it a bug of tensorflow for feed type?,"See the code snippet: sample_sc1 and sample_sc2 are both ndarray with the size of 32 and dtype of int32, and all numbers in them range from 0 to 9. sc is tf.placeholder with dtype of tf.int32 and size of [None]. When I feed sample_sc1 into sc, it works well, but when I feed sample_sc2 into sc, it raises tensorflow.python.framework.errors_impl.InternalError: Unsupported feed type. It is an amazing error, is it a bug of tensorflow?",https://stackoverflow.com/questions/53173449,8165066.0,1
348,73689334,Keras save model with named layers,I have a keras model where each layer has a specific name and I would like to save the model in its entirety so that I can load it later. Saving and loading the model looks like this Unfortunately I get the following error when I try to load the file I also tried to save only the weights but I get the same error Following what has been discussed in this question I tried downgrading h5py but the error remains. How can I fix it? EDIT: Following Dr.Snoopy answer I checked again if h5py was correcty downgraded and also matched Keras version between Google Colab and my local machine. It works now with h5py version 2.10.0,https://stackoverflow.com/questions/73689334,7286547.0,1
349,35955144,Working with multiple graphs in TensorFlow,"Can someone explain to me how name_scope works in TensorFlow? Suppose I have the following code: When I run this code I get the following error message: I agree ""g2/MatMul"" is not an element of graph g1, but why is it selecting ""g2/MatMul"" when the session graph is set to g1? Why doesn't it select ""g1/MatMul""? The following code seems to work: By flipping the switch use_g1, graph g1 or g2 will run in the session. Is this the way name scoping was meant to work?",https://stackoverflow.com/questions/35955144,1430078.0,1
350,45521499,legacy_init_op in TensorFlow Serving,I've noticed every example on TensorFlow Serving uses legacy_init_op parameter in SavedModelBuilder but I have not found any clear explanations on what this is and why it is called legacy. Anyone knows the purpose of this argument? Example:,https://stackoverflow.com/questions/45521499,539617.0,1
351,51654599,Tensorflow Beamsearch Decoder unable to decode the value,"I am trying to code seq2seq example with Tensorflow with Beam Search and Attention. Till now I have found no concrete example which explains the both the decoding and/or attention together using current tf version. Either the previous versions have an issue with the beam search decoder which will tell you to do a batch_tile. I have a working example of simple decoder example, which for time being is Ok but I want to use Beam Search I am getting this error I believe the beam_width is adding extra dimension which changes the rank of the tensor as the code works without BeamSearch with BasicDecoder. If I set the beam_size =1 (fun sake) it throws this error I would be glad if anyone can help me this error. If I set the",https://stackoverflow.com/questions/51654599,1516947.0,1
352,65046236,Why do we use sigmoid fn when we make Mnist Gan example?,"Hello I'm studying GAN by using Mnist example. And I see example code as like below nn_G(x) seems like generator definition, HL seems hidden layer and OL seems like the Output layer. I can't understand the meaning that we want to get 0 ~ 1 at the OL. Thank you for reading the beginner's question",https://stackoverflow.com/questions/65046236,14699191.0,1
353,74481219,How to get number of values in each row of a sparse tensor?,"I have a Sparse Tensor as follows: I want to convert this sparse tensor to another 1D tensor of shape (5, 1) where the only column represents the number (or size) of values in each of the rows. For example, for the above sparse tensor, desired 1D tensor would be [3, 2, 0, 3, 4]. How can I do it? I tried going through the TensorFlow API docs but couldn't find anything to try.",https://stackoverflow.com/questions/74481219,3243499.0,1
354,60040736,"Apply a function to each element of a 3D, 2 channel Keras tensor","I have a model that processes 2 input 3D images of the same size, A and B, for use in a more classical function to attempt to increase performance of this function. In order to properly train the model I need to apply the function to the result of each run. The function itself takes 2 values, which correspond to the values in A and B at the same coordinate p. This result is to be stored in a 3D image, C, of the same size as A and B at point p. Classical implementations of this would perform a for loop over all the coordinates and apply the function for each pair. Unfortunately, this approach does not work for training a Keras model as the output of the function has to feed back to the weights of the previous layers. I have attempted to write a custom Keras layer for this. This layer accepts a 4D tensor (channel, z, y, x) and should return a tensor with shape (1, z, y, x). Currently this looks like: Unfortunately, this method has severely slowed down the training. Whereas the model without the custom layer at the end took around 45 minutes to train per epoch, the model with the custom layer takes about 120 hours per epoch. The model and the function on their own can perform the required task with a significant error, however I wanted to see if I could combine the two for better results. The real-life use in my case is the decomposition of materials from Dual Energy CT. You can calculate the fraction of materials for each voxel by assuming 3 known materials mat1, mat2, mat3 and an unknown sample sample. With some calculations you can then decompose this unknown sample into fractions of each known material f1, f2, f3 (f1 + f2 + f3 == 1.0). We are only interested in f3, so the calculations for the other fractions have been omitted. Actual code:",https://stackoverflow.com/questions/60040736,9299773.0,1
355,46371321,Mixture usage of CPU and GPU in Keras,"I am building a neural network on Keras, including multiple layers of LSTM, Permute and Dense. It seems LSTM is GPU-unfriendly. So I did research and use But based on my understanding about with, with is try...finally block to ensure that clean-up code is executed. I don't know whether the following CPU/GPU mixture usage code works or not? Will they accelerate speed of training?",https://stackoverflow.com/questions/46371321,4518087.0,1
356,34221453,Tensorflow: how to add user custom op accepting two 1D vec tensor and output a scalar?,I'm trying below but not work. ./test.py I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8 I tensorflow/core/common_runtime/direct_session.cc:60] Direct session inter op parallelism threads: 8 F ./tensorflow/core/public/tensor.h:453] Check failed: dtype() == DataTypeToEnum::v() (1 vs. 2) Aborted,https://stackoverflow.com/questions/34221453,5668239.0,1
357,46788566,Can someone explain the train function in cifar10_train.py from cifar10 tutorials in tensorflow,"I am following cifar10 tutorials from https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10. In this project, there are 6 classes. After searching the internet I understood cifar10.py and cifar10_input.py classes. But I can't understand train function in cifar10_train.py. Here is the train function in cifar10_train.py class. Can someone please explain what is happening in _LoggerHook class?",https://stackoverflow.com/questions/46788566,5138134.0,1
358,64247065,ValueError: Must setup local AWS configuration with a region supported by SageMaker,"I am new to Sagemaker and trying to use Sagemaker with python SDK with sample minist code provided by aws, and called it sm_mnist.py: I created the Tensorflow estimator train.py: and here is my dockerfile: I can create the image using: I am getting this error which I could not solve it: I do not know where my mistake is?",https://stackoverflow.com/questions/64247065,8060154.0,1
359,49268505,How to reuse a frozen previously learned subgraph in new computation graphs,"I have build an autoencoder which is trained using the Dataset API. The architecture is depicted on this tensorboard schema : I would like to reuse only the encoder part in an other learning task so I have attempted to freeze the graph using and then trying to import it in my other code using but when running the out tensor with feeding something in encoder_input I get None as result I've tried to visualize the exported graph in tensorboard and it seems that the shape of the tensors as disappeared. So my question is how can I export my encoder in a way which allows me to use it as a ""black box"" in an other piece of code ? EDIT : I have implemented my model using placeholder instead of Dataset iterator get_next tensors and the lack of dimension stays the same except for the input node (corresponding to the placeholder) which stores its shape in its attributes. Edit 2 : Following the advice in this issue report I added the shape information when exporting my graph using and now see the shape information on the tensorboard schema, but the computation still returns None",https://stackoverflow.com/questions/49268505,5159937.0,1
360,59267936,Loading a 3D Array from a VarLenDeature in TfRecords with Tensorflow 2.0,"I am trying to load 3D Arrays from TFRecord Data into Tensorflow. The Data has not been created by me and I have just been given the image_feature_description Dictionary. But I am not sure if what I am doing is correct and in doesn't seem right. Here is the output: This is what happens if I print my Dataset in total(With it Containing the Contents of the Array and a Integer Label. Now the Shape (None,None,None) is making me worried. this doesn't seem right. Can anybody help me here please?",https://stackoverflow.com/questions/59267936,10196987.0,1
361,65190580,"Keras says dimensions aren't equal, but I'm sure they are. Works when I set batch size to 1","So I'm trying to get a convolutional variational autoencoder to work on MNIST. It was working fine with I didn't use convolution layers, and had everything with Dense layers, but as soon as I added convolution, it fell apart. I'm sure this is something to do with how I'm dealing with Samples x 784 data, vs Samples x 28 x 28 data, but I can't figure it out. However, if I set the batch size to 1, it works. I'm sure the final error code is telling me exactly what I'm doing wrong, but I can't understand it: So here is the code The models all seem right and here is the error",https://stackoverflow.com/questions/65190580,10773339.0,1
362,51531156,Tensorflow mean square error calculation differers from sklearn,I'm trying to calculate mse using tensorflow and compare the result with sklearn.metrics.mean_squared_error method. My test loop But my tf function always return either 0 or 1. Could you please point me where I'm wrong. UPD Thanks to @apnorton for pointing on issue with types.,https://stackoverflow.com/questions/51531156,3911211.0,1
363,55421290,TensorFlow 2.0 Keras: How to write image summaries for TensorBoard,"I'm trying to setup an image recognition CNN with TensorFlow 2.0. To be able to analyze my image augmentation I'd like to see the images I feed into the network in tensorboard. Unfortunately, I cannot figure out, how to do this with TensorFlow 2.0 and Keras. I also didn't really find documentation on this. For simplicity, I'm showing the code of an MNIST example. How would I add the image summary here?",https://stackoverflow.com/questions/55421290,820833.0,1
364,70962316,Beginner's Tensorflow question: Can't get the dimensions for a simple linear equation right,"I'm starting to dabble in Tensorflow and want to teach a model a simple linear equation. So to generate training data, I'm writing a little script to produce two arrays, one of 100 tuples of two random integers (x1, x2) and one where each value is y = 2x1 + 5x2: Then I want to build a simple model to learn the relationship between these two arrays: The code runs, but it's quite useless - it starts with a ridiculously high loss, and that loss never goes down over those 100 epochs. After some attempts at troubleshooting, my theory is that the problem lies with the dimensionality of the input_shape parameter in the input layer which I got wrong in such a way that the model doesn't know it's supposed to map two input integers from x_data to one output integer from y_data. But my attempts to change that parameter only get me an error that the model expects another dimensionality of input data. And (2,) is what I get when I pass one of the instances of x_data into np.shape(). Anyone have an idea what I'm doing wrong?",https://stackoverflow.com/questions/70962316,18103012.0,1
365,68538913,Why is model variables initialization method called twice in tensorflow?,"I'm trying to figure out the implementation of SGD in tensorflow. In the apply_gradients method just before self._create_all_weights(var_list) I added some logging and then I got the initialized weights and bias twice, which I don't understand. Why is this method called twice? To verify my guess, I disabled all my logging except just before this line each time I ran my script I got only one of that logging Why is weights and bias initialization method called twice in tensorflow? click here to check the whole piece and reproduce my trial on colab",https://stackoverflow.com/questions/68538913,12214867.0,1
366,55696971,"Neural Network after first epoch generates NaN values as output, loss","I am trying to set neural network with few layers which will solve simple regression problem which should be f(x) = 0,1x or f(x) = 10x All the code is showed below (generation of data and neural network) problem is after I am running it the output and loss function are turning into NaN value: And the output layer: [NaN, NaN, NaN, ..... , NaN] I am new to tensorflow and I am not sure what I might be doing wrong (badly implement next batch, learning, session implementation)",https://stackoverflow.com/questions/55696971,10190351.0,1
367,54613474,Tensorflow Keras Input layer does not add _keras_shape,"According to the keras documentation, Input adds the _keras_shape attribute to the input tensor. However, as shown below, this is not the case. Have I misunderstood something, or is this a bug I should report? The lack of this attribute makes further Keras functions go haywire: I'm using tensorflow version '1.11.0-rc2'",https://stackoverflow.com/questions/54613474,2110869.0,1
368,60044769,Log to tensorboard an internal loss function in Tensorflow 2.0,"I have been implementing my first Variational Autoencoder for a custom application I am working in. Everything runs smoothly but I am not able to log the KL term to Tensorboard at each batch forward pass. I want this in order to gain inside on the model and to study the effect of KL annealing techniques. I've defined my model from the examples on the TF documentation webpage, meaning that the KL term is added to the current batch loss by the Model.add_loss() function: I define, compile and train my model with the built-in functions (I am not defining a custom training loop): With this setup, I am able to get in Tensorboard logs of the combined loss function (Reconstruction + KL) and also only reconstruction (by use of the MAE metric). Nevertheless, I cannot seem to find a way to also log the KL term, since its value is computed inside the graph. I have tried to use a multi-output configuration but it requires assigning constant loss_weights, which I need to avoid since I want to use KL annealing. I would like to avoid to write a custom training loop so I am able to do this, but I have tried several ideas so far and now I believe it might be the only way. Am I wrong? Is there a way to log this internal loss value to Tensorboard?",https://stackoverflow.com/questions/60044769,3179768.0,1
369,63637847,How exactly Tensor masking and indexing should be done in Tensorflow?,"I have been using TF for 2 years now and at each project, I have lots of non-sense error popping out for masking which usually are not helpful and don't indicate what actually is wrong. or worst than that, the result is wrong but no error. I always test the code outside the training loop with dummy data and it's fine. but in the training (calling fit), I don't understand what TensorFlow expects exactly. just for one example, can someone experienced please tell me why this code does not work for a binary cross-entropy, the result is wrong and model does not converge but no error in this case: while this works correctly: and for a categorical example, the opposite is true. I can't use the mask as an index like y_pred[mask], or y_pred[mask[0]], or using tf.squeeze() and so on. but using tf.gather_nd() works. I always try all the combination that I think is possible, I just don't get it why something so simple should be this hard and painful. is Pytorch like this too? I'm happy to switch if you know Pytorch doesn't have similar annoying details. EDIT 1: They work correctly outside training loop, or graph mode to be more exact. first snippet: 1.2907861471176147 second snippet: 1.2907861471176147 EDIT 2: After printing losses in graph mode as @jdehesa suggeted, they differ, which they shouldn't: first: 0.814215422 second: 0.787778914 first: 0.779697835 second: 0.802924752 . . .",https://stackoverflow.com/questions/63637847,10528078.0,1
370,59764734,Why model could be fitted with numpy array in wrong dimensions in tensorflow(2.x)?,"When I learn to build a model with tensorflow.keras.Model(tensorflow.version=2.0.0), I compile my model on the way below: When I need to use model.fit method, I make some attempts: It should be correct, and so the running result is. This code should thread an error since the dimensions of the y cannot adapt to the model's output, and I got a ValueError such as Dimensions must be equal, but are 2 and 3 for 'loss/dense_loss/mul' (op: 'Mul') with input shapes: [?,2], [?,3]. It is still as expect. So I think that this code should also thread an error just like Attempt 2, but why the model could be fitted with such a training data? and what did the model learn?",https://stackoverflow.com/questions/59764734,12722491.0,1
371,47393251,understanding tensor flow function output,"Could someone explain why the following code generates the output of array([ 0.59813887, 0.69314718], dtype=float32) ? For example, numpy.log(0.5) = 0.69314718, but how does the 0.598138 come from ?",https://stackoverflow.com/questions/47393251,3390810.0,1
372,61463099,IndexError: list index out of range in TensorFlow Python,I am new to tensorflow and I got an error when trying to fit my model. The error is: Here is my code: A few lines from housedata.csv which I use,https://stackoverflow.com/questions/61463099,13418916.0,1
373,56866651,Tensorflow: How to identify input variable? / Is it possible to save and use predict without input placeholder?,"Using Tensorflow 1.3.1 I have created a neural network and trained it and now I would like to save it using tf.saved_model.simple_save(sess, export_dir, inputs, outputs) so that I can use it to make predictions. Therefore I need to find the 'inputs' variable of my model. The model I have is defined like this: When I look at the variables in the scope (using): I get: I tried saving it and then loading it with but I get the error I haven't defined a placeholder for the input data. Does this mean I cannot save and then load it via the simple_save approach?",https://stackoverflow.com/questions/56866651,1826893.0,1
374,56088294,tf.keras.models.Sequential model cannot fit with input type tf.Tensor,"I have written a simple tf.keras.models.Sequential model. When I try to fit it with data and labels as tf.Tensor, it gives me some error. However I can fit it with numpy array with exactly the same underlying data. Why is it? I am using tensorflow 1.13 with only CPU. I checked the fit function of tf.keras.models.Sequential but it says both tf.Tensor and numpy array can be used as data and label as long as their types match. The first fit does not work and throws the following error. But the second works. This is interesting because they have exacly the same underlying data",https://stackoverflow.com/questions/56088294,11484456.0,1
375,35695183,Tensorflow : Memory leak even while closing Session?,"I was just trying some stuff for a quaternionic neural network when I realized that, even if I close my current Session in a for loop, my program slows down massively and I get a memory leak caused by ops being constructed. This is my code: The problem seems to come from test2 = feedForward(..). I need to declare these ops after executing retour once, because retour can't be a placeholder (I need to iterate through it). Without this line, the program runs very well, fast and without a memory leak. I can't understand why it seems like TensorFlow is trying to ""save"" test2 even if I close the session ...",https://stackoverflow.com/questions/35695183,5962133.0,1
376,62927710,How to get the output I want?,"I have started using Tensorflow of Machine learning. I am a beginner to don't understand much like the functions and their purpose. I started with a simple Hello world program. The I used is this: This is the output: The output I wanted was ""hello Tensorflow"" but there is a b at the beginning. I was wondering why is that",https://stackoverflow.com/questions/62927710,13742883.0,1
377,71692505,How to call TensorFlow model with linspace?,I'm trying to call a TensorFlow model on a linspace but I can't seem to get even a very simple example (based on https://www.tensorflow.org/api_docs/python/tf/keras/Model) to work: I get the following error (on the line indicated above): I have tried adding an input layer But then the error becomes Any help is appreciated.,https://stackoverflow.com/questions/71692505,2978125.0,1
378,42645165,Reevaluate dependencies of a while loop,"I am trying to understand how while loops work in tensorflow. In particular I have a variable, x say, that I update in the while loop, and then I have some values that depends on x, but when running the while loop the values does not seem to be updated when x changes. The following code where I have tried to implement a simple gradient decent optimizer might illustrate what I mean: Running this on tensorflow 1.0 gives this result for me: and the issue is that the value of the gradient is not updated as x changes. I have tried various variations on the above code, but can not seem to find a version that works. Basically my question is if the above can be made to work, or do I need to rethink the approach. (Maybe I should add that I am not interested in writing a gradient decent optimizer, I just built this to have something simple and understandable to work with.)",https://stackoverflow.com/questions/42645165,6850023.0,1
379,74508999,Get softmax output and raw output of the last layer of a model,"When creating a neural network for image classification, I want to get the classification on one hand and the raw output on the other hand to determine if the image really contains one of the images I want to classify or not. If not then the raw output should contain very low values for all classes. But if the image really contains one of the objects that I want to classify, then the raw output should have a high value for one of the neurons. Assuming I have the following code: How would I get the raw output of the last dense layer?",https://stackoverflow.com/questions/74508999,18057198.0,1
380,45043979,How to decode TFRecord data sample with variable length strings?,"Let's say we have a TFRecord file with data samples like this: Here encoded_jpg is the raw value of encoded 32x32 jpg images, the length of which can be quite different for different images; label is a fixed-length vector. For fixed-length fields, one can always use something like the following to decode the sample: But here the length of image/encoded is not constant, the aforementioned one doesn't work anymore. If I change the code into this: image/encoded is something like sparse tensor, I don't know how to decode the image from this stuff. Does anyone have similar experience before? Any suggestion is appreciated. Thanks!",https://stackoverflow.com/questions/45043979,,1
381,63101648,Flattened input layer shape,"The code below was taken from TensorFlow in Practice by deeplearning.ai course in Coursera (computer vision example - week 2). The question: How TensorFlow deduce the shape of the input layer? Which shape is being flattened here? The input shape should be derived from the shape of the input data, Am I missing something here?",https://stackoverflow.com/questions/63101648,4910008.0,1
382,67346696,Is it possible to use EinsumDense instead of multiple parallel Dense layers?,"I have an input of shape (None, 20, 250), where 20 is my context window and 250 my embedding dimension. I want to apply a different dense 250 -&gt; 250 for each element in the context window. The following code works and does what I want, but does not use Einsum: If I understand Einsum correctly, the following code should do the exact same: The documentation for EinsumDense states that ab,bc-&gt;ac would be equivalent to a dense layer, so I figured this should work. However I'm getting drastically different results when doing this. What am I doing wrong here?",https://stackoverflow.com/questions/67346696,15808690.0,1
383,72040565,How to create my own preprocessing layer in Tensorflow in python?,"I have a specific sequential model for preprocessing data as follows: However, I would like to add my own preprocessing layer, that is defined by the Python function below: How can I do that with TensorFlow? as a new preprocessing layer that will receive inputs and outputs from other layers, should I have to guarantee that the input and outputs are of a given type?",https://stackoverflow.com/questions/72040565,2163392.0,1
384,76161447,Randomness inside tf.function,"I have a unique application in tensorflow where I need to randomly sample from a constant tensor while computing the loss function for a neural network (this is different from sampling a batch from training data). Here's a simplified version: Is this the ""right"" way to do this? Does this implementation affect graph execution in any way?",https://stackoverflow.com/questions/76161447,5027427.0,1
385,47911104,How to make predictions with tf.estimator.Estimator from checkpoint?,"I just trained a CNN to recognise sunspots with tensorflow. My model is pretty much the same as this. The problem is that I cannot find anywhere a clear explanation on how to make predictions with the checkpoint generated by the training phase. Tried using the standard restore method: but then I cannot figure out how to run it. Tried using tf.estimator.Estimator.predict() like this: but what it does is spitting out &lt;generator object Estimator.predict at 0x10dda6bf8&gt;. While if I use the same code but with tf.estimator.Estimator.evaluate() it works like a charm (reloads the model, performs evaluation and sends it to TensorBoard). I know there are many similar questions but I couldn't really find the way that worked for me.",https://stackoverflow.com/questions/47911104,7697546.0,1
386,49963417,tf.py_func InvalidArgumentError,I'm trying to wrap a python function into tensorflow using tf.py_func() and getting an InvalidArgumentError which I don't understand. I'm passing two 2-d tensors and function returns a float value.,https://stackoverflow.com/questions/49963417,6735793.0,1
387,69738564,Setting specific entries to some value in Keras,"I have the following Keras model code: I want to set some outputs entries to new values based on inputs with the following code: However, it throws an error: TypeError: 'KerasTensor' object does not support item assignment. I've also tried using but it throws a different error: 'KerasTensor' object has no attribute 'assign' (however, it works with ordinary tensorflow tensors). So, is there a way to set some values of outputs to ones in the way I want? Example of what I want to do (using arrays): After outputs = outputs * inputs[..., :1] I get And with outputs[..., 0] = tf.ones_like(inputs[..., 0]) - inputs[..., 0] I want to get",https://stackoverflow.com/questions/69738564,5658683.0,1
388,47004783,TensorFlow's TensorBoard doesn't show event graph,"I'm following a simple ""Hello, World"" tutorial on TensorFlow and am trying to use TensorBoard to show the machine learning loss over multiple iterations of the gradient descent loss. I think I followed everything correctly in my Jupyter (IPython) notebook, but I don't think the events are being generated saved to the file for TensorBoard to visualize. Here is my code: When I then check out TensorBoard, there is only one point. There should be a graph with a curve. I also looked at my output file in the directory. It seems that not much has been written to the output file (only 84 bytes): What can I do to have TensorBoard show the events?",https://stackoverflow.com/questions/47004783,4561314.0,1
389,65334652,"Error subclassing model in Tensorflow 2 ""InaccessibleTensorError""","Background My question is based off an example from Hands-On Machine Learning by Geron, Chapter 12: Custom Models. The purpose of this example is to create a custom neural network model. The model has 5 Dense hidden layers. The custom part is that we add a reconstruction layer before the output. The purpose of the reconstruction layer is to reconstruct the inputs. Then we take the difference reconstruction-inputs, get the MSE, and apply this value to the loss function. It's supposed to be a regularization step. Minimum (should be) Working Example The following code is almost directly from the textbook, but it doesn't work. Error Message However, I get the following error while calling model.fit(): and, at the end of the error message: Troubleshooting If I comment out the code that computes the loss, i.e., in call, but I keep everything else the same, then I get the following warning Not sure if that's relevant.",https://stackoverflow.com/questions/65334652,2799466.0,1
390,69425981,How to create a dynamic number of layers in Tensorflow?,"In Keras, I would do the following to dynamically create a model's layers: however, in the case of Tensorflow, I have the following: where I would want to do something like: but I am unsure how to dynamically create this layer since the add function does not work in this context as it did in Keras.",https://stackoverflow.com/questions/69425981,7619808.0,1
391,65059742,Tensorflow - Numpy arrays and Shape error,"I am trying to build a Tensorflow simple AI and I don't understand where my problem is when I compare it to various articles I read about this topic. I have two numpy arrays made for training of sizes (N,1) (what should be predicted) and (N,3) (what are the inputs that should be predicted), and I want my algorithm to predict with Input[0,i] Input[1,i] Input[2,i] the value of ToPredict[i] (the i-th sample). I thought I had to use tf.data.Dataset.from_tensor_slices and then modele = tf.keras.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dense(1) ]) modele.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['sparse_categorical_accuracy']) modele.fit(A, epochs=10) from an example I got online. (here A represents the tf.data.Dataset.from_tensor_slices(Inputs_Learning,ToPredict_Learning)) When I do that, I get the following error: So I know that there is a shape error, but I don't know how to tell the algorithm what I want as shapes. Could anyone help me? Also yes I have seen related stackoverflow posts but they don't seem to solve my issue.",https://stackoverflow.com/questions/65059742,14729172.0,1
392,65913108,`tape` is required when a `Tensor` loss is passed,"Some question about tf. As I start the last line of my code, below error comes out. I know it is related with tensorflow version 2, but don't want to modify to version 1. Want a solution with tensorflow ver2. Thx.",https://stackoverflow.com/questions/65913108,15010729.0,1
393,50161455,'Tensor' object has no attribute 'assign_add',"I encountered error 'Tensor' object has no attribute 'assign_add' when I try to use the assign_add or assign_sub function. The code is shown below: I defined two tensor t1 and t2, with the same shape, and same data type. then I use the assign_add on t1 and t2 to create t3 then I try to create a new tensor t4 using t1[1] and t2[1], which are tensors with same shape and same data type. but got error, same error when using assign_sub Any idea where is wrong? Thanks.",https://stackoverflow.com/questions/50161455,4987560.0,1
394,52248293,How to write an argmax function in TensorFlow?,"I'm not talking about tf.argmax but about argmax in the mathematical sense, e.g. given a discrete set of values and a function find the value that maximizes it. I currently have something like this Now I want to define another TensorFlow node, max_Qhat, which will take an array of Tensors as its argument. It will feed each of these tensors to Qhat and return the one that resulted in the greatest value. How do I do this? (NOTE I am not looking to run Qhat, so no session.run. I just want to define a function that evaluates it.) Code I have so far:",https://stackoverflow.com/questions/52248293,4077294.0,1
395,58237726,Keras model fails to decrease loss,"I propose a example in which a tf.keras model fails to learn from very simple data. I'm using tensorflow-gpu==2.0.0, keras==2.3.0 and Python 3.7. At the end of my post, I give the Python code to reproduce the problem I observed. The samples are Numpy arrays of shape (6, 16, 16, 16, 3). To make things very simple, I only consider arrays full of 1s and 0s. Arrays with 1s are given the label 1 and arrays with 0s are given the label 0. I can generate some samples (in the following, n_samples = 240) with this code: In order to input this data in a tf.keras model, I create an instance of tf.data.Dataset using the code below. This will essentially create shuffled batches of BATCH_SIZE = 12 samples. I propose the following model to classify my samples: The model is optimized using Adam (with default parameters) and with the binary_crossentropy loss: The output of clf_model.summary() is: The model is trained for 500 epochs as follows:",https://stackoverflow.com/questions/58237726,8733347.0,1
396,40746229,TensorFlow not updating weights,"So I'm trying to create a VERY simple neural network with no hidden layers, just input (3 elements) and linear output (2 elements). I then define some variables to store configurations and weights I then create the training network I define the optimizer to minimize the square different between the target value and the training network And finally, I run some values in an infinite loop. However, the weights are never updated, they maintain the random values with which they were initialized I took the code from a working DQN implementation, so I figure I'm doing something blatantly wrong. The network should converge to: But they do not change at all. Any pointers? Turns out that clipping the loss is causing the issue. However, I don't understand why...",https://stackoverflow.com/questions/40746229,2015911.0,1
397,58653915,How to predict in multiple models consisting of tensorflow (.pb) model and keras model (.h5) at the same time in flask?,"I try to describe the situations completely. But due to my ability of language, there will be possible some unclear statements. Please let me know. I will try to explain my meaning. Recently, I want to apply facenet (I mean davisking's project on github) to my project. Therefore, I wrote a class I can use this class independent in flask. But I have different demands later. I train two models by using keras. I want to use them (.h5 model) with the above facenet model to predict. I load them first. I print the fake image to test the models. It seems to work normally. But when I run flask server and try to post an image to this api, the message pop up and the prediction doesn't work. I try to use these two keras model without loading facenet model in flask server. It works normally. I think that it must collide with something (maybe about session?) to make these three models cannot work simultaneously. But I don't know how to solve this problem. Please help me! Thanks in advance.",https://stackoverflow.com/questions/58653915,9805858.0,1
398,58176658,Retrain a SavedModel in Tensorflow,"Is there any example of retraining a SavedModel? In many places they claim it is possible, instead of using checkpoints, but not examples provided. When I have tried to carried out, the variables of the model remain fixed: The code above trains the model, stores every interaction in a model and print the associated error. The code has an output where the error is improving: 2773.6885 291.35968 263.40912 255.27612 When we load it again, and we try to train it, the error stays the same: The output is always the error from the initial training: 255.27612 255.27612 255.27612 255.27612",https://stackoverflow.com/questions/58176658,4671617.0,1
399,43489549,Tensorflow: Input pipeline with sparse data for the SVM estimator,"I am trying to train the tensorflow svm estimator tensorflow.contrib.learn.python.learn.estimators.svm with sparse data. Sample usage with sparse data at the github repo at tensorflow/contrib/learn/python/learn/estimators/svm_test.py#L167 (I am not allowed to post more links, so here the relative path). The svm estimator expects as parameter example_id_column and feature_columns, where the feature columns should be derived of class FeatureColumn such as tf.contrib.layers.feature_column.sparse_column_with_hash_bucket. See Github repo at tensorflow/contrib/learn/python/learn/estimators/svm.py#L85 and the documentation at tensorflow.org at python/contrib.layers#Feature_columns. The data that I use is the a1a dataset from the LIBSVM website. The data set has 123 features (that would correspond to 123 feature_columns if the data would be dense). I wrote an user op to read the data like tf.decode_csv() but for the LIBSVM format. The op returns the labels as dense tensor and the features as sparse tensor. My input pipeline: Here is an example batch with batch_size = 5. This is what I tried so far:",https://stackoverflow.com/questions/43489549,6581491.0,1
400,56326004,TensorFlow: Why is my Keras callback monitor value not available?,"I use TensorFlow 1.12. I try to fit a model using Keras callbacks: However, this throws the following error: Firstly, I do not understand how the string given to monitor is being resolved. I'm following two guides on Keras (1, 2), and both supply string names which aren't referenced anywhere else in their code. I assume these specify strings which the user can later use to retrieve the development of performance after training, rather than specify which metric fit is supposed to monitor? If so, why is it saying that the value isn't available? Secondly, answers to similar questions all point out that the problem is the absence of validation data. However, I am pretty sure that I am supplying fit with data, as evidenced by looping through val and counting the number of records. What am I doing wrong? For reference, my datasets are generated like this: My loss function looks as follows: I perform semantic segmentation, and the dice loss is calculated per pixel.",https://stackoverflow.com/questions/56326004,,1
401,37921781,What does opt.apply_gradients() do in TensorFlow?,"The documentation is not quite clear about this. I suppose the gradients one can obtain by opt.compute_gradients(E, [v]) contain the ∂E/∂x = g(x) for each element x of the tensor that v stores. Does opt.apply_gradients(grads_and_vars) essentially execute x ← -η·g(x), where η is the learning rate? That would imply that if I want to add a positive additive change p to the variable, I would need to need to change g(x) ← g(x) - (1/η)p, e.g. like this: Is there a better way to do this?",https://stackoverflow.com/questions/37921781,852592.0,1
402,42628143,Does Tensorflow simplify a computational graph?,"I have a simple question and I was also searching already quiet a bit, but maybe I'm using the wrong keywords. How does Tensorflow handle a given graph? If one has the simple graph: The arithmetic statement is of course given by the computational graph, but is Tensorflow then kind of compiling and simplifying it in terms of saving time by not copying memories, etc.? So that it a 'condensed' version of the computational kernel is executed on the 'device' like CPU or GPU? So that it reduces to something like that: Maybe somebody knows a good resource to learn more about how exactly Tensorflow runs under the hood without looking too deep into the source-code. Thank you very much in advance!",https://stackoverflow.com/questions/42628143,3015202.0,1
403,47656367,Getting predictions in Logistic Regression (tf),"I am new to Tensorflow and I still have troubles understanding how it works. I saw some examples but I am still not sure. I am trying to print the predictions and the accuracy. I have this code: So, now I want to actually read the values of y_pred and calculate the accuracy. In some other sources I saw people adding this line to with tf.Session() as sess: Clearly, it does not work for me, because my trainSetX has all the examples, while X is a placeholder for only 1 example at a time. I have tried to put the correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)) and modify another like like this: But it just gives the following arror for ArgMax (Why?) InvalidArgumentError (see above for traceback): Expected dimension in the range [0, 0), but got 1 [[Node: ArgMax_1 = ArgMax[T=DT_FLOAT, Tidx=DT_INT32, output_type=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_Placeholder_1_0_1, ArgMax/dimension)]]",https://stackoverflow.com/questions/47656367,8037521.0,1
404,62019212,Tensorflow input pipeline using text,"in the last weeks I tried to get the input pipeline running with tf.records under tensorflow (tf 2.0.1). From a CSV sentences are loaded and a record is generated: This works so far. This record should be loaded later, edited with a tf-hub model and then trained with the record. However, I either get an IndexEror or it fails completely: Has anyone perhaps tried something similar or an idea? Unfortunately the documentation didn't help much. Thanks in advance",https://stackoverflow.com/questions/62019212,9398272.0,1
405,56771305,Keras submodel needs to be built,I am creating a python class that inherits from a keras model. This gives me this error: It is fixed if I add one line after creating the model: But it doesn't look the best way of doing this. How can I fix it?,https://stackoverflow.com/questions/56771305,9652994.0,1
406,63716372,Does mixed tf.keras.mixed_precision work for inference?,"I am not sure if I understand the idea of tensorflow keras mixed precision. My goal is to run a tf.keras model with floating point 16 precision to improve inference speed. Can this be done with mixed precision? I am setting this policy before training my model: Or this is just to speed-up training. If this is the case, how could I achieve weights/activations of my tf.keras model to have FP16 precision? Note: I am using tensorflow==2.3.0",https://stackoverflow.com/questions/63716372,4544940.0,1
407,75056736,Keras custom loss returning nan,"I have the following model: Where I am using a custom weighted categorical crossentropy (CCC) loss, because the ""normal"" CCC does not work with weighting in my case because my output has too many dimensions. The loss itself seems to work fine when I call it on a test sample but for some reason it turns nan sometimes.: During training the first few epochs work fine, but at some point (usually between epoch 5-10) I suddenly get a nan loss and the training crashes and throws the following exception: I think it has something to do with my activation functions, that the loss turns nan which is then crashing due to the metrics. So I really need to find out how to stop my loss returning nan. I have this issue both with ReLU and LeakyReLU, but with LeakyReLU my model trains better (or atleast quicker in the first few epochs). I have already checked my data and there is no nan values in the data.",https://stackoverflow.com/questions/75056736,13981994.0,1
408,65998640,TensorFlow fit using dataset from generator with multiple outputs: Cannot properly define shapes?,"I am attempting to convert a project to a single network with multiple outputs using a generator but I cannot seem to work out how to get the multiple outputs to function properly when a generator is being used. Here is a minimally verifiable hunk of code: This results in a very long error, the final portion of which is: I have tried this using output_shape, output_signature, etc. with every way I can imagine reshaping the data. No matter what, I continue to run into shape problems. Am I missing something obvious here or is there something wrong in fit using a generator as a source for a dataset? I have no problem doing this when I'm loading the data from memory, for example.",https://stackoverflow.com/questions/65998640,2191105.0,1
409,50164090,Tensorflow ServingInputReceiver input shape error in client,"I'm currently working with tensorflow Estimator API and have problems with the confusing serving options that are available. My confusion comes from the very undetailed tensorflow documentation. This is my goal: Use tensorflow-serving prediction_service_pb2 by sending a serialized proto message as string to the ServingInputReceiver function of my exported Estimator model. I expect the ServingInputReceiver function to receive the serialized proto string on the ""input"" tensor which then will deserialize it to the features ""ink"" (=varlength float array) and ""shape"" (=fixedlength int64). This is my (implementation of google quickdraw model) estimator Input function: This is my Serving Input Function: This is my client.py request: And this is the error I get after calling the Predict function in client.py I tried the following Servingfunctions: ServingInputReceiver and build_raw_serving_input_receiver_fn give me the same grpc error. When I use build_parsing_serving_input_receiver_fn it wont even export my model. I tried to wrap my head around the documentation but it is very undetailed and I don't understand when to use which serving input function.",https://stackoverflow.com/questions/50164090,8804834.0,1
410,49364346,"When zipping two Datasets, some samples are never chosen",How come some samples are never picked when zipping two Datasets? Consider this toy example: This outputs The last 10 samples of d2 are never picked.,https://stackoverflow.com/questions/49364346,1735003.0,1
411,56615277,Why does this operation execute faster on CPU than GPU?,"When I was reading the tensorflow official guide, there is one example to show Explicit Device Placement of the operations. In the example, why does CPU executed time is less than GPU? More usually, what kind of operation will be executed faster on GPU?",https://stackoverflow.com/questions/56615277,7212365.0,1
412,58979037,HOWTO tf.estimator with continuous and categorical columns,"I have a tf.estimator which works for continuous variables and I want to expand it to use categorical variables. Consider a pandas dataframe which looks like this: To build the estimator for just the label and the continuous variable column (con_col) I build the following feature_column variable. Then I pass it to the DNNClassifer like so. Later I build a serving_input_fn(). In this function I also specify the columns. This routine is quite small and looks like this: This works. However, when I try to use the categorical column I have a problem. So using the categorical column, this part seems to work. For the serving_input_fn() I get suggestions from the stack trace but both suggestions fail.: This is the error message if try #0 is used. Lak's answer implementation Using Lak's answer as a guide, this works for both both feature columns.",https://stackoverflow.com/questions/58979037,1008596.0,1
413,61067132,Why is my custom loss (categorical cross-entropy) not working?,"I am working on some kind of framework for myself built on top of Tensorflow and Keras. As a start, I wrote just the core of the framework and implemented a first toy example. This toy example is just a classic feed forward network solivng XOR. It's probably not necessary to explain everything around it but I implemented the loss function like this: This will be used in the actual model class like this: Now, when it comes to training, I can train the model like this: or I can just set loss=mse. Both cases work as expected without any problems. However, I have another Modality class which I am using for sequence-to-sequence (e.g. translation) tasks. It looks like this: What this does is just reshaping the y_true and y_pred tensors [batch_size, seq_len, embedding_size] to [seq_len * batch_size, embedding_size] - effectively stacking all examples. From this, the categorical cross-entropy is calculated and normalized. Now, the model I am using is a very simple LSTM - this isn't important though. As I am training the model like this: The model does learn the task as expected. However, if I use the CategoricalCrossentropy-modality from above, setting loss=model.loss, the model does not converge at all. The loss oscillates randomly but does not converge. And this is where I am scrathing my head. Since the simple XOR-examples works, both ways, and since setting categorical_crossentropy works as well, I do not quite see why using said modality doesn't work. Am I doing something obviously wrong? I am sorry that I cannot provide a small example here but this not possible since the framework already consists of some lines of code. Empirically speaking, everything should work. Any ideas how I could track down the issue or what might be causing this?",https://stackoverflow.com/questions/61067132,826983.0,1
414,43421884,AttributeError: 'module' object has no attribute 'setup_graph',"I am new to deep learning and trying to implement code written here http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html. I am trying to implement same code but I am getting error while importing basic_rnn as written in the code: then I changed basic_rnn = tf.contrib.rnn.BasicRNNCell, then I am getting error I am assuming I will again get error in while implementing basic_rnn.RNN_config. What would be the correct syntax? I am using tensorflow of version 1.0.0 pls help",https://stackoverflow.com/questions/43421884,7419270.0,1
415,70244415,Own Dataset: ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type int),"I'm quite new to Tensorflow, and I've tried following a standard introductory example with a slightly different dataset. However, I'm getting an error and unable to proceed: along with: I've provided a minimum reproducible example from my dataset, if there are any other possible errors please let me know.",https://stackoverflow.com/questions/70244415,8770088.0,1
416,45660585,Tensor comparison does not work as expected,"I need to write a piece of code to understand if any of a tensor's entries have a specific value ""2"". This is the code I'm using for testing: And this is the error I'm getting: Surprisingly, if I change the == operator to &gt;= like this: it works fine, and returns: I was wondering what the problem might be, or if it's possible to do the same task in another way. Thanks in advance for any suggestion.",https://stackoverflow.com/questions/45660585,8458076.0,1
417,42608245,How to use tf.contrib.seq2seq.simple_decoder_fn_inference API,"I did not understand the parameters that needed to be passed into the API call to tf.contrib.seq2seq.simple_decoder_fn_inference in Tensorflow 1.0 for building the inference block for a Seq2Seq Attention mechanism RNN. Can someone explain, in detail, what each parameter of this function call means and is supposed to do? The link to the documentation is here : tf.contrib.seq2seq.attention_decoder_fn_inference()",https://stackoverflow.com/questions/42608245,7661539.0,1
418,68687448,Error in Tensorflow 2.5.0 while using Colab TPU - NotFoundError: Could not find metadata file. [Op.DatasetCardinality],"Note: These same steps work without any errors on Colab GPU. Please help me with this. I created a dataset and saved it as file When I try to load it and run any function on the data like len(data), data.batch(16) or data.take(1) then I get this error: TPU config Is it similar to this TF1.14][TPU]Can not use custom TFrecord dataset on Colab using TPU ?",https://stackoverflow.com/questions/68687448,3389828.0,1
419,58712548,Runtime Error : Session Graph is Empty. Add Operations to Graph,This above code is taken from tensorflow core r2.0 documentation But it gives the above error,https://stackoverflow.com/questions/58712548,11925201.0,1
420,52879126,How are tensors immutable in TensorFlow?,"I read the following sentence in the TensorFlow documentation: Can someone elaborate a little bit on the ""immutable"" aspect of a Tensor?",https://stackoverflow.com/questions/52879126,3926152.0,1
421,56105489,Implementation of adversarial examples generator using evolutionary algorithm performs poorly,"I am trying to implement evolutionary algorithm using MAP-Elites evolutionary strategy and polynomial mutation operator (as defined here at point 2.) as discussed in this paper. I created a three different MNIST models and trained them using tensorflow==2.0.0a using Keras API. The models are performing fine (all around 95% accuracy). My understanding of the mentioned evolutionary strategy is that we create a starting population and then with each iteration mutate a randomly chosen specimen from that population. If after the mutation the new specimen gets the certainty of belonging to any class higher than a previously chosen best specimen for that class then we treat it as the best and add it to population. The expected result is that after algorithm is finished we should have a specimen for each of the classes that manages to get classified within that class with high certainty. The initial population of images is created is created using uniform distribution. The issue is that my models classify random input created with uniform distribution always as the same class with high certainty (i.e CNN model always classifies it as 8). So most or all specimens i end up with are being classified as the same class (with slightly varying certainties of belonging to other classes) even after big starting population and number of iterations (i.e 1000 starting specimens and 20000 iterations). Input samples are normalized to range [0.0, 1.0]. All of the reasoning bellow is constrained for simplification sake just to Dense model (CNN, and simplified LeNet5 yield similar results) described at the bottom. Using normal distribution with mean=0.0 and stddev=0.3 or mean=0.5 and stddev=0.3 for generating starting population and mutation chance of 0.3 (instead of 0.1 as in paper) yields similar results. I tried using (1 , λ) evolutionary strategy with targeting just one class (starting population 100, 100 generations) and it yields better results than the MAP-Elites implemented bellow (i can generate specimen for more than one class). I tried not normalizing the data for model and training it again using [0, 255] range but the results were almost the same. I also tried using Gaussian mutation operator instead of polynomial but it didn't seem to make much of a difference. Turning off data augmentation when training doesn't seem to have effect. Here is the implementation i wrote. In the paper authors state that they were able to get specimens for each digit classified with &gt;99.99% confidence after 50 generations. This is vastly different from the results that i get. It seems that i am doing something wrong but i am unable to pinpoint the issue. I am not sure whether it is just some small bug in the code or is my reasoning behind implementation wrong. My model is constructed like this input_1 (InputLayer) [(None, 28, 28, 1)] 0 flatten (Flatten) (None, 784) 0 dense (Dense) (None, 784) 615440 dense_1 (Dense) (None, 800) 628000 dense_2 (Dense) (None, 800) 640800 dense_3 (Dense) (None, 10) 8010 It have been trained for multiple epochs with data augmentation using Adam optimizer. EDIT: i just noticed that i am not clipping values of specimens after mutation. If i do that then using normal distribution yields similar results to using uniform distribution. i fixed this in posted code. stupid mistake",https://stackoverflow.com/questions/56105489,4363423.0,1
422,50805501,TensorFlow: prediction not working properly,"I am having a few issues with the model that I've made. 1) Sometimes the prediction returns an array of 0s (But that might be normal). 2) If I repeat the prediction multiple times (using loops) I always get the same result. 3) Strangely enough, if I stop the program and rerun it, the prediction changes (point 2 still applies). 4) The results are wrong. I insert the same exact query as the training (the response predicted is correct while training), but I get a very different response. Now, the weird thing is that while training I can see that it is improving and that it is working fine. Here is the piece of code that displays the correct results (training): And this is the part that I'm having trouble with (prediction): That's it. I don't know why this happens. Any help is appreciated. I've also included the other methods for even more context. This is next_feed(): And this is batch_method:",https://stackoverflow.com/questions/50805501,9872568.0,1
423,63557713,How to use TensorFlow v2 for dataflow programming?,"I cannot find proper documentation on how to use TensorFlow v2 for basic dataflow programming. I can find many resources online about TensorFlow v1 but much of the behaviour they explain is now deprecated. For instance, the following python code works fine in TensorFlow v1: Here I have converted some python functions into tensorflow operations; I have defined a graph in which g depends on e and f which in turn depend on a,b,c,d; finally, I have executed a session and provided inputs for a,b,c,d. I can also avoid to provide all inputs and choose intermediate nodes instead: Here, I already provide f, instead of its dependencies c,d. How would something like this work in TensorFlow v2 (besides importing tensorflow.compat.v1)? Is TensorFlow v2 even thought to do something like this or is it just machine learning? Note: This is somehow connected to this question which deals with a much more complicated problem.",https://stackoverflow.com/questions/63557713,2668222.0,1
424,44295360,Why doesn't a TensorFlow cubic model work when an equivalent quadratic model works?,"In this sample code (mostly like the example code for a linear regression here), TensorFlow is supposed to find a, b, c, and d values for given points making up a cubic. In this case, it should be 0x^3 + 0x^2 + 1x + 0, but instead gets steadily larger and larger until it hits nan. The strange thing is that the same code with a modification to the line: model = a * x * x * x + b * x * x + c * x + d to model = a * x * x + b * x + c will give correct output (for a quadratic instead of cubic, of course). What's the issue? Code here:",https://stackoverflow.com/questions/44295360,6772171.0,1
425,41437364,Tensorflow Network Save and Restore,"I am trying to prepare a network with this architecture, My code structure is like Now, this model is tested with a online handwriting data. The network is working fine. But the problem is that the saving is restoring is not working properly. My CNN layer weight and bias variables have distinct names. I run the training for 100 epochs (pass 1). Then I am loading it again for pass 2 training. I have checked the weights and biases are loaded in pass 2 exactly as they are saved at the end of pass 1. But at the start of pass 2 the training loss is increasing w.r.t the loss at the end of pass 1. What am I doing wrong? Is it due to the optimizer configuration? Any help will be highly appreciated.",https://stackoverflow.com/questions/41437364,5367279.0,1
426,43686318,How run multiple operation together in one line in tensor session?,"I am learning tensorflow and i have two questions first is , is it necessery to run each opeation in session ? like if i create a simple program in which there are three operations addition and substraction and matrix multiply then is it necessary to run all those operation in session ? so now i have to run each operation (add,sub and matmul) in session ?? if ""yes"" i have to run then can i run all those operation together ? i tried but i got error : first i tried this : i got this error : so i removed one argument (mul) from run then i got this error : how i can run all operation once or i have to run each individually ? second during writing this code i tried to multiply two matrix with shape [2,3] my program was : i got this error : how multiply a=([1,2,3],[4,5,6]) b= ([9,8,7],[6,4,3]) ??",https://stackoverflow.com/questions/43686318,,1
427,53317523,Part 3: Switching between multiple contexts - no error and a bad exit code,"I've been struggling with managing multiple Keras models with tf.Graphs and tf.Sessions for several weeks now. In short, I'd like to have multiple models open and switch between them as needed. This includes training new models, opening from file and making predictions. The bottom line is: (almost) everything works fine until the program crashes with exit code 0xC0000005. No error messages are given. Let me explain. You get the point. This is how I currently manage the graphs and sessions. I use a context manager to set the created graph and session as defaults and later switch to the previous state. And with the above class, here's how a network is used elsewhere: Here are my previous efforts at articulating the problem. To the best of my abilities and with the help of some people, I've tried to come up with a way to manage these resources (context manager and ""closing"" the network after training). But I have not come across documentation or a tutorial describing the process of Tensorflow or Keras resource management in detail. My goals are two-fold. If you can help me achieve or even step a tiny amount towards the direction of either one, I'd greatly appreciate it! I have the experience, that my struggles are neither unique nor something that others haven't already thought of. So I must just be lacking the proper approach.",https://stackoverflow.com/questions/53317523,7089239.0,1
428,61030540,Example for Distributed learning using tensorflow and boosted trees,"I have traversed through numerous githubs, however i am unable to find an example where Tensorflow distributed learning was used with Boosted Trees Classifier estimator. All the tutorials are for Neural nets. I have slightly adapted the boosted trees code to work with distributed strategy as below: However, whenever i run this code, i get the error: So, i would be grateful if i could either get a way to debug this error or find an example which uses distributed learning with Boosted Trees.",https://stackoverflow.com/questions/61030540,13221678.0,1
429,42697341,"How to use softmax activation function at the output layer, but relus in the middle layers in TensorFlow?","I have a neural net of 3 hidden layers (so I have 5 layers in total). I want to use Rectified Linear Units at each of the hidden layers, but at the outermost layer I want to apply Softmax on the logits. I want to use the DNNClassifier. I have read the official documentation of the TensorFlow where for setting value of the parameter activation_fn they say: I know I can always write my own model and use any arbitrary combination of the activation functions. But as the DNNClassifier is more concrete, I want to resort to that. So far I have:",https://stackoverflow.com/questions/42697341,4933403.0,1
430,37966924,Why does tf.assign() slow the execution time?,"Today I add a learning rate decay to my LSTM in Tensorflow. I change to and run every train step However, this change increases the execution time from ~7 minutes to over ~20 minutes. My question is: Why does this change increase the execution time? An obvious work-around is to do the assignment only every 1000 iterations. However, I'd like to understand the reasoning behind this.",https://stackoverflow.com/questions/37966924,6104317.0,1
431,54820869,Calculating percentage of number with Tensorflow,"I have tried this: I am not seeing any numbers. I want to get the percentage done by tensorflow. Kindly, let me know what I am missing here. Even when I tried evaluating, I got session based error. It's true that I need o establish session, but do not know how I can call it inside. Please let me know if I missed something.",https://stackoverflow.com/questions/54820869,4948889.0,1
432,48814723,how to freeze the tensorflow model?,"I have a model.py file that save a class of rnn. for example: In my main.py, I used the following code to use this model. My question is how to freeze the model in the testing step? I know if I run training step, the weights of the model would be updated. But when I run testing step, I don't want to update the weights anymore, I only want to get the predicted results? How should I modify my code to make this happen?",https://stackoverflow.com/questions/48814723,4921197.0,1
433,71175695,Tensorflow conv1d/Keras Conv1D strange performance variation,"I am getting somewhat unexpected results when measuring the processing runtime of the Conv1D layer and wonder if anybody understands the results. Before going on I note that the observation is not only linked to the Conv1D layer but can be observed similarly for the tf.nn.conv1d function. The code I am using is very simple I was expecting to observe the first call to be slow and the others to show approximately similar runtime. It turns out that the behavior is quite different. Assuming the code above is stored in a script called debug_conv_speed.py I get the following on an NVIDIA GeForce GTX 1050 Ti where ... indicates approximately the same result. So as expected, the first time is slow, then for each input length, I get the same speed of about 550kHz. But then for the repetition, I am astonished to find all operations to run about 4 times faster, with 2MHz. The results are even more different on a GeForce GTX 1080. There the first time a length is used it runs at about 200kHz, and for the repetitions, I find a speed of 1.8MHz. In response to the https://stackoverflow.com/a/71184388/3932675 I add a second variant of the code that uses tf.function a the result after running on google's colab GPU This shows that with the given tf.function args retracing is not happening and the performance shows the same difference. Does anybody know how to explain this?",https://stackoverflow.com/questions/71175695,3932675.0,1
434,59504276,resave tf1.x saved_model.pb into new tf2.0 saved_model.pb,"I have an old trained tf1.x model (let it be Model1), constructed with Placeholders, tf.contrib and so on. I can use this model by restoring graph from .ckpt checkpoint in tf.Session (in tf1.x). I resolved the easiest way to use the Model1 is to export it: I can use the obtained saved_model.pb even in tf2.0: Now imagine, I have a pre/post processing written with tf2.0 tf.function. I wish the construction of preprocessing -&gt; Model1-&gt; postprocessing to be exported in a single saved_model.pb in tf2.0. And here come the problems due to saved_model.pb of Model1 utilizes tf.Placeholders (smth like this, I'm not an expert here). At the same time, I can easily build saved_model.pb from other tf2.0 exported model: But when I'm trying to do the same, except replacing first saved_model.pb from tf2.0 saving on tf1.x saving, It doesn't work: Now switch to tf2.0 and try to build new saved_model.pb with first one as a part of a computing graph: So the question is: how to save this architecture in a single saved_model.pb in tf2.0 preprocessing (tf2.0 @tf.function) -&gt; Model1 (saved_model.pb created in tf1.x) -&gt; postprocessing (tf2.0 @tf.function)",https://stackoverflow.com/questions/59504276,5030761.0,1
435,43599416,tf.gradients return all zero vector when called on a tf.gradients result,"I have the following code snippet: Where Discriminator corresponds to a neural network. The first call to tf.gradients is working correctly and I get back non-zero slope values in the gradients variable. However, whenever I try to find the second derivative by applying tf.gradients to the gradients variable, my result is always a vector of zeroes. I don't expect this to be the case because it shouldn't be perfectly linear, am I using tf.gradients incorrectly?",https://stackoverflow.com/questions/43599416,7916440.0,1
436,60377677,How to compute hessian in tensorflow 2.0?,https://www.tensorflow.org/api_docs/python/tf/hessians Typical approach should be to do But of course the transpose does not work like that through the tape. tf.hessian has no example in the docs. I think it might be from tf 1.0. UPDATE: use tf.jacobian,https://stackoverflow.com/questions/60377677,287238.0,1
437,62847518,"ValueError: Shapes (None, 2) and (None, 1) are incompatible",I'm training a model to identify foreign objects in an image. This is my data generator: I've loaded Resnet and tried to do transfer learning. This is the model creation: When I'm compiling with accuracy metrics: and try to fit it: it runs successfully and gives the accuracy results. but when I change in Compile the metric to AUC: I get an error: Can someone assists with an idea of how to solve that?,https://stackoverflow.com/questions/62847518,5139410.0,1
438,61745573,regularization with customized training in tf.keras (TF2.0),"I have a keras model with regularization initialized with kernel_regularizer. In the customized training loop, where GradientTape is used, does optimizer.apply_gradients applies regularization loss automatically? if not, the following code shows an implementation, is that a good way to apply regularization? Am I doing the right way?",https://stackoverflow.com/questions/61745573,13523418.0,1
439,76447111,where is the documentation of keras.engine.sequential.Sequential?,"I got &lt;class 'keras.engine.sequential.Sequential'&gt;. I need documentation of keras.engine.sequential.Sequential, but can't locate it.",https://stackoverflow.com/questions/76447111,3646484.0,1
440,59216666,Callback to add boxplots in Tensorboard / cannot use .numpy() in on_batch_end,I want to add in Tensorboard a boxplot of the final values returned by the model during training. Even though I have enforced eager execution I can't make this work because I can't access model output values in on_batch_end methods. MWE:,https://stackoverflow.com/questions/59216666,4444546.0,1
441,35065524,Accuracy remains identical between Tensorflow runs,"I've been trying to utilise Tensorflow to gauge it's suitability for classifying data that I'm studying on a Huntington Disease project (not relevant to the problem, just providing context). Previously, I was using Support Vector Machines to classify my data, which were 'ok'. I'm hoping NNetworks are better. Loading the data is fine, no issues there. After reading the documentation for Tensorflow, and following some tutorials and examples online, I wrote the following to do a very simple network example with CSV data. The data I use in this provided example is the standard MNIST image database, but in CSV format. All functional. Train, test and onehot arrays are all the correct size and populated with the correct values. The actual tensorflow code is where I am most likely going wrong (?). Each output of this code always produces the exact same accuracy, and I can't figure out why. I have went back and looked at the tutorials, and examples I learned from. The iris dataset (loaded in the same manner) produced a proper output that predicted accurately. Yet, this code with the MNIST CSV data does not. Any insight would be appreciated. EDIT 1: So I had a few minutes and tried some of your suggestions, to no avail. I also decided to go back and test things with the Iris CSV dataset, for comparisons sake. Output is slightly different after use sess.run(train_step, feed=dict={...}: Values generally hover around this range, until it reaches Run 64, where it is locked at:",https://stackoverflow.com/questions/35065524,5852644.0,1
442,58571072,How to load local images in tensorflow?,"I found from the tensorflow documentation that the code to load a dataset named ""flower_photos "" is I'm having some images in my local machine and want to load and use it for doing some neural network algorithms like CNN. How to load and preprocess a locally stored image in tensorflow?",https://stackoverflow.com/questions/58571072,6733836.0,1
443,68651758,Printing outcome probabilities from a trained Keras Model,"I am attempting to print the predicted probabilities of each class outcome from my trained model, when I present new raw data. This is a multi-class classification problem, with 8 outputs and 21 inputs. I am able to print 1 outcome when I present new data, for example: Instead, I would expect to see something similar to the below. Where the probabilities of each class (0, 1, 2, 3, 4, 6, Wide, Out) are shown: Please note I have tried searching for similar issues including here, here and here as well as consulted the TensorFlow documentation. However, these mainly discuss alterations to the model itself e.g. softmax activation on the final layer, categorical crossentropy as the loss function etc. so that probabilities are generated. I have included the model architecture as well as the prediction code for full visibility. Model: Making predictions: Output: I have tried making changes to the for loop which makes use of TensorFlow's logits, but I am still unable to get it to print each outcome and associated probability. Any guidance is much appreciated.",https://stackoverflow.com/questions/68651758,16306039.0,1
444,48558181,variables_to_train flag in Tf-slim,"I am fine-tuning my model from a pretrained model using TF-Slim. When I used the create_train_op, I found that it has a parameter that is variables_to_train. In some tutorial, it used the flag as follows: But in the official TF-Slim, it does not use So, what is different between with and without using variables_to_train?",https://stackoverflow.com/questions/48558181,2938494.0,1
445,76144678,How to handle pipelines in tensorflow vs sklearn,"I'm just started studying deep learning and I'm trying to implement pipelines for a better data flow. I come from a scikit learn background where pipelines are pretty straight forward: ) Just state your transformations and attach a model to fit at the end. On the other side, with Tensorflow's tf.data it's much more cumbersome: Now, my problem lies specifically with how this pipeline is implemented (not with the model), since you are supposed to keep adding methods to the dataset to complete the pipeline. I know it's possible to combine tensorflow models into sklearn pipelines via a keras wrapper: So now I'm wondering on what are the best practices as to code readability, performance, optimization, etc. As far as I know Tensorflow is very optimized so i don't know what the impact would be if i used sklearn api, but then again I think sklearn pipelines have better functionalities, as well as ease of ensembling with other machine learning models. So, should I just stick with tf.data, or is combining sklearn with tensorflow a good alternative?",https://stackoverflow.com/questions/76144678,12350323.0,1
446,46677935,No gradients provided in tensorflow (mean_squared_error),"I'm trying to build a simple net of 2 input neurons (+1 bias) going into 1 output neuron to teach it the ""and""-function. It's based on the mnist-clissification example, so it might be overly complex for the task, but it's about the general structure of such nets for me, so please don't say ""you can just do it in numpy"" or something, it's about tensorflow NNs for me. So here is the code:",https://stackoverflow.com/questions/46677935,8484798.0,1
447,56417975,How to limit GPU memory use in TF Slim?,"When training using TF Slim's train_image_classifier.py I would like to tell Slim to only allocate what GPU memory it needs, rather than allocating all the memory. Were I using straight up TF and not Slim I could say this: Or even just this to put a hard cap on GPU memory use: How can I tell Slim the same thing(s)? My comprehension fail is that Slim seems to use it's own loop and I can't find docs on the nitty gritty of configuring the loop. So, even if someone could point me to good Slim docs that'd be fantastic. Thanks in advance!",https://stackoverflow.com/questions/56417975,,1
448,52058758,How to create own dataset for using Mask-RCNN models from the Tensorflow Object Detection API?,"I do not quite understand this guide: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/instance_segmentation.md I have many objects of three classes. According to the guide I have to make mask with dimension [N, H, W], where: I have this function to create a mask I use this guide for creating my dataset: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md I add a mask to the end of tf_example Because of reshape (I suppose), RAM quickly runs out and I get a memory error. What am I doing wrong? Maybe somewhere there is a detailed guide, how to create a mask for using Mask-RCNN and Tensorflow Object Detection API? I did not find this.",https://stackoverflow.com/questions/52058758,6588796.0,1
449,47459225,ValueError: ConvLSTMCell and dynamic_rnn,"I'm trying to build a seq2seq model in tensorflow (1.4) using the tf.contrib.rnn.ConvLSTMCell API together with the tf.nn.dynamic_rnn API, but I got an error with the dimension of the inputs. My code is: I get the following error Looking at the tf implementation, it seems that the inputs to dynamic_rnn is only 3-dimensional in contrary to the hidden state, which is 4-dimensional. I tried to pass the input as a nested tuple, but it didn't work. The problem is similar to TensorFlow dynamic_rnn regressor: ValueError dimension mismatch, it's slightly different though, as they're using a plain LSTMCell (which worked for me). Can anyone give me a minimal example how to use these 2 APIs together? Thanks!",https://stackoverflow.com/questions/47459225,8461333.0,1
450,65511729,Tensorflow SavedModel ignoring Assets File on Load,"I fine-tuned a BERT model from Tensorflow hub to build a simple sentiment analyzer. The model trains and runs fine. On export, I simply used: tf.saved_model.save(model, export_dir='models') And this works just fine.. until I reboot. On a reboot, the model no longer loads. I've tried using a Keras loader as well as the Tensorflow Server, and I get the same error. I get the following error message: The model is trying to load assets from the tfhub modules cache, which is wiped by reboot. I know I could persist the cache, but I don't want to do that because I want to be able to generate models and then copy them over to a separate application without worrying about the cache. The crux of it is that I don't think it's necessary to look in the cache for the assets at all. The model was saved with an assets folder wherein vocab.txt was generated, so in order to find the assets it just needs to look in its own assets folder (I think). However, it doesn't seem to be doing that. Is there any way to change this behaviour? Added the code for building and exporting the model (it's not a clever model, just prototyping my workflow):",https://stackoverflow.com/questions/65511729,1605795.0,1
451,60299104,How is data from tf.data generated and passed to the model,"In the book Hands-On ML with Scikit-Learn, Tensorflow and Keras, the author explains using the Data API to manipulate, transform and pass data to the model efficiently, he writes the following function: Then : train_set = csv_reader_dataset(train_filepaths) and: model.fit(train_set, epochs=10) What I don't understand is the part where he creates the actual train_set from the function, isn't that way he only has one batch of data? He says that we create a training set once and don't need to repeat it as it will be taken care of by Keras but I don't see how.",https://stackoverflow.com/questions/60299104,8277282.0,1
452,48754467,Function approximation Tensorflow,"I am trying to create a neural network in Tensorflow that approximates a sine function. I have found some examples of universal function approximators but I am not fully understanding the code and, since I am quite new with Tensorflow, I would like to code it myself to understand every step. This is my code: If you run that program you will see how the loss diverges and I don't know why it behaves like that. Could anyone help me? Thank you!",https://stackoverflow.com/questions/48754467,6321698.0,1
453,72249693,Why the tuned number of hidden layers (show 3) is not the same as the units (show 4 units) when tuning an ANN model using KerasTurner?,"I am currently using the KerasTuner to tune my Artificial Neural Network (ANN) deep learning model for a binary classification project (tabular dataset ). Below is my function to build the model: Codes of creating tuner: The best result shows that I have to use 3 hidden layers. However, why there is a total of 4 hidden layers shown? If I didn't misunderstand, the num_layers parameter indicates how many hidden layers I have to use in my ANN, and parameters units_0 to units_3 indicate how many neurons I have to use in each hidden layer where units_0 refers to the first hidden layer, units_1 refers to the second hidden layer and so forth. The input layer of my ANN should equal the number of features in my dataset which is 67 as shown in my code above (within the build_model function), so I believe the units_0 does not refer to the number of neurons in the input layer. Is there something wrong with my code? Hope any gurus here can solve my doubt and problem!",https://stackoverflow.com/questions/72249693,13974275.0,1
454,49880372,"What is the difference between ""y=x"" and y=tf.identity(x) in tensorflow","I am confusing about following code: y = x and y = tf.identity(x). More precisely, I get confusing when I run following code snippets: code 1: This will give output: 0.0 0.0 0.0 0.0 0.0 Code 2: The only change is from y=x to y=tf.identity(x), but now the results is 1.0 2.0 3.0 4.0 5.0 Thank you very much.",https://stackoverflow.com/questions/49880372,4644118.0,1
455,56106447,What is the right way of using Saver parameter `keep_checkpoint_every_n_hours`?,"I want to save my tensorflow variables every 5 hours during training. So, according to Tensorflow Saver doc, I constructed saver = Saver with parameter keep_checkpoint_every_n_hours=5, and called saver.save() for every step of learning. So what I expected was the saver module somehow detects the time passed after starting the training, and save the model every 5 hours, instead of actually saving model for every step where it is called. Below simplifies how i used the feature. However, I found out that by doing this way, the model is saved every time when the function is called. I guess I'm missing something or not using it in proper way. I want to know the proper way of using the feature of the tensorflow Saver. Thank you in advance.",https://stackoverflow.com/questions/56106447,7789561.0,1
456,51829971,"tf.data.Dataset.from_tensor_slices, tensors and eager mode","Using Iris dataset example: Imports used: I downloaded the dataset and then I used pd.read to represent train_plantfeatures, train_categories arrays. After that I used tf.contrib.keras.utils.to_categorical to create the categorical representation. When I tried to use tf.data.Dataset and from_tensor_slices I received: Same implementation without eager mode works perfectly.Here the Colab example",https://stackoverflow.com/questions/51829971,1093708.0,1
457,48134099,CNN performs worse than fully connected net - how to spot mistakes?,"I'm experimenting with CNNs and I'm baffled, because model I've built actually learns slower and performs worse than fully connected NN. Here are two models: fully connected: CNN: Basically CNN have a little more shallow fully connected net, but added conv layers vs just fully connected. CNN arrives to accuracy ~88% vs 92% of deep nn after same number of epochs and same dataset. How to debug issues like that? What are good practices in designing conv layers?",https://stackoverflow.com/questions/48134099,459519.0,1
458,63858339,Obtaining the Probability of a Sentence using a Language Model,"I have trained a language model using the following architecture, Note that I have used a pre-trained layer of word embeddings for this purpose. What I would like to do now is, given an entirely new sentence, to generate the probability of that sequence based on this language model. This is not about predicting the next word in the sequence, but about generating the probability of the entire sentence provided. How do I do this in TensorFlow 2? I have seen similar questions posted based on TensorFlow 1, but not with relation to the new version.",https://stackoverflow.com/questions/63858339,9542989.0,1
459,62844452,Using softmax as output function while using binary_crossentropy as loss function?,"Currently I am training a model for binary classification. I liked the idea of having two probabilities (one for each of the existing classes) which add up to 1. So I used softmax in my output layer and have gotten very high accuracies (up to 99,5%) with also very low losses of 0,007. While researching a bit I found that binary crossentropy is the only real choice when training for a 2 dimensional classification problem. Now I am getting confused if I have to use a classification_crossentropy as lossfunction when I want to use softmax. Could you help me to understand what should be used as loss function and activation function in a binary classification problem and why? Heres my code:",https://stackoverflow.com/questions/62844452,8305027.0,1
460,75726853,Attaching two parts of a pandas data frame in a Tensor of type tensorflow.python.data.ops.dataset_ops.PrefetchDataset,"I want to run a Neural Network on my data and for preprocessing I want to create tensor including two element: The first element including inputs in the form of a array of shape (100,4) and the other one of shape of (100,1): I have created these two Tensors by using below codes: Can anyone help, please? I have tried concat but there are some errors each time I alter my method....",https://stackoverflow.com/questions/75726853,20696272.0,1
461,63830441,what is the pytorch equivalent of a tensorflow linear regression?,"I am learning pytorch, that to do a basic linear regression on this data created this way here: I know that using tensorflow this code can solve: but I need to know what the pytorch equivalent would be like, what I tried to do was this: But the model doesn't learn anything, I don't know what I can do anymore. The input/output dimensions is (1/1)",https://stackoverflow.com/questions/63830441,10856009.0,1
462,60607402,Style Transfer : Save&Restore checkpoint/model in tensorflow 1.15.0,"i am a bit frustrated about saving and restoring models in tensorflow 1.15.0. I want to achieve it in a jupyter notebook / google colab notebook environment. The application is style-transfer of images. I simply want to save the model and restore it in order to apply the style transfer for a larger number of images. The tensorflow documentation is a bit confusing, (i did not find examples for this), so i never really know what the right syntax looks like. I am at a point now where i want to achieve 1 thing: I will write the relevant lines now: When i want to restore the model, i use the command: How can i fix this issue, and load my checkpoint files correctly? Thank you The google colab project is here: https://colab.research.google.com/drive/12hTitoQ2-tH8pYEsfMDR5jtsg8a96PgC",https://stackoverflow.com/questions/60607402,8092502.0,1
463,54516938,Weights decay on evaluation step - Tensorflow,"My weights are defined as I want to use the weights decay so I add, for example, the argument to the tf.get_variable. Now I'm wondering if during the evaluation phase this is still correct or maybe I have to set the regularizer factor to 0. There is also another argument trainable. The documentation says If True also add the variable to the graph collection GraphKeys.TRAINABLE_VARIABLES. which is not clear to me. Should I use it? Can someone explain to me if the weights decay effects in a sort of wrong way the evaluation step? How can I solve in that case?",https://stackoverflow.com/questions/54516938,9540764.0,1
464,39882623,"In Tensorflow, how can you check if gradients are correct for your custom operation?","My question is, how backpropatation paths are determined e.g., when using tf.slice? Let me take an example. Let's say, I have a K-classification problem. I can do this in a standard way like In this case, the gradient of loss will backpropagate to each weights. Let's say, I calcuated a custom loss value by slicing labels and fc2 output (maybe since I think a certain class is more important?) In this case, I am not getting how back-propagation would work. From the ""slicing"", didn't we lose backprob paths? This might be a weird pseudo-code, but my question is ""when using tf.slice, how backpropagation work?""",https://stackoverflow.com/questions/39882623,3251207.0,1
465,62365769,Train DL model using tf.data.Dataset,"I'm trying to do a simple Deep Learning task to learn how to use Tensorflow (and especially its Dataset tool). The task is the following : training a model which can tell if the sum of a given sequence of floats (length is fixed) is positive (labelled as 1) or negative (labelled as 0). I did the following without using tf.data.Dataset and it works well. Still, when I'm trying to do the same using a tf.data.Dataset input, I'm getting an error at the training step model.fit(...) Here is my code : I get the following error : Even changing the input_shape to (6, 1) doesn't make it worked. Is there a kind soul to enlighten a lost sheep like me ?",https://stackoverflow.com/questions/62365769,11779147.0,1
466,71921640,how to make DataFlow from CSV in googleDrive to tf DataSet - in Colab,"according to the instructions in Colab I could get buffer &amp; even take a pd.DataFrame from it (file is just example)... But have trouble with correct creation of dataFlow to Dataset - ""buf"" var is not working in =&gt; only ""csv_file_path"" as 1st arg. Is it possible in Colab to get IO from my GoogleDrive's csv-file into Dataset (used further in training)? And how to do it in a memory-efficient manner?.. P.S. I understand that I perhaps can make file opened for all (in GoogleDrive) &amp; get url to use the simple way: ! but I DON'T need to share real file... How to save file confidential &amp; get IO from it (in GoogleDrive) to tf.data.Dataset in Colab ? (preferably the shortest code - there will be much more code in real project tested in Colab)",https://stackoverflow.com/questions/71921640,15893581.0,1
467,55172653,Cannot initialize variable with a placeholder in tensorflow,How does one go about creating variables with placeholders as initializers? The following graph breaks down with: My code: The documentation on initializers in tensorflow says: However if i comment out the line where i create b the code seems to run. My fetch is not even dependent upon b. How do i go about creating variables that initialize according to some placeholder?,https://stackoverflow.com/questions/55172653,6546694.0,1
468,68673736,Is there a way for TFF clients to have internal states without sending them to server? tf.function prevents updating internal states,"Similar to this Is there a way for TFF clients to have internal states? question, but I dont want to send internal states to server. When I looked at the stateful clients example we can see we had sent client states to server where they would eventually be the output of next_fn and get updated outside the entire tf.function/tff.tf_computation/tff.federated_computation structure As far as I understand this is because tf.function() has some issues with mutating class attributes of its inputs Is there any way to workaround this so I can simply keep and update client states without doing federated aggregation.",https://stackoverflow.com/questions/68673736,16428078.0,1
469,50027652,Tensorflow Error: Attempting to use uninitialized value beta1_power_18,This is my code in tensorflow for simple neural network: When I run this using : I'm getting this error: What am I doing wrong?,https://stackoverflow.com/questions/50027652,5502316.0,1
470,38641104,Tensorflow Relu Misunderstanding,"I've recently been doing a Udacity Deep Learning course which is based around TensorFlow. I have a simple MNIST program which is about 92% accurate: My next assignment it to Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units nn.relu() and 1024 hidden nodes I am having a mental block about this. Currently I have a 784 x 10 Matrix of weights, and a 10 element long bias vector. I don't understand how I connect the resulting 10 element vector from WX + Bias to 1024 Relus. If anyone could explain this to me I'd be very grateful.",https://stackoverflow.com/questions/38641104,1747088.0,1
471,58530328,Cannot obtain the output of intermediate sub-model layers with tf2.0/keras,"Say we use TensorFlow r2.0 and say we want to use sub-models in Keras, so we have a model A like this: and model B that makes use of model A: This works like a charm. We can instantiate a model B like this: And benefit from all the advantages of a tf.keras.Model. But, the problem arises when we want to obtain the result of an intermediate layer that is of sub-model A. If the layer is part of model B, everything works: But if the layer is of sub-model A, it crashes with a ValueError. This command: Gives: I'm not sure I understand all the inside mechanics of keras. But what I understand when I dove in the source code, is that sub-models used this way have two input tensors object created. They can be printed like this: One is the sub-model tf.keras.Input and the other one is the input linked to the top-model. When building a new model from a top-model B input tensor to a top-model B output tensor, the path in the graph seems to correctly pass by the 'batch_normalization_5' input and both tensors are correctly connected in the graph. However, when trying to link a top-model B input tensor to a sub-model A output tensor, the output tensors seems to be connected to the sub-model tf.keras.Input and both tensors are disconnected. A solution I found at the moment is to use the top-model version of the tensor model.get_layer('A_3').output: But this seems overcomplicated and not clean... In addition, it does not let us make use of the layers inside model A. I wonder if someone could give me some precision on this particular tf.keras behavior. Am I right to do so? Is this the intended behavior? Is this a bug? Thanks a lot!",https://stackoverflow.com/questions/58530328,4163977.0,1
472,34556932,XOR gate with a neural network,"I was trying to implement an XOR gate with tensorflow. I succeeded in implementing that, but i don't fully understand why it works. I got help from stackoverflow posts here and here. So both with one hot true and without one hot true outputs. Here is the network as i understood, in order to set things clear. My Question #1: Notice the RELU function and Sigmoid function. Why we need that(specifically the RELU function)? You may say that in order to achieve non linearity. I understand how RELU achieves non-linearity. I got the answer from here. Now from what I understand the difference between using RELU and without using RELU is this(see the picture).[I tested the tf.nn.relu function. The output is like this] Now, if the first function works, why not the second function? From my perspective RELU achieves non-linearity by combining multiple linear functions. So both is linear function(upper two). If first one achieves non linearity, 2nd one should too, shouldn't it? The question is that, without using the RELU why the network gets stuck? XOR gate with one hot true outputs The code you see above implements the XOR gate with one hot true outputs. If i take out tf.nn.relu, the network gets stuck. Why? My Question #2: How can I understand if a network is going to get stuck on some local minima[or some value]? Is it from the plot of cost function (or loss function)? Say, for the network designed above, I used cross entropy as the loss function. I could not find the plotting of cross entropy function. (If you can provide this, this would be very helpful.) My Question #3: Notice on the code there is a line hidden1_neuron = 10. It means that i have set the number of neurons in the hidden layer 10. Reducing the number of neurons to 5 makes the network to get stuck. So what should be the number of neurons on hidden layer? The output when the network works the way it is supposed to : The output when the network gets stuck:",https://stackoverflow.com/questions/34556932,4341948.0,1
473,41875067,TensorFlow tf.equal() operator doesn't work as expected,"I wrote the following code, but it doesn't work like I expect. I expected that 'true' would be printed, but instead 'false' is printed. Can you explain why this happens?",https://stackoverflow.com/questions/41875067,7474000.0,1
474,61215270,input_shape with image_generator in Tensorflow,"I'm trying to use this approach in Tensorflow 2.X to load large dataset that does not fit in memory. I have a folder with X sub-folders that contains images. Each sub-folder is a class. I create my data generator from my folder like this: I've did a smaller dataset to test the pipeline. Only 629 images in 2 classes. Now I can create a dummy model like this: Once compile I try to fit this dummy model: From what i understand, the last batch doesn't has the same shape has the previous batches. So it crashes. I've tried to specify a batch_input_shape. I've found here that I should put None to not specify the number of elements in the batch so it can be dynamic. But no success. Edit: From the comment I had 2 mistakes: Here is the final code:",https://stackoverflow.com/questions/61215270,5462743.0,1
475,45943779,Tensorflow - How do I split an image in half?,"I want to split an image in to two pieces so that I can process the first piece on GPU #1 and the second piece on GPU #2. Here's the problem, though: I can't seem to split the image in half Now comes the tricky part. How do I split the image in half? Here is pseudo code of what I want to do I've tried to get the image shape using image_float32.get_shape().as_list(), which returns [None,None,3]. I've also tried x=tf.shape(image_float32)[0], but that returns I know about tf.split, but I don't know how to split the image in the way I want in my pseudo code. Any ideas?",https://stackoverflow.com/questions/45943779,7093236.0,1
476,66912115,Confused about keras output,"I am using the Keras functional API and I am confused about the output. What I am confused about is why is my output is (None,100,100,9) when I thought it would be (None,25,25,768). I have a feeling is something to with my model2 but I have no idea how to get the correct shape. Any help is much appreciated.",https://stackoverflow.com/questions/66912115,13735830.0,1
477,62067434,Custom binarize (thresholding) image layer in TensorFlow 2.2,"I am building a CNN in Tensorflow whose output needs to be a binary image (0, 1). I'd like to implement a custom layer with a single tunable variable (threshold) that will format the final image, e.g.: I have attempted to implement this as: However, this results in ValueError: An operation has 'None' for gradient.. Is there a way around this? I have tried adding tf.stop_gradient() to all of the parts of ""call"", but the error persists.",https://stackoverflow.com/questions/62067434,3986485.0,1
478,44558833,How to get the number of the neurons in the fully-connected layer?,"I saw an example code about a CNN with tensorflow, but I can't understand why the fully-connected layer is (3456, 784), can you tell how to get these number from the convolutional Layer. The input is an 80*100 image and 4 input channels. Here is the code. Thank you very much.",https://stackoverflow.com/questions/44558833,2011225.0,1
479,55552715,Tensorflow 2.0: minimize a simple function,Yields ValueError: This looks like the examples they partially give. I'm not sure if this is a bug with eager or 2.0 or something I am doing wrong. UPDATE: Pasted an embellished version of the solution below as there were some issues and interesting notes.,https://stackoverflow.com/questions/55552715,287238.0,1
480,42315202,Understanding TensorBoard (weight) histograms,"It is really straightforward to see and understand the scalar values in TensorBoard. However, it's not clear how to understand histogram graphs. For example, they are the histograms of my network weights. (After fixing a bug thanks to sunside) What is the best way to interpret these? Layer 1 weights look mostly flat, what does this mean? I added the network construction code here.",https://stackoverflow.com/questions/42315202,364772.0,1
481,50666681,How to load MNIST via TensorFlow (including download)?,"The TensorFlow documentation for MNIST recommends multiple different ways to load the MNIST dataset: All ways described in the documentation throw many deprecated warnings with TensorFlow 1.8. The way I'm currently loading MNIST and creating batches for training: How could I do exactly the same thing, just with the current method of doing this? I couldn't find any documentation on this. It seems to me that the new way is something in the lines of: But how can I use these datasets in my train_run and test_run method?",https://stackoverflow.com/questions/50666681,2230045.0,1
482,49419477,tf.train.range_input_producer doesnot work,"there ,I am new to tensorflow,when I am trying tf.train.range_input_producer, it does not work from my code: I get the size of my queue is :0 what is the wrong going on with my code ?Thanks in advance!",https://stackoverflow.com/questions/49419477,7117816.0,1
483,47406652,How to correctly implement Keras's fit_generator on multiple datasets?,"I am having a problem implementing Keras's fit_generator function. I have followed the Keras documentation and numerous other documentation online. But I can't seem to get this thing to work. When I run the fit_generator, it is not throwing an error. I could tell that something is running in the background since my GPU usage on my task manager skyrockets to 70% processing. However, there is no text/verbose that says that the batches are being processed for my convolutional neural network. I have six hdf5 files that I want to loop through that each contain 40,000 images. They are already formatted as Numpy arrays. I am yielding a batch size of 20 each time. When fitting my model with my generator, I know that my GPU is processing the data; I've got an NVIDIA GTX 1070. But there is no verbose/text displayed when running this code below. I also tried running without GPU, but still no luck. Is there something I'm doing wrong here?",https://stackoverflow.com/questions/47406652,5187714.0,1
484,62950167,Why loss function is inside tf.GradientTape block and gradients calculation is outside?,"I am new in Tensorflow. In the textbook example I saw the following code designed to train simple linear model using Tensorflow 2.x API: Why it is necessary to include the definition of loss function into the block with tf.GradientTape() as tape , but gradients = tape.gradient(loss, [m, b]) code line is outside with block? I understand that it may be Python language specific, but this construction seems unclear to me. What is the role of Python context manager here?",https://stackoverflow.com/questions/62950167,6194150.0,1
485,76142861,Behavior of Tensorflow's GradientTape when target is not a scalar,"Can somebody explain to me the shape and value of Tensorflow's GradientTape output when target is not a scalar value? For example, I had the following code: The value of c is [[2.],[2.]]. The value of grads is [[5.],[7.],[9.]]. I expected the value of grads to have shape (3,2) or (2,3), and contain values of partial derivatives of each entry of c with respect to a. I am not sure what the values of 5, 7, and 9 represent (interestingly, it seems to be the gradients as if c had been tf.reduce_sum(b @ a) instead) The documentation that I found doesn't really explain the output.",https://stackoverflow.com/questions/76142861,10024860.0,1
486,54905301,tf.train.init_from_checkpoint does not initialize variables created with tf.Variable,"It seems that tf.train.init_from_checkpoint initalizes variables created via tf.get_variable but not those created via tf.Variable. For example, let's create two variables and save them: If I load them again via a tf.train.Saver, everything works fine: variables are loaded back to 1 even though they are initialized at zero here: However if I use tf.train.init_from_checkpoint I get bar is set back to 1 as expected but foo remains at 0. Is this the intended behavior? If so, why?",https://stackoverflow.com/questions/54905301,9973879.0,1
487,49785605,How does tensorflow connect the dimensions of linked convolutional layers?,"The is a very basic tensorflow question, but I haven't yet seen a clear explanation in the docs. Following the examples on the tensorflow site, we basically have these two layers connected: The shape at this point will be (28, 28, 32). The shape at this point will be (28, 28, 64). How does tensorflow take the (28, 28, 32) and turn it into (28, 28, 64) using a 2d kernel. Could you please explain or point me to the documentation? How about when the output dimension of the second layer is smaller, say How would tensorflow combine the 32 dimensions into 8?",https://stackoverflow.com/questions/49785605,1759909.0,1
488,71412499,How to prevent Keras from computing metrics during training,"I'm using Tensorflow/Keras 2.4.1 and I have a (unsupervised) custom metric that takes several of my model inputs as parameters such as: However, it happens that custom_metric is very expensive so I would like it to be computed during validation only. I found this answer but I hardly understand how I can adapt the solution to my metric that uses several model inputs as parameter since the update_state method doesn't seem flexible. In my context, is there a way to avoid computing my metric during training, aside from writing my own training loop ? Also, I am very surprised we cannot natively specify to Tensorflow that some metrics should only be computed at validation time, is there a reason for that ? In addition, since the model is trained to optimize the loss, and that the training dataset should not be used to evaluate a model, I don't even understand why, by default, Tensorflow computes metrics during training.",https://stackoverflow.com/questions/71412499,6315123.0,1
489,65842496,How to define a map_func for tf.data.Dataset.map that can return empty result,"I'm using the Dataset APIs in TF 2.4 . Currently I have a working code piece like The map_func function defined above return a tuple of (features, labels) , where labels might contain zeros or non-zeros. By chaining a filter call, I filter out samples whose labels are all 0s. What's the problem I'm wondering if it is possible to ""integrate"" the filter logic inside the map_func, because the current implementation looks somehow ugly and redundant. I tried to return a tuple of ([],[]) or (None, None) when I want to abandon the results, but TF would complain return types mismatching.",https://stackoverflow.com/questions/65842496,8800948.0,1
490,58585560,Different output shape of Conv2D between tf.keras and keras?,"It might be a dumb question since I'm new to Keras and Tensorflow. I have this simple model: When running with tf.keras.* (like from tensorflow.keras.models import Sequential) classes, summary shows the first layer as: but when running with keras.*(like from keras.models import Sequential) classes. summary shows the first layer as: Why do they give different output shapes? I'm using tensorflow 2.0.0 and keras 2.3.1",https://stackoverflow.com/questions/58585560,2934382.0,1
491,48357434,How to perform additional operation on a trainable variable in Tensorflow,"My training loop is like following, ::pseudocode Now I am stuck in the portion of ""normalize some weight of MLP"" How should I define my normalization code snippet in my model class? I have tried the following way, I have also tried to incorporate this by tf.assign() but it can not be used if I want to optimized my model based on the parameter W_trans.",https://stackoverflow.com/questions/48357434,2277037.0,1
492,35560123,Stuck in an infinite loop when using while operation in tensorflow,"To crop a batch of images in tensorflow in parallel, I used those lines of code: My question is this one: if I don't put the instruction o.set_shape( [None] + list(dims)) the program get stuck in what seems to be an infinite loop, Why?",https://stackoverflow.com/questions/35560123,5499453.0,1
493,59478115,Custom CTC loss function in Keras/Tensorflow,"I feel like I'm fundamentally misunderstanding something. I went through the Keras documentation to no avail. I'm trying to implement the ctc_batch_cost loss for my neural network. My neural network ends with an LSTM layer which returns sequences into a dense layer with 4+1 symbols softmax output. The output shape has 20 time steps and looks as follows: My labels are simply the string that should be output, of variable lengths. Here is my attempt at the CTC function: Now, of course, Tensorflow currently errors with the following: which is understandable since at compile time variables such as samples will be None. But I am at a loss about how to use this. Any hints are appreciated. I want to understand what's happening, not just get an easy fix. I tried testing for None and returning a placeholder but that didn't work either and felt like a hack to begin with. Thank you",https://stackoverflow.com/questions/59478115,5963142.0,1
494,42893408,Tensorflow - memory leak (or something) when reading TFRecord,"i'm working on some CNN model in tensorflow, but i have a problem related to the reading of my data. i have a file, a TFRecord file, compressed using GZIP, i want to read the data from this file in batches, and i set up the next code to do so: the usual code for reading TFRecords. then i procced to create the a test graph, not the actual NN, for testing i run this code and i never get to see the ""test"" printed. the program crashes my pc. I use the ""top"" command to watch the memory usage, and it grows fast until the program and everything in my pc colapses. The dataset is large. each sample is a 3d matrix ( 150 x 150 x 150 ), and there are a thousand samples. but i'm not ( in theory ) loading it to the memory , i'm reading it in tiny batches, right? , then why this occurs... what is the problem with the way i'm reading the files and how can i fix it. Thanks beforehand. any insight is welcome.",https://stackoverflow.com/questions/42893408,1544674.0,1
495,44769958,Tensorflow: sum over non-NaNs of 2-dimensional tensor in axis 1?,"Let tensor be a tensor where len(tensor.get_shape()) == 2. How to do np.nansum(tensor, axis=1)? From the documentation, nansum ""returns the sum of array elements over a given axis treating Not a Numbers (NaNs) as zero"". I can see how to do this using: But this seems overly complicated. Is there a better method?",https://stackoverflow.com/questions/44769958,4521118.0,1
496,35497710,Convolution and Pooling in TensorFlow Deep MNIST,"When I study Deep MNIST for Experts tutorial, I have many difficulties. I'd to know why they used Convolution and Pooling in a Multilayer Convolutional Network. And I don't understand the following two functions. I'd to know the meaning of strides=[1,1,1,1] in conv2d function. Should we always use ksize=[1, 2, 2, 1] and strides=[1, 2, 2, 1] in max_pool_2x2 function. What is the difference between padding='SAME' and padding='VALID'",https://stackoverflow.com/questions/35497710,2853544.0,1
497,66525883,Unable to load the frozen model (.pb) in GraphDef in tensorflow version 2.x,Now Here's the main issue: I'm getting same error when converting .pb to .dlc (Qualcomm). Actually I want to run original model on Qualcomm's Hexagon DSP or GPU.,https://stackoverflow.com/questions/66525883,3479295.0,1
498,68302777,What's the mean of tf.nn.softmax in cnn,"I've implemented a CNN for image classification using some tutoriels on the net, I found this function of softmax, and I didn't understand it when I use it I found values that I didn't understand their meaning can anyone explain this function and it's used for what please!",https://stackoverflow.com/questions/68302777,12259162.0,1
499,76050961,Mismatch in counting operations in tensorflow,"2 approaches of counting operations in Tensorflow provides different answers. It is not clear how it is counted. Any one can explain this? I tried below 2 approaches (get_flops, get_flops_tfv2_1) . I didn't expect 2 approaches of profiling to provide different numbers. get_flops_tfv2_1 provides output as 1440 (close to theoretical operations) get_flops provides output as 120",https://stackoverflow.com/questions/76050961,11471226.0,1
500,59480805,"""This TensorFlow binary is optimized with Intel(R) MKL-DNN... enable them in non-MKL-DNN operations"" What can I do?","I have installed tensorflow using conda. When I test it, I get this performance: I know it can keep working in this way, and I am not sure if I am understanding that message. I would like to know if I can improve the performance with the CPU or what I must do for that message? Configuration: Windows 10 64b. Intel i5 8250. GF MX130 Python 3.7.4 PyCharm 2019.3.1 Conda 4.8.0 Tensorflow 2.0.0",https://stackoverflow.com/questions/59480805,6929738.0,1
501,45882699,Gradient computation with tensorflow,"I would like to compute the gradient of the parameters of a neural network. I wrote I simple toy program, but the gradient is not workig, trhowing instead an error, which I do not understand. The error is: Caused by op u'MatMul', defined at: (I cannot post the whole Traceback because stackoverflow complains that my question is most of all code)",https://stackoverflow.com/questions/45882699,3439054.0,1
502,44462550,Keras + Tensorflow : Debug NaNs,"Here is a great question on how to find the first occurence of Nan in a tensorflow graph: Debugging nans in the backward pass The answer is quite helpful, here is the code from it: Apparently, running the training and the numerical check at the same time will result in an error report as soon as Nan is encountered for the first time. How do I integrate this into Keras ? In the documentation, I can't find anything that looks like this. I checked the code, too. The update step is executed here: https://github.com/fchollet/keras/blob/master/keras/engine/training.py There is a function called _make_train_function where an operation to compute the loss and apply updates is created. This is later called to train the network. I could change the code like this (always assuming that we're running on a tf backend): I'm currently trying to set this up properly and not sure whether the code above actually works. Maybe there is an easier way ?",https://stackoverflow.com/questions/44462550,497600.0,1
503,56096108,How to properly use tf.data for training Keras models in tensorflow v2?,"I'm unclear on how to optimally use tf.data for training Keras models in tensorflow v2: I've taken the following approach: where the dataset is defined to take one full pass through all the data, and then stop (i.e. reach the end). Please note that all the repeat operations have been commented out. The model would be trained as follows: in this case each epoch would correspond to a new pass through the entire dataset object. Alternatively, we could uncomment the ""repeat"" statements above and then train the model like so: Which is the optimal approach and why? Should we be using the repeat operations as in the second approach. In practice, I've found the first approach has better training time... but then when should one use the ""repeat"" operation. There also seems to be a long pause when Keras finishes training the epochs and then runs the validation set. I can literally see the GPU utilization drop from 95% to 0... any suggestions regarding this? Thanks! Using the first approach above, I also see this message after each epoch: Does the shuffle buffer need to be refilled after each epoch? and I also see this, which I don't understand: In particular, I see the GPU usage utilization drop to 0 after this message",https://stackoverflow.com/questions/56096108,190894.0,1
504,50313090,The tf.case cannot run twice correctly,"I am using google colab as a tool to learn Stanford cs20 tensorflow course. I found a strange thing about tf.case. Here is the colab notebook The code is simple in that nodebook and run successfully. Then I changed the following line: I changed the tf.constant(0.0) to tf.constant(0), it will throw error as the type doesn't match as expected. But after I changed it back to tf.constant(0.0) and then it doesn't work with the following error: I had to recreate a new session to make it works again. Can some explain the reason behind the situation?",https://stackoverflow.com/questions/50313090,691385.0,1
505,66475045,Loss function for Image captioning with visual attention,I am trying to understand the TensorFlow implementation of Image captioning with visual attention. I understand what SparseCategoricalCrossentropy is but what is loss_function doing? Can someone explain? Tensorflow Implementation,https://stackoverflow.com/questions/66475045,12098671.0,1
506,40304005,tf.gradients applied to pooling wrong result?,"I have a problem in tensorflow with tf.gradients applied to pooling: [edit]: I was able to reproduce my expectation by changing the equation to: Anyway, I am not sure why I have to do it this way and people answered below do not seem to understand my problem. I don't understand the tf result for tf.gradients pool test backward. (Looks like tensorflow only returns the store matrix for the locations??). Any idea why tf does not return the actual upsampling result? Here is my code:",https://stackoverflow.com/questions/40304005,4132112.0,1
507,73142975,Custom loss function Tensorflow 2 [Keras symbolic inputs/outputs do not implement],"I'm trying to use custom loss function and started with simple MSE. Do not pay attention to oscillator function, it needs just for creating data. The code above produces the following error: TypeError: Keras symbolic inputs/outputs do not implement __len__. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly. Process finished with exit code 1 The problem is in loss_func = tf.reduce_mean(tf.math.squared_difference(tf_y,output_layer)). I think this is because of different dimensions of tf_y and output_layer. Any ideas how to compute MSE by hand using output_layer and y?",https://stackoverflow.com/questions/73142975,17183719.0,1
508,54627554,Error while running multiple Tensorflow sessions in the same Python process,"I have a project with this hierarchy: Content of main.py: Content of file1.py: content of file2.py: When I run main.py, I got the following error: After some debugging, I didn't find any tensor in the second model that has (?, 227, 227, 3) as shape. Instead, I found that the tensor x (defined by x = tf.placeholder(tf.float32,shape=[None,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3]) in func1 from file1) has (?, 227, 227, 3) as shape. I checked the shape of input_img (defined by input_img = sess.graph.get_tensor_by_name('Placeholder:0') in func2 from file file2), I found it (?, 227, 227, 3) when I run main.py. However when I run file2.py (independently by running python file2.py), I don't get this error and and I found that the input_img's shape is placeholder shape: (?, ?, ?, 3). So I assumed that may be both models have the same tensor's name (placeholder) and when I import both file1 and file2 in main.py, the first shape of placeholder (?, 227, 227, 3) remains in the GPU memory. I tried session.close() in file1.py, but it didn't work! Is there a more appropriate way to use multiple Tensorflow sessions in the same process without getting into any confusion between them? Or simply, how to properly close a Tensorflow session before starting another one in the same python process?",https://stackoverflow.com/questions/54627554,8128190.0,1
509,46906441,Equivalent of tf.SparseFeature in tf.data,The neural network I am currently working on is accepting a sparse tensor as input. I am reading my data from a TFRecord as follows: It works like a charm but I was looking at the tf.data API which looks more convenient for a lot of tasks and I am not sure how to read tf.SparseTensor objects like I do with the tf.RecordReader and tf.parse_example(). Any idea?,https://stackoverflow.com/questions/46906441,5236675.0,1
510,56894352,how to find common values of rows of a matrix in tensorflow,"I have a tensor like this: I would like to find whole indices in this matrice which are repeated more than n time. For example: 1 being repeated two times. 2 being repeated three times. 5 being repeated one time. Repetition between rows is considered. Also, I want to skip the number 10 totally(10 is constant). here n=2, So the result looks like: because 2 and 4 being repeated more than two times. I found an example here but the explanations are for Matlab code. Thanks in advance:)",https://stackoverflow.com/questions/56894352,7934786.0,1
511,41156460,tensorflow doing gradients on sparse variable,"I am trying to train a sparse variable in tensorflow, As far as I know current tensorflow doesn't allow for sparse variable. I found two threads discussing similar issue: using-sparsetensor-as-a-trainable-variable and update-only-part-of-the-word-embedding-matrix-in-tensorflow. I am not quitely understand the answer, and it would be good if there is any example code one way I have tried is: when compute the gradients, according to the second link using tf.IndexedSlices the above code of course don't work, and I am confused here. tf.IndexedSlices make the input to be IndexedSlices instance, how to use it to update the gradients given the indices? Also, many people mentioned using tf.scatter_add/sub/update. The official document doesn't contain any example code on how to use and where to use for gradient update. should I use tf.IndexedSlices or tf.scatter? it would be much helpful if there is any example code. Thank you!",https://stackoverflow.com/questions/41156460,6233298.0,1
512,66926747,Building a simple Neural Network: ValueError: Input 0 of layer sequential is incompatible with the layer,"this simple neural network is giving me a headache ;-) Why does it give me the following error: ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 11)",https://stackoverflow.com/questions/66926747,14687074.0,1
513,50475348,How to save the model for text-classification in tensorflow?,"Reading tensorflow documentation for text-classification, I have put up a script below that I used to train a model for text classification (positive/negative). I am not sure on one thing. How could I save the model to reuse it later? Also, how can I test for the input test-set I have? Currently, if I run the above script it retrains the complete model. I want to reuse the model and have it output for some sample texts that I have. How could I do this? I have tried the following to save: but this throws an error, saying Value Error: No variables to save",https://stackoverflow.com/questions/50475348,9830669.0,1
514,41369062,"Tensorflow fail with ""Unable to get element from the feed as bytes."" when attempting to restore checkpoint","I am using Tensorflow r0.12. I use google-cloud-ml locally to run 2 different training jobs. In the first job, I find good initial values for my variables. I store them in a V2-checkpoint. When I try to restore my variables for using them in the second job : I got the following error message : The checkpoint is created with these lines in the first job : According to this answer, it could come from the absence of metadata file but I am loading the metadata file. PS : I use the argument clear_devices=True because the device specifications generated by a launch on google-cloud-ml are quite intricated and I don't need to necessarily get the same dispatch.",https://stackoverflow.com/questions/41369062,4543908.0,1
515,72486389,Object localization MNIST Tensorflow to Pytorch : Losses doesn't decrease,"I am trying to convert a Tensorflow object localization code into Pytorch. In the original code, the author use model.compile / model.fit to train the model so I don't understand how the losses of classification of the MNIST digits and box regressions work. Still, I'm trying to implement my own training loop in Pytorch. The goal here is, after some preprocessing, past the MNIST digits randomly into a black square image and then, classify and localize (bounding boxes) the digit. I set two losses : nn.CrossEntropyLoss and nn.MSELoss and I do (loss_1+loss_2).backward() to compute the gradients. I know it's the right way to compute gradients with two losses from here and here. But still, my loss doesn't decrease whereas it collapses quasi-imediately with the Tensorflow code. I checked the model with torchinfo.summary and it seems behaving as well as the Tensorflow implementation. EDIT : I looked for the predicted labels of my model and it doesn't seem to change at all. This line of code label_preds, bbox_coords_preds = model(digits) always returns the same values label_preds[0] = tensor([[0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156]], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;) Here are my questions : Thanks a lot !",https://stackoverflow.com/questions/72486389,16427586.0,1
516,58788002,TensorFlow-gpu-2.0.0rc2 cannot find cuda-10.1 libraries and skips registered GPU devices,"I am using an NVIDIA Tesla V100-SXM2-32GB on a system where I am a non-admin user, so I cannot change the Cuda version. The Cuda version currently installed on the system is 10.1, and I am trying to get TensorFlow to run with this version. After installing TensorFlow version 2.0.0rc2 (using cudnn-7.6.4 and cudatoolkit-10.1.243), I get the error reported below (within default-enabled eager execution mode). The paths to the Cuda libraries are correctly exported. According to the official documentation and this post, TensorFlow supports Cuda10.0 at the moment. Anybody is aware about a version (even alpha) that could run with Cuda 10.1? returns",https://stackoverflow.com/questions/58788002,5405298.0,1
517,57112278,How to compare two strings in Tensorflow?,Suppose I want to compare to element of a tensor of type string: text,https://stackoverflow.com/questions/57112278,4802687.0,1
518,52088934,Make identity matrix in tensorflow,"I'm beginner student of python and tensorflow. So I need some advice about tensor knowledge, or at least googling keyword I want to do I don't know how to make identity matrix same size with input gradients shape, they have various sizes such as (1,) (5, 5) (5, 5, 1, 1) (5, 5, 1, 64) ... With tf.eye(..) can make 1, 2 dimensional identity matrix, but not higher. help me, please",https://stackoverflow.com/questions/52088934,9854075.0,1
519,53275045,Why does model.fit() raise ValueError with tf.train.AdamOptimizer using categorical_crossentropy loss function?,"I'm following the TensorFlow basic classification example with the Keras API provided in the ""Getting Started"" docs. I get through the tutorial as-is just fine, but if I change the loss function from sparse_categorical_crossentropy to categorical_crossentropy, the code below: fails during the training/fitting step with the following error: The documentation on the loss functions doesn't delve much into expected input and output. Obviously there is a dimensionality issue here, but if any experts can give a detailed explanation, what is it about this loss function or any other loss function that raises this ValueError?",https://stackoverflow.com/questions/53275045,1773216.0,1
520,63233460,How to take gradient in Tensorflow for VGG16,"I am a starter in TF, and here is what problem I have encountered: I am tying to take gradient in this example but it returns none, please help me to understand why.",https://stackoverflow.com/questions/63233460,10407840.0,1
521,47129071,Creating a tf.sequence_mask based on input values,"The example given by the tensorflow tutorial shows that the mask can be created: What if I would like to create a dynamic mask based on the values of my batches? Say if my input is [[1, 0, 2, 3, 4], [2, 3, 4, 4, 4], [2, 3, 4, 5, 4]], and I would like to mask everything up to the first 4 to be True and everything after the first 4 to be false, and the resulting mask should be: I am trying to use this as weight to apply to my sequence_loss tensor",https://stackoverflow.com/questions/47129071,3669481.0,1
522,56498165,How is the second Conv2D layer being calculated?,"This code I've got from Udacity tutorial ""Intoduction to Deep learning with TensorFlow"": What I can not understand is how the second Conv2D being calculated after the first MaxPooling2D-layer. Let's assume that we are processing 28x28px image. First Conv2D-layer returns (28, 28, 32) shape where 32 equals the number of filters being applied. (3,3) is the kernel size. The results than are being sent to MaxPooling2D-layer which reduces the size of an image from (28, 28, 32) to (14, 14, 32). Am I right here? Now we have a shape (14, 14, 32) and send it to the second Conv2D-layer which will apply 64 filters using (3,3) kernel. How is the process of applying (3,3) kernel with 64 filters will look like on our (14, 14, 32) data? Will the second Conv2D-layer create (14, 14, 2048) output shape or not? Or the second Conv2D-layer will create (14, 14, 32)x64 different blocks each for one of 64 applied filters? I have searched all over the internet to find visually how it works to understand better this process with no luck. Thanks!",https://stackoverflow.com/questions/56498165,523630.0,1
523,57033145,Performing one hot encoding inside a Lambda layer in Keras to avoid memory issues: problem,"I've made a sequential model in keras, for generating musical sequences. Something very simple, with LSTM and dense softmax. I have 333 possible musical events I know that model.fit() needs all training data in memory, which is a problem if it is one hot encoded. So I give the model an integer as input, transform this to one hot encoding in a Lambda layer, and then use sparse categorical cross entropy for loss. Because each batch would be transformed to one hot encoding on the fly, I thought that this would sort out my memory issues. But instead, it hangs at the beginning of fitting, and fills up my memory, even with small batch size. Evidently, I'm not understanding something about how keras works, which is not surprising, given that I'm new to it (and on that note, please point out anything too naive in my code). 1) what is happening behind the scenes? What is it about keras that I'm not understanding? It seems like keras is going ahead and running the Lambda layer on all of my training examples before doing any training. 2) How can I solve this, and make keras do it truly on the fly? Can I solve it with model.fit(), which I'm currently using, or do I need model.fit_generator(), which to me looks like it could solve this rather easily? Here is some of my code: I then fit my model:",https://stackoverflow.com/questions/57033145,3120842.0,1
524,59150100,Sagemaker and Tensorflow model not saved,"I am learning Sagemaker and I have this entry point: And I am training it so far it is trying correctly and it tells me that everything when well, but when I check the output there is nothing there or if I try to deploy it I get the error saying it couldn't find the model because there is nothing in the bucker, any ideas or extra configurations? Thank you",https://stackoverflow.com/questions/59150100,6308651.0,1
525,70609983,How to use mobilenet_v2.preprocess_input on tensorflow dataset,"I'm again struggling with the usage of tensorflow datasets. I'm again loading my images via I want to use this dataset in the pre-trained MobileNetV2 The documentation says, that the input data must be scaled to be between -1 and 1. To do so, the preprocess_input function is provided. When I use this function on my dataset I get the error: TypeError: unsupported operand type(s) for /=: 'BatchDataset' and 'float' So how can I use this function properly with the tensorflow dataset?",https://stackoverflow.com/questions/70609983,10873281.0,1
526,37151895,TensorFlow - Read all examples from a TFRecords at once?,"How do you read all examples from a TFRecords at once? I've been using tf.parse_single_example to read out individual examples using code similar to that given in the method read_and_decode in the example of the fully_connected_reader. However, I want to run the network against my entire validation dataset at once, and so would like to load them in their entirety instead. I'm not entirely sure, but the documentation seems to suggest I can use tf.parse_example instead of tf.parse_single_example to load the entire TFRecords file at once. I can't seem to get this to work though. I'm guessing it has to do with how I specify the features, but I'm not sure how in the feature specification to state that there are multiple examples. In other words, my attempt of using something similar to: isn't working, and I assume it's because the features aren't expecting multiple examples at once (but again, I'm not sure). [This results in an error of ValueError: Shape () must have rank 1] Is this the proper way to read all the records at once? And if so, what do I need to change to actually read the records? Thank you much!",https://stackoverflow.com/questions/37151895,1191087.0,1
527,46678809,tensorflow : cost function output 0 in some input data,"hi Im studying machine learning. I tried softmax classification with neural net. In learning progress, label 1,2 is good learning state. But at label 3, cost output is always 0.0. I think i`m not fully understand about neural net. I,m trying to make learning model. input_sequence_length = 3, output_class = 3 0 &lt;= input &lt;= 2 result = 1 3 &lt;= input &lt;= 5 result = 2 6 &lt;= input &lt;= 8 result = 3 please let me know what i missing. below source code is partial. input data (0~2 -&gt; 1, 3~5 -&gt; 2, 6~8 -&gt; 3) 1,2,3 = label output source code",https://stackoverflow.com/questions/46678809,8755775.0,1
528,58873635,What is tensorflow.matmul?,"From the output of print, it is function. But according to the official document: it is a constructor. So I think it is a class name. But, printing the return value of tf.matmul shows it is a tensor, not an ""Object of type Operation"". Is the class Tensor inherited from the class Operation? I tried to find the definition of tf.matmul in tensorflow source code but could not get it.",https://stackoverflow.com/questions/58873635,10142726.0,1
529,44177817,Calling reshape on an LSTMStateTuple turns it into a tensor,"I was using dynamic_rnn with an LSTMCell, which put out an LSTMStateTuple containing the inner state. Calling reshape on this object (by my mistake) results in a tensor without causing any error at graph creation. I didn't get any error at runtime when feeding input through the graph, either. Code: Is this a bug (I ask because it's not documented anywhere)? What is the reshaped tensor holding?",https://stackoverflow.com/questions/44177817,4204963.0,1
530,64511096,Batched elements after shuffling seemingly non-consecutive in TensorFlow 2.x,"I have the following simple example: It returns, as expected: If I then batch the dataset as: I receive, as expected: The batched dataset takes consecutive elements. However, when I suffle first and then batch as: the batched elements are non-consecutive: I'm using Google Colab with TensorFlow 2.x. My question is: Why shuffling before batching makes batch return non-consecutive elements? Thank you for any answer.",https://stackoverflow.com/questions/64511096,1886641.0,1
531,56514579,How to use scatter_update update a tensorflow diagonal weight matrix,I tried to update a tensorflow diagonal weight matrix using scatter_update but with no luck so far. It either prompted shape mismatch or only updated along first row. It is very bizarre API behaviour. Could anyone help me out? Thanks,https://stackoverflow.com/questions/56514579,9125078.0,1
532,70682974,Tensorflow tf.data.Dataset interleave() returns Unexpected result,"I was following some another example from this link which is about the tf.data.Dataset.interleave() method. I tried to understand this example, so I started with the range(3), range(4), ..., and so on. For example, Until range(9), it returns the dataset I expected. But from range(10), it doesn't return the dataset I expected. What is going on here? Isn't this should be [0, ..., 0, 1, ..., 1, 2, ..., 2, ..., 8] ?",https://stackoverflow.com/questions/70682974,7820717.0,1
533,42860617,Evaluating Tensorflow operation is very slow in a loop,"I'm trying to learn tensorflow by coding up some simple problems: I was trying to find the value of pi using a direct sampling Monte Carlo method. The run time is much longer than I thought it would be when using a for loop to do this. I've seen other posts about similar things and I've tried to follow the solutions, but I think I still must be doing something wrong. Attached below is my code: In comparison, doing a for loop type solution in numpy is an order of magnitude faster Attached below is a plot of the difference in overall executioin times for various numbers of trials. Please note: my question is not about ""how to perform this task the fastest"", I recognize there are much more effective ways of calculating Pi. I've only used this as a benchmarking tool to check the performance of tensorflow against something I'm familiar with (numpy).",https://stackoverflow.com/questions/42860617,1322179.0,1
534,57986086,tensorflow 1.13 how to use tf.searchsort safe?,"With code I got first error It also reminded me in line 3459 of got But when tensor shape contain 0 dimension, input.shape=(0,), it will return an error. see here I want to check the tensor shape before using tf.searchsorted, and I know the dimension is None So I use Then I got my second error, and I know that tf.equal will return bool tensor, which cannot be used like bool. But I don't know how to solve my first error. My question is how to use tf.searchsort safe if the first error trigered by 0 dimension",https://stackoverflow.com/questions/57986086,9839954.0,1
535,49273255,Back Propagation in time for tf.nn.dynamic_rnn for sequential input (from batch),"I have a code like this: Here, I use dynamic_rnn to simulate the time steps from the batch. While each forward pass, I can get lstm_c, lstm_h which I can store anywhere outside. So, suppose I have done a forward pass for N items in a sequence in my network and have the final cell state and hidden state provided from the dynamic_rnn. Now, to perform back propagation, what should be my input to the LSTMs? By default, does backprop happen across time steps in dynamic_rnn? (say, no. of time steps = batch_size=N) So is it enough for me to provide the input as: (where prev_rnn_state is a tuple of cell state, hidden state, which I got from the dynamic_rnn from forward propagation for the previous batch.) Or do I have unroll the LSTM layer across time series explicitly and train it by providing a vector of the cell states and hidden gathered across the previous time series?",https://stackoverflow.com/questions/49273255,5002496.0,1
536,44560128,About mechanism/behavior of 'softmax_cross_entropy_with_logits' function on Tensorflow,":) Hi guys. Now, I'm working on Multi-hot classification by using tensorflow. If softmax_cross_entropy_with_logits is used, the loss function increases (e.g. loss: 50 -&gt; loss: 190000 -&gt; loss: 2138712811 -&gt; ...). Therefore, I want to clarify the mechanism of softmax_cross_entropy_with_logits. I thought that the python code of below could imitate softmax_cross_entropy_with_logits. However, behavior is different between genuine (implemented in tensorflow) and the above code. Using the above code, the loss function converges. why? I'm changing only code below.",https://stackoverflow.com/questions/44560128,8164260.0,1
537,42939426,Tensorflow placeholder error,"I have been playing around with tensorflow, I have managed to train the mode and serve it but when i try run the client to send data for classification i get this error I do not quite understand this error, here are my placeholders And i used the builder as in the documentation, writing the prediction_signature as well as classification signatures. If any may know why this is happening i would be extremely grateful",https://stackoverflow.com/questions/42939426,6664161.0,1
538,47909158,Add new variables to optimize to a tensorflow model,I have a tensorflow version of GloVe: I would like to add a new input (increase input size of 1 and add the corresponding rows in wordIW and wordIB). I can't find a proper way to modify the existing graph. ps: my goal is to stop the gradient on existing variables and optimize the loss only on the new input.,https://stackoverflow.com/questions/47909158,6084245.0,1
539,59201620,Keras vs TensorFlow2 Implementation of Multilayer Perceptron,"I have the following implementation of a simple multilayer perceptron model as below: and plot_model() function returns the following graph: I then attempt at implementing the same model in Tensorflow2 as below: However, plot_model() function returns this graph (different than above graph): Is there something wrong with my implementation of Tensorflow2 model?",https://stackoverflow.com/questions/59201620,3899975.0,1
540,57063872,Weird tf.Print bug,I am trying to use a tf.Print like this: but it crashes with this error: This makes no sense to me because the data argument is wrapped in a list.,https://stackoverflow.com/questions/57063872,268408.0,1
541,56091886,Tensorflow: Tensordot reproducible results,"I am playing around with tf.tensordot in Tensorflow. However, I am experiencing some inconsistencies which are bugging me. Below is a reproducible example: This returns a tensor that has dimensions (150, 196, 22) This returns a tensor that has dimensions (1, 196, 22) Now, if we test whether the first element from output_150 is almost equal to the first and only element from output_1, the result is a mismatch between the two arrays. On the other hand, if we do: We see that the inputs are exactly the same. With that said, I would expect that the outputs from the tf.tensordot to be the same as well and they are not. On the same note, here is a tf.tensordot equivalent using tf.reshape and tf.matmul: The outcome is exactly the same, a mismatch between the output arrays. How can that be?",https://stackoverflow.com/questions/56091886,3987085.0,1
542,66320198,Keras fit with generator function always execute in the main thread,"How can I make Keras Models fit method execute a generator in the main thread? From the docs, it looks like that setting workers=0 would execute the code in the main thread. However when I do: I get Which I interpret as only the first step in the iterator has been executed in the main thread. In my use case this is problematic because I need that the code inside the generator to always be executed in the main thread otherwise the program crashes.",https://stackoverflow.com/questions/66320198,3297472.0,1
543,63258249,How to fix memory leak issue in Keras using K.clear_session()?,"I have a network which I'm training by feeding batches of my data, and I'm using model.train_on_batch() to do this. If I run only this training portion, I see my network trains just fine at 3% RAM utilisation for 40+ epochs (as yet) and each epoch has about 2000 iterations. When I try to do validation after each epoch (which also happens in batches), there is a very bad memory leak leading to 90% RAM utilisation and my code getting killed. So I've tried a couple of things in the past few days, it seems model.predict() in a loop causes memory leak open issue at Tensorflow GitHub. I tried predict_on_batch(), same behaviour. model(inputs, training=False) seemed slow down the memory leak, instead of the abrupt jump from 3% - 7% - 13% - 40% - 80% - 90% (intervals of 60sec), it increased as 1% per minute. But at a point it reached 90% too. The only thing left for me to try out of this github thread is using K.clear_session(). I tried reading up documentation for K.clear_session() and some SO posts, all suggest using it when you are creating multiple models, which I am not doing. So my question is if I have a single model being trained and evaluated in loops, where should I use K.clear_session(), after each epoch and reload saved model before each epoch? Will that be correct? Apart from this, I also get the topological sort error another open issue, so I wonder if it's because I'm training in loops because my code otherwise has no loops and this is somehow causing the memory leak too, and K.clear_session() would help somehow? Minimal example of my code structure: Tensorflow-gpu-1.14, python3.6. Would appreciate suggestions if I'm doing something wrong too.",https://stackoverflow.com/questions/63258249,4512432.0,1
544,49838852,Tensorflow : How to use restored model?,"I am trying to save and restore my model in tensorflow , I tried to search and found many tutorials but None of them are giving clear instructions that while restoring the model should i use same program which was used during training or just restore the model ?? This is simple linear regression model in tensorflow : when i run i am getting this output: ...... Now how i save this model and how to restore in new file? I tried this stackoverflow question and did something like this: But i am not getting how to use this saved model and how to give input to model and get a prediction output?",https://stackoverflow.com/questions/49838852,5904928.0,1
545,69108284,"tf.data.Dataset, map functionality and random","Manipulating tf.data.Dataset I get a behavior, I am not able to understand the origin. I am manipulating a tf.data.Dataset a simple integer buffer where I want to add a random integer to each number (the important point). TF provides a map function to apply a transformation (generator) to each element of the dataset. If I code: This code will not work return what as I want. The random generator is apply only once (return 6), and applied to every element of the buffer. I get [7, 7, 7, 7 ,7 ,7 ,7]. However, if I code: return [7, 8, 1, 9, 1, 4] (what I need). I am confuse, why the first version does not work, the generator is applied but the function randint(0,9) is performed only once. Any suggestions ? Thank you, Timocafé",https://stackoverflow.com/questions/69108284,1812233.0,1
546,43983528,How do I store and rebuild and dictionary of weights in tensorflow,"When training I store my weights in a dictionary of tensorflow-variables. I pass that dictionary of weights to a 'model'-function together with some data to get my desired output. After training, I would like to store that dictionary in a file in such a way that I can recreate it. That way I can apply the learned weights by simply passing the dictionary of weights together with the new data to the same model function. According to the documentation, simply passing the dictionary of weights to a saver should save those weights under the correct names. Then I should be able to create the same dictionary in the application function and then restore the saved values. However if I do this, I get an 'values are uninitialized'-error. Can anyone help me find what I am doing wrong? Minimal self-contained code example and corresponding error: Calling the 'run()' function in the code above gives the following error:",https://stackoverflow.com/questions/43983528,3426322.0,1
547,45931866,Running pre-trained VGG-16 in tensorflow on images in parallel,"I'm using a pre-trained VGG-16 net to transform images into features. I can do this fine sequentially. However, I'd like to do this in parallel and I'm not sure how to properly construct the batch. Specifically, let's say I load up 16 images that are held in a numpy array (i.e. 16x224x224x3). I want to transform these in parallel. Here's what I have so far: I end up getting an error: Can anyone help me here? The batch tutorials seem to be focused on creating batches while reading in data, but I've already read in the data and simply want to create a batch to parallelize the network's computation of the different images.",https://stackoverflow.com/questions/45931866,5091701.0,1
548,43764963,placeholder created in function not being recognized in tensorflow,"I found the solution to my problem via hit and trial but do not understand why it worked. I am going through getting started of tensorflow. I ran the code till the end of the following code block and it works fine. Now, I thought that loss looks like something that should be in a function. I tried the following. But it gave me an error. I then tried the following. The only difference is I returned y also. It worked. Why?",https://stackoverflow.com/questions/43764963,2235567.0,1
549,38697265,tensorflow: understanding cross entropy calculation with reduce_mean and reduce_sum,"I was looking at the Tensorflow's basic neural network for beginners [1]. I am having trouble understanding the calculation of the entropy value and how its used. In the example a place holder is created to hold the correct labels: and the cross-entropy, sum y'.log(y), is calculated as follows: Looking at the dimensions I assume we have (element wise multiplication): y_ * log(y) = [batch x classes ] x [batch x classes ] y_ * log(y) = [batch x classes ] And a quick check confirms this: Now here is what I don't understand. My understanding is that for cross-entropy we need to consider the distributions of y (predicted) and y_ (oracle). So I assume that we first need to reduce_mean of the y and the y_ by their columns (by class). I would then get 2 vectors of size: y_ = [classes x 1 ] y = [classes x 1 ] Since y_ is the ""correct"" distribution, we then do a (notice that in the example the vectors are flipped): log(y_) = [ classes x 1 ] And now we do an element wise multiplication: y x log(y_) Which gives us a vector with the length of the classes. And finally we simply sum this vector to get a single value: Hy(y_) = sum( y x log(y_) ) However, this does not seem to be the calculations that are being performed. Can anyone explain were my error is? Maybe point me to some page with a good explanation. In addition to this we are using one-hot encoding. So log(1) = 0 and log(0) = -infinity so this will cause errors in the calculations. I understand that the optimizer will calculate the derivatives, but isn't the cross-entropy still calculated? TIA. [1] https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html",https://stackoverflow.com/questions/38697265,2051561.0,1
550,39657063,Is the collection in tensorflow.get_collection() cleared?,"I'm learning about neural nets using Tensorflow through the Stanford course. I found this while implementing a RNN and did not quite understand why the losses are accumulated: The documentation for get_collection() here doesn't mention anything about clearing the variables. Since this is run for every training step, are the losses incremented every epoch / minibatch of training and carried over? I am still new to NNs so do correct any misunderstanding I have on this!",https://stackoverflow.com/questions/39657063,4207476.0,1
551,56280759,"Keras Bidirectional LSTM returns two outputs (fwd + backward), which step maps to which row in the output tensor?","Using the following Keras bidirectional LSTM: x_foraward and x_backward are now tensors of shape [batch_size, seq_length, 128]. In x_forward I presume that x_forward[:, 0, :] maps to the output for sequence step 0, and so on. I'm unclear about x_backward. Does x_backward[:, 0, :] map to the first sequence step or the last sequence step?",https://stackoverflow.com/questions/56280759,4790871.0,1
552,49546211,How to reduce gigantic TFRecord size caused by repetitive keys,"Since my input json is a few GB in size which takes a long time to parse I decided to try and turn it into more efficient (or so I thought) TFRecord files. Long story short, by doing that I inflated my dataset by 10x... When I took a closer look at some of my generated tfrecord files I saw that for each protobuf Example all the keys for every single input feature were included. Since I have 130 (fairly verbose) keys and a few million examples the majority of disk space is now used up by those repetitive keys. Clearly there must be a better way than repeating keys for every Example. Here is my code I found the documentation regarding TFRecords very lacking so I'm asking here: How can I efficiently save my data using TFRecords? Is it possible to save by feature and not by example? That way I would only have to include the key name once per feature.",https://stackoverflow.com/questions/49546211,9367924.0,1
553,57484616,Why is loss changing with dense and embedding layers sizes?,"I have a simple model as follows: My loss is calculated using softmax cross entropy and weights updated with the adam optimizer. When vocab_size = 2 (for testing purposes), loss is this: When vocab_size = 20200 (full size of vocab), loss is this: Why is the shape of the loss changing, when everything is the same except for dense and embedding layer sizes? And how do I get the same, nice shape for loss with the larger vocabulary size?",https://stackoverflow.com/questions/57484616,10458815.0,1
554,69901379,Overfitting a small data set through the ReLU activation,"I would like to train a network by only using the ReLU activation and completely overfit the data. However, no matter how many different network structures I utilize (e.g., increasing the number of neurons and layers), I'm not able to reach a loss value close to zero. It is important to emphasize that i) I don't want to use another activation function, and ii) for now, I won't be normalizing the data points. My current network is quite vanilla, and in my opinion, the ReLU activation should ""easily"" memorize/overfit the data especially when considering the size and dimension of the data set. Is there a chance that I might be doing something wrong in my code? or What could be the reason that my network does not work?",https://stackoverflow.com/questions/69901379,11391711.0,1
555,48798950,"Tensorflow: problems about setting parameter""reuse"" for ""tf.get_variable""","I am reading a book about Tensorflow and an example is shown： When I try this, I receive an error: How to deal with this problem and...why is it occurring? enter image description here enter image description here",https://stackoverflow.com/questions/48798950,9362733.0,1
556,62052776,"Profiling with TensorBoard only produces one tool (trace_viewer) out of the 5 available in the ""Profile"" tab","I want to profile a CNN to find out which layers are taking up more execution time. First I import my model created in Keras and load the parameters I already trained Then I enable the trace Then I calculate the prediction: And finally I write the traces: However, I cannot see anything else than ""trace_viewer"" in the ""profile"" tab. In particular, I am interested in the ""TensorFlow stats"" tool (as shown in https://www.tensorflow.org/guide/profiler). I also tried a different approach with callbacks: But this one doesn't even generate a profile tab, only a ""graphs"" tab. Any suggestions?",https://stackoverflow.com/questions/62052776,13630129.0,1
557,47787615,"Tensorflow: TypeError: float() argument must be a string or a number, not 'generator'","I'm just a beginner of ML-learner using Tensorflow, and on tutorials I'd like to solve ""Iris"" judging program without using batch solution. Here's my code: And always I got this message: I think my code's wrong, but I can't figure out what's wrong... Any help is really appreciated. (I'm sorry about my poor English and Python ability.)",https://stackoverflow.com/questions/47787615,9092514.0,1
558,61257468,Tensorflow: run different function elementwise depending on True/False value of tensor,Code: I get: ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all() What I want to achieve is depending on crct run different function elementwise. (I am new to tensorflow),https://stackoverflow.com/questions/61257468,13333189.0,1
559,53996020,keras model with tf.contrib.losses.metric_learning.triplet_semihard_loss Assertion error,"I am using python 3 with anaconda, and trying to use a tf.contrib loss function with a Keras model. The code is the following I get the following error: When I am using the same network with a keras loss function it works fine, I tried to wrap the tf loss function in a function like so And still getting the same error What am I doing wrong here? update: When changing the func to return the following everything works fine! But i cant get it to work with the specific tf loss function... When i go into tf.contrib.losses.metric_learning.triplet_semihard_loss and remove this line of code: assert lshape.shape == 1 it runs fine Thanks",https://stackoverflow.com/questions/53996020,4406595.0,1
560,53946149,Numpy and tensorflow RNN shape representation mismatch,"I'm building my first RNN in tensorflow. After understanding all the concepts regarding the 3D input shape, I came across with this issue. In my numpy version (1.15.4), the shape representation of 3D arrays is the following: (panel, row, column). I will make each dimension different so that it is clearer: Here my understanding is: I have two timesteps with each timestep having 3 observations with 5 features in each observation. However, in tensorflow ""theory"" (which I believe it is strongly based in numpy) RNN cells expect tensors (i.e. just n-dimensional matrices) of shape [batch_size, timesteps, features], which could be translated to: (row, panel, column) in the numpy ""jargon"". As can be seen, the representation doesn't match, leading to errors when feeding numpy data into a placeholder, which in most of the examples and theory is defined like: x = tf.placeholder(tf.float32, shape=[None, N_TIMESTEPS_X, N_FEATURES], name='XPlaceholder') So, to summarize: My question is: ¿Is there anything I'm missing in regard to this different representation logic which makes the practice confusing? ¿Could the solution be attained to switching to dynamic_rnn? (although the problems about the shape I encounter are related to the dataset API initializer being fed with shape [N_TIMESTEPS_X, None, N_FEATURES], not with the RNN cell itself. Thank you very much for your time. Full code:",https://stackoverflow.com/questions/53946149,9273596.0,1
561,38363515,How do I name a division operation in a TensorFlow graph?,"I am writing a language model in TensorFlow, following the example in ptb_word_lm.py. I calculate the batch cost like so: I would like to attach a name to the cost node in the graph so that I can visualize and do a scalar summary of it in TensorBoard. However, I cannot figure how to attach a name to the / infix operator. I'm thinking I have to do something like but the exact syntax eludes me.",https://stackoverflow.com/questions/38363515,1120370.0,1
562,52864435,Measuring GPU memory usage with TensorFlow profiler,Is there a way to properly measure GPU usage of tf.Estimator model using TensorFlow profiler? I've followed the documentation: But the printed result is always 0.,https://stackoverflow.com/questions/52864435,5991102.0,1
563,64072148,"TypeError: '...' has type str, but expected one of: bytes","I'm trying to get basic Tensorflow bounding box object detection working on Open Images Dataset (v6)... The relevant code seems to be here: I thought maybe value=[value.encode()] might fix it, but then it says: (Well which is it, TF? bytes or str?) The row in the input file contains: The feature map for the TFRecord: Any idea? I installed with pip3 and had to fix a bunch of package deprecation bugs before it got to this point. EDITs: Versions: I tried but it gets the following: (Where did the .jpg go?)",https://stackoverflow.com/questions/64072148,188587.0,1
564,64065895,How to use tf.dataset for making predictions?,"I feel that using using tf.dataset is very intransparent how and why stuff works. I just hang out here and wonder how to make predictions now that I have a model using again a tf.dataset. It is so easy to use numpy arrays. If I use a tf.dataset in tf.keras.predict(), how does this model know what is the data data to use as input and what are the labels? Because I have labels in my data where I want to do predictions... I don't understand the way of using and understand the inner working. Thanks for enlightment. EDIT: Also since I need this for a custom callback I wonder if the output of predict with a datsset is aligned with the labels of the origin data structure? How could I extract the labels from the dataset of which I did predictions? Edit: I have scores of predict: where test is a tf.datsaet which ahs 4 column with names. I actually don't know how to display a datset. I just can iterate with take(). Then the 1. element look like this: I just see that the last element has no key name? this is the label key. So I think that internally the label key is ignored? Hopefully? The first 3 keys should be used for predictions. Also, Is the order of the result predictions the same as of the dataset used? Such that I can extract the labels from the dataset and do custom evaluation with the scores?",https://stackoverflow.com/questions/64065895,9451356.0,1
565,62894479,Keras model.predict giving different shape from training label array,"I'm using the following code to try and learn tensorflow. I've clearly specified the shapes of the training and validation X and y arrays. When I run yval.shape, model.predict(Xval).shape, I get the output ((200, 1), (200, 10)). I'm not able to understand where these extra 9 dimensions are coming from. Even the Xval prediction should have the shape (200, 1).",https://stackoverflow.com/questions/62894479,2889733.0,1
566,50049485,FailedPreconditionError: Attempting to use uninitialized value conv2d_1/kernel with Tensorflow/Python,"I am trying to create a CNN model with help of the following code: Here, my input is a 500 * 530 * 3 dimension image. I am trying pass input and other parameters using following code: When I am trying to print logits(means value of x) I am getting the following error: I am not sure what wrong I did. I need to see the logits generated from my CNN model. I really need help on this.",https://stackoverflow.com/questions/50049485,7388547.0,1
567,45852612,Create duplicate copies of value in same shape as another tensor,"I have a tensor of some arbitrary shape. I want to create a second tensor of the same shape but populated with some value c so I can multiply them together pairwise. I currently have the following code. input is the tensor with a predetermined shape and arbitrary values. There's two problems with this current code. Firstly, mult is not initially created as a tensor and I can't just state shape = inputs.shape. I'm new to tensorflow so any help is greatly appreciated.",https://stackoverflow.com/questions/45852612,,1
568,37113556,TensorFlow: dimension error. how to debug?,"I'm a beginner with TF I've tried to adapt a code which is working well with some other data (noMNIST) to some new data, and i have a dimensionality error, and i don't know how to deal with it. To debug, i'm trying to use tf.shape method but it doesn't give me the info i need... the whole code is on my github https://github.com/FaguiCurtain/Kaggle-SF the Udacity Assignment 3 file is working the original data is here https://www.kaggle.com/c/sf-crime/data in Udacity, the data were images and each image was a 28x28 matrix which was reformatted into flattened vectors of size 784 in the Kaggle-SF file, i am feeding vectors of size 29, and labels can take 39 different values. thanks for your help",https://stackoverflow.com/questions/37113556,4832010.0,1
569,70948006,"Getting ""dictionary update sequence element #0 error"" while training linear regression model in tensorflow","So I am completely new to Machine learning using tensorflow.I was doing simple linear regression which has multiple input classes. Let me share code. And this is the error I kind of have some idea that my variable x_train has shape (400,7) 400 rows of 7 columns each. But this code was supposed to run for multiple column input. One more feeling which I am getting is that the error has something to do with the line I have done variations like dict(enumerate(data_tf.flatten(),1) and other fixes but to no use. I even tried lists but still I am getting some other weird error. Let me share the jupyter notebook from where I was learning Link",https://stackoverflow.com/questions/70948006,17542615.0,1
570,40127783,Is necessary to use to both eval and run?,I understood the difference between the two from this answer. But in most talks/code online I find people using both as below: I don't understand the need and utility for doing so.,https://stackoverflow.com/questions/40127783,3646408.0,1
571,46997735,What is wrong with the batch_size of the following tensorflow code?,"The following Tensorflow code, which I was using to check a small technique, does regression. here input_size, reg_param, blocks are input to the function. And None is the placeholder for batch_size of the network. During training whenever I use batch_szie = 1, I get correct output. The network converges to desired output after about 6,000 iterations and I get output error around ~0.001. But whenever I use batch_size=2 or more the code does not converge at all and I tried upto 100,000 iterations yet the mean output error on training data is like ~0.2. At first I thought some operations went wrong. However, during testing I have changed batch_size to upto 50 and saw that the test results are correct (when trained using batch_size=1 during training). So I think, the forward operation is okay. IN summary, I am at a loss here. Does anyone know what am I doing wrong? What could be done to remove this discrepency?",https://stackoverflow.com/questions/46997735,817824.0,1
572,48598418,Reuse variables in tensorflow,I can't understand how variables and scopes are supposed to be used. Here there is my failed attempt to reuse a variable defined inside a function: And then I call the function: Quite surprisingly the output is: I expected Thanks to anyone clarifying the concepts of variable and scopes in TF.,https://stackoverflow.com/questions/48598418,512225.0,1
573,66253543,BERT Model Fine Tuning and migrating to TF2,I executed this excellent tutorial: https://towardsdatascience.com/building-a-multi-label-text-classifier-using-bert-and-tensorflow-f188e0ecdc5d I understood most of it except where model is being created. I would like to know it and migrate to TF2 bert.,https://stackoverflow.com/questions/66253543,210351.0,1
574,52922980,Error when using Quantized Conv2D with tf.qint8 inputs,"I am new to quantization and I was learning usage of QuantizedConv2D operation in tensorflow. The code is as below I get the following error: I am not sure if my code is right or this is a bug. Any help will be appreciated. Thanks and Regards, Abhinav",https://stackoverflow.com/questions/52922980,9104473.0,1
575,46836857,Results not reproducible with Keras and TensorFlow in Python,"I have the problem, that I am not able to reproduce my results with Keras and ThensorFlow. It seems like recently there has been a workaround published on the Keras documentation site for this issue but somehow it doesn't work for me. What I am doing wrong? I'm using a Jupyter Notebook on a MBP Retina (without Nvidia GPU). Used Python version: The workaround is already included in the code (without effect). With everytime I do the training part I get different results. When resetting the kernel of the Jupyter Notebook, 1st time corresponds with the first time and 2nd time with 2nd time. So after resetting I will always get for example 0.7782 at the first run, 0.7732 on the second run etc. But results without kernel reset are always different each time I run it. I would be helpful for any suggestion!",https://stackoverflow.com/questions/46836857,7483494.0,1
576,58900947,"Keras, Tensorflow : Merge two different model output into one","I am working on one deep learning model where I am trying to combine two different model's output : The overall structure is like this : So the first model takes one matrix, for example [ 10 x 30 ] Now the second model takes two input matrix : I want to make these two matrices trainable like in TensorFlow I was able to do this by : I am not getting any clue how to make those matrix_a and matrix_b trainable and how to merge the output of both networks then give input. I went through this question But couldn't find an answer because their problem statement is different from mine. What I have tried so far is : Overview of the model : Update: model a I am merging like this: Is it right way to matmul two keras model? I don't know if I am merging the output correctly and the model is correct. I would greatly appreciate it if anyone kindly gives me some advice on how should I make that matrix trainable and how to merge the model's output correctly then give input. Thanks in advance!",https://stackoverflow.com/questions/58900947,5904928.0,1
577,42663047,tensoflow word2vec_basic input-output placeholders,"I am a newbie in tensorflow. I am trying to understand the word2vec_basic script. At the beggining it defined input and output. If I understood correctly the shape of train_inputs - [batch_size] is an array of integers, and the length of the arrays is batch_size. Then the shape of train_labels is [batch_size, 1], which is the matrix with a single row. Correct? If yes, I don't understand why it's so, and what should be stored in those placeholders. According to the theory, the label is a int and the input is an array of the sliding window of context, so why batch_size shows up there? It seems like I missed something fundamental in the theory. I would appreciate an explanation.",https://stackoverflow.com/questions/42663047,811921.0,1
578,60974077,How to save Keras model as frozen graph?,I am working with Tensorflow 2.0 and want to store the following Keras model as frozen graph. I can't find any good examples how to do this in Tensorflow 2.0. I have found the freeze_graph.py file in the Tensorflow Github repository but find it hard to wrap my head around it. I load the file mentioned above using: But what exactly do I have to provide to the freeze_graph function itself? Here I marked the arguments where I am not sure with a questionmark. Can someone provide a simple example that shows how I can store the model above as a frozen graph using the freeeze_graph function?,https://stackoverflow.com/questions/60974077,3861775.0,1
579,45113950,TensorFlow tracker class crashing when creating second instantiation - Sessions need to be unique?,"I have a TensorFlow tracker which I'm building to conform to the standard OpenCV Tracker format. These trackers can be used like so (I replaced the calculations and things that don't use tensorflow with ~&lt;this&gt;~): And so this is how I would like to structure the use of my TensorFlow tracker class. HOWEVER! Currently my Class code looks like so: The problem I am experiencing is that I need to be able to create multiple trackers in my code at once, however they attempt to share the same Session and this causes a problem (actually I'm replacing the old one, hoping it will be garbage collected, but I should be able to have two tracker objects if need be): I would like any instantiation of this class to create its own Session. However, instead of using the ""with tf.Session() as sess:"" wrapper around all of my class member functions I have tried to just add: to the __init__ function to attempt to give each instantiation its own unique Session but it has the exact same problem, and in addition I don't get to use the nice __enter__ and __exit__ methods which come with the use of the with statement. Since in my test code I'm currently only using one tracker at a time, I can simply call my 'init' function on my tracker object with a new initial_image and initial_bbox without creating a whole new object. HOWEVER, I need to be able to! Any help with this annoying problem would be most appreciated!",https://stackoverflow.com/questions/45113950,7656519.0,1
580,76087824,Tensorflow Data API .map() Problems,"I'm working on an image multi-classifier and I am running into issues when I'm building out the dataset using the td.data API. I currently have ~33k images with labels. I'm running this out of a Jupyter Notebook on SageMaker. Why is the dataset.map() function passing values (Tensor) to the parse_function which doesn't seem to be readable for normalizing the images? Here are the (truncated) functions I'm using: The data I’m passing to the create_dataset function looks like this: The .map() function passes the individual ""rows"" off as it's iterating through, but the returned values are empty. When I print the filename, I’m getting a Tensor: But if I manually pass the URL and label to the parse_function, I get the desired results. For example: Gives me the following (truncated for brevity):",https://stackoverflow.com/questions/76087824,1833925.0,1
581,69026872,Unclear purpose of a class derived from Keras' BatchNormalization,"I'm reading the code of a Keras implementation of YOLOv4 object detector. It uses a custom Batch Norm layer, like this: Even though I understand how the usual Batch Norm layer works during training and inference, I don't understand the comment nor the need for this modification. What do you think?",https://stackoverflow.com/questions/69026872,3618854.0,1
582,57748176,Cannot install Tensorflow with Pycharm because of Protobuf error,"I installed Pycharm for Windows 10 pip install tensorflow went fine without errors When trying to run a simple project I get the error message Can somebody please tell me how I can get a working installation of Tensorflow, it seems that all the versions are mismatched and pip makes no attempt to install correct versions of each package. I don't care if its outdated. What commands do I need to type in to get a working stable version from a clean installation of Pycharm so that the code above would run? Thank you",https://stackoverflow.com/questions/57748176,2056201.0,1
583,55950608,"TF/keras subclass works perfectly in Eager Execution, and throws a massive untraceable error without it?","I learned to write custom layers from keras.io. Here it is: When run in Eager execution, I get nice outputs. Without that mode, I get very weird error that I cannot even trace to where it started, it is in a different world. Here it is:",https://stackoverflow.com/questions/55950608,11210476.0,1
584,65825675,How to save a learnable tensorflow distribution?,"I have been trying to save and load a Tensorflow distribution. There don't seem to be any good examples out there on how to do this. Specifically I have been trying to save a PixelCNN++ distribution which inherits from tfp.distributions.Distribution. A minimum working example can be found below (this is taken from the PixelCNN documentation). How do I save the distribution? Or instead, how do I extract the distribution from the model (which can be easily saved) in order to sample from it?",https://stackoverflow.com/questions/65825675,14288502.0,1
585,50913045,how to use skip with tf.data.Dataset api in tensorflow or setting batch to 0,"Here is the code to begin with: So the main aim of this code is to be able to iterate over the 5 different datasets that I have created using the tf.data.Dataset.range function. I want to take 1 element from first dataset and 1 element from the second. THEN, I want to consider data2 and data3, THEN data3 and data4, THEN data4 and data5, THEN data5 and data1 and so on and so forth. I have thought about it this way and here is the output: Now i was just testing the starting point for the first dataset and see if it works correctly, but I got the above results. I thought I was going to get a 2 instead of the 5, but that was not the case. As if the skip has almost no effect. I would like if someone can help me out solving this problem. Finally, I am working on this since I have a custom dataset that will not fit the GPU memory and therefore I am looking to implement something similar. I have tried the following test for the skip() function and here are the results: output: therefore, how to force the iterator to skip at each training step? Any help is much appreciated!!",https://stackoverflow.com/questions/50913045,7886651.0,1
586,48815431,Max pooling layer after 1D convolution layer,I'm new to Tensorflow. I'm trying to add a max pooling layer after a 1D convolution layer: But I get errors which I figure out why is that?,https://stackoverflow.com/questions/48815431,6485602.0,1
587,38777380,Questions regarding tensorflow distributed training example,"I am studying distributed tensorflow example: tensorflow distributed training code template It's a between-graph replicas and asynchronous training example template. I also found the following code example which follows the same fashion (between-graph, asynchronous).This example is from murry's answer. I pasted it below to help me express my questions: 1, In this example, say I have two worker tasks and two ps tasks, do all the Variables: hid_w,hid_b,sm_w,sm_b... are placed on parameter server(ps) devices? If yes, does the placement follow a round-robin fashion (hid_w to ps/task:0, hid_b to ps/task:1, sm_w to ps/task:0, sm_b to ps/task:1 .... ) 2, If I want to achieve synchronous replicated training, I can use tf.train.SyncReplicasOptimizer as a wrapper. However, tf.train.SyncReplicasOptimizer can only wrap gradient descent based Optimizer such as tf.train.AdagradOptimizer and tf.train.GradientDescentOptimizer. My question is how to achieve synchronous training of algorithm like K-means that does not use any Optimizer?; is there any way that can achieve synchronous training without tf.train.SyncReplicasOptimizer",https://stackoverflow.com/questions/38777380,6437725.0,1
588,56639621,how to use tensorflow tf.losses.softmax_cross_entropy?,"I am doing some semantic segmentation problem and need to define loss function. Does any one know how to use tensorflow ""tf.losses.softmax_cross_entropy""? It is said in the documentation that the first input of the function is onehot_labels, so do we need to first transfer the pixel-wise class label into one hot encode format and input one hot encode into this function? Or we can directly input the pixel class label like tf.losses.sigmoid_cross_entropy in this post sigmoid_cross_entropy loss function from tensorflow for image segmentation? Thank you so much!",https://stackoverflow.com/questions/56639621,9357193.0,1
589,50704004,Tensorflow: Efficient multinomial sampling (Theano x50 faster?),"I want to be able to sample from a multinomial distribution very efficiently and apparently my TensorFlow code is very... very slow... The idea is that, I have: Let's say len(counts) = N and len(probs) = (N, 50). What I want to do is (in our example): such that my final matrix looks like (for example): A = [[22, ... 13], ..., [12, ..., 3]] where np.sum(A, axis=1) == counts (i.e the sum over each row = the number in the corresponding row of counts vector) Here is my TensorFlow code sample: elapsed time: 0.12 seconds My equivalent code in Theano: elapsed time: 0.0025 seconds Theano is like 100x faster... Is there something wrong with my TensorFlow code? How can I sample from a multinomial distribution efficiently in TensorFlow?",https://stackoverflow.com/questions/50704004,2683177.0,1
590,75316353,tf.data.datasets set each batch (prefetch),"I am looking for help thinking through this. I have a function (that is not a generator) that will give me any number of samples. Let's say that getting all the data I want to train (1000 samples) can't fit into memory. So I want to call this function 10 times to get smaller number of samples that fit into memory. This is a dummy example for simplicity. Again lets say get_samples(1000,0) won't fit into memory. So in theory I am looking for something like this: But this still loads everything into memory. Again this function is a dummy representation and the real one is already defined and not a generator. In tf land. I was hoping that: I understand that I can use tf.data.Datasets with a generator (and I think you can set a generator per batch). But the function I have gives more than a single sample. The set up is too expensive to set it up for a every single sample. I was wanting to use tf.data.Dataset.prefetch() to run the get_batch function on every batch. And of course, it would call the get_batch with the same parameters on every epoch. Sorry if the explaination is convoluted. Trying my best to describe the problem. Anyone have any ideas?",https://stackoverflow.com/questions/75316353,1839674.0,1
591,64111110,"How to do ""round half up"" in tensorflow","I have some question when doing tf.round(x) x=[0.4, 1.5, 2.5, -1.5, -2.5, -0.4] If I want to get the ans=[0, 2, 3, -2, -3, 0] rounding half way away from zero How should I do? I've tried tf.keras.backend.round(), tf.math.round, tf.math.rint() I got similar answer in python but not in TF Thank you",https://stackoverflow.com/questions/64111110,14353628.0,1
592,55761855,TensorFlow: a subtlety about seed,"I want to seed my random number generator. I can do the following, which works: The following also works: However, the following generates a different number each time I run it: Information about seed: https://www.tensorflow.org/api_docs/python/tf/random/set_random_seed 1) Why does the latter not work? 2) What can I do in order to make it work, i.e. without the use of ""with tf.Session() as sess1:"" ?",https://stackoverflow.com/questions/55761855,2594778.0,1
593,57794598,"Best method to add noise on tf.dataset images ""on the fly""","After training a model (image classification) I would like to see how it performs differently when I evaluate a proper image and various noised versions of it. The type of noise I'm thinking is a random change in pixels value, I tried with this approach: This process works fine but it is very slow. I also use dataset.batch and dataset.prefetch on dt and I didn't found a combination for their values that reduces the algorithm time Is there a smarter way to do it? I tried by yielding not noised images and to add the noise later inside dataset.map. The problem is that inside map I have to manipulate tensors and I didn't found a way to change each pixel value SOLUTION I used @Marat approach and it worked like a charm, the whole process went from 20-30 hours to minutes. My noise was a simple +-1 but I didn't want to go in overflow (255+1 = 0 in uint8) and therefore I only had to use numpy masks",https://stackoverflow.com/questions/57794598,7702081.0,1
594,72614441,Difference between tensorflow Model subclassing,"Let's say I am building my neural network architecture by subclassing tensorflow's Model class. A standard way to do this would be to: Which I understand, we subclass the Model class and any argument not specified has the default value in **kwargs. Now I also saw this option which is confusing me: Why would we pass IdentityBlock and self in super(), and also not put **kwargs in the __init__ parameters? What is the difference between these two subclassing methods, and if there isn't one, how are these the equivalent?",https://stackoverflow.com/questions/72614441,13469674.0,1
595,36468701,AdamOptimizer and GradientDescentOptimizer from tensorflow not able to fit simple data,"Similar question: Here I am trying out TensorFlow. I generated simple data which is linearly separable and tried to fit a linear equation to it. Here is the code. I get the following output: Right after the first iteration it gets struck at 0.46. And following is the plot: Then I changed the code to use gradient descent: Now i got the following: 0.54, 0.54, 0.63, 0.70, 0.75, 0.8, 0.84, 0.89, 0.92, 0.94, 0.94 And following is the plot: My questions: 1) Why is the AdamOptimizer failing? 2) If the issue is with learning rate, or other parameters which I need to tune, how do I generally debug them? 3) I ran gradient descent for 50 iterations (I ran for 10 above) and printed the accuracy every 5 iterations and this is the output: Clearly it started to diverge, looks like the issue is with fixed learning rate (it is overshooting after a point). Am I right? 4) In this toy example what can be done to get a better fit. Ideally it should have 1.0 accuracy as the data is linearly separable. [EDIT] As requested by @Yaroslav, here is the code used for plots",https://stackoverflow.com/questions/36468701,6170554.0,1
596,74146034,How to debug a custom loss function during model fitting?,"I would like to see what is happening in my loss function during model fitting. However, I cannot figure out how to do that. This is what I am trying but it does not work: After starting training by calling the fit() function I only get the following output: How do I display the actual value of label, pred, mask and loss?",https://stackoverflow.com/questions/74146034,1020704.0,1
597,48142181,What's the purpose of keras.backend.function(),"The Keras manual doesn't say too much: Tensorflow source code, which is actually quite short, shows that K.function(...) return a Function object which, when called, evaluates the outputs and updates using the inputs. The interesting part is how it handles the updates which I don't follow. Any explanations/examples/pointers to help understanding this K.function(...) is appreciated! Here is the relevant part from Tensorflow source code",https://stackoverflow.com/questions/48142181,2658138.0,1
598,69964540,Changing BatchNormalization momentum while training in Tensorflow 2,"I want batch normalization running statistics (mean and variance) to converge in the end of training, which requires to increase batch norm momentum from some initial value to 1.0. I managed to change momentum using a custom Callback, but it works only if my model is compiled in eager mode. Toy example (it sets momentum=1.0 after epoch zero due to which moving_mean should stop updating): Output (get this when run_eagerly=False) Expected output (get it when run_eagerly=True) I guess this happens because in graph mode TF compiles the model as graph with a momentum defined as 0.99, and the uses this value in the graph (so momentum is not updated by BatchNormMomentumCallback). Question: Is there a way to update that compiled momentum variable inside the graph while training? I want to update momentum not in eager mode (i.e. using run_eagerly=False) because training efficiency is important.",https://stackoverflow.com/questions/69964540,1653453.0,1
599,46715102,"What does this error InvalidArgumentError (see above for traceback): Expected dimension in the range [-1, 1), but got 1 mean?","I'm getting an error when trying to run the following code: The actual error is: The code is running a simple binary classification using logistic regression in TensorFlow. I've been doing some research on the net but can't really find a satisfactory solution. Thanks,",https://stackoverflow.com/questions/46715102,2366887.0,1
600,55908329,Tensorflow - ValueError: Output tensors to a Model must be the output of a TensorFlow `Layer`,"I have created an RNN with the Keras functional API in TensorFlow 2.0 where the following piece of code workes I then had to changed to Tensorflow 1.13 which gives me the following error I don't understand why the output tensor is not from a Tensorflow layer, since t_sum is the output from keras.layers.Add. I have tried to wrap parts of the code into keras.layers.Lambda as suggested in ValueError: Output tensors to a Model must be the output of a TensorFlow Layer , but it doesn't seem to work for me.",https://stackoverflow.com/questions/55908329,4411131.0,1
601,45348472,"After getting weight from train/answer, How can I predict the future vaue?","It might be the tensorflow beginner question. I have a combination trainX(training) and trainY(answer), testX and testY and single furtureX(to predict futureY) then I got the weight as w_h,b_h,w,b Now, with the final 'weight', I want to predict future from the futureX. What kind of function should I use??? I read many books for beginners and understand how to put train and test data, but can't find the way to predict the future..",https://stackoverflow.com/questions/45348472,1942868.0,1
602,47580828,Is making multiple shards of your data with multiple threads minimize the training time?,"My main issue is : I have 204 GB training tfrecord file that has 2 million images, and 28GB for validation tf.record file, of 302900 images. it takes 8 hour to train one epoch and this will take 33 day for training. I want to speed that by using multiple threads and shards but I am little bit confused about couple of things. In tf.data.Dataset API there is shard function , So in the documentation they mentioned the following about shard function : and these are my question: 1- Is there any relation between the number of tf.records files and number of shards? is number of shards(worker) depend on the number of CPU you have it, or the number of tf.records files you have ? and how I create it, , just by setting the number of shards to specific number? , or we need to split the files to multiple files and then set specific number of shards. note the number of worker referred to number of shards 2- what is the benefit of creating multiple tf.records file? some people said here is is related with when you need to shuffle you tf.records in better way but with Shuufle method exists in tf.Dataset API we don't need to do that, and other people said here it is only to split your data to smaller sizes parts. My question Do I need to as first step to split my tf.records file to multiple files 3- Now we come to num_threads in the map function ( num_paralle_calls in new version of tensorflwo) should be the same as number of shards you have it . When I searched I found some people say that if you have 10 shards, and 2 threads, each thread will take 5 shards. 4- what about about the d.interleave function , I know how it works as was mention in this example. But again I missed the connection num_threads, cycle length for example 5- If I want to use multiple GPU should I use the shards? as mentioned in the accepted comment here as a summary I am confused about the relation between ( number of tf.records files, num_shards(workers), cyclic length, num_thread(num_parallel_calls). And what is the better situation to create in order to minimize the training time for both cases ( using multiple GPUs, and using single GPU)",https://stackoverflow.com/questions/47580828,8262057.0,1
603,65235985,Load tensorflow (keras) model on Flask server under mod_wsgi,I have created a Flask sever which run tensorflow as service. Now I want to deploy the system and I try to use the mod_wsgi in apache2. The setup of the Flask server in apache2 works well. In my first edition of my Flask sever I used the if __name__ == '__main__': to preload the tensorflow model. Like this: my_app.py Now (under the mod_wsgi) Ι have created a .wsgi file like this: my_server.wsgi The problem is that like the above example (mod_wsgi) the code under the if __name__ == '__main__': it is not executed in the start of the server so as to preload my model and to be ready for the POST requests. I dont want in every POST request to reload my model. I want my model to be preloaded when the server is starting up. Any idea??,https://stackoverflow.com/questions/65235985,4878771.0,1
604,35710938,Are these functions equivalent in TensorFlow?,"I'm a newbie wit TensorFlow and I've studying it for the last few days. I want to understand if the following two functions are equivalent or not: 1. 2. If they are in fact different, what is the main difference?",https://stackoverflow.com/questions/35710938,859453.0,1
605,42256938,What does tf.gfile do in TensorFlow?,"I've seen people using several functions from tf.gfile such as tf.gfile.GFile or tf.gfile.Exists. I have the idea that tf.gfile deals with files. However, I haven't been able to find the official documentation to see what else it offers. It'd be great if you could help me with it.",https://stackoverflow.com/questions/42256938,5029595.0,1
606,55312887,Is there a simple way to set epochs when using TFRecords with Tensorflow Estimators,"There is a nice way to set epochs when feeding numpy arrays into an estimator But I can't track down a similar method with TFRecords, most people seem to just stick it in a loop Is there a clean way to explicitly set the number of epochs for TFRecords with estimators ?",https://stackoverflow.com/questions/55312887,200699.0,1
607,42478339,How to use a trained model on different inputs,"I implemented a relatively straightforward logistic regression function. I save all the necessary variables such as weights, bias, x, y, etc. and then I run the training algorithm... The model is saved and the prediction and accuracy of the trained model is displayed... This is all fine and dandy. However, now I want to be able to predict any given image using the trained model. For example, I want to feed it picture of say 7 and see what it predicts it to be. I have another module that restores the model. First we load the variables... This is good. Now I want to compare one image to the model and get a prediction. In this example, I take the first image from the test dataset mnist.test.images[0] and I attempt to compare it to the model. I know this will not work. I get the error... I am at a loss for ideas. This question is rather long, if a straightforward answer is not possible, some guidance as to the steps I may take to do this is appreciated.",https://stackoverflow.com/questions/42478339,4333347.0,1
608,46803985,How i get rating predict?,"I use DNNClassifier Estimator, and I want to predict rating. However, I don't know use predict. I expect the result, below. prediction rating : XX plz, help me, give me a guide( use predict) below, my code.",https://stackoverflow.com/questions/46803985,7198412.0,1
609,53403722,Scale actor network output to the action space bounds in Keras Rl,"I am trying to implement DDPG from Keras RL and have the following actor network. However, I would prefer to have the output scaled to a custom gym environment action space bounds for my problem. env.action_space. https://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html shows this using the tflearn api where they use What is the equivalent command for scaling the output layer according to my requirements?",https://stackoverflow.com/questions/53403722,7411022.0,1
610,43447363,no broadcasting for tf.matmul in tensorflow for 4D 3D tensors,"First I find another question here No broadcasting for tf.matmul in TensorFlow But that question does not solve my problem. My problem is a batch of matrices multiply another batch of vectors. x is a batch of matrices.There are 10*1000 matrices.Each matrix is of shape [3,4] y is a batch of vectors.There are 1000 vectors.Each vector is of shape[4] Dim 1 of x and dim 0 of y are the same.(Here is 1000) If tf.matmul had supported broadcasting,I could write But tf.matmul does not support broadcasting If I use the approach of the question I referenced above The result is of shape [10,1000,3,1000],not [10,1000,3]. I don't know how to remove the redundant 1000 How to get the same result as the tf.matmul which supports broadcasting?",https://stackoverflow.com/questions/43447363,5241934.0,1
611,71803405,Tensorflow - post training integer quantization,"I am trying to perform post training integer quantization to a model trained in Tensorflow 2.8.0, following the instructions mentioned here with some adaptations. I have all my images in a directory called ""customTF2/data/images"". I can't figute out though how to generate a representative dataset needed for the quantization. The official documentation, as well as the majority of examples found online, use either Tensorflow datasets or datasets where the images are already labelled and split into relevent subfolders (which is not the case for my project). Below is my code which fails with the error : Given shapes, [1,20,20,128] and [1,19,19,128], are not broadcastable.Node number 68 (ADD) failed to prepare. Not sure how I should perform the quantization for that dataset or how the previous code needs to be updated. Any help would be appreciated.",https://stackoverflow.com/questions/71803405,7127572.0,1
612,34706950,How many processes does TensorFlow open?,"I am using torque to run some CNN-based learning using tensorflow library. (1 CPU per task) When I run top on my server, I noticed that: load average: 677.29, 668.59, 470. I create a session like this: sess = tf.Session() So my question is there some place in documentation where I can read when and how many processes TensorFlow uses.",https://stackoverflow.com/questions/34706950,1886138.0,1
613,63576461,error while using tf.sparse.to_dense function,"I'm trying to parse my tfrecord dataset to use it in object detection. when I'm trying to change my sparse tensor to dense tensor I get following error which I can't understand it : my feature_description is : my code for parsing : I used a for loop to see if something is wrong with my data and tf.sparse.to_dense did its job perfectly with for loop, but when I use the .map(_parse_tfrecord) it gives me the error that I wrote above. result of printing x['image/object/bbox/xmin'] in _parse_tfrecord(x) : result of printing x['image/object/bbox/xmin'] in for loop: my for loop : What is my mistake here?",https://stackoverflow.com/questions/63576461,7645361.0,1
614,39564964,How to correctly create a batch normalization layer for a convolutional layer in TensorFlow?,I was looking at the official batch normalization layer (BN) in TensorFlow however it didn't really explain how to use it for a convolutional layer. Does someone know how to do this? In particular its important that it applies and learns the same parameters per feature map (rather than per activation). In other order that it applies and learn BN per filter. In a specific toy example say that I want to do conv2d with BN on MNIST (2D data essentially). Thus one could do: Where z = BN(z) applies the BN to each feature created by each individual filter. In pseudocode: we have a proper batch norm layer applied to it (in pseudocode omitting important details): i.e. for each filter f we apply BN.,https://stackoverflow.com/questions/39564964,1601580.0,1
615,47186485,What is the instruction of checking which version of cuda and cudnn the tensorflow is running on?,"What is the instruction of checking which version of cuda and cudnn the tensorflow is running on? like the tensorflow version could be checked by the instruction tf.version . I want to check my tensorflow 1.4 running on the 8.0 cuda and 6.0 cudnn, not running on the 9.0 cuda and 7.0 cudnn.",https://stackoverflow.com/questions/47186485,8908700.0,1
616,56141142,"How to pass ""step"" to ExponentialDecay in GradientTape","I tried to use an optimizers.schedules.ExponentialDecay isntance as the learning_rate to Adm optimizer, but i don't know how to pass ""step"" to it when train the model in GradientTape. I use tensorflow-gpu-2.0-alpha0 and python3.6. And i read the doc https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/optimizers/schedules/ExponentialDecay but with no idea how to tackle it.",https://stackoverflow.com/questions/56141142,3167681.0,1
617,61882452,Tensorflow tf.layer.batch_normalization: how to use global moving stats to do normalization during training?,"From the documentation, the arg training It never mentioned that this arg also controls whether to update global moving stats. Even if the update ops is added through they will not be updated is training=False. I am curious if there is a way to have these moving stats keep updating during training, at the same time use them to perform normalization?",https://stackoverflow.com/questions/61882452,11111055.0,1
618,48349536,Basic Tensorflow: Define Tensor variable using existing variables,"I have some very simple tensorflow code to rotate a vector: The code works fine when I hand-code the identity matrix. However, in its current form I get this error: I've tried specifying the shape in multiple ways, but I can't make this work. What am I doing wrong?",https://stackoverflow.com/questions/48349536,1747088.0,1
619,44831580,Receiving Negative Input Dimensions with TensorFlow MonitoredTrainingSession,"I'm attempting to switch from a tf.Session() to a tf.train.MonitoredTrainingSession (all on one machine, no fancy distributed computing), but I'm getting an error that I don't fully understand. Further down, I receive a little more information about the error: I'm using tf.contrib.seq2seq and my input and output sequences have variable lengths e.g. x_placeholder = tf.placeholder(tf.float32, [batch_size, None, 4]). I suspect that the queues that I'm using to read data and bucket data by sequence length are somehow failing or getting interrupted by the MonitoredTrainingSession, as I don't have this problem with a vanilla Session. Here's the code that sets up the MonitoredTrainingSession Here is how I'm creating my training hooks:",https://stackoverflow.com/questions/44831580,4570472.0,1
620,47018007,Why TensorFlow can not restore a variable initialized by a constant?,"I am new to TensorFlow. When I read tensorflow saving and restoring variables manual, I encountered a problem. I saved a variable initialized by a constant, but I can not restore the variable. The code is as following: Then I restore it. I want to get output like [2,3,4], but I got [ 2.80259693e-45 4.20389539e-45 5.60519386e-45]. It's all zeros. However, when I modify the first line in the first code snippet to I can get the right restored variable: [ 1. 1. 1.] I wonder the reason for this situation.",https://stackoverflow.com/questions/47018007,6630751.0,1
621,57254879,Saving model history on google cloud storage,I am running a tensorflow job on google ai-platform. After the model is trained I want to save model.history to file. Since I need to write to a cloud storage bucket I use tf.io.write_file. I have tried the following: I get he following error message: It looks like hist.history is a dictionary with strings as keys and lists as values. How can I get hist.history in the right format so that it can be written to file using tf.io.write_file?,https://stackoverflow.com/questions/57254879,9371809.0,1
622,57704850,How to convert SparseTensorValue to numpy array?,"I have a Tensorflow network and can get the values of the graph after I call Session().run(). However, I have some trouble converting SparseTensorValue to other types. For example, the following program creates a SparseTensorValue. What I want is some way to convert t to a np.array or np.matrix, for example, np.array([[2., 1.], [4., 3.]]). What I have currently is the following Is there a better way to perform the conversion? Especially, I want to eliminate the for-loop.",https://stackoverflow.com/questions/57704850,7709727.0,1
623,59130129,"Keras No data provided for ""<column_name>"". Need data for each key in:","I'm getting the following error (the one in the title) and I couldn't find any questions on stackoverflow that resolve my issue, I'm including the code below: I can't share the data and I renamed the columns but assume that my dataframe has columns named like this:""col1,col2,col3...col7"". the exact error message would be: No data provided for ""embed_col1"". Need data for each key in: ['embed_col1', 'embed_col2', 'embed_col3', 'embed_col4', 'embed_col5', 'embed_col6', 'embed_col7'].",https://stackoverflow.com/questions/59130129,10168218.0,1
624,41310637,No OpKernel was registered to support Op 'Conv2D' with these attrs,"new to this may be something dumb but cant get conv2d to run windows 10 anaconda 4.2.13 python 3.5.2 C:\windows\system32&gt;nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2016 NVIDIA Corporation Built on Sat_Sep__3_19:05:48_CDT_2016 Cuda compilation tools, release 8.0, V8.0.44 cudnn 5.1 TensorFlow 0.12 results in:",https://stackoverflow.com/questions/41310637,7336667.0,1
625,74833640,How to create a keras layer with a custom gradient *and learnable parameters* in TF2.0?,"this is a similar question to: How to create a keras layer with a custom gradient in TF2.0? Only, I would like to introduce a learnable parameter into the custom layer that I am training. Here's a toy example of my current approach here: This is failing with the following shape related error in the optimizer: I've been staring at the docs for a while, I'm a bit stumped as to why this isn't working, I would really appreciate any input on how to fix this toy example. Thanks in advance.",https://stackoverflow.com/questions/74833640,7861160.0,1
626,47432870,Can tf.contrib.training.batch_sequences_with_states handle input sequences with variable lengths?,"I was trying to use tf.contrib.training.batch_sequences_with_states to create padded batches of variable length input sequences in order to train an LSTM network. While reading the documentation I stumbled upon contradicting statements, concerning the capabilities of this function. Specifically the parameter input_sequences is confusing to me. How do I supply this function with multiple examples? Executing this code snippet leads to the following error message: An example showing how to correctly supply this function with multiple examples of varying input_sequence lengths would be really helpful!",https://stackoverflow.com/questions/47432870,5970048.0,1
627,52091047,Recalculate a convolution value with the eager execution,"I'm trying to use the eager execution. I create a training set, a weight, and a convolution layer. I declare the convolution and change the weights. How can I get the convolution calculated again without having to declare the layer again? I expected it to be something like that: But it does not work, the value of the convolution is not updated. How can I do this?",https://stackoverflow.com/questions/52091047,4285244.0,1
628,71524470,TypeError: Reduce.update_state() got multiple values for argument 'sample_weight',"I am creating a basic deep learning model and tried to compile it with tf.keras.metrics.Mean() but I keep getting this error and I am not sure how to fix it. I realized that tensorflow documentations for these metrics is supposed to use the ""add_metric"" function but I do not really understand how to use that function. Here is a simple code to reproduce that error: If anyone knows how to use the Mean() metrics, please let me know. Thanks!",https://stackoverflow.com/questions/71524470,16193032.0,1
629,45753336,TensorFlow post-LSTM fully connected layer outputs return the same values as each other,"I was trying to train a sequence-to-sequence LSTM model with a dataset with three labels: [1, 0] for detection of class 1, [0, 1] for detection of class 2, and [0, 0] for detection of nothing. After getting the outputs from the LSTM network, I applied a fully connected layer to each cell's output the following way: On the output, I apply tf.nn.sigmoid_cross_entropy_with_logits and reduce the mean. The model seems to work just fine achieving high accuracy and recall, except for the fact that in almost all the cases it outputs either [0, 0], or [1, 1]. The two logit outputs from the fully connected layer always have very similar values (but not the same). This effectively puts a hard-cap on precision of 50%, which the model converges to (but not a fraction of a percent above). Now, my intuition would tell me that something must be wrong with the training step and both fully connected outputs are trained on the same data, but curiously enough when I replace my own implementation with the prepackaged one from tf.contrib: without changing a single other thing, the model starts training properly. Now, the obvious solution would be to just use that implementation, but why doesn't the first one work?",https://stackoverflow.com/questions/45753336,7000919.0,1
630,55609036,What does steps mean in the train method of tf.estimator.Estimator?,"I'm completely confused with the meaning of epochs, and steps. I also read the issue What is the difference between steps and epochs in TensorFlow?, But I'm not sure about the answer. Consider this part of code: Also, the number of training samples is 400. I consider the MAX_STEPS // EVAL_EVERY_N_STEPS equal to epochs (or iterations). Indeed, the number of epochs is 100. What does the steps mean in nn.train?",https://stackoverflow.com/questions/55609036,8405742.0,1
631,43145200,Tensorflow: How to index a tensor using 2D-index like in numpy,"I would like to do the following numpy code in Tensorflow: given an input such as: I have tried the following, but seems like an overshooting: This works only because my first index is conveniently [0,1,2] but wouldn't be doable for [0,0,2] for example (besides looking really long and ugly). Would you have any easier syntax, something more tensoric/pythonic?",https://stackoverflow.com/questions/43145200,4449593.0,1
632,44132579,feed data into a tf.contrib.data.Dataset like a queue,"About the tf.contrib.data.Dataset (from TensorFlow 1.2, see here and here) usage: The way how to get data doesn't really fit any way how I get the data usually. In my case, I have a thread and I receive data there and I don't know in advance when it will end but I see when it ends. Then I wait until I processed all the buffers and then I have finished one epoch. How can I get this logic with the Dataset? Note that I prefer the Dataset interface over the QueueBase interface because it gives me the iterator interface which I can reinitialize and even reset to a different Dataset. This is more powerful compared to queues which cannot be reopened currently after they are closed (see here and here). Maybe a similar question, or the same question: How can I wrap around a Dataset over a queue? I have some thread with reads some data from somewhere and which can feed it and queue it somehow. How do I get the data into the Dataset? I could repeat some dummy tensor infinite times and then use map to just return my queue.dequeue() but that really only gets me back to all the original problems with the queue, i.e. how to reopen the queue.",https://stackoverflow.com/questions/44132579,133374.0,1
633,37766384,Tensorflow : How to recover a tensor properly,"Sorry for this newbie question, but i have some trouble learning tensor flow. I know basic things about ML ( linear regression, nn, cnn, perceptron, Kmeans ..) but i did not have any experience on a particular library. I'm currently learning how to save and recover datas from a graph. In my example, i do have a tensor which shape is equal to [168,8,8] It has been named saved_tensor But i don't know how to recover it properly, below what i've done so far. As you will see, it is working when shape is constant and as you would imagine, shape can be in the form [x,8,8] Regards, Pierre Have found the following site to learn tensorflow from the start :http://learningtensorflow.com",https://stackoverflow.com/questions/37766384,5937305.0,1
634,47533983,get result from tensor flow model,"I'm new to neural networks i have created a simple network according to this tutorial. It is trained to clarify text among 3 categories: sport, graphics and space https://medium.freecodecamp.org/big-picture-machine-learning-classifying-text-with-neural-networks-and-tensorflow-d94036ac2274 I wonder how after training i can feed this model with my own text and get the result Thanks",https://stackoverflow.com/questions/47533983,1102197.0,1
635,47030529,Why does reading a simple tfrecord crash python?,I wrote the following snippet for writing and reading a TFRecord. The last tf.run() statement stops python from responding to anything. What is the reason for this? I tried including tf.train.Coordinator() in the code but could not get that to work either.,https://stackoverflow.com/questions/47030529,2541982.0,1
636,35532457,TensorFlow placeholder variable for integer or boolean isn't working,"I am using the following code snippet in TensorFlow to conditionally pull data from one source or another: I keep obtaining error vomit as threads spazz out, but the recurring theme is the following error: Any help would very much be appreciated!",https://stackoverflow.com/questions/35532457,3067467.0,1
637,75329646,Tensorflow dataset iterator pick a sub-sample of whole data,"I have a code that generates an iterator from a Tensorflow dataset. The code is this: However, I want to do the manual splitting. For example, the MNISt dataset has 60000 training samples, but I want to only use the first 50000 (and hold others for validation). The problem is I don't know how to do so. I tried to convert it to NumPy and split based on that, but then I couldn't apply the map to it. I was wondering how to do so. P.S: The ordering of data is also important for me, so I was thinking of loading all data in Numpy and saving the required ones in png and loading with tfds, but I'm not sure if it keeps the original order or not. I want to take the first 50000 samples of the whole 60000 samples. Thanks.",https://stackoverflow.com/questions/75329646,12461032.0,1
638,44219077,label_keys type error on DNNCLassifier Tensorflow,"I want to embed labels into a DNNClassifier model in Tensorflow. Unlike the documentation example, here , I get the following error message: &lt; dtype: 'string'&gt;, got &lt; dtype: 'int64'&gt; On the other hand, if I make the label_key_values column a numpy.array, I will get the following error:",https://stackoverflow.com/questions/44219077,5279947.0,1
639,52371049,Minimizing two cost functions simultaneously w.r.t. two different parameters,"I have a model with two scalar cost functions C_1(p, t) and C_2(p, t). My objective is to simultaneously minimize C_1 with respect to p and C_2 with respect to t. In other words, choose p and t such that dC_1(p, t) / dp = 0 dC_2(p, t) / dt = 0 Notice that I don't want dC_1(p, t) / dt to be 0 or vice versa. In other words, this problem is not equivalent to minimizing some linear combination of C_1 and C_2. Currently, I'm doing this in by alternating between minimizing C_1 while passing p as the parameter list, then minimizing C_2 while passing t. However this is inefficient and causes problems with momentum-based optimizers. Is there a way to optimize both costs simultaneously in tensorflow without the gradients from C_1 being applied to t and vice versa? Edit: A quick example looks like this: I'm looking for a way to avoid having to alternate between C_1 and C_2, so that I can use momentum-based optimizers (and also because I suspect it will lead to better convergence).",https://stackoverflow.com/questions/52371049,2166880.0,1
640,41704484,What is difference between tf.truncated_normal and tf.random_normal?,"tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None) outputs random values from a normal distribution. tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None) outputs random values from a truncated normal distribution. I tried googling 'truncated normal distribution'. But didn't understand much.",https://stackoverflow.com/questions/41704484,5708247.0,1
641,67346290,How to calculate the Jacobian of a vector function with tensorflow,"I am new to TensorFlow. I would like to know what's wrong with the following code to calculate a Jacobian: where I expect a 2x2 matrix from the definition of the Jacobian of a vector function: but the result is [None, None]",https://stackoverflow.com/questions/67346290,7341479.0,1
642,66814389,"Conditional in TensorFlow dataset map is inconsistent with ""basic"" Python behavior","Consider that I have a file data.csv which contains: I would like to load this as a dataset and transform the label into a boolean such that it is true for class_1 and false otherwise. Here is my code: This throws an error: InvalidArgumentError: Input to reshape is a tensor with 3 values, but the requested shape has 1 [[{{node Reshape}}]]. Why is that? This is all the more confusing that when I replace the if~else with the one-liner that's commented out, label = label=='class_1', the problem disappears. What's happening here? I'm using TensorFlow 2.4.1 and Python 3.8.5.",https://stackoverflow.com/questions/66814389,5640161.0,1
643,49172710,"What does google cloud ml-engine do when a Json request contains ""_bytes"" or ""b64""?","The google cloud documentation (see Binary data in prediction input) states: I would like to understand more about how this process works on the google cloud side. I have found no way to create a serving input function which uses this nested structure to define the feature placeholders. I only use ""b64"" in mine and I am not sure what the gcloud ml-engine does on receiving the requests. Additionally when predicting locally using gcloud ml-engine local predict, sending the request with the nested structure fails, (unexpected key image_bytes as it is not defined in the serving input function). But when predicting using gcloud ml-engine predict, sending requests with the nested structure works even when the serving input function contains no reference to ""image_bytes"". The gcloud predict also works when leaving out ""image_bytes"" and passing in just ""b64"". An example serving input function I gave the example using images but I assume the same should apply to all types of data sent as bytes and base64 encoded. There are a lot of stackoverflow questions which contain references to the need to include ""_bytes"" with snippets of information, but I would find it useful if someone could explain a bit more in detail whats going on as then I wouldn't be so hit and miss when formatting requests. Stackoverflow questions on this topic",https://stackoverflow.com/questions/49172710,6859185.0,1
644,49018918,Tensorflow sharing variables under different variable_scope,"I have three networks, call them V, V_target, and Actor, and I'm trying to achieve the following setup: For those familiar with deep RL, I'm using this within an actor-critic algorithm with shared layers between the value and policy networks, plus a target network V_target. I tried the following: As expected, this doesn't work because the use of the outermost variable_scope prevents sharing between Policy and V_main: the Variable W has name Policy/shared/W in one scope but has name V_main/shared/W under the second scope. Why not use tf.name_scope(""Policy"") and tf.name_scope(""V_main"")? If I do that, the shared variables can be defined, but then I don't have a good way to get the variables under V_main and V_target. Specifically, because tf.name_scope does not append anything to names created by tf.get_variable, I cannot use tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES ,'V_main') and tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES ,'V_target') to get both sets of objects for the so-called ""target updates"". Is there any clever way around this?",https://stackoverflow.com/questions/49018918,2643159.0,1
645,53036403,KL Divergence of Normal and Laplace isn't Implemented in TensorFlow Probability and PyTorch,"In both TensorFlow Probability (v0.4.0) and PyTorch (v0.4.1) the KL Divergence of the Normal distribution (tfp, PyTorch) and the Laplace distribution (tfp, PyTorch) isn't implemented resulting in a NotImplementedError error being thrown. I assume as this is missing from both of these libraries that there is some good reason for this and that the user would be expected to implement it themselves with tfp.distributions.RegisterKL in TensorFlow Probability and torch.distributions.kl.register_kl in PyTorch. Is this the correct assumption? If so, can someone explain why the KL Divergence wouldn't be implemented for given distribution classes? I think I am missing something very basic about this. If my assumption is wrong, can someone explain how to properly have TensorFlow and PyTorch implement these operations? For additional reference, using for this example an older version of TensorFlow that works with Edward, In this minimal example above, I'm trying to implement the equivalent of the following edward toy example code in tfp (or in torch).",https://stackoverflow.com/questions/53036403,8931942.0,1
646,47380238,tensorflow variables didn't initialize properly,"Here I tried to create a simple model with one variable but the same across all the gpus. I tried to initialize the variable. However, I didn't get it initialized properly. I got this output:",https://stackoverflow.com/questions/47380238,4403135.0,1
647,43185641,Visualize tf.contrib.learn.LinearClassifier weights,"I've played with tensorflow's LinearClassifier data with the famous titanic dataset. (my question itself is down at the bottom - this is all some code for the model itself) So I have my feature columns: my input function: and my model: Now when i run the model, it does okaish, and I want to look at the weights of the model to better visualize them. So clf.weights_ exists (although it is listed as deprecated), so I just pull them out manually: And I get some decent results: Now my question is - How do I pull out the keys that were originally used? So I could better match the numbers, for example with Sex - the keys are originally mapped to male/female. Thanks!",https://stackoverflow.com/questions/43185641,2820297.0,1
648,67635660,Using Cifar-10 dataset from tfds.load() correctly,"I'm trying to use the Cifar-10 dataset to practice my CNN skills. If I do this it's ok: But I was trying to use tfds.load() and I don't understand how to do it. With this I download it, Now I tried this but is not working, Can somebody show me the way to achieve it? thank you!",https://stackoverflow.com/questions/67635660,8551424.0,1
649,60876340,How can I save a trained TensorFlow Federated model as a .h5 model?,"I want to save a TensorFlow federated model which was trained with the FedAvg Algorithm as a Keras/.h5 model. I couldn't find the documents on this and would like to know how it may be done. Also if possible, I'd like to have access to both the aggregated server model and the models of the clients. The code I use to train the federated model is below:",https://stackoverflow.com/questions/60876340,12992742.0,1
650,63756001,is word embedding in Keras a dimensionality reduction technique also?,"I wanted to understand the purpose of embedding_dim vs using a one hot vector of the entire vocab_size, Is it a dimension reduction to the one hot vector from vocab_size dim to embedding_dim dimensions or is there any other utility intuitively? Also how should one decide the embedding_dim number? Code - O/P -",https://stackoverflow.com/questions/63756001,12073433.0,1
651,40339510,Tensorarray initialization,"I am writing an example program to learn distributed tensorflow on 4 nodes. My program consists of assigning values to a simple numpy array. Then I convert them into tensorflow arrays to do a basic arithmetic addition operation. I store the outputs in another tensorflowarray. Finally convert this array into tensor to print it in the output. I want to overwrite the tensorarrays u1,u2,u3,u4. The above written program gives the following error:- Is there anyway to initialize the used tensorarrays after the first for loop? Please help.",https://stackoverflow.com/questions/40339510,6527887.0,1
652,67744841,Assign to a slice of a flattened view of a variable in TensorFlow,"In TensorFlow, I miss a straightforward way to assign something to a slice of the flattened view of a variable. Here's an example to achieve the same result in a roundabout way: But that's not an efficient solution for large tensors. Building multi_dim_indices should be unnecessary. scatter_nd_update is a sparse operation, but what I am looking for is really a dense assignment to a consecutive stretch of memory. With a numpy-like API I could write: Is there an efficient way to achieve the same result in TensorFlow, maybe with an uglier API?",https://stackoverflow.com/questions/67744841,1095888.0,1
653,45128032,Error while computing second derivatives in tensorflow,I am training a model that requires computation of second derivatives (i.e) gradients of gradients. Here is a short snippet that does that: I am getting the following error,https://stackoverflow.com/questions/45128032,8315023.0,1
654,65661130,Can't Create Non-Trainable Variables in Tensorflow v2,"I manually implement the batchnormalize layer. But the code in the initial function to create the nontrainable variables seems not to work. code: when training, another error was raised: TypeError: An op outside of the function building code is being passed a ""Graph"" tensor. It is possible to have Graph tensors leak out of the function building context by including a tf.init_scope in your function building code.",https://stackoverflow.com/questions/65661130,12151569.0,1
655,58997048,"Why is a new axis created, when only the first element is needed?","First of all, sorry for the vague title As I was interested in learning more about TensorFlow and Image segmentation, I was following their tutorial (https://www.tensorflow.org/tutorials/images/segmentation). However, I noticed something that I could not quite grasp, also not after some Googling around. In this section: What is the reason for first creating a new axis to the pred_mask vector, only right after that to pick only the first element? Why is not like I expected, as seen below:",https://stackoverflow.com/questions/58997048,12416937.0,1
656,63235245,Tensorflow combined non max suppression for candidate regions of an image,I want to run combined non max suppression in a set of windows for an image. I am using tf.image.combined_non_max_suppression from tensorflow as follow: But the output 'boxes' is just an array of zeros and ones:,https://stackoverflow.com/questions/63235245,4604986.0,1
657,54907610,Cost not changing in TensorFlow,"I'm trying to build a neural network in tensorflow to learn the library better, and my loss value is not changing. This is my code: My entire dataset is 985x12, but most of the columns are text, so I isolated two columns. I know that a neural network should not be used like this, with a 1:10:1 node system and with real-numbered labels, but I'm not trying to optimize the network, just learn the language. And I know that I should be using feature scaling/mean normalization, but as I said, I'm not really trying to optimize the neural net perfectly. This is my output: I've tried a lot of things. Originally, my cost function was ordinary cross-entropy, but since my data was real-number valued, I changed it to mean squared error. I also tried changing the optimizer, and it didn't change anything. Is the problem that I'm not trying to design the network well and I'm using a bad architecture, or is it something else?",https://stackoverflow.com/questions/54907610,11107475.0,1
658,44691406,How to understand tf.get_collection() in TensorFlow,"I am confused by tf.get_collection() form the docs, it says that And an example from the Internet is here Is it means that it collects variables from tf.GraphKeys.TRAINABLE_VARIABLES to from_scope? However, how can I use this function if I want to get variables from another scope? Thank you!",https://stackoverflow.com/questions/44691406,5046896.0,1
659,67943413,"In Tensorflow, how do you include a pre-trained model in a custom model?","I've got a custom model that I've pre-trained in a separate notebook called vae which I've saved using vae.save(). I'm now looking to implement a model which is a full training pipeline containing the pre-trained vae and some other (including a ResNet-50 from the Tensorflow gallery). In the Tensorflow documentation about Making new Layers and Models via subclassing it doesn't mention anything about including models in subclassed models. My question is how do I include my pre-trained VAE in a new subclassed model? I've already tried writing the code below, which works fine for training, but I haven't seen implementations like it elsewhere and I'm getting errors when trying to do reid.save() or reid.summary() on the model, so I presume there is a better way to do it:",https://stackoverflow.com/questions/67943413,15170857.0,1
660,59095603,Exploding LOSS in TensorFlow 2.0 Linear Regression Example using GradientTape,"I'm trying to construct a little educational example for multivariate linear regresssion, but the LOSS is increasing until it explodes rather than getting smaller, any idea? This even happens if I initialize the weights with the ""correct"" values (found out via a scikit-learn regressor)",https://stackoverflow.com/questions/59095603,3656912.0,1
661,60002889,Tensorflow 2: how to connect two layers from saved models?,"I have two saved models. I want to load and connect the output from model-1 to the input for model-2: I know you can set the Input when you instantiate a Layer by passing the input as a parameter (x = Input(shape)). But how do you set the Input, in my case x, on an existing layer? I've looked at the documentation for the Layer class here, but I can't see this mentioned? Edit: Adding the summaries of both models... Here is the top of model1: And here is the input of model2: I need the output of conv2d_18 in model1 to be fed as the input to block1_conv1 in model2.",https://stackoverflow.com/questions/60002889,3042437.0,1
662,40802457,Training vs Testing with Queues,"I'm using the setup described here to load some training images in batches, i.e., basically this: That's all good for training - however, I don't see how I can test the resulting network! What confuses me: Basically, this question boils down to: what's the canonical way to test a network built using the tf.train.shuffle_batch approach.",https://stackoverflow.com/questions/40802457,482601.0,1
663,51683495,what does it mean to set kernel_regularizer to be l2_regularizer in tf.layers.conv2d?,"I found in other questions that to do L2 regularization in convolutional networks using tensorflow the standard way is as follow. For each conv2d layer, set the parameter kernel_regularizer to be l2_regularizer like this Then in the loss function, collect the reg loss Many people including me made the mistake skipping the 2nd step. That implies the meaning of kernel_regularizer is not well understood. I have an assumption that I can't confirm. That is Is it correct or is there a better explanation?",https://stackoverflow.com/questions/51683495,1959884.0,1
664,57456584,AttributeError: 'Conv2D' object has no attribute 'shape',I am new to tensorflow I was tring to use tf.concat so I used this layout instead of the regular Sequential layout. But the error I get is AttributeError: 'tuple' object has no attribute 'layer' The error exists in the 2nd line The imported files are The error is Please Anyone tell me What to Do The Code is little changed than before Please take a look again,https://stackoverflow.com/questions/57456584,11792842.0,1
665,55765618,Using class_werights with multiple loss functions,"My question is that I have network with two outputs and each output has its own loss function. I want to apply the class_weight on only one of the output, how I can achieve that. I searched the documentation of class_weights and I don't think it support multiple outputs. Because they didn't mentioned it. Also I don't know exactly the current class-wegiht strategy . Is it going to apply for both outputs or it will be applied on only the first one. Any one have thoughts about what should I do?",https://stackoverflow.com/questions/55765618,8262057.0,1
666,45224136,How to programmatically add multiple LSTM cells,"So, here is a piece of my existing code: I've got this running which is a nice start but i'm looking to emulate another model that is using 3 LSTM cells. I'm not quite sure I know how to code this. Would it be this: Any feedback would be much appreciated",https://stackoverflow.com/questions/45224136,7148245.0,1
667,48869256,Distributed Tensorflow: Unable to run evaluation-only worker,"I'm trying to distribute training and evaluation over two machines: To do so, I'm trying to adapt the tf.contrib.learn.Experiment framework, but I can't seem to get the cluster specification right. This is a stripped-down version of my code: The main function looks as follows: where unused_argv contains a job name and optionally an index (defaults to 0). Running three processes with the appropriate job names and task ids, I can't get the worker go past the session initialization step because it expects evaluator to communicate with the chief worker (which it doesn't, if continuous_eval is called, apparently). Researching the issue, I found this answer where they suggest to add a device_filter, so I tried adding: This effectively unlocks the worker and ps, but the evaluator then crashes when attempting to restore the newest checkpoint: What is the proper way to designate a worker for evaluation only? In the logs from Tensorflow, I see that the RunConfig used has a parameter '_evaluation_master': '', but I can't find any documentation about it. Is this somehow related? Are there any working examples that show how to distribute experiments separating training and evaluation? As suggested, I added log_device_placement=True when defining session_config. The log output, however, seems to crash before logging the device placements: This is slightly confusing, shouldn't I see the placement log at session creation? And doesn't the restore op need the session to run? Setting allow_device_placement=True also didn't change anything in the log and error. setting log_device_placement=True for all machines only logs it in worker:0 (aka the master), which I assume is the expected behaviour Updated the code above to reflect how I set allow_device_placement=True (Only the main function changed).",https://stackoverflow.com/questions/48869256,3214872.0,1
668,69549395,How to view predicted values from MultiStep tensor flow model?,"I used timeseries dataframe with 9 variables, trying to predict 1 of them. I followed the official tutorial and got the final model. But I don't know how to view the predicted values. #Split the data column_indices = {name: i for i, name in enumerate(df.columns)} n = len(df) train_data = df[0:int(n*0.7)] val_data = df[int(n*0.7):int(n*0.9)] test_data = df[int(n*0.9):] num_features = df.shape[1] #Data windowing.... #Split the data #Train the model class MultiStepLastBaseline(tf.keras.Model): def call(self, inputs): return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1]) last_baseline = MultiStepLastBaseline() last_baseline.compile(loss=tf.losses.MeanSquaredError(), metrics=[tf.metrics.MeanAbsoluteError()]) multi_val_performance = {} multi_performance = {} multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val) multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0) multi_window.plot(last_baseline) Finally I got this plot model output plot Now how can I see the predicted values for next two days? I tired the following but it says missing positional argument x MultiStepLastBaseline.predict(test_data)",https://stackoverflow.com/questions/69549395,5500767.0,1
669,70979815,How to crop an image using TensorFlow?,"I'm trying to crop an image where I have a detected object. From TensorFlow's documentation there is a function. I'm trying to work out how to get the given arguments but not sure what information to use. Here's the code I'm working with. With this being the result, I'm trying to crop out everything but the bounding box - Identified object",https://stackoverflow.com/questions/70979815,18114544.0,1
670,40435329,TensorFlow:What should be the first parameter for prediction using sess.run() in TensorFlow after loading a saved model.ckpt file?,I am new to TensorFlow and machine learning. I am trying to classify two objects a cup and a pendrive (jpeg images). I have trained and exported a model.ckpt successfully. Now I am trying to restore the saved model.ckpt for prediction of an image. Here is the script: In the above script what should I use as the first parameter in sess.run() ? I have read many stackoverflow and github posts but havent found a solution that works for my case. The TensorFlow Documentation is also not very clear. Thank you in advance,https://stackoverflow.com/questions/40435329,6438307.0,1
671,50779554,NameError: name 'GATE_OP' is not defined #tensorflow,I'm not working long with Tensorflow and have encountered a problem I don't really understand. This is the code which causes the problem because GATE_OP is not known to PyCharm: When I try to execute an example I always get NameError: name 'GATE_OP' is not defined. But I have imported Tensorflow. This is the example I've reused from the git repository https://github.com/lucfra/FAR-HO/blob/master/far_ho/examples/Example_weighted_error(and_lr_and_w0).ipynb: I'm using Python 3.6 on MacOs with Tensorflow Version 1.7.0. Thanks in advance!,https://stackoverflow.com/questions/50779554,9747182.0,1
672,46573345,How to correctly use the tf.layers.batch_normalization() in tensorflow?,"I'm confused by the tf.layers.batch_normalization in tensorflow. My code is as follows: The training seems to work well and the val_accuracy is reasonable (say 0.70). The problem is: when I tried to use the trained model to do test (i.e., the test function), if the phase_train is set to False, the test_accuracy is very low (say, 0.000270), but when the phase_train is set to True, the test_accuracy seems right (say 0.69). As far as I understood, the phase_train should be False in testing stage, right? I'm not sure what the problem is. Do I misunderstand the batch normalization?",https://stackoverflow.com/questions/46573345,2495287.0,1
673,50229777,Efficient multi-feature similarity with each feature in tensorlflow,I want to calculate multi-feature similarity with each feature in tensorflow. But I don't know how to write it efficiently. Here is my sample code: Can anyone tell me how to write efficient coding style in tensorflow? Thanks!!,https://stackoverflow.com/questions/50229777,7239131.0,1
674,55399622,How to implement on Keras YOLOv3 decode outputs?,"I'm trying to train a YOLOv3 model using Keras (and this git as a reference: https://github.com/experiencor/keras-yolo3) and my own dataset. Even though, I've achieved good results in the training part, when I do inference of my model it runs at nearly 15 fps. Using other implementations in, for example, TF-Slim It has run at 30 fps (GTX 1070 used). While doing some testing I've discovered that the bottleneck is because the Keras model outputs the 3 feature maps of layers 82, 94 and 106 and the decode part to obtain the bounding boxes and scores is done using numpy on CPU. The model that achieved 30 fps was the one of https://github.com/YunYang1994/tensorflow-yolov3. The difference between these two models is that when YunYang freezes the model makes use of a predict method in YOLO's class. I want to perform these same operations inside my Keras model, so I've thought of using a Lambda layer or create a custom layer. However, I don't know if it will be possible. Would it be possible to add to the model this extra layer? Another option I've thought is to convert the model that outputs the three feature maps to .pb, then run a tf.sess and do there the method to get the bounding boxes and scores. Finally, I would freeze this new model. Although, I'm not sure if this one is even a worst idea... Thanks!",https://stackoverflow.com/questions/55399622,7021501.0,1
675,35819407,A Simple Network on TensorFlow,"I was trying to train a very simple model on TensorFlow. Model takes a single float as input and returns the probability of input being greater than 0. I used 1 hidden layer with 10 hidden units. Full code is shown below: The problem is, I am getting terribly unrelated results. Model does not learn anything and returns irrelevant probabilities. I tried to adjust learning rate and change variable initialization, but I did not get anything useful. Do you have any suggestions?",https://stackoverflow.com/questions/35819407,5540330.0,1
676,48931351,How to update model (Variable) in custom python operator (tf.py_func)?,"I need to write a custom Op in python, which will generate an output based on a model and another op that will update the model. In the following sample code, I have a very simple model of just a scaler, w (but in reality it will be a nxm matrix). I figured out how to ""read"" the model as demonstrated in the custom_model_read_op function (in reality much more complicated). However, how can I create something similar that will update w in some custom complicated way (using custom_model_update_op)? I assume this is possible given the fact that Optimizer ops like SGD are able to do this. Thanks in advance!",https://stackoverflow.com/questions/48931351,1625820.0,1
677,61014502,TensorFlow get stuck after use concatenate layer,"I have the next model: But when I try to fit it, get stuck and only appears Epoch 1/100 and nothing more happens even if i let it run for hours. But when I remove the concatenate layer, everything go well. I'm using Google colab. Why is this happening?",https://stackoverflow.com/questions/61014502,7136476.0,1
678,44779086,Tensorflow practice y = xw how do you initialize vector x?,I am studying with first machine-learning practice. This is the prediction system of monthly temperature. train_t has the temperatures and train_x has the weight for each data. However I have a question where initializing train_x However I don't understand here What does this mean?? There is no comment about this in my book?? Why train_x is initialized here??,https://stackoverflow.com/questions/44779086,1942868.0,1
679,47056814,Tensorflow: tf.name_scope without 'with',"I would like to use tf.name_scope for something like this: I would like to avoid using the with tf.name_scope('something') as scope notation, as I don't know when the first time I want to use the name scope something. The simple my_scope = tf.name_scope('something') doesn't work, resulting in the error TypeError: expected string or buffer. Right now I use: which works, but is very unsatisfying.",https://stackoverflow.com/questions/47056814,3747801.0,1
680,62177038,Intersection of two Tensors in Tensorflow while keeping order,"Suppose that I have two tensors x = tf.constant([[""a"", ""b""], [""c"", ""d""]]), y = tf.constant([[""b"", ""c""], [""d"", ""c""]]) Then, I want to get the following tensors: x_ = [[0, 1], [1, 1]] y_ = [[1, 0], [1, 1]] How is x_ constructed? The (0,1) entry in the first row of x is in the first row of y, so we set the (0,1) entry of x_ equal to 1. In addition, both the (1,0) and (1,1) entries of x are in the second row of y, so we set the (1,0) and (1,1) entries of x_ equal to 1. How is y_ constructed? The (0,0) entry of the first row of y is in the first row of x, so we set the (0,0) entry of y_ equal to 1. In addition, both the (1,0) and (1,1) entries of y are in the second row of x, so we set the (1,0) and (1,1) entries of y_ equal to 1.",https://stackoverflow.com/questions/62177038,13673688.0,1
681,47851283,Running subgraphs and feeding intermediate variables,"I have an autoencoder model in Tensorflow that roughly can be written as (this is unrealistically simplified example): So I have input placeholder x, intermediate representation z, weights matrix W and output y. Then I train my model like this: Now given some test data I can check the output of the model: I can also get the intermediate representation for that data What I want is to be able to change my intermediate representation (z) and obtain the decoded results y. Something like this: Of course, it doesn't work as z is not a placeholder, I have an error like You must feed a value for placeholder tensor 'x'. If I provide x, the results will not depend on z at all (which again is what we can expect). So my question is: how can I run a subgraph that calculates y as a function of z and feed it with my own values of z?",https://stackoverflow.com/questions/47851283,3025981.0,1
682,66697266,Using a Windowed Dataset for Time Series Prediction,"I have been working on a time series analysis using a LSTM model implemented via TensorFlow 2.0. Now, it is clear that this is accomplished by creating windows of data. For instance, the first 30 values of the time series is a window, i.e. the input and the next value will be the target. I came across the following function for creating these windows, This returns a tf.data.Dataset object when a series is passed in along with the other arguments like so, On examination of this object, I found that each element is a batch of 128 windows and each window contains 30 values (as defined by the arguments passed). This is all well and good, but what confuses me is that after defining a model like so, this dataset itself can be passed in to the model.fit() method, How is it possible that the target does not need to be defined here? You would normally need to do something like model.fit(x=inputs, y=targets, epochs=num_epochs). How come this is not necessary?",https://stackoverflow.com/questions/66697266,9542989.0,1
683,54569726,How Does RL continuous control via Gaussian policy work?,I'm implementing Soft-Actor-Critic algorithm but I'm not able to understand how the stocastic policy works. I've searched online but I don't find any site interesting that explains well the following implementation. The only thing that I understood is that in the case of stocastic policy we model it as a Gaussian and we parametrize the mean and the log std (I think that std is standard deviation) but for example: why do we need the log std and not just std?,https://stackoverflow.com/questions/54569726,10916087.0,1
684,55203017,Use of colocate_with in Keras,"Is there another use of colocate_with in Keras? The Keras Model API code documented here: https://keras.io/models/model/ and here: https://www.tensorflow.org/api_docs/python/tf/keras/models/Model results in a deprecation warning. The referenced code does not directly use colocate_with (though perhaps the API uses colocate_with). Will this Model API be deprecated or is the warning in error? Example code from Keras documentation: Example code from TensorFlow documentation: Both of these examples result in a deprecation warning: This warning and use of colocate_with appears to be different than that referenced in ""What is colocate_with used for in tensorflow?"" Will the documented method of using the Model API be deprecated? Will there be an alternative short of using a Sequential model?",https://stackoverflow.com/questions/55203017,11214686.0,1
685,44335033,Does 'tf.assign' return its argument?,"The Tensorflow documentation says that tf.assign(ref, ...) returns ref, but it appears instead (not surprisingly) to return a Tensor (attached to the assign op): produces demonstrating that the argument Q and what's returned qop behave differently (and that Q is unchanged until qop is executed). Is the return value of tf.assign described correctly in the documentation?",https://stackoverflow.com/questions/44335033,656912.0,1
686,57605741,Convolutional Net Model not working on very simple data,"I have generated a very simple dataset. Basically, a 3x3 image with either a column of white pixels or a row of white pixels. I am trying to train a convolutional net model to distinguish between the images of either a row white pixels or a column of white pixels. Hoping by the end of the training, the filters(two 2x2 conv filters, no bias in conv-layer) will be doing some sort of vertical/horizontal edge detection. This is my architecture: *I am using a softmax layer as output for this experiment. I have the following parameters set up: Pretty straight forward classification task, but for some reason, which escapes me, this model doesn't learn squat! I have tried changing the learning rate, number of epochs, the optimizer, loss function, etc. but still nothing. With the random seed set to 48, I get the following 2 filters which remain same after training :(, so no learning at all. BTW, I ran this experiment on a conv-net I created from scratch(all numpy) with the same architecture, it performed much better. The data is set up as follows: So, someone where am I going wrong.",https://stackoverflow.com/questions/57605741,4699994.0,1
687,48767184,Tensorflow running session multiple times in a loop,I'm trying out a simple Tensorflow code to compute the product of two matrices multiple times. My code is as follows: Upon running session.run() in the for loop: I get the following error: I looked at the sample code for MNIST on the Tensorflow website but they run 'session.run()' in a similar manner in a for loop. I'm looking for any insight on why 'session.run()' in my code does not work inside a for loop. Thank you.,https://stackoverflow.com/questions/48767184,5279281.0,1
688,47190556,Tensorflow reuse neural network,"I'm new in tensorflow and I've been training a simple neural network, but once is trained, I don't know how to reuse the NN to get the outputs of an input. So, once I've saved the model and try to restore it, I don't know how to continue to get the output of the NN from the ""input_data"".",https://stackoverflow.com/questions/47190556,8909906.0,1
689,53192619,Using gather_nd to build matrix,"I am trying to construct the rank-2 tf.float tensor, x, from a rank-3 tf.float tensor, y, and rank-2 tf.int32 tensor, z as: x[i][j] = y[i,z[i][j],j] I know that I need to use tf.gather_nd as: where indices[i][j][:] = [i,z[i][j],j] However, I am having trouble using tensorflow functions to essentially expand z into a higher-rank to construct indices. I am trying to maintain these operations in a vectorized form. Is it more practical to simply use tf.stack as, indices = tf.stack([ii,z,jj],axis=-1) where ii[i,:] = i and jj[:,j] = j?",https://stackoverflow.com/questions/53192619,6091064.0,1
690,52256503,Why does tf.variable_scope has a default_name argument?,"The first two arguments of tf.variable_scope's __init__ method are If I understand correctly, this argument is equivalent to (and therefore could be easily replaced with) Now, I am not sure I understand why it was deemed necessary to have this special treatment for the scope name — after all, many parameters could use a parameterizable default argument. So what is the rationale behind the introduction of this argument?",https://stackoverflow.com/questions/52256503,9973879.0,1
691,68899955,"loading keras model, TypeError: 'module' object is not callable","I have searched through stackoverflow and read through documentation but somehow still my trained model is not being loaded! I have checked following links and many more so please do not mark as duplicate straight away. thank you here is my model: And After that I have some test and train generator as follows, The dataset is classical dog-vs-cat dataset and I'm trying to achieve one-class classification task. Then finally, I do compile the model Then I do save model as follow Either I do save in that format or 'my_custom_model.h5' it saves perfectly without any error. If I use just save, then a folder is created with 'assets, variables, .pb files' that is expected as mentioned in posts of stackoverflow. ** Then here comes the problem ** All throw same error TypeError: 'module' object is not callable I know I'm doing some mistake or model is bit different, please guide me to the right direction where I can look for solutions. Python: 3.7.2 Tensorflow: 2.6.0 Keras: 2.6.0 Full Stack Trace",https://stackoverflow.com/questions/68899955,8147960.0,1
692,34097457,TensorFlow Training,"Assuming I have a very simple neural network, like multilayer perceptron. For each layer the activation function is sigmoid and the network are fully connected. In TensorFlow this might be defined like this: The design target for this model is to map a n_fft points fft spectrogram to another n_fft target spectrogram. Let's assume both the training data and target data are of size [3000, n_fft]. They are stored in variables spec_train and spec_target. Now here comes the question. For TensorFlow is there any difference between these two trainings? Training 1: Training 2: Thank you very much!",https://stackoverflow.com/questions/34097457,5231637.0,1
693,58190584,Unable to pass padded_batch tf.data.Dataset to tf.estimator,I have a tf.data.Dataset object as output from an input_fn used with a tf.estimator. Trivial example below: This results in the error below: I was able to train a tf.keras model with a slightly modified version where there are no formats for the required feature_columns argument. Am I labeling by variant_dataset 'x' incorrectly? I am expecting this to simply pass to the estimator like any other dataset api. The piece I'm not very familiar with and attempting to become more familiar with is the use of padded_batch and if there are other considerations I may need to consider when using.,https://stackoverflow.com/questions/58190584,11311824.0,1
694,41317117,Cannot achieve repeatability in tensorflow,"I am trying to learn tensorflow with High level API for learning with TensorFlow and having problem with not getting repeatable results. TensorFlow 0.12.0-rc0 (CPU Only) python 3.5 As you see, I am trying to put random seed MY_SEED wherever possible, but results are different from run to run. What did I miss?",https://stackoverflow.com/questions/41317117,4055043.0,1
695,68080447,Error calling adapt in TextVectorization Keras,"I have the following code, with a custom standardization definition. But when I call adapt, like this, I got the next error According to their explication, Blockquote Source But I can't see where the error is EDIT: I'VE DONE SOME RESEARCH IN MY CODE When I pass an array like ['The other day was raining', 'Please call me later'], the function custom_standardization() returns something like this So it seems that it is not respecting to have same shape. Why it changes thought?",https://stackoverflow.com/questions/68080447,12712848.0,1
696,56250541,Can anyone explain the following Tensorflow code? How could the function recognize the input and take it as numpy array?,"Can anyone help me to explain the following TensorFlow code? I define a simple function test_loss which takes input as a numpy array; when I call this function test_loss(out1), the input is a TensorFlow tensor; how could python recognize the input tensor and take it as numpy array? I am really confused.",https://stackoverflow.com/questions/56250541,9357193.0,1
697,64830568,tf.gather_nd to get values of 2d array from 1d array of indices,"I have a 2D array of values and a 1D array of indices. I want to get the value of each index at each element of the 2D array using tf.gather_nd or some other numpy or tensorflow command like so: What I currently have is this mess: A cleaner solution that avoids using zip and list would be greatly appreciated, as I don't think I'm currently utilizing tf.gather_nd completely correctly.",https://stackoverflow.com/questions/64830568,11656914.0,1
698,55354612,How to turn a tf tensor to some form that keras can fit?,"I'm using keras to build a network, however, I have to declare a tf tensor to do some cuda computation in set_abstraction_msg and set_abstraction methods, and then turn the tensor back to some kinds of form that keras can complie and fit. How can I do that? The method below is generally called getModel, but I called it pointnet2 instead. The code below is mainly to, first declare the tensorflow placeholder, second do some cuda computation and apply Conv2D and BatchNormalization in set_abstraction_msg and set_abstraction methods, third apply some Dense, BatchNormalization and Dropout ops. I tried Input(tensor=input_points). It turned out that prediction is a tensor, which is prefect for me. But I want tensor turned to keras form in the end, and above code got some error like this at this line Model(inputs=model_input, outputs=prediction): For more information, the complete code project is here: https://github.com/HarborZeng/pointnet2-keras",https://stackoverflow.com/questions/55354612,8473101.0,1
699,50903390,Cannot get next batch's embedding indexes,"The first module minibatch. and the second module model. With the last line next_idx = batch.next_batch, I want to get the next batch's indexes to look up in embeddings. But it keeps showing empty list as result.",https://stackoverflow.com/questions/50903390,9322512.0,1
700,67351796,Keras incompatible shapes NN,"So I have this neural network and I am feeding examples ""X"" and labels ""Y"" whose shapes are: The code for the model looks like: Now for some reason once I run this i get the error: I am confused because I fed it data where each example of both ""X"" and ""Y"" have shapes (10, 2). So why is it saying that I passed it (None, 10, 2) and (None, 20)",https://stackoverflow.com/questions/67351796,15763070.0,1
701,64842113,"Keras `Input` Layer is returning layer [(None, 32)] rather than (None, 32) in summary","Keras ver 2.4.3 I'm creating a simple Image-Caption Model which has two inputs and an output. The model definition code is as follows: The model however gives a error on model.fit() and I noticed the Input Layer is giving a strange output which I believe is causing the error. snippet of summary looks like this: As you see the output shape for the input layers need to (None, 512) and (None, 39) but however they seem to be a list. And hence, I'm getting a ValueError: no grad available for the variables though I did test the python data-generator. I believe this Input layer api is causing some strange error. Any Ideas ?",https://stackoverflow.com/questions/64842113,7712643.0,1
702,49150587,"Distributed TensorFlow [Async, Between-Graph Replication]: which are the exactly interaction between workers and servers regarding Variables update","I've read Distributed TensorFlow Doc and this question on StackOverflow but I still have some doubt about the dynamics behind the distributed training that can be done with TensorFlow and its Parameter Server Architecture. This is a snipped of code from the Distributed TensorFlow Doc: And here part of the answer of the StackOverflow question that I read: I have to reproduce this kind of parameter server architecture in another environment and I need to deeply understand how workers and PS tasks interact with each other inside the TensorFlow framework. My question is, does the PS task do some kind of merging or updating operation after receiving the value from the workers or it just store the newest value ? Can be something reasonable just storing the newest value ? Looking at the code from the TensorFlow documentation I see that the PS task just do a join() and I wonder behind this method call which are the complete behaviour of the PS task. One more question, what is the difference between compute a gradient and apply a gradient ?",https://stackoverflow.com/questions/49150587,9099269.0,1
703,48486306,Prediction failed: contents must be scalar,"I have successfully trained, exported and uploaded my 'retrained_graph.pb' to ML Engine. My export script is as follows: I build my prediction Json using the following: However this fails with the response: Any help appreciated, I'm so close I can taste it :D",https://stackoverflow.com/questions/48486306,3667551.0,1
704,73607799,How to fit model to a multidimensional output space using pandas dataframe as input?,"I want to fit a dataframe to a sequential deep learning model with multiple units in the final layer of the model. I'm new to deep learning. Code: Traceback: I can only fit the model if I set the units to 1 in the final layer. How do I use multiple units in the final layer of the model? I tried reshape(-1,1) and still get the same error. Data:",https://stackoverflow.com/questions/73607799,19785334.0,1
705,54087060,Bug related to tf.sparse_tensor_dense_matmul(),"Example The following example has some bugs that I can not solve. System information tesorflow-gpu = 1.9.0 python = Python 3.6.5 :: Anaconda, Inc. Ubuntu 16.04",https://stackoverflow.com/questions/54087060,10809789.0,1
706,61056770,Application hangs if training tff Model using a created Client DataSet,"I create a DataSet following EMNIST. But When I train my model it seems to be trapped in a infinite loop and RAM gets filled in a short time. Here is the code. I print my dataset and EMNIST dataset to draw a comparison (BAL1 is my DataSet): Here is the result: and this is the part I use BAL1 to replace EMNIST: My model can work well with EMNIST. But if I change EMNIST to my dataset, the ""Python3 Google compute Engine"" becomes busy. Even after waiting a long time nothing is calculated, so I have to interrupt it.",https://stackoverflow.com/questions/61056770,13086990.0,1
707,44378333,Tensorflow saver.restore() not restoring network,"I am completely lost on the the tensorflow saver method. I'm trying to follow the basic tensorflow deep neural network model tutorial. I want to figure out how to train the network for a few iterations, then load the model in another session. Skipping ahead to training. The console prints out: Next I want to load the model Now I want to re-test to see if the model loaded The console prints out: It doesn't appear that the model is saving any of the data? What am I doing wrong?",https://stackoverflow.com/questions/44378333,7742534.0,1
708,47390473,is there a simple way to use features from tf.data.Dataset.from_generator with a custom model_fn(Estimator) in tensorflow,"I am using tensorflow dataset api for my training data, the input_fn and generator for tf.data.Dataset.from_generator api then I created a custom model_fn for my Estimator with some code like : when training : however, the code doesn't work since the features parameter for function model_fn is something : code ""features[""x""]"" will fail and tell me : if I changes input_fn to : the code goes on because features now is a dict. I have searched code for estimator and found it use some function such as to retrieve features and label from input_fn, but I have no idea about why it passes me(model_fn) two different data type of features by using different dataset implements, if I want to use my generator mode, then how to use that type (IteratorGetNext) of features ? thanks for any help! [UPDATED] I had made some change to code, however, still failed at tf.layers.dense, now it said although the features is a dict : in the correct case, it is something : I learned similar usage from https://developers.googleblog.com/2017/09/introducing-tensorflow-datasets.html but there is no official example for the generator case which returns an iterator to a custom model_fn.",https://stackoverflow.com/questions/47390473,1693720.0,1
709,49843243,TensorFlow MNIST DataSet,I started to learn TensorFlow by reading a book which started by classifying MNIST digits. Link to the code This is the block of code which executes the session. My question is - the for loop iterates STEPS times and batch is the mini batch of size 50. Shouldn't we iterate STEPS times over the whole training set? This code only trains 50 images in an epoch. What am I missing here? How does the next_batch() method work,https://stackoverflow.com/questions/49843243,8726732.0,1
710,61850203,How to implement TF Lite inference in Python,"For research purposes, I'm trying to understand how TF Lite does its inference. I'm interested only in the software logic. I'm using TensorFlow 2.1 and TensorFlow Model Optimization 0.3.0. As an example, I use a very simple fully connected network: I train the network on mnist with quantized aware training. And then quantize the network with TF Lite: In order to make sure that I know what I'm doing I did 3 things: I used TF to get outputs from the 32 bit model. I used TF Lite to get outputs from the quantized model. I implemented in Python the forward pass for the 32 bit model and compared its outputs to the previous 2. Now I'm trying to understand how to implement the forward pass of the quantized model. Using interpreter.get_tensor_details(), I get the following output: I'm using this paper as a reference: https://arxiv.org/pdf/1712.05877.pdf I also read this page: https://www.tensorflow.org/lite/performance/quantization_spec My current implementation goes like this: the function quantize_multiplier_smaller_than_one is my Python implementation for the C function here: https://github.com/google/gemmlowp/blob/master/doc/quantization_example.cc So my questions here are, is this the correct approach? I'm definitely missing some calculation here, what is it? And also, when I have a bigger network, how do I know how to systematically use the correct indexes to pull the quantization params for each layer. Many thanks for any advice.",https://stackoverflow.com/questions/61850203,1466792.0,1
711,49505986,How do i get the VALUES of trainable variables from a restored graph & checkpoint in tensorflow,"I want to get the values of the variables from a trained model. I have a check point file and I can restore graphs and checkpoints and do inference with them just fine. However, I'm finding it extremely difficult to figure out how to get the trainable variable values (like the weight and bias values, not names...i want the VALUES) after I restore the checkpoint and graph. I've read through Tensorflow documentation and there's lots of suggestions regarding ""with variable_scope"", ""reuse = True"", and ""tf.get_variable(""myvar"") within the scope...etc, but I get errors stating either the variable already exists or it hasn't been initialized. tf.graphkeys only returns names...not values.",https://stackoverflow.com/questions/49505986,3496060.0,1
712,49705034,How to use regularization with Dynamic_rnn,I want to use l2-regularizatin with Dynamic_rnn in tensorflow but it seems this is not handled gracefully currently. While loop is the source of error. Below is a sample code snippet to reproduce the problem How can i add l2 regularization if i have dynamic_rnn in my network? Currently i can be going ahead with getting trainable collection at the loss calculation and adding l2 loss there but i also have word vectors as trainable parameters which i dont want to regularize on,https://stackoverflow.com/questions/49705034,6546694.0,1
713,69023519,Python Tensorflow - InvalidArgumentError: cannot compute BatchMatMulV2 as input,"I am new in tensorflow. I am doing this- For this, I am getting this error- Can anybody please help?",https://stackoverflow.com/questions/69023519,2193439.0,1
714,42367538,Tensorflow. Switching from BasicRNNCell to LSTMCell,I have built a RNN with BasicRNN now I want to use the LSTMCell but the passage does not seem trivial. What should I change? First i define all the placeholders and variables: Then I unstack the labels: Then i define my RNN: The error that I get is:,https://stackoverflow.com/questions/42367538,6317571.0,1
715,49986029,Writing the following CNN in tensorflow,"I am new to this Deep Learning. I have learnt the basics through reading and trying to implement a real network to see how/if it'll really work. I chose Tensorflow in digits and the following network because they give out the exact architecture with training materiel. Steganalysis with DL I wrote the following code for the architecture in Steganalysis with DL by looking at networks existing networks in digits and Tensorflow documentation. I tried running it but the accuracy is pretty low. Could someone tell me if I've done it completely wrong or what's wrong with it and tell me how to properly code it? UPDATE: Thank you Nessuno! With the fix you mentioned I came up with this code: Solver type is SGD. Learning rate is 0.001. I am shuffling training data.I have increased training data to 6000 (3000 per category, 20% from that is reserved for validation). I downloaded the training data from this link. But I am only getting the following graph. I think this is overfitting. Do you have any suggestions to improve the validation accuracy?",https://stackoverflow.com/questions/49986029,8789273.0,1
716,68509390,How to determine the proper dimension of a TensorFlow embedding_column,"I'm new to tensorflow and trying to understand embedding_column. It takes a parameter dimension that isn't totally making sense to me. In this example (from a Google tutorial), dimension = 8 Which I had assumed was 2^3, since there are 3 possibilities and each can be ""on"" or ""off"". However in the documentation example: I'm not tracking why dimension is 9 here. Can anyone explain what the rule should be?",https://stackoverflow.com/questions/68509390,9078185.0,1
717,39848466,"Tensorflow + Keras + Convolution2d: ValueError: Filter must not be larger than the input: Filter: (5, 5) Input: (3, 350)","I have been trying to run the code below which I got from here and even though I have changed almost nothing other than the image size (350,350 instead of 150, 150) is still cannot get it to work. I am getting the above filter error (in title) which I do comprehend but I am not doing it wrong so I don't understand this. It basically says that I cannot have more nodes than inputs, correct? I was able to eventually hack my way to a solution by changing this line: with this: but I would still like to understand why this worked. Here is the code below along with the error I am getting. Would appreciate some help (I am using Python Anaconda 2.7.11). and the error:",https://stackoverflow.com/questions/39848466,6171195.0,1
718,58697729,Denormalize Tensorflow,"I would like to denormalize my prediction from neural network. I first normalize my ground truth, and save its std and mean value in a numpy array: Then I train my network: I would like to denormalize my data to the original distribution so I can interpret the rmse in a range that makes sense as follows: but I can't, if I try to convert the numpy values to tensor values with tf.convert_to_tensor like this: I will get this error: and if I want to cast tensor values: I get this error: how do I do this?",https://stackoverflow.com/questions/58697729,7815941.0,1
719,67069600,Understand the shape in tf.keras.Input?,"I just learn tensorflow and keras. Here is a code example: The document says shape: A shape tuple (integers), not including the batch size. For instance, shape=(32,) indicates that the expected input will be batches of 32-dimensional vectors. Elements of this tuple can be None; None elements represent dimensions where the shape is not known. But in the above code, two print lines both work. But for me, they are 1D dimensions and 1 scalar. So how do understand the shape?",https://stackoverflow.com/questions/67069600,4827407.0,1
720,69408994,Matplotlib plot becomes blank after tf.image.resize,"I have some code that I am using with tensorflow datasets. It's worked fine previously and it may still work. But I don't think so Just outputs a blank 224x224 canvas. outputs the image correctly. img_paths is a list of strings with pathnames I have tried: and and The shape is correct and this code has worked before. And may still work, I'm thinking I may not use it correctly anymore (been a while since I wrote it). thanks for any hints or thoughts you can provide? And of course solutions ;-)",https://stackoverflow.com/questions/69408994,11106507.0,1
721,70400987,TypeError: tf__normalize_img() missing 1 required positional argument: 'label',I'm new to deep learning and I was working with the Tensorflow Oxford Flowers dataset when I ran into an error while normalizing the images. I followed the guide on how to normalize images on the Tensorflow website but the error remains. Followed by I referred to https://www.tensorflow.org/datasets/keras_example. My Code:,https://stackoverflow.com/questions/70400987,17706343.0,1
722,49721407,"access Variables within function, which defines model to use it on test data Tensorflow","I am already very impressed with Tensorflow and it's automatic chain rule when it comes to find derivative. But I have one question, is it possible to access Variables from function which models train data? Session already holds some data regarding weights and bias. Is it possible to get it out by?",https://stackoverflow.com/questions/49721407,5962981.0,1
723,61098841,Why is my logistic regression classifier in Tensorflow not learning?,"I am learning Tensorflow by implementing a logistic regression classifier to classify a binary MNIst digit dataset. I am using tensorflow 1.13 as the code below shows The dataset is as it follows: The following dataset has the following shapes From these shapes, I defined placeholders for inputs and variable for the weights (I hope they are correct) Now I define the loss, optimizer and calculate the class probabilities as below Then, I create a function to call the computation of the class from probabilities Now, I start to separate training and testing sets Finally, I train and test for each iteration My problem with the above code is that, although I can see that the loss decreases at each iteration, the ROC metric remains the same. The output of this loop is something as follows: By printing the output of predict_function(X_train) or predict_function(X_test), I see that the prediction is always 0. Therefore, there is something I may not be understanding or not doing correctly. What am I missing here? EDIT: I also tried increasing the learning rate to 0.1 and number of iterations to 50000 as suggested, the loss turns out to zero very fast, but both train and test AUC are 0.5, meaning that the classifier is predicting just one class. I am sure that is something wrong with my code, what exactly it would be?",https://stackoverflow.com/questions/61098841,2163392.0,1
724,50587540,Using TensorFlow to optimize a graph over a moving time series data window without dict_feed,"I am trying to set up an optimization graph in Tensorflow that avoids using feed_dict with a tf.FIFOQueue - at least this seems to be the right direction for time series data. I will first describe how my graph looks (in minimal terms) using feed_dict, and then where I am trying to take it. Let's say my time series is stored in a numpy array time_series: Now data_wnd[k] can represent window k in the time series. Assuming step is my Tensorflow optimizier, this would work classically as follows: If I didn't have a window, then instead of using a placeholder data_ I could simply use a tf.constant and be rid of feed_dict. So that is out of the question. So in comes tf.FIFOQueue: Great, so now I have a queue, but this is clearly wrong. qr needs to feed the correct data frame into the queue depending on k. Is there a way to get either enqueue or QueueRunner to select the correct frame? Better yet, is there some specialized Tensorflow API to deal with time-series data in this fashion? An important constraint to the solution requires that I keep everything in the same session and variables are not reinitialized because the optimized solution of a frame is close to the optimal solution of the previous frame. An incomplete proposal I was thinking of having several nq_op defined as follows: But this still leaves the need for QueueRunner to correctly select the right enqueue. Another proposal Apparently Tensorflow now has a tf.data API, but I have no idea where to start - or for that matter, end - with this API.",https://stackoverflow.com/questions/50587540,8411980.0,1
725,64194339,GCP ML Tensorflow serving with authorization for GRPC,I needed help in setting up GRPC for an ML model deployed on GCP. I have deployed the model and want to serve it using GRPC but not able to find any documentation on how to do that. Does anyone have any info on the below:- Currently there is sufficient documentation for serving with JSON requests but these requests are becoming very big and I need an alternative for reducing size and thats why needed to find more doc on it. right now I am getting error let me know if you would need more info. this the code i am using,https://stackoverflow.com/questions/64194339,9063834.0,1
726,65006011,Size of output of a Conv1D layer in Keras,"I am trying to understand the output of a 1D convolution layer applied on a number of batches (3 in this case) of 2D input shapes (6x6). The output of the code below is (4, 10, 32). This answer is quite straight-forward for the first 2 indices. By the documentation this should be the output shape",https://stackoverflow.com/questions/65006011,7450491.0,1
727,75786416,tf.data.experimental.CsvDataset ignore my feature specification (tensorflow),tf.data.experimental.CsvDataset seems to be ignoring my feature specification. I had the same issue using a record_default programmatically generated from a SchemaGen schema. The data is synthetic to eliminate data as potential source of errors. I generate the data like this: I load the data like this: Everything gets loaded as a string anyway:,https://stackoverflow.com/questions/75786416,3604745.0,1
728,71568714,Layer up_sampling2d_1 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>,"I am testing how the UpSampling2D layer works in Keras, so I am just trying to pass different inputs to check the output. While checking the example, given in the official documentation here, I can not reproduce the example, and it is giving me the error. Code in documentation: Error: How should I be able to test this layer without creating a model and testing it, just like given in the documentation.",https://stackoverflow.com/questions/71568714,10342778.0,1
729,38890591,RNN & Batches in Tensorflow,"The batche approach for RNN in Tensorflow is not clear to me. For example tf.nn.rnn Take as input list of Tensors [BATCH_SIZE x INPUT_SIZE]. We normally are feeding to session batches of data, so why it take list of batches not single batch? This leads to next confusion for me: I pass list of Tensors [CONST_BATCH_SIZE x CONST_INPUT_OTPUT_SIZE] to tf.nn.rnn and got output value that is list of Tensors [CONST_BATCH_SIZE x CONST_NUM_OF_HIDDEN_STATES]. Now I want to use softmax for all HIDDEN_STATES outputs and need to calculate weights with matmaul + bias Should I use for matmul: Or should I create 2D array from val and then use tf.matmul without for?",https://stackoverflow.com/questions/38890591,1451579.0,1
730,59358665,How to use tensorflow ctc beam search properly?,I want to perform CTC Beam Search on (the output of an ASR model that gives) matrices of phoneme probability values. Tensorflow has a CTC Beam Search implementation but it's poorly documented and I fail to make a working example. I want to write a code to use it as a benchmark. Here is my code so far: I'm having issues with understanding the code: Looking forward to your answers / comments! Thanks!,https://stackoverflow.com/questions/59358665,4129434.0,1
731,63326215,How does the TensorFlow dataset handle large data that cannot fit into the memory in a server?,"How does the TensorFlow dataset handle large data that cannot fit into the memory in a server? Spark RDD can handle large large data with multiple nodes. For the question in Tensorflow Transform: How to find the mean of a variable over the entire dataset, the answer is using Tensorflow Transform which uses Apache Beam that requires a distributed computation cluster such as Spark. Hence I suppose TensorFlow requires a multi node cluster but not clear if TensorFlow has its own cluster implementation, or re-using existing technologies. Since TensorFlow pre-processing e.g. getting mean or std of a column requires Apache Beam, I guess it is Apache Beam based too, but not sure. A google paper Large-Scale Machine Learning on Heterogeneous Distributed Systems shows multiple workers. This article TensorFlow: A new paradigm for large scale ML in distributed systems tells the system components. This Github TensorFlow2-tutorial/05-distributed-training/ tells TF_CONFIG specifying the node IP/port. TensorFlow example Github Distributed TensorFlow has the section below but do not see node setup detail. Hence apparently there is a way to setup TensorFlow cluster which I suppose handles large dataset loading into a TF dataset. However, Install TensorFlow 2 only shows: Please point to the step by step documentation of how to setup a TensorFlow multi node cluster, and resources that explain the details on how the large data loading is handled (Similar to the Spark RDD/DataFrame explanation and internals) in TF.",https://stackoverflow.com/questions/63326215,4281353.0,1
732,42818842,Transitioning to Tensorflow 1.0.0,"I am trying to translate this pix2pix GAN code to Tensorflow 1.0.0 using the following script as described in Tensorflow Documentation, but I keep getting the following error: This is the Adam optimizer part: Where d_vars is: And the discriminator code:",https://stackoverflow.com/questions/42818842,7671750.0,1
733,45446236,Tensorflow slower when using multiple threads during preprocessing on CPU,"I have a dataset that is generated on the fly on the CPU. Samples are computed in python by a function make_sample that is pretty complex and cannot be translated into tensorflow ops. Because sample generation is time consuming, I want to call the function from multiple threads to fill an input queue. I started from the example given in the documentation and arrived at the following toy example: What surprises me is that, when increasing read_threads, the CPU usage never goes above 50%. What's worse, the computation time plummets: on my computer, Is there an explanation, and above all, a solution to get efficient multithreaded data generation with custom python function on tensorflow?",https://stackoverflow.com/questions/45446236,1735003.0,1
734,67599150,Why I can't get the internal output of a trained model?,why i can't get the output of 'conv2d_4' that is the internal layer of the model? And i get the following error.,https://stackoverflow.com/questions/67599150,15922026.0,1
735,70302430,Why did this model still need calling 'build()' firstly when I have defined parameters?,"I have defined a image, img_shape , its shape is (28,28,1) before this model, Then I tried to directly use it as input and print the structure of this model, However, it shows But when I tried to add build() before summary, it shows I dont know how to solve this problem...and the process of creating image is below,",https://stackoverflow.com/questions/70302430,12931358.0,1
736,38094217,TensorFlow: argmax (-min),"I just noticed an unexpected (at least for me) behavior in TensorFlow. I thought tf.argmax (-argmin) operates on the ranks of a Tensor from outer to inner, but apparently it does not?! Example: tf.argmax takes two arguments: input and dimension. Since the indices of array arr are arr[rows, columns], I would expect tf.argmax(arr, 0) to return the index of the maximum element per row, while I would have expected tf.argmax(arr, 1) to return the maximum element per column. Likewise for tf.argmin. However, the opposite is true: Can someone explain this behavior? Generalized every n-dimensional Tensor t is indexed by t[i, j, k, ...]. Thus, t has rank n and shape (i, j, k, ...). Since dimension 0 corresponds to i, dimension 1 to j, and so forth. Why does tf.argmax (&amp; -argmin) ignore this scheme?",https://stackoverflow.com/questions/38094217,3314143.0,1
737,47712805,Tensorflow: Add function returning first tensor as result,"This was a simple add function to add two tensors: One would expect 5.5 as result But the result is: 2.0 Tried adding 1 rank as well, Output: [ 1. 2.]",https://stackoverflow.com/questions/47712805,6488955.0,1
738,72302381,Listwrapper not allowing multiplication of learning rate and thus no update of weight for Nueral Network,I am new to tensorflow and nueral networks. I am trying to create a NN to estimate y = x^2 I created a nueral network class to obtain my weights and biases and run forward propagation. Next I created a class updat to do backward propogation But when I run the code I get an error saying I tried substituting My_NN.weights -= (lr*dw) with My_NN.weights.assign_sub(lr*dw) still it shows that Is there any solution for this?,https://stackoverflow.com/questions/72302381,19152216.0,1
739,40467296,Tensorflow - How to implement hyper parameters random search?,Consider this simple graph + session definition. Suppose I want to tune hyper params (learning rate and drop out keep probability) with a random search? What is the recommended way to implement it? I tried putting everything inside a function But I ran into scope issues (I am not very familiar with scopes in Python/Tensoflow). Is there a best practice to achieve this?,https://stackoverflow.com/questions/40467296,990616.0,1
740,57186654,Can't restore tensorflow variables,"I have a class as follows and the load function returns me the tensorflow saved graph. I have another class lets call it TrainNet(). In my training class I use the above class simply by loading the graph using load function as self.train_graph = StoredGraphclass.load(sess,metasaver) My doubt is are all the variables restored by loading the saved graph ? Normally everyone defines the restoration operation in the same script like saver.restore() which restores all the variables of the graph. But I am calling saver.restore()in a different class and using the returned graph to access placeholders. I think this way not all the variables are restored. Is the above approach wrong ? This doubt arose when I checked the values of weights in two different .meta files written at different training steps, and the values were exactly the same meaning this variable wasnt updated or the restoration method has some fault.",https://stackoverflow.com/questions/57186654,8954691.0,1
741,67687683,Vectorised assignment to tensor,"I'd like to assign multiple values to a tensor, but it seems that it's not supported at least in the way that is possible using numpy. The above works, but the tensorflow equivalent doesn't: How could this be achieved? Are loops the only option? In my case the resulting array is indeed only slices of an identity matrix rearranged, so maybe that could be taken advantage of somehow.",https://stackoverflow.com/questions/67687683,7089239.0,1
742,36046125,Can I use TensorBoard also with jupyter notebooks,"I am experimenting (learning) TensorBoard and use the following code I got from the internet (simple regression function) The code runs fine when I create a python file and run the file with also it runs fine in the jupyter notebook However, while Tensorboard gets the information from running the python file (that is to say, it creates the xyz....home file), the interactive version does not create any info usable for Tensorboard. Can somebody explain to me why, please! Thanks Peter",https://stackoverflow.com/questions/36046125,1968073.0,1
743,73326638,"TensorFlow with custom gym environment: Layer ""dense_6"" expects 1 input(s), but it received 2 input tensors","I am trying to use TF to solve a custom gym environment, all within Google Colab. The environment loads fine via env = suite_gym.load(env_name), and subsequent code cells run fine as well, until the following two cells: After that cell, I get an error: I'm too much of a TF novice to understand what's going on here. I suspect it's because the action state changed from 2 states (in CartPole) to 4 (in the custom GridWorld environment). But beyond that I cannot figure it out.",https://stackoverflow.com/questions/73326638,3453768.0,1
744,50484453,How to restore a model in tensorflow properly?,"I had saved a trained model in tensorflow with the command: Then,I load the model with the command: Now,to evaluate accuracy the following function is used: But the above function gives the error: But,when I print the tensors from the graph,it shows the matrix of Variable_12: Variable_12:(Showing only one variable from the output) Can anyone please explain why the uninitialized error is being shown as the value is there which is confirmed by the inspect_checkpoint? Thank you for your time.",https://stackoverflow.com/questions/50484453,8586569.0,1
745,70294280,"Remove top layer from pre-trained model, transfer learning, tensorflow (load_model)","I have pre-trained a model (my own saved model) with two classes, which I want to use for transfer learning to train a model with six classes. I have loaded the pre-trained model into the new training script: base_model = tf.keras.models.load_model(""base_model_path"") How can I remove the top/head layer (a conv1D layer) ? I see that in keras one can use base_model.pop(), and for tf.keras.applications one can simply use include_top=false but is there something similar when using tf.keras and load_model? (I have tried something like this: and then add it to a new model (?) but I am not sure on how to continue) Thanks for any help!",https://stackoverflow.com/questions/70294280,15768051.0,1
746,53544809,Tensorflow Dataset using many compressed numpy files,"I have a large dataset that I would like to use for training in Tensorflow. The data is stored in compressed numpy format (using numpy.savez_compressed). There are variable numbers of images per file due to the way they are produced. Currently I use a Keras Sequence based generator object to train, but I'd like to move entirely to Tensorflow without Keras. I'm looking at the Dataset API on the TF website, but it is not obvious how I might use this to read numpy data. My first idea was this However, this passes a TF Tensor placeholder to a real numpy function and numpy is expecting a standard string. This results in the error: The other option I'm considering (but seems messy) is to create a Dataset object built on TF placeholders which I then fill during my epoch-batch loop from my numpy files. Any suggestions?",https://stackoverflow.com/questions/53544809,4487238.0,1
747,64744276,Keras: Input 0 of layer sequential is incompatible with the layer,"I am trying to create a neural network model with one hidden layer and then trying to evaluate it, but I am getting an error that I am not able to understand clearly: It looks like I have an error with the dimensions of my input layer, but I can't quite spot what. I've googled and looked on stackoverflow, but haven't found anything that worked so far. Any help please? Here's a minimal working example:",https://stackoverflow.com/questions/64744276,1479938.0,1
748,48432622,How to use SessionRunHook to print tensor with tf.data.Dataset API?,I am using the tf.data.Dataset API and assigning names to operations within the closure that is passed to Dataset.map as in the below When using tf.train.LoggingTensorHook to dump some of the values the second hook throws an exception: I am getting errors like this: I guess the Dataset operations create a new graph for each function? Is there a way to customize tf.train.LoggingTensorHook so it knows which graph to search for the named tensor?,https://stackoverflow.com/questions/48432622,2202478.0,1
749,76183952,Parallel data extraction with generators and tf.data,"I have a huge dataset (1TB) with thousand of small hdf5 files, each consisting out of two 3D numpy arrays (only float64 numbers), which currently are fetched by a generator which is given to the tf.data.Dataset.from_generator function: Unfortunately, I have a data bottleneck. Now I want to parallel extract from my datasets to utilize all my 64 CPUs. There was a similar post: tf.data: Parallelize loading step, but I couldn't figure out what I did wrong. Does anyone know how to handle this problem? UPDATE As Tim Roberts pointed out, my reading speed is probably just too low. Additionally, the tf_pyfunc is only using one core and I don't know how to parallelize it.",https://stackoverflow.com/questions/76183952,19264587.0,1
750,45679562,Output from fully connected network in tensorflow,"In this code,the output from fully connected layer is given as 1024 but I cannot understand from which calculation this '1024' is generated and I cannot find any satisfactory answer from tensorflow documentation.And How this ouput size affects the prediction result. Thanks in advance.",https://stackoverflow.com/questions/45679562,7580858.0,1
751,49749237,Why do I get different results when printing tensor names?,"I was trying to print the names of the nodes in a graph and I got different results using different codes. The placeholder is defined as: If I run the code: And I get the result like this: But if I run the following code: There is a "":0"" added at the end of the name: I am confused about it. Could any one explain this for me? Thanks.",https://stackoverflow.com/questions/49749237,6302953.0,1
752,52562679,"Tensorflow Keras Python3 expects output of shape (1,) but gets shape (3,)","I'm kind of a newbie to tensorflow and building neural networks. I'm trying to make a neural network with the tf.keras api that will take a single input, and give 3 outputs. Here is my code: I have specified that the last layer should have three outputs, but I get this error every time I run it: I can't figure out why it seems to think I want a single output from the network. NOTE: The dataset I am using is not what I will actually use. I'm just trying to get a functional network, and then I'll generate the data later.",https://stackoverflow.com/questions/52562679,9947487.0,1
753,73206445,IndexError: list index out of range while keras model.predict(),If I try to predict with my model with 3 inputs with this code: I get this error: This my Model: But this works just fine: While: is true. I also tried: But it gets me the same error. I also tried: But it gets me this error: I really have no idea how to solve and can't explaine it to myself that one thing works but another thing which is equal to the first thing doesn't work. Please help!,https://stackoverflow.com/questions/73206445,19673787.0,1
754,73121139,how to convert tf.contrib.layers.batch_norm to tf2.0,I am converting the following code I tried to convert with But I get the following error My question is : How can I convert tf.contrib.layers.batch_norm with scope correctly?,https://stackoverflow.com/questions/73121139,19623911.0,1
755,48533216,Convert code from Keras 1 to Keras 2: TypeError: __call__() missing 1 required positional argument: 'shape',"I am trying to convert a V-net code that was written in Keras 1 into Keras 2. It seems that I have an issue with the following class: When I try to call it using Deconv3D(128, (2, 2, 2), (1, 16, 16, 8, 128), (2, 2, 2))(), I get the following error that I don't understand: What am I doing wrong?",https://stackoverflow.com/questions/48533216,5256563.0,1
756,63239226,usage of tf.keras.layers.DenseFeatures,"Here is the official doc. This is used in TF example and usually put in keras.Sequential(...) model construction. Like below: In my case, I want to use it to transfer my dictionary data type into Tensor format and pass it into model. So I used code like below: And input is the training data I would feed into model. The question is whether my usage of this DenseFeatures() layer is reasonable. Or this feature_layer has to be in keras.Model class?",https://stackoverflow.com/questions/63239226,2189731.0,1
757,74875654,TypeError when modifying tf.keras.Optimizer parameter,"I have been trying to implement a (heavily-inspired) Gradient-Accumulation wrapper for my Adam optimizer, as shown below: But seem to butt into the following TypeError when I try to train: which points to the part where self.optimizer.learning_rate is updated based on self.cond, although I'm sure that tf.condshould return a single value if the true/false function returns a singleton list. I'm using Tensorflow 1.15.x (and constrained to this version, sadly). Any ideas how this could be circumvented?",https://stackoverflow.com/questions/74875654,13361308.0,1
758,62508861,input_shape parameter in Keras/Tensorflow,"I do tutorial for machine learning in Tensorflow, with following code: It works fine but I struggle with understanding what data are taken as an input for each epoch run. Input data are two arrays of numbers, model.summary() call shows that model expect two inputs but I do not understand what exactly is that input - is it eg. -1.0 and -3.0 for the first epoch or are taken both complete arrays and put into the 1 neuron in the layer?",https://stackoverflow.com/questions/62508861,11823653.0,1
759,56523318,Tensorflow: create vector based on input,"I am not really experienced in Tensorflow and I am doing one of those things that would apparently be very easy, but getting stuck at it. I need to create a matrix given an input using a tensorflow layer. Here is what I've gotten: This gives the error:",https://stackoverflow.com/questions/56523318,2116599.0,1
760,71713428,Effect of nested @tf.function calls on computation graph,"Consider the following code: When I inspect the computation graph in tensorboard, it looks as follows: Notice that inner is represented by a StatefulPartitionedCall. Then there's another thing in the tensorboard output, which I theorize is the actual op instantiation of inner but that doesn't have an apparent tie to the StatefulPartionedCall. What are the conclusions of this? Do inner and outer both get separate computation graphs? Can I be confident that inner is still executing graph style (my empirical testing says yes). Is there a performance hit from not having it all inline in a single graph, or is it all effectively still in a single graph? Thanks for any insight.",https://stackoverflow.com/questions/71713428,834214.0,1
761,64048058,Tensorflow: Train Keras model using GPU,"I know, there are a lot of related questions, but they are outdated, mostly they are even dealing with TensorFlow 1. I have 1 GPU (GeForce 960) which is recognized by TensorFlow, so the installation was successful. I'm not sure if this is the right way to do it, but this is how I train a Keras-model: But I get a lot of problems:",https://stackoverflow.com/questions/64048058,13319886.0,1
762,40628977,How to scale tf.nn.embedding_lookup_sparse,"I'm trying to build a very large sparse model (e.g. LR if there is only one embedding layer), the input dimension can be as large as 100000000, and the sample is very sparse, the average number of non zero value is around 100. Since the weights is very large and we have to partition and distribute it onto different servers. Here is the code: This is the generated graph for this op From the graph, embedding_lookup_sparse just simply cancat the sharded weights, which cause a huge of unnecessary network traffic. This looks stupid. The resonnable way is making lookup for each shard in local indepently, and just send back the lookuped results and aggregate them. In this way, the traffic is dramatically reduced. I'm wondering whether TensorFlow support this mode? Of course, I can do this by customized code. The solution that works as expected:",https://stackoverflow.com/questions/40628977,2934662.0,1
763,58115439,How to reuse the BERT model using tensorflow.contrib,"I have tried below codes for reusing the saved BERT model. But I am receiving the error below: ' Cannot feed value of shape () for Tensor 'input_example_tensor:0', which has shape '(?,)' I tried below codes for prediction. Can someone advise me on this?",https://stackoverflow.com/questions/58115439,8211216.0,1
764,66083370,Change intermediate activations/output and observe prediction in TF2/Keras,"Let us say I have a simple NN model classifying MNIST like so: And I extract the output tensor from the 2nd layer, i.e. Dense layer (after activation relu) like so: For some particular data input x, I extract the output tensor activation values now: And make some changes to it: And now, I would like the model to continue from this layer's modified output values and predict results accordingly. How would I do that? I tried to construct another K.function([mid_layer_outputs], model.layers[-1].output) starting from this layer to the end, but I got the following error: which is understandable as it cannot continue predictions with a NP array object instead of a model layer object. How do I do this?",https://stackoverflow.com/questions/66083370,6089653.0,1
765,73835386,How to understand the self-attention mask implementation in google transformer tutorial,"I am reading google's transformer tutorial, and the part why the attention_mask for multi-head attention can be built via mask1 &amp; mask2 was unclear to me. Any help would be great! toy example breakdown",https://stackoverflow.com/questions/73835386,1269298.0,1
766,41716090,Tensorflow: different fetches bring different results,"I am playing around with Tensorflow and there is one thing I can't seem to understand: the role of the fetches argument for the Session.run(). From the doc: What I understood is that the parameter is used to read certain values from the from the run step. I see, though, that different fetches bring to different results So now I wonder what else the fetches parameter is used for, given that it seems to influence the way the training is run. I didn't really understand it from the documentation...",https://stackoverflow.com/questions/41716090,1093494.0,1
767,63501505,"TensorFlow - ValueError: Shapes (3, 1) and (4, 3) are incompatible","I'm completely new to DL and I'm stuck with this error when I fit my model ValueError: Shapes (3, 1) and (4, 3) are incompatible Dataset: Model: Error at model.fit Thanks for any help",https://stackoverflow.com/questions/63501505,13040796.0,1
768,40946389,How can I train a model with TensorFlow without giving a formula?,"I am learning TensorFlow. I have a question about the code in Introduction: This program learns best fit of W and b. If I don't know the formula (y = W * x_data + b), how can I train a model? For example, this is a training set: How to train a function(a, b) ~= (a+b)?",https://stackoverflow.com/questions/40946389,7244589.0,1
769,47103581,TensorFlow : optimizer gives nan as ouput,"I am running a very simple tensorflow program this gives me [array([ nan], dtype=float32), array([ nan], dtype=float32)] what am i doing wrong?",https://stackoverflow.com/questions/47103581,2334092.0,1
770,64908920,Can't use color_mode = 'grayscale' with grayscale JPEGs,"I'm using tensorflow v 2.3.1 This is my code: Errors out with : I thought, documentation says, grayscale is how jpeg will be preprocessed. Any ideas about the cause?",https://stackoverflow.com/questions/64908920,14665728.0,1
771,46870058,Calling TensorFlow's Dataset.from_generator method,"The TensorFlow 1.4 documentation provides code that demonstrates the usage of Dataset.from_generator. When I run the code, I get an InvalidArgumentError:0-th value returned by pyfunc_0 is int32, but expects int64. I'm using Python 3.6.1. Here's the code: Any ideas?",https://stackoverflow.com/questions/46870058,934904.0,1
772,76031814,Keras tensorflow Model not returning Map with UserDefined Keynames,"I am new to Keras API , I am able to get Map as response but i am not able to get userdefined key names in response For Ex: My Expected response is My Actual response is I am expecting userdefined key names such as ""outputKeyVal"",""outputKeyStr"" instead i get only ""map_script_1"",""map_script"" Here are the details about my Model: I am using Keras Functional API for saving the tensor model and using predict method for retrieving the model",https://stackoverflow.com/questions/76031814,5245143.0,1
773,44841463,Keras - weighted average of tensors,"If I've n tensors T_i of shape (?, k), and one tensor U of shape (?, n), how can I get the tensor (?, k) that is equal to sum(T_i * U[i]) ? I've tried writing a layer to do so: that I called with: however that fails with a rather long tensorflow trace:",https://stackoverflow.com/questions/44841463,2054629.0,1
774,62369151,General question about time series forecasting,"I have a general question about time series forecasting in machine learning. It's not about coding yet, and I'm just trying to understand how I should build the model. Below is some code I have related to my model: Here is my feature layer: The time series forecasting modeling technique I learned recently is totally different than how I have been building the model. The technique involves time windows that use past values (my labels!) as features and the next value as the label. It also involves RNN and LSTM. Is the way I built the model and the time series forecasting technique fundamentally different and will generate different outcomes? Is the way I have been modeling this reasonable, or I should switch to the proper time series forecasting approach?",https://stackoverflow.com/questions/62369151,12777244.0,1
775,45074049,Tensorflow: How does tf.get_variable work?,"I have read about tf.get_variable from this question and also a bit from the documentation available at the tensorflow website. However, I am still not clear and was unable to find an answer online. How does tf.get_variable work? For example: Does it mean that var2 is another variable with initialization similar to var1? Or is var2 an alias for var1 (I tried and it doesn't seem to)? How are var1 and var2 related? How is a variable constructed when the variable we are getting doesn't really exist?",https://stackoverflow.com/questions/45074049,6687875.0,1
776,42364283,Tensorflow: calculate gradient for tf.multiply,"I'm building a neural network that has the following two layers I then want to multiply them using tf.multiply (which, unlike tf.matmul multiplies corresponding indices, i.e. c_ij = a_ij * b_ij) My goal is to learn weights. So I run But it doesn't work. The network doesn't change at all. Looking at tensorboard, I could see that 'input' has no gradient, so I'm assuming that's the problem. Any ideas how to solve this? From reading tensorflow docs it seems like I might have to write a gradient op for tf.multiply, but I find it hard to believe no one needed to do this before.",https://stackoverflow.com/questions/42364283,1660762.0,1
777,53754540,Tensorflow Access CsvDataset values,"Eager execution I have been digging through the API for 2 days and I cant seem to find a way to use the data from a CsvDataset object. I have the following sample from a dataset: 70,1,4,130,322,0,2,109,0,24,2,3,3,2 67,0,3,115,564,0,2,160,0,16,2,0,7,1 57,1,2,124,261,0,0,141,0,3,1,0,7,2 64,1,4,128,263,0,0,105,1,2,2,1,7,1 74,0,2,120,269,0,2,121,1,2,1,1,3,1 65,1,4,120,177,0,0,140,0,4,1,0,7,1 56,1,3,130,256,1,2,142,1,6,2,1,6,2 59,1,4,110,239,0,2,142,1,12,2,1,7,2 60,1,4,140,293,0,2,170,0,12,2,2,7,2 63,0,4,150,407,0,2,154,0,4,2,3,7,2 I read the csv as said in their high-level APIs video: But from here on i cant acess any data like, getting the values of a column. Converting the dataset to a list using: list(dataset) is not an option, as it takes a very long time with normal size csv's (~190k samples). So, is there any way to get column or row values from this object? Or is there really no point in using TF to read data instead of using scikit/pandas? Edit 1: Tried doing col1 = dataset.map(lambda *row: row[0]) as said by @kvish, this return a &lt;MapDataset shapes: (), types: tf.float64&gt; which is iterable. Problem is that having to loop over every column and then iterating over every MapDataset would make the complexity O(n^2). The idea output would be a list of tensors, each tensor containing all values from a column, similar to this:",https://stackoverflow.com/questions/53754540,3497258.0,1
778,64508203,I don't understand map_fn with two inputs,"I'm having trouble understanding what map_fn does, when I use it on a tuple. For testing I did the following thing: What I expected here is that map_fn takes a and b apart into three vectors each and gives them to func. func then only returns the first input and map_fn stacks them back together. So I thought I should just get a back. What happens instead is a terrible error: It seems to me that map_fn somehow tries to combine the whole tuple with one of it's components. Can someone please explain what's going on here?",https://stackoverflow.com/questions/64508203,12743095.0,1
779,71520085,Tensorflow 2.8 GPU out_of_mem when using multiprocessing,I'm trying to convert .ogg files to tfrecords. I'm running the below code on my GPU using multiprocessing but my GPU RAM gets allocated 100% and the program crashes. Anyone have some input on using multiprocessing with tensorflow or any documentation to best practices? I haven't been able to find what I'm looking for. Think i figured it out. I added the below code to the _write_tfrecord_file function:,https://stackoverflow.com/questions/71520085,15891508.0,1
780,56426839,Why does `tf.data.Dataset.map` run only once?,"I have been digging around. Still baffled me, I can't find clear explanation anywhere. I expect .map to behave like a normal functional map. Which, it supposed to apply a function to each element. It feels like some of my assumptions are totally off.",https://stackoverflow.com/questions/56426839,4353874.0,1
781,60128565,'serving_default' : Classification input must be a single string Tensor,"I'm building a very simple Classifier. The input data has the following features The error is: Then, I changed the serving function to this: The error becomes: I modified the serving function again like this: Then the error changed to: Finally, I solved it as follows: However, I faced another problem in prediction. I cannot provide a data format that the serving function can read. This is the Signature_Def This is my code of prediction The error message is: Can anyone tell me where the problem is? Is it the input input (test.json) or the serving function? What is your suggestion to fix it?",https://stackoverflow.com/questions/60128565,11116759.0,1
782,65734836,"Numpy Equivalent to ""tf.tensor_scatter_nd_add"" method","Question is in the title really, I am looking for a method in scipy/numpy/etc. (not TensorFlow) which encapsulates the behaviour described in the tf.tensor_scatter_nd_add but on Numpy arrays rather than tensors. I have come across the scipy.ndimage.sum method, but couldn't get this to reproduce the example I've given below. Whichever method you think fits has to be able to reproduce the rank-3 example that is provided in the TF Documentation: Hopefully someone has solved a similar problem before and can help here - Thanks in advance!",https://stackoverflow.com/questions/65734836,7861160.0,1
783,50158467,How to penalise negative weights in TensorFlow?,"I'm building a neural network with TensorFlow and I'm trying to implement a quadratic penalization to negative values in the weight matrix, i.e. P(W[i,j]) = W[i,j]^2 if W[i,j] &lt; 0. In summary, I initialized the weights, performed some operations, defined the main objective function to minimize, and defined this nonnegativity penalization as follows: I'm wondering if this is a correct way to implement such penalization.",https://stackoverflow.com/questions/50158467,4099259.0,1
784,55302893,TF 2.0 print tensor values,"I'm learning the newest release of Tensorflow (2.0) and I have tried to run a simple code to slice a matrix. Using the decorator @tf.function I made the following class: So, when run the code using a numpy matrix, I can't retrieve the numbers. Output: I need to get this tensor in a numpy format, but TF 2.0 has not the class tf.Session to use run() or eval() methods. Thanks for any help that you can offer me!",https://stackoverflow.com/questions/55302893,11243689.0,1
785,69954102,Tensorflow access tensor.numpy() in .map function but using py_function slows down iterator generation,"I want to one hot encoder a tensor with my own one hot encoder. For this, I have to call tf.keras.backend.get_value() in .map which is only possible when using tf.py_function: The problem is, when mapping the dataset and calling one_hot_encode: tensorflow will take forever to create an Iterator for this dataset e.g. when trying to access the data in a for loop: But if I use tensorflows build in one hot encoder, everything works fine and tensorflow is fast. In both approaches, the dataset and all tensors have the same shape. Does anyone know of another method to access the value of a tensor in .map or why tensorflow becomes so slow?",https://stackoverflow.com/questions/69954102,13798993.0,1
786,69331522,"What does a tensor t[..., 1, tf.newaxis] ...stands for?",I am beginning to work with Python and TensorFlow machine learning. I am working through an example where I create a simple tensor representing a matrix with two rows and three columns of floats: The tutorial then provides the following code: I am wondering what the ellipsis ... stands for? I cannot find any reference to this syntax in the Tensorflow API.,https://stackoverflow.com/questions/69331522,11785384.0,1
787,47315508,"""ValueError: setting an array element with a sequence"" - When trying to feed list into placeholder in feed_dict","I must admit I am a beginner, but I could not find an answer to my question on any questions asked in StackOverflow or Github. Please do help The Error: ""Train"" is a Matrix that looks like:[(user_id,item_id) implicit_rating....] Code to build the MLP: Code to Build Inputs from training Matrix: Building the Model: And finally training (CODE THAT GIVES THE ERROR) Any ideas for debugging?? Thank you in advance!",https://stackoverflow.com/questions/47315508,8732893.0,1
788,50269385,How to process the whole batch tensor in efficient way?,I want to process the two batch: a and b and product c. Batch size is 1000. Every element ci is the contract result of ai and bi. The contract operation is defined by myself. But I am not sure whether it is an efficient way to do this? Is there any simple method ? Thanks.,https://stackoverflow.com/questions/50269385,6407393.0,1
789,55176903,Merging Keras models: can Keras automatically ignore names or relabel them?,"I am trying to merge two sequential models in Keras. The code is as follows, being taken from this answer: However, I get this error: This is probably coming from the fact that keras automatically names the layers if I don't provide a name. However, for various reasons, I don't want to have have to continually name all my layers before I can merge two models. Is there a way to merge these models without this error that does not involve manually giving the layer names? Is there a way to have keras automatically rename all the layer names for me? Update: I still seem to get this error, even if I manually relabel all the layers to have distinct names. What am I doing wrong?",https://stackoverflow.com/questions/55176903,8292871.0,1
790,63536670,Poor performance when using Batch Normalization with batch size,"I noticed a strange effect, When training a Keras model, let's say this one It will perform okay on the validation set. i.e And accuracy is 92%. i.e accracy drops to 70% or 60%. What is the reason? Thanks",https://stackoverflow.com/questions/63536670,10342778.0,1
791,49452941,Creating appropriate input_fn in DNNClassifier TensorFlow,"I'm building a neural network with DNNClassifier and I've read the examples on the site, and done by others, about this estimator, but I'm still confused on the construction of the input_fn. I post my code below I've omitted part of the code because is mostly the same when I define the embedded and indicator columns, and also when I define COLUMNS, FEATURES and LABELS. After running the script I bump in the error: '_NumericColumn' object has no attribute '_get_sparse_tensors', and I don't know how to overcome it or where I did wrong. Is the problem in the creation of the input_fn? Or is it before that? And if it before the input_fn, how do I write a proper input_fn? Any help would be greatly appreciated, thanks in advance.",https://stackoverflow.com/questions/49452941,,1
792,49288325,How to deal with many columns in Tensorflow,"I am studying Tensorflow, and I have a question. Original code is that If I have many columns like that How do i deal with many columns in Tensorflow? (Independent variable = 'price', dependent variable = else) Do I have to make each train_set and W with columns?",https://stackoverflow.com/questions/49288325,9243606.0,1
793,46391224,tf.Print not printing in console,"I am running a TensorFlow code in console (not Jupyter notebook) and despite me using tf.Print, it does not print anything. The usage is as follows : Later during session : The above does not print anything and nor does the following print anything : What am I doing wrong ?",https://stackoverflow.com/questions/46391224,8530591.0,1
794,35875652,LSTM inputs for Tensorflow,"I'm trying to create an LSTM network in Tensorflow and I'm lost in terminology/basics. I have n time series examples so X=xn, where xi=[[x11x12,x13],...,[xm1xm2,xm3]] and where xii is a float. First of all I want to train a model that given the start of a sequence ([x11x12,x13]) I can predict the rest of the sequence. Then later I hope to include a classifier to predict which binary class each xi belongs to. So my problem is what do I feed in to the start and pull out the end of my model? So far I have something that looks like the below EDIT: Specifically, how to I finish the __init__ function so that it is compatible with my data?",https://stackoverflow.com/questions/35875652,3921875.0,1
795,36498127,How to apply gradient clipping in TensorFlow?,Considering the example code. I would like to know How to apply gradient clipping on this network on the RNN where there is a possibility of exploding gradients. This is an example that could be used but where do I introduce this ? In the def of RNN But this doesn't make sense as the tensor _X is the input and not the grad what is to be clipped? Do I have to define my own Optimizer for this or is there a simpler option?,https://stackoverflow.com/questions/36498127,2527680.0,1
796,72341231,ValueError: Unknown metric function: top_2_accuracy. Please ensure this object is passed to the `custom_objects` argument,"I'm working on a CNN classification project, and I've used the top 2 Accuracy (top_k_categorical_accuracy) as the accuracy matrix for training. the function in the model notebook is: then I used it as Now I need to load the model to use it in an application I tried to use this code: but an error occurred while loading then I've googled and tried this too: but it generated another error How can I solve this??",https://stackoverflow.com/questions/72341231,16488727.0,1
797,41819049,Unable to read properly a text file in tensorflow,"I have a txt file which has 2000 row and 10 columns, columns data separated by tab. To read file I simply defined a function. and when I am trying to read the file but the output is empty [] some posts say we have to use sess.run to load, so, I tried with out using a function I get out put as in single line(It is reading the tab and next line also) where I expect to be in size of [2000x10], which is not loaded correctly. I need to load the file inside a function because I need to do some mathematical calculations on the column data. How to load file inside a function ? So that I will be able to call the function. I can do it using I hope this isn't the right way to load in to tensor",https://stackoverflow.com/questions/41819049,7460588.0,1
798,47736951,tensorflow : load csv data file and training the model,I am new to tensorflow . I need to load the dataset to train my model . And sample of my dataset looks like I Load this csv file with mentioned code in tensorflow documentation .This is how i loaded my training file and when i compile the script i got the following error,https://stackoverflow.com/questions/47736951,9044016.0,1
799,45024333,"When I run ""tf.nn.dynamic_rnn"", I got TypeError: Expected int32, got list containing Tensors of type '_Message' instead",I trying to convert following code to tensorflow 1.2 but I hard understand how to fixed it. Thanks for your any replying. All Input Variables: Error Messgae: . .,https://stackoverflow.com/questions/45024333,8283199.0,1
800,59383356,Accessing layer's input/output using Tensorflow 2.0 Model Sub-classing,"Working on a university exercise, I used the model sub-classing API of TF2.0. Here's my code (it's the Alexnet architecture, if you wonder...): My goal is to access an arbitrary layer's output (in order to maximize a specific neuron's activation, if you have to know exactly :) ). The problem is that trying to access any layer's output, I get an attribute error. For example: I found some questions with this error here in SO, and all of them claim that I have to define the input shape in the first layer, but as you can see - it's already done (see the definition of self.conv1 in the __init__ function)! I did find that if I define a keras.layers.Input object, I do manage to get the output of conv1, but trying to access deeper layers fails, for example: I googled every exception that I got on the way, but found no answer. How can I access any layer's input/output (or input/output _shape attributes, by the way) in this case?",https://stackoverflow.com/questions/59383356,5462551.0,1
801,76032177,Error: with dtype is deprecated and will be removed in a future version,"Program exit with error: ValueError: Layer #389 (named ""mrcnn_bbox_fc""), weight &lt;tf.Variable 'mrcnn_bbox_fc/kernel:0' shape=(1024, 324) dtype=float32&gt; has shape (1024, 324), but the saved weight has shape (1024, 8). I try to using tensorflow-gpu 2.8.0 with pixellib 0.7.1 and I get this error:",https://stackoverflow.com/questions/76032177,17605456.0,1
802,57437692,"How to fix ""AttributeError: 'Tensor' object has no attribute 'set_weights'"" error for keras","Im currently trying to load the weights of a network trained in tensorflow into the equivalent network in keras. The issue is once the weights are read, when I try to use the "".set_weights"" command with each layer, this error above occurs. I am not sure why my layers are of class type ""Tensor"" when I have only used keras layers. Below you may see the code, I have loaded the meta file from tensorflow, and the weights from the checkpoint files. Once the network is made in keras and I try to load the weights, it tells me my layers are of class ""Tensor"". #This is for loading the weights into the ""model_vars"" array. with tf.Session() as sess: #An example of how im attempting to load the weights into the layers If you guys could please help out with why my layers are returning tensors, and not keras type layers that would be super helpful.",https://stackoverflow.com/questions/57437692,11892298.0,1
803,56286985,Print the value in the variable which is set using tensorflow high API,"Recently, I tried to touch tf.data.Dataset API. I wish to print the value such as: It not work. Error : My expected results should be:",https://stackoverflow.com/questions/56286985,11194433.0,1
804,64984056,Restore weights from chekpoints Tensorflow object detection API,"I'm working with tensorflow object detection API and I followed their tutorial at: https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb. The problem is that I want to train a Faster R-CNN but I don't know how to load from chekpoint the pretrainded weights. The following code (reported from tutorial) must be adapted for the purpose, but I don't know how.. I don't found any reference or documentation.",https://stackoverflow.com/questions/64984056,12580264.0,1
805,58635125,Cannot make sense of keras.datasets.imdb,"I have two problems: While in fact it's the contrary, print(tf.keras.datasets.imdb.get_word_index()) This result in a nonsense string Shouldn't I get a valid movie review?",https://stackoverflow.com/questions/58635125,1719931.0,1
806,66260432,How to convert numpy code into tensorflow?,I am trying to convert numpy code into tensorflow graph format. But somewhere I am missing an understanding of dimensionality. Here is numpy code: Here is the code which I have been trying: I am getting below error: Could someone help me with this? Thanks in advance,https://stackoverflow.com/questions/66260432,15151611.0,1
807,45905601,How does tf.map_fn work?,"Look at the demo: I can't understand the second and third. For the second: I think the result is [2, -1], because the first time x=np.array([1, 2, 3]) and return 1*2, the second time x=np.array([-1, 1, -1]) and return 1*(-1) For the third: I think the shape of result is (3,2), because the first time x=1 and return (1,-1), the second time x=2 and return (2,-2), the third time x=3 and return (3,-3). So how does map_fn work?",https://stackoverflow.com/questions/45905601,8165066.0,1
808,70980642,Python Tensorflow Dataset Filter Set .issubset(),"I have a tensorflow dataset: I'd like to filter it with the following pythonic function: Unfortunately, decorating with @tf.function doesn't work. Can any of you wizards help me? Here's what I have so far.",https://stackoverflow.com/questions/70980642,14890683.0,1
809,55393557,How to replace particular values based on condition by using tf.where(),I would like to replace values under condition. NumPy version would go like this But TensorFlow has a bit different usage for tf.where() When I tried this I got this error Does that mean I should 4 dimensional tensor for 1e-4?,https://stackoverflow.com/questions/55393557,8979023.0,1
810,49719685,Working of TensorFlow feature columns,Say I have a pandas dataframe with column names 'A' and 'B'. If I write the following line : col = tensorflow.feature_column.numeric_column('A') Does it fetch the values from the dataframe and convert it into a feature column or is col a placeholder? I do not understand the working of tensorflow.feature_column. EDIT The code that caused the confusion,https://stackoverflow.com/questions/49719685,6916919.0,1
811,59363031,Using FOR loop to initialise weights using TensorFlow,"I am facing the following problem. I want to have a function that given the number of points in each hidden layer, creates the weights for a simple NN. I call this function then using to check everything is fine and an IndexError is raised. Anyone can help with this?",https://stackoverflow.com/questions/59363031,12375149.0,1
812,37822097,Using TensorArrays in the context of a while_loop to accumulate values,"Below I have an implementation of a Tensorflow RNN Cell, designed to emulate Alex Graves' algorithm ACT in this paper: http://arxiv.org/abs/1603.08983. At a single timestep in the sequence called via rnn.rnn(with a static sequence_length parameter, so the rnn is unrolled dynamically - I am using a fixed batch size of 20), we recursively call ACTStep, producing outputs of size(1,200) where the hidden dimension of the RNN cell is 200 and we have a batch size of 1. Using the while loop in Tensorflow, we iterate until the accumulated halting probability is high enough. All of this works reasonably smoothly, but I am having problems accumulating states, probabilities and outputs within the while loop, which we need to do in order to create weighted combinations of these as the final cell output/state. I have tried using a simple list, as below, but this fails when the graph is compiled as the outputs are not in the same frame(is it possible to use the ""switch"" function in control_flow_ops to forward the tensors to the point at which they are required, ie the add_n function just before we return the values?). I have also tried using the TensorArray structure, but I am finding this difficult to use as it seems to destroy shape information and replacing it manually hasn't worked. I also haven't been able to find much documentation on TensorArrays, presumably as they are, I imagine, mainly for internal TF use. Any advice on how it might be possible to correctly accumulate the variables produced by ACTStep would be much appreciated.",https://stackoverflow.com/questions/37822097,6466534.0,1
813,72646236,Is there a way to pickle a custom tensorflow.keras metric?,"I defined the following custom metric to train my model in tensorflow: After training the model, I save the model and I also tried to save the custom object as follows: However, when I try to load the metric like this: I always get some errors, e.g. AttributeError: 'MulticlassMeanIoU' object has no attribute 'update_state_fn'. Now I wonder whether it is possible to pickle a custom metric at all and if so, how? It would come in handy if I could save custom metrics with the model, so when I load the model in another Python session, I always have the metric which is required to load the model in the first place. It would be possible to define the metric anew through inserting the full code to the other script before loading the model, however, I think this would be bad style and could cause problems in case I would change something about the metric in the training script and forget to copy the code to the other script.",https://stackoverflow.com/questions/72646236,11611246.0,1
814,46025610,Rank mismatch error in Tensorflow,I'm working on creating an image classifier that can differentiate between cats and dogs. I have the follwing code: But I'm getting this error: Can anyone point out the problem and help me to solve it. I'm totally new to this.,https://stackoverflow.com/questions/46025610,6866762.0,1
815,71641343,Extracting nested layer features (from a pretrained model) with keras sequential API,"I have the following simple model for transfer learning with a pretrained model (VGG16) without the FC layers, followed by a few new layers, defined with keras sequential API. Notice the summary of the model does not show the internal layers for VGG16: I have trained the above model on my custom dataset and got the desired accuracy on my test dataset with transfer learning. Now, let's say I want to create a new model (e.g., to compute the activation map) that accepts the inputs as the input to the previous model, and as outputs, I want an intermediate output (by extracting the features at a convolution layer, e.g., block5_conv3, of the pretrained model) along with the output from the previous model. That's something where I am getting stuck and I am getting errors. For example, I have defined the new model like the following: where I am getting the following error: or like the following: where I am getting the following error: I have also tried to set the names of the input layer of the model and the pretrained model nested inside so that the input layer names are the same: but getting the same error. I think the model structure can be changed (e.g., using keras functional API, etc.), to define the grad_model, but not sure how to. Also, I am more interested to know if there is a way to resolve the issues without changing the model structure / without requiring me to retrain.",https://stackoverflow.com/questions/71641343,4706171.0,1
816,58008541,Why tf.linspace() will return a long decimal number?,"Today, I tried to equally split a number range into a number list with TensorFlow's linspace function, I found it return a very annoying result: The output: But if I use the same function in Numpy, it will show a more reasonable result: The output: Why TensorFlow will return a number that has a long decimal, like -0.5999999 not just -0.6?",https://stackoverflow.com/questions/58008541,7121726.0,1
817,48020809,How to implemet weighted loss for imbalanced data for multi-label classification in tensorflow,"I have an imbalanced dataset,and my task is multi-label classification this is my code for minimizing loss: now.I want to use weighted-loss for my classification,exactly how can I do it? Can I use this link,and replace softmax with sigmoid ? Point I have read this link,but my case is not binary classification and in tensorflow_org I think it is for binary classification too.",https://stackoverflow.com/questions/48020809,9149674.0,1
818,42453138,Tensorflow automatically deletes old model files,"I use tf.train.Supervisor to start a session to train my model, and save model parameter every 1000 steps. But it seems that tensorflow would automatically delete old model files. Only 5 recent models were saved. Once model.ckpt-6000 is produced, the model.ckpt-1000 is deleted. But I can not find any documents on this operation.",https://stackoverflow.com/questions/42453138,7620627.0,1
819,51842242,Tensorflow: Understanding the layer structure of LSTM model,"I'm new to tensorflow and LSTM and I'm having some trouble understanding the shape and structure of the network (weights, biases, shape of inputs and logs). In this specific piece of code taken from here Thanks.",https://stackoverflow.com/questions/51842242,10224602.0,1
820,44270198,"When using TFRecord, how can I run intermediate validation check? (a better way?)","Let's say I defined a network Net and the example code below runs well. The Net does not have tf.placeholder, since input is provided by tensors from TFRecord provider. What if I would like to run validation set as well, e.g., every 500 steps? How can I switch input flow? Only one thing I can imagine is, modifying Net to have placeholders, and every time running like However, this seems to me that I lost benefits of using TFRecord (e.g., full TF integration). In the middle of computation flow, I have to stop the flow, run tf.sess, and continue (doesn't this lower speed by forcing to use CPU in the middle?) I am wondering, Thanks in advance.",https://stackoverflow.com/questions/44270198,3251207.0,1
821,47064693,Tensorflow Data API - prefetch,"I am trying to use new features of TF, namely Data API, and I am not sure how prefetch works. In the code below does it matter between each lines above I put dataset=dataset.prefetch(batch_size)? Or maybe it should be after every operation that would be using output_buffer_size if the dataset was coming from tf.contrib.data?",https://stackoverflow.com/questions/47064693,648946.0,1
822,51582024,Predicting on new datas with TensorFlow,"I'm trying to use tensorflow thanks to a tutorial, but I'm really struggling with the way you have to use it. For the moment I trained a model with these functions : After that, I call everything with my model function : So far so good, but I can't predict my model on new datas. For the moment I've tried things like this : X = scipy.misc.imresize(my_image, size=(64,64)).reshape((1,64,64,3))/255. Returning with the error : Attempting to use uninitialized value fully_connected_1/biases [[Node: fully_connected_1/biases/read = IdentityT=DT_FLOAT, _class=[""loc:@fully_connected_1/biases""], _device=""/job:localhost/replica:0/task:0/cpu:0""]] Or even : But when I run the function with my image, I have the error Tensor(""W1:0"", shape=(4, 4, 3, 8), dtype=float32_ref) must be from the same graph as Tensor(""Placeholder:0"", shape=(?, 64, 64, 3), dtype=float32) How should I do to use my trained models (I have the parameters stored in a variable parameters, I guess ?)Thanks",https://stackoverflow.com/questions/51582024,6528334.0,1
823,45617709,matrix multiplication with sparse output specified by another sparse matrix on tensorflow,"I would like to implement a matrix multiplication on TensorFlow like C = A · B where A ∈ ℝn,k and B ∈ ℝk,n. In my case, n could be potentially large but k is typically small (e.g. low rank or latent embeddings). As you know the dense matrix C ∈ ℝn,n is expensive to store in RAM. However, the only entries in C I want to retain are sparse. That is, by defining another sparse matrix D ∈ ℝn,n, what I really care about are those values with indices [i,j] having values in D. The non-empty values in D should only be 1. So, instead of doing stuff like this: I want to avoid explicitly computing the dense tensor tmp above. Thanks in advance!",https://stackoverflow.com/questions/45617709,8446260.0,1
824,58113043,Visualizing a Keras Model with Tensorboard in Tensorflow 2.0,I am learning to visualize a Keras model using Tensorboard with Tensorflow 2.0 For a reproducible example: How can I proceed from this point to get the visualization? When I run the command from my Jupyter Notebook I get an error message: When I run it from the terminal window again I get an exception:,https://stackoverflow.com/questions/58113043,8270077.0,1
825,42497521,Use of softmax with tf.nn.weighted_cross_entropy_with_logits,"Is it necessary to use tf.nn.softmax() to get the softmax of logits before using tf.nn.weighted_cross_entropy_with_logits()? I am doing binary classification on an imbalanced set, and have my pos_weight value set to [1.0, 15.0] to compensate for the latter class being underrepresented in the data. The other similar op tf.nn.softmax_cross_entropy_with_logits() explicitly says not to use softmax beforehand, but the weighted version does not specify. I have tried it both with and without, and when I use the softmax before the model does not learn (e.g. AUC converges to 0.500). The last layer in my model is using elu activation on a [batch_size, 2] tensor. My labels are coded as [1, 0] for the first class, and [0, 1] for the second.",https://stackoverflow.com/questions/42497521,7542570.0,1
826,65452658,tensorflow argsort confusion in sort?,"I must be missing something rather obvious, however argsort() seems to behave inconsistently. here is a simple example of 5 float numbers, where the first example shows expected results, however the second example seems mixed up... This yields... where I would expect: Could someone explain this behavior?",https://stackoverflow.com/questions/65452658,1725944.0,1
827,59176383,Python Failed to create a NewWriteableFile,"I had some github code to turn two .csv files into .records, to use for image recognition machine learning. The github file is generate_tfrecord.py at https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py, and I had to do some modifications to it, since apparently some of the code in it didn't exist in the libraries it uses. For reference, the new code is: When ran, as specified in command prompt, using and respectively, I get the following error: How do I fix the error? For further reference, someone had an almost identical problem at tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a NewWriteableFile: And the offered answer was Starting from MyPath, which is where I run generate_tfrecord.py from, the csv files which I use (test_labels.csv and train_labels.csv respectively) are inside a folder named ""images"", and there are two folders which images named ""train"" and ""test"" inside it, along with the csv files"". I've tried several variations of changing the paths as advised such as: But they were ineffective. I've tried front slashes, back slashes, without quotes, with """" quotes, nothing worked. I've also searched how to declare a path in flags, didn't help. What should I do to fix the program and get the .record files?",https://stackoverflow.com/questions/59176383,9156980.0,1
828,42468292,GradientDescentOptimizer got wrong result,"I want use gradient descent to solve equation set, but I got wrong result everytime, so I check my code and written a numpy edition, in this edition I provide explicit loss gradient and I can get currect result. So I don't understand why GradientDescentOptimizer can not work. here is my code without tf: And here is my code with tf: I test these 2 codes with very simple equation set: Use gradient descent So at 1st compute, the delta x = (0.7, 1.8) But unfortunately my code with tf give the And my code without tf give the Absolutely code without tf is right, but why tf comput gradient may less 0.05 then currect result? I think this is the reason my code without tf can solve the equation set, but tf edition can not solve equation set currently. Can someone tell me why tf give a incurrent gradiant? Thanks My platform is Win10 + tensorflow-gpu v1.0",https://stackoverflow.com/questions/42468292,2885553.0,1
829,75246436,How to read files in parallel with tf.data.Dataset.from_generator?,"I have successfully created a TF dataset using tf.data.Dataset.from_generator that reads several binary files in sequence and converts them to strings. The code looks like this: The generator does something like this: However, I would like to read the files in parallel using dataset.interleave. Since this operates on an existing dataset, I first created one like this: I then changed my generator to operate on a single file and integrated it into dataset.interleave as follows: It seems as if TF is now expecting my generator to operate on Tensors instead of regular types though, because I get the following error message: As far as I know, this usually means that we need to wrap with tf.py_function, but when I do that I get: Here’s how I did the wrapping: I found this question that gets the same error message, and they suggest using tf.map_fn. However, I am not applying my function to multiple arguments. Instead, I am returning multiple values by applying it to a single argument. Not sure where to go from here...",https://stackoverflow.com/questions/75246436,1465726.0,1
830,42120723,Tensorflow: 'module' object has no attribute 'RunMetaData',I am trying to get GPU/CPU time stats using tensorflow timeline module but on It gives following error. I am using 0.10.0rc0 version. I also go to tensorflow/python/client/timeline.py to actually see the function definition but It didn't exist there. P.S: I have imported from tensorflow.python.client import timeline [Code snippet] [ERROR SNIPPET],https://stackoverflow.com/questions/42120723,1514682.0,1
831,34800715,Tensorflow: custom data load + asynchronous computation,"This is how-to which I believe is missed from TF examples. Task: Each separate bit could be found, however I think have them all together in one place will help to save a lot of time for TF beginners (like myself). Lets tackle 1. in my case it is two sets of images: Now we have all file-names and one-hot labels preloaded. Lets move to the 2. It is based on How to prefetch data using a custom python function in tensorflow. In short it has: Notes: Typical output: All as expected Only thing left is to apply TF as it is intended to be used by replacing some_op :) And a question: one observed problem problem - in case I use tf.FIFOQueue for file-names and tf.RandomShuffleQueue for samples - shuffling doesn't happen. However other way around (as it code above) it does shuffle perfectly. Any problem with shuffling for tf.RandomShuffleQueue(len(fnames), 0, [tf.float32, tf.float32], shapes=[f_s, l_s]) ? ADD: The version with two threads: Also added correct way to stop threads.",https://stackoverflow.com/questions/34800715,5766785.0,1
832,45509356,Deep Dream Code does not generate recognizable patterns,I've tried to create my own Deep Dream Algorithm with this Code: But even after running this loop for 100 iterations the resulting picture still looks random (I will attach said picture to this Question). Can someone please help me to optimize my code?,https://stackoverflow.com/questions/45509356,6725958.0,1
833,51650033,TensorFlow dataset.shuffle() behavior when used with repeat() and batch(),"What exactly will this do? I've noticed several related questions but none of them answered exactly my concern. I'm confused with what shuffle(buffer_size) is doing. I understand it will take 5 first examples [0, 0, 0, 1, 1] into memory, but what will it do next with this buffer? And how does this buffer interact with repeat() and batch()?",https://stackoverflow.com/questions/51650033,4157370.0,1
834,39304995,Reuse large dequeued variable in Tensorflow,"I have a large tensor (some hundreds of megabytes) that is dequeued. I'd like to reuse the large variable on subsequent calls to S.run, but I'm not sure how to do with the existing tensorflow variable sharing paradigm. tf.get_variable requires an initializer, so this is the wrong way to do it but illustrates what I'm trying to do: EDIT 1: Here is the a more complete example -- I'd like to cache result1 and result2 in get_expr()",https://stackoverflow.com/questions/39304995,1611416.0,1
835,45548684,Tensorflow Error : Cannot assign a device for operation 'Bincount' ... because no supported kernel for GPU devices is available,"So, I'm getting the following error : "" Cannot assign a device for operation 'Bincount_1': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available. [[Node: Bincount_1 = Bincount[T=DT_INT32, _device=""/device:GPU:0""](ToInt32_1, Minimum_1, Const_7)]] "" And to me, this is very weird. Because I'm trying to run the following code : And what is weird to me is that when I run the a slightly different code, it works : And, if I remove the tf.bincount function, it also works. So my question is, why does tf.bincount causes an error when trying to use device placement ? And I really need this function to work. Also, the system I'm running is an 8 K-40 GPUs with python3, tensorflow 1.2 .",https://stackoverflow.com/questions/45548684,6315345.0,1
836,49294769,TensorBoard + tensorflow.slim working together,"On low level tensorflow API, I can plot a histogram for example using the following code Recently I decided to try out the slim API, and I was wondering how can I manage my TensorBoard plots in simple, and more complex cases. For example, if I would like to plot the histogram (as tf.summary.histogram) of the weights and the mean (as tf.summary.scalar) of biases in the following two examples, what would I do? Simple example: Complex example:",https://stackoverflow.com/questions/49294769,5368083.0,1
837,48173081,Is tf.Variable a tensor or not?,"I've read some answers on this question here and here, however I'm still a bit puzzled by tf.Variable being and/or not being a tf.Tensor. The linked answers deal with a mutability of tf.Variable and mentioning that tf.Variables maintains their states (when instantiated with default parameter trainable=True). What makes me still a bit confused is a test case I came across when writing simple unit tests using tf.test.TestCase Consider the following code snippet. We have a simple class called Foo which has only one property, a tf.Variable initialized to w: Now, let's say you want to test that the instance of Foo has w initialized with tensor of the same dimension as passed in via w. The simplest test case could be written as follows: Now when you run the test you'll get the following error: You can ""get around"" this unit test error by doing something like this (i.e. note assertShapeEqual was replaced with assertEqual): What I'm interested in, though, is the tf.Variable vs tf.Tensor relationship. What the test error seems to be suggesting is that foo.w is NOT a tf.Tensor, meaning you probably can't use tf.Tensor API on it. Consider, however, the following interactive python session: In the session above, we create a variable and run the get_shape() method on it to retrieve its shape dimensions. Now, get_shape() method is a tf.Tensor API method as you can see here. So to get back to my question, what parts of tf.Tensor API does tf.Variable implement. If the answer is ALL of them, why does the above test case fail? with I'm pretty sure I'm missing something fundamental here or maybe it's a bug in assertShapeEqual ? I would appreciate if someone could shed some light on this. I'm using following version of tensorflow on macOS with python3:",https://stackoverflow.com/questions/48173081,569763.0,1
838,75575777,Trying understand tensorflow sequential summary,I can't figure out a summary of my model. For example first 2 rows of the summary(tf.keras.Sequential.summary()): I don't understand why 4736 params? 64 * 64 * 32 != 4736 my model:,https://stackoverflow.com/questions/75575777,4521938.0,1
839,41353436,TensorFlow: function reduce_sum input,"I am learning TensorFlow from the example at: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/2_BasicModels/linear_regression.ipynb I have a question in the code below: The input of tf.reduce_sum is tf.pow(pred-Y, 2)) which seems to be a scalar (or am I wrong?) Then I am wondering why we want to do reduce_sum on a scalar? What did I miss here? Thanks!",https://stackoverflow.com/questions/41353436,3993270.0,1
840,55822349,Unable to use online prediction service with image input using a model saved from keras,"Consider the following code to create a saved_model Now, I am trying to get an online prediction request to work with the payload full payload at https://gist.github.com/suyash/00d6846ab1a82e74f312ebb43b384c12 which errors out with However, locally if I simply do it works fine UPDATE: I have something working with but that fixes the usable batch size for the service to 1. Ideally, I'd like to use the Lambda layer with tf.map_fn",https://stackoverflow.com/questions/55822349,3673043.0,1
841,45162446,"What's the purpose of ""FLAGS"" in tensorflow","I am studying the mnist example in tensorflow. I am confused with the module FLAGS In the ""run_training"" funcition : What's the purpose of using ""FLAGS.batch_size"" and ""FLAGS.num_epochs"" here? Can I just replace it with a constant number like 128? I found a similar answer in this site but I still can't understand.",https://stackoverflow.com/questions/45162446,8286720.0,1
842,53810890,Select different modes by string in Tensorflow,"I am trying to build a VAE network in which I want the model to do different things in different modes. I have three modes: ""train"", ""same"" and ""different"" and a function named interpolation(mode) that does different things depend on the mode. My code looks like: But the output looks like: which means the mode that gets passed in doesn't change the condition. What have I done wrong? How do I select mode by string argument?",https://stackoverflow.com/questions/53810890,8577452.0,1
843,51557383,Keras - passing different parameter for different data point onto Lambda Layer,"I am working on a CNN model in Keras/TF background. At the end of final convolutional layer, I need to pool the output maps from the filters. Instead of using GlobalAveragePooling or any other sort of pooling, I had to pool according to time frames which exist along the width of the output map. So if a sample output from one filter is let's say n x m, n being time frames and m outputs along the features. Here I just need to pool output from frames n1 to n2 where n1 and n2 &lt;= n. So my output slice is (n2-n1)*m, on which I will apply pooling. I came across Lambda Layer of keras to do this. But I am stuck at a point where n1 and n2 will be different for each points. So my question is how can pass a custom argument for each data point onto a Lambda Layer? or am I approaching this in a wrong way? A sample snippet: The above argument crop_at needs to be custom for each data point when fitting in a loop. Any pointers/clues to this will be helpful.",https://stackoverflow.com/questions/51557383,5554311.0,1
844,55803529,Tensorflow is failing at idiomatically simple piece of code,"I'm using Google Colab to play with Tensorflow. I'm trying to evaluate simple perceptron created by hand rather than using Keras with eager execution mode. The perceptron is expecting input of (1x2) tensor, there are two layers consisting of following weights and biases W1:(2x2) / B1:(1x2) and W2:(2x1) / B2:(1x1), And I have found this simple piece of code failing at my face for no apparent reason. The seems somehow related to optimizers, every optimizer I've tried failed with different errors. For example for optimizer used below (GradientDescentOptimizer) Tensorflow says that the operation is not implemented, I can't figure out why. Here is self-sufficient piece of code (Tensorflow 1.13.1 / Python3): What am I doing wrong? Thank you in advance!",https://stackoverflow.com/questions/55803529,504325.0,1
845,62026001,How to create an complex128 tensor using tf.range,The following lines work: Now if I use I get the usual error : What am I doing wrong?,https://stackoverflow.com/questions/62026001,3926152.0,1
846,42777108,Tensorflow: variable batch_size gives error when trying to predict with eval (Dimensions of inputs should match),"I am training a model with variable batch_size (first batches are 200). So I have used batch_size None to make it variable (I couldn't do that for init_state because it gave an error). Training the model goes well. Then I try to predict probabilities with an x of shape (1, 10) instead of (200, 10): I tried: I also tried in a sligly different way with: Same error: So 1058 is my num_classes, 200 is the (initial) batch_size and 4 is the width of the tensor. I think I am not using the variable batch_size correctly. Any ideas on what to change?",https://stackoverflow.com/questions/42777108,1496362.0,1
847,42426960,How does one train multiple models in a single script in TensorFlow when there are GPUs present?,"Say I have access to a number of GPUs in a single machine (for the sake of argument assume 8GPUs each with max memory of 8GB each in one single machine with some amount of RAM and disk). I wanted to run in one single script and in one single machine a program that evaluates multiple models (say 50 or 200) in TensorFlow, each with a different hyper parameter setting (say, step-size, decay rate, batch size, epochs/iterations, etc). At the end of training assume we just record its accuracy and get rid of the model (if you want assume the model is being check pointed every so often, so its fine to just throw away the model and start training from scratch. You may also assume some other data may be recorded like the specific hyper params, train, validation, train errors are recorded as we train etc). Currently I have a (pseudo-)script that looks as follow: essentially it tries lots of models in one single run but it builds each model in a separate graph and runs each one in a separate session. I guess my main worry is that its unclear to me how tensorflow under the hood allocates resources for the GPUs to be used. For example, does it load the (part of the) data set only when a session is ran? When I create a graph and a model, is it brought in the GPU immediately or when is it inserted in the GPU? Do I need to clear/free the GPU each time it tries a new model? I don't actually care too much if the models are ran in parallel in multiple GPU (which can be a nice addition), but I want it to first run everything serially without crashing. Is there anything special I need to do for this to work? Currently I am getting an error that starts as follow: and further down the line it says: however further down the output file (where it prints) it seems to print fine the errors/messages that should show as training proceeds. Does this mean that it didn't run out of resources? Or was it actually able to use the GPU? If it was able to use the CPU instead of the CPU, when why is this an error only happening when GPU are about to be used? The weird thing is that the data set is really not that big (all 60K points are 24.5M) and when I run a single model locally in my own computer it seems that the process uses less than 5GB. The GPUs have at least 8GB and the computer with them has plenty of RAM and disk (at least 16GB). Thus, the errors that tensorflow is throwing at me are quite puzzling. What is it trying to do and why are they occurring? Any ideas? After reading the answer that suggests to use the multiprocessing library I came up with the following script: honestly I am not sure why his answer suggests to use pool, or why there are weird tuple brackets but this is what would make sense for me. Would the resources for tensorflow be re-allocated every time a new process is created in the above loop?",https://stackoverflow.com/questions/42426960,1601580.0,1
848,56799561,How can I find the list of available string abbreviations for keras classes used as arguments?,"Keras (specifically I'm using tf.keras) allows you to use certain strings as arguments when creating a new class instance, and these strings reference other Keras classes. For example, 'elu' in tf.keras.layers.Dense(10, activation='elu') is a shortcut for tf.keras.activations.elu. However, in the documentation, I can't seem to find any sort of comprehensive list of valid arguments for each parameter. Some are going to be obvious, but it would be a lot easier if I had a list to work from. Furthermore, the behavior of arguments like 'accuracy' in model.compile(..., metrics=['accuracy']) seems far too ambiguous to be lacking in documentation describing its behavior. Can anyone help to point me to appropriate resources for this issue? In addition to the above mentioned 'accuracy', I'm also particularly interested in the monitor parameter of tf.keras.callbacks.EarlyStopping. And does anyone know why the source documentation is lacking so much? Thanks in advance!",https://stackoverflow.com/questions/56799561,9286276.0,1
849,42507766,Why am I getting only one channeled-output through the tf.nn.conv2d?,"I am just trying to use convolution and apply some blur effect initially. Yeah I know that my kernel values aren't right. But my question is, I am giving an input image that has 3 channels. How could I get an output image of 3 channels. Well. I tried. But all I get is some one channeled values alone.",https://stackoverflow.com/questions/42507766,7368783.0,1
850,73776503,How to get shapes of all the layers in a model?,"Consider the following model Is there any way I can get the shape/size/dimensions of the all the layer(s) of a model ? For example in the above model, 'conv2d_1' has shape of (64,1,5,5) while 'conv2d_2' has shape of (32,64,5,5)?",https://stackoverflow.com/questions/73776503,19953155.0,1
851,44288272,Tensorflow argmax along multiple dimensions,"I'm newbie to tensorflow and I'm trying to get the index of the maximum value in a Tensor. Here is the code: Here is the output: Because of dimension=1 in the argmax function the shape of Tensor(""ArgMax:0"") = (32,3). Is there any way to get a argmax output tensor size = (32,) without doing reshape before applying the argmax?",https://stackoverflow.com/questions/44288272,818663.0,1
852,47425424,How to Specify a diagonal matrix using tf.get_variable,I am trying to create a diagonal matrix using tf.get_variable But I do not know how! Like I can make a variable which is a diagonal matrix like: but I can not do it with tf.get_variable. Thanks for your help in advance!,https://stackoverflow.com/questions/47425424,8234464.0,1
853,51103811,Writing functions using TensorFlow,"So I am very new to TensorFlow so my question might be a little stupid or obvious. So I wrote a small and simple code in TensorFlow using function. So basically I am reading 1000 parameters and storing it in a numpy array and passing it through a NN with 2 hidden layers. Here is my code: import tensorflow as tf import numpy as np import random pc = open(""../data/pcNum.txt"", 'r') npc = open(""../data/npcNum.txt"", 'r') lines1 = pc.readlines() lines2 = npc.readlines() size = 200 learning_rate = 0.01 epochs = 200 trainDataset = np.array([]) labels = np.array([]) trainList = [] def arrayfy(sequence): seq = np.array([]) for i in range(0, len(sequence)): seq = np.append(seq, int(sequence[i])) return seq for i in range(0, size): sequence = lines1[i].strip() trainList.append((sequence, 1)) sequence = lines2[i].strip() trainList.append((sequence, 0)) random.shuffle(trainList) for i in trainList: seq = arrayfy(i[0]) trainDataset = np.append(trainDataset, seq) if(i[1] == 0): label = np.array([0, 1]) else: label = np.array([1, 0]) labels = np.append(labels, label) trainDataset = trainDataset.reshape((2 * size, 1000)) trainDataset = trainDataset.T labels = np.transpose(labels.reshape((-1, 2))) dataset = np.asarray(trainDataset, np.float32) labels = np.asarray(labels, np.float32) dataset = tf.convert_to_tensor(dataset, tf.float32) #labels = tf.convert_to_tensor(labels, tf.float32) # Begining of TensorFlow code l1_nodes = 100 l2_nodes = 100 out_nodes = 2 weights_l1 = tf.get_variable('weights_l1', dtype = tf.float32, initializer = tf.random_normal((1000, l1_nodes), mean = 0.0, stddev = 1.0)) weights_l2 = tf.get_variable('weights_l2', dtype = tf.float32, initializer = tf.random_normal((l1_nodes, l2_nodes), mean = 0.0, stddev = 1.0)) weights_out = tf.get_variable('weights_out', dtype = tf.float32, initializer = tf.random_normal((l2_nodes, 2), mean = 0.0, stddev = 1.0)) bias_l1 = tf.get_variable('bias_l1', dtype = tf.float32, initializer = tf.constant(0.0)) bias_l2 = tf.get_variable('bias_l2', dtype = tf.float32, initializer = tf.constant(0.0)) bias_out = tf.get_variable('bias_out', dtype = tf.float32, initializer = tf.constant(0.0)) """"""a1 = tf.placeholder(dtype = tf.float32, name = 'a1') a2 = tf.placeholder(dtype = tf.float32, name = 'a2') z_out = tf.placeholder(dtype = tf.float32, name = 'z_out') hypothesis = tf.placeholder(dtype = tf.float32, name = 'hypothesis')"""""" def forwardPropagation(dataset, weights_l1, bias_l1, weights_l2, bias_l2, weights_out, bias_out): a1 = tf.sigmoid(tf.tensordot(tf.transpose(weights_l1), dataset, axes = 1) + bias_l1) a2 = tf.sigmoid(tf.tensordot(tf.transpose(weights_l2), a1, axes = 1) + bias_l2) z_out = tf.tensordot(tf.transpose(weights_out), a2, axes = 1) + bias_out return z_out entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = z_out, labels = labels, name = 'cross_entropy') loss = tf.reduce_mean(entropy, name = 'loss') optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss) hypothesis = tf.nn.softmax(z_out) correct_preds = tf.equal(tf.argmax(hypothesis, 0), tf.argmax(labels, 0)) accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) writer = tf.summary.FileWriter('./graphs/logreg', tf.get_default_graph()) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(0, epochs): z_out = sess.run(forwardPropagation(dataset, weights_l1, bias_l1, weights_l2, bias_l2, weights_out, bias_out)) _, l = sess.run([optimizer, loss]) #, feed_dict = {z_out:z_out, labels:labels}) sess.run(hypothesis) sess.run(correct_preds) acc = sess.run(accuracy) print(""Epoch :"", i+1, "", loss : "", l, "", accuracy :"", acc) writer.close() It gives the error as: entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = z_out, labels = labels, name = 'cross_entropy') NameError: name 'z_out' is not defined So what do I have to do to make this run properly keeping the function? Also when I remove the function it apparently runs although I am not sure whether it is doing what I expect it to do: import tensorflow as tf import numpy as np import random pc = open(""../data/pcNum.txt"", 'r') npc = open(""../data/npcNum.txt"", 'r') lines1 = pc.readlines() lines2 = npc.readlines() size = 200 learning_rate = 0.01 epochs = 200 trainDataset = np.array([]) labels = np.array([]) trainList = [] def arrayfy(sequence): seq = np.array([]) for i in range(0, len(sequence)): seq = np.append(seq, int(sequence[i])) return seq for i in range(0, size): sequence = lines1[i].strip() trainList.append((sequence, 1)) sequence = lines2[i].strip() trainList.append((sequence, 0)) random.shuffle(trainList) for i in trainList: seq = arrayfy(i[0]) trainDataset = np.append(trainDataset, seq) if(i[1] == 0): label = np.array([0, 1]) else: label = np.array([1, 0]) labels = np.append(labels, label) trainDataset = trainDataset.reshape((2 * size, 1000)) trainDataset = trainDataset.T labels = np.transpose(labels.reshape((-1, 2))) dataset = np.asarray(trainDataset, np.float32) labels = np.asarray(labels, np.float32) dataset = tf.convert_to_tensor(dataset, tf.float32) #labels = tf.convert_to_tensor(labels, tf.float32) l1_nodes = 100 l2_nodes = 100 out_nodes = 2 weights_l1 = tf.get_variable('weights_l1', dtype = tf.float32, initializer = tf.random_normal((1000, l1_nodes), mean = 0.0, stddev = 1.0)) weights_l2 = tf.get_variable('weights_l2', dtype = tf.float32, initializer = tf.random_normal((l1_nodes, l2_nodes), mean = 0.0, stddev = 1.0)) weights_out = tf.get_variable('weights_out', dtype = tf.float32, initializer = tf.random_normal((l2_nodes, 2), mean = 0.0, stddev = 1.0)) bias_l1 = tf.get_variable('bias_l1', dtype = tf.float32, initializer = tf.constant(0.0)) bias_l2 = tf.get_variable('bias_l2', dtype = tf.float32, initializer = tf.constant(0.0)) bias_out = tf.get_variable('bias_out', dtype = tf.float32, initializer = tf.constant(0.0)) """"""a1 = tf.placeholder(dtype = tf.float32, name = 'a1') a2 = tf.placeholder(dtype = tf.float32, name = 'a2') z_out = tf.placeholder(dtype = tf.float32, name = 'z_out') hypothesis = tf.placeholder(dtype = tf.float32, name = 'hypothesis')"""""" #def forwardPropagation(dataset, weights_l1, bias_l1, weights_l2, bias_l2, weights_out, bias_out): a1 = tf.sigmoid(tf.tensordot(tf.transpose(weights_l1), dataset, axes = 1) + bias_l1) a2 = tf.sigmoid(tf.tensordot(tf.transpose(weights_l2), a1, axes = 1) + bias_l2) z_out = tf.tensordot(tf.transpose(weights_out), a2, axes = 1) + bias_out #return z_out entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = z_out, labels = labels, name = 'cross_entropy') loss = tf.reduce_mean(entropy, name = 'loss') optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss) hypothesis = tf.nn.softmax(z_out) correct_preds = tf.equal(tf.argmax(hypothesis, 0), tf.argmax(labels, 0)) accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) writer = tf.summary.FileWriter('./graphs/logreg', tf.get_default_graph()) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(0, epochs): #z_out = sess.run(forwardPropagation(dataset, weights_l1, bias_l1, weights_l2, bias_l2, weights_out, bias_out)) _, l = sess.run([optimizer, loss]) #, feed_dict = {z_out:z_out, labels:labels}) sess.run(hypothesis) sess.run(correct_preds) acc = sess.run(accuracy) print(""Epoch :"", i+1, "", loss : "", l, "", accuracy :"", acc) writer.close() Any help and tips is much appreciated.",https://stackoverflow.com/questions/51103811,8560127.0,1
854,72356358,What's the difference between the print inside and outside,"I am learning the tensorflow which version is 2.8.0 on my MacBook M1. For debugging the code in the map function of dataset, I want to print tensor value in my function. I got the output as blew: After I delete the print outside, I did not get any output. What's the difference between the print inside and the print outside. I don't understand why it can only take effect when the prints appear at the same time. Beside that, what the difference between print and tf.print?",https://stackoverflow.com/questions/72356358,12652230.0,1
855,39054414,Tensorflow: Using tf.slice to split the input,"I'm trying to split my input layer into different sized parts. I'm trying to use tf.slice to do that but it's not working. Some sample code: Output: This works and is roughly what I want to happen, but I have to specify the first dimension (3 in this case). I can't know though how many vectors I'll be inputting, that's why I'm using a placeholder with None in the first place! Is it possible to use slice in such a way that it will work when a dimension is unknown until runtime? I've tried using a placeholder that takes its value from ph.get_shape()[0] like so: x = tf.slice(ph, [0, 0], [num_input, 2]). but that didn't work either.",https://stackoverflow.com/questions/39054414,4829166.0,1
856,55242278,Tensorflow - trainable variable does not change over time,"I'm trying to apply two different masking methods to an input tensor, one is a half normal distribution filter and the other is a simple step function. While the half Gauss filter works fine, when trying to apply a step function filter, the variable (i.e that defines the point where the step occurs) doesn't seems to learn at all. This is the filters code: And from tensorboard it seems like it doesn't even attached to the Adam optimizer at the end. and weight_param_v is flat on weight_param. Is it possible that because other operations, e.g sequence_mask the variable becomes non-trainable?",https://stackoverflow.com/questions/55242278,7034613.0,1
857,43484396,"tensorflow slice dimension,change only a channel of tensor","I want to multiply a channel by 2. I tried the following code, but it doesn't work, anybody knows why?",https://stackoverflow.com/questions/43484396,7859760.0,1
858,52381912,"Why is the training step slower in tensorflow than in Keras (Same network, optimizer, everything)?","I am implementing a CNN fro MNIST both in Tensorflow and in Keras. Therefore Im trying to implement the same network in both platforms, just to compare. However, Im getting a really strange result: The Keras code is really faster than the TF code. I know Keras is just a wrapper, so I cant actually explain it. Here is my keras code: And here is my tensorflow equivalent: Does anyone know what am I doing wrong in TF, that it is so slow?",https://stackoverflow.com/questions/52381912,10373919.0,1
859,72783608,Creating Tensorflow Dataset for mulitple time series,I have a multiple time series data that looks something like this: where each object (1 and 2) has its own data (about 2000 objects in real data). I would like to feed this data chunkwise into RNN/LSTM using tf.data.Dataset.window in a way that different objects data don't come in one window like in this example: Output: Expected output: Maybe there is another way to do it. The main requirement that my model should see that non-mixed data chunks come from different objects (maybe via embedding).,https://stackoverflow.com/questions/72783608,8973620.0,1
860,33762831,Error when building seq2seq model with tensorflow,"I'm trying to understand the seq2seq models defined in seq2seq.py in tensorflow. I use bits of code I copy from the translate.py example that comes with tensorflow. I keep getting the same error and really do not understand where it comes from. A minimal code example to reproduce the error: The error I get when evaluating the last line (I evaluated it interactively in the python interpreter): I suspect the error comes from my side :) On a sidenote. The documentation and the tutorials are really great but the example code for the sequence to sequence model (the english to french translation example) is quite dense. You also have to jump a lot between files to understand what's going on. Me at least got lost several times in the code. A minimal example (perhaps on some toy data) of constructing and training a basic seq2seq model would really be helpful here. Somebody know if this already exist somewhere? EDIT I have fixed the code above according @Ishamael suggestions (meaning, no errors returns) (see below), but there are still some things not clear in this fixed version. My input is a sequence of vectors of length 2 of real valued values. And my output is a sequence of binary vectors of length 22. Should my tf.placeholder code not look like the following? (EDIT yes) I also had to change tf.int32 to tf.float32 above. Since my output is binary. Should this not be tf.int32 for the tf.placeholder of my decoder? But tensorflow complains again if I do this. I'm not sure what the reasoning is behind this. The size of my hidden layer is 512 here. the complete fixed code",https://stackoverflow.com/questions/33762831,1782011.0,1
861,66748911,Wrapper layer to change kernel weights,"I'm trying to write a custom wrapper layer such as the following one (simplified), where I want to modify the kernel weights of the wrapped layer: However, the code breaks in the first line of the call function with the following output: I've already checked https://www.tensorflow.org/addons/api_docs/python/tfa/layers/WeightNormalization but am not sure whether it helps. While they also seem to redefine the kernel, they redefine it based on separate variables and not the kernel itself (in my understanding). Any help would be greatly appreciated!",https://stackoverflow.com/questions/66748911,2135504.0,1
862,42488475,Tensorflow LSTM Dropout Implementation,"Everything I read about applying dropout to rnn's references this paper by Zaremba et. al which says don't apply dropout between recurrent connections. Neurons should be dropped out randomly before or after LSTM layers, but not inter-LSTM layers. Ok. In the paper that everyone cites, it seems that a random 'dropout mask' is applied at each timestep, rather than generating one random 'dropout mask' and reusing it, applying it to all the timesteps in a given layer being dropped out. Then generating a new 'dropout mask' on the next batch. Further, and probably what matters more at the moment, how does tensorflow do it? I've checked the tensorflow api and tried searching around for a detailed explanation but have yet to find one.",https://stackoverflow.com/questions/42488475,6534643.0,1
863,40762677,how do you change the rank of tensorflow object,"Hello I am new in tensorflow I make my graph and I try to run it but I get this error : which comes from this line I checked the rank of my variable phix and the result is 0, I didn't understand why because its shape is (3,3). this is my script, could you help me please.",https://stackoverflow.com/questions/40762677,5462772.0,1
864,48408886,TensorFlow: How to run timeline / trace? AttributeError: module 'tensorflow' has no attribute 'RunSettings',"apparently, with a recent update to tensorflow, the option of running a trace / timeline / or whatever it's called has disappeared. The following code used to create a .json file that allowed me to see a detailed timeline of the code, using Chrome: However, now I'm getting the error Has that function been implemented in another way? I have no idea what the documentation is trying to tell me: https://www.tensorflow.org/api_docs/python/tf/RunOptions This directs me to a github repo and I have no idea how that would be helpful. TLDR; How do I run the timeline / tracer with the current version of tf (1.4.1)?",https://stackoverflow.com/questions/48408886,6621268.0,1
865,75721717,Understanding Vision Transformer Implementation in Keras: Issues with Patch Shape and Embedding Layer,"I'm trying to understand this implementation of vision transformers in keras. Here is the full code. I can't understand why patches = tf.reshape(patches, [batch_size, -1, patch_dims]) is returning a tensor (batch_size,num_patches,patch_dim) with shape of (none,none,108) instead of a tensor of shape (none,144,108), in this case is returned only one patch and I can The dimension of patches before being reshaped is (none,12,12,108) in which 12 and 12 are the height and width of all the patches in the image Later this tensor is then passed to the PatchEncoder() that passes this 108 elements patch in a 64 dimension dense layer but this should not be done for each of the 144 patches instead of just one(the returned patch of Patches())? So that I can have an embedding layer for each of the 144 patches I have 64 dimension vector elements all different from each other based on the corresponding patch? So I thought that the embedding layer should be something like this in which for each patch I have different values based on the values in the actual patch Instead of this in which all the values in the initial patches are the same because of the shape return in tf.reshape() My question is how passing a tensor of shape (none,none,108) make sense with this ViT implementation? Here is also the summary of the model:",https://stackoverflow.com/questions/75721717,20504956.0,1
866,52712301,"Keras merge VS concatenate, can't update my code","I have a Keras functional model for a CNN. I'm trying to implement a triplet-loss function. I found some posts about who to do that using ""merge"", which is now deprecated, but I'm not able to use ""concatenate"" as I was using merge. The original code looks like this: I was using loss = merge([anchor_embed, positive_embed, negative_embed], mode=triplet_loss, output_shape=(1,)) as a way to transform the output of the function triplet_loss into a keras layer output (as suggested in https://codepad.co/snippet/F1uVDD5N). The function concatenate doesn't have a parameter ""mode"". HIs there any way to adapt my code to get the result of the loss function as a Keras layer output?",https://stackoverflow.com/questions/52712301,2302912.0,1
867,69391384,Tensorflow does not work with cudnn problem,"I'm using ubuntu 20.04 and installed anaconda. According to this instruction, I create an environment by conda create -n tf tensorflow-gpu after installing the necessary package like scikit-learn and tqdm, I tried to run the following code I use the command python tftest.py to run the code with GPU. However the code stuck for 4 minutes here, then the error occurs My GPU is Geforce RTX3060, and CUDA version is 114.4 I've tried rebuilding the enviroment. Here's some of my package list. Thanks!",https://stackoverflow.com/questions/69391384,11522867.0,1
868,58976313,How to fix: AttributeError: module 'tensorflow' has no attribute 'contrib',I'm training a LSTM and I'm defining parameters and regression layer. I get the error in the title with this code: I'm using tensorflow2 and I have already read the https://www.tensorflow.org/guide/migrate guide and I think almost everything on the net. But I'm not able to solve it. How can I do it?,https://stackoverflow.com/questions/58976313,12410520.0,1
869,54865674,Tensorflow's placeholder initialization differs from tensorflow's constant initialization. Why?,I have written 2 functions that initialize tensorflow's variables in different ways. I don't know why the results are different. Here is the first function using placeholder for initialization: And the result is: Second function uses tf.constant to initialize variables: Result: What is the problem? Is it related to np.random.seed(1) ? Thanks.,https://stackoverflow.com/questions/54865674,8902456.0,1
870,70590588,TypeError: __init__() got an unexpected keyword argument 'intialize_fn',"I use TFF v:0.18 I would like to load a pretrained network in the inside of create_keras_model() So I write this : But I find this error: I don't believe that the syntax is error,",https://stackoverflow.com/questions/70590588,14253961.0,1
871,49495364,Failed to train toy LSTM in tensorflow,"I'm trying to get acquainted with recurrent networks in tensorflow using a toy problem for sequence classification. Data: Model: Training: My training accuracy varies around 0.5, which confuses me because the problem is very simple. Changing the toy data to: Yields an instant convergence to accuracy 1. Could anyone please explain me why this network fails on such a simple task? Thank you. The code above is based on this tutorial.",https://stackoverflow.com/questions/49495364,4405942.0,1
872,53481163,TensorFlow: how to start the Profiler,"I want to profile my model. This is a tutorial on how to do it: https://towardsdatascience.com/howto-profile-tensorflow-1a49fb18073d. But I would like to use the TensorFlow profiler, as shown in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/README.md#quick-start. According to this post, the following code should start the profiler: I generated the file profile_100 and located the directory profiler. So this is what I typed in my terminal: This raised the following error: My directory profiler contains: But according to the above code, there should be Which I don't have. What do I do to start the Profiler?",https://stackoverflow.com/questions/53481163,2594778.0,1
873,51788429,3D CNN parameter calculation,"I have a CNN code that was written using tensorflow library: my input image x_img is 25x25x25(3d image), I have some questions about the code: 1- is [3,3,3,1,32] in 'W_conv1_layer' means [width x height x depth x channel x number of filters]? 2- in 'W_conv2_layer' weights are [3,3,3,32,64], why the output is 64? I know that 3x3x3 is filter size and 32 is input come from first layer. 3- in 'W_fc_layer' weights are [409600,1024], 1024 is number of nodes in FC layer, but where this magic number '409600' come from? 4- before the image get into the conv layers why we need to reshape the image",https://stackoverflow.com/questions/51788429,3392589.0,1
874,71638519,Tensor error using DiffAugment for data augmentation in my own dataset . data efficient gans,"I'm trying to create synthetic data from pics within a folder called Bathroom using Running the command they have, and without having errors of locations/etc: Appears the following error: The pictures in the folder bathroom are all .jpg, and regarding the resolution I choose in the code above, the result is the same. By the way, I don't have really clear how to specify the output volume of pics, for my own dataset. Anyone else working with their own dataset for that repo? Thanks",https://stackoverflow.com/questions/71638519,12315558.0,1
875,72660715,Streamlit with Tensorflow to analyse image and return the probability if is positive or negative,"I'm trying to use Tensorflow to Machine Learning to analyze an image and return the probability if is positive or negative based on a model created (extension .h5). I couldn't found a documentation exactly for that, or repository, so even a link to read will be awesome. Link for the application: https://share.streamlit.io/felipelx/hackathon/IDC_Detector.py Libraries that I'm trying to use. The function to load the model. The function to work the image, and what I'm trying to see: model.predict - I can see but is not updating the %, independent of the image the value is always the same. Thank you in advance to any help.",https://stackoverflow.com/questions/72660715,12164652.0,1
876,63624397,How to prepare a Tensorflow model to be deployed in AI Platform,"I'm using a Tensorflow 2 pre-trained model (vgg16) to classify images. I have done the training on my local machine and now I wanted to deploy it GCloud AI Platform. This model's input is expecting an already decoded and resized image. However, when I try to call a predict, it returns an error that I'm exceeding the size limit. After looking into the documentation I saw that this method is very inefficient and so I must use base64 encoding to represent the image. The problem is that the model is not expecting an encoded image and I know that I need to modify the model before exporting it. However all the questions (1,2,3,4) that I see related to this are from TF version 1, using placeholders that are deprecated in TF 2. Can someone help me on this? Here is the code I'm using for transfer learning:",https://stackoverflow.com/questions/63624397,9824232.0,1
877,64677724,Sequential model with tensorflow dataset,"I tried to understand how to use tensorflows Datasets for a simple regression model, instead of feeding it with a separate np.array for training input and output. Here a simple standalone example: Running that example my_model.fit(X_train_set,y_train_set,epochs=2)does work. However, my_model.fit(train_dataset,epochs=2) throws an error: The question is: do I have to create a different Sequential model or is my train_dataset simply incorrect? I would assume a np.array should be exchangeable with a Dataset in the training step?",https://stackoverflow.com/questions/64677724,8800103.0,1
878,47761069,Tensorboard Embedding Visualization,"I am working on a text classification problem. I have 3M+ rows which need to be classified into 20 categories. Following are two code snippets from my entire code: This is the code where my tf variables are defined.: The tensor I would like to visualize is embedded_chars. And this is the code where I am given input to the projector api: My expectation: I want to see my trained input data and how its being classified. Actual result: When I use embedded_chars tensor as input to projector, noting loads. however, when I use emb_var I see the embeddings loading. The problem is emb_var is just my vocabulary but I need to see my actual dataset.",https://stackoverflow.com/questions/47761069,7320664.0,1
879,39083712,tensorflow merge input and output,"I would like to use two model in tensorflow in a row, to fit the first one and to use directly it for the second one as input. But I didn't find the good way to do it. I tried to proceed as the following , The thing is to minimise first minimise cross_entropy( y1 y1_) with parameters W_conv b_conv then use y1 as parameter by construciting im_y1 as describe. But like I written it, it dosent work because tf.zeros_initializer refuse to get the argument None. What is the good way to pipeline different fit in the same model in Tensorflow? Thanks to any comments!",https://stackoverflow.com/questions/39083712,4508245.0,1
880,42551282,don't understand mnist example in tensorflow,"I don't understand the mnist example in 'deep mnist for experts' in Tensorflow. In order to build a deep network, we stack several layers of this type. The second layer will have 64 features for each 5x5 patch. I don't know why outputchannel is 64. I think we need to 32*2 * 5*5 filter for 64 outputchannel, so first of all, i'm sorry for not good english maybe you hard to understand my ask so i', write sudo code logic i think it make 62 output feature using 32*2 filter and save memory what part is wrong? thank you",https://stackoverflow.com/questions/42551282,7646272.0,1
881,68688234,Why does tensorflow put `ReadVariableOp` for some variables while doesn't put a `ReadVariableOp`s for the other?,"I'm trying to understand tensorBoard’s Graphs dashboard following a tf tutorial Here is the code And I got this plot Why does tensorflow put ReadVariableOps for a and b, pointed out by the red rectangles, while doesn't put a ReadVariableOp for c?",https://stackoverflow.com/questions/68688234,12214867.0,1
882,45585546,Error with tf.contrib.keras + tf.placeholder,"I am trying to use built-in models in Keras. This works well: This is not: It makes error You must feed a value for placeholder tensor 'Placeholder' with dtype float but I have no sess.run(). Why does it complain about feed when I just try to construct the graph? Add This is the stacktrace. The error comes from model.load_weights. However, I think loading InceptionV3 weights should be independent of the other part of the graph.",https://stackoverflow.com/questions/45585546,2547570.0,1
883,53404301,How to compute Spearman correlation in Tensorflow,"I need to compute the Pearson and Spearman correlations, and use it as metrics in tensorflow. For Pearson, it's trivial : But for Spearman, I am clueless ! From this answer : But this return NaN... Following the definition of Wikipedia : I tried : But running this I got the following error :",https://stackoverflow.com/questions/53404301,9494790.0,1
884,54610824,Definition of tf.Variables (using a list?),"I am starting with Tensorflow and so far I have only dealt with 'shallow' feed-forward networks or neural networks with a small number of hidden layers, whose corresponding W's were defined individually in a way such as this (the example corresponds to the initialization of a network with five hidden layers): My question is whether there exists any mechanism to pass the depth of the NN as a hyperparameter (while specifying the number of nodes per layer), so that you could avoid this step, in case you are dealing with deeper networks. Many thanks in advance, and may you have a nice weekend.",https://stackoverflow.com/questions/54610824,4765393.0,1
885,34790159,Stacked RNN model setup in TensorFlow,"I'm kind of lost in building up a stacked LSTM model for text classification in TensorFlow. My input data was something like: The skeleton of my code looks like: The problem is that no matter how large the dataset is, the loss and accuracy has no sign of improvement (looks completely stochastic). Am I doing anything wrong? Update:",https://stackoverflow.com/questions/34790159,1472128.0,1
886,69987048,Multi-branch neural network does not learn dependencies,"I am currently trying to learn using a multi-branch neural network. The underlying data looks something like the following table: I would now expect that my neural network learns besides the distribution of variables per column (Var_1: a_1=3/5, b_1=2/5; Var_2: a_2=3/5, b_2=2/5; Var_3: a_3=2/5, b_3=2/5; c_3=1/5) also that there is an dependency between the occurance of a_1 and a_2 as well as b_1 and b_2. But my observation is that the neural network only learns the distribution of the variables per columns and then always predicts the most often occuring value per column. So if I would like to predict Var_1 and Var_3 have already given Var_2 the predictions are indifferent of what value for Var_2 is already given. It always predicts the most often occuring value per column and looks the following: Var_2=a_2 -&gt; Var_1=a_1; Var_3=a_3 Var_2=b_2 -&gt; Var_1=a_1; Var_3=a_3 The neural network is built the following: Here a snapshot of the network: I use Adam as an optimizer, but have already tried some others. Edit: I recognized in the meantime that the last branch is learning correctly. I changed the variable that is in the last branch (most right in the picture of the output layer) to verify that and it has proven right. The accuracy is continuously increased for this variable during training whereas the other variables stop at the proportion of the most often occurring variable value. A very strange behavior for my understanding. Any recommendation would be highly welcome. Thank you! Best regards, Mathias",https://stackoverflow.com/questions/69987048,13100134.0,1
887,66000321,dataset.repeat() will cause the infinite loop?,"I am learning Tensorflow by reading the official document. But confused by this line: dataset = dataset.shuffle(1000).repeat() I try to run this whole project, it can actually work. But I don't understand why it won't step into the endless loop caused by dataset.repeat(), because you don't assign the count so it will repeat indefinitely. Hope anyone can help me to figure this out? Here is the link to this line of code:https://www.tensorflow.org/tutorials/estimator/premade It is in part ""define the feature columns"" and the whole code block is copied below:",https://stackoverflow.com/questions/66000321,15125892.0,1
888,73115505,"""TypeError: Could not build a TypeSpec for name ..."" when using tf.assert on unknown dimensions","Suppose I am building a model with partially known dimensions: my_custom_op is a large, complex tensor function that uses assertions in various places to ensure that assumptions about shape and rank are being met. For the sake of reproducing the problem I'll just make it this: When I run this I get the following error: I don't understand what this error message is telling me. If I run tf.assert_equal(2, 2) I don't get an exception, so I assume it's to do with the fact that the dimensions are not known yet. But isn't the point of asserts that they run when the dimensions are known? If not, does this mean I can't use asserts in my_custom_op because they will cause these errors when the graph is constructed? Here is the full error message:",https://stackoverflow.com/questions/73115505,1613983.0,1
889,61595909,Tensorflow hub.load Model to TFLite,"I am trying to convert a model loaded with hub.load to TFLite. The model in question is universal-sentence-encoder (4) found at https://tfhub.dev/google/universal-sentence-encoder/4 I tried in Python with Tensorflow version 2.1.0 and 2.2.0 I get the following error: From my understanding hub.load return a keras SavedModel, so shouldn't be convertible right away?",https://stackoverflow.com/questions/61595909,2155494.0,1
890,60012898,Is there a way to create a variable that persists over tf.estimator.train_and_evaluate evaluation steps?,"I have found this : How to create a variable that persists over tf.estimator.train_and_evaluate evaluation steps? But nobody seems to have answered the original question. For other reasons I need to do this, i.e. have variables that persist each of the steps of the estimator evaluate. Is there a simple way to do this ? Thanks,",https://stackoverflow.com/questions/60012898,906012.0,1
891,46288154,"In tensorflow, why do the predictions are two dimensional?","As I'm learning Tensorflow, I have a confusion about the dimensions of the output layer tensor. I am learning how to build a multilayer_perceptron model in Tensorflow. The code I'm starting from is this one. In short, it's basically as the below frame: I understand the concepts of argmax and equal methods. But why in tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)) the axis argument is 1? Or to say, why the pred is more than 1 dimension? To me, the pred shall be just similar to a 1D array. E.g. [0,1,1,1,1] means except the first prediction, all others are right. And why we need a argmax before the equal method? Thank you!",https://stackoverflow.com/questions/46288154,7521737.0,1
892,57516662,"ValueError: Error when checking input: expected input to have 4 dimensions, but got array with shape (859307, 1)","I'm creating a convolutional autoencoder that takes in 16x16 images but I keep getting the following error: From other stack overflow posts such as this one, it seems like I need to add another dimension for the colour channel but what would the other dimension I add be? Code New Error after reshaping is added: Error without reshaping:",https://stackoverflow.com/questions/57516662,9715052.0,1
893,64857781,Why in created dataset in tensorflow Labels showed with shape and datatype information?,I am new to Tensorflow: I want to create my own dataset: why when I plot the images the labels printed this way and not just label name?,https://stackoverflow.com/questions/64857781,13417019.0,1
894,47141359,How to calculate factorial in tensorflow?,"I am new to tensorflow, I am trying to find a function that calculates the n!. I saw that one can use the gamma function, which was possible with theano, but did not work for tensorflow. I am using a for loop to multiply number from n to 1, but I assume there is an easier and faster way. I saw functions related to gamma distribution, but couldn't figure out how to calculate the factorial. Would appreciate if one can point me to some documentation. Here is the way I do it now Output is",https://stackoverflow.com/questions/47141359,1577800.0,1
895,57346868,Why prediction on activation values (Softmax) gives incorrect results?,"I've implemented a basic neural network from scratch using Tensorflow and trained it on MNIST fashion dataset. It's trained correctly and outputs testing accuracy around ~88-90% over 10 classes. Now I've written predict() function which predicts the class of given image using trained weights. Here is the code: This uses forward_propagation() function which returns the weighted sum of the last layer (Z) and not the activitions (A) because of TensorFlows tf.nn.softmax_cross_entropy_with_logits() requires Z instead of A as it will calculate A by applying softmax Refer this link for details. Now in predict() function, when I make predictions using Z instead of A (activations) it's working correctly. By if I calculate softmax on Z (which is activations A of the last layer) it's giving incorrect predictions. Why it's giving correct predictions on weighted sums Z? We are not supposed to first apply softmax activation (and calculate A) and then make predictions? Here is the link to my colab notebook if anyone wants to look at my entire code: Link to Notebook Gist So what am I missing here?",https://stackoverflow.com/questions/57346868,5353128.0,1
896,58530265,How to use tensorflow-gpu GPUOptions,I am trying to use tensorflow-gpu so I can run my models faster but I don't really understand how I can activate it. At the moment my code looks like this: But this code obviously doesn't work and I am how to use it. I already looked on the official tensorflow website documentation but it's really confusing. Can someone please tell me how to use it properly?,https://stackoverflow.com/questions/58530265,11651915.0,1
897,40819321,Understanding the conceptual basics of Distributed TensorFlow,Let me describe the cluster setup first : I have gone through the Distributed TensorFlow documentation but there are some functional basics I could not understand properly and hence this question. Consider the following situation : If I want to use Distributed TensorFlow to train a model :,https://stackoverflow.com/questions/40819321,6842947.0,1
898,72311927,How to train mnist data with tensorflow ParameterServerStrategy distributed training?,"I'm trying to train the mnist dataset using the ParameterServerStrategy. As a beginner, I find the documentations to be confusing specially when it comes to the section ""Clusters in the real world"". This is the docs that I'm following:https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#scrollTo=zyby6M2Jqg6J&amp;uniqifier=1 So far I have this: I copy these files to the worker and ps VM, change the index and run ""main.py"" on all of them at the same time. I get the message saying that the server was started at ip_address but that's about it. Would anyone please show me what I need to do in order to get this working?",https://stackoverflow.com/questions/72311927,11909464.0,1
899,63357758,Recurrent loss in tensorflow without executing eagerly,I have the following very simple example for a loss (that probably doesnt make sense) that just evaluates the reduced_mean of the model_output combined with the last model_output (in a ratio of 9 to 1). So for example if I understand correctly how tf is working this is only possible because by default tf is executing eagerly (tf.executing_eagerly() == True). That's should be the reason why I can overwrite the self.last_output variable with a new tensor to achieve a recurrent structure. My Question: How can I can i achieve the same kind of recurrent structure in a tf graph that doesn't use eager execution?,https://stackoverflow.com/questions/63357758,7018093.0,1
900,56571803,Understanding graphs in TF 2.0 beta,"I'm doing experiments with NN. Everything is perfect when I don't put @tf.function decorator on my train_one_step function. When I say perfect, I mean everything works as expected. However, training is terribly slow, so I have to put the decorator back on. As I do this, weird things start to happen and I don't understand it and therefore cannot do any experiments. For example, after dome training, I decided to go and delete the optimizer, Then do some more training, and .... nothing is wrong and training goes as usual !! what the heck? I deleted the optimizer! when I'm not putting the decorator and I delete the optimizer, the program shouts at me and says this thing is not defined (because it is required in training function). That's just one extreme example of weird things that I don't understand when the decorator is on. My question is: can someone explain the what the decorator is doing? it seems to be taking my stuff and build a graph out of it, when its first called, but I don't have access to that graph, it sounds like things are happening in a different world where I have no control over what's happening. If I change things later in my world, they don't reflect in that world. EDIT: Some one said that's too general and I want a code. I made a simple version based on mnist to illustrate Now, everything is perfect. After running the code above, go to a different cell (I'm assuming Jupyter notebook). delete the optimizer, run train(model), and it works perfectly !! With no optimizer!! If the decorator wasn't on, this wouldn't have happened. This is just one extreme example of how things that I do are not reflected in whatever is happening behind the scenes. To be extra clear, this is from TF website tutorial, but I made some changes, including removing the parameter 'optimizer' that was being passed from train function to train_one_step cause I thought it is global and you don't need to keep passing it around.",https://stackoverflow.com/questions/56571803,10870968.0,1
901,39732460,How to use evaluation_loop with train_loop in tf-slim,"I'm trying to implement a few different models and train them on CIFAR-10, and I want to use TF-slim to do this. It looks like TF-slim has two main loops that are useful during training: train_loop and evaluation_loop. My question is: what is the canonical way to use these loops? As a followup: is it possible to use early stopping with train_loop? Currently I have a model and my training file train.py looks like this Which is awesome so far - my models all train and converge nicely. I can see this from the events in train_log_dir where all the metrics are going in the right direction. And going in the right direction makes me happy. But I'd like to check that the metrics are improving on the validation set, too. I don't know of any way to do with TF-slim in a way that plays nicely with the training loop, so I created a second file called eval.py which contains my evaluation loop. Questions: 1) I currently have this model for the evaluation_loop hogging up an entire GPU, but it's rarely being used. I assume there's a better way to allocate resources. It would be pretty nice if I could use the same evaluation_loop to monitor the progress of multiple different models (checkpoints in multiple directories). Is something like this possible? 2) There's no feedback between the evaluation and training. I'm training a ton of models and would love to use early stopping to halt the models which aren't learning or are not converging. Is there a way to do this? Ideally using information from the validation set, but if it has to be just based on the training data that's okay, too. 3) Is my workflow all wrong and I should be structuring it differently? It's not clear from the documentation how to use evaluation in conjunction with training. Update ~~It seems that as of TF r0.11 I'm also getting a segfault when calling slim.evaluation.evaluation_loop. It only happens sometimes (for me when I dispatch my jobs to a cluster). It happens in sv.managed_session--specifically prepare_or_wait_for_session.~~ This was just due to evaluation loop (a second instance of tensorflow) trying to use the GPU, which was already requisitioned by the first instance.",https://stackoverflow.com/questions/39732460,5565980.0,1
902,70406637,Adam optimizer between Tf 1 and Tf 2,"I am trying to replicate the same result between Tf1 and Tf2. In below, there is a simple example using Adam optimizer. Here in TF2: x is: &lt;tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0.49998665, 1.4999859 , 2.4999857 ], dtype=float32)&gt; While in TF1: x is: [1. 2. 3.] Does anyone know what causes inconsistencies between Tf1 and Tf2 when using Adam Optimizer? I do not exclude the possibility of a wrong implementation. I would appreciate it a lot if anyone could tell me what I am doing wrong in TF1 that I cannot get the same result as in TF2. Many thanks!",https://stackoverflow.com/questions/70406637,13049909.0,1
903,46923947,Tensorflow: How to generate a random orthogonal matrix in data preprocessing pipeline using tensorflow.contrib.data module?,"I want to generate a random orthogonal matrix to randomly rotate my 3D point cloud data in the data preprocessing state. (I have found a numpy implementation How to create random orthonormal matrix in python numpy) As is suggested, I'm using TensorFlow's new Dataset API. 1.I have tried directly transferring the Numpy code into Tf code, I met the problem that TensorFlow does not allow slicing assignment (TF even does not allow assign for ordinary tensors). 2.I'm trying And got 3.I'm thinking of using placeholder for the random orthogonal matrix, but the dataset API uses map, so it's hard to pass a matrix in. I cannot realize where this error come from. Except hard-coding the Numpy implementation into a function generating 9 tf variables, and then stacking these variables into a 3*3 matrix, what else can I try? The code for my current API: class PointCloudDataGenerator(object):",https://stackoverflow.com/questions/46923947,7642379.0,1
904,43537083,TensorBoard - Plot loss from 2 networks trained simultaneously on the same graph,Is there a way to plot both training losses for two different networks being trained at the same time? At the moment I use two FileWriter and save the summaries to two different directories: And later in the code: But then when I fire TensorBoard I get two different graphs loss_class and loss_class_1. I've read at different places like here and there that creating two directories was the way to go. Am I missing something?,https://stackoverflow.com/questions/43537083,1281249.0,1
905,58311214,Input an integer with placeholder in tensorflow?,"I want to feed a batch_size integer as a placeholder in Tensorflow. But it does not act as an integer. Consider the following example: When I print the values of batch, mask0 and mask1 I have the following: Indeed I thought mask0 and mask1 must be the same, but it seems that Tensorflow does not treat batch_size_placeholder as an integer. I believe it would be a tensor, but is there anyway that I can use it as an integer in my computations? Is there anyway I can fix this problem? Just FYI, I used tf.one_hot as just an example, I want to run train/validation during training in my code where I will need a lot of other computations with different values for batch_size in training and in validation steps. Any help would be appreciated.",https://stackoverflow.com/questions/58311214,7179480.0,1
906,70123730,how can i build tensorflow model in specific shape?,I build a time-siries forcasting model but i can't understand how to handle this. which layer should i use to make this available?,https://stackoverflow.com/questions/70123730,17515932.0,1
907,45231880,An extra Invoke of kernel's Compute method,"Build a naive kernel like below. Run in python with: This prints ""Compute"" twice. If SetIsStateful is turned on, or if the int ""8"" is replaced with a placeholder, it is then only executed once. Is this intentional? Why is it necessary?",https://stackoverflow.com/questions/45231880,700535.0,1
908,53110171,GPU device mapping information in Tensorflow,"This could be a trivial question. The problem is, I only have 1 GPU device. To test if tensorflow is using GPU as the accelerator, like discussed in this question, I run: and similar to that answer, I have such device mapping information appeared twice: So what makes this happen?",https://stackoverflow.com/questions/53110171,4468490.0,1
909,52664110,AttributeError: 'Sequential' object has no attribute 'output_names',"I have got some problem for the below code of the following line new_model = load_model('124446.model', custom_objects=None, compile=True) Here is the code: Errors are: So can any one give me ant solution. Note: I use pycharm as IDE.",https://stackoverflow.com/questions/52664110,6859553.0,1
910,50371333,usage of tf.app.run() and argparse,"I have understood what a parser does, but I do not get its use when it is mingled with tf.app.run() in the following code: the main function in the program does not have any arguments as it is defined as def main(_). So what is the argv argument in tf.app.run() supposed to mean or do? Thanks",https://stackoverflow.com/questions/50371333,7415247.0,1
911,42390543,Enable XLA when using tf.contrib.learn.Estimator,"Seeing the TF Dev Summit talk on the potential (and highly experimental) benefits of turning on XLA on TensorFlow graphs, I thought I'd experiment with it a bit. Question: When using tf.contrib.learn.Estimator, how do I enable JIT XLA? I can flag certain ops for JIT XLA by However, the docs warn that this is meant just for testing. I'd like to be able to do this using the recommended way but I can't figure out a way of setting the tf.Session from outside the model_fn. This pseudo-code may clarify the problem better: tf.contrib.learn.RunConfig seemed like a good candidate but it doesn't have something for the session (which I guess makes sense, why would the RunConfig have a pointer to the existing session?) I could be overthinking this and tf.get_default_session could be all I need but can I modify the config of session after it's created?",https://stackoverflow.com/questions/42390543,281089.0,1
912,67510197,ValueError: No gradients provided for any variable error in tensorflow,"This is the error i'm getting: ValueError: No gradients provided for any variable: ['my_model/dense/w:0', 'my_model/dense/b:0', 'my_model/dense_1/w:0', 'my_model/dense_1/b:0']. I can't seem to find a solution for this error. I've looked on other similar errors but had no luck. Thanks in advance!",https://stackoverflow.com/questions/67510197,13781401.0,1
913,36568568,"Tensorflow doesn't allow for training data to be used in (features,targets) style?","I have data that is a ndarray containing features and targets with different dimensions respectively. This seems to give tensorflow problems. If I have a function: This results in ValueError: setting an array element with a sequence. It seems to be because feed_dict is not recognizing my inputs as numpy arrays. I think this is because features and targets have different dimensions and ndarray has problems with that; if I have data with 100 pairs then its shape is (100,2). If I then slice it: data[:,0].shape=(100,) and data[:,1].shape=(100,), so the length of the feature/target vectors is not recognized even after slicing. I've got around the problem by splitting data up beforehand into feats and targs, who's shapes are returned correctly. My question is, is this normal - is this supposed to be like this? Or am I just doing something wrong? It would be nicer to just work with data instead of passing two variables around all the time. edit: The dimensions of data should be self-explanatory.",https://stackoverflow.com/questions/36568568,4829166.0,1
914,40350539,TFSlim - problems loading saved checkpoint for VGG16,"(1) I'm trying to fine-tune a VGG-16 network using TFSlim by loading pretrained weights into all layers except thefc8 layer. I achieved this by using the TF-SLIm function as follows: This works fine as long as I do not change the num_classes for the VGG16 model. What I would like to do is to change the num_classes from 1000 to 200. I was under the impression that if I did this modification by defining a new vgg16-modified class that replaces the fc8 to produce 200 outputs, (along with a variables_to_restore = slim.get_variables_to_restore(exclude=['fc8']) that everything will be fine and dandy. However, tensorflow complains of a dimensions mismatch: So, how does one really go about doing this ? The documentation for TFSlim is really patchy and there are several versions scattered on Github - so not getting much help there.",https://stackoverflow.com/questions/40350539,1050648.0,1
915,40859416,Confusion about rank and shape in TensorFlow,"I am confused about rank and shape concept of TensorFlow. I have read the details from here and did run some code to clear my concept about them. But I am still confused and need help to understand. I thought x is like a 2d matrix where 2 is number of rows and 12 is number of columns. Then why I am getting shape for x[120, :] as (12, )? How even x[120, :] is possible with the given shape? Besides, since I thought x is a 2D tensor, its rank is also 2 because dimension and rank is the same thing for tensors (according to my understanding). But when I run: I am getting this error: It means my understanding is wrong about rank and dimension. What I am missing about rank and dimensions? Is rank and dimension two different things? How the rank of tensor x in the above example is 1? How can I set the rank of a tensor? Can anyone explain in details with some comprehensive examples?",https://stackoverflow.com/questions/40859416,5352399.0,1
916,73840190,Why is StringLookup from producing an extra label?,"From TF documentation: ""one_hot"": Encodes each individual element in the input into an array the same size as the vocabulary. As far as I understand it it should encode to a 26 shaped tensor. Why does it encode to a 27 shaped one? Should there be an extra label to represent ""no class""?",https://stackoverflow.com/questions/73840190,14742134.0,1
917,68381892,tf2onnx Tensorflow to Onnx inconsistent outputs,"I'm experimenting with creating a super simple Tensorflow network (one data processing Lambda layer), and then converting the model to ONNX and verifying the results match when calling the ONNX model from onnxruntime. I'm using Tensorflow v2.5.0. &amp; onnxruntime v1.8.1. Model definition: Then I can feed my example_input2 into the network: Which provides the desired output (simply a tf.roll operation): Great! Now I can save my tensorflow model, Then at the shell, I can convert it to an ONNX format using tf2onnx: Then, back in python, I can load the onnx model and try to feed through the same input: Which provides output that matches the input, and not the desired output (which should have been tf.roll'd by -1): I'm totally at a loss as to why the output here isn't matching when I call model.predict from within python on my original keras model. Any ideas?",https://stackoverflow.com/questions/68381892,1546011.0,1
918,59293247,How Do I Save Tensorflow Predictions To A File? (CSV Preferred),"This is my code. I have trained a model on housing price data from 2011-2018 and have attempted to predict housing prices for 2019. I want to save my prediction results to a .csv file. My goal is to create a simple webpage and display the predictions using Google Maps API, so I would need each individual result. However, not much resources exist for saving prediction results to a .csv file. How can I do so? Or What are some better ways to achieve my goal?",https://stackoverflow.com/questions/59293247,4301279.0,1
919,52983880,tf.case get unexpected results when use lambda,"Look this example. We expect m1, m2 is 0, 1 but we got 24. And the result of M_list is right, just like m1_ and m2_, it's strange. Although I have fixed this bug(see my answer), I still have a question, I don't know why this code will cause closure, case_set is not in any function, dose anyone know why this is closure?",https://stackoverflow.com/questions/52983880,9589731.0,1
920,47117498,Does `tf.data.Dataset.repeat()` buffer the entire dataset in memory?,Looking at this code example from the TF documentation: Does the dataset.repeat(num_epochs) require that the entire dataset be loaded into memory? Or is it re-initializing the dataset(s) that came before it when it receives an end-of-dataset exception? The documentation is ambiguous about this point.,https://stackoverflow.com/questions/47117498,4790871.0,1
921,69954835,Using GradientTape for A tf.keras Neural Network with dictionary input (composed from multiple models),"I need to take a derivative from a neural network implemented in Tensorflow/Keras 2.0 (super_model). This model has been composed of multiple basic models (x1 to x6) due to my previous issue explained in this post. (Thus, I will get an error if only passing angles to the model.) See the following code: Now, I need to take a derivative of the network based on the input data using GradientTape. I have tried the following and aim to get the gradient value of the network for the above-specified data: But, data is a dictionary and I cannot call tape.watch and then gradient. I cannot also call tf.convert_to_tesnor over data as it is a dictionary. So, my question is how I can continue the work without changing the structure of the super_model?",https://stackoverflow.com/questions/69954835,3768871.0,1
922,48878053,Tensorflow gradient with respect to matrix,"Just for context, I'm trying to implement a gradient descent algorithm with Tensorflow. I have a matrix X which I multiply by some feature vector Y to get Z I then put Z through a softmax function, and take the log. I'll refer to the output matrix as W. All this is implemented as follows (little bit of boilerplate added so it's runnable) W (corresponding to action_problogs) looks like I'd like to find the gradient of w1 with respect to the matrix X- that is, I'd like to calculate (preferably still looking like a matrix so I can add it to X, but I'm really not concerned about that) I was hoping that tf.gradients would do the trick. I calculated the ""gradient"" like so However, when I inspect problog_gradient, here's what I get Note that this has exactly the same shape as X, but that it really shouldn't. I was hoping to get a list of two gradients, each with respect to 8 elements. I suspect that I'm instead getting two gradients, but each with respect to four elements. I'm very new to tensorflow, so I'd appreciate and explanation of what's going on and how I might achieve the behavior I desire.",https://stackoverflow.com/questions/48878053,1543167.0,1
923,70171763,Making Class Activation Map (CAM) for EfficientNetB3 architecture,"I would like to draw a class activation map for a model built upon EfficeintNet B3. But when I follow different tutorials and codes from different sources, it simply fails.... Can't build a grad_model This is the model:",https://stackoverflow.com/questions/70171763,15365699.0,1
924,47750300,Tensorflow - Can't convert Operation to Tensor,I would like to compute the pairwise Euclidean distance between the output of an Operation and a Tensor. I'm using code suggested here. Here's the gist of my code: However I get the following error: For this line: How should I fix this?,https://stackoverflow.com/questions/47750300,4487030.0,1
925,65290855,Ragged Tensors of non-text data as input for LSTM,"I am learning about ragged tensors with applications for particle tracking. I have the following minimal example which reproduces a the error i keep experiencing. When i execute the above code i get the following error: The 10 refers to the number of units in the LSTM-layer, which is equal to the bounding shape of t1. The two 8's refer to batch_size and window_length. I thought that 1 refered to the output shape, but that is not the case, since it does not change when i add more units to the Dense-layer the number remains the same.",https://stackoverflow.com/questions/65290855,4658608.0,1
926,65725030,How can I manage Queues in Tensorflow 2.0?,"Well, I'm trying to understand the Threading and Queues. I saw many documents on the web, but surprisingly there is not even a single example of this topic in tensorflow 2.0. What I want my queues to do is to, What I have in mind is, I have no idea what I'm doing. I also learned that how to manage multiple threads using tf.train.Coordinator() but I don't know where to use this.. While asking this, I have a suspicion that many APIs in the tf.data.Dataset replace all of these and multiple threads can be replaced with the tf.data.experimental.AUTOTUNE. Sorry for all the mess here. I can't arrange this properly even during asking. Any comments will be appreciated. Thanks in advance.",https://stackoverflow.com/questions/65725030,7820717.0,1
927,47072498,Evaluation of tensorflow model with Opencv fails,I am using the following simple convolutional network: To train the network I use the Adam optimizer as follows: To save the network I use at the end: Training with TensorFlow yields good results but now I would like to use the network from OpenCV. I transform the network as follows: I am using then opt_graph.pb to load the model with cv::dnn::readNetFromTensorflow. Then I am testing on my training data and I get a 2% recognition rate. Can anyone help ? Is it possible that I did not save the weights properly in opt_graph.pb ? To me it seems like the training data has been lost.,https://stackoverflow.com/questions/47072498,1293937.0,1
928,55020305,how does OOP version of a custom tensorflow model work,"Hi guys i have a question from object oriented implementation of a tensorflow model that i see in CS231.n and this is the model: and this is the function that test it: my question is how does model is being called with the input x and scores is made, i mean this isn't pythonic way of calling an object function and it should be: or the call method should be a magic method call i mean:",https://stackoverflow.com/questions/55020305,8590342.0,1
929,41927426,Why do we need to explicitly update the moving_mean and moving_variance in TensorFlow's Batch normalization in tf.contrib.layers.batch_norm?,"To Long To Read: How can I use Batch Normalization with tf.contrib.layers.batch_norm without having to explicitly tell session to update the moving_statistics (moving_mean and moving_variance) or not? A few months ago I provided an answer to How could I use Batch Normalization in TensorFlow? and noticed a few weird details that I wanted to address. First it seems that the implementation that I provide seems repetitive with respect to the is_training variable. Recall my suggested code: in it I have a train_phase variable that just holds a tf boolean tf.placeholder(tf.bool, name='phase_train'). As you can see, it is used to decide if the batch norm layer should be in inference mode or not. However, the variable seemed a little redundant, since it seems I have two variables that specify the same thing twice. i.e. once in train_phase and another in is_training. Is that really necessary? I thought about it a bit and it seems I might to be able to remove the hard coded (is_training=True/False) with the (pseudo)code: which seems to make the train_phase variable completely redundant/silly. This actually highlights my most important point, is the train_phase variable and tf.cond(train_phase, lambda: bn_train, lambda: bn_inference) even necessary? Which actually brings up my biggest complaint about the code (though I think this code might not even run because when defining the graph the placeholder train_phase might not even have a value but you get the idea). Honestly I find having to even explicitly define train_phase very dangerous because it seems very unnecessary for users to have to handle the inference/training mode of Batch Norm this explicitly. Though, ""normal"" users of Batch Norm should always update the moving_mean,moving_variance with the train data and any standard user of Batch Norm should not be updating moving_mean,moving_variance with test statistics at any time. Since the user is required to do: it can bring cause really bad bugs for users that shouldn't even exist in the first place (at least in my opinion). Furthermore, it seems weird to have to explicitly say what the phase_train is because whenever one trains, one uses an optimizer, so it should be incredibly clear when that code is called that it should be true. Maybe this is a terrible idea but it feels like the optimizer or the session should be setting that to true automatically rather than relying on the user to do it right. I understand that sometimes users are allowed more flexibility to be more creative but I can't really appreciate how this (even for a researcher) be a good feature. Maybe I am just using the library incorrectly or being paranoic, but should the user really be forced to be so explicit when using batch norm? Is there some way around this? As a side point, having the phase_train be part of the model also makes the code be a bit more ugly and confusing than it feels necessary because it seems to me that its unavoidable to have a line of code where the session is being used to check if the batch norm flag is on or not. The code I am trying to avoid writing is the logic: it just feels totally unnecessary. It feels the during training the model should know if it should be updating the variables or not. As quick (really ugly) solution to the last problem with the if condition in the session, one can always define phase_train as part of the model (or at least as part of the graph) and accordingly set it equal to true and/or false when appropriate but when one doesn't actually use the batch norm layer, one actually does not use the phase_train placeholder in the model even if we set it have a value in the session.run. i.e. the sessions sets it to true or false, but when BN is not being used, it doesn't even matter what one sets it equal to since its not actually being used. Obviously, this makes the code really confusing (since one is defining some variable one doesn't even need), but I can't seem to find a way to hide the phase_train variable. For the moment this is what I am going for because it seems really ugly to have to split (or duplicate) my code between lines that have: and the ones that don't have it all: Ideally I want the second solution and have batch norm work regardless if I use the silly phase_train variable.",https://stackoverflow.com/questions/41927426,1601580.0,1
930,44492936,Graph transform gives error in Tensorflow,"I am using tensorflow 1.1 version. I want to quantize inception_resnet_v2 model. The quantization method using this doesn't give accurate results. For inception_v3 the results are okay but for inception_resnet_v2 it doesn't work (0% accuracy for the predicted class labels). I got to know that I can rather use graph_transform in my case to quantise. Like described in https://github.com/tensorflow/tensorflow/issues/9301#issuecomment-307351419. using However, I get error ""ValueError: No op named QuantizedAdd in defined operations"" now when tf.import_graph_def(graph_def, name='') is called. I checked similar issues and solution to the same. However, it is not helping in my case, I still get error. Here are the links to similar issues. Error with 8-bit Quantization in Tensorflow Install Tensorflow with Quantization Support In my case _quantized_ops.so and kernels/_quantized_kernels.so are not created after doing bazel build for quantize_graph. any inputs to resolve this issue?",https://stackoverflow.com/questions/44492936,6887131.0,1
931,63696005,Simple way to evaluate input with a TensorFlow model?,"Here I have a boosted decision tree being trained with generated data, and saved as est: I would like to use the model to make a prediction based on a row of training data for testing purposes; something like this: res = est.predict(trainX.loc[0]), however, I'm having a tough time figuring out how to go about it.",https://stackoverflow.com/questions/63696005,10818367.0,1
932,49416931,What does the tensorflow.python.eager.tape do in the implementation of tf.contrib.eager.custom_gradient?,"I am going through TensorFlow Eager Execution from here and find it difficult to understand the customizing gradients part. First, it is difficult to make sense what does dy do in the gradient function. When I read the implementation of tf.contrib.eager.custom_gradient. I can't really make sense the working mechanism behind tape. Following is the code I borrow from the implementation of tf.contrib.eager.custom_gradient. Can anybody explain what does tape do here? Even though I found the implementation of tape from here. But I can't really get much out of it due the poor documentation.",https://stackoverflow.com/questions/49416931,3744927.0,1
933,64933711,"ValueError: Input 0 of layer sequential_33 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [64, 100]","I am following this guide to learn to build a Simple RNN. Different to the guide I just want my model to predict the next int in a ascending sequence (e.g. x = [1,2,3] y = [2,3,4]) But when attempting to train my model I receive this error message: Like in the guide my dataset has shape: A little different form the guide my Model is defined as with the summary beeing: Could you help me understand why I get this error, and how to fix it? I have made sure that the dataset has the same dimensions as in the guide, and provided the Input layer with the ""batch_input_shape= (BATCH_SIZE,100,1)"" because I learned that LSTMs need at least 3D data with shape [batch_size, timesteps, features]. So I am a confused where I'm still incorrect. Any help yould be appreciated!",https://stackoverflow.com/questions/64933711,12408945.0,1
934,69361779,Implimenting CTC loss keras,"Considering the fact that you have a basic model similar to this: How would you implement CTC loss? I tried something from the keras code tutorial on OCR like this: However when it came to the model.fit part it started to fall apart due to me not knowing how to feed the model the ""label"" input layer thing. I think that the approach in the tutorial is quite unambiguous so what would be a better and more efficient way to do implement the CTC loss?",https://stackoverflow.com/questions/69361779,12504573.0,1
935,67676763,How to read an array (list of dictionaries) into Python Tensorflow?,"As a result of dealing with a gigantic dataset that takes up too much memory, I need to tap into Tensorflow's generator functions (e.g. map, apply) I have the following array that I'd like to load into Tensorflow: From reading the documentation, I've tried the following: However it returns the following error: I've also tried the following based on this documentation that generates the same error: I've also tried this as well, which generates a different error: Error:",https://stackoverflow.com/questions/67676763,2850808.0,1
936,45437680,How to assign values in a TensorFlow while_loop,"The goal is to implement a recurrent function in TensorFlow to filter a signal over time. The input is later presented as a 5-D tensor of form [batch, in_depth, in_height, in_width, in_channels]. I want to use tf.while_loop to iterate over in_depth and reassign values depended on values of previous time steps. However, I fail to reassign variable values within the loop. In order to simplify the problem, I have create a 1-D version of the problem: tf.assign returns an operation, which has to be run in a session in order to be evaluated (see here for further details). I expected, that TensorFlow would chain the operations within the loop and hence execute the assignments once I run a session and request signal. However, when I execute the given code and print the result, signal contatins [1.2, 0, 0, 0] and i contains (as expected) 4. What is my misconception here and how can I change the code such that the values of signal are reassigned?",https://stackoverflow.com/questions/45437680,2393597.0,1
937,56133254,UnboundLocalError when fitting neural network - TensorFlow bug?,"Consider the following ""hello world"" of neural networks: Calling the fit method leads to the exception below. Versions: I installed keras and tensorflow freshly with Anaconda: The following warnings seem suspicious, but a solution is not clear: On module import: On compile: Somewhere in stdout: Error message:",https://stackoverflow.com/questions/56133254,626537.0,1
938,42542893,Using tf.py_func() as a reader on queues gives out of range errors,"I am trying to create an input pipeline using tf.py_func() as a reader on queues. My data is distributed as following: I have a file that contains paths to these data files in the following format: I am creating three queues out of them, and then using readers and decoders to parse the elements in queues. Since tensorflow has defined readers like tf.read_file() and decoders such as tf.image.decode_jpeg() and tf.image.decode_png() for jpg and png formats but none for npz format, so I am using a python wrapper to parse the queue for activations files (third column in the file above): Now, if I try to construct a wrapper using tf.py_func() around the python function above and use it to as a reader, I ran into out of range errors: Following is the invocation of different readers and decoders on input queues: And ImageReader is defined as: When I try to call ImageReader.dequeue(1), I ran into out of range error. I think I am not correctly using the python wrapper in this setting. Any suggestions? Below is a sample code to reproduce the problem: where 'list.txt' simply consists of names of 'x' number of files and './data' contains those files. For simplicity I used 'txt' files.",https://stackoverflow.com/questions/42542893,7643851.0,1
939,59767073,Python 3.5 - AttributeError: module 'tensorflow' has no attribute 'contrib',"I have the following function: But when I run it, I get this exception: I tried using tensorflow 1.x but it didn't dix anything. What is the replacement to contrib?",https://stackoverflow.com/questions/59767073,12632377.0,1
940,51383415,How to use an array as an input of a dense layer,"I'm coding a neural network with python and Keras. I would want to add a dense layer to my network. After this dense layer, I will use some transposed convolutions, so I need to reshape my initial inputs like this: When I want to use this input in the dense layer, following the example given in the documentation, there is the following error: Here is my code: And the full returned error message: Thank you for your help",https://stackoverflow.com/questions/51383415,9529736.0,1
941,70381437,How to freeze a keras model in TensorFlow 2.0? (specifically freeze a saved model format to .pb format),"Can any one please explain the procedure to freeze a keras model (saved model format) into .pb format in TensorFlow 2? Created a sample mobilenet keras model and saved it to the disk in saved model format Then in another file, I need to load the model and freeze it to a .pb format",https://stackoverflow.com/questions/70381437,7317039.0,1
942,75185375,How to prepare PIL Image.Image for tf.image.decode_image,"For a file read with: I keep getting error for this line tf.image.decode_image(read_image): How can I pass imae read with PIL to tensorflow so that I could decode and resize, so that I could resize this big picture to 32x32x3?",https://stackoverflow.com/questions/75185375,5684405.0,1
943,74142147,"tensorflow meet a warning ""Gradients do not exist for variables""","sorry I'm a beginner to tensorflow, when I tried to write a custom layer there was a warning 'Gradients do not exist for variables' after call model.fit() To illastrate my issues, here are my code: Can someone tell me why the gradients do not exist and how to solve this problem, please.",https://stackoverflow.com/questions/74142147,20292826.0,1
944,55915167,Swap gnews with ELMo in the simple colab tutorial,"I'm working on this colab notebook: https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_text_classification.ipynb I'd like to replace the gnews swivel embeddings with the ELMo embeddings. So, replace with: There is a cascade of things that change here, such as needing But I'm not understanding the graph shape I need to do this replacement successfully. Specifically, I'm seeing. Produces This seems fine. But: Then this gives: What else is changing about the graph dimensions and how do I fix it?",https://stackoverflow.com/questions/55915167,1052117.0,1
945,44217076,tf.extract_image_patches for 3D images,"The documentation of tf.extract_image_patches It is only for 2D image, could it be expand to 3D images, which is useful for the implementation for SSIM loss function? I cannot find the source code. There is a similar function skimage.util.view_as_windows, however, when I try to use this function with the tensorflow as backend in keras, there are errors. The transition from numpy array to tensor confused me a lot.",https://stackoverflow.com/questions/44217076,7845074.0,1
946,62035590,Tensorflow: tf.strings.split(),"I'm new to Python and AI. I'm trying to do a hello world AI. But I have a question regarding the code. The path is ""C:\ABC\AAC\data\as001.jpg"" || ""C:\ABC\AAC\data\wb001.jpg"" I'm trying to understand why Print #1 prints Tensor(""strided_slice:0"", shape=(), dtype=string) but Print #2 prints the actual value tf.Tensor(b'as001.jpg', shape=(), dtype=string) Also, I'm trying to map the values (wb0 to 0 and as0 to 1) in process function but I can't seem to extract the value from part[-1]. What am I doing wrong? Any help is appreciated.",https://stackoverflow.com/questions/62035590,7575440.0,1
947,74876117,BERT embeddings in LSTM model error in fit function,"I am novice in TensorFlow I am traying to use BERT embeddings in LSTM model this is my model function I recieved this error in fit function when I tried to input data ""ValueError: Layer ""model_1"" expects 2 input(s), but it received 1 input tensors. Inputs received: [&lt;tf.Tensor 'IteratorGetNext:0' shape=(None, 512) dtype=int32&gt;]"" also,I received these warning massages I do not know what is means. WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU. WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU. can someone help me, thanks in advance.",https://stackoverflow.com/questions/74876117,18900893.0,1
948,48161987,change data and get very wired output (simple linear regression),"this is a very simple sample, it is like homework something. code is below: this output is: 0 [1.2522789, 2.0945494] 40 [5.304193, 2.5357442] 80 [7.116992, 1.5568293] 120 [8.229965, 0.95582175] 160 [8.913281, 0.58682966] 200 [9.332804, 0.36028674] 240 [9.590374, 0.22119847] 280 [9.748508, 0.13580598] 320 [9.845596, 0.083378375] 360 [9.905204, 0.0511902] it is pretty good. then i changed data this way: then output is 0 [327576.72, 640.39246] 40 [nan, nan] 80 [nan, nan] 120 [nan, nan] 160 [nan, nan] 200 [nan, nan] 240 [nan, nan] 280 [nan, nan] 320 [nan, nan] 360 [nan, nan] anyone can tell me why the second output is this?",https://stackoverflow.com/questions/48161987,5937236.0,1
949,44710487,Run distributed tensor flow using Keras with fit_generator,"Is there a way to run a Keras model based on model.fit_generator() on several machines? I defined my model using so I have no lower-level access to my tf.Variables and cannot use or as explained in Google's distributed tensor flow tutorial. I found a way to do it using Keras + Spark, but is it a simpler way?",https://stackoverflow.com/questions/44710487,6255101.0,1
950,54764500,How to create end execute a basic LSTM network in TensorFlow?,"I want to create a basic LSTM network that accept sequences of 5 dimensional vectors (for example as a N x 5 arrays) and returns the corresponding sequences of 4 dimensional hidden- and cell-vectors (N x 4 arrays), where N is the number of time steps. How can I do it TensorFlow? ADDED So, far I got the following code working: However, there are many open questions:",https://stackoverflow.com/questions/54764500,245549.0,1
951,57449318,Implementing batch normalization in tensorflow where the graph is run multiple times before updating batch norm moving averages,I have a feed forward network with batch normalization layers in it. the network has to be run multiple times before one backpropogation can be applied. It is used to compute: a. vanilla logits (vl) b. logits with noisy inputs (nl) difference between vl and nl is also part of the cost function I cant understand how and when to run tf.GraphKeys.UPDATE_OPS. If i run it typically by grouping it with optimizer i think the moving averages will be updated with mean and standard deviation of noisy batches since that is the last run of the network but i need the updates based on vanilla (no noise) run of the network. I can't change the order of different runs of the network as noise is computed using the output of vanilla run of the network,https://stackoverflow.com/questions/57449318,6546694.0,1
952,55805576,Tensorflow reports 'TypeError: List of Tensors when single Tensor expected' when using tf.cond(),"I am using Tensorflow to code a model. Part of my conditional statement like: and src_shape is the result of tf.shape(). It reports TypeError: List of Tensors when single Tensor expected. I know it is because tf.constant([1, src_shape[0]]) is a list of tensors, but I don't know how to implement my code in a legal way. I have try to remove tf.constant() like but it reports ValueError: Incompatible return values of true_fn and false_fn: The two structures don't have the same nested structure.",https://stackoverflow.com/questions/55805576,6187009.0,1
953,42329059,How is tf.summary.tensor_summary meant to be used?,TensorFlow provides a tf.summary.tensor_summary() function that appears to be a multidimensional variant of tf.summary.scalar(): I thought it could be useful for summarizing inferred probabilities per class ... somewhat like However it appears that TensorBoard doesn't provide a way to display these summaries at all. How are they meant to be used?,https://stackoverflow.com/questions/42329059,195651.0,1
954,60180766,Custom training loss with custom gradients,"I am trying to write a custom loss in Tensorflow v2, for simplicity let's say that I'm using Mean Squared Error loss as follows, Now I know that Tensorflow does automatic differentiation. But I want to specify my custom gradient, in the BackPropagation algorithm, if we use MSE, we have to do the following Is it possible in Keras to replace with where p is a tensor that is passed during training before applying gradients.",https://stackoverflow.com/questions/60180766,11309609.0,1
955,46658297,The matrix obtained by tf.concat () is not the same as before the merge,"Display is Should not be the beginning of the merged matrix X, the first matrix x1 is the same? Why is X different from x1, X2, X3?",https://stackoverflow.com/questions/46658297,8749184.0,1
956,48335501,How to know correct learning rate for GradientDescentOptimizer in Tensorflow?,"I am confused on learning rate of Gradient Descent Optimizer in Tensorflow, So suppose i am trying to predict next value from this data : If i choose learning rate as 0.01 , Here is my program : Then i am getting this output and its going in inf (that's my second confusion why its going into infinity ?) But if i choose learning rate as 0.001 then i am gettin correct output : Again if i choose learning rate 0.0001 then i am not getting correct output: So my question is , How i am going to know which learning rate is best for my equation and for my prediction ? How i am going to choose right learning rate ? Thank you in advance.",https://stackoverflow.com/questions/48335501,9177763.0,1
957,53704764,Shape equals (),I am reading the tests in the TensorFlow MNIST official model. Line 49 has: and selected lines leading up to it are: but the TensorFlow documentation suggests that a shape is an array of numbers: These two statements that print the shape of the object don't help much: What is the meaning of a () shape?,https://stackoverflow.com/questions/53704764,9251158.0,1
958,52742586,tf.layers.dense underperforms low-level api?,"I've built a simple NN using TF that supposes to learn a quadratic equation. Surprisingly, tf.layers.dense underperforms actually writing the NN myself, but I can't seem to understand why. I would very much appreciate it someone can point to what it is I'm missing - here's the code: Data generation Output: Low level API: Output: Using tf.layers.dense: Output:",https://stackoverflow.com/questions/52742586,5863503.0,1
959,65421447,Weird results with if-else in a tf.data.map,"Why does the else block run when the below script is executed in TF.2.3.1? Expect to print but see Created a collab https://colab.research.google.com/drive/1ZgLF0ytiRJ4_VwfMMpVRP1TVkV-cFdDc?usp=sharing works but I am trying to know why in graph mode, the if-else approach doesn't work as expected",https://stackoverflow.com/questions/65421447,1585523.0,1
960,70699795,"Building the output layer of NLP model (is the ""embedding"" layer)","I was looking through some notebooks in Kaggle just to get a deeper understanding of how NLP works. I came across a notebook for the natural language inference task of predicting the relationship between a given premise and hypothesis. It uses the pretrained BERT model for this task I had a question about the build_model() function: I am confused about this line: embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0] What does this ""embedding"" represent and why is there a [0] infront of the function call? Why is the bert_encoder used to instantiate this ""embedding""? Thanks in advance!",https://stackoverflow.com/questions/70699795,16533111.0,1
961,54937280,Writing custom optimizers questions,apologies beforehand if these are basic questions - I've done some digging around and can't find straightforward answers. If there are links to any resources that can help that would be great too! I'm currently looking at the below piece of code for a class that implements optimizer.optimizer. I'm having trouble understanding the following things:,https://stackoverflow.com/questions/54937280,11133843.0,1
962,50899488,"Tensorflow python: reshape input [batchsize] to tensor [batchsize, 2] with specific order","I have a tensor (shape=[batchsize]). I want to reshape the tensor in a specific order and into shape=[-1,2]. But I want to have: Here is an example code with a tensor range=(0 to input=8). Now my output is: But I want the output to be: Keep in mind I do not know how big batchsize is, I just set input= 8 for exemplary reason. Furthermore here I want to break the order after every 2nd element. In future I also would like to have this flexible. And in my real code the tensor ´x´ is no range array but complex random numbers, so you cannot sort in any way w.r.t. the values. I just made this code for a demonstration purpose.",https://stackoverflow.com/questions/50899488,9948048.0,1
963,44241670,Batch input to a certain layer in tensorflow,"I'm working on a network based on inception-v3 .I train the network successfully, and now I want to feed a batch of opencv images to my network and get some output. The original placeholder of the network accepts a string and decodes it a jpg (this image) But I read the video frames with opencv and convert them in a list of nparray : If I want to work with a single images, beacuse i read frames directly from opencv, I convert them to np-array and then feed it to ""Cast:0"" layer of the inception network: Results are OK to this point. But I want to feed a batch of frames: I tried to use feed_dict in the current way: but i got errors; I know i have a mistake in feeding the batch. do you have any suggestion how i can feed a batch of images to a certain layer of a network ?",https://stackoverflow.com/questions/44241670,6349023.0,1
964,58803868,Set .trainable variable in GAN implementation in tf.keras properly,"I am confused with the .trainable statement of tf.keras.model in the implementation of a GAN. Given following code snipped (taken from this repo): during the definition of the model self.combined the weights of the discriminator are set to self.discriminator.trainable = False but never turned back on. Still, during the training loop the weights of the discriminator will change for the lines: and will stay constant during: which I wouldn't expect. Of course this the correct (iterative) way to train a GAN, but I don't understand why we don't have to pass self.discriminator.trainable = True before we can do some training on the discriminator. Would be nice If someone has a explanation for that, I guess that is a crucial point to understand.",https://stackoverflow.com/questions/58803868,7784503.0,1
965,69899618,"Combining gradients from different ""networks"" in TensorFlow2","I'm trying to combine a few ""networks"" into one final loss function. I'm wondering if what I'm doing is ""legal"", as of now I can't seem to make this work. I'm using tensorflow probability : The main problem is here: Which gives me None gradients and throws on apply gradients: Full code:",https://stackoverflow.com/questions/69899618,6296435.0,1
966,63689286,How to assign values to a tensor by index?,"I have a 2D tensor, the shape is (M,N). And I want to get a mask that for each row, the top-k of the given tensor is 1, and others as 0. For example, the tensor is: If set the topk as 1, the mask should be: If set the topk as 2, the mask should be: I figure out a very tedious method: This operation is heavily memory consumption, I think there is a concise way to do this, can anybody help me?",https://stackoverflow.com/questions/63689286,14202852.0,1
967,61806873,Different results when using Manual KFold-Cross validation vs. KerasClassifier-KFold Cross Validation,"I've been struggling to understand why two similar Kfold-cross validations result in two different averages. When I use a manual KFold approach (with Tensorflow and Keras) I get When I use the KerasClassifier wrapper from scikit I get Additionally, when using KerasClassifier the following warning appears Do the results differ because KerasClassifier uses predict_classes() while the manual Tensorflow/Keras approach uses just predict()? If so, which approach is more reasonable? My model looks like this",https://stackoverflow.com/questions/61806873,13469181.0,1
968,55988347,The metric function returned error result: tf.keras.metrics.Accuracy(),"I'm training my model using Keras, here is my code: My y_test has 0:85%; 1:15%, It's output: But when I checked it using:predictions = model.predict(x_test.values, verbose=1), it predicted nearly all cases to 0. So, in my opinion the ['accuracy'] could be 85% instead of ""acc: 1.0000"". What's going wrong ?",https://stackoverflow.com/questions/55988347,11089153.0,1
969,42454973,Tensorflow: Slice Input image and grayscale,"I am new to Tensorflow and am trying to slice an image to then grayscale it. My code so far looks like this. I am first taking the input, then extract image data into a tensor, then slice the middle part of the image. The weights etc. can be disregarded for this step, just wanted to give the reader context: Whenever I run this, however, I get an error stating: I have read the documentation on slicing and resizing, but I am still confused. As said, I'm new to tensorflow, would be grateful for any help :) I tried commenting out to debug, but I'm not even sure if that caused the problems. I am always getting the above error.",https://stackoverflow.com/questions/42454973,3262787.0,1
970,67368816,@tf.function( input_signature ) on an object's method defined outside of a class scope,"Say I have a Custom Layer : if I want to decorate @tf.function(with input_signature) to A_Method to control tracing what spec should i put for self ? I tried putting tf.TensorSpec but it raised an error ___Updated the question___ : Im quite new to tensorflow sorry if the code is weird or doesnt make sense. the reason I do this is I found RNN took a long time for first epoch to get started, I dont know if this custom layer can do something alike but is taking less time. but ultimately I believe the slow initialize time is because of tensorflow retracing repeatedly even on same input_spec - input_shape. I use this layer repeatedly as, then I ran .experimental_get_tracing_count() count is 300 which really shouldn't be above 10, thats why I wanted to take this method out def Mimic_RNN(self, step_input, step_state) remove it from the class and try giving it an input_signature. Please see below :",https://stackoverflow.com/questions/67368816,15550096.0,1
971,47169336,Tensorflow: How to have saver.save() and .restore() in one module?,"I have a module called neural.py I initialize the variables in the body. I save the checkpoint in a function train() after training: I want to also restore and run the network after training in the run() function of this module: It just doesn't work. It gives me either NotFoundError (see above for traceback): Key beta2_power not found in checkpoint or ValueError: No variables to save if I add tf.reset_default_graph() under run(), as commented above. However, if I put the exact same code for run() in a new module without train() and with tf.reset_default_graph() at the top, it works perfectly. How do I make it work in the same module? Final snippet:",https://stackoverflow.com/questions/47169336,5919010.0,1
972,47752258,"What is the relationship among batch-size, sequence-length and hidden_size?","When reading the API document of dynamic_rnn, I have the following question: Are there constraints on the relationship among batch-size, sequence-length and (cell)hidden_size? I am thinking that: sequence-length &lt;= (cell)hidden_size, or, batch-size * sequence-length &lt;= (cell)hidden_size Am I correct? I have been reading through a lot of web pages but couldn't find an answer. Thanks all. https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn Example:",https://stackoverflow.com/questions/47752258,9083471.0,1
973,65240446,ValueError: Negative dimension size caused by subtracting 2 from 1 for in neural network using tensorflow,"I am trying to write a model to classify the handwritten digits from the mnist dataset. I am currently using a model that looks like this: Its supposed to be a convolutional deep neural network with 5 layers and I keep getting this error message on the last line of the model. I don't understand the error or how to fix it. Can someone please help me? I already set the padding to ""same"" but it didn't fix it. I am also using google colab if that helps.",https://stackoverflow.com/questions/65240446,13638224.0,1
974,38312668,How does one do Inference with Batch Normalization with Tensor Flow?,"I was reading the original paper on BN and the stack overflow question on How could I use Batch Normalization in TensorFlow? which provides a very useful piece of code to insert a batch normalization block to a Neural Network but does not provides enough guidance on how to actually use it during training, inference and when evaluating models. For example, I would like to track the train error during training and test error to make sure I don't overfit. Its clear that the batch normalization block should be off during test, but when evaluating the error on the training set, should the batch normalization block be turned off too? My main questions are: To make it very clear, I will provide an extract (of simplified) code I have been using to run batch normalization with Tensor flow according to what is my understanding of what is the right thing to do: and the code I am using to produce batch normalization blocks is:",https://stackoverflow.com/questions/38312668,1601580.0,1
975,64358575,What do the dimensions mean while using images in CNNs?,"Please go through the code below. Image size is (32, 256 , 256 , 6). I don't think it is necessary to know what net is and what it does. My question is purely analytical. The dimension of net turns out to be (32, 248, 248, 3) according to me. But apparently according to the paper it should be (32, 256, 256, 3). Ques1) Where did I go wrong? Ques2) In slim.conv2d what exactly is 64 and [5,5]? I think they are the number of filters and 5*5 is the dimension of the kernel. But since I am getting the wrong dimensions am I wrong here too? Ques3) When you say (32,256,256,3) does it mean that there are 32 samples, 256*256 is the pixel strength and 3 are the number of channels? Ques4) I know this might be difficult to answer but could someone tell me what is the need to first decrease the dimensions and then increase them again? A link to the concept shall be much appreciated.",https://stackoverflow.com/questions/64358575,10754202.0,1
976,62340722,Tensorflow: train multiple models in parallel with the same ImageDataGenerator,"I'm doing HPO on a small custom CNN. During training the GPU is under-utilised and I'm finding a bottleneck in the CPU: the data augmentation process is too slow. Looking online, I found that I could use multiple CPU cores for the generator and speedup the process. I set up workers=n_cores and this did improve things, but not as much as I'd like. So I though that I could train multiple models simultaneously on the GPU, and feed the same augmented data to the models. However, I can't come up with some idea on how to do this and I couldn't find any similar question. Here's a minimal example (I'm leaving out imports for brevity):",https://stackoverflow.com/questions/62340722,13732802.0,1
977,74989725,tensorflow sparse dense layer,"I want to create a custom dense layer in tf.keras, which works with sparse weight matrices. My weight matrices are zero almost everywhere, and I know the sparsity pattern. It would be a huge cost saving. How would I incorporate sparse matrices into a custom Dense layer? Could someone point me to a reference? I could not find this functionality in tf. Edit: the layer should be trainable.",https://stackoverflow.com/questions/74989725,13560598.0,1
978,37221092,Higher Order Functions in TensorFlow - How to use?,"the new higher order functions within TF is detailed here: https://www.tensorflow.org/versions/r0.8/api_docs/python/functional_ops.html#map_fn In particular, the map function looks useful. Here is what they wrote for the tutorial: Thus I created an empty python file: Running this gives this error: Does anyone know what's going on? Thanks! Edit: I'm using TensorFlow version 0.8.",https://stackoverflow.com/questions/37221092,4873739.0,1
979,66654938,Tensorflow pruned model is the same size as original baseline model,"I have a baseline TF functional model that I want to prune. I have tried following the code in the documentation, but the size the compressed pruned model is the same size as the compressed baseline model. (https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide#export_model_with_size_compression) I don't believe there is anything wrong with my code, so why does this occur? Output: EDIT: I also tried this with the same model as in the documentation, and the pruned model is still the same size as the baseline: Output:",https://stackoverflow.com/questions/66654938,14565727.0,1
980,55896529,"TensorFlow, how to distinguish this vector operation?","I defined the following code below, Why v[:, None] - v[None, :] outputs a 5x5 matrix? v[:, None] - v[None, :] and v[None, :] - v[:, None] are different, how to figure out their differences? It really confused me and I am not sure its output given these two expressions.",https://stackoverflow.com/questions/55896529,5046896.0,1
981,48239019,Shape must be rank 1 but is rank 0 for 'CTCLoss' (op: 'CTCLoss'),"I've successfully converted a Tensor into a SparseTensor with this code: I want to try out using a SparseTensor converted from a dense one: Unfortunately, when I do this, I encounter this error: How do I fix this error?",https://stackoverflow.com/questions/48239019,8023137.0,1
982,40091310,Cannot debug tensorflow using gdb on macOS,I am trying to debug TensorFlow using GDB on macOS Sierra. I followed the instructions on the post.After I installed developer version of tensorflow for debug I tried to use gdb to attach a python session. When I run gdb -p &lt;pid&gt;: When I set the breakpoint: Then even I run sess = tf.Session() as the post says. GDB will never enter into breakpoint.,https://stackoverflow.com/questions/40091310,4093741.0,1
983,48904963,Tensorflow Extracting Classification Predictions,"I've a tensorflow NN model for classification of one-hot-encoded group labels (groups are exclusive), which ends with (layerActivs[-1] are the activations of the final layer): The tf.round is included to force any low probabilities to 0. If all probabilities are below 50% for an observation, this means that no class will be predicted. I.e., if there are 4 classes, we could have probs[0,:] = [0.2,0,0,0.4], so classes[0,:] = [0,0,0,0]; preds[0] = 0 follows. Obviously this is ambiguous, as it is the same result that would occur if we had probs[1,:]=[.9,0,.1,0] -&gt; classes[1,:] = [1,0,0,0] -&gt; 1 preds[1] = 0. This is a problem when using the tensorflow builtin metrics class, as the functions can't distinguish between no prediction, and prediction in class 0. This is demonstrated by this code: which has the output: I experimented with setting a value of preds to np.nan for observations with no predictions, but tf.metrics.accuracy throws ValueError: cannot convert float NaN to integer; also tried np.inf but got OverflowError: cannot convert float infinity to integer. How can I convert the rounded probabilities to class predictions, but appropriately handle unpredicted observations?",https://stackoverflow.com/questions/48904963,1686236.0,1
984,47277171,Implementing LSTM regression model with tensor flow,"I am trying to implement a tensor flow LSTM regression model for a list of inputs number. example: The code is below: But i am not able to minimize the cost, the calculated MSE increases at each step instead of decreasing. I suspect there is a problem with the cost problem that i am using. any thoughts or suggestions as to what i am doing wrong ? Thanks",https://stackoverflow.com/questions/47277171,6477201.0,1
985,37374548,tf.cond not behaving as expected,"I have a question related to how tensorflow evaluates expressions in a tf.cond statement. I use a custom operation that gives me batches of data of either type A or type B. Its signature looks like that The type output is 1 for type A and 2 for type B. Depending on the type, I want to run a different (custom) operation, say opA or opB. Of course, their output has the same type. To express this data flow, I use tf.cond as in: I added some debug statements to getData, opA and opB. For a data sequence ABA I hope to get However, I do get Is this the expected behaviour? The result of the joined_op does correctly take the if-else into account but still, both operations are always computed. This is not only a computational burden but also defeats the purpose if opA and opA perform actions that affect variables (such as an optimization step). CORRECT SOLUTION as pointed out by @Yaroslav For a more detailed example, please see the dummy implementation of the three operations below:",https://stackoverflow.com/questions/37374548,5188903.0,1
986,55739840,Accessing and working with placeholders in tensorflow,"I'm very new to tensorflow. Currently, I have a neural network set up to solve an ODE (though the application isn't important). The code looks something like this I use a batch stochastic gradient descent to train the network like this: The get_batch function is defined as follows: However, I am trying to do something quite complicated with my cost function now. In each batch returned by get_batch, I need to sample from an arbitrary number of subdomains, so let's say returnX is partitioned into N parts that will correspond to different parts of my cost function. In particular, I want to do something like this I know that accessing a placeholder the way I have above makes no sense as placeholders are just that -- placeholders. But I hope the idea of what I'm trying to do is clear. The batch data returns a batch in partitions, and each of these partitions needs to be used in a different way to compute the cost function. So in forming my cost function, how can I access these different partitions given that they are just placeholders? Edit: I've attached the full code below.",https://stackoverflow.com/questions/55739840,1799323.0,1
987,53357706,How to update weights with TensorFlow Eager Execution?,"So I tried TensorFlow's eager execution and my implementation of it wasn't successful. I used gradient.tape, and while the program runs, there is no visible update in any of the weights. I've seen some sample algorithms and tutorials using optimizer.apply_gradients() in order to update all variables, but I'm assuming I'm not using it properly.",https://stackoverflow.com/questions/53357706,5204470.0,1
988,57154569,shape of output tensor by keras.losses.binary_crossentropy,"I want to implement a custom loss function in keras based on binary_crossEntropy. I have question about shape of output tnesor of Keras.losses.binary_crossentropy. I expect that it should be a 1D tensor with length of batch_size. but it returns a tensor with shape of [batch size, classes] with identical loss amount in each row for all classes. should i manually use max along rows? is there a better way? and why the output of K.binary_crossentropy is not 1d tensor? is it related to math concepts?",https://stackoverflow.com/questions/57154569,5291224.0,1
989,54521572,How to transform keras model to tpu model,"I am trying to transform my Keras model in the Google cloud console into a TPU model. Unfortunatelly I am getting an error as shown below. My minimal example is the following: My output is: The keras_to_tpu_model method seems experimental as indicated on the tensorflow website. Has it recently been removed? If so, how can I proceed to make use of TPUs to estimate my Keras model? If the keras_to_tpu_model method would be still available, why can I not invoke it?",https://stackoverflow.com/questions/54521572,6493472.0,1
990,49687358,Tensorflow neural network is always 50% sure after training,"I have just followed a tutorial on neural networks, and I tried to put my knowledge to the test. I made a simple XOR logic learning network but for some reason it always returns 0.5 (50% sure). Here is my code: Sorry if this is a bad question, I am new to machine learning.",https://stackoverflow.com/questions/49687358,6166724.0,1
991,47807919,Tensorflow You must feed a value for placeholder tensor 'p' with dtype float,"I was using mnist data to see how tf.train.shuffle_batch works, and I got this error But I did feed a value with dtype float to the 'p' placeholder, so I don't get why I'm getting this error Here's my code:",https://stackoverflow.com/questions/47807919,9097530.0,1
992,60485386,How to slice using Keras Lambda Layer?,"I am trying to create sentence vectors for a text classification model by extracting the word with the largest norm (using that word to represent the sentence). Below is part of my Keras code: However, the following error is produced: Which I do not understand why this is so. Can someone please explain this to me? It would be better if there is a solution using a Keras approach that does not directly involve Tensorflow.",https://stackoverflow.com/questions/60485386,12545857.0,1
993,47735825,Evaluate a condition on each element of a vector y in tensorflow,"I am trying to evaluate a condition on each element of a vector y so that I get a vector whose i’th element tells me whether y[i]satisfies the condition. Is there any way to do this without using loops? So far, I have tried the following: For a given input x, I want delta[i] to be 1 if y[i] = x[0] and 0 otherwise. I get error I am new to TensorFlow, any help would be appreciated!",https://stackoverflow.com/questions/47735825,9059299.0,1
994,58199862,Error porting Tensorflow Keras model to Tensorflow Version 1.14.0,I recently programmed a small NN to play Tic Tac Toe against me. It really was my first NN I wrote by myself. Today I wanted to show it to a friend via Google Collab and I got this Error: I never got this error before. I think it has to do with Google Collag using Version 1.14.0 and me using Version 1.13.1 Here's my code: Trainingdata looks like this: (of course just one data block =D) Thanks for the help in advance -nailuj05,https://stackoverflow.com/questions/58199862,10929070.0,1
995,51371276,Tensorflow FailedPreconditionError: Attempting to use uninitialized value beta1_power,"I am trying to set up a simple convolutional network in Tensorflow. I'll try to keep the amount of code at a minimum level. Here's the class: I was trying to run the optimize operation to train the network on a simple dataset (e.g. images of cats vs dogs). Here is the main: However I keep getting the following error (it's actually much longer than this, I can post it if necessary): Can somebody help me figure out where the problem is? Thanks a lot",https://stackoverflow.com/questions/51371276,6447718.0,1
996,62213536,Get the Cross Entropy Loss in pytorch as in Keras,"I am struggling to port a classification model form keras to pytorch. Especially the cross entropy loss seems to return totally different numbers. prints: Since I have a custom loss function where cross entropy is a part of it, I would need to get similar if not the same numbers.",https://stackoverflow.com/questions/62213536,1298461.0,1
997,41455101,What is the meaning of the word logits in TensorFlow?,"In the following TensorFlow function, we must feed the activation of artificial neurons in the final layer. That I understand. But I don't understand why it is called logits? Isn't that a mathematical function?",https://stackoverflow.com/questions/41455101,6773030.0,1
998,57571337,Combine tensorflow low level API (tensors/placeholders) with Keras model,"According to tensorflow. Using tf.keras.Input gives a placeholder and using tf.keras.layers.Dense gives a Tensor. So I wanted to test the equivalence using Tensors and Placeholders with tensorflow low level API's and then use the keras high level API to train my model. This is my code: However, upon call to tf.keras.Model I get the error: I do give the input a placeholder right? PS: full error message:",https://stackoverflow.com/questions/57571337,5931672.0,1
999,64946166,Why is `tf.reduce_mean` used when computing the accuracy of logistic regression?,"The following function is meant to calculate accuracy of logistic regression, but what is the point of using reduce_mean function in this function? The code is:",https://stackoverflow.com/questions/64946166,,1
1000,55679218,keras.model.predict raise ValueError: Error when checking input,"I trained a basic Neural Network model on the MNIST dataset. Here's the code to the training: (imports omitted) I wanted to see how this model works with my own inputs, so I wrote a prediction script with help from this post. My prediction code is: (imports omitted) First, I don't understand the purpose of this line: If some one could shed light on why this line necessary, that would be of great help. Second, this very line throws the following error: What am I missing here?",https://stackoverflow.com/questions/55679218,1495549.0,1
1001,52279048,Unexpected error in Tensorflow when testing simple linear regression,"I'm learning Tensorflow from a book named A Concise Handbook of TensorFlow and there is a piece of code that uses Tensorflow for linear regression, but I get an AttributeError when testing. Information about error: I don't know why there is an error and I can't debug it.",https://stackoverflow.com/questions/52279048,7706100.0,1
1002,46846081,what is wrong with my cosine similarity? Tensorflow,"I want to use cosine similarity in my Neural network, instead of the standard dot product. I've had a look at the dot product and at the cosine similarity. In the example above they use However, I tried doing it my own way Is my way wrong? Also, what is going on in the matrix multiplication? Are we actually multiplying the weights of one node for the inputs of different samples (within one feature)?",https://stackoverflow.com/questions/46846081,6435921.0,1
1003,51402943,Tensorflow Saver restores all variables no matter which ones I specified,"I'm trying to save and restore a subset of variables from Tensorflow graph, so that everything I don't need is discarded and their weights don't take memory. The common advice to pass list or dict of desired variables to tf.train.Saver doesn't work: the saver restores all the variables no matter what. A minimal working example: outputs Nevertheless, print(saver._var_list) outputs [&lt;tf.Variable 'v2:0' shape=(5, 5, 3) dtype=float32_ref&gt;] What's wrong here?",https://stackoverflow.com/questions/51402943,3669254.0,1
1004,74170725,Tensorflow Model Fit : AttributeError: 'numpy.dtype[float64]' object has no attribute 'is_floating',"I develop a model using Tensorflow 2.9.1. My inputs are like this : When I process this data : And then apply fit on my model, I get this error : AttributeError: 'numpy.dtype[float64]' object has no attribute 'is_floating' The code fails when running keras.engine.compile_utils.match_dtype_and_rank on target data so I guess the problem comes from my y tensor but I do not understand why it is considered as numpy.dtype[float64]. Any advice ?",https://stackoverflow.com/questions/74170725,11807955.0,1
1005,51902093,Force keras to evaluate,"I am taking the cifar10_cnn.py and modifying it so I can generate my own kernels. (Trying a new idea). My code sets up the Sequential as usual, and compiles the model, then generates the CNN kernels with explicit python code, and copies them into the model. Next I call model.predict on a single image and that works fine. Like... The print_tensor never happens. There is a note in the docs that the return value of print_tensor must be 'used' later to get the print_tensor to be executed in the computation graph. I tried putting n = prt[0,0] and that does nothing, probably because n is never used. How can I force a variable to get 'used'?",https://stackoverflow.com/questions/51902093,5577970.0,1
1006,49659536,Tensorflow csv input pipline: Shuffle batches but preserve sequence order within each batch,"I build a recurrent neural network in tensorflow. Then I build a pipeline to import training data from my dataset (within a csv file) into my model. The procedure in the code section (source: here) works perfectly. The only additional thing is, that I use to create batches for training in the shape [batch_size x timesteps x features]. Now my question: I want to pass randomized/shuffled training data to my model, but at the same time preserve the sequence ordering within each batch. So the batches as a whole should be randomized/shuffled, but the sequences within each batch should preserve the original sequence order. Is there a simple way to do that?",https://stackoverflow.com/questions/49659536,9333513.0,1
1007,66911400,TypeError: Can not convert a NoneType into a Tensor or Operation -- Error believe related to converting to graph,"Below find my model: And below is my custom loss And then finally: My data inputs are of size (sequence length, feature length) where sequence length is variable hence I am using tf.data.experimental.bucket_by_sequence_length to pad to max sequence length of the batch (as opposed to batch to max sequence length). All in all, my train and val data are tf.data.Datasets each created using tf.data.experimental.bucket_by_sequence_length where each batch is of size (None, None, feature length). When I run the above code, I get the following errors and cannot seem to understand where I am going wrong: The four print statements inserted in the train_step function above are printed.",https://stackoverflow.com/questions/66911400,12949388.0,1
1008,60683848,What is the need to return a function object while creating a data set using tensorflow,I am new to Machine Learning and I am trying to create a Machine Learning Model using the Tensorflow API from the tutorial in the Tensorflow documentation from here But I am having trouble understanding this part of the code Then storing the output of the function in a variable And at last training the model with the data set I failed to realize what we are trying to do when by just returning the function name of the inner-function in make_input_function instead of just returning our data set and passing it to train the model. I am a beginner in Python and just started to learn Machine Learning and I am unable to find a proper answer to my question so if anyone can kindly explain it in a beginner friendly way I would be very much obliged.,https://stackoverflow.com/questions/60683848,11743459.0,1
1009,45281124,Using Word2vec with Tensorflow on Windows,"In this tutorial file by Tensorflow the following line is found (line 45) to load the word2vec ""extension"": I am using Windows 10, and as also is pointed out in this SO question, .so-files are for Linux. What is the equivalent extension to load on Windows? Also, I don't understand why so much else is included in Tensorflow upon installation but Word2Vec has to be built locally. In documentation, Installing TensorFlow on Windows, there is no mention of having to build these extensions. Was this an old practice that has now changed and everything is shipped with the installation? If so, how does that change apply to the word2vec module in the example?",https://stackoverflow.com/questions/45281124,1144382.0,1
1010,57265893,Change colors with ImageDataGenerator,"I'm using keras ImageDataGenerator for preprocessing training images and need some kind of color change function (random color, hue change). My code for generator looks like this: I tried to go throught keras manual for datagerator and the best i found was - channel_shift_range but it works more like brightness/contrast.",https://stackoverflow.com/questions/57265893,11675155.0,1
1011,47569423,Output of my three layer neural network is NAN,I have written a simple three layer neural network without any optimization or cost minimization. I am only initializing the weights of Neural Network and then feed forwarding to have the output. Here is my code. Now parameter initialization. now the important function for feed forward where I think there is some issue which is not giving the valid output. Below is the code for session creation and running for session for my training data with a same train_x_upsampled and train_y_upsampled. I Want to get the value of output for Z3 for the initialized parameters. Currently I am getting an invalid output.,https://stackoverflow.com/questions/47569423,8163412.0,1
1012,65716925,Tensorflow dataset from numpy array,"I have two numpy Arrays (X, Y) which I want to convert to a tensorflow dataset. According to the documentation it should be possible to run When doing this however I get the error: ValueError: Shapes (15, 1) and (768, 15) are incompatible This would make sense if the shapes of the numpy Arrays would be incompatible to the expected inputs/outputs. But if I run it with the numpy arrays by using model.fit(X,Y) it runs without any problems, so the shapes seem to be okay. In a next step I checked the output sizes: The input layer for the neural network expect (None, None) and the output (None, 15). So this also seems to match. My dataset is rather large, so it's difficult to share that, but here is a minimal reproducible example which shows the problem. It's the same error, and the fit with just the numpy arrays works. Can someone point me into the right direction on how to solve this? Tensorflow version is 2.3.1.",https://stackoverflow.com/questions/65716925,5632058.0,1
1013,62538267,Is adding values with tf.concat slow in for-loops?,"Im using tensorflow 2.0 and try to speed up my training by optimizing my code a little bit. I run my model batchwise and want to safe the results from each batch to have all results at the end of one epoch in one tensor. This is how my code looks like: Lets assume, one prediction is just a scalar value. So predictions_batch is a tensor with shape=[batchsize,]. This way of doing the concaternation just works fine. Now my question is: Does this tf.concat() operation slow down my whole training? I also used tf.stack()for this purpose, but it seems like no difference in speed. I wonder, because once I worked with Matlab, adding new values to a Vector (and hence change its size) within a for-loop was extremly slow. Initializing the vector with zeros and then assign values in the loop was way more efficient regarding speed. Is this also true for tensorflow? Or is there another more 'proper' way of doing something like adding tensors together in a for-loop which is more clean or faster? I did not find any alternative solution online. Thanks for the help.",https://stackoverflow.com/questions/62538267,13799627.0,1
1014,45266707,"keras: TypeError: Expected int32, got list containing Tensors of type '_Message' instead","I am learning the time series analysis using neural net implemented by Keras. Here's link to the dataset: airline_passanger_dataset : https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;display=line Code is: here I am encountering an error: my python version is 3.5.2, tensorflow version is 0.12.0 and keras version is 2.0.6 . I have tried to update tf.concat syntax in tensorflow_backend.py (https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py) on line 1039 and 1042 fro this link: Tensorflow Slim: TypeError: Expected int32, got list containing Tensors of type '_Message' instead from to the error is still same: Can someone please help me with the correct code? and explain what I am doing wrong? Thank you.",https://stackoverflow.com/questions/45266707,4769180.0,1
1015,56328140,How do I implement a masked softmax cross-entropy loss function in Keras?,"I'm trying to implement a softmax cross-entropy loss in Keras. The loss should only consider samples with labels 1 or 0 and ignore samples with labels -1 (i.e. missing labels). I found a binary_crossentropy function that does that but I couldn't implement a softmax version for it. Here's the binary_crossentropy: I tried to change the K.binary_crossentropy() function with K.categorical_crossentropy, but this only gives me ""nan"" when the loss is calculated. How can I implement this on Keras (Tensorflow backend)? In this answer, the author suggested to use sparse_crossentropy, but I ran into an error while compiling the model: Use sparse_categorical_crossentropy and boolean_mask",https://stackoverflow.com/questions/56328140,7777625.0,1
1016,55510265,How to save a Tensorflow dataset to csv?,"I find a lot of documents/forums telling how to convert a csv to a Tensorflow dataset, but not a single one saying how to convert a dataset to a csv. I have csv with two columns now (filename, weight - more columns maybe be added later). I read that into tensorflow and create a dataset. At the end of the script the 2nd column is modified and I need to save these columns to a csv. I need them in csv (not checkpoint) because I may need to do stuff with it on Matlab. I tried to call the dataset map function and tried to save to csv inside map function. But it doesn't work as expected. This doesn't work as expected just writes the tensor shape to csv Tensor(""arg0:0"", shape=(), dtype=string) Tensor(""arg1:0"", shape=(), dtype=float32) This solution is probably a bad one. I really need to get a neat way to do this",https://stackoverflow.com/questions/55510265,10415898.0,1
1017,44969269,Tensorflow: Weird broadcasting behavior,"I did not quite well understand how the broadcasting mechanism works in Tensorflow. Assume that we have the following code: So, I load the MNIST dataset, which consists of 28x28 sized images. The convolution operator uses 32 filters of 5x5 size. I use a batch size of 1000, so data tensor x has the shape (1000,28,28,1). The tf.nn.conv2d operation outputs a tensor of the shape (1000,28,28,32). y is a placeholder, a variable which I add to check Tensorflow's broadcasting mechanism by adding it to (1000,28,28,32) shaped conv1 tensor. In the line y_data = np.ones(shape=(1000, 32)), I experiment with various tensor shapes for y. The shapes (28,28), (1000,28) and (1000,32) won't add to conv1, with the errors of the type: The shapes (28,32) and (28,28,32) work and broadcast correctly. But according to the broadcasting semantics explained in https://www.tensorflow.org/performance/xla/broadcasting , the first three shapes have to work as well, since they are of the correct order by matching dimensions with the 4D conv1 tensor. For example, (28,28) matches (1000,28,28,32) in the dimensions 1 and 2, (1000,32) matches in the dimensions 0 and 3, just as mentioned in the link. Am I missing or misunderstanding something here? What is the correct broadcasting behavior of Tensorflow in such cases?",https://stackoverflow.com/questions/44969269,1538049.0,1
1018,68020370,"Why is Tensorflow ""save_model"" failing?","I'm working in Tensorflow 2.0.0, and trying to save a model. Here's the code I'm using (thanks to @m-innat for suggesting to simplify the example model) However, the save_model call gives an error: Nothing in the call stack suggests what the underlying problem is. Can you please help?",https://stackoverflow.com/questions/68020370,2417922.0,1
1019,52440824,"Save Model for Serving but ""ValueError: Both labels and logits must be provided."" when trying to export model","I wanted to save a model to do some predictions on specific pictures. Here is my serving function: and here is where I export the model: But I get the following error: Now this Error I don't understand since the Serving stuff should just create a placeholder so I can later put some images through the placeholder to make predictions on the saved model? Here is the whole traceback: Nevermind the mnist naming, I just used the structure of the code, but didn't rename it. Thanks for any help!",https://stackoverflow.com/questions/52440824,8821185.0,1
1020,69843184,Using SageMaker pipe mode with an s3 directory of tfrecords,"My call to sagemaker.tensorflow.TensorFlow.fit() hangs indefinitely with no error message when I use Pipe instead of File as the input_mode. I correspondingly replace the TensorFlow Dataset with Pipemodedataset. The training in File mode completes successfully. My data consists of two s3 buckets with multiple tfrecord files in each. Despite having looked extensively through the documentation, I am not confident about how to use the Pipemodedataset in this case - specifically, how to set the channel. Here is my Sagemaker notebook setup: If I were to run aws s3 ls on the s3_data_channels, I'd get a list of tfrecord files. Here is the way I set up the dataset (see the if / else statement depending on whether pipe_mode is selected:",https://stackoverflow.com/questions/69843184,4008884.0,1
1021,59517740,RNN : understanfingConcatenating layers,I am trying to understanding concatenating of layers in tensorflow keras. Below I have drew what I think is the concatenation of 2 RNN layers [ Spare for picture clarity] and the output Here I am trying to concatenate two RNN layers. One layer has longitudinal data[ integer valued ] of patients in some time sequence and other layer has again details of same patients of other time sequence with categorical input. I don't want these two different time sequences to be mixed up since it is medical data. So I am trying this. But before that I want to be sure if what I have drawn is what concatenating of two layers means. Below is my code. It appears to work well but I want to confirm if my what i drew and what is implemented are correct .,https://stackoverflow.com/questions/59517740,2165803.0,1
1022,65633944,CRNN get accuracy from keras.backend.ctc_decode,"I have a CRNN fitted model with CTC loss output. I have the prediction and I use keras.backend.ctc_decode to decode it. As written in documentation (https://code.i-harness.com/en/docs/tensorflow~python/tf/keras/backend/ctc_decode), the function will return a Tuple with the decoded result and a Tensor with the log probability of the prediction. keras.backend.ctc_decode can accept multiple values for its prediction but I need to pass it once at time. This is the code: Output: The prediction is always correct. However what I think it's the probability seems not to be what I expect. They looks like completely random numbers, even grater than 1 or 2! What am I doing wrong?? Thank you in advance! PS: during the training part, the final CTC loss was around 0.1",https://stackoverflow.com/questions/65633944,14967854.0,1
1023,63118152,When did we feed the input? in Tensorflow/Deep-Learning,"Im working with mnist data set. In coding no problem all is well But when i want to understand how code is works i cant. I have problem with works of tensorflow codes. In my code has 3 hidden layer and one of out. My NNA model: And this train Last one main THE PROBLEM Now the question is, we are starting with train_neural_network(x). then x goes to prediction = neural_network_model(x) The problem x, which is a placeholder and has no data. It has not feed yet. So how neural network gives a value or output? OUTPUT",https://stackoverflow.com/questions/63118152,13641707.0,1
1024,60532788,Problem during preprocessing of data in Tensorflow,"I'm getting some errors while trying to follow tensorflow's own Quickstart. My problem is: I'm trying to implement it using a custom dataset, and I'm having some trouble figuring out how the MNIST dataset is preprocessed. Here is a code from the documentation that loads the data: Keras' documentation reads that load_data() returns a tuple of Numpy arrays, however I can't for the life of me figure out how to prepare datasets from tensorflow_datasets in the same way you can prepare Keras datasets. Is it even possible? I've already tried using but as anticipated this doesn't work. Any ideas, or am I going to have to learn to use tensorflow_datasets using a different resource?",https://stackoverflow.com/questions/60532788,13007994.0,1
1025,68427532,tf.keras.losses.CategoricalCrossentropy gives different values than plain implementation,Any one knows why raw implementation of Categorical Crossentropy function is so different from the tf.keras's api function? Above gives: If now with another y_true and y_pred: It gives:,https://stackoverflow.com/questions/68427532,6398487.0,1
1026,49481611,Successive matrix multiplication in R using TensorFlow,"A simple question. Suppose I have an m x m matrix (mat) which I'd like to raise to the power of n, meaning mat %*% mat %*% mat %*% ... (and suppose I'd like to keep all the intermediate products) To to this using tensorflow (since I want to make it efficient using GPUs), would the code be: Or am I not using tensorflow appropriately?",https://stackoverflow.com/questions/49481611,1701545.0,1
1027,45564441,How to pass more than 1 input into a Tensorflow Neural Network?,I am stuck at passing in 3 inputs (placeholders with different shapes) into a neural network's hidden layer. This is what I have so far: Placeholders: Hidden Layers: all the final_layer[1-3] and final_output I have tried Googling for some sample code but unable to find any.,https://stackoverflow.com/questions/45564441,4086171.0,1
1028,50675178,tf.ones(dtype=tf.float32) or tf.ones(dtype=tf.int32) behave differently,"When I use dtype = tf.float32, I got the result like this: However, when I use dtype=tf.int32， I got the result: Can you help me why it seems not correctly when use tf.float32?",https://stackoverflow.com/questions/50675178,7701908.0,1
1029,56199905,How to create sum of different kernel objects in TensorFlow Probability?,"I have one question about specifying kernel function in Tensorflow-probability. Usually, if I want to create a kernel object, I will write I know that kernel object support batch broadcasting. But what if I want to build a kernel object that is the sum of several different kernel objects, like additive Gaussian processes? I am not sure how to ""sum"" up the kernel object in Tensorflow. What I am able to do is to create several separate kernel objects K1, ... KJ It seems that there is no similar question online. Thanks for the help in advance. Updates: I tried direct +, but there is something strange with the covariance matrix. I made up the following example: The first four covariance matrices are fine, and I double check it by comparing the k(x_i, x_j) element-wise. However, I don't know how it computes the last one. I tried Below are the results of the last three matrices: They don't match with my result. Does anyone know how they compute the last matrix with different index_points? Or in general, how do I specify the kernel so that they can fit the model such as additive Gaussian processes, where different index_points correspond to different kernel functions, so that I can fit the model y_i = f_1(x_{1,i}) + f_2(x_{2,i}) + ... under TensorFlow Probability framework?",https://stackoverflow.com/questions/56199905,3200615.0,1
1030,43369777,Tensorflow model restoration (resume training seems starting from scratch),"I've a problem for resuming training after saving my model. The problem is that my loss decrease form 6 to 3 for example. At this time I save the model. When I restore it and continue training, the loss restart from 6. It seems that the restoration doesn't really work. I don't understand because printing the weights, it seems that they are loaded properly. I use an ADAM optimizer. Thanks in advance. Here:",https://stackoverflow.com/questions/43369777,4875236.0,1
1031,57141343,Invalid type tf.complex64 for tf.train.GradientDescentOptimizer(),"I am working with complex neural networks. I have created a network that works correctly using: Now when I try to use: I get, for line training_op = optimizer.minimize(mse) the following: Is this truly not supported for complex? Or am I doing something wrong? I tried the same with real-valued net and it worked correctly so I believe I have the structure correct. New insight: According to this. Minimize is divided into two parts: If we test them separately, the error occurs on the compute_gradients method. So running tf.gradients work but running optimizer.compute_gradients doesn't? This is getting weirder. Anyone knows the reason?",https://stackoverflow.com/questions/57141343,5931672.0,1
1032,66106583,Why the difference before and after dropout is not equal to the dropout proportion?,"I'm specifying a network with regularization from dropout. But I'm having trouble understanding how the dropout is being processed here. Specifically, why isn't the difference between the number of zeros before and after applying dropout exactly equal to the dropout proportion?",https://stackoverflow.com/questions/66106583,12655251.0,1
1033,52939042,Tensorflowsharp and Retinanet -- How to determine what to Fetch when graph is run?,"I've been using TensorflowSharp with Faster RCNN successfully for a while now; however, I recently trained a Retinanet model, verified it works in python, and have created a frozen pb file for use with Tensorflow. For FRCNN, there is an example in the TensorflowSharp GitHub repo that shows how to run/fetch this model. For Retinanet, I tried modifying the code but nothing seems to work. I have a model summary for Retinanet that I've tried to work from, but it's not obvious to me what should be used. For FRCNN, the graph is run in this way: From the model summary for FRCNN, it is obvious what the input (""image_tensor"") and outputs (""detection_boxes"", ""detection_scores"", ""detection_classes"", and ""num_detections"") are. They are not the same for Retinanet (I've tried), and I can't figure out what they should be. The ""Fetch"" part of the code above is causing a crash, and I'm guessing its because I'm not getting the node names right. I won't paste the entire Retinanet summary here, but here is the first few nodes: And here are the last several nodes: Any help with figure out how to fix the ""Fetch"" part of this would be greatly appreciated. EDIT: To dig a little further into this, I found a python function to print the operation names from a .pb file. When doing this for the FRCNN .pb file, it clearly gave the output node names, as can be seen below (only posting the last several lines from the output of the python function). If I do the same thing for the Retinanet .pb file, it's not obvious what the outputs are. Here's the last several lines from the python function. For reference, here's the python function that I used: Hope this helps.",https://stackoverflow.com/questions/52939042,973987.0,1
1034,57792660,Tensorflow 1.14+ Serialize Subclassed Keras Layers?,"I've gone through and re-re-re-read the Tensorflow Keras docs, e.g. I have a simple subclassed layer: and then have a functional model: and figure then I could load the model as: but I get: from the docs: which I have. What am I doing wrong?",https://stackoverflow.com/questions/57792660,5623899.0,1
1035,67638773,"Can you please clarify the logic behind ""one-hot encoding the labels to use MSE"" in a Classification Problem","Thank you Keras Team for the very detailed explanation about Train and Evaluate but I have a query. I want to understand the statement, and want to understand exactly, how One-Hot-Encoding and MSE work together (because One-Hot-Encoding just creates columns with 0's and a 1), in the code mentioned below in the Documentation of Keras Train and Evaluate",https://stackoverflow.com/questions/67638773,13503628.0,1
1036,53175991,How can I make predictions from a trained model inside a Tensorflow input pipeline?,"I am trying to train a model for emotion recognition, which uses one of VGG's layer's output as an input. I could manage what I want by running the prediction in a first step, saving the extracted features and then using them as input to my network, but I am looking for a way to do the whole process at once. The second model uses a concatenated array of feature maps as input (I am working with video data), so I am not able to simply wire it to the output of VGG. I tried to use a map operation as depicted in the tf.data.dataset API documentations this way : But I'm getting this error : Tensor Tensor(""fc1/Relu:0"", shape=(?, 4096), dtype=float32) is not an element of this graph which is pretty explicit. I'm stuck here, as I don't see a good way of inserting the trained model in the same graph and getting predictions ""on the fly"". Is there a clean way of doing this or something similar ? Edit: missed a line. Edit2: added details",https://stackoverflow.com/questions/53175991,10563517.0,1
1037,73749353,"Is there any way I can count the number of layers in a model, i.e., numerical answer?","Consider the following model I can extract summary of the model instance but is there any method that can give/count the number of layers (with trainable parameters)? For example, the above posted model has 4 layers with trainable parameters.",https://stackoverflow.com/questions/73749353,19953155.0,1
1038,45591967,How does Kmeans clustering work in tensorflow?,"I saw that there is an implementation of Kmeans clustering available within tensorflow contrib library. However, I was not able to do the simple operation of estimating cluster centers for 2D points. Code: I get the following error : I guess I'm doing something wrong but couldn't figure out what from the documentation. Edit: I solved it using input_fn but it is really slow (I had to reduce the number of points in each cluster to 10 to see results). Why is that and how can I make it faster? Solved: It seems that a relative tolerance should be set. so I changed only one line and it works fine. kmeans = tf.contrib.learn.KMeansClustering(num_clusters = n_clusters, relative_tolerance=0.0001)",https://stackoverflow.com/questions/45591967,6828367.0,1
1039,44782544,Tensorflow: Invalid calculations,"I am new into tensorflow and try to understand how the computation graph works. I am working on the very basic linear regression example on the tensorflow website. I have the following piece of code: I just try to apply gradient descent to a simple (w*X - b - Y)^2 model. I don't use Tensorflow's own optimizer purposefully, I want to understand the underlying graph update mechanisms. In order to check that the system calculates correct gradients, I implemented my own loss and gradient calculation functions for linear regression as well. Unfortunately, it seems that tensorflow does not calculate the loss function and the gradients as expected. Here is what I get as an output: As you can see, tensorflow calculates incorrect loss value and gradients for W and b in the second iteration, actually the same ones as the first iteration. In some trials, it starts to diverge from the actual values from third or fourth iterations; not always in the second one. Am I doing something wrong here? As soon as I get the values of W and b and their gradients, I update their values with tf.assign() in the training loop. Does the problem lie here; is it a wrong way to update variables with tensorflow? It is really discouraging to run into such problems just at the start.",https://stackoverflow.com/questions/44782544,1538049.0,1
1040,66441258,Bad results in keras after Warning: tf.function retracing,"I just started to use keras and tesorflow to create a simple multilayer perceptron with 3 inputs, one hidden layer with 10 neurons and one neuron as the output. I trained the network and the results were okay with a 'val_mean_absolute_percentage_error' of about 5 %. I played around with some parameters of the training (especially the epochs) and trained the model several times. All of a sudden, when predicting one value I get the following warning that I do not understand The very strange thing is that after this warning occured I get very bad results having a 'val_mean_absolute_percentage_error' of about 125% and also the prediction results are quite bad. As I am also new to python, I do not understand the possible reasons in the warning message. Why did this warning and the bad results all of a sudden occur and how can I get rid of them? I'd appreciate every comment and would be quite thanful for your help. Here you see the model that I created Update: Here you can see my data. I have 3 numbers (inputs) and one number (output) which is just the sum of the 3 input numbers",https://stackoverflow.com/questions/66441258,7133942.0,1
1041,63329820,How to work with TensorFlow 3d deconvolution?,"I have the following 3d transpose operation: But I'm getting the error: Where the original shape of cost volume is (2, 12, 39, 1, 128). What am I doing wrong and how do I fix this? I'm not aware of what input batch and output batch the error message is referring to.",https://stackoverflow.com/questions/63329820,12654090.0,1
1042,50174630,What Mechanisms does Tensorflow Provide for Managing Model Input Parameters?,"I am really not sure, whether this question has not already been answered. But I did not find it. Maybe I just don't know the terms to find it. To create a model in Tensorflow I do the following two steps I create the model: I create dictionaries where I save the weights and biases: I would like to know if there is a way where I just provide a list with network parameters like: network_parameters = [n_input, n_hidden_1, n_hidden_2, n_classes] where n_inuput, n_hidden_1 etc. are numbers, to create a model. That would be great for larger models. How do I do that?",https://stackoverflow.com/questions/50174630,3861775.0,1
1043,68344978,"Logits and labels must be broadcastable: logits_size=[29040,3] labels_size=[290400,3]",I am using this code: and I receive: If I just omit the LSTM layer: then the code runs without any problem!,https://stackoverflow.com/questions/68344978,583464.0,1
1044,44639260,Retrieving an unnamed variable in tensorflow,"I've trained up a model and saved it in a checkpoint, but only just realized that I forgot to name one of the variables I'd like to inspect when I restore the model. I know how to retrieve named variables from tensorflow, (g = tf.get_default_graph() and then g.get_tensor_by_name([name])). In this case, I know its scope, but it is unnamed. I've tried looking in tf.GraphKeys.GLOBAL_VARIABLES, but it doesn't appear there, for some reason. Here's how it's defined in the model: Is there any way of finding the variable without a name?",https://stackoverflow.com/questions/44639260,1810854.0,1
1045,61042573,tf.data filter dataset using label predicate,"I am trying to filter the CIFAR10 training and test data with specific labels as given below, as per similar issue. However, the filter function returns the unfiltered in the above code. Returns To reproduce the result, please use this colab link",https://stackoverflow.com/questions/61042573,6573817.0,1
1046,50485506,Basic tensorflow classification example,"i'm struggling to understand tensorflow, and I can't find good basic examples that don't rely on the MNIST dataset. I've tried to create a classification nn for some public datasets where they provide a number of (unknown) features, and a label for each sample. There's one where they provide around 90 features of audio analysis, and the year of publication as the label. (https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd) Needless to say, I didn't manage to train the network, and little could I do for understanding the provided features. I'm now trying to generate artificial data, and try to train a network around it. The data are pairs of number (position), and the label is 1 if that position is inside a circle of radius r around an arbitrary point (5,5). If tried many combinations of network shape, parameters, optimizers, learning rates, etc (I admit the math is not strong on this one), but eithere there's no convergence, or it sucks (70% accuracy on last test). Current version (labels converted to one_hot encoding [1,0] and [0,1] (outside, inside). The acuracy in this example is around 70% (loss around 0.6). The question is... what am I doing wrong? I'm leaving the question as originally asked. Main lessons I learned: Normalize your input data. The mean should be around 0, and the range ~ between -1 and 1. Blue: normalized data, Red: raw input data as created above Batch your input data. If the subsets used are random enough, it decreases the number of iterations needed without hurting accuracy too much. Don't forget activation functions between layers :)",https://stackoverflow.com/questions/50485506,1756928.0,1
1047,76098508,How to implement tf.assign in PyTorch?,"I'm trying to convert a Tensorflow network to Pytorch, and I found there is a tensorflow function called tf.assign that I didn't know how to implement in Pytorch. The Source code: self.v is a trainable variable with shape (self.num_grid, self.num_grid, self.grid_cell_dim) I try to implement by set tensor.data, is this right?",https://stackoverflow.com/questions/76098508,10752716.0,1
1048,48511365,Why can't I fit this simple tensorflow model?,"I have a very simple tensorflow model. However, I can't seem to train the model to give the desired output. Example code is below: However, after 1,000 training iterations, it comes out as something like: But my desired output is: I would have hoped that such a simple model would fit very precisely and in a small number of training iterations. The model is flexible enough to match the desired output. Setting the weights to these values will give the desired output: How can I: Update: If I change the activation function from tf.nn.relu to tf.nn.sigmoid it can make a reasonable fit after 100,000 iterations (59 seconds on my machine). Here is the output:",https://stackoverflow.com/questions/48511365,847663.0,1
1049,62674827,Keras Custom Loss Function InvalidArgumentError: In[1] is not a matrix. Instead it has shape [],"I’m trying to use the Spearman rank correlation coefficient to write a custom loss function. I want to compute the Spearman rank correlation coefficient between each pair of y_true and y_pred samples (each sample is an array of 8 elements; e.g., [1 2 3 4 5 6 7 8] and [3 2 1 4 5 8 6 7]). I have followed the indications of this answer (How to compute Spearman correlation in Tensorflow) and Keras documentation (https://keras.io/api/losses/), however there must be something I’m skipping with regard to the output shape of the computed loss. Training the model with this custom function produces the following error: I have tried a tricky way to solve this, I use a working example of a Keras loss function and I simply modify the result with the values computed in my loss function. This way the training function works, however, I don’t think this is the way of doing things properly but I’m not seeing where is the problem. Looking at the outputs of the prints in the custom function, can be seen that the shape and type of my loss output object and the tensorflow's loss function output object are the same. This is the way I’m computing the loss: And this is the output:",https://stackoverflow.com/questions/62674827,4940835.0,1
1050,41626542,"Tensorflow: InvalidArgumentError with MNIST, [55000] vs. [10000]","I'm working through the code from this presentation http://www.youtube.com/watch?v=vq2nnJ4g6N0&amp;t=20m28s and am getting this error: InvalidArgumentError (see above for traceback): Incompatible shapes: [55000] vs. [10000] I've already worked through a few errors regarding tensor shape/dimensions, but have no idea how to specifically understand this let alone correct it. I'm new to tf and any advice is much appreciated, here is the code: The total error output is:",https://stackoverflow.com/questions/41626542,5355831.0,1
1051,61578535,Trainable custom Keras layer using a Tensorflow wrapper for Numpy functions,"I am trying to create a custom Keras layer which is a general-purpose wrapper for functions which operate on numpy arrays and return numpy arrays. I am using a Tensorflow 2.0 back end for Keras. I think this could be really useful for anyone who has some outside code they want to implement as a trainable Keras layer. My strategy was to use tf.numpy_fun together with the @tf.custom_gradient decorator to define a differentiable Tensorflow operator which wraps a Numpy function. In principle, if there is a way to call the function and also a custom function to compute gradients, it should be trainable via backpropagation. Here I show an example implementing the nonlinear transformation: y=Bexp(-Ax) I verified that the tensorflow function was compatible Tensorflow's automatic differentiation using tf.GradientTape() But when I try to implement the function in a custom Keras layer I get an error that I don't fully understand. Here is my code: When I run this, I get an error at the first tf.numpy_fun call insideMyTensorflowFun. Here is the error message: OperatorNotAllowedInGraphError: iterating over tf.Tensor is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function. I am confused because I thought that Tensorflow has eager execution enabled by default. If I run tf.executing_eagerly() it returns True, but if I run it right before the error it returns False. Does this mean that Keras is executing in graph mode? How can I fix this? Also interested if anyone has other general suggestions for accomplishing the goal of trainable numpy functions in a custom Keras layer.",https://stackoverflow.com/questions/61578535,3204332.0,1
1052,71789096,how to pad sequences in a tensor slice dataset in TensorFlow?,"I have a tensor slice dataset made from two ragged tensors. tensor_a is like: &lt;tf.RaggedTensor [[3, 3, 5], [3, 3, 14, 4, 17, 20], [3, 14, 22, 17]]&gt; tensor_b is like: &lt;tf.RaggedTensor [[-1, 1, -1], [-1, -1, 1, -1, -1, -1], [-1, 1, -1, 2]]&gt; (Same index, same length for tensor_a and tensor_b.) I made the dataset by How to pad the sequences in my dataset? I've tried tf.pad and tf.keras.preprocessing.sequence.pad_sequences but haven't found a right way.",https://stackoverflow.com/questions/71789096,18560219.0,1
1053,43612810,Creating a Slim classifier using pretrained ResNet V2 model,I am trying to create an image classifier that utilizes the pre-trained ResNet V2 model provided in the slim documentation. Here is the code so far: The problem is I keep getting this error: So it seems TF/Slim is unable to find any variables and this is made clear when I call: As it outputs an empty array. How can I go about using the pre-trained model?,https://stackoverflow.com/questions/43612810,127602.0,1
1054,68716149,Dynamic RNN in Keras: Use Custom RNN Cell to Track Other Outputs at Each Timestep,"Is there a way to return multiple outputs for a given timestep when implementing a custom cell for an RNN in keras? E.g. outputs with shapes: (sequences=[batch, timesteps, hidden_units], other_outputs=[batch, timesteps, arbitrary_units], last_hidden_states=[batch, hidden_units]) My motivation for this stems from Algorithm 1 'recurrent decoder' of ""Self Attention in Variational Sequential Learning for Summarization"" (Chien, ISCA 2019) which 'accumulates the variational objective' and thus must track several outputs for a given recurrent timestep. With a keras RNN, if you pass the return_sequences=True and return_state=True args when instantiating the layer, the outputs from a forward pass through the RNN are ([batch, timesteps, hidden_units], [batch, hidden_units]) which are hidden states at all timesteps and the last hidden state, respectively. I want to track other outputs at each timestep using the RNN, but I am not sure how. I am thinking I could change the output_size attribute in the custom cell, class but I am not certain this is valid since the TensorFlow RNN documentation seems to indicate only a single output is possible for each timestep (i.e., 'single integer or TensorShape'): This is what I have for a custom implemented 'RNN cell' so far: Then I want the cell to work like this:",https://stackoverflow.com/questions/68716149,15001463.0,1
1055,61305608,"Weird shaped kernels after initialization in a CNN, tensorflow","I was trying to make a CNN in pure tensorflow, and for initializing the kernels for a layer, I am using the following code: I expected to it give 3, 2*2 matrices but instead it gave the following output: Output Screen Shot I am totally confused as I wanted to iterate over the 3, 2*2 kernels, which I am unable to do currently. Please, help me understand the shape issue! tensorflow version is 1.14.0 Book's Excerpt",https://stackoverflow.com/questions/61305608,13157701.0,1
1056,51025483,"ValueError: No gradients provided for any variable, check your graph for ops that do support gradien","I am a beginner in tensorflow and I tried some toy example from the net: But when I run it, I have the following error : If you have any idea to help me ...",https://stackoverflow.com/questions/51025483,9989482.0,1
1057,64981900,Reassignment of weights in tensorflow 2/keras,"I'm currently testing some modified versions of dropout in Keras and one of them involves adjusting the weights during the training of a customized dense layer. I however have not been able to run it without error yet. I suspect is has something to do with eager execution but I'm not sure. Error: TypeError: Expected binary or unicode string, got &lt;tf.Tensor 'sequential_3/linear_3/mul:0' shape=(4, 3) dtype=float32&gt;",https://stackoverflow.com/questions/64981900,11614302.0,1
1058,49957862,Tensorflow placeholder for one-hot encoded labels,"I've one-hot encoded labels (11 classes ranging from 0 to 10): And have the following placeholders: And I'm using sparse_softmax_cross_entropy: TF throws: ValueError: Cannot feed value of shape (500, 1, 11) for Tensor 'labels:0', which has shape '(?, 1)' I've tried everything and can't get it to work. What is the proper placeholder for one-hot encoded data?",https://stackoverflow.com/questions/49957862,452610.0,1
1059,38781746,Computation on a Tensor as numpy array in graph?,"Is there any way to do some computation on a tensor in graph. Example my graph: I can separate graph into 2 parts and use Session.run([part1]) After that use the result to input my function, then feed it to Session.run([part2]) But it seems weird.",https://stackoverflow.com/questions/38781746,775628.0,1
1060,67405427,Deep learning with Tensorflow: personalized training loop that learn with one element at a time,"I need to use batch with element of different size, so i try to create a personalized training loop, the main idea is to start from the one supplied from keras: and add a cicle over the batch size, in this way i can train the network one element a time, and update the weight only after every element of the batch pass trough the newtork. Something like: where x and y are a single element of the batch. But i notice that in this way i consider only the last batch ( because grads is ovewritten). How can i manage this? I don't know how to ""merge"" different grads. Also one curiosity: i thought that the variable create with ""with"" statements are valid only inside the statement, so how is it possible that using it outside works? UPDATE I tried SoheilStar's solution, but tape.gradient return a vector [None, None, None, None] and on ""apply_gradients"" it said "" No gradients provided for any variable: ['conv1d/kernel:0', 'conv1d/bias:0', 'dense/kernel:0', 'dense/bias:0']."" I don't know how to debug in this case to find the problem There is the main part of the code i use: UPDATE 2: I notice that if i change the training cicle in this way, it works but i don't understand why and if it is correct:",https://stackoverflow.com/questions/67405427,,1
1061,50187501,Can't write Tensorflow scalar summary to event log,"i'm trying to learn how to write tensorflow code on my own, but i'm stuck with this very basic issue: During learning steps i can't write any scalar summary to the event file, which is needed for Tensorboard. Here is my code: the error i get: Pls help me correct my code, because i have read a lot of issues around the topic but never encountered this specific problem. Thanks",https://stackoverflow.com/questions/50187501,9744785.0,1
1062,51066569,NCE loss in word2vec vs a common Neural Network,"As I was trying to learn more about NLP, I realized that people use NCE loss without defining a connected NN. To be more specific: Instead, why do people not define a connected NN, and a with sigmoid as the activation function in the final layer? Would my suggestion be considered as doable if we were to use one-hot encoding, and not relevant in most-frequent value representation? I am sorry if my question is a bit dumb since I am not so much familiar with NLP yet. Thanks",https://stackoverflow.com/questions/51066569,7415247.0,1
1063,60405018,GRU/RNN state in graph mode Vs eager execution mode,"I have same piece of code written first in eager execution mode and then in graph mode. Now, I am not quite able to figure out why the GRU state is not retained in the graph mode while it's working fine in eager mode. Here's the eager mode code: Output of this code: Now, the graph model code: output: Any insights on how to fix this ambiguity and retain states in case of graph mode? There's a similar question asked before but unanswered. Statefulness in eager mode vs non-eager mode",https://stackoverflow.com/questions/60405018,7776604.0,1
1064,43789760,Tensorflow: About the Variable value after Session run?,"In Tensor, I don't understand the value of Variable. Below is my code, I think after I do The value of W should be calculated, however, After print it , I find it didn't change. The code is an MNIST example code from TensorFlow website. Anyone can explain why W doesn't change?",https://stackoverflow.com/questions/43789760,3239558.0,1
1065,68738910,Keras model fits on data with the wrong shape,"I've created the following model: and the following dummy data: with the shapes of (4, None, 2) and (4, 3). Looking at the model structure one can see that the model has 3 outputs of shape (None, 1). I was wondering how come the fit works, when I expected they to be of shape (4, 3, 1) and not (4, 3). So I added one output to the target and tested the same model with a y of shape (4, 4) and the fit works .... I'm lost. Question: How should I shape my y to fit the model and what actually happened when I gave it the wrong y shape? Code on Colab",https://stackoverflow.com/questions/68738910,1115237.0,1
1066,34646471,Tensorflow MNIST beginners need some understanding evaluation step,"I went thru the elementary example in Tensorflow of evaluating the trained model. Here is what it says: I did not follow this code, where is the trained 'model'? or is it tf.reduce_mean(....) ? checking the trained model.",https://stackoverflow.com/questions/34646471,1176802.0,1
1067,72417008,Custom Model train_step is never called,"I want to build and train a language model according to this example from the keras documentation My MaskedLanguageModel class looks like this: I'm facing the issue, that the train_step function is never called. And my loss is always ""0.0000e+00"". But when I comment out the following section the loss is updated and gets smaller. According to this answer train_step should automatically called when training the model via .fit(...) What am I doing wrong? (My tensorflow version is 2.1.0) Thank you in advance.",https://stackoverflow.com/questions/72417008,6761285.0,1
1068,57244733,Where does the documentation point to a list of values for the loss property of the compile function?,"I'm following the Tensorflow documentation for creating a simple neural network. One of the steps is When I look at the documentation for the loss parameter, it says Based on this documentation of the compile function, how would I find a list of the strings and/or objective functions that I can pass for the loss parameter? I found the tr.keras.losses that has the objective functions by Googling, but it seems like there should be a link or mention of that in the documentation for Sequential.compile. Am I missing something?",https://stackoverflow.com/questions/57244733,4820436.0,1
1069,49169804,"Distributed TensorFlow: at low-level, how the workers and the ps interact with each other during training?","I'm studying how distributed TensorFlow handle its distributed computation in order to replicate its architecture. I need to understand at the low-level the operations done by workers and the operations done by the PS, I can't just rely on the correctness of the python API. Here my previous question on SO. So it seem that the worker calculate the gradients and then send the gradients to the PS that apply them updating the weights. But if I look at the code that I found in the Distributed TensorFlow Doc I see that inside the worker code there is a call to the method minimize() If we look at the source code of the method minimize inside the Python API we saw that it call compute_gradients() and apply_gradients(). It seem that the worker does the compute and the apply operations. What kind of information then the workers send to the PS ? They send maybe the weights already updated by the applying of the gradients ? And if the PS receive the all weights how do it merge them ?",https://stackoverflow.com/questions/49169804,9099269.0,1
1070,38692531,Explanation of GRU cell in Tensorflow?,"Following code of Tensorflow's GRUCell unit shows typical operations to get a updated hidden state, when previous hidden state is provided along with current input in the sequence. But I don't see any weights and biases here. e.g. my understanding was that getting r and u would require weights and biases to be multiplied with current input and/or hidden state to get an updated hidden state. I have written a gru unit as follows: Here I explicitly make use of weights Wx, Wr, Wz, Wh and biases br, bh, bz, etc. to get updated hidden state. These weights and biases are what get learned/tuned after training. How can I make use of Tensorflow's built-in GRUCell to achieve the same result as above?",https://stackoverflow.com/questions/38692531,2745266.0,1
1071,65732702,Tensorflow 2 custom loss return nan,"I have a model, I compile it using binary_crossentropy, the training process goes well, the loss is printed. Then I write a custom loss function, the loss become nan I use a batch_loss(tf.ones((1,))) to test my loss function, seems it return the correct result. But when it run together with training, it becomes nan, where should I start to debug? model and data code (for those who need it to reproduce):",https://stackoverflow.com/questions/65732702,11607378.0,1
1072,41439254,What are the differences between tf.initialize_all_variables() and tf.global_variables_initializer(),"On Tensorflow official website, it gives explantions of the tf.initialize_all_variables() and tf.global_variables_initializer() functions as follow It seems like both can be used to initialize all variables in graphs. Can we use these two functions exchangbly? If not, what would be the differences?",https://stackoverflow.com/questions/41439254,6733064.0,1
1073,41613767,tf.parse_example used in mnist export example,"I am new to tensorflow and are reading mnist_export.py in tensorflow serving example. There is something here I cannot understand: Above, serialized_tf_example is a Tensor. I have read the api document tf.parse_example but it seems that serialized is serialized Example protos like: So how to understand tf_example = tf.parse_example(serialized_tf_example, feature_configs) here as serialized_tf_example is a Tensor, not Example proto?",https://stackoverflow.com/questions/41613767,5685754.0,1
1074,55734820,Running simple regression in base Tensorflow 2.0,"I'm learning Tensorflow 2.0 and I thought that it would be a good idea to implement the most basic simple linear regression in Tensorflow. Unfortunately, I ran into several issues and I was wondering if anyone here might be able to help. Consider the following set up: Now on with the model definition: Unfortunately, I'm getting the following error: The full error output is here: The trouble is, 2.0 is set to eager execution by default! In addition to this problem, I have a few extra questions: Many thanks!",https://stackoverflow.com/questions/55734820,3236215.0,1
1075,42784350,How to split image to RGB channels in Tensorflow,"I want to split an RGB image into 3 channels to perform some operations on them (convert to YUV, to be more precise) and then join them again. This is what I have done so far (this code does not work as I get dimension errors): and this is check_image (from pix2pix implementation):",https://stackoverflow.com/questions/42784350,7671750.0,1
1076,44604278,Tensorflow: Incompatible types for dataset.map() in tf.contrib.data,"When using a hash table lookup with tf.contrib.Dataset.map(), it fails with the following error: TypeError: In op 'hash_table_Lookup', input types ([tf.string, tf.string, tf.int32]) are not compatible with expected types ([tf.string_ref, tf.string, tf.int32]) Code to reproduce: It complains about tf.string_ref and tf.string being incompatible. It's strange that it expects a tf.string_ref and not a tf.string. Does anyone know why this is the case and what I can do about it? The issues is related to table_ref being tf.string_ref here.",https://stackoverflow.com/questions/44604278,1681337.0,1
1077,52548643,How to create Keras model with optional inputs,"I'm looking for a way to create a Keras model with optional inputs. In raw TensorFlow, you can create placeholders with optional inputs as follows: In a similar fashion, I would want to be able to have optional inputs for my Keras model. It seems like the tensor argument in the keras.layers.Input.__init__ might be what I'm looking for, but at least it doesn't work as I was expecting (i.e. the same way as tf.placeholder_with_default shown above). Here's an example that breaks: The first call to the model.predict seems to give correct output, but for some reason, the direct call to model fails with the following error: Can the tensor argument in Input.__init__ be used to implement optional inputs for Keras model as in my example above? If yes, what should I change in my example to make it run correctly? If not, what is the expected way of creating optional inputs in Keras?",https://stackoverflow.com/questions/52548643,1599247.0,1
1078,46435578,Tensorflow: embedding Variable into matrix and solving,"Sorry if the title isn't very clear... I'm trying to solve for the value of ""w"" in the following problem with Tensorflow: where Y is a 22x5 matrix, X is a 22x3 matrix, and B(w) is a 3*5 matrix with the following structure: Here's my code: But i'm getting the error ""FailedPreconditionError (see above for traceback): Attempting to use uninitialized value w..."" I'm guessing this has to do with the how I'm constructing B and passing it along to the cost function, but I'm too new to Tensorflow to see what I'm doing wrong. Any help?",https://stackoverflow.com/questions/46435578,6815126.0,1
1079,47236171,What is tf.extract_image_patches method meant for?,"I want to divide my images into smaller windows which will be send to a neural net for training (e.g. for face detectors training). I found tf.extract_image_patches method in Tensorflow which seemed like exactly what I need. This question explains what it does. The example there shows input of (1x10x10x1) (numbers 1 through 100 in order) given the ksize is (1, 3, 3, 1) (and strides (1, 5, 5, 1)). The output is this: But I'd expect windows like this (of a shape (Nx3x3x1), so that it's N patches/windows of the size 3x3): So why are all patch values stored in 1D? Does it mean that this method is not meant for the purposes I described above and i can't use it to prepare batches for training? I also found another method for patches extracting, sklearn.feature_extraction.image.extract_patches_2d and this one really does what I was expecting. So should I understand it like that these two methods don't do the same thing?",https://stackoverflow.com/questions/47236171,6204637.0,1
1080,64388497,Calculating recursive mean in Keras custom loss function,I have this unconventional use case where I need to calculate a recursive mean in a custom loss function in Keras. Recursive mean is calculated as (I wished there's mathjax) $m_t = m_{t-1} + (x_t - m_{t-1}) / t$. So I've hacked up a solution where I create tf.Variable outside of the model like so: and I get the following error: Any idea how I can have states in the loss function?,https://stackoverflow.com/questions/64388497,1272975.0,1
1081,56175959,Tensorflow: 3D tensor and 2D matrix multiplication,"When passing a 3D tensor through a dense layer, I have seen implementations in the following way: On the other hand, I have seen this as well: Although the two approaches should essentially be the same, I can't get the same result with the first and the second approach even though I am also setting both random seeds(I have omitted them from the code snippets for readability). Can someone point me in the right direction in case I am missing something? Looking forward to you answers!",https://stackoverflow.com/questions/56175959,3987085.0,1
1082,61872515,Tensorflow: Why does Modulo (i.e. tf.math.floormod) not support unsigned integers?,From the Docs: Example:,https://stackoverflow.com/questions/61872515,6920649.0,1
1083,52995453,"How to plot training error , validation error and prediction accuracy over training progress in tensorflow?","I am running Vanilla RNN code on tensorflow in google colab. I want to plot training error, validation error and prediction accuracy over training progress without using tensorboard. I am new to tensorflow. Can anyone please guide me. Here is a part of my code What changes should I make in the code to get the plots?",https://stackoverflow.com/questions/52995453,8547664.0,1
1084,55688621,How to apply mask to a tensor and keep its original shape,"I have two tensors: one containing data and the other mask of boolean values. I would like to set all values in data tensor to zero, if boolean values are False, while keeping the original shape of data tensor. So far I can achieve it only while mask is a numpy array. Since https://www.tensorflow.org/api_docs/python/tf/boolean_mask influences shape of the tensor, I cannot use it. How to do that?",https://stackoverflow.com/questions/55688621,1435046.0,1
1085,48353821,"Predicting values with Tensorflow neural network, after training it","So, I've managed to train a neural network using Tensorflow. The following code does: Code: So, now I read from another excel file to predict for new input X, using the following code: What I don't understand is how do I predict the new outputs Y for the given X. I've come across many different code solutions, but none seemed to work for me: either because they can't, or I'm not familiar with the tensorflow syntax enough (I believe it's the latter). *Note: I tried different variations of the tf.run() and tf.equal() methods, but I'm missing some of the required parameters.",https://stackoverflow.com/questions/48353821,6650769.0,1
1086,55901810,TX2 GPU not allocating memory properly,"I am trying to run a code on TX2 but the tensorflow code that allocates GPU memory usage seems to be working in a weird manner. Here's the code I have to allocate memory: The weird thing is, when I use 0.0 instead of 0.5, the processing is faster. And when I use 0.9, I get the following error: What's happening here?",https://stackoverflow.com/questions/55901810,4595522.0,1
1087,52175147,What are the 'inputs' and 'outputs' arguments for tf.saved_mode.simple_save()?,"I am moving a trained model to production inference. To do this, I need to save the model so that it (and/or the checkpoints) can be changed at runtime from production run to production run. Moveover the shapes of the input and output shapes of the model can change from run to run. So I am looking at tf.saved_model.simple_save: If I run inference production code like: Then how do I determine what to enter for inputs and outputs for: ie What are the 'inputs' and 'outputs' arguments for tf.saved_mode.simple_save()? I am running debugging sessions in PyCharm if that's relevant.",https://stackoverflow.com/questions/52175147,1637126.0,1
1088,59049360,ValueError: Attempt to convert a value Tensor,"I am trying to prepare my.CSV file for deep learning. currently, I am trying to read data from the CSV file. but got an error that cant understand. Any help appreciated. Thanks",https://stackoverflow.com/questions/59049360,11396830.0,1
1089,59380518,How to run tensorflow retrain.py from other script?,"I am writing a script to automate a training using the main() function in the tensorflow retrain.py. This script is normally called from the shell with parsed arguments. In retrain.py: I understand that tensorflow usually handles the FLAGS argument as global variable, but I don't understand how this variable is set as global, since in the code snippet, FLAGS should be an argparse.Namespace object. However, I've tried to define the FLAGS variable manually in my own script: And always get the error AttributeError: 'NoneType' object has no attribute 'summaries_dir'. How should I run the retrain.py from my script?",https://stackoverflow.com/questions/59380518,11258538.0,1
1090,53122412,AOT compilation of an Estimator,"I find it very challenging to find in the documentation any help on this important issue.. Indeed, after creating an estimator (canned or custom), one wants to tf.compile the resulting predictor, produce the .so and link it to one's project.. So I have my calib class in which I define a simple linear estimator After training, I want to 1- get the trained model with optimal parameters (load it in my variable self.model) 2- extract the graph and freeze it 3- tf.compile that graph I could not find any way to do parts 1- and 2-. Once I have them, part 3 is solved by using tf.compile Can you please point me to a good way to it?",https://stackoverflow.com/questions/53122412,886724.0,1
1091,56386913,Dimensions Mismatch during Clone Model step of Final Export of Estimator,"I'm creating a Tensorflow Estimator from a Keras model. Currently, the estimator is created, the model is trained, and the model is evaluated without issues. However, on the last evaluation, the model is exported because I use the FinalExporter API, and I get a dimensions mismatch error: It appears that the issue occurs when the Keras model has clone_model called on it before export (the traceback below shows this). However, the dimensions mismatch error seems to imply I have an issue with my input pipeline, which doesn't make sense to me since I don't understand how my model can even train and evaluate without issues if the format of the input functions is incorrect or if my input pipeline is broken somewhere else. The full traceback is below: Any help would be greatly appreciated. Thank you!",https://stackoverflow.com/questions/56386913,5059570.0,1
1092,75295445,"Efficient way to create a ""rolling window"" type grouping in TensorFlow","Imagine you have an n-dimensional tensor where one of those dimensions corresponds to time. What I'd like to do is: given some integer window_size, I'd like to replace my time dimension with two new dimensions, [..., n_groups, window_size]. Where n_groups is representative of all posible groupings of size window_size across the time dimension. So if we started with a time dimension of size n_periods, then n_groups should end up being n_periods - window_size. All of this is very easy to accomplish using traditional ""pythonic"" looping and slicing, such as: However, if the time dimension is very long, this produces a staggering number of graph operations. I am wondering if there isn't a built-in TensorFlow function that might help me accomplish this relatively simple task more efficiently... So common is the idea of ""rolling-window grouping"" that the Pandas project has a very sophisticated and sizeable API to handle this particular case. I would have thought that TensorFlow would also include such a utility.",https://stackoverflow.com/questions/75295445,8036542.0,1
1093,62389114,What does mean_squared_error translate to in keras,"while looking at tensorflow examples online , i'm seeing this I was trying to re-write this line so that it uses objects rather than string literals So far i'm able to For mean_squared_error we have keras.losses.mean_squared_error(y_true, y_pred) I'm unable to understand y_true, y_pred and what values needs to be provided for the example above. In summary, from example above what is equivalent of",https://stackoverflow.com/questions/62389114,260298.0,1
1094,36251165,Tensorboard not listing any event,Running Tensorflow and Tensorboard on docker here. I was trying to write the simplest code to just demonstrate how tensorboard may work: I then ran tensorboard --logdir={absolute path to log/test_logs} but no event was listed there. Is there anything I should have written differently in the code maybe? Note that log/test_logs does contain files like events.out.tfevents.1459102927.0a8840dee548.,https://stackoverflow.com/questions/36251165,278191.0,1
1095,70544894,"Python TensorFlow Error - Op needs to be operation [[1], [0]]","I have made a function that converts variables like tuples, strings, and integers to a TensorFlow tensor and I am trying to convert said variables to a tensor in a function initializeTheory in a variable named lengthMatrix from a class named createNewTheory. I am getting a error named TypeError: op needs to be an operation [[1] [2]], I have tried to convert it to the same dtype as the one found in convToTfTensor down below, tried to switch the dtype to see if that would change anything, tried to set the operation in the lengthMatrix variable to be a singular integer, and I have also tried to look at other posts about similar problems such as this one but I have not found any that are specific to my problem. Here are some links to a few posts that I had looked at that do not fit within the bounds of my problem: Tensorflow - Can't convert Operation to Tensor What does tensorflow ""op"" do? Here is the error that I am getting when I run the script in it's entirety: Here is the code that I am trying to run: convToTfTensor Function inside of utilityTheory.py: createNewTheory class with the initializeTheory function inside of it, also appart of utilityTheory.py: What could I be potentially missing here, any help would be greatly appretiated thank you!",https://stackoverflow.com/questions/70544894,16556045.0,1
1096,39706197,What does 4d tensor mean in Tensorflow?,"I need to perform convolution along the text line of fixed size. So essentially, a training example is of a form: 1*N_FEATURES where N_FEATURES is equal to 3640 (140 characters encoded as one-hot, so 40*26=3640). I am trying to make sense of the example here, precisely: I do not understand why in this line: we have : [WINDOW_SIZE, 1] and not [1, WINDOW_SIZE] ? Since as far as I understand, convolution should be performed as following: and so on, each window of size [1, WINDOW_SIZE] since its height is 1, and width is 3. But why does the example given says "" features = skflow.ops.conv2d(X, N_FILTERS, [WINDOW_SIZE, 1], padding='VALID')""?",https://stackoverflow.com/questions/39706197,2542738.0,1
1097,72386845,Get predictions from Tensorflow Serve SavedModel,"I have a SavedModel that I've managed to load. With the command saved_model_cli show --dir &lt;model_dir&gt; --all I get the following output: I'm trying to run the model to get a prediction, but for some reason I keep getting an error: I have discovered that this error is defined in the struct2tensor package but unfortunately I don't see how I can fix it. The way in which I am preparing my input and calling the model is the following: I'm not sure if this is the right way. I've tried many approaches (like loading the whole row, aoncerting it to a string, and then making it into a tf.Tensor) but I still get the same error.",https://stackoverflow.com/questions/72386845,2262377.0,1
1098,55865891,Optimise function for many pseudodata realisations in TensorFlow 2,"My end goal is to simulate likelihood ratio test statistics, however, the core problem I am having is that I do not understand how to get TensorFlow 2 to perform many optimizations for different data inputs. Here is my attempt, hopefully, it gives you the idea of what I am trying: Output: In the end I want to compute the test statistic and show that it has a chi-squared distribution with 5 degrees of freedom. I am new to TensorFlow so perhaps I am doing this entirely wrong, but I hope you get the idea of what I want. Edit: So I played around a bit more, and I suppose that TensorFlow simply doesn't perform optimizations over the input tensors in parallel like I assumed. Or perhaps it can, but I need to set things up differently, i.e. perhaps give it a tensor of input parameters and a gigantic joint loss function for all the minimizations at once? I also tried doing things with a simple loop just to see what happens. As predicted it is pathetically slow, but I also don't even get the right answer: The output is not a chi-squared distribution with DOF=5. Indeed the test statistic often has negative values, which means that the optimized result is often a worse fit than the null hypothesis, which should be impossible. Edit 2: Here is an attempt at the ""monster"" solution where I minimize a giant network of different input variables for each pseudodata realization all at once. This feels more like something that TensorFlow might be good at doing, though I feel like I will run out of RAM once I go to large sets of pseudo-data. Still, I can probably loop over batches of pseudo-data. Unfortunately I now get the error: which I suppose is a basic sort of error. I think I just don't understand how TensorFlow keeps track of the derivatives it needs to compute. It seems like things work if I define variables inside the loss function rather than outside, but I need them outside in order to access their values later. So I guess I don't understand something here.",https://stackoverflow.com/questions/55865891,1447953.0,1
1099,62847194,Why there is difference in Dense layer input_shapes while fitting and predicting model?,"I am learning TF and trying to implement following code So in Dense() layer my input_shape is (4,) then why does this model.predict(np.array([4,5,3,2])) not work? And model.predict(np.array([4,5,3,2])[None]) this works? If the mentioned input_shape is (4,) then while predicting why does it need (1,4)? Thanks",https://stackoverflow.com/questions/62847194,3516936.0,1
1100,36875498,TensorFlow: Hadamard Product:: How do I get this?,"Tensorflow has the function: Which multiplies two vectors and produces a scalar. However, I need to do the following: However, there is nothing I can set softmax_weight_variable to in order to accomplish this with a matrix multiplication. I need to use the ""Tensor Product"" (also called ""Outer Product""...) but this function doesn't seem to be implemented. How do I implement a Hadamard (element-wise) multiplication and Outer Product in TensorFlow?",https://stackoverflow.com/questions/36875498,3834415.0,1
1101,61720555,"Handling text data with Tensorflow 2 ""ERROR: Attempted to pad to a smaller size than the input element""","I'm getting this error while iterating through a tokenized text dataset: It probably stems from the fact that I simply cannot understand the padded_shapes=([None], (1,)) argument. Here's the dataset and the code: How can I deal with this?",https://stackoverflow.com/questions/61720555,10908375.0,1
1102,56093388,What does the kernel_regularizer parameter in a tf.keras.layers.Layer actually implement in terms of the loss function being optimized?,Consider the following model built using the tf.keras API where I used kernel_regularizer=tf.keras.regularizers.l2(l2) at the penultimate layer just before the sigmoid layer for binary classification. What exactly does the kernel_regularizer parameter in a tf.keras.layers.Layer actually implement in terms of the loss function being optimized? Is this just adding the regularization penalty i.e. to the loss function as is traditionally taught? Is it doing that with regards to all the network's weights or just that layer's?,https://stackoverflow.com/questions/56093388,902414.0,1
1103,63519240,how to convert tensor output in to image and save in tensorflow2?,this is function i am using to convert output tensor of my model in to image and save it and i got the below error after running code my model is a neural style transfer model on images,https://stackoverflow.com/questions/63519240,11094002.0,1
1104,47997203,TensorFlow - restore if present,"Is it possible to restore a variable, only if present? What is the most idiomatic way of doing so? For instance, consider the following minimal example: When run twice with the same argument, the program first prints 0\n1 and then 1\n2 as expected. Now suppose you update your code to have new functionality, by adding a z = tf.get_variable('z', initializer=0) after add1 within the persistent scope. Running this again when the old save file is present will break with the following:",https://stackoverflow.com/questions/47997203,1779853.0,1
1105,67496007,how to create the feature column in tensorflow?,"i am working on the feature_column construction following the tensorflow document, but i met some problem, can anyone help me? THX! this my code below: #data is the dictionary of the train dataset #train the estimator and got an error listed below: the list in the valueError is the age_fea, when i delete the age_fea from estimator construction, the valueError lists the the list of gender_fea. as the demo returns an numpy ndarray rather than tensor, i am confused about what to feed into the feature_columns when constructing the model.",https://stackoverflow.com/questions/67496007,15525911.0,1
1106,51588479,How can I use newton or L-BFGS as optimizer?,"I read a example of newton or lbfgs optimizer as follow: but I am confused because it's different from gradient descent optimizer as: My question is CAN I USE THE L-BFGS OPTIMIZER AS BELOW EXAMPLE SHOWED? If the answer is not, how can I use the L-BFGS optimizer at following code?",https://stackoverflow.com/questions/51588479,10119919.0,1
1107,66926798,Different weights for datasets tf.data.experimental.sample_from_datasets,"I run this piece of code: And get the result: That confused me. I thought it should be a downsampling for both datasets a and b. And I should get a result like [1,1,2,2,2] instead of containing all the original elements since it should be 0.2 * len(a) + 0.8 * len(b). Did I misunderstand the weighted sampling?? Thanks in advance!",https://stackoverflow.com/questions/66926798,6187027.0,1
1108,74502661,validation loss goes up and down [variational inference],i was training a mlp through variational inference for a regression task on a small dataset with 1 feature. The nn works and the training loss goes down but the validation loss has random spikes and i do not understand how to avoid them the result of the training is almost always something like this how can i avoid this issue?,https://stackoverflow.com/questions/74502661,3882900.0,1
1109,57418315,Can we change kernel values manually of a trained model?,"I have a trained model, and I want to set some kernels to zero. Normally we get these kernel weights by using kernels = tf.trainable_variables() and then run the session to find the values of these weights. Although it also give us biases and fully connected layer's weights too, but i am specifically interested in convolutional kernels. So if e.g. I have 96 kernels in the first layer and I want to set Kernel# 04, 25, 26, 48, 90 set to zero, so that it can not take part in processing. how it is done? any help please.",https://stackoverflow.com/questions/57418315,2594171.0,1
1110,72874108,how to define create_tf_dataset_from_all_clients() function,"I am trying to make a centralized dataset from a federated one. Data contains path, client_id and label So first I create a clientdata object using a function that accepts the client's id creating clientdata: I expected a dataset with different labels and files but this code is producing a dataset with only one file in it. Is it because I am trying to implement the graph execution method? I tried using a similar function for creating a clientdata object that works for federated settings and produces the expected dataset, but using the same function gives me an error when I try to produce a centralized dataset",https://stackoverflow.com/questions/72874108,11776320.0,1
1111,53409455,"How do I find the output of a tensor and/or op in tensorflow? (or ""tensorflow op.outputs only pointing to itself"")","First things first - this might be a very basic and dumb question, but I've tried many things and searched all over to no avail, so here I am. The problem is the following: I have a tensor, and I'd like to find ""where it leads"" for various reasons. The way to theoretically do this would be to just look at my_tensor.op.outputs, as per documentation and such, but this always seems to point back to my_tensor itself! I've easily gone the other way before, meaning I can get the input tensor by using my_tensor.op.inputs, but for some reason ""outputs"" isn't doing the expected. Here's a simple example: If you tried the above, you'll see you got back to 'a'... Again, running my_sum.op.inputs gives the 'add' op, and running even further back get's us to 'a' and 'b' as expected: But the other way round? No such luck: So what am I doing wrong? I've also tried using the (deprecated) op.values() with no success, and I'm confused because the documentation explicitly states that this should give me the outputs of the op (from https://www.tensorflow.org/api_docs/python/tf/Operation): (I checked that a.op.__class__ is the right class and that I'm reading the correct documentation). (Just to wrap things up, the node_def of the ops also shows no signs of an output field...). Thanks in advance for any advice! Edit (due to Yuxin's answer): Just to clarify, taking the output of the output of the etc. stays put on the same tensor. I'm trying to reach the next tensor/op. P.S: This is my first stackoverflow question, so if I did anything ""wrong"" let me know and I'll try fix it.",https://stackoverflow.com/questions/53409455,5024514.0,1
1112,73796337,is it possible to create a layer that perform only Pointwise Convolution part of keras.layers.SeparableConv2D,"I created the following CNN model: My intension was that the seperableConv2D layer will create a single 3x3 kernel that will operate separately on each one of the 16 3x3 input images and will result in 16 single numbers. However, the result was that it learned 3x3x16 kernel and resulted in a single number. After reading the explanation regarding Seperable2D in here, I understood that it is training different 3x3 for each one of the channels (which I could live with) but then merges these 16 numbers to 1. My questions are:",https://stackoverflow.com/questions/73796337,20049055.0,1
1113,54902293,Change tf.dataset source at runtime in Tensorflow,"I have two tf.datasets, one for validation and one for training. Every now and again I want to switch the data source so that I can run the validation and check some accuracy measure on it. This blog suggests to use placeholders and feed normal numpy arrays to it. But this would defeat the entire efficiency purpose; As the tf.data API api guide says: So, here is a conceptual example of what I want to achieve: It does not of course has to be done in this exact way! I'd prefer a pytonic/ideomatic tensorflow way, but any way that does not require feeding raw data is great for me!",https://stackoverflow.com/questions/54902293,997253.0,1
1114,56279396,Creating json instance for AI Platform from image for custom neural network,"I recently created a custom neural network with the following code for basic architecture: I've trained the model and now I want to deploy the model on Cloud ML Engine / AI Platform. I used the following code to convert and save the keras model as a Saved Model : However, now I am having trouble creating an instance in order to predict the outputs. The Google cloud website specifies the following format : I have tried using the following code in order to convert the image : But it failed with the following error : Also, I use the following code (keras) for predictions when using the model locally :",https://stackoverflow.com/questions/56279396,8606703.0,1
1115,72280269,Keras custom loss function TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x',"I am attempting to make a custom loss function for a Keras neural network. The network has been tested and works until I attempt to use my new function. Below is the custom loss function. The function is called here: When I run my program I get the following output: I cannot find where or how argument x becomes an int32. As you can see delta is printed as a float32 prior to running the first case statement. I have attempted to explicitly cast both of these as float32 and the int32 still remains. I also tried to instantiate a (1,) tensor of float32 for the constant and produced the same exact error. See that in the snippet below. Any help would be greatly appreciated.",https://stackoverflow.com/questions/72280269,10598777.0,1
1116,47320722,First tensorflow tutorial doesn't work with different training data,"I've recently installed tensorflow on my computer, but I'm confused about some results I'm getting from the first tutorial program. It's a very simple linear regression model that finds W and b for W*x + b = y: result: It works! But then I changed the training data from: to: I should theoretically get W: [~1] b: [~6] loss: ~0, but instead I get: Below is a print of i, W, b, and loss after 10 iterations of training Does anyone know what could be causing this? I'm using Tensorflow 1.4.0 (CPU only) with Python 3.5.2 on Ubuntu 16.04 EDIT: normalizing the data helped, thanks!",https://stackoverflow.com/questions/47320722,8948686.0,1
1117,51899669,Tensor shape does not make sense to me after using `batch()` on dataset,"Here is my code to test tf.data.Dataset: The program outputs a shape of [1,10,10] not [3,10,10] which totally makes no sense to me. Anyone can help to explain this ? Thanks!!",https://stackoverflow.com/questions/51899669,5200092.0,1
1118,70051186,how to build TensorFlow input pipelines for images and their coresponding label,"I would like to create an image generator with their labels. First, import data from csv and then map 43 classes using this code: The output will be something like this: Then will load images from directory using: Now I map the labels from csv file using: Now when I want to show each image with its corresponding label I cannot. I used this code: When I run the show_img it shows images, but the labels are all 0.",https://stackoverflow.com/questions/70051186,7155334.0,1
1119,70746095,"Tensorflow MirroredStrategy halves the 2nd dimension, though shape in the object remains right","I've recently tried to use MirroredStrategy for training. The relevant code is: dataset print is: which is in the correct dimension, but I get the following error: which is odd, as the documentation says that the strategy will halve the first dimension not the second, it should split the dataset for 2, along the first axis. Does anyone know what is the problem? sidenote: the name of the variable ""feature"" is misleading, it should be label instead.",https://stackoverflow.com/questions/70746095,16563202.0,1
1120,40693159,"Tensorflow, try and except doesn't handle exception","I'm new to tensorflow and I've been stuck at an annoying problem here. I'm making a program that loads image ""raw data"" taken with tf.WholeFileReader.read(image_name_queue) from a tfrecord file and then decodes it with tf.image.decode_jpeg(raw_data, channels=3) and then passes it through a function that vectorizes it. main code read_and_decode function The code is working, but eventually it comes across a bad, non-jpeg file and an error this is raised and the program stops running. error I want to skip these ""errors"". I tried to surround the code with try and except. new code When I run the program again the same error occurs, the try and except doesn't seem to handle the error. How can I handle these exceptions? Also, if you see that I've misunderstood the tensorflow ""structure"" please mention that.",https://stackoverflow.com/questions/40693159,6118414.0,1
1121,62391991,Training a model using a tensorflow dataset,"I am trying to understand this(https://www.kaggle.com/reighns/groupkfold-and-stratified-groupkfold-efficientnet) implementation of a ML model by implementing my own adjusted version of it. Using the same data set as in the example, the tf.dataset object is produced using: The model I am trying to learn with is: I am getting the following error when I attempt to train however: And I am training as: This seems to be something to do with the training data input format. Currently this is a tensorflow Tensor, which is produced using the functions decode_image and data_augmentation. I think the error is arising since some np array method is being called on the input. However, when I try to change the code in the decode and augment functions, then the Tensor speed-up is lost. Is there any quick way to fix this?",https://stackoverflow.com/questions/62391991,10311645.0,1
1122,61534670,How is the Model Made in Tensorflow Using Graph,I am trying to understand how the following model is made in the tensorflow. I am more used to seeing multilayer perceptrons made using Tensorflow.kera.Sequential(). If someone can explain how the model is created or how to find out more about its architecture - something like model.summary() - I would really appreciate it. Thanks! source: https://github.com/github/CodeSearchNet/blob/master/src/models/model.py The entire definition of the class can be found in the link above.,https://stackoverflow.com/questions/61534670,8333833.0,1
1123,52154245,Tensorflow - Create an operation conditionally on one of its placeholder value,"Let's say I have an operation multiply_square that multiplies the squared value of two placeholders xand y I want to define this operation conditionally on some particular realization of y. For instance I want to create the operation square, imposing y=1 by doing something like the following: which now only depends on x (and returns the square of x). I'd then be able to run the following command: without Tensorflow complaining that I haven't specified a value for y. I know this is easily achievable when x and y are tf.Variable (using tf.assign). Is there anyway to do that with placeholders (and without using eager execution)? Also, I would like for the solution to be independent of how the graph is build as I want to implement such a method in some already existing code. The motivation behind this toy example is the following. I want to design a scalar loss that writes like: where both f and g are functions of x and y but g is partially evaluated at y=z. Now I want to evaluate or optimize loss while feeding it some values for its placeholders x and y while having y still evaluated to z in the second part of the loss.",https://stackoverflow.com/questions/52154245,10251792.0,1
1124,51889794,How to Let Custom Module Refer to Imported Module on Main Python,"Here's my custom module stored in util.py that wrapps up 3-steps what I always gone-through to read images when using tensorflow But this is quite inefficient to deal with lots of image load since it generally calls import tensorflow as tf everytime I read ""single image"". I'd like to let this function to inherit tf command from the main.py's tf where the load_image actually imported into. Like..",https://stackoverflow.com/questions/51889794,8889050.0,1
1125,53815562,How to use TensorFlow tf.print with non capital p?,"I have some TensorFlow code in a custom loss function. I'm using tf.Print(node, [debug1, debug2], ""print my debugs: "") It works fine but TF says tf.Print is depricated and will be removed once i update TensorFlow and that i should be using tf.**p**rint(), with small p. I've tried using tf.print the same way i would tf.Print() but it's not working. Once i fit my model in Keras, i get an error. unlike tf.Print, tf.print seems to take in anything **kwargs, so what am i suppose to give it? and unlike tf.Print it do not seem to return something that i can inject into the computational graph. It's really difficult to search because all the information online is about tf.Print(). Can someone explain how to use tf.print()? Edit: Example code",https://stackoverflow.com/questions/53815562,905423.0,1
1126,60102214,Tensorflow Keras modify model variable from callback,"I am trying to modify a non-trainable model variable from a callback on beginning of each epoch. Essentially I would like to have a mechanism similar to the learning rate scheduler (which has built in infrastructure in TF) but applicable to an arbitrary model variable. The code below is a minimum example to show the concept. I am trying to modify the decay variable but it does not work. Apparently the initial value of the variable (1.0) is treated as a constant and folded by the graph and never looked at again as training progresses even though the variable seems to be properly modified (to 0.5) by the callback. @nbro: Here you go. The code below is what worked for me. I use a teacher forcing protocol and the per-epoch decay variable is used to ""lower teacher's voice"" as training progresses.",https://stackoverflow.com/questions/60102214,12852002.0,1
1127,59926356,"ValueError: Dimensions must be equal, but are 3 and 3072 for 'loss/output_1_loss/mul' (op: 'Mul') with input shapes: [?,3], [?,3072]","I have an error in my codes, and I've done read the documentation but it still error, what is mean about dimensions must be equal? But actually I've done adding some layers in my code model.fit() This is my code : and the error : How to solve it?",https://stackoverflow.com/questions/59926356,12789359.0,1
1128,56913304,Differentiating a trained simple neural net with tensorflow gives the wrong result and changes model weights,"I am trying to teach a neural net a simple function (f(t) = 2t) and then compute derivative with respect to input (df/dt = 2). I use a net with one dense layer and no activation: My data consist of pairs t -&gt; f(t), where t is chosen randomly on [0, 1] to compute df/dt of my net I found this code: https://groups.google.com/forum/#!msg/keras-users/g2JmncAIT9w/36MJZI7NBQAJ and https://colab.research.google.com/drive/1l9YdIa2N40Fj3Y09qb3r3RhqKPXoaVJC This is my full code on colab: I believe my model performs a simple w*t + b transform, so its derivative should be just w. But the code I found provides wrong results and breaks trained weights. I actually think it resets them to initial weights because if I initialize dense layer weights with kernel_initializer= ""ones"", the code returns 1 as a derivative. So, I need help with correct derivation of neural net.",https://stackoverflow.com/questions/56913304,6557037.0,1
1129,42419837,Tensorflow tf.matmul example is incorrect?,"I read the official document for tf.matmul and I understand the first example. It is a simple [2,3] x [3,2] operation: However, the second example seems very strange : Why the matrix with shape [2,2,3] is allowed to multiply with [2,3,2] ?",https://stackoverflow.com/questions/42419837,7611906.0,1
1130,65140446,train keras applications from scratch in tensorflow 2,"For benchmarking different Frameworks, I want to train a inception v3 network from scratch. Here the code snippet to build the model: according to the official keras website, the argument weight=None , means a random initialization. Does this mean that I am training my network from scratch? If not, how is it possible to train the nerwork from scratch?",https://stackoverflow.com/questions/65140446,12435064.0,1
1131,55544225,How to get the tensor of a layer from the name,"In order to re-use some hidden layers of a DNN model, I would like to get the tensor of a hidden layer Here I have a simple example of what I want to do: In the get_tensor_by_name function if I give X instead of hidden1 it works but not with hidden1. I also to call the get_tensor_by_name after running the training (not shown here). TensorFlow is reporting that the operation, hidden1, does not exist in the graph. What am I doing wrong? How am I suppose to get a hidden layer in order to re-use it?",https://stackoverflow.com/questions/55544225,4584515.0,1
1132,60412616,Repeat_elements function to repeat columns of tensor,i've read documentation https://www.tensorflow.org/api_docs/python/tf/keras/backend/repeat_elements?hl=ID the problem is the result is not what i expected the result i really want is how to do this ?,https://stackoverflow.com/questions/60412616,11114048.0,1
1133,45399907,How do I convert my basic feed-based TensorFlow code to use 'Dataset'?,"I understand that there are advantages (especially as I expand the scope of the models I build and the size of the datasets they work on) to using TensorFlow's new Dataset as the idiom for my data feeding pipeline. However I'm having trouble mapping my existing feed_dict based code to this new model. One problem I face is that I can't sort out how batching and epochs interact, or how these interleave with the logging and validation that I often do. For example, how does something like the following map to using Dataset? Some of the less obvious definitions for the above, if needed:",https://stackoverflow.com/questions/45399907,656912.0,1
1134,42911120,Dice/Jaccard Coefficient Optimization in Tensorflow,"I am trying to optimize my network with either Dice's or Jaccard's coefficient. My issue is an image segmentation problem so my output is a tensor of shape (1, 256, 256, 11). In order to calculate the intersection of my output and the truth image I take which returns a datatype of ""int"" which tensorflow optimizers (specifically AdamOptimizer) don't seem to take so I then convert this to a float with However, it doesn't seem as though there is a gradient defined for tf.cast (or tf.argmax for that matter). Has anybody been able to sucessfully implement",https://stackoverflow.com/questions/42911120,3451457.0,1
1135,58127059,How to understand masked multi-head attention in transformer,"I'm currently studying code of transformer, but I can not understand the masked multi-head of decoder. The paper said that it is to prevent you from seeing the generating word, but I can not unserstand if the words after generating word have not been generated, how can them be seen? I try to read the code of transformer (link:https://github.com/Kyubyong/transformer). The code achieved mask is shown below. It uses the lower triangular matrix to mask, I can not understand why.",https://stackoverflow.com/questions/58127059,12128213.0,1
1136,48977277,TensorFlow train batches for multiple epochs?,"I don't understand how to run the result of tf.train.batch for multiple epochs. It runs out once of course and I don't know how to restart it. I think this is confusing because I'm not really building an input pipeline since my input fits in memory, but yet I still need to be building out batching, shuffling and multiple epochs which possibly requires more knowledge of input pipeline.",https://stackoverflow.com/questions/48977277,1339987.0,1
1137,43302762,"What does the '2' in ""Ran 2 tests in 0.016s"" mean?","I am running the tensorflow unit test, but I do not know the meaning of '2' in the output of test. The output is ""Ran 2 tests in 0.016s"".",https://stackoverflow.com/questions/43302762,7602053.0,1
1138,43404588,Target function of Gradient Descent in Tensorflow,"When using a neural network to construct a classifier ,I used the GD,but it seems I didn't understand it well. what's the difference between the two implements of target function about Gradient Descent where D is a classifier while X is labeled 1 and Y is labeled 0. example 1: example 2:",https://stackoverflow.com/questions/43404588,7819168.0,1
1139,58854501,Adding two numbers by using Tensorflow 2 and Python 3.7?,Running the following simple code: gives this error: RuntimeError: The Session graph is empty. Add operations to the graph before calling run().,https://stackoverflow.com/questions/58854501,12291567.0,1
1140,58142567,Streaming NumPy data as input to Tensorflow,"I was reading https://www.tensorflow.org/guide/datasets to look for a solution to stream NumPy arrays stored in npz files, which may be too large to fit in memory. This snippet is provided in the documentation: Does this method really allow you to stream NumPy data? Doesn't features = data[""features""] load the data entirely into memory?",https://stackoverflow.com/questions/58142567,11876924.0,1
1141,39664120,TensorFlow's perceptron gives unexplaineble output,"I'am new to TF: I took perceptron's code from this tutorial on MNIST(actually, its not necessary to follow this link) :https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/multilayer_perceptron.py I wanted to remake those perceptron to a perceptron with 1 layer and linear activation function, to make it the most simpliest form of : output =w2(w1*x+b1)+b2. But this is what i get: Data: X_train: array([[ 10.], [ 10.], [ 11.], [ 6.], [ 8.], [ 9.], [ 22.], [ 14.], [ 6.], [ 8.], [ 11.], [ 9.], [ 13.], [ 7.], [ 13.], [ 7.], [ 13.], [ 11.]]) y_train: array([[ 44.5825], [ 53.99 ], [ 52.4475], [ 37.6 ], [ 38.6125], [ 39.5875], [ 43.07 ], [ 74.8575], [ 34.185 ], [ 38.61 ], [ 34.8175], [ 36.61 ], [ 34.0675], [ 37.67 ], [ 49.725 ], [ 79.4775], [ 50.41 ], [ 51.26 ]]) X_test: array([[ 6.], [ 14.], [ 14.], [ 12.], [ 13.], [ 13.]]) y_test: array([[ 55.75 ], [ 33.035 ], [ 38.3275], [ 39.2825], [ 50.7325], [ 45.2575]]) Parameters: Perceptron model: Let's build the graph: Finally, let's run the session: And now, we get the output: The most confusing thing is the output(first number)! It should be somewhere in range of [30; 50]! Please, explain me, where did i do wrong.",https://stackoverflow.com/questions/39664120,,1
1142,58567446,get_weights is slow with every iteration,I'm computing gradients from a private network and applying them to another master network. Then I'm copying the weights for the master to the private (it sounds redundant but bear with me). The problem is that with every iteration get_weights becomes slower and I even run out of memory. This is the function that uses get_weights. Looking around I found a post that suggested using at the end of the while block (at the !!!!!! segment) because somehow new nodes are being added (?!) at the graph. But that onle returned an error: Is there a faster way to transfer weights? Is there a way to not add new nodes (if that is what is indeed happening?),https://stackoverflow.com/questions/58567446,6405137.0,1
1143,47613730,Why is there no implicit control dependency when requesting the value of a variable with `sess.run`?,"I want to understand if there is a reason for the following behavior which can be reproduced with the code snippet below. When I request sess.run to return the value of a Variable, the value it returns does not depend on all operations that might update the variable being performed before returning it. In the example here I'm testing the dependencies applied to copying the value of variable a into b before re-assigning a with a random value. The process works, but the results of the first print statement are arbitrary (depending on arbitrary processing order), the results of the 2nd print statement are correct. I would naturally expect that the value returned for tensors a and b are the variable's values at the END of all computations, but this is not the case. Is there a good reason for NOT including an implicit control dependency on variables that are requested as part of sess.run? Results below. Notice that the values of a, and b are different between calls to sess.run though they don't change. This demonstrates that tensorflow doesn't guarantee the return value of a Variable be the last thing computed before return.",https://stackoverflow.com/questions/47613730,4790871.0,1
1144,39418948,tf.image.rot90() gives error when parameter k is a tensor,I am trying to introduce a random 90-degree rotation to images as part of a training data pipeline. However when I try to populate the k parameter of tf.image.rot90() with a scalar tensor I get the following error: TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;. The function works as expected when k is a python variable. The following demonstrates the problem: Is there a way to set k to a random value as part of the training pipeline? Or is this a bug in tf.image.rot90()?,https://stackoverflow.com/questions/39418948,5587428.0,1
1145,76343894,How can I access model.input attribute after training of tensoflow keras model subclassing?,I defined a tensorflow model using model subclassing and fed the input image tensor through a for loop in the call method. But I am not able to access the model.input attribute after the model is built. A sample of the model is shown below: Here is the what the erro looks like;,https://stackoverflow.com/questions/76343894,13711721.0,1
1146,51359731,Tensorflow While loop with Variable Creation,"Tensorflow While loop with Variable Creation Code here : So, I want to do that in while loop in tensorflow as: How can I achieve this in tensorflow. Thanking you",https://stackoverflow.com/questions/51359731,4087952.0,1
1147,70220813,How to change batch size in VGG16?,"How do I change the batch size in VGG16? I'm trying to address an issue of exceeding memory constraints by 10% by doing this. Error: Here is my code: I tried changing model.predict to: but it doesn't appear to have any impact in trying to resolve the issue I tried using: but that did not help I ran and then installed normal tensorflow via but that did not help Just fyi, I'm getting the same error with all of these attempts so far. As suggested I tried: But I now get the following error: I know I didn't do it exactly as instructed, but it was throwing an error so I followed this suggestion I corrected the error by making the following change: But now I get the error: I think this can be resolved by trying multiple scales, is that correct? So I have been addressing the issues one-by-one and the first issue was my lack of installation of cudnn. I followed these instructions to do that. Additionally, I corrected my code as the latest suggested said. So now my code looks like this: For anyone checking in the future, please note that this code does not handle the case in which the scale reaches below 0. That should explicitly be handled in the code. I will post the final results when I get this working properly. So when I run the code as suggested I get the following error: I changed to and got the following error:",https://stackoverflow.com/questions/70220813,16988242.0,1
1148,65231630,Understanding average (sum) pooling padding in keras,"I have a simple sum pooling implemented in keras tensorflow, using AveragePooling2D*N*N, so it creates a sum of the elements in pool with some shape, same padding so the shape won't change: After testing it on very simple 2D array I have found out it does not do what I expect (original and pooled data): You can see that the single one sum-pooled (according to average pooling) ended up with sum greater than real sum, which is 1, near the borders. (in this case max can be used, but the real data are more complex and we need sum) This would mean that average near borders is count not from padded data but the original. Or is this misunderstanding of padding from my side? I need to have ones on indices where 1.1, 1.2, 1.4 is. Why is this and how can I solve such problem? Note that I do not want to manually set the correct sum, so I am looking for a way to achieve this in keras pooling itself.",https://stackoverflow.com/questions/65231630,3157428.0,1
1149,46204466,Saving and Restoring a model using tensorflow,"I saved parameters of my neural network using this: Now I have these 3 files in my disk: I tried something like this: I received the message: However, I am not able to restore the original parameters. I tried something like this (inside the with tf.Session() as sess) w_h1 = tf.get_default_graph().get_tensor_by_name(""w_h1:0"") but I receive the message However, I am not able to recover the weights. How can I do that? I used to know what had been saved and I realized that it saved a lot of stuff (just a sample below), but I though that I have saved only a small number of important parameters:",https://stackoverflow.com/questions/46204466,2065691.0,1
1150,73050688,How do I implementing Dice loss in a Tensorflow segmentation model?,"I am new to TensorFlow, and I am trying to implement dice loss to my Image Segmentation model. The problem is, that all the tutorials I am getting are only showing what the function looks like. ie. But none of them is showing me how it can actually be called in the model. i.e: I have tried the code below but obviously, I don't have the variable target in my code: My question is, how do I call it and which parameters do I pass it?",https://stackoverflow.com/questions/73050688,12601926.0,1
1151,43170017,Linear regression with tensorflow,"I trying to understand linear regression... here is script that I tried to understand: Question is what this part represent: And why are there random float numbers? Also could you show me some math with formals represents cost, pred, optimizer variables?",https://stackoverflow.com/questions/43170017,6342729.0,1
1152,74492503,Load numpy array to a Tensorflow dataset,"I am trying to do image colorization. I have 5000 images (256x256x3) and would like not to load all data in my program (for memory reason). I have found that it is possible to use ImageDataGenerator.flow_from_directory() but I use LAB images and I would like to feed my model with a numpy array of the L component (256, 256, 1). My targets are A and B components (256, 256, 2). To have my image I then merge the input and output to have a LAB image (256, 256, 3). The problem i that ImageDataGenerator.flow_from_directory() only works with image type files (so a 256x256x3 image) and I would like to know if there is a way to do the same thing with numpy arrays. I tried using tf.data.Dataset.list_files(), I had all my files but I did not found how to load my numpy array to feed my model. I guess I need to use some sort of generator but I do not really understand how to use it. This is what I have for now : Output : The shape seems to be correct but I don't know how to have the numpy.array",https://stackoverflow.com/questions/74492503,20520268.0,1
1153,51006462,How to feed a local placeholder?,"I would like to feed a placeholder defined in a function. The following is an simplified example. The graph is correctly created as shown in the following Tensorboard graph. The problem is that feed_dict={x2:2.0} doesn't work, since x2 is a local variable used within the function CreateInference. Could anyone please tell me how to access and feed values for the variable x2 in the above example?",https://stackoverflow.com/questions/51006462,735008.0,1
1154,49874590,Problems when using tf.data.Dataset.batch,"I want to make clear how tf.data.Dataset.batch work with my dataset. The dataset is as follows: Then I use batch method: and iterate the dataset once. As I suppose, the result should be a 2*4 array, but it returns the whole 4*4 dataset. Could anyone give me some details about how to apply the batch method?",https://stackoverflow.com/questions/49874590,9657676.0,1
1155,58233453,Complex numbers ValueError: Attempt to convert a value with an unsupported type to a Tensor,I was using tensorflow 1 to do complex-valued neural networks and was Ok. However I didn't do it on eager mode and now tensorflow 2 is getting on my nerves. Apparently all is keras now so I tried to implement a layer like this: However I get the error:,https://stackoverflow.com/questions/58233453,5931672.0,1
1156,72724458,Representing SHAP values as a percentage contribution in binary problems,"I have a dataset that can be simplified to this: Which I fed into a probablistic algorithm and then a shap Explainer. I'm not really well versed with data processing in general since this is my first project, but what I would like to do is to express ranking and color as a percentage of how much they contributed to the algorithm making the decision of state 1 instead of state 0. Can someone point me towards the right direction in doing so? My first thought was to scale all the values such that the sum of the absolute values of these values add up to 100%, and then adding up the values of ranking-A, ranking-B and ranking-C etc to find the % contribution of the column ranking. Is doing this accurate? Example code: The expected behaviour is that I get the percentage that each column provides during the model's calculation for probablity that a particular entry belongs to state 1.",https://stackoverflow.com/questions/72724458,18445473.0,1
1157,74460032,How to get the mean of each image in a batch?,"I have a batch of images thus the shape [None, 256, 256, 3] (the batch is set to none for practical purposes on use). I am trying to implement a layer that calculates the average of each of the of images or frames in the batch to result the shape [None, 1] or [None, 1, 1, 1]. I have checked to use tf.keras.layers.Average, but apparently it calculates across the batch, returning a tensor of the same shape. In hindsight I tried implementing the following custom layer: but when it is used: I get the result: Which makes it entirely wrong. I also tried this change on the call: Which in turn results to: Which is also wrong.",https://stackoverflow.com/questions/74460032,11505421.0,1
1158,66815863,What is the use of tensorflow backend utilities?,"In order to create custom loss functions, I have seen many people use backend functionality from tensorflow. For example if we want to create custom loss function that takes y_true and y_pred as input and compute square of difference between them. ie MSE Code: Output: Why is the loss function created using backend utilities instead of normal tensorflow utilities? What is the use of backend utilities except for using the function that are not present in normal tensorflow?",https://stackoverflow.com/questions/66815863,9557970.0,1
1159,33633370,How to print the value of a Tensor object in TensorFlow?,"I have been using the introductory example of matrix multiplication in TensorFlow. When I print the product, it is displaying it as a Tensor object: But how do I know the value of product? The following doesn't help: I know that graphs run on Sessions, but isn't there any way I can check the output of a Tensor object without running the graph in a session?",https://stackoverflow.com/questions/33633370,4993513.0,1
1160,49495540,"Error writing TFRecord using TFRecordWriter: ""'tuple' object has no attribute 'SerializeToString'""","I use create_coco_tf_record-script to convert a json file with COCO labels to TFRecords, using the following code: Now the create_coco_tf_record.create_tf_example script runs without errors, but the very last line which is supposed to write the TFRecord using TFRecordWriter throws the following exception: What am I doing wrong? My COCO json file looks like this:",https://stackoverflow.com/questions/49495540,1934212.0,1
1161,75503580,Image classification Using CNN,"I am working on breast cancer classification. I found this online code to train my pre-processed outputs on it. The results was awful but I didn't understand the code, I want to train my own model but I don't how to replace my own code with this one. Any help would be appreciated.",https://stackoverflow.com/questions/75503580,12860924.0,1
1162,70087525,"TENSORFLOW DATASET API: cannot load image ""cannot iterate over a scalar tensor""","im new learning how to use tensorflow and i'd like to know how to plot my images, i tried to convert my tensor to np array but didnt work. My code is: and then i get the error.",https://stackoverflow.com/questions/70087525,17491931.0,1
1163,50653562,"Why does ""tf.constant(tf.random_normal((10, 4)))"" cause an error?","In the following code, ""a"" works perfectly fine, and ""c"" also works. But ""b"" causes an error. Could someone explain the reason?",https://stackoverflow.com/questions/50653562,735008.0,1
1164,47922359,Multiple sequential Tensorflow operations in same Session.run() call,"As the title suggests, I want to run multiple Tensorflow operations in the same Session.run() call. Specifically, to make the problem more concrete, suppose I want to run multiple training iterations in a single call. The standard way of doing that with multiple Session.run() calls would be something like this: However, this of course will have some overhead because we are making multiple session calls. I assume that we could remove some significant overhead by somehow grouping the operations. I assume that either the group or count_up_to are what I should be using, but I cannot find any examples demonstrating how to use them for this case. Could somebody please point me in the right direction? The ultimate goal is to define some compound operation that would run N iterations in a single call, so that the above could be transformed to something like this: EDIT:: As musically_ut points out, I could indeed chain the opertions together by forcing the problem to have feed dictionaries. But that feels like a solution to one very specific problem. My overall concern is how to sequentially execute operations in a single session run. I can given another example why you would want this.... Suppose now that in addition to wanting to run my optimizer, I want to retrieve the optimized values, let's say these lay in the variable X. If I want to optimize AND get the optimized values, I could try to do something like this But in fact this will not work because the operations (optimizer,X) do not run sequentially. I fundamentally need to have 2 session calls: The question is how one can combine these two calls into one.",https://stackoverflow.com/questions/47922359,3309610.0,1
1165,40267573,shape of a sparse tensor without invoking run(),"sparse tensor.shape method returns a tensor object which seems to be of no use to extract the actual shape of the sparse tensor without resorting to run function. To clarify what I mean, first consider a sparse tensor: a = tf.SparseTensor(indices=[[0, 0, 0], [1, 2, 1]], values=[1.0+2j, 2.0], shape=[3, 4, 2]) a.shape returns: tf.Tensor 'SparseTensor_1/shape:0' shape=(3,) dtype=int64 This is kind of no use. Now, consider a dense tensor: a = tf.constant(np.random.normal(0.0, 1.0, (4, 4)).astype(dtype=np.complex128)) a.get_shape() returns: TensorShape([Dimension(4), Dimension(4)]) I can use this output and cast it into a list or tuple of integers without ever invoking run(). However, I cannot do the same for sparse tensor, unless I first convert sparse tensor to dense (which is not implemented for complex sparse tensor yet) and then call get_shape() method on it, but this is kind of redundant, defeats the purpose of using a sparse tensor in the first place and also leads to error down the road if the input sparse tensor is complex. Is there a way to obtain the shape of a sparse tensor without invoking run() or converting it to a dense tensor first?",https://stackoverflow.com/questions/40267573,5434483.0,1
1166,50653999,Tensorflow matrices broadcast,"In tensorflow, I tried to add two matrices. One is 3 x 3 matrix and another is 3 x 1 matrix, so I expected that the latter matrix was broadcasted. But the result wasn't what I expected. Could you explain what kind of calculation is executed in below code? The result is below.",https://stackoverflow.com/questions/50653999,4656998.0,1
1167,51847618,Tensorflow: Differentiable Primitives,"I was under the impression that all tensorflow primitives are differentiable. Under this ""illusion"" I wrote this function in the hopes that tensorflow will just automatically differentiate it and I can backprop erros through it. Rank-weight function: Unfortunately the function works as expected in the forward pass but does not work in the reverse pass because the derivative does not exist (from the error I keep getting). The function is explained in the attached image: I have the following questions: 1: Why can't I take the derivative of the function above. 2: If it is an implementation issue, can you suggest how I can rewrite it so I can take its derivative and backprop errors through it? 3: Are all tensorflow ops differentiable?",https://stackoverflow.com/questions/51847618,8738553.0,1
1168,55368272,"How do you index a RaggedTensor along the ragged dimension, in TensorFlow?","I need to get values in a ragged tensor by indexing along the ragged dimension. Some indexing works ([:, :x], [:, -x:] or [:, x:y]), but not direct indexing ([:, x]): The documentation explains why this fails: This makes sense, but how do I actually implement options 1, 2 and 3? Must I convert the ragged array into a Python array of Tensors, and manually iterate over them? Is there a more efficient solution? One that would work 100% in a TensorFlow graph, without going through the Python interpreter?",https://stackoverflow.com/questions/55368272,38626.0,1
1169,59352090,How can I wrap tf.io.parse_single_example with tf.py_function?,"First, I was wondering if I should wrap tf.io.parse_single_example with tf.py_function when reading TFRecord data from dataset.map, becauseThe tf.data guide mentioned that I tried to wrap with However, running the code gave me the following error: It seems to me tf.py_function(tf.io.parse_single_example(example_proto, features)) is not supported because example_proto is of type tf.string ? The primary reason I might want to do this is because the current input data pipeline is slow. Will I get some performance improvement if I wrap tf.io.parse_single_example with tf.py_function? The above code is run in tensorflow-gpu==2.0 Thank you!",https://stackoverflow.com/questions/59352090,1244177.0,1
1170,66799169,Clipping tensor data to a bounding volume,"I have 2 questions about tensorflow 2.0, with the focus on how tensorflow handles combined conditional tests in it's operations graph. The task: cut up a volume of data points into blocks, and store the indices to the samples that belong to the volume (not the samples themselves). My initial approach: loop all elements and collect the indices of the data points that are inside the 'bounding volume'. This was pretty slow, no matter how I reordered the compares on the coordinates. I then came up with the idea to produce boolean tensors and logically 'and' them to get the indices of the elements I need. A whole lot faster, as shown in the next sample: This code produces the correct result, but I wonder if it is optimal. The first question is about scheduling: Indeed, in the above example c1 and c2 are asking questions on elements that may c0 already excluded from the set. Especially when you have a high number of elements to test, this could be a waste of time, even on parallel hardware platforms So, what if we cascade the tests based on the results of a previous test? Although it seems like a solved problem, this solution is incorrect, because the final indices tensor will refer to a subset _X, not to the total set X: I could of course 'solve' this by simply expanding X, so that each element also includes the index of itself in the original list, and then proceed as before. So my second question is about functionality:",https://stackoverflow.com/questions/66799169,1230621.0,1
1171,63561584,Bayesian Optimisation via HParams and Tensorboard,"I'm currently using HParams to instigate a grid search hyperparameter optimisation session, which works fine, and is outputting logs to my tensorboard HParams plugin, and I can see the various different runs and the Parallel Co-Ordinates view. The code is structured like so, although it might not be necessary to review it for this question: I've done a lot of googling, but I'm still unsure how to go about implementing a more efficient optimisation session, such as Bayesian Optimisation in order to find the optimum model in a faster way. All I want to know is - is it possible to do Bayesian Optimisation within HParams, or do I need to use a different package like Weights and Biases? If it's possible, any advice on where to find an example of such an implementation would be very helpful.",https://stackoverflow.com/questions/63561584,7605543.0,1
1172,55323968,"How to fix ""InvalidArgumentError: Incompatible shapes"" when calling model.fit() in TensorFlow?","As a total TensorFlow beginner, I am attempting to get a semantic image segmentation model working using TensorFlow Keras' functional API and a per-pixel categorical cross-entropy (at least that's the intention): For now, I am simply simulating input data, and I am aware that my annotations are the same for every pixel. I just want to have something training initially. However, when I run this, I get the following stack trace: I am aware it has something to do with my simulated dataset, but I'm not sure what to do next. Any help is greatly appreciated!",https://stackoverflow.com/questions/55323968,,1
1173,49277473,"Custom Keras metric, changing",I am currently trying to create my own loss function for Keras (using Tensorflow backend). This is a simple categorical crossentropy but I am applying a factor on the 1st column to penalize more loss from the 1st class. Yet I am new to Keras and I can't figure out how to translate my function (below) as I have to use symbolic expressions and it seems I can't go element-wise: Can someone help me? Many thanks!,https://stackoverflow.com/questions/49277473,9401788.0,1
1174,55868314,Different behaviour with and without @tf.function,"The following code will not produce ""Fizz"" when the value of i is a multiple of 3: But if one comments the @tf.function decorator out, it works normally for multiples of 3. How come?",https://stackoverflow.com/questions/55868314,7549930.0,1
1175,55749899,Training a simple model in Tensorflow GPU slower than CPU,"I have set up a simple linear regression problem in Tensorflow, and have created simple conda environments using Tensorflow CPU and GPU both in 1.13.1 (using CUDA 10.0 in the backend on an NVIDIA Quadro P600). However, it looks like the GPU environment always takes longer time than the CPU environment. The code I'm running is below. Here are some outputs printed if they're any indicative of what's happening: For the CPU run: For the GPU run: I am about to post another question about implementing CUBLAS in R as well because that was giving me slow speed times compared to Intel MKL, but I'm hoping that maybe there's a clear cut reason why even something as well built as TF (compared to hacky R and CUBLAS patching) is being slow with GPU. EDIT: Following Vlad's suggestion, I wrote up the following script to try and throw some large sized objects and training it, but I think I might not be setting it up correctly because the CPU one in this case even as the size of the matrices are increasing. Any suggestions perhaps?",https://stackoverflow.com/questions/55749899,4975860.0,1
1176,58591562,How can we use lbfgs_minimize in TensorFlow 2.0,I have been unable to reproduce this example from tensorflow having tensorflow 2.0 installed. This is the original snippet: Which does not work with the following error: If I change the code and have gradient tape instead like the following: I also get the following error: In general anything I tried didn't work and I don't know how I can use lbfgs in tensorflow 2.0.,https://stackoverflow.com/questions/58591562,10392393.0,1
1177,49878200,Re-training (fine tune) specific layers of a pre-trained model (saved as ckpt) in TensorFlow,"I am doing my fist steps in TF and I feel that I am confused... I am trying to fine tune (retrain) a pre-trained model that I have downloaded from object detection zoo. More specifically I want to train only the BoxPredictor layers of the ssd_mobilenet_v2_coco: BoxEncodingPredictor (weights+biases) and ClassPredictor (weights+biases). From my understanding I need to do the following steps: The problem is that I am unable to get the var_list and the loss from the graph. in the way I have expected: I am importing the ""ssd_mobilenet_v2_coco"" graph using tf.train.import_meta_graph, like follows: But all variables lists are empty: I also tried different types of variables and all of them are empty. But get_operations() returns variables: How can this be? how can I restore the graph with the trainable variables?",https://stackoverflow.com/questions/49878200,3906284.0,1
1178,48981602,Quantize the variable with slicing assignment in Tensorflow,"I want to do quantization for only some area of variables. More specifically, I would like to perform only on any channel in the convolution layer. This is binarization code: I want to do quantization through the for-loop for a variable area that corresponds to an index. And this is the variable assignment which I found here(How to do slice assignment in Tensorflow): However, as far as I know, once variable is assigned, it is regarded as tensor so that it can not be assigned again. This is the error message after first assignment: Is there any other way to solve this problem? For a more clear question, I've added some print functions. Result:",https://stackoverflow.com/questions/48981602,7718773.0,1
1179,40618560,sharing the parameters when using tf.contrib.layers.convolution2d,"I'm building a neural network, which is processing two sets of images in parallel. I want the two columns to share the parameters. This is what I do. with tf.variable_scope(layer_name) as s: h1 = tf.contrib.layers.convolution2d(inputs = x1, num_outputs = 10, kernel_size = [3, 3], stride = [1, 1], padding = 'VALID', scope = s) h2 = tf.contrib.layers.convolution2d(inputs = x2, num_outputs = 10, kernel_size = [3, 3], stride = [1, 1], padding = 'VALID', reuse = True, scope = s) Is this the correct way to do this? I can't find an example of how to do that correctly when using tf.contrib.layers.convolution2d class.",https://stackoverflow.com/questions/40618560,6780382.0,1
1180,46238408,How to slice a tensor with None dimension in Tensorflow,"I want to slice a tensor in ""None"" dimension. For example, but It is same that i get a message when i used another place_holder to feed size parameter for tf.slice(). The second methods gave me ""Input size (depth of inputs) must be accessible via shape inference"" error message. I'd like to know what's different between two methods and what is more tensorflow-ish way. [Edited] Whole code is below",https://stackoverflow.com/questions/46238408,3731883.0,1
1181,57974040,Error in Keras Lambda layer when wrapped function expects non-float argument,"I want to wrap a tensorflow function in a Keras Lambda layer as per the docs. However, my inputs are complex64. Here is a more complete example of the code i am using to replicate this behavior: which gives the following error: However, if I use the commented line instead: s = Lambda(layer0, output_shape=shape)([z1, z2]) The code runs just fine. It seems that ""output_shape=(...)"" is necessary to make the division in the lambda function work. While this solution solves the problem for a single output variable, it doesn't work when having multiple outputs.",https://stackoverflow.com/questions/57974040,11979471.0,1
1182,51623428,How do I prevent failed to create session error in keras?,"I am new to tensorflow and Keras, below is my code I keep getting the following error after running this code 2018-07-31 19:25:45.099850: I C:\users\nwani_bazel_nwani\mmtm6wb6\execroot\org_tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 2018-07-31 19:25:45.711357: I C:\users\nwani_bazel_nwani\mmtm6wb6\execroot\org_tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1356] Found device 0 with properties: name: GeForce 840M major: 5 minor: 0 memoryClockRate(GHz): 1.124 pciBusID: 0000:04:00.0 totalMemory: 2.00GiB freeMemory: 1.66GiB 2018-07-31 19:25:45.718218: I C:\users\nwani_bazel_nwani\mmtm6wb6\execroot\org_tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1435] Adding visible gpu devices: 0 2018-07-31 19:25:45.722718: E C:\users\nwani_bazel_nwani\mmtm6wb6\execroot\org_tensorflow\tensorflow\core\common_runtime\direct_session.cc:154] Internal: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version Traceback (most recent call last): File ""c:\Users\Seth Siva\Documents\mnist digit recognizer.py"", line 44, in batch_size=32, nb_epoch=10, verbose=1) File ""C:\Users\Seth Siva\anaconda\lib\site-packages\keras\engine\training.py"", line 1042, in fit validation_steps=validation_steps) File ""C:\Users\Seth Siva\anaconda\lib\site-packages\keras\engine\training_arrays.py"", line 199, in fit_loop outs = f(ins_batch) File ""C:\Users\Seth Siva\anaconda\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2653, in call if hasattr(get_session(), '_make_callable_from_options'): File ""C:\Users\Seth Siva\anaconda\lib\site-packages\keras\backend\tensorflow_backend.py"", line 183, in get_session _SESSION = tf.Session(config=config) File ""C:\Users\Seth Siva\anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 1560, in init super(Session, self).init(target, graph, config=config) File ""C:\Users\Seth Siva\anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 633, in init self._session = tf_session.TF_NewSession(self._graph._c_graph, opts) tensorflow.python.framework.errors_impl.InternalError: Failed to create session.",https://stackoverflow.com/questions/51623428,7113212.0,1
1183,68178765,convolutional layer - trainable weights TensorFlow2,"I am using TF2.5 &amp; Python3.8 where a conv layer is defined as: Using a batch of 60 CIFAR-10 dataset as input: Output volume of this layer preserves the spatial width and height (32, 32) and has 64 filters/kernel maps applied to the 60 images as batch- I understand this output. Can you explain the output of:",https://stackoverflow.com/questions/68178765,3616293.0,1
1184,48368096,TensorFlow Python warning in PyCharm - Cannot find reference __version__ in __init__.py,"I'm using the statement within PyCharm, which is found in many of the TensorFlow GitHub examples, like so: This works great, I'm at TensorFlow 1.4.0 currently, if I run this script as above, the error message does not show, and if I change the if statement to, for example, 2.4.0 (which is not out yet of course) then the error shows as expected and the program exits. The problem I'm encountering is PyCharm shows the following warning on the if statement: Here is a screenshot: If I choose the PyCharm light bulb icon, I get these options: none of which are especially appealing. For the moment, I'm choosing the last option ""Suppress for statement"", which adds this line above the if statement My concern here is I'm in the process of writing documentation that many other people will use, some of whom will be using PyCharm and some of whom will inevitably be using a different editor. For this reason, I can't alter any of the TensorFlow __init__.py files, because that would then create a custom install on my computer and anybody following my documentation would see different results on their screen if they are using PyCharm. Further, I'm using pip to install packages so I'm not even sure if this is possible, but even if it is it's still not an acceptable choice. Similarly, I'd prefer not to include a comment line specific to PyCharm since that would cause confusion for those not using PyCharm. I'd really prefer to not disable this inspection entirely since I find PyCharm's warnings very helpful in many circumstances and therefore I'd rather not disable them. Upon Googling on this concern, I found this post. The suggested answers were to either edit an init.py file which I'd rather not do for the reasons mentioned above, or to change the import statement to be to the effect of which does not seem to be applicable in my case since I'm importing TensorFlow entirely with the statement Even if modifying the import statement to prevent this warning is somehow possible I'd still rather not do this as this would cause confusion for non-PyCharm users and would make my examples different than all the other TensorFlow documentation and examples available. At the moment it seems this is the best I can do: Is there something I'm missing here? Any suggestions as to a better way to do this?",https://stackoverflow.com/questions/48368096,4835204.0,1
1185,60585307,"What does "" t[..., :1] "" in below code means?",Here is the context:,https://stackoverflow.com/questions/60585307,13026660.0,1
1186,73997008,Augment a tf.data.Dataset with has image and mask. Both Needs to be augmented,I have a tf.data.Dataset of image paths of image and masks mapping a function to turn paths into images Now How do i Augment it . I do not want to use ImageDataGenerator as tf says Deprecated: tf.keras.preprocessing.image.ImageDataGenerator is not recommended for new code. Note: Both Image and Mask needs to be augmented the same way.,https://stackoverflow.com/questions/73997008,14076425.0,1
1187,72128138,How tensorflow.nn.ctc_loss works in tensorflow 2 and how to use it for handwritting recognition?,I try to create a simple model for handwritting recognition with tensorflow 2.8 based on this keras example but I have trouble understanding how the CTC loss tensorflow.nn.ctc_loss works and how to use it in my code. I use images representing words from the IAM dataset : I tried to reuse the CTCLayer from the keras example : But when I try to construct a model with it I get an error : The error : I also tried to use the tf.nn.ctc_loss function with simple tensors but I do not get how it works. How could I use the CTC loss for my model in this use case ? EDIT : If I remove the CTCLayer this is what I obtain with model.summary() :,https://stackoverflow.com/questions/72128138,7685195.0,1
1188,73148058,shaping tf.Data as input for LSTM layer fails with incompatible dimensions,"I'm trying to build a neural network that predicts the next number from a simple sequence of numbers, thus I'm taking my input of 3 and putting in a tf.data.Dataset, now when I try to feed this to an LSTM layer I get the following error After building the simplest tf.data.Dateset I can image with just 4 samples I try to feed it into a an LSTM which has 64 hidden units, and since the sequence is 3 steps, I'm shaping the input as (2, 3, 1) (batch size=2, steps = 3, features =1), from the data I constructed every dataset tensor will be ((3,1),(1,)) and then when batches, the first layer should receive it's (2, 3, 1) which is not happening? But I cannot see why this would happen for such a simple setup: tf.data.Dataset doesn't have any reshape function, so I cannot follow most of the other answers on SO, what is it missing to fit the input to the LSTM?",https://stackoverflow.com/questions/73148058,53991.0,1
1189,38326578,TensorFlow custom model optimizer returning NaN. Why?,I want to learn optimal weights and exponents for a custom model I've created: The problem is that whenever there is a negative value zero in x the optimizer returns the weight as NaN. If I simply add 0.0001 when x = 0 then everything works as expected. But should I really have to do this? Shouldn't the TensorFlow optimizer have a way to handle this? I've noticed Wikipedia shows no activation functions where x is taken to an exponent. Why isn't there an activation function that looks as below Image? For the above image I'd like my program to learn that the correct exponent is 0.5.,https://stackoverflow.com/questions/38326578,1676118.0,1
1190,46516168,Word2Vec Tutorial: Tensorflow TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x',"Version of Tensorflow: 1.2.1 Version of Python: 3.5 Operating System: Windows 10 Another poster has asked about this same problem on StackOverflow here, and he appears to be using code from the same Udacity Word2Vec tutorial. So, maybe I'm dense, but the code of this example is so busy and complex that I can't tell what fixed his problem. The error occurs when I call tf.reduce_means: Right before the call to tf.reduce_mean the key variables have the following data types. I tried every permutation of data type in the definitions of the variables train_dataset.dtype, train_labels.dtype and valid_dataset.dtype: making them all int64, all float32, all float64, and combinations of integer and floating point. Nothing worked. I didn't try altering the data types of softmax_weight and softmax_biases, because I'm afraid that might foul up the optimization algorithm. Don't these need to be floats to support the calculus that is done during backpropagation? (Tensorflow is often a very opaque black box with documentation that verges on completely useless, so I can suspect things but never know for sure.) Program Flow at Time of Error: After the call to reduce_mean program control transfers to sampled_softmax_loss() in file nn_impl.py which in turn calls _compute_sampled_logits(): At this point I check the data types of the passed-in parameters and get the following: On the very next step an exception occurs, and I am thrown into the StreamWrapper class in file ansitowin32.py. Running to the end, I get the following Traceback: Here's the complete program:",https://stackoverflow.com/questions/46516168,2046923.0,1
1191,48346409,Importing own dataset in TensorFlow,"I am making a neural network using TensorFlow. I now want to import my own images as dataset, to train the neural network on these images. For this, I at first get a list of filenames and their corresponding label. I am doing this with the following code: locations is here a dictionary with the label as key and their folder as value. This works fine: I get a list of the file locations, a list of the labels and a list of which turns the output neuron number in a monkey type. I am then trying to makes from this a TensorFlow dataset. I at first convert the list of the filenames and the labelnames in a TensorFlow constant: I first tried the code on the Tensorflow website. However, I get the error that image contains no shape after decoding an image. How to correctly import images? Further, after making an dataset, I want to loop through it in batches. The MNIST dataset contains a very handy function for it, but is it also possible for custom datasets? Searching for this problems doesn't give me a lot of useful tips.",https://stackoverflow.com/questions/48346409,9198145.0,1
1192,69943995,Invalid argument error with TensorFlow 2 with self-defined loss function (Student t distribution),"This question is a follow-up to the following question that has already been answered, which I would like to formally ask here as a new question. The original question is located here: Invalid argument error with TensorFlow 2 with self-defined loss function, although everything seems to be correct As mentioned, I am currently training TensorFlow models to predict parameters of different distributions. For this purpose, I create appropriate layers and modify the loss functions. Unfortunately, when I use a multivariate t-distribution (tfp.distributions.MultivariateStudentTLinearOperator), the following error results: This time, the procedure for defining the loss function is as follows: I have copied the complete (somewhat more extensive) code and the required data to https://drive.google.com/drive/folders/1IIAtKDB8paWV0aFVFALDUAiZTCqa5fAN?usp=sharing (notebook ""normdist_2D_not_working_t.ipynb""). The operating system I use is Windows 10, the Python version is 3.6. All libraries listed in the sample code are the latest, including tensorflow-gpu. I would be very grateful if the problem could be solved. The topic is particularly relevant for the financial sector, since such distributions play a major role here, especially in risk management.",https://stackoverflow.com/questions/69943995,,1
1193,48924405,Random initial state using MultiRNNCell in TensorFlow,"I have a MultiRNN cell created in this way And I am trying to initialize its state to a random value. I tried doing this: But I keep getting an error that says When I use it UPDATE I tried using As suggested by Pop, and it works for Basic RNN cells and GRU cells, but when I use it with LSTM cells I get the following error SOLVED LSTM cells state is composed by a tuple, so I found this solution that works",https://stackoverflow.com/questions/48924405,9395551.0,1
1194,58858204,I used TensoFlow 2.0 and python3.6 to train MNIST dataset with 99.68% accuracy but it predict the digit wrong,Here I train my sequential model with one hidden layer with activation function relu and softmax. I also cheacked the dataset image and then input the same type of image to predict with a simple model. But it fails to predict correctly. If the accuracy is high then why I get the wrong prediction can't understand.,https://stackoverflow.com/questions/58858204,12176942.0,1
1195,71975766,Why are gradients disconnected,"Consider the following code I wanted get_derivatives to return the partial derivative of function_to_diff with respect to the first element of X. However, when I run I get None. If I use unconnected_gradients='zero' for tf.graidents, I'd get zeros. In other words, the gradients are disconnected. Questions This could fix the problem. What if my function can only take in one argument, i.e. what if my function looks like test_function(X)? For example, test_function could be a trained neural network that takes in only one argument.",https://stackoverflow.com/questions/71975766,1691278.0,1
1196,59728014,How do you to save and load a tensorflow model that has a feature_layer?,"I was following this tutorial with my own dataset: https://www.tensorflow.org/tutorials/load_data/csv. This was my squential of the model: Now, I want to save the trained model so that I can use the model in a different program. The first way I used was using checkpoint callbacks. However, this didn't work because in the other program that I wanted to use the model, I wasn't able to copy the exact shape of the model: I also tried this: ... but it still didn't work. After that, I tried to use model.save(""myModel.h5"") but this won't save at all, and now I'm lost. Please help. Thank you.",https://stackoverflow.com/questions/59728014,12708678.0,1
1197,50479619,Error as I try to export the tf.estimator.DNNClassifier model. How could I save this?,"I have created my estimator as : and run training as: After these two steps, I want to save my model/estimator. I tried the following: But this throws an error saying:Feature sentence if not in features dictionary. I trained the model as given in doc at text_classification_with_tf_hub What is it that I am doing wrong?",https://stackoverflow.com/questions/50479619,9830669.0,1
1198,51432909,How to force Tensorflow to show a simple linear regression prediction result?,"I have a simple linear regression question as below: My codes are as below: Prediction: However, print(y0) shows Tensor(""Softmax_2:0"", shape=(1, 1), dtype=float32) instead of a figure. I expect y0 would be around 0.99. I tried y0.eval(), but I got ValueError: Cannot evaluate tensor using 'eval()': No default session is registered.. How can I make a change to obtain the result? Thanks!",https://stackoverflow.com/questions/51432909,9096553.0,1
1199,60493855,Wrap tensorflow multiply with Lambda,I am trying to do the simplest thing (so I think): Wrap the tf.math.multiply with keras Lambda layer in TF 2.0: For two inputs (with broadcasting) the following works: but none of the bellow seems to work:,https://stackoverflow.com/questions/60493855,1877002.0,1
1200,68701979,Recall and precision not working correctly(keras),"I have to build a model in keras. I am really struggling with my actual dataset, hence I am just trying to figure out the basics on a simpler dataset. This gets printed out: Something really strange about this results. I believe it is due to using the softmax with two nodes. y_train looks something like this: I tried a sigmoid, but then the whole model breaks down, at least here the fitting works. Is there a way to configure recall and precision so they consider one output notes as Positive?",https://stackoverflow.com/questions/68701979,847773.0,1
1201,44407873,Tensorflow: traning by batch stuck forever in sess.run,"I'm trying to train my model batch by batch, as I couldn't find any example to how to do it properly. This is as far as I can do, on my mission to find how to train a model batch by batch in Tensorflow. Which outputs, As you can see, Which stuck forever when it runs the batch_x,batch_y=sess.run([X_train_batch,y_train_batch]) line. I don't know how could I solve this, or is this the proper way to train a model batch by batch?",https://stackoverflow.com/questions/44407873,5951165.0,1
1202,48431507,TensorFlow: approximating a function,"I wrote a simple TensorFlow program which doesn't work. Here's the problem I'm trying to solve. Given x as input, I would like to roughly evaluate a function that returns a value of 0.0 if x is in &lt;0, 0.33&gt; or &lt;0.66, 1.0&gt; interval, and 1.0 if x is in (0.33, 0.66) interval. Here is the code: The values in weights and biases are just plain wrong after the training. They are all 1s even after the first iteration and don't change after. The code I wrote is based on some code that was used for digit recognition and I thought I would ""minimize"" the problem to one number/""pixel"". Any ideas what to try other than changing iterations count or learning rate? EDIT: So I managed to solve my problem with using sigmoid, as suggested below, and using more layers. Here is the working code: To see whether my model works well I actually plotted a whole set of values in &lt;0, 1&gt; interval and turned out, after going through the network, they produced pretty much what I was expecting. This can be fiddled with. I noticed for instance that the more iterations I perform the more ""steep"" the function becomes and more smooth if a few iterations and performed.",https://stackoverflow.com/questions/48431507,1104724.0,1
1203,44139960,tensor flow using uninitialized value,"here is my code: the error was: I run my code ,and I init the value, and something goes wrong, I don't know why, and how to deal with it. it's my second time to run the code, I just add something into it, but the convolution layer wasn't change anything. Is the problem with another code?",https://stackoverflow.com/questions/44139960,8003653.0,1
1204,55275221,How to restore pretrained checkpoint for current model in Tensorflow?,"I have a pretrained checkpoint. And now I'm trying to restore this pretrained model to the current network. However, variable names are different. Tensorflow document says that using dictionary like: However, variables in current network are defined like: So, the variable name seems to be a/b. How to make the dictionary like ""v2"": a/b?",https://stackoverflow.com/questions/55275221,10153344.0,1
1205,46019409,What happens when I ask tensorflow to calculate,"Consider this very simple example: Will tensorflow calculate b only one time, or two times?",https://stackoverflow.com/questions/46019409,4929704.0,1
1206,49063384,Are tensorflow random-variables only created once per sess.run?,If I have something like this: Will a be the same or different when calculating b and c?,https://stackoverflow.com/questions/49063384,3598519.0,1
1207,54170461,Suspiciously high accuracy for binary classification problem,"Based on the layer function The following network for a binary classification problem is constructed: The training routine generates the following output: and the the accuracy on the test set acc_test is 1.0. The batches are generated by the input shapes are Obviously, the accuracy on the training and test tests can't be correct. Where could be the problem in the network, training or evaluation procedure?",https://stackoverflow.com/questions/54170461,1934212.0,1
1208,59554745,"Tensorflow, CNN + LSTM: Easier way to reuse CNN?","I am using TensorFlow 1.15 to train an LSTM on 2D images sequentially in time. So effectively I have the following [Input (3x) -&gt; CNN -&gt; LSTM -&gt; Output]. Since I am training on multiple images, I want to apply the entire CNN subgraph to each image (I would like to reuse all the weights since the current frame is image-wise no different from 1-X frame(s) ago), then feed all the outputs to the LSTM. My current code I am using 3 frames of data so I use a loop to create 3 placeholders (Input0/Input1/Input2) and 3 CNNs (sharing the weights by calling tf.Variable outside the loop, although tf.get_variable might simplify that a bit). Is there a simpler way to express in TensorFlow I have a subgraph I want to call 'CNN' and use it with X placeholders, then feed all those outputs to something like LSTM?",https://stackoverflow.com/questions/59554745,8524411.0,1
1209,40264622,Tensorflow DNNClassifier ValueError,"I am trying to write a fairly simple classifier using Tensorflow. The classifier will take in a 128 element vector and output a 2 category response. Here is the code: The code is based entirely on the code found on the Tensorflow website. I can see that both training_set.data and training_set.target are parsed correctly. At the classifier stage I get an error: I also get an error at the bottom of the trace saying: I am using an IPython Notebook to program in, with the latest TensorFlow library installed (last night's nightly build).",https://stackoverflow.com/questions/40264622,1747088.0,1
1210,73631817,Tensorflow: x - reduce_mean(x) has gradient 0,I was observing gradients when I noticed that the gradient of subtracting one's axis' mean is zero. I think this is very counter-intuitive because gradient = 0 normally means the function is constant. Can anyone explain intuitively why the gradient here is zero? outputs me 0,https://stackoverflow.com/questions/73631817,16748295.0,1
1211,45994346,"Tensorflow: Saving a model to model.pb, to visualize it later",I found the following code snippet to visualize a model which was saved to a *.pb file: Now I am struggling to create the saved_model.pb in the first place. If my session.run looks like this: How do I save the graph contained in train_op to saved_model.pb ?,https://stackoverflow.com/questions/45994346,1934212.0,1
1212,47908091,Model seems to be overfitting with Optimizer.minimize() but not tf.contrib.layers.optimize_loss(),"When I create train_op like this: I get a working network that performs well on validation and test sets. If I just use minimize() method like this: I get much worse results (precision, recall, loss) even on the first validation after 1000 steps, and after a while it seems like it completely overfitted (loss on validation is more or less constant and is 100x train loss, but precision and recall crash) I created a function that is cleaned-up version of contrib one, that differs from straight Optimizer.minimize() in two marked places: And validation performs well again. Training in all cases look more or less same (and healthy). Network is relatively straightforward CNN/batchnorm/dropout/maxpool mix with cross-entropy loss. The way I understand this is that there are some operations that are part of a graph that don't appear as dependencies for loss, but that are needed to calculate gradients. How is that even possible? If this is a normal situation, why aren't those two snippets part of a core? Should I have done something different while building a model to avoid the need for this dependency forcing?",https://stackoverflow.com/questions/47908091,4433.0,1
1213,75801547,What is the difference between tensorflow.keras.backend.round and tf.round?,if i have some tensorflow function foo and function bar what is the difference between foo and bar? i expect that sombody answer on my question,https://stackoverflow.com/questions/75801547,17191240.0,1
1214,53571432,Replacing Queue-based input pipelines with tf.data,"I am reading Ganegedara‘s NLP with Tensorflow. The introduction to input pipieline has the following example Which has the following output: It also generates a lot of warning about Queue-based input pipelines being deprecated and suggests using the tf.data module instead. This is my attempt to using tf.data module Which produces this output instead: It looks like the original code samples 3 rows everytime, and my attempt with tf.data samples 3 columns. Why is this and how can I fix my code and make it equivalent to the original?",https://stackoverflow.com/questions/53571432,,1
1215,63758810,Use my model to predict output in tensor flow 2 without using keras,"I am new to TensorFlow and I have a very basic question. I have found several posts regarding this question for the previous TensorFlow versions but I could not use the answer for TensorFlow 2 which I am using. The examples I found in the documentation in the original site use Keras. Now, about my question, say, I have built my own model using only TensorFlow without using Keras. I have finished training my model and now I want to use my trained model to predict output for some input I give. I am starting out very simple in order to learn to use TensorFlow 2. I am stuck here and it would be of great help if someone provides me a solution. I have attached my snippet of code herewith.",https://stackoverflow.com/questions/63758810,7341905.0,1
1216,49730288,Tensorflow exporting custom Estimator (defining serving_input_fn and PredictOutput),"Link to stack trace: https://gist.github.com/vyzyv/885e7e63520332e5ee42f4bc332a877f PROBLEM SOLUTION: Can be useful information for others: Do not calculate loss for prediction mode in tf.Estimator (solution by @AlexandrePassos, see comments).",https://stackoverflow.com/questions/49730288,5651485.0,1
1217,55314531,"Deep learning, how to represent zero to many items?","Suppose I'd like to predict what presents a parent wants to buy for their kids, and I have kid's age. Problem is that some have just 1 kid, and some have more. I guess the question is independent of what framework I use. But if you need concrete framework to answer the question, I'd go with tf.keras",https://stackoverflow.com/questions/55314531,433570.0,1
1218,62852017,Why is bias layer shape not equal to the weight layer shape in Custom Model which has custom layer,"I stumped across a Custom dummy Linear Regression model where the code is like: I want to ask why is weight has 2 D shape of in,out but bias has only out and more specifically why is weight of a 2D shape?",https://stackoverflow.com/questions/62852017,11725056.0,1
1219,67267305,How should Exponential Moving Average be used in custom TF2.4 training loop,"I have a custom training loop that can be simplified as follow The TensorFlow documentation of ExponentialMovingAverage is not clear on how it should be used in from-scratch training loop. As anyone worked with this? Additionally, how should the shadow variable be restored into the model if both are still in memory, and how can I check that that training variables were correctly updated?",https://stackoverflow.com/questions/67267305,1782553.0,1
1220,55381342,Will tf.gradients pass through tf.cond?,"I would like to create a pair of recurrent neural networks, say NN1 and NN2, where NN2 reproduces its output from the previous time step and does not update its weights at the current time step whenever NN1 outputs a different value from the previous time step. To do this, I was planning to use tf.cond() together with tf.stop_gradients(). However, in all toy examples I have run, I cannot get tf.gradients() to pass through tf.cond(): tf.gradients() simply returns [None]. Here is a simple toy example: Here is another simple toy example where I define true_fn and false_fn in tf.cond() (still no dice): I originally thought that the gradient should flow through both true_fn and and false_fn, but clearly no gradient is flowing at all. Is this the expected behavior of gradients computed through tf.cond()? Might there be a way around this issue?",https://stackoverflow.com/questions/55381342,5269626.0,1
1221,44173110,Using tf.get_variable(...) with an unknown batch size,"Given that I have some input batch x with shape (batch_size, n_features) how would I use tf.get_variable(...) to create another matrix with shape (batch_size) if it isn't known ahead of time. For example I am able to do: b = tf.zeros(shape = (tf.shape(x)[0])) But I am unable to do: b = tf.get_variable(""b"", shape = (tf.shape(x)[0]), initializer = tf.constant_initializer(0.0))",https://stackoverflow.com/questions/44173110,3529361.0,1
1222,43253928,I cannot understand Tensorflow system,"I cannot understand Tensorflow system. First,I wrote and it print out 5. Second,I wrote and it print out Tensor(""Add:0"", shape=(), dtype=int32). I cannot understand this system. I use Python and other languages, so I think tf.add() method is add method.However,in the case of Tensorflow,it seems different. why is this part necessary? What functions does this part have?",https://stackoverflow.com/questions/43253928,7740027.0,1
1223,62839005,Tensorboard graph messy (readvariableop_resource nodes) using tf.summay.trace_export,"The code bellow build two tensorboard graphs for the same model, while using Keras API build nice simple graph, using tf.summary.trace_export() add for each variable define in the graph a node in the external scope with the suffix ""readvariableop_resource"", which make the graph be really messy as the number of the parameters increase. (In the example below we have 2 dense layer each one have 2 variable (kernel and bias) total 4 variables (4 nodes))",https://stackoverflow.com/questions/62839005,7516674.0,1
1224,49285664,training a custom estimator in tensorflow,"I am new to tensorflow and trying to train a custom CNN estimator with inputs being provided from TFRecord files. The Load_input() function is supposed to look into DATA_DIR for TFRecords file and decode it through a call to read_and_decode function(which is supposed to do the actual decoding of the records), store the information into an instance of _image_object and return it. cnn_model is where I have defined the CNN architecture. And generate_input_fn is supposed to create the batches and feed it to the estimator.train while training. I just have an abstract understanding of the codes, no idea of the internal mechanics which is the primary reason why I am not able to debug. Here is my code : it gives me the following error : also the layers shapes are as follows : I don't understand why is the batch size 9 even if I try to explicitly set it to 3 in the code. Note : If anyone has a better/easier solution please post it. The aim is to use tfrecords to train a custom CNN",https://stackoverflow.com/questions/49285664,7713497.0,1
1225,68339171,Create a tensor inside an autographable function based on input tensor's shape,Consider following program: This executes as expected. However if the @tf.function decorator is uncommented it aborts with an error: Is there a way to declare a dynamically shaped tensor inside a function and have it autographed? How are dynamically shaped tensors supposed to be allocated in autograph-enabled functions?,https://stackoverflow.com/questions/68339171,1257383.0,1
1226,40370004,Generate new tensorflow tensor according to the element index of original tensor,"I have a question about tensorflow tensor. If I have a NeuralNet like y=xw+b as an example. then x is placeholder([7,7] dims), w is Variable([7,1]) and b is Variable([1,1]) So, y is tensorflow tensor with [7,1] dims. then, in this case. can I make a new tensor like new_y = [tf.reduce_sum(y[0:3]), tf.reduce_sum(y[3:5]), tf.reduce_sum(y[5:])] and use it for training step? If possible, how can I make it?",https://stackoverflow.com/questions/40370004,5706128.0,1
1227,56267554,Tensorflow's variable_scope() and tf.AUTO_REUSE will not reuse variables in a for loop,"I want to pass several different inputs into a reusable tensorflow architecture (decoder). To do this, I use a for loop in which I feed my inputs into the model. However, I fail to reuse the layer variables and instead, create variables for each loop iteration. Assume this code: while the decoder is: If I now output the variables immediately after the loop with I get the following output, indicating that I am not sharing my variables among the loop iterations: What is going on here? Shouldn't the tf.AUTO_REUSE flag allow me to first initialize my decoder when i==0 and for all iterations i&gt;0 reuse my variables? The above reoccurs for every layer I have in my decoder. I am using TensorFlow version 1.12.0. Thank you.",https://stackoverflow.com/questions/56267554,7353970.0,1
1228,56422657,not able to use tf.metrics.recall,I am very new to tensorflow. I am just trying to understand how to use tf.metrics.recall I am doing the following And that is giving me the following error: Please help me to understand this better. Thank you in advance,https://stackoverflow.com/questions/56422657,5147241.0,1
1229,46013115,How to change global_step in tensorflow`s SKCompat,"I'm using SKCompat class from tensorflow.contrib.learn for classifying MNIST data: Which works as intended, with a small problem: it outputs Info messages every 100 steps, which I suspect encoded in global_step variable: Question: Is there a way to reduce Info outpus to let's say every 1'000 steps? To download data*: *Source: Hands-on machine learning with Scikit-learn and Tensorflow",https://stackoverflow.com/questions/46013115,4317058.0,1
1230,43893272,Performance of basic operations,"I have prepared a TensorFlow implementation of a machine learning algorithm: such implementation is incredibly slow. Unfortunately, I am not able to see where I made mistakes, so came here asking. Let's say that I have quite a lot of parameters whose value depends on a single variable, like, e.g., the epoch. For example, I have this parameter: The value sSigma is used for every input example of each epoch and is computed as a function of the variable epoch (sSigma0, sSigmaTau, sSigmaMin are tf.constant). I would like to ask: Simple code for the question: how many times is the op maxInA executed?",https://stackoverflow.com/questions/43893272,774133.0,1
1231,46838739,Tensorflow - Graph is finalized and cannot be modified,I am trying to launch a Distributed Tensorflow and get the following error. My code looks like this: When I get the error it's failed on random_mini_batches function. But I completely don't understand how and why. random_mini_batches function is a function written in pure python + numpy without anything related to TensorFlow. x_train and y_train were not used before. Here is the error that I get: Any help would be highly appreciated! Thanks,https://stackoverflow.com/questions/46838739,3489820.0,1
1232,63207118,Unable to concatenate features to same shape,"I am embedding a text document using the following code: After the embedding layer I would like to attach further features - this is a one hot encoded numpy array, which contains 11 cols and a row per sample. I have tried various combinations for the concatenation axis and also for the shape, but with no luck. The model will compile when setting the following params: But will throw an error when running fit(): EDIT: Here is the compiling but failing model summary:",https://stackoverflow.com/questions/63207118,4896449.0,1
1233,47681151,Why does tf.train.batch add an extra dimension to output in TensorFlow?,"In TensorFlow, say we have training data xs in numpy NHCW format. I want to sample batches from xs in Tensorflow, I did Instead of sampling from tensor_list, this code returns a list whose length is the same of the number of data points (4 in this case), and each list element is a tensor where the first dimension is batch_size (3 in this case). Personally the intuitive outcome would be x_batch is a 4 dimensional tensor and the value of the first dimension is batch_size, and the contents are randomly sampled. Then each time we call sess.run(x_batch) we have a different batch. Please let me know where I did wrong.",https://stackoverflow.com/questions/47681151,8277962.0,1
1234,39677168,"Tensorflow documentation's example code on ""Logging Device Placement"" doesn't print out anything","Tensorflow documentation has the following example code on finding out the device placement of nodes. That is, on which device a particular computation takes place. For me, the code does not print out the locations of the devices like it is supposed to. I'm using the Jupyter notebook running on Ubuntu. How might I fix this or find out the information some other way?",https://stackoverflow.com/questions/39677168,4700482.0,1
1235,66538337,How to get Tensorflow Embedding Projector to work with images,"After reading the documentation [here] and [here] 1 2, I have been unable to get my embedding to populate the Tensorflow Embedding Projector. I am working with image data and want to visualize the embeddings, but after saving the weights and the labels to /log_dir Tensorboard still says no data was found. Any help would be appreciated. This is copy pasted from a notebook so I apologize for any formatting errors.",https://stackoverflow.com/questions/66538337,10413628.0,1
1236,42816644,"tensorflow: Strange result from convolution compared to theano (not flipping, though)","I am trying to implement some deep neural network with tensorflow. But I have already a problem at the first steps. When I type the following using theano.tensor.nnet.conv2d, I get the expected result: However, when I do the presumingly same thing in tf.nn.conv2d, my result is different: The layout of the convolution operation in tensorflow is a little different from theano, which is why the input looks slightly different. However, since strides in Theano default to (1,1,1,1) and a valid convolution is the default, too, this should be the exact same input. Furthermore, tensorflow does not flip the kernel (implements cross-correlation). Do you have any idea why this is not giving the same result? Thanks in advance, Roman",https://stackoverflow.com/questions/42816644,5631237.0,1
1237,75237100,aberrant shuffling behaviour from dataset,"Let us suppose I am importing an image dataset using ""image_dataset_from_directory"" with no labels, with the shuffling argument set to True. Afterwards, I want to keep track of the file paths I imported, so I used ""file_paths"" property. Because the file paths are not in batches, I had to do the following: Seems everything is OK. But now the shuffling starts. Everytime I access train_ds, it is shuffled. When I say ""access"", I am referring to one of the following options: All these options reshuffle the dataset. The problem is the following: only the first column (with the images) is shuffled. The paths are not shuffled, and now they are unsynced with the respective images. Honestly, I cannot see any appication where it is usefull to shuffle independently columns of a dataset. Now, imagine I was adding not the list of paths, but a list of labels? When I trained the data, everything would be messed up. Anyway, I believe shuffling should be applied to all columns of a dataset. This is done with I import a labeled dataset, but not when I merge datasets using the zip method. I also don't know how to print my dataset in a reproductive way other than setting shuffle=False when importing the data. I don't want to do it, because of the following statement I found in Keras documentation when using model.fit: shuffle: Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). This argument is ignored when x is a generator or an object of tf.data.Dataset. link So if I set shuffle to False, and because I used a generator, the argument is ignored and this means I cannot shuffle the data when training my model. Thats not what I want. I want to shuffle ONLY when training my model, and not otherwise. Maybe I am doing something wrong and there is a better way to do this. I don't know. Anyone knows a workaround? I want my file path list to be synced with the respective images all the time. Best regards",https://stackoverflow.com/questions/75237100,6227537.0,1
1238,53993596,"tensorflow placeholder shape [None] [None,1] difference","I am new to tensorflow. I experimented a DQN algorithm with a section involving and initialized the input y with y_batch=np.zeros(nbatch). The network hardly trained at all. Then, I switched to defining y as and initialized the input with y_batch=np.zeros(nbatch).reshape(-1,1), which worked nicely. What was happening in the first implementation?",https://stackoverflow.com/questions/53993596,9955539.0,1
1239,40367514,mini-batch gradient descent implementation in tensorflow,"When reading an tensorflow implementation for a deep learning model, I am trying to understand the following code segment included in the training process. I think it is related to mini-batch gradient descent, but I cannot understand how does it work, or I have some difficulties to connect it to the algorithm shown as follows",https://stackoverflow.com/questions/40367514,288609.0,1
1240,63984268,Need help in understanding Encoder-Decoder code in Tensorflow,"I am reading ""Hands-On Machine Learning with Scikit-Learn and TensorFlow"" by Aurelion Geron. I am currently reading the Encoder-Decoder section of the book and I stumbled upon some code that I don't fully understand, and I find the explanations from the book to be unsatisfactory (at least for someone like me, a beginner). The following picture presents the model we are trying to implement (or to be more precise, we will implement a model that is similar to the following picture, not exactly this model): (picture from Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, chapter 16, page 543, figure 16-3) This is the code that was used (again, the above model is not the exact thing we are going to code. The author explicitly said that the model we will build is just similar to the above picture): There are things in the above code that I don't know what they do, and there are things that I think I know what they do, so I'll try to explain exactly what I am confused about. If I am wrong in anything that I say from this point, please let me know. We import tensorflow_addons. In lines 2-4 we create the input layers for the encoder, for the decoder, and for the raw strings. We could see in the picture where these would go. A first confusion arises here: Why is the shape of encoder_inputs and decoder_inputs a list with the element None in in, while the shape of sequence_lengths is an empty list? What are the meaning of these shapes? Why are they different? Why must we initialize them like this? In lines 5-7 we create the embedding layer and apply it on the encoder inputs and on the decoder imputs. In lines 8-10 we create the LSTM layer for the encoder. We save the hidden state h and the memory cell state C of the LSTM, as this will be the input into the decoder. Line 11 is another confusion for me. We apparently create a so called TrainingSampler, but I have no idea what this is or what it does. In the words of the author: I don't really understand this explanation. What exactly does the TrainingSampler do? Does it tell the decoder that the correct previous output is the previous target? How does it do that? And even more imporantly, would we need to change this sampler during inference (since we wouldn't have the targets during inference)? In lines 12 and 13, we define the decoder cell and the output layer. My question here is why do we define the decoder as LSTMCell, while we declared the encoder as LSTM, not a cell. I read on stackoverflow that LSTM is a recurrent layer, while LSTMCell contains the calculation logic for one step. But I don't understand why we had to use LSTM in the encoder and LSTMCell in the decoder. Why this difference? Is it because in the next line, the BasicDecoder actually expects a cell? In the next few lines, we define the BasicDecoder and apply it on the decoder embeddings (again, I don't know what sequence_lengths does here). We get the final outputs, which we then pass through a softmax function. There's a lot going on in that code and I am really confused about what happens. If someone could clear things up a bit, I would be extremely grateful.",https://stackoverflow.com/questions/63984268,11641316.0,1
1241,42092737,Freezing/exporting a part of a TensorFlow graph,"My question is related to this one here about persisting graphs: I wonder if it is possible to only export a certain part of a graph, e.g. a subgraph prefixed by a given scope, using TensorFlow 0.12 or newer. I'm currently using a combination of tf.train.import_meta_graph(), graph_util.convert_variables_to_constants() and tf.train.write_graph() to export (""freeze"") a graph into a protocol buffer file which I then can load back using tf.import_graph_def(). During the export I can specify which nodes are considered required outputs of the graph, so no upstream nodes are thrown away, while during import I can rewire certain parts of the graph to other operations using input_map. This all works fine, but it is missing the notion of unnecessary inputs and the problem is that by doing so, the entire upstream of the output_nodes is written to the file as well, i.e. everything input and preprocessing related. Currently, exporting looks like this: While importing looks like this: Is there a way to filter and/or remove the parts I do not require during or before exporting? To be clear, I known I can ignore them after loading, but I do not to export them to begin with. Would using collections help at some point?",https://stackoverflow.com/questions/42092737,195651.0,1
1242,45462341,How to access TensorArray elements with tf.while_loop in Tensorflow?,"I have a question relative to using TensorArray. The Problem: I would like access elements of a TensorArray with a tf.while_loop. Please note that I am able to read the contents of the TensorArray using for example, u1.read(0). My current code: Here is what I have so far: The error message: During handling of the above exception, another exception occurred:",https://stackoverflow.com/questions/45462341,3564164.0,1
1243,61141331,Tensorflow InvalidArgumentError when calling model.fit,"I am trying to setup a really simple keras model in tensorflow. I have a X_train and a Y_train numpy.ndarray variables with size of (846, 30, 373) and (846, 1, 1) respectively. The model looks as follow: The last line produces the following InvalidArgumentError: I believe I am making confusion and passing inputs (X_train and Y_train) with a shape that keras is not expecting, but I can't figure out why is it the case. What am I doing incorrectly? Edit: model_logic.summary() prints the following: where the shapes seem to be ok with those of my X_train and Y_train. Or should the Output Shape of the InputLayer be (None, 30, 373) instead of [(None, 30, 373)]? And if so, where do the extra [] come from?",https://stackoverflow.com/questions/61141331,9299506.0,1
1244,56805939,use gather_nd to acquire result in a loop - shapes of all inputs must match,"I have this example in numpy: and I want to do it in tensorflow: until line with the computation of c is ok. At last line (res) it gives me: I am not sure how to receive the result. UPDATE basically, the problem lies in the fact that [idx, c] is of type list and trying to do : tf.convert_to_tensor([idx, c], gives :",https://stackoverflow.com/questions/56805939,583464.0,1
1245,73332240,LIME text explainer for model with preprocessed input,"I'm trying to explain a Keras LSTM model using LIME text explainer. I have news titles and a binary target variable (the sentiment). My model is the following: I want to use a LimeTextExplainer in the following manner: However, my model inputs a padded sequence ( not a string). So, instead of model.predict I have tried to implement a custom predict function which, firstly, preprocesses the input and then makes a prediction: Still, my problem is not solved and I encounter the following error: IndexError: index 1 is out of bounds for axis 1 with size 1",https://stackoverflow.com/questions/73332240,13449514.0,1
1246,54084247,"Error: ""List of Tensors when single Tensor expected"" in computing a polynomial",I want to calculate a polynomial using TensorFlow Python API as the following: Polynomial: f(x) = a0 + a1*x + a2*x^2 + a3*x^3 + a4*x^4. The code is: A piece of quite simple code but I can't get it right. Here is the error trace: I don't understand why it says there is a list of tensors. Please advise. Thanks.,https://stackoverflow.com/questions/54084247,6302803.0,1
1247,61761477,What's the use for converter.build() in TensorRT?,"The official documentation on TensorRT lists two ways to convert a TensorFlow SavedModel into a TensorRT SavedModel: the first is and the second is Stripping out all of the boilerplate code for imports, inference etc the difference seems to lie in the call to converter.build(). The documentation explains this function as such: ""This method optimizes the converted function (returned by convert()) by building TensorRT engines. This is useful in case the user wants to perform the optimizations before runtime. The optimization is done by running inference on the converted function using the input data received from the argument input_fn. This argument is a generator function that yields input data as a list or tuple. "" What does ""before runtime"" mean in this context? Will the ""optimizations"" be performed upon model loading, upon the first inference, or upon every single inference using the converted model? What are those optimizations, even? Isn't converting the model to TensorRT an optimization in itself? I am asking because if I call converter.build() the conversion seems to fail in unpredictable ways after taking a LOT of time (more than two hours) to run without producing any sensible output, so I was wondering how much am I losing by not calling it and whether there is more comprehensive documentation on using TF2.x SavedModels with TensorRT. Thanks in advance to whoever can answer!!",https://stackoverflow.com/questions/61761477,5623016.0,1
1248,48206320,TensorFlow - `keys` or `default_value` doesn't match the table data types,"(Complete novice at python, machine learning, and TensorFlow) I am attempting to adapt the TensorFlow Linear Model Tutorial from their offical documentation to the Abalone dataset featured on the ICU machine learning repository. The intent is to guess the rings(age) of an abalone from the other given data. When running the below program I get the following: The error is being thrown in lookup_ops.py at line 220 and is documented as being thrown when: From debugging parse_csv() it seems to be the case that all the tensors are created with the correct type. Could you please explain what is going wrong? I believe I am following the tutorial code logic and cannot figure this out. Source Code: Here is the classification of the columns of the dataset from abalone.names: Dataset entries appear in this order as common separated values with a new line for a new entry.",https://stackoverflow.com/questions/48206320,7454312.0,1
1249,50160889,How to use Tensorflow with a GTX 1050 mobile edition?,"I recently started programming with Tensorflow on python. I wanted to improve the calculation-power using my GTX 1050 in my laptop but i didn't success... After installing all the required libraries and softwares (CUDA 9.0, CuDNN for CUDA 9.0, imported : tensorflow and tensorflow-gpu...), I tryed basic example from the Tensorflow website : but this return the following answer (I translate it right after) : This heavy message mean that the only device available on my laptop is my CPU but I have a GTX 1050. I tried to add this line at the begining : with tf.device(""/device:gpu:0""): I spare you all the insult of the command line but it return me this : Is anyone have an idea of the origin of my issue ? Or someone have ever overcome this issue and could help me ?",https://stackoverflow.com/questions/50160889,9736935.0,1
1250,50425365,Tensorflow populating placeholder with an array,"I am having difficulty populating a placeholder with a tensor. I've searched but can only find values with single values being supplied into the computation graph. Here's my code: gives me the following error: I have also tried defining the placeholder as a tf.Constant: This gives me a different error: I just want to supply an 2 x 1 matrix like this [[0],[1]] but it's proving difficult. Any help would be greatly appreciated.",https://stackoverflow.com/questions/50425365,658493.0,1
1251,63541028,MediaPipe TensorflowLite Iris Model,"I am trying to understand the output of the tflite Iris landmarks model available from mediapipe. The model card describes the output as 71 2D landmarks and 5 2D landmarks. When inspecting the model as follows: I see 213 values and 15 values in the model outputs - so I assume I am getting an x/y/z coordinate for each point. After running the model on an image I get values in the -7000 to +7000 range. My input was a 64x64 image, any idea of how these points correspond to the original image? I would like to have pixel coordinates of the eye keypoints, which are rendered in the mediapipe examples.",https://stackoverflow.com/questions/63541028,10582271.0,1
1252,60839967,Keyword arguments in BERT call function,"In the HuggingFace TensorFlow 2.0 BERT library, the documentation states that: I'm trying to use the first of these two to call a BERT model I created: But when I execute the last line, I get an error: Could someone please explain how to properly use the keyword argument style of inputs?",https://stackoverflow.com/questions/60839967,424306.0,1
1253,62095767,How to create a custom PreprocessingLayer in TF 2.2,"I would like to create a custom preprocessing layer using the tf.keras.layers.experimental.preprocessing.PreprocessingLayer layer. In this custom layer, placed after the input layer, I would like to normalize my image using tf.cast(img, tf.float32) / 255. I tried to find some code or example showing how to create this preprocessing layer, but I couldn't find. Please, can someone provide a full example creating and using the PreprocessingLayer layer ?",https://stackoverflow.com/questions/62095767,2135819.0,1
1254,47320412,"Tensorflow - ValueError: Shape must be rank 0 but is rank 1 for 'limit' for 'range' (op: 'Range') with input shapes: [], [10], []","I am learning how to build a simple neural network recently. Following Mr Mo's tutorial, I write the code step by step: However, I get an Error: I find some similar questions and their solutions. For example, ""You declared the learning rate as a 1D Tesnor while it should be a scalar"". Unfortunately, I don't know what it actually means or how to solve my problem. Thank you so much in advance!",https://stackoverflow.com/questions/47320412,8781724.0,1
1255,70044988,Why should the input_shape property of a Conv2D layer be specified only for the first Conv2D layer?,"I am new to AI/ML stuff. I'm learning TensorFlow. In some tutorial, I noticed that the input_shape argument of a Conv2D layer was specified only for the first. Code looked kinda like this: In many examples, not only in the above, the instructor didn't include that argument in there. Is there any reason for that?",https://stackoverflow.com/questions/70044988,17112669.0,1
1256,51591531,"Building a language model using tensorflow , dataset shape issue","I'm trying to build a translation model, so I'm getting a text as input, I'm encoding him to a list of integers (the type of enocding is not important).so far so good. let's say this is what I have so far: Now I want to do this lines: (btw why do we need the first line, just to be able to do the second?) But from this lines I'm getting: and I don't understand why? I have a batch size of 32 and 10 numbers, why isn't it (1,32) (with paddings or something)??? This impacts me after on in the code, I really need to understand how to handle this. btw just reshape isn't working :( Thanks!",https://stackoverflow.com/questions/51591531,7036833.0,1
1257,49603346,Understanding how tf.gradients evaluates,"I'm studying how to break linear classifiers, but I'm having trouble understanding tf.gradients. The point of the project is to take a model and train it on the mnist dataset. Once it is trained, I am taking an image, slightly changing it, and feed it back to the model. However, when I feed it back, the prediction should be different. For example, if I have an image of a 2 and I want the model to predict a 6, I will change the image slightly so that the image still looks like a 2 but the model will think its a 6. How this is done is a simple equation. We take the derivative of the loss function and take the sign of it and apply it to the image multiplied by some epsilon value. For example, the equation is something like this... The part that confuses me is tf.gradients. I am looking at an example but I am having a hard time understanding it. First, 10 images of a number 2 are extracted. Next, 10 labels are created representing the label 6. So the labels looks as follows... And then to the derivative of the cost function looks as so (cross_entropy is the cost function)... x0 is are the 10 images of a 2 and y_six are the labels representing the number 6. The sign of this derivative is then used in the equation I demonstrated above. My question is this, what exactly is the tf.gradients returning and why is the derivative being evaluated with a label of 6 rather than a label of 2? I'm having a hard time understanding what is being returned and why a fake label is being used. I understand that a fake label is probably necessary to trick the classifier but it is hard to see this because I don't understand what tf.gradients is returning.",https://stackoverflow.com/questions/49603346,4333347.0,1
1258,42978731,Video frames as inputs to the Tensorflow graph,"More specifically, how to create a custom reader that reads frames from a video and feeds them into the tensorflow model graph. Second, how can I use opencv to decode the frames to create the custom reader if possible? Is there any code which can better demonstrate the purpose in mind (In python)? I am mainly working on emotion recognition through facial expression and I have videos as input in my database. Finally, I have tried using a Queue and a QueueRunner with a Coordinator hoping to solve the problem in hand. According to the documentation in https://www.tensorflow.org/programmers_guide/threading_and_queues, the QueueRunner runs the enqueue operation which in turn, takes an operation to create one example (Can we use opencv in this operation, to create one example, to return the frames as the examples to enqueue?) Please note that my purpose is to let the enqueue and dequeue operation to occur a the same time on different threads. Following is my code so far: Thank you!!",https://stackoverflow.com/questions/42978731,1780735.0,1
1259,33932901,What's the purpose of tf.app.flags in TensorFlow?,"I am reading some example codes in Tensorflow, I found following code in tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py But I can't find any docs about this usage of tf.app.flags. And I found the implementation of this flags is in the tensorflow/tensorflow/python/platform/default/_flags.py Obviously, this tf.app.flags is somehow used to configure a network, so why is it not in the API docs? Can anyone explain what is going on here?",https://stackoverflow.com/questions/33932901,5607347.0,1
1260,67834365,Apply augmentation on tf.data.Dataset.from_generator(),"I have this augmentation code : And this how I import my image dataset : train_ds = tf.data.Dataset.from_generator(path) I would like to apply this augmentation on my train_ds, So, please, how can I proceed ?",https://stackoverflow.com/questions/67834365,14253961.0,1
1261,56010489,Keras not showing progress bar when training model,"I need to train a CNN to classify some images. I did that before with Keras on TF backend, worked like a charm. Now it doesn't want to show that progress dialog which shows accuracy and current epoch. Here's the code of my CNN model: Is there something I'm missing? All I see now is this: Epoch 1/10 Thanks...",https://stackoverflow.com/questions/56010489,9232190.0,1
1262,70570900,"NeuralODE Python - ""AttributeError: module 'tensorflow' has no attribute 'defun' ""","I am currently working with NeuralODE on google CoLab, and I tried to use a command, 'defun', without success. I am using Tensorflow version 1.x which is a requirement for NeuralODE, but when I try to use tf.defun, I get the error ""AttributeError: module 'tensorflow' has no attribute 'defun'. How can I actually get to defun? This is the particular bit of code I need it for I have seen similar questions on stackoverflow, but the solutions are all very specficic and I haven't seen any about 'defun' specifically. I hope this makes sense, I am a beginner. Thanks!",https://stackoverflow.com/questions/70570900,16098569.0,1
1263,63891202,Tensorflow multiple parameter to function,"While learning tensorflow, I am confused with code like: So I try to print the x: My understanding is: 0.2 is the parameter to the function, but what is this (x) syntax? Any reference would be appreicated",https://stackoverflow.com/questions/63891202,1112245.0,1
1264,66381477,Can anyone explain eager_few_shot_od_training_tflite.ipynb code,I am trying to understand example code provided by tensorflow team in github link eager_few_shot_od_training_tflite.ipynb. I am able to understand most of the code except below few lines of code. Can anyone explain in detail what below code is doing (and comments provided above this code mean)?,https://stackoverflow.com/questions/66381477,2175896.0,1
1265,70608765,ValueError in user code because of custom definition train_step function,"I am trying to build my custom graph neural network, however I do not fully understand the Keras API. Is there anyone who has experience in how to build custom neural networks in the Keras API? I have looked at this documentation. But my application doesn't seem to work due to a ValueError in user code. The problem lies in the input training data and the input of the first layer. In the MNIST data set, the data points is a vector composed of pixel values. And you plug these vectors in the first layer as input layer. However, in my case my data points are matrices. The input of the first layer is a row from this matrix. Per row the loss is calculated and added to the previously calculated loss. Eventually obtaining a cumulative loss per row. Then we backpropagate using the cumulative loss of the entire matrix. Then the next matrix in the dataset is called, etc.... I tried to define a custom train_step function, but failed miserably at it: The error Im getting: Code to reproduce:",https://stackoverflow.com/questions/70608765,17825323.0,1
1266,41984881,Unexpected behavior after updating a placeholder,"The output of the following snippet is [5], and not [1005] as I would expected. I've been answered that the ph+=1000 line overwrote the original placeholder so I'm not feeding what I think I'm feeding. However, I didn't fully understand this answer. If ph was a variable then the output was [1005] of course. So what am I feeding? What does ph hold after the update op?",https://stackoverflow.com/questions/41984881,6718080.0,1
1267,63590092,How to upgrade this code from tensorflow 1 to tensorflow 2,"I have the following piece of code: In the last line, we're using the slim module from tf.contrib, which is deprecated in tensorflow 2. What functions exist in tensorflow 2 or otherwise to do the same function as the slim.utils.collect_named_outputs line?",https://stackoverflow.com/questions/63590092,12654090.0,1
1268,44325179,Tensorflow/LSTM machanism: How to specify the previous output of first time step of LSTM cells,"Just started using TensorFlow to build LSTM networks for multiclass classification Given the structure shown below: A RNN model Let's Assume each node A represents TensorFlow BasicLSTMcell. According to some popular examples found online, the input for training is prepared as [batch_size, timeStep_size, feature_size] let's Assume timeStep_size = 5, feature_size = 2, num_class = 4, given one training set : (dummy data) According to the popular usage: It seems to me that the training of LSTM cell doesn't make use of all the five outputs of y (y at t0 - t3). Only y at time t4 is used for calculating the loss when compared to output[-1]. Question 1: is it the case that LSTM calculates/approximates y_t0 by itself, and feed into t1 to calculate y_t1, and so on... until it y_t4 is calculated? If this is the case, Question 2: what if y at t-1 is very important? Example: VS: Which means that even though the input features from t0 to t4 are same, the output y are different since the previous outputs (y_t-1) are different. Then how to deal with this kind of situation? how does TensorFlow set the output for t-1, when calculating the output at t0? I've thought about increasing the timeStep_Size, but the real case might be very large, so I'm a bit confused... Any pointers are highly appreciated! Thank You in advance. ================= UPDATE =============================== Re: jdehesa, Thanks Again. Some additional background: my intention is to classify a long series of x, like below: The main confusion behind this post is that there are some known rules for manual classification. Take the dummy data above for example, assume there are rules that In such case, if the LSTM only sees [5 by 2] feature vector (x) same as t1 to t4, the network will completely lost in wheather classify as class 2 or class 4. So what i mean is that not only do those features of the 5 time steps matter, so does the output/label of previous time step. So restate the question: if now the training set is t1 to t5, so in addition to x [batch_size, t1:t5, 2], how to involve the label/class y at t0 as well. Below are my reponse to your answer. consider i use GRU instead of LSTM, where cell output and cell state are all represented by ""h"" as in understandign LSTM. Again thank you so much",https://stackoverflow.com/questions/44325179,8102163.0,1
1269,70937339,tfa.metrics.F1Score calculated wrong?,"I train a Keras model from scratch for image classification and print the F1 score during training. I use the following metrics in the metrics property in model.compile(): When I check my logs I have a precision of 0.98956, a recall of 0.9875 and a F1 score of 0.98113. According to the formula in the documentation the F1 score should be 0.9885. Is the formula or my setup wrong?",https://stackoverflow.com/questions/70937339,14836138.0,1
1270,49923958,Tensorflow custom activation function,I implemented a network with TensorFlow and created the model doing the following in my code: I initialize the weights and the biases doing: Now I want to use a custom activation function. Therefore I replaced tf.nn.relu(layer_1) with a custom activation function custom_sigmoid(layer_1) which is defined as: Where beta is a trainable parameter. I realized that this can not work since I don't know how to implement the derivative such that TensorFlow can use it. Question: How can I use a custom activation function in TensorFlow? I would really appreciate any help.,https://stackoverflow.com/questions/49923958,3861775.0,1
1271,46768626,Parsing tfrecords with tf.feature_column.make_parse_spec and tf.contrib.data.Dataset,"I have created a simple tfrecords file using the following code. Now I want to create a tf.contrib.data.Dataset from this using the tf.feature_column feature columns. I have defined my features like this. I'm then trying to use the following code to apply a parse function to each row of the raw tfrecords dataset using the features I defined above. This breaks with the following stack trace. So the parse function expects a byte string to read the features from but it seems like it's already a SparseTensor for some reason that I don't understand. I then tried parsing the same tfrecords file using the ""old"" way with queues. Which gives me this output so it seems to work I guess. But my question is, how do I make this work with tf.contrib.data.Dataset? TLDR: I want to use tf.feature_column to define my features and then create input functions reading from tfrecord files that are compatible with the tf.estimator classes. Preferably I want to use the tf.contrib.data.Dataset API for this.",https://stackoverflow.com/questions/46768626,2372357.0,1
1272,57485790,Understanding the computation graph of Tensorflow Keras layer,"I've created the simplest Dense layer with just 2 parameters (kernel and bias with 1 parameter each): And this is the graph drawn by Tensorboard: I don't think I'm understanding the major pieces - in particular, is my model (with the two parameters) the red ""dense"" block, or the one near the bottom of the graph? (The one in the Adam has red border because I clicked on it.)",https://stackoverflow.com/questions/57485790,11876924.0,1
1273,50283417,Loading operations from saved TensorFlow RandomForest Classifier,"I've trained a TF Random Forest Classifier similar to the following code: Now I want to reload my model and use it to make predictions on unseen data like this: However, I get the following error message: My question is - how can I save my model such that when I reload it, I can import those operations defined above and use them on unseen data? Thanks!",https://stackoverflow.com/questions/50283417,6019463.0,1
1274,36177958,TensorFlow: Rerun network with a different input tensor?,"Suppose I have a typical CNN model in TensorFlow. A typical forward pass could be done like this: Now suppose my input function now returns a pair of arguments, left_images and right_images (stereo camera). I want to run right_images up to conv_28 and left_images up to fc_30. So something like this This however fails with I want to avoid having to evaluate inputs to then feed it back to TensorFlow. Calling inference twice with different arguments will also not work because functions like conv_layer create variables. Is it possible to rerun the network with a different input tensor?",https://stackoverflow.com/questions/36177958,234167.0,1
1275,52340375,how to track percentage complete and average training iteration runtime in tensorboard?,"I have what I think should be a simple problem but I can't seem to figure it out. Let's say that I have something like this Now my tensorboard is tracking all sorts of variables relating to the self.training_graph - accuracy, cross entropy, information about the weights and what not. All I want to do is have another graph on tensorboard that tracks the average runtime of each training step. If I time the step, (see train_time), how do I put these into an ever increasing array and show it in tensorboard for this graph? The issue seems to be that these values aren't apart of my main model graph, they're different values. If I make them with a new graph that simple appends new runtimes then they don't show up in tensorboard. I could make them apart of the graph but that seems dumb.. why would my complicated ML graph have a random part that caluclates the average training iteration runtime?",https://stackoverflow.com/questions/52340375,4652515.0,1
1276,65808376,Summation of tensors and weights changing dimensions,"I am trying to create a custom layer in keras, but I'm coming across a strange issue. When I'm summing the tensors before returning the answer, the dimensions change. This happens when I sum the bias weights to the two tensors, see the code below. which gives which surely should give an output shape (5,None)? self.b is initialised with: Shouldn't the weight self.b broadcast to be the shape (5,None) then added to the summation, rather than removing the None dimension? Any clarification would be much appreciated. The None size is from the initialisation of the layer, supposedly if it works with None it ought to work with any number of samples I assume? Hence why I'm quite confused. I should add I have just tried the + operator and I have the same issue.",https://stackoverflow.com/questions/65808376,15044063.0,1
1277,64824145,Read values of the loss function in Tensorflow 2.3.1,"I am aiming to make a personal loss function, and for that i would like to access the values which I receive through parameters. The goal is to just has these values received in y_true in some np array, make some modifications on it, and then to operate the loss function in fact. I have tried to convert the data from Tensor to np.array, using the Tensor.numpy(), but the result is: AttributeError: 'Tensor' object has no attribute 'numpy' Indeed, this error seems to be related to the fact that my variable y_true is not a EagerTensor, but just Tensor. Since I am trying to personalize my layer and model creation, I dont know how to enable the Eager Execution Mode. Here is the code I am writing: In this situation, how can I convert from Tensor to Numpy? Is there some way to convert from Tensor to EagerTensor in this case? I am using Tensorflow 2.3.1, but would not be a problem to regress to older versions of tf2. In the code posted, the line in interest is that one righ bellow the statement of def Personalized_loss_procedure.",https://stackoverflow.com/questions/64824145,13774601.0,1
1278,57111573,Softmax and Sigmoid identity in TensorFlow 2,"I understand that the sigmoid function is identical to the softmax function with two categories (K=5). Yet I don't understand why TensorFlow 2 gives me different results here, where I compare a bottom-up calculation of cross-entropy with the cross-entropy function of Tensorflow: As far as I understand it, they should result in the same results. Mathematically, I came as far as the following (cross-entropy again): These results also come out of the above functions but are obviously not the same. Can anybody resolve this inconsistency? (I'm aware of this and this which are quite questions.)",https://stackoverflow.com/questions/57111573,4735848.0,1
1279,44328955,Dealing with unknown dimensions in Tensorflow,"I wrote a function that calculates the gram matrix for image features of shape (1, H, W, C). Method I wrote is below: To Test my implementation of the gram matrix, There is a method: When I run gram_matrix_test() I get an error -&gt; ValueError: Cannot convert an unknown Dimension to a Tensor: ? (The error is on this line -&gt; ""gram = tf.divide(gram,tot_neurons)"" ) On debugging I found out that the shape of model.extract_features()[5] is (?, ?, ?, 128) and hence the division is not possible. Dimensions of style_img_test are ((1, 192, 242, 3)), so when we run the session H,W,C will get populated. Can you please guide me on how to fix this?",https://stackoverflow.com/questions/44328955,2971813.0,1
1280,76199563,TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type uint8 of argument 'x',"I'm working on a GAN with generator and discriminator. This function throws an error: But I try to subtract it manually, it works just fine, they are both float32",https://stackoverflow.com/questions/76199563,5672673.0,1
1281,45012534,What is an epoch and how is related to steps and batch_size?,"I have looked through other solution to the similar questions but none gave a complete explanation. For my understanding, the epoch is a test round in which the test-set divided in 'm' batch_size goes under 'n' steps. And in this case, no of epochs will be the size(data-set)/m. Ok, but what if the batch_size was equal to the size(data-set), then how to decide the number of the epochs.I faced the similar problem when going through the documentation. Here the batch_size is equal to the size(data-set). So what's the real related behind these terms.Please explain with a well-defined example..",https://stackoverflow.com/questions/45012534,7369870.0,1
1282,74498973,model optimzer in intel open vino,"I used for saving my image classification model (tensorflow version on google colab = 2.9.2, intel open vino version[Development Tools] = 2021.4.2 LTS) I am getting this kind of error even after I downloaded need help",https://stackoverflow.com/questions/74498973,20243415.0,1
1283,73267868,How to do slice and update operation on tensors in Tensorflow 2.0,I have been trying to convert the following PyTorch code into TensorFlow 2.0. My implementation of the above in TensorFlow resulted into the following error I have tried implementing TensorFlow slice assignment using tf.tensor_scatter_nd_update function but haven't been able to come up with a viable solution. I would greatly appreciate any help regarding how to tackle this problem.,https://stackoverflow.com/questions/73267868,13190846.0,1
1284,51225080,TypeError: 'float' object cannot be interpreted as an index in Multi GPU's,"I am unable to understand why the my jupyter notebook is showing TypeError for float, each time I execute it. Error:",https://stackoverflow.com/questions/51225080,7697170.0,1
1285,53470714,image classify and tensorflow serving,"First of all sorry I am not prcise for this question but I am studying the tensorflow-serving and how to put in production my cnn. sincerely the documentation is quite confuse to me. I hope you can help to understand better the save model architecture. So please reply to me as teacher, i would like to know more about the whole flow. I am developping a simple cnn to classify an image to 4 output. I need tensorflow-serving to put it in production. The image in input can be watherver size, the CNN should resize it first and predict. Here the code the code will take the picture from a cam http://192.168.3.21:7451/shot.jpg and then it will predict it When I compile the code it return a lot of errors when it try to save the model. can you please check it and tell me if the save model instructions are right? I use x = model.input as input from the serving but I would like it take the picture as input from the server. I am quite confuse actually, sorry. The scope is when I request by gRPC to predict the image the model can give me the prediction result Thanks",https://stackoverflow.com/questions/53470714,10675469.0,1
1286,51449027,Carrying gradients from previous time steps to current time steps with GRU in Tensorflow,"I have the following model in tensorflow: So as we can see from the code that the cell size of the first GRU is 64, the cell size of the second GRU is 32. And the batch size is 34 (but this is not important for me now). And the size of input features is 200. I have tried computing the gradients of the loss with respect to the trainable variables through: After printing out the grads I got the following: Assume that I saved the gradients after training the model on the first batch, that is, after feeding a tensor of shape: (34, 100, 200) as input_features ""In the model function argument"", and output of shape (34 * 100, 3), how to back propagate these gradients on the second mini-batch?",https://stackoverflow.com/questions/51449027,7886651.0,1
1287,69595923,How to decrease the learning rate every 10 epochs by a factor of 0.9?,I want to set the learning rate at 10^-3 with a decay every 10 epochs by a factor of 0.9. I am using the Adam optimizer in Tensorflow Keras. I have found this code in the official documentation: I do not know what is this decay_steps=100000. Actually I want to decrease my learning rate after 10 epochs. How can I do it?,https://stackoverflow.com/questions/69595923,14808637.0,1
1288,56951177,Computing gradients of keras output with respect to the network inputs?,"If i have a network in Keras with some input variables say x, y, z. How would i calculate the gradient of the outputs with respect to each of these inputs (x,y,z). I have been looking around and can't find a clear answer to this and haven't managed to work it out myself after messing around with tf.gradients for a while. I have seen this question Keras with TF backend: get gradient of outputs with respect to inputs but this is not clear at all to me and i don't understand what to do or how to implement it. Any help and simple example would be great, thanks. EDIT: Here is a concrete example of what i am looking for. Consider for example the function f(x,y,z) = x^2 + y^2 + z^2. If I trained the neural network on random examples of x,y,z and function values f(x,y,z) and approximated the function f(x,y,z), what i would like to do is to then use the network to return the gradient of the function with respect to each of the inputs individually. The gradient vector for this example would be given by f'(x,y,z) = 2x + 2y +2z. So once the network is trained, for a given input vector (x,y,z) i would like to not only approximate the function value but also its derivatives with respect to the inputs, for example, once the network has been trained if i provided say the input vector (1,2,3) to the network, i would not only like to get the network approximation for f(1,2,3) = 1^2 + 2^2 + 3^2 = 14, but i would like to get the approximation for the derivative of f(x,y,z) with respect to each of the individuals separately, so in this case i would want to approximate the partial derivative of f(x,y,z) with respect to x=1 which would of course be 2, and likewise for the partial derivative of f(x,y,z) with the respect to the other two inputs, which are 4 and 6 respectively. This is just a simple example of what i would like to do.",https://stackoverflow.com/questions/56951177,11705178.0,1
1289,45711708,How can I do a non-cumulative tensorflow scatter_add?,"As part of learning my way around tensorflow I am converting some existing matrix-processing logic. One of the steps is a scatter operation such as the one using scatter_add in the example below. My problem with this example is that each time the operation is evaluated, it adds cumulatively on top of the previous result. With the 3 run() calls as shown below, the results printed are: Whereas what I want is [[8 12 8]...] every time. The indices vector contains duplicates, and the corresponding elements in updates need to be added together, but not to the existing value already held in scattered. None of the scatter operations in the tensorflow documentation seem to be what I'm looking for. Is there an appropriate operation to use? If not, what is the best way to achieve what I need?",https://stackoverflow.com/questions/45711708,8463507.0,1
1290,47298866,Tensorflow Conv2D SAME padding when Stride is larger than Kernel Size,"I'm running into a weird issue trying to compare my implementation of a convolution operator with tensorflow's dealing with the SAME padding. According to this post the SAME padding is calculated as follows: I was running some random testing and narrowed down a mismatch between my implementation and tensorflow's with the following tf(1.4.0) program: Since the filter is 1x1, and it's value is 1.0, it will be easy to see which input element the is used to calculate the output value: Changing the padding to 'VALID' gives the expected result of 1.0: Alternatively if you change the stride to be (2x1) we get expected result for output[0]: Any guess as to what's going on? My only thought is that the actual TF implementation is not protecting against the padding calculation from going negative and it's calling tf.pad (or something equivalent) with a negative padding, and as a result actually removing the first element of the input, making the new (padded) input[0] = 1.1.",https://stackoverflow.com/questions/47298866,314864.0,1
1291,42068999,Tensorflow: Convolutions with different filter for each sample in the mini-batch,"I would like to have a 2d convolution with a filter which depends on the sample in the mini-batch in tensorflow. Any ideas how one could do that, especially if the number of sample per mini-batch is not known? Concretely, I have input data inp of the form MB x H x W x Channels, and I have filters F of the form MB x fh x fw x Channels x OutChannels. It is assumed that inp = tf.placeholder('float', [None, H, W, channels_img], name='img_input'). I would like to do tf.nn.conv2d(inp, F, strides = [1,1,1,1]), but this is not allowed because F cannot have a mini-batch dimension. Any idea how to solve this problem?",https://stackoverflow.com/questions/42068999,3990607.0,1
1292,53209495,Tensorflow: copy existing graph into new graph multiple times,"I want to paste an existing tensorflow graph into a new graph. Suppose I create a graph computing y = tanh(x @ w) Great. Now suppose I've lost the code that generated that graph, but I still have access to variables (x, y). Now I want to take this graph (using the current value of w), and copy it twice into a new graph (the two paths should share the same w), so that I now compute d = tf.reduce_sum((tanh(x1 @ w)-tanh(x2 @ w))**2) by adding the line: What do I fill in for &lt;SOMETHING HERE&gt; to make this work? (Obviously, without recreating the first graph)",https://stackoverflow.com/questions/53209495,851699.0,1
1293,63552222,Flatten entire batch in Tensorflow Keras functional API,"I would like to faltten an entire batch in my network to further process data. Here is an example of a layer I would like to flatten completely (including batch dimension) I found this post, which seems not to cover Tensorflow 2.x. How can I flatten an entire batch in TF 2.x?",https://stackoverflow.com/questions/63552222,3861775.0,1
1294,74007730,"TypeError: Expected binary or unicode string, got tf.RaggedTensor(values=Tensor",I get the errors below when loading a model in a separate script to make inferences. I'm able to train and save the model without a problem. My model is almost identical to the one in the Keras documentation HERE: https://keras.io/examples/nlp/pretrained_word_embeddings/ my training session runs without a hitch. I'm even able to make predictions in the same training session. I'm loading my model as follows: I'm running Keras 2.6.0 the full call back is:,https://stackoverflow.com/questions/74007730,13629177.0,1
1295,59718624,Create my own convolutional network without using Keras,I've just started with AI and implementing my own CONV networks. I have this conv network: Is there any way to implement the Conv2D layers without using keras? I want to try to understand how they work implementing them by myself.,https://stackoverflow.com/questions/59718624,68571.0,1
1296,34908033,ValueError when performing matmul with Tensorflow,"I'm a total beginner to TensorFlow, and I'm trying to multiply two matrices together, but I keep getting an exception that says: Here's minimal example code: Confusingly, the following very similar code works fine: Can anyone point to what the issue is? I must be missing something obvious here..",https://stackoverflow.com/questions/34908033,2225493.0,1
1297,69857097,How do I find the max value in a tensorflow dataset batch across a specific number of columns?,"Suppose the following code below: Let me explain what the above code does. It creates many features and labels. Then it takes the maximum value from each column and adds it the individual values in the column. For instance, this feature and its corresponding label: have the following max values in each column: The max-values are then added to the corresponding column and you get the final output: Instead of extracting the maximum value from each column, I want to extract the maximum value from the first three columns and the last two columns of each feature and its corresponding label. After the extraction, I want to add the max value to each value in the corresponding column. For instance, in the above example, the max value would be 6 for the first three columns and 7 for the last two columns. After that, 6 would be added to each value in the first three columns and 7 to each value in the last 2 columns. The final output for the first batch would look like this: Has anyone got an idea how to extract the max value from the first three columns and the last two columns in each batch?",https://stackoverflow.com/questions/69857097,4015352.0,1
1298,52992821,Tensorflow graph fetch all consts in a scope,"I create a graph and now I want to fetch their ops, how can I do this? Can you show me document links about this?",https://stackoverflow.com/questions/52992821,6935676.0,1
1299,63792603,"implementing unpooling layer in u-net, InvalidArgumentError is occurred","I am using EM_dataset segmentation, keras2.3.1 and tensorflow 2, in google colab Here is my code. This is a U-net. also I am using ImageDataGenerator in keras Network is fine but If i do fit, Error is occured InvalidArgumentError: Input to reshape is a tensor with 12800 values, but the requested shape has 25600 [[node functional_33/tf_op_layer_Reshape_393/Reshape_393 (defined at :4) ]] [Op:__inference_train_function_56708] I don't know why this error is occured... please some help...",https://stackoverflow.com/questions/63792603,9828302.0,1
1300,43848414,How is memory managed during tensor transformations?,"Even if the question involves TensorFlow, I will use normal math terminology to describe my question. Let's say that After reading some code examples, the way I do it now is as it follows (n = self.nNodes, k=self.inputShape): It seems to be - but I am not sure - that, after a while, TensorFlow has some difficulties in managing the memory (especially on the GPU) since the expand_dims and tile operations return new tensors. Is there any way to allocate a tensor for X_MM (as I do for W) and copy the input value x into each element of X_MM. In this way the memory for X_MM would be allocated only once. Is there an ""atomic"" instructions for copying a vector, line by line, into another (a sort of tiling without allocating new memory)? Should I use a TensorFlow iterator for obtaining this? More in general, should I worry about memory management with TensorFlow? It seems to me it is an important topic, but cannot find any relevant info on the documentation and all of the examples I see use operators that allocate new memory.",https://stackoverflow.com/questions/43848414,774133.0,1
1301,43504906,How do I read variable length 1D inputs in Tensorflow?,"I'm trying to read variable length 1-D inputs into a Tensorflow CNN. I have previously implemented reading fixed length inputs by first constructing a CSV file (where the first column is the label and the remaining columns are the input values - flattened spectrogram data all padded/truncated to the same length) using tf.TextLineReader(). This time I have a directory full of files each one containing a line of data I want to use as input (flattened spectrogram data again but I do not want to force them to the same dimensions), and the line lengths are not fixed. I'm getting an error trying to use the previous approach of compiling a CSV first. I looked into the documentation of tf.TextLineReader() and it specifies that all CSV rows must be the same shape, so I am stuck! Any help would be much appreciated, thanks :)",https://stackoverflow.com/questions/43504906,3296050.0,1
1302,41614400,tensorflow run takes forever on small data,"I'm trying a simple example of a book where I have a train data sample with 892 lines, the usual titanic survival textbook example. I define: And now I try to do: and I see but the run part hangs forever (or at least a very long tiem). I'm running this on Jupyter with a 2.7 kernel and tf version 0.12 What am I missing?",https://stackoverflow.com/questions/41614400,1225744.0,1
1303,55399080,Returning specific elements with Dataset api,i wrote a tfrecord file in which i have images and their labels.Then i can pick them up using after that i want to filter out some examples using probably something like this: but i get this error:,https://stackoverflow.com/questions/55399080,7248145.0,1
1304,67986384,keras LSTM: An `initial_state` was passed that is not compatible with `cell.state_size`,"I'm building a very simple NN made of 1 LSTM layer. The code is as follows: When I run this code, I get the following error: I don't understand why the cell.state_size is [15,15]. However, even when I tried to input an array of zeros having this size, I still get the same error. Any help?",https://stackoverflow.com/questions/67986384,16233252.0,1
1305,56104993,Defining Keras Models for Arrays,"I have 3 inputs that will go into my model, They are: 1. 20 X 20 List 2. n numbers of X [2] array or like [ [a,b], [c,d], ......] 3. [a,b] array That's it making the model simple but I do not understand how to define the inputs and outputs for this. The model should have 2 hidden layers of 32 each.",https://stackoverflow.com/questions/56104993,10462295.0,1
1306,65568205,Why don't I get the same result as with tensorflow's method when I write my own expression?,"I'm learning logistic regression and I want to calculate what is the value of the cross entropy loss function during minimizing it via gradient descent, but when I use tensorflow's sigmoid_cross_entropy_with_logits function, I get different result from what I get via my own expression. Here is an example: The output: Can anyone explain to me what's wrong with this? I checked the tensorflow documentation about their function, and it seems like it should be doing exactly the same as my expression.",https://stackoverflow.com/questions/65568205,6866590.0,1
1307,68495571,Tensor Name doesn't show when trying to print it,I tried to initialize a tensor with a specific name and print it with the following code: But the output does not show the tensor name: Is there a reason why the output is like this? (I've seen examples of it working and showing the tensor name),https://stackoverflow.com/questions/68495571,14340277.0,1
1308,60259037,Reading a TensorArray in Tensorflow always returns zeroes,"I am using Tensorflow v1.15. I have a very basic implementation of the TensorArray given in the following example: The print in the for loop does not print all zeros, while the last print statement does. Why is this happening? Thanks.",https://stackoverflow.com/questions/60259037,6997665.0,1
1309,48769142,Tensorflow: How to use dataset from generator in Estimator,Trying to build simple model just to figure out how to deal with tf.data.Dataset.from_generator. I can not understand how to set output_shapes argument. I tried several combinations including not specifying it but still receive some errors due to shape mismatch of the tensors. The idea is just to yield two numpy arrays with SIZE = 10 and run linear regression with them. Here is the code: Another question is if it is possible to use this functionality to provide data for feature columns which are tf.feature_column.crossed_column? The overall goal is to use Dataset.from_generator functionality in batch training where data is loaded on chunks from a database in cases when data does not fit in memory. All opinions and examples are highly appreciated. Thanks!,https://stackoverflow.com/questions/48769142,9354535.0,1
1310,50113938,Tensorflow-tf.concat() shows different results,"then it shows t1 and t2 have the same shape and value, why the result is different?",https://stackoverflow.com/questions/50113938,6642434.0,1
1311,49883861,"In tensorflow slim models, alexnet_v2.py, use conv2d instead of fully connected layer","In the implementation, it uses conv2d instead of fully_connected_layers. The tensor shape from pool5 is 6*6*256. After a kernel size 5*5 no padding, stride =1, output should be 2*2*4096. But from the fully_connected layer implementation, the neuron is 4096. Could anyone explain this? Thank you very much.",https://stackoverflow.com/questions/49883861,8604859.0,1
1312,47599461,TensorFlow - 3D tensor that gathers every Nth tensor from 2D tensor and strides 1,"Suppose I have a 2D-Tensor T in [M, 1] e.g. and I want to reshape it like so: I know M and N (the number of tensors in each group) in advance. Further, let t_reshp.shape[0] = M/N = P in the I have tried using tf.reshape However, I end up with: Can I do this using some slicing or reshape operation?",https://stackoverflow.com/questions/47599461,2399935.0,1
1313,56479870,Difference between tf.constant and tf.Variable (trainable= False),I came across some code where tf.Variable(... trainable=False) was used and I wondered whether there was any difference between using tf.constant(...) and tf.Variable(with the trainable argument set to False) It seems a bit redundant to have the trainable argument option available with tf.constant is available.,https://stackoverflow.com/questions/56479870,2443944.0,1
1314,48910416,"Explain why does Tensorflow throw ""Attempting to use uninitialized value"" during linear transform",I am trying to apply tf.layers.dense on a tensor while running jupyter notebook. The code I am using raises FailedPreconditionError: Jupyter notebook code: I am new to Tensorflow and the idea I am playing with is how to apply linear transformation on a 5x3 tensor and transform it into 5x100 tensor when you have a 3x5x3 input tensor. So that we could convert 3x5x3 tensor to 3x5x100 tensor.,https://stackoverflow.com/questions/48910416,1984680.0,1
1315,45437572,Tensor Shape Error: Must be rank 2 but is rank 3,"I am having difficulty searching for documentation, studies, or blogs that can help me in building text sequence (features) classifier. The text sequence that I have contains logs of network. I am building a GRU model using TensorFlow, with an SVM as the classification function. I am having trouble with the tensor shapes. It says ValueError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [?,23,1], [512,2]. Here is a sample of the data I am using for training my neural network. The goal of my project is to use this GRU-SVM model for intrusion detection on Kyoto University's honeypot system intrusion detection dataset. The dataset has 23 features, and a label (if there is an intrusion in the network or none). Note: The reason why I built my MultiRNNCell as I did (snippet isolated below) is because I was having an error similar to this post. Thank you in advance for your response! Update 08/01/2017 The source was improved based on @jdehesa's sugestions: My next move is to validate if the results I'm getting are correct.",https://stackoverflow.com/questions/45437572,6838049.0,1
1316,62446010,"Keras Creating CNN Model ""The added layer must be an instance of class Layer""",enter image description here,https://stackoverflow.com/questions/62446010,10147786.0,1
1317,63859629,"Getting a ValueError in tensorflow 2.x: ValueError: Shapes (50, 6) and (50, 100) are incompatible","I am fairly new to tensorflow and I have this simple model: When I try to fit the model with: I get the following error: ValueError: Shapes (50, 6) and (50, 100) are incompatible I have this dataset: &lt;MapDataset shapes: ((50, 6), (50, 6)), types: (tf.int64, tf.int64)&gt; I used this code to make the dataset: I am trying to make a model that, given a sequence of arrays, it will predict the next element in the sequence. I am using google colab to run my code. Any help will be appreciated.",https://stackoverflow.com/questions/63859629,14168968.0,1
1318,46371866,Tensorflow table lookup int->float,"Given a 2D Tensor of unknown dimensions [?, ?] containing integers (representing classes), I would like to obtain a new Tensor of the same shape, but with the values replaced by floats taken from a lookup table (representing class weights). For example: I have tried to chain two lambda functions with tf.map_fn, iterating over every row, then over every element: but could not find a proper way of defining the lookup function. Any advice on how to implement this behaviour ? Is there a native op that I could use instead of map_fn ?",https://stackoverflow.com/questions/46371866,3115923.0,1
1319,43147428,MNIST Tensorflow example,"This is the code from the Deep MNIST for experts tutorial on Tensorflow website. I have two questions: 1) The documentation k-size is an integer list of length greater than 4 that refers to the size of the max-pool window. Shouldn't that be just [2,2] considering that it's a 2X2 window? I mean why is it [1, 2, 2, 1] instead of [2,2] ? 2) If we are taking a stride step on size one. Why do we need a vector of 4 values, wouldn't one value suffice? 3) If padding = 'SAME' why does the image size decrease by half? ( from 28 X 28 to 14 X 14 in the first convolutional process )",https://stackoverflow.com/questions/43147428,6203717.0,1
1320,38743538,How to fetch specific rows from a tensor in Tensorflow?,"I have a tensor defined as follows: I also have an array of indexes of rows to be fetched from tensor: Now I want to take a subset of temp_var at those indexes i.e. idx I know that to take a single index or a slice, we can do something like or But how to fetch rows indicated by idx array? Something like temp_var[idx, :] ?",https://stackoverflow.com/questions/38743538,2745266.0,1
1321,42418029,Unable to use summary.merge in tensorboard for separate training and evaluation summaries,"I am trying to use tensorboard to watch the learning of a convolutional neural net. I am doing good with the tf.summary.merge_all function to create a merged summary. However, I would like to have tracking on accuracy and loss both for training and test data. This post is useful:Logging training and validation loss in tensorboard. To make things easier to handle, I would like to merge my summaries into two merged summaries, one for training and one for validation.(I will add more stuff eventually, like images weights etc.) I tried to follow the description from tensorboard tf.summary.merge. I can't make it work and I am unable to find any working examples to help me understand where I am going wrong. This results in the following error: I would like to know why this doesn't work, and how I can find a solution, any working examples are appreciated.",https://stackoverflow.com/questions/42418029,4274789.0,1
1322,71686704,TensorFlow 2.4.1 loadmodel throws an error,"python 3.6.9 and tensorflow 2.4.1 I have a simple working inference function as following: When I try to call a custom loadModel(frozen_model) function, having the same function body: it throws this weird error: What changes when loadModel() returns the infer object to inference()? Is it a bug or I am missing something here? Thanks!",https://stackoverflow.com/questions/71686704,2815551.0,1
1323,68276292,How to encode binary data for prediction input in Vertex AI,I have searched high and low across StackOverflow to solve this issue but either the answers are outdated (don't used TF 2.x) or are too complicated. I have created a model as so: I am saving the model as thus and want to host this SavedModel on Vertex AI Predictions. Is there a different way I should save the model? I want to use binary data encoded as base64 strings as prediction inputs. The official documentation from Vertex AI for online predictions says: My question is thus: How should export my SavedModel such that I can use base64 strings to send requests for online predictions?,https://stackoverflow.com/questions/68276292,5052482.0,1
1324,69025265,Multi task classification CNN,"i have a df which is constructed like this, i have 5 columns and i have to perform a multi task or multi output classification my problem is when i have done the flow from dataframe, i don't know how to use tf.data.dataset in order to build the dataset. Someone suggest me to use TFRecords but i have never used it. How can i do without using it?",https://stackoverflow.com/questions/69025265,16802587.0,1
1325,43515986,Getting a simple plot in Tensorboard,"I'm trying to a simple plot on tensorboard, just like they have it on homepage, something like this: To understand how this is working I've wrote the following : while I can see the graph, I can't see any scalar value. Can any explain to me what I'm doing wrong here? PS: I've run all official examples and they are all working but I need to understand this example to be able to work with it. Thanks for any help ! Update after run @dv3 code the program crashs. and here is what I get:",https://stackoverflow.com/questions/43515986,1563123.0,1
1326,58527048,Accessing intermediate layers from a loaded saved_model in Tensorflow 2.0,"When using SavedModels in Tensorflow 2.0, is it possible to access activations from intermediate layers? For example, with one of the models here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md, I can run, for example, to get output predictions and bounding boxes. I would like to be able to access layers other than the outputs, but there doesn't seem to be any documentation for Tensorflow 2.0 on how to do this. The downloaded models also include checkpoint files, but there doesn't seem to be very good documentation for how to load those with Tensorflow 2.0 either...",https://stackoverflow.com/questions/58527048,11357382.0,1
1327,40753861,Tensorflow saving error,"I have a python class which creates a model and a corresponding tf.Saver object: I then proceed to call this function (defined in the same class as above), passing it my current tensorflow Session: However, I get the following error when I make a call to the function above:",https://stackoverflow.com/questions/40753861,7133559.0,1
1328,49984317,Running a basic distributed MNIST solver in TensorFlow,"I'm trying to learn a model to predict MNIST classes in distributed TensorFlow. I've read the main distributed TensorFlow page, but I don't understand what I run to create a distributed TensorFlow model. I'm just using a linear classifier for the moment, based on the code here. How do I run this model? The link I got the code from says that this command should be run in the terminal: If I run this in the terminal, I get the following messages: This message just repeats indefinitely. So how do I start the training process? For reference, the model is defined as follows:",https://stackoverflow.com/questions/49984317,6392842.0,1
1329,50083055,tf.map_fn & tf.range confusing result,"Here is the reproducible code: This code is expected to output a [[1,2,3], [5,6]]. However, I get an error of: Do I misunderstand the usage of tf.range() and tf.map_fn() or is it a bug?",https://stackoverflow.com/questions/50083055,4845608.0,1
1330,67128487,Unsolved 'tensorflow.python.keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects',I'm doing a Detection model and I'm in the step of Configuration For Transfer Learning. The error shows when I try to do these import: I have already insert in C:\Users\Chiara\AppData\Local\Programs\Python\Python38\Lib\site-packages\tensorflow\python\keras\utils but it doesn't work. I don't have tf.nighly installed. This is the traceback: Also from the pip list I understand that I have installed tensorflow 2.4.1 but if I do tf .__ version__ it tells me 2.2.0. I have Python 3.8.1. Thank you so much !!,https://stackoverflow.com/questions/67128487,14094546.0,1
1331,53588987,python3 TensorFlow Check failed: new_num_elements == NumElements() (96 vs. 60000),I'm coding up a basic Neural Network using TensorFlow(1.12.0) in Python(3.6.7). Everything seems to work fine individually but I'm getting this error message when I run the model(). I haven't used the number 96 anywhere in my code as far as I can tell. I've provided my code below: model.py: preprocessing.py: parameter.py: forward.py: cost.py: Full output:,https://stackoverflow.com/questions/53588987,3396545.0,1
1332,53001403,Tensorflow: Strange behavior with splitting string in tf.data.Dataset,"I'm using the tf.data.Dataset API in Tensorflow. I have 2 numpy arrays, where data is 2-d and labels is 1-d. I've created a Dataset like this: I have a preprocessing function I'd like to use that looks like this: I try to use map like this: but I get back: I googled around and found that someone suggested this approach in the preprocessing function: But it's unclear to me why I would do that. It doesn't error out as before, but the shape of my data is incorrect. For instance, this is what I see for the first element in my dataset: So the dictionary value is a 2-d array when it should only be 1-d. Where am I going wrong? Thanks!",https://stackoverflow.com/questions/53001403,1316501.0,1
1333,56465346,LSTM timesteps in Sonnet,"I'm currently trying to learn Sonnet. My network (incomplete, the question is based on this): In other frameworks (eg. Keras), LSTM inputs are of the form (batch_size, sequence_length, input_length). However, the Sonnet documentation states that the input to Sonnet's LSTM is of the form (batch_size, input_length). How do I use them for sequential input? So far, I've tried using a for loop inside _build, iterating over each timestep, but that gives seemingly random outputs. I've tried the same architecture in Keras, which runs without any issues. I'm executing in eager mode, using GradientTape for training.",https://stackoverflow.com/questions/56465346,5533928.0,1
1334,56315222,Dimensional error when trying to train keras model,"I want to build a 3d dcgan out of a 2d dcgan. While everything worked for 2d, in 3d I got a dimensional error when trying to train the generator. Sadly, the error thrown is pretty cryptic and I can't make much out of it: As of now I checked if each model can run by itself and they do. As expected the generator gives me a cube and the discriminator does it's job too. I tried looking up the mkl_util header. This is my init: And, here the error occurred self.combined.train_on_batch(noise, valid) I wouldn't expect that result at all as the generating model runs by itself and so does the discriminator.",https://stackoverflow.com/questions/56315222,8216929.0,1
1335,61434932,Keras model doesn't load weights,"I can get the model to train, I am having a problem with loading and testing it on new data. I was able to verify my model by loading new data before saving and making a prediction (see code example). The documentation from Keras on how to load and save a model does not work for me. The code for training, testing, saving and loading it: Results from use_cnn_model(): Output of main():",https://stackoverflow.com/questions/61434932,11237191.0,1
1336,52732523,Input to tensorflow in_top_k should be rank 1 or rank 2?,I try to experiment with in_top_k function to see what exactly this function is doing. But I found some really confusing behavior. First I coded as follows Then it generates the following error: Then I changed my code to But now the error becomes So should the input be rank 1 or rank 2?,https://stackoverflow.com/questions/52732523,7701224.0,1
1337,75410827,How does masking work in Tensorflow Keras,"I have difficulty understanding how exactly masking works in Tensorflow/Keras. On the Keras website (https://www.tensorflow.org/guide/keras/masking_and_padding) they simply say that the neural network layers skip/ignore the masked values but it doesn't explain how? Does it force the weights to zero? (I know a boolean array is being created but I don't know how it's being used) For example check this simple example: I asked the Embedding layer to mask zero inputs. Now look at the output: If you change the ""mask_zero"" argument to False you get the exact same results. Does anyone know what's happening behind the scene? Any resources explaining the masking mechanism more thoroughly is highly appreciated. P.S: This is also an example of a full Neural Network which gives an identical outcome with and without masking:",https://stackoverflow.com/questions/75410827,12014637.0,1
1338,73340784,Tensorflow Recommenders : Getting back a array of tensors instead of actual value,"I am trying to use the TFRS libraries for my custom datasets and leverage context features in the candidate tower, following the notebook in the below link : https://www.tensorflow.org/recommenders/examples/context_features However this notebook does not have code snippet to get the actual predictions. I tried to use the following code to get the predictions : But it gives me tensors and not actual values, as below : Can anyone please help with pointer on either directly getting the predictions or a quick way to reverse look up these tensors back to meaningful values ?",https://stackoverflow.com/questions/73340784,6599018.0,1
1339,42074595,Convolution neural network output value in range,"i'm trying to learn about convolution neural network using tensorflow , i'm using the code bellow to create my network . this network take a [80,80,4] object an output a ACTIONS prediction ;(ACTIONS number of classes) My question is how to create a network that output a value between [a,b]",https://stackoverflow.com/questions/42074595,6409135.0,1
1340,66187358,Using the prediction from tensorflow model,I used the following code to create a prediction on new data: which provides: And then I can print the value via: But I want to use the value in a future calculation such as: Which I would want to have return: But as of now I cannot find a way to extract out and use the prediction.,https://stackoverflow.com/questions/66187358,2438475.0,1
1341,41865218,Interleaving slim.dropout and slim.fully_connected in slim.stack?,"In tf.slim, I'd like to create a stack of fully-connected layers with dropout. To the example from documentation: slim.stack(x, slim.fully_connected, [32, 64, 128], scope='fc'), I'd like to add dropout. Is it possible to use slim.stack or do I have to go back to the verbose approach?",https://stackoverflow.com/questions/41865218,314710.0,1
1342,65564663,Using Tensorflow Estimators with Dataset API results in strange steps behavior,"I'm facing some issues regarding the behavior of the training loop of Tensorflow's Estimator and Dataset APIs. The code is as follows (tf2.3): I just don't understand the behavior I'm seeing though. Number of steps the TF estimator trains for seems to be capped at 300 steps, regardless of whatever I set for batch_size, training steps or number of epochs. My dataset has 8K training elements, when I'm choosing n_epochs=100 with a batch_size=1000 and steps=None, I'm expecting tensorflow will run 100 (n_epochs) * 8 (steps required for 1 epoch) steps, but no, it runs 300. Below is actually a summary of multiple experiments with different N_EPOCHS, BATCH_SIZE and STEPS, the first 3 to me are fine, but not the rest. As can be seen, from the 4th row onwards, my expectation is not equal to the actual steps the tensorflow training runs. This basically means when I lower batch_size to say 10 it only runs 300 epochs on the size 10 batch of the data which is wrong, but I'm failing to understand what is incorrect with my implementation, looking at the docs so any help is super appreciated! Also it doesn't matter if I use train_and_evaluate with Specs or directly train, it's train here for simplicity. The log for the train function is as follows (for the 7th experiment):",https://stackoverflow.com/questions/65564663,1597771.0,1
1343,57879330,Getting imagenet model pnasnet_large with to work with hub.KerasLayer,"I am trying out various Tensorflow models from hub but I can't seem to get this one to work with KerasLayer: ""https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/3"" I am using the same procedure used within the examples in the documentation: https://www.tensorflow.org/tutorials/images/hub_with_keras feature_extractor = hub.KerasLayer(URL, input_shape=(height, width,3)) even tried a few amendments such as including: trainable=True, tags={""train""}), so it would look like this: feature_extractor = hub.KerasLayer(URL, input_shape=(height, width,3), trainable=True, tags={""train""})) because that's what it said to do in the docs. However, I am still getting this error:",https://stackoverflow.com/questions/57879330,6802252.0,1
1344,73359572,normalize trained data with tensorflow,"this is the code from the TensorFlow website, but doesn't explain well, i know what is the goal of this code which is to normalize data and make it between 0 and 1 instead of 0 to 255, but I need to understand what does lambda means here.",https://stackoverflow.com/questions/73359572,4399890.0,1
1345,47383336,How do I use the output of one RNN applied to slices as input of the next?,"Suppose I have training data X, Y where X has shape (n,m,p) I want to set up a neural network which applies a RNN (followed by a dense layer) given by f to each i-slice (i,a,b) and outputs f(m,x) which has shape (p') then concatenates all the output slices (presumably using tf.map_fn(f,X)) to form a vector of dimension (n,p') then runs the next neural network on (n,p'). Essentially something similar to: X' = tf.map_fn(f,X) Y= g(X') I am having difficulty getting my head around how to prepare my training data, which shape should X, X' (and later Z) should be. Further more what if I wanted to merge X' with another dataset, say Z? Y = g(X' concat Z)",https://stackoverflow.com/questions/47383336,6246353.0,1
1346,53125515,How to restore Tensorflow model from Google bucket without writing to filesystem?,"I have a 2gb Tensorflow model that I'd like to add to a Flask project I have on App Engine but I can't seem to find any documentation stating what I'm trying to do is possible. Since App Engine doesn't allow writing to the file system, I'm storing my model's files in a Google Bucket and attempting to restore the model from there. These are the files there: Working locally, I can just use Where the model is loaded into memory using Flask's @before_first_request. Once it's on App Engine, I assumed I could to this: Then do the same restore. But App Engine won't allow it. Is there a way to stream these files into Tensorflow's restore functions so the files don't have to be written to the file system?",https://stackoverflow.com/questions/53125515,3711940.0,1
1347,50066313,Tensorflow - 2D convolution with mutliple channels,"I am defining my input and my kernels in this way And convolve the two using Yielding a result of What I want to do is to perform one convolution with one ""subfilter"" over the input at the time. Doing it myself with pen and paper, I get All other permutations of the ""reshape-parameters"" yield errors and I cannot find what I am doing wrong in the TF documentation. Does anyone know what I am doing wrong?",https://stackoverflow.com/questions/50066313,4308982.0,1
1348,61219672,Why isn't my so simple linear regression working,"I am new to tensorflow-2 and I was starting my learning curve, with the follow simple Linear-Regression model: For a reason I don't understand it seems like my model is not fitting the curve. I also tried with keras.layers.Dense(1) and I had the same exact result. Also it seems like the results don't correspond to a proper loss function, as around epoch 120 the model should have less loss than on 250. Can you maybe help me understand what I am doing wrong? Thanks a lot!",https://stackoverflow.com/questions/61219672,2227026.0,1
1349,50201953,"Tensorflow, tf.train.batch, no result","I'm a newbie about tf.train.batch, so i wrote a sample to test it. When i run the code, i got no result and the process was still running. Have you met the same situation before? Many thanks in advance! Plus, the function tf.train.slice_input_producer works. When i ignore tf.train.batch, the code becomes: The result is :",https://stackoverflow.com/questions/50201953,9749096.0,1
1350,38117252,Tensorflow: LSTM with moving average of weights of another LSTM,"I would like to have an LSTM in tensorflow whose weights are the exponential moving average of the weights of another LSTM. So basically I have this code with some input placeholder and some initial state placeholder: What I would like to do now is something similar along these lines (which don't actually work because the exponential moving average puts the tag ""ema"" behind the variable name of the weights and they do not appear in variable scope because they were not created with tf.get_variable): where eventually theta_2_1 would be equal to theta_2_2 (or throw an exception because the variables already exist).",https://stackoverflow.com/questions/38117252,6531677.0,1
1351,74809221,Model's prediction doesn't work. (Facial Expressions Kaggle) InvalidArgumentError: Computed output size would be negative: -1,"To begin with I'm very very new to python and to ML, which means i don't understand many things written, but the idea was to take trained model from Kaggle and predict the expression on my test photo, When is works, then try to go deeper into understanding the code. But i suck here... file_name = 'kaggle_model.h5' model_path = os.path.join('checkpoint',file_name) Output: There are couple of posts with the same problem here in stack, but i couldn't figure out the solution on that basis. Many thanks in advance! If i try to reshape the image such as then i get a different problem and this test_image=test_image.reshape(48,48,1) gives",https://stackoverflow.com/questions/74809221,17675352.0,1
1352,42852323,Tensorflow LinearRegressor evaluate method hangs,"Consider the following toy TensorFlow code. The fit method of LinearRegressor works properly and finds the right coefficients (i.e. y = x1 + x2), but evaluate (see the last print statement) hangs. Any idea what's wrong?",https://stackoverflow.com/questions/42852323,856803.0,1
1353,39176529,Tensorflow - TextSum model: How to create my own training data,"I am trying to create my own training data for TextSum model. As my understanding, I need to put my articles and abstracts to a binary file (in TFRecords). However, I can not create my own training data from raw text files. I don't understand format very clearly, so I am trying to create a very simple binary file using the following code: And I try to use the following code to read out the value of this test_data file But I always get the following error: I have no idea what is wrong. Please let me know if you have any suggestions to solve this issue.",https://stackoverflow.com/questions/39176529,461640.0,1
1354,56434667,Tensorboard callback on keras gives InvalidArgumentError when training multiple networks,"I have a method train_model which gets a keras model object as input and trains it. I have a loop somewhere else in my code that creates a new model in each iteration and passes it to this method. If I don't pass a TensorBoard Callback my code works fine. However, when I do pass the TensorBoard Callback, the first network gets trained but for the second one I get this error: after calling .fit method. (the network i'm building is 5 layers) and there is more unexpected behaviors: When I run this code for a second time, the first network won't need training (since I have already saved the model and it will just load that) and the second network gets trained with no errors but I get the same error for the third network. In this case, when I check the TensorBoard graphs, I see that the first network has been created correctly, but the second network has twice the layers it should have (as if the first model has been loaded first and then the second network was built on it). here is my train_model method: I have done everything I could and i'm really out of ideas about what's wrong with my code. Any help is appreciated. thanks in advance.",https://stackoverflow.com/questions/56434667,6411761.0,1
1355,47796453,predict new data by pre-trained model in tensor-flow,"I trained a LSTM model in tensor-flow and I want to predict new data based on it. However, I keep getting an error I can't understand: This is the model: And the prediction part: the shape of X_as_batch is as expected by pred (it's shape is [5126, 60, 39] and the shape of pred is [?, 60, 39]) But I get the error What might be the reason?",https://stackoverflow.com/questions/47796453,6057371.0,1
1356,48169011,"How split pre loaded data in fix length along the 0-dim, to use them with the QueueRunner in Tensorflow?","Is there anything comparable to the tf.FixedLengthRecordReader only with the difference that the data is loaded from a tensor instead of a file? I try to build an input pipeline that looks like this (My problem is described under point 4.): At this point I would like to use database similar to a file which is read with the function read() from tf.FixedLengthRecordReader. In my current solution, the whole data set is packed in a batch. I don't know if it's relevant but the whole thing runs as a multi GPU system I don't have an answer to the question yet, but I have a solution for the problem that should solve the answer to my question. So instead of saving the datapoints in a tensor, I save them in a binary file and load them with tf.FixedLengthRecordReader. This answer has helped me a lot: Attach a queue to a numpy array in tensorflow for data fetch instead of files?",https://stackoverflow.com/questions/48169011,6444384.0,1
1357,51593212,Soft attention from scratch for video sequences,"I am trying to implement soft attention for video sequences classification. As there are a lot of implementations and examples about NLP so I tried following this schema but for video 1. Basically a LSTM with an Attention Model in between. 1 https://blog.heuritech.com/2016/01/20/attention-mechanism/ My code for my attention layer is the following which I am not sure it is implemented correctly. So, adding this layer in between my LSTMs (or at the begining of my 2 LSTM) makes the training so slow. More specifically, it takes a lot of time when I declare my optimizer: My questions are:",https://stackoverflow.com/questions/51593212,7611967.0,1
1358,76282813,Memory leak after calling Keras model.fit(),"I wrote my custom Keras layer called Material and tried using it in my model: For some reason it turns out to use more and more RAM after each fit iteration (I mean function call, not each epoch). At around 5 GB the memory usage growth slows down but still continues. And the problem is present both on CPU and GPU. Could anyone explain what is going on? Is there something wrong with my custom layer? Thanks for any suggestions.",https://stackoverflow.com/questions/76282813,15450358.0,1
1359,49969349,Hidden states vs. final state returned by Tensorflow's dynamic_rnn,"tensorflow.nn.dynamic_rnn creates a recurrent neural network given cell, which is an instance of RNNCell, and returns a pair consisting of: Here is a toy recurrent neural network as well as its output[*]: Output: My understanding is as follows: thus, am I not supposed to get the same values in h component of the finale state and in the last hidden state of each sequence? [*] Code largely inspired from this post",https://stackoverflow.com/questions/49969349,3441514.0,1
1360,58815710,Tensor.graph is meaningless when eager execution is enabled,tensorflow-gpu2.0 i don't know why. i am a beginner of tensorflow,https://stackoverflow.com/questions/58815710,11673702.0,1
1361,39093727,Tensorflow: Dequeue and then enqueue,"I have a queue (called queue_A) and populate 100 elements inside. If I would like to do the following 2 things: For achieving 1, I can write: For achieving 2, I can write: However, I don't know how can I do these two things at once. Now, I use the following code: I expect the size of queue_A is a constant, but when I use session.run(queue_A.size()) to check it, the size is gradually decreasing. What is wrong with that code? And how to achieve what I want?",https://stackoverflow.com/questions/39093727,6727583.0,1
1362,45634246,input_alternative error on export_savedmodel in Tensorflow,"I have a simple LinearModel with two sparse and two real-valued features. I trained it and now I want to export it with the export_savedmodel. Referencing few sources I came up with something along the lines of: where: Unfortunately I get ValueError: A default input_alternative must be provided. on export_savedmodel. I digged in a little into the codebase of tensorflow and it seems that build_parsing_serving_input_receiver_fn always returns ServingInputReceiver but the method that extracts input_alternatives always creates them empty if serving_input_fn passed to export_savedmodel is not of the type InputFnOps. Is build_parsing_serving_input_receiver_fn somehow deprecated, something is wrong in the process of extraction of input_alternative, or maybe I'm misunderstanding process completely and doing something wrong? I'm using python 3.6 with tensorflow 1.2, my model is a simple tf.contrib.learn.LinearRegressor.",https://stackoverflow.com/questions/45634246,4717346.0,1
1363,59718635,How to use tf.Lambda and tf.Variable at TensorFlow 2.0,"I'm very new to TensorFlow 2.0. I wrote a code for Cyclic GAN as follows (I extract code only for building generator neural network): but when I run this code, get an error as follows: It seems that I should rewrite tf.Lambda and tf.Variable part. Could anyone teach me How I should rewrite this code?",https://stackoverflow.com/questions/59718635,10233413.0,1
1364,68924907,Converting a fully connected neural network with variable number of hidden layers from tensorflow to pytorch,I recently started learning pytorch and I am trying to convert a part of a large script including coding a MLP with variable number of hidden layers from Tensorflow to pytorch. Are these two codes compatible? and also how should I change tf.shape in this line: tf.random_normal(tf.shape(self.sigma[-1])),https://stackoverflow.com/questions/68924907,2811074.0,1
1365,67766010,"When mapping tensor values with dictionary i get TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key","I try to create a new tensor based on a dictionary that maps 1 to 1 the values from a tensor to some other value (the example below is trivial on purpose), and i get the error ""TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key."" - even though I do not use Tensors as keys in the dictionary, i convert them to int before: The error i get running the above snippet in colab:",https://stackoverflow.com/questions/67766010,4030048.0,1
1366,45410300,"tensorflow/ improved wgan-gp code that i writed diverged very quickly,","Here is my code : The generator code is: And the error log is: Obviously ,the code is not work ,it diverge quickly, this problem confused me a long time, I really would like to know the origin of this problem.",https://stackoverflow.com/questions/45410300,8328723.0,1
1367,43634396,Tensorflow - assigning placeholders values into variables,"I'm trying to modify the TensorFlow MNIST example, so that the placeholder input values are passed to a variable for manipulation, prior to generating the results. For instance: In the example above, I'm passing placeholder values input_X into var_X, where I can perform arbitrary manipulations on the values, before multiplying by weights to get the output result. I'm getting the following error on tf.matmul: I'm confused why, in the above example, this works: but this doesn't: As both input_x and var_x should both be a 784 length vector. I essentially want it to be exactly the same matrix multiplication you'd have in the normal MNIST example, but using a variable rather than a placeholder. This seems like it should be super straight-forward, however I'm new to TensorFlow, and despite reading a lot of tutorials/SO questions, I haven't seen this particular scenario anywhere before. Thanks in advance for any suggestions!",https://stackoverflow.com/questions/43634396,7134393.0,1
1368,65273118,Why is Tensorflow not recognizing my GPU after conda install?,"I am new to deep learning and I have been trying to install tensorflow-gpu version in my pc in vain for the last 2 days. I avoided installing CUDA and cuDNN drivers since several forums online don't recommend it due to numerous compatibility issues. Since I was already using the conda distribution of python before, I went for the conda install -c anaconda tensorflow-gpu as written in their official website here: https://anaconda.org/anaconda/tensorflow-gpu . However even after installing the gpu version in a fresh virtual environment (to avoid potential conflicts with pip installed libraries in the base env), tensorflow doesn't seem to even recognize my GPU for some mysterious reason. Some of the code snippets I ran(in anaconda prompt) to understand that it wasn't recognizing my GPU:- 1. As you can see it completely ignores the GPU. 2. Here, it was supposed to indicate that it ran with a GPU by showing Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0 (as written here: https://www.tensorflow.org/guide/gpu) but nothing like that is present. Also I am not sure what the message after the 2nd line means. I have also searched for several solutions online including here but almost all of the issues are related to the first manual installation method which I haven't tried yet since everyone recommended this approach. I don't use cmd anymore since the environment variables somehow got messed up after uninstalling tensorflow-cpu from the base env and on re-installing, it worked perfectly with anaconda prompt but not cmd. This is a separate issue (and widespread also) but I mentioned it in case that has a role to play here. I installed the gpu version in a fresh virtual environment to ensure a clean installation and as far as I understand path variables need to be set up only for manual installation of CUDA and cuDNN libraries. The card which I use:-(which is CUDA enabled) Tensorflow and python version I am using currently:- System information: Windows 10 Home, 64-bit operating system, x64-based processor. Any help would be really appreciated. Thanks in advance.",https://stackoverflow.com/questions/65273118,14372142.0,1
1369,73596655,applying skip connections for pre-trained vgg19 in keras,"I am trying to use VGG19 as an encoder in convolutional LSTM autoencoder structure, i want to apply skip connections similarly in UNet between the last convolutional layer of each block in VGG19 to my decoder ( which has a similar architecture with the VGG19, just upsampling instead of max pooling). Since the inputs are time dependent, i wrapped the VGG19 with a timedistributed layer. But however, when i initalized my model, i have a graph disconnection error. My code is as follows: The issue happens in the build_res_vgg function. When i call the Model API. It seems to only work if i include 2 inputs in the lstm_model, however i should only have 1 input, input shape of (batch size, timestep, img_h,img_w,3), it is suppose to go through the vgg19 encoder, lstm layers then get reconstructed back to the same image.",https://stackoverflow.com/questions/73596655,16961436.0,1
1370,45900653,TensorFlow: How to predict from a SavedModel?,"I have exported a SavedModel and now I with to load it back in and make a prediction. It was trained with the following features and labels: So say I want to feed in the values 20.9, 1.8, 0.9 get a single FLOAT32 prediction. How do I accomplish this? I have managed to successfully load the model, but I am not sure how to access it to make the prediction call. This question is not a duplicate of the question posted here. This question focuses on a minimal example of performing inference on a SavedModel of any model class (not just limited to tf.estimator) and the syntax of specifying input and output node names.",https://stackoverflow.com/questions/45900653,4736556.0,1
1371,44064458,Why does tf.zeros allow an unknown dimension whereas tf.get_variable doesn't?,"Given some placeholder tensor x such that: x = tf.placeholder(None, 100) I was wondering why: h = tf.zeros(shape = (tf.shape(x)[0], 50)) works but something like: h = tf.get_variable(""h"", shape = (tf.shape(x)[0], 50), initializer = tf.constant_initializer(0.0)) Gives me a value error: Don't they both initialize some variables, why make it so that tf.zeros(...) works with an unknown size, whereas tf.get_variable(...) doesn't?",https://stackoverflow.com/questions/44064458,3529361.0,1
1372,55891843,"ValueError: Dimensions must be equal, but are 2 and 3799 for 'softmax_cross_entropy_with_logits_sg","I am developing a neural network model for classifying benign and malware apks. I have tried using tf.squeeze() function but after using it I am unable to use optimizer The shape of pred and y must be same however by running the code I am having different shape of pred is (3799,2) whereas the shape of y is (1,3799).",https://stackoverflow.com/questions/55891843,11405522.0,1
1373,50255035,Tensorflow dataset with partial shuffle,"I am playing with TensorFlow's dataset API, and I am confused by the shuffle() method, according to the docs: If I only 'partially' shuffle my dataset (e.g. buffer_size &lt;= no. of elements), I'd expect only the first buffer_size elements will be shuffled, however this is not the case, see example: output: why is 5 here? as the buffer size is only 4? the first 2 elements should be within 1~4 right? what am I missing here? Thanks",https://stackoverflow.com/questions/50255035,1182671.0,1
1374,38493468,What are the parameters of TensorFlow's dynamic_rnn for this simple data set?,"I want to train an RNN language model using TensorFlow. My training data is a sequence of 5 tokens represented with integers like so I want the unrolled length of the RNN to be 4, and the training batch size to be 2. (I chose these values in order to require padding.) Each token has an embedding of length 3 like so What should I pass as parameters to tf.nn.dynamic_rnn? This is mostly a repost of ""How is the input tensor for TensorFlow's tf.nn.dynamic_rnn operator structured?"". That was helpfully answered by Eugene Brevdo. However he slightly misunderstood my question because I didn't have enough TensorFlow knowledge to ask it clearly. (Specifically he thought I meant the batch size to be 1.) Rather than risk additional confusion by editing the original question, I think it is clearest if I just rephrase it here. I'm trying to figure this out for myself by writing an Example TensorFlow RNN Language Model.",https://stackoverflow.com/questions/38493468,1120370.0,1
1375,56251994,Issues with my custom keras loss function,"i'm a beginner in Tensorflow/Keras and I would like to customize my loss function, my code is here : I get these errors : Shape of my x_train =[330,28,28,3] and the Shape of my arrTest = [1,28,28,3] Could you help me please?",https://stackoverflow.com/questions/56251994,9636937.0,1
1376,50948158,Tensorflow CPU usage >100% when the whole graph is running on GPU,"I have simple tensorflow code: I don't understand, why top show me &gt;100 %cpu, because all operations run on gpu: trace_data Any ideas?",https://stackoverflow.com/questions/50948158,8880017.0,1
1377,67933642,TensorFlow SparseTensor Input gives Value Error for multi-dimensional input shape,"I have a keras model which takes multi-dimensional input data. When I build a model, setting the input shape to anything with multiple dimensions and sparse=True, I get the following error: Following the sparse tensor guide, this works for me: But if I add in another dimension, I get the error (which occurs at the second line): If I set sparse=False then the error goes away: What am I doing wrong here?",https://stackoverflow.com/questions/67933642,13258525.0,1
1378,50590061,Different types of divisions in TensorFlow,"I am very new to TensorFlow. So I came across this different types of division in TensorFlow from here. Code printed below: Since I am a noob in programming languages I could not understand some of their documentation which included things like ""computes division python style"", etc. If someone can explain the differences between all and their practical aspect, I would be grateful.",https://stackoverflow.com/questions/50590061,8560127.0,1
1379,68514669,Where is the key to make tensorboard work?,"I'm new to tensorboard and learning the use of it following the tutorial, which goes well and tensorboard works as expected. Referring to that tutorial, I wrote my own code to train a logic-and model with jupyter notebook the training goes well and needs some improvement. However, tensorboard shows nothing where is the key to make tensorboard work?",https://stackoverflow.com/questions/68514669,12214867.0,1
1380,61994141,Loss and learning rate scaling strategies for Tensorflow distributed training when using TF Estimator,"For those who don't want to read the whole story: TL; DR: When using TF Estimator, do we have to scale learning rate by the factor by which we increase batch size (I know this is the right way, I am not sure if TF handles this internally)? Similarly, do we have to scale per example loss by global batch size (batch_size_per_replica * number of replicas)? Documentation on Tensorflow distributed learning is confusing. I need clarification on below points. and BATCH_SIZE to the best of my understanding is defined above as per replica batch size. To complicate things further, the scaling is handled automatically if you are using Keras (for reasons I will never understand, it would have been better to keep everything consistent).",https://stackoverflow.com/questions/61994141,1586200.0,1
1381,46003967,How does the Tensorflow TrainingHelper know the vocab size used to decode?,"How does the decoder learn to map cell state to the vocab if we don't tell it the vocab size? In the tf dynamic decoding docs there's a code sample: So if GreedyEmbeddingHelper selects most probable sample_id to input into next time step, it must use a weight matrix of dimension [lstm_hidden_size, vocab_size] over which to argmax, which must have been learned during training. But we didn't tell TrainingHelper the vocab size. So where is this missing tensor?",https://stackoverflow.com/questions/46003967,4925151.0,1
1382,63063260,Extracting features from EfficientNet Tensorflow,"I have a CNN model trained using EfficientNetB6. My task is to extract the features of this trained model by removing the last dense layer and then using those weights to train a boosting model. i did this using Pytorch earlier and was able to extract the weights from the layers i was interested and predicted on my validation set and then boosted. I am doing this now in tensorflow but currently stuck. Below is my model structure and I have tried using the code on the website but did not had any luck. I want to remove the last dense layer and predict on the validation set using the remaining layers. I tried using : layer_name = 'efficientnet-b6' intermediate_layer_model = tf.keras.Model(inputs = model.input, outputs = model.get_layer(layer_name).output) but i get an error "" ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""input_1:0"", shape=(None, 760, 760, 3), dtype=float32) at layer ""input_1"". The following previous layers were accessed without issue: []"" Any way to resolve this?",https://stackoverflow.com/questions/63063260,5197636.0,1
1383,43270849,tensorflow map_fn TensorArray has inconsistent shapes,"I am playing around with the map_fn function, and noticed that it outputs a TensorArray, which should mean it is capable of outputting ""jagged"" tensors (where the tensors on the inside have different first dimensions. I tried to see this in action with this code: however got the error: ""TensorArray has inconsistent shapes. Index 0 has shape: [259] but index 1 has shape: [773]"" This of course comes as a surprise to me since I am under the impression that TensorArrays should be able to handle it. Am I wrong?",https://stackoverflow.com/questions/43270849,2442449.0,1
1384,70988847,Save tensorflow model with StringLookup layer with encoded vocabulary,"I'm having some issues saving a trained TensorFlow model, where I have a StringLookup layer and I'm required to use TFRecods as input for training. A minimal example to reproduce the issue: First I define the training data I save it in a file as tfrecords Then I use the tf.data API to be able to stream the data into training (the original data doesn't fit into memory) The data looks like this: The strings of the original dataset were converted to bytes in the process. I have to pass this new vocabulary to the StringLookup contructor, as passing strings and training with bytes will throw an error But when I try to save the model, I get an error because the vocabulary input to the StringLookup layer is encoded as bytes and can't be dumped into json I really don't know what to do, I read that TensorFlow recommends using encoded strings instead of normal strings but that doesn't allow to save the model. I also tried to preprocess the data decoding the strings before thay are fed to the model, but I wasn't able to do it without loading all the data into memory (using just tf.data operations)",https://stackoverflow.com/questions/70988847,13630890.0,1
1385,49886322,Slice assignment in loop in Tensorflow,"I have a 5x3 matrix of zeros that I want to update with ones while in a while_loop. I want to use the looping variable to be the indices argument of the scatter_nd_update function. I have my code like this: This throws an error that says: AttributeError: 'Tensor' object has no attribute 'handle' and points to the line num = tf.scatter_nd_update(num, [[i]], updates) When I run this code without a loop by running num = tf.scatter_nd_update(num, [[i]], updates) twice with different i values then it works and I get a matrix with 2 rows of ones, but this error occurs when I try the same thing in a while_loop.",https://stackoverflow.com/questions/49886322,9655387.0,1
1386,50581043,Practical determination of anomaly threshold in (variational) autoencoders,"Although not strictly a programming question, I haven't found anything about this topic on this site. I currently dealing with (variational) autoencoders ((V)AE), and plan to deploy them to detect anomalies. For testing purposes, I've implemented an VAE in tensorflow for detecting handwritten digits. The training went well and the reconstructed images are very similar to the originals. But for actually using the autoencoder, I have to use some kind of measure to determine if a new image fed to the autoencoder is a digit or not by comparing it to a threshold value. At this point, I have two major questions: 1.) For training, I used a loss consisting of two components. First one is the reconstruction error, which is a crossentropy function: The second one is KL-divergence, which is a measure of how similar two probability distributions are, as we are demanding that the latent variable space is a distribution similar to a Gaussian. For determining the reconstruction error of a new image, do I have to use both parts of the training loss? Intuitively, I would say no and just go with the recon_loss. 2.) How do I determine the threshold value? Is there already a tf functionality implemented that I can use? If you have some good source for anything related, please share the link! Thanks!",https://stackoverflow.com/questions/50581043,8334261.0,1
1387,68272502,TF depth_to_space not same as Torch's PixelShuffle when output channels > 1?,"I noticed something interesting when trying to port a torch-trained model to tensorflow (TF). When the output channels of a PixelShuffle operation are greater than one, the corresponding depth_to_space function in TF is not equivalent (Note: I convert the input to TF to NHWC and the output back to NCHW). I was wondering whether this expected behavior OR there is a misunderstanding? Specifically, and and Here is a testbench:",https://stackoverflow.com/questions/68272502,420620.0,1
1388,56459677,"AssertionError when using MirroredStrategy: isinstance(x, dataset_ops.DatasetV2)","I am trying to use MirroredStrategy to fit my sequential model using two Titan Xp GPUs. I am using tensorflow 2.0 alpha on ubuntu 16.04. I successfully run the code snippet from the tensorflow documentation: However, when I try to train on my data, which is a sparse matrix of shape (using adam optimizer and binary crossentropy): I receive an assertion error in _distribution_standardize_user_data at In the TensorFlow code, line 2166 in training.py seems to be causing this assertion error. Can someone explain to me what the problem with my data could be?",https://stackoverflow.com/questions/56459677,5924132.0,1
1389,43864841,TensorFlow: Do preprocessing operations get frozen in a graph as well?,"I believe after training, the model saved to the checkpoint does not contain any of the preprocessing operation, as upon examination of the checkpoint model, the operations available start from the input of a model (and not the preprocessing operations that precede the model input). However, when freezing a graph restored from a point file, where the graph has additional preprocessing operations, does the preprocessing operation gets frozen as well? I have included a preprocessing operation for test time in the graph, and intend to freeze the graph together with the checkpoint model, but the result seem to vary a lot for these 2 scenarios: So my question is does the preprocessing operation gets effectively frozen, or is it advisable to only preprocess images at test time so that we can leave the frozen graph for performing inference only (and not any preprocessing op)? My intention was to include the preprocessing ops within the graph to make it more convenient, but it seems that this approach does not work. What is the TensorFlow's take on such a workflow? Should preprocessing be done within the graph and frozen, or should it be a separate task outside of the frozen graph? Here is how I intended to put the preprocessing ops within a graph and freeze them all:",https://stackoverflow.com/questions/43864841,5107084.0,1
1390,48896762,How to use the Tensorflow Dataset API to read files with different names without evaluating the filename string,"Say I received csv dataset files with filenames of the form index_channel.csv where index is the index of the example (running from 1 to 10000) and channel is the index of the channel (running from 1 to 5). So 7_3.csv is the 3rd channel of the 7th example. I want to load all these csv files and concatenate the channels to get the correct tensors as my data set. I am missing references to functions which will enable me to do this. Below is the code I have so far. When I get to running it, it complains that TypeError: expected str, bytes or os.PathLike object, not Tensor. I am guessing it is trying to evaluate the expression instead of only after sess.run() has been called, but not sure how to circumvent that. Sorry, I am a newbie at TF. My question seems trivial but none of the examples I found by googling answered my questions.",https://stackoverflow.com/questions/48896762,154510.0,1
1391,57381329,"Expected a callable, found non-callable tensorflow_federated.python.learning.model_utils.EnhancedTrainableModel","Unable to use TFF's build_federated_averaging_process(). Followed the tutorial from the TFF federated documentation. Here's my model code: I get the error: TypeError: Expected a callable, found non-callable tensorflow_federated.python.learning.model_utils.EnhancedTrainableModel.",https://stackoverflow.com/questions/57381329,11867229.0,1
1392,73798813,"preprocess_input changes array inplace, but doesn't change tensor","I've noticed some strange behaviour in preprocess_input, a function used to preprocess images to normalise values correctly for the specific pre-trained network you are using. After several hours of debugging, it appears that when a tensor is used as an input, the input tensor is unmodified, and it returns the processed input as a new tensor: returns However when doing the exact same thing but with a numpy array as input, apart from returning the processed version as a new array, the original array is changed to be the same as the new array: returns Three questions:",https://stackoverflow.com/questions/73798813,8489363.0,1
1393,52783781,Get Keras model input from inside a custom callback,"I have a very simple question. I have a Keras model (TF backend) defined for classification. I want to dump the training images fed into my model during training for debugging purposes. I am trying to create a custom callback that writes Tensorboard image summaries for this. But how can I obtain the real training data inside the callback? Currently I am trying this: But I am getting the error: InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,224,224,3] There must be a way to see what models, get as an input, right? Or maybe I should try another way to debug it?",https://stackoverflow.com/questions/52783781,2641587.0,1
1394,55322558,How to use tf.contrib.copy_graph.copy_op_to_graph()?,"I'm using tf.contrib.copy_graph.copy_op_to_graph() to copy an operation from g1 to g2. Edited code: New error when copy_variable_to_graph(BATCH_SIZE, g2): If I comment the following two lines: I get another error: Actually, I do not know how to use this function. Some one can explain the third param [] in the function for me? And how to solve this error? Thank you! I saw an example here. But I do not know the meaning of []? EDIT: Edit code and errors.",https://stackoverflow.com/questions/55322558,10153344.0,1
1395,68837658,Tensorflow Keras ValueError on input shape,"I am doing a simple Conv1D using TensorFlow Keras to try out a time-series dataset. Data: Model: Summary: Fit: Error raised @ Fit: From the various SO, it was said that this is due to the input data shape. So I tried a recommendation in a SO to reshape the my data and re-input it Reshape: Error raised @ Fit after reshaping: I am at a loss here. What is the way to tackle this?",https://stackoverflow.com/questions/68837658,7602461.0,1
1396,44750752,Effect of max_pool in Convolutional Neural Network [tensorflow],"I'm following Udacity Deep Learning video by Vincent Vanhoucke and trying to understand the (practical or intuitive or obvious) effect of max pooling. Let's say my current model (without pooling) uses convolutions with stride 2 to reduce the dimensionality. Now I introduced pooling: Replace the strides by a max pooling operation (nn.max_pool()) of stride 2 and kernel size 2. What would be the compelling reason that we use the later model instead of no-pool model, besides the improved accuracy? Would love to have some insights from people who have already used cnn many times!",https://stackoverflow.com/questions/44750752,3907250.0,1
1397,44107208,In tf.nn.dropout what is the effect of keep_prob argument?,"I am learning tf.nn.dropout command. Documentation says that with probability keep_prob, outputs the input element scaled up by 1 / keep_prob, otherwise outputs 0. The scaling is so that the expected sum is unchanged. Can someone please explain that why we take 1/keep_prob. And if I set its value 0.1. Does it mean that I am keeping only 10 percent nodes?",https://stackoverflow.com/questions/44107208,7997184.0,1
1398,49543158,How to use weights in tf.metrics.auc?,"The docs for the tf.metrics.auc function in tensorflow say and Suppose I want to use the weights to measure two AUCs: one for men, one for women. Can you give an example of how to do that? EDIT: And suppose I have enough classes that I don't want to divide the data into all the different classes, and enough data that I don't want to read it all into memory. That is, I want to do it in a streaming fashion.",https://stackoverflow.com/questions/49543158,34935.0,1
1399,63253714,"What numbers go into DCGAN Generator models, in order to produce larger images","I really have tried to do my due diligence here but I can't find a lot of documentation on why certain numbers are chosen. I'm also fairly hazy on how convolutions work in generators (have a better understanding in terms of classifiers) so that's not helping my case. I think my question should be pretty simple to address for some more experiences folks out there though. Take Google's tutorial for example, the Generator class: Where is 7x7x256 coming from? I understand that 7x7 is a multiple of the eventual 28x28 size, so that makes sense somewhat, but what is the 256 all about? And then in the following layers, I notice a pattern but I'm not sure how to re-write it so it works for a wholly different image size. Any help or direction is appreciated.Thanks! EDIT: Thanks to the helpful input I changed my gen to: and discriminator:",https://stackoverflow.com/questions/63253714,1135125.0,1
1400,64924817,Keras: Modify/Rearrange elements of Input Layer to create a new Input Layer and feed the new input Layer to create a new Output,"Suppose that I have a Keras Input Layer ""input_layer_A"" (in Python) I also have a dense layer Then I create an output as: I want to modify/edit a copy of ""input_layer_A"" (as an example) as follows: (syntax on how to edit the Input Layer properly is a part of the question) Is it the correct way to edit/modify the input Layer? If not what is the proper way? Then I feed “input_layer_B” to “dense_layer_1” to create a new output “out2” (kind of a recursion and it can be applied in a for loop as well) Finally create the model When I run the model I get an error in the form of (related with out2: this is where the graph becomes disconnected, no problem for out1, which means there is something wrong about how I modify the ""input_layer_B"") ValueError: Graph disconnected: cannot obtain value for tensor What is the correct way to modify/edit an Input Layer so that I can still use it to feed successfully to ""dense_layer_1"" to end up with a connected and proper graph? Any help, suggestion or an alternative method to accomplish what I want is appreciated. Thank you PS: My motivation for building such a recursive network is to model a NARX Neural Network with feedback to estimate multi-step ahead output of a dynamical system. So there can be n-many outputs in theory",https://stackoverflow.com/questions/64924817,5860745.0,1
1401,70549999,ValueError: The last dimension of the inputs to a Dense layer should be defined. Found None,"I'm playing around a bit with Tensorflow 2.7.0 and its new TextVectorization layer. However, something does not work quite right in this simple example: This works so far. I make ints out of words, embed them, flatten them. But if I want to add a Dense layer after flattening (i.e. uncomment a line), things break, and I get the error message from the question title. I even used the input_length parameter of the Embedding layer because the documentation says that I should specify this when using embedding-&gt;flatten-&gt;dense. But it just does not work. Do you know how I can get it to work using Flatten and not something like GlobalAveragePooling1D? Thanks a lot!",https://stackoverflow.com/questions/70549999,8194183.0,1
1402,47327618,"Tensorflow-Python - InvalidArgumentError - logits and labels must be of the same size, logits_size=[512, 8] labels_size=[128, 8]","I tried to port the Levi-Hassner non-BN model from the rude-carnie Github project into tf.layers syntax which now looks like this: Running it with my tf.Estimator gives the error in the title. I've checked the tensors' sizes. conv1's is (?, 56, 56, 96), pool1's is (?, 27, 27, 96), pool2's is (?, 13, 13, 256), pool3's is (?, 6, 6, 384), flat's is (?, 13824), drop2's is (?, 512), and logits's is (?, 8). All the shapes seem to check out to me, or am I missing something? And since the '?' refers to the batch size which I set up as 128, is it possible that I'm setting up the TFRecords input function wrong? EDIT: With batch size being 1, I get the same error except with a twist: the logits_size is [4, 8] and the layers_size is [1, 8]",https://stackoverflow.com/questions/47327618,4535784.0,1
1403,62654494,Tensorflow 2.2: Dataset with increasing batch size,"I have a custom model to train a text classifier. In our code we overwrote all important methods of tf.keras.models.Model, e.g. fit, predict etc. One of the reasons for that was that we wanted to adapt the batch size every epoch. So, during the first epoch we would have, for example, a batch size of 16, in the next iteration the batch size would increase to 20, and so on. Until we reach an upper limit. Here is the method that generates our tf.Dataset. We would call this method for every epoch to get a dataset with the desired batch size. With Tensorflow 2.2. it is possible to just overwrite train_step and test_step instead of fit etc. This would simplify our code quite a bit. However, I could not find a way how to keep the increasing batch size over the epochs. Does someone has an idea on how to solve this? Or do we need to keep our custom fit method in order to achieve this?",https://stackoverflow.com/questions/62654494,11561511.0,1
1404,35622434,Custom operation implementation for RBM/DBN with tensorflow?,"Since Google released out tensorflow, it becomes kind of trend in the current deep learning selections. I'd like to do some experiments about RBM/DBN (Restricted Boltzmann Machine/Deep Belief Network), I've made some attempt by myself and kind of implement it well through the combination of available APIs from tensorflow. See code and previous answer. So, if doesn't bother the code running performance, here's the gift for RBM/DBN implementation with tensorflow. But, the running performance must be considered for the future. Because of the special progress of CD (Contrastive Divergence) algorithm, I think it just works against the framework (data flow graph) used by tensorflow. That's why my code seems weired. So, the custom operation should be implemented for acceleration. I've followed the current documentation about adding custom ops. In my design, NaiveRbm should is an operation that takes visible,weights,h_bias,v_bias as input, but output by only first 3 Variables ( simply sigmoid(X*W+hb) ), its gradient should return at least gradients for last 3 Variables. Imagine example psuedo code like this: But the tensorflow library is too complex for me. And after too much time seeking for how to implement these existing operations (sigmoid, matmul, ma_add, relu, random_uniform) in custom operation, no solution is found by myself. So, I'd like to ask if someone could help me achieve the remain works. PS: before getting some ideas, I'd like to dive into Theano since it implements RBM/DBN already. Just in my opinion, Caffe is kind of not suitable for RBM/DBN because of its framework. Update: After scratch through the tutorials from Theano, I found the key reason for Theano implemented the RBM/DBN while the tensorflow haven't is the scan technology. So, there might wait tensorflow to implement scan technology to prepare for RBM/DBN implementation.",https://stackoverflow.com/questions/35622434,1749667.0,1
1405,59511122,How to understand input images for convolutional neural network in this code,"I am not sure my answer is correct (#note is my answer) Is it means normalize the image data? but I have not seen this syntax classification images-&gt; float32 format(0,255)-&gt;normalization to (-1,1) return img, lab I know it means shuffle dataset randomly,but what is 1000 means? about the part prefetch, is it means The program can automatically select the optimal number of threads in parallel？ what did get_structure means? is it same as reshape func? Thanks a lot",https://stackoverflow.com/questions/59511122,12438557.0,1
1406,54820842,`gradient` gives AttributeError when building a TensorFlow graph,"I'm trying to learn how to build a graph in TensorFlow, but got stuck in a seemingly trivial operation. This is what I have, At this point I got an AttributeError, as follows What am I doing wrong and how do I get the gradient? Thanks in advance.",https://stackoverflow.com/questions/54820842,170477.0,1
1407,45986970,Is it possible for Tensorflow graph to run outside of session,"Could someone please explain the following situation: I've created a simple convolutional neural network using Tensorflow. I'm using a class and I've created my graph in the constructor. I then train the network using a train method I've written. I'm also using queues and the feed-in mechanism. This is an excerpt from the code: When I run this code, I get the following error output: When I remove the sess.run() from my pred output, the code seems to operate normally. Could someone please explain this to me? Normally, the graph is only evaluated when run under a session! What gives here?",https://stackoverflow.com/questions/45986970,8312790.0,1
1408,59167849,PyTorch equivalent of a Tensorflow linear layer,"I was trying to reimplement a Tensorflow code using PyTorch framework. Below I have included the TF sample code and my PyT interpretation. TensorFlow implementation: PyTorch implementation: I was wondering what is the proper way to implement the matmul part, given that the weights in pytorch are not explicitly defined as they are in the TF (or correct me if I'm wrong).",https://stackoverflow.com/questions/59167849,6651940.0,1
1409,72392579,SciKeras - RandomizedSearchCV for best hyper-parameters,"I'm trying to follow the example on chapter 10 of the book Hands-On Machine Learning with SciKit-Learn, Keras and TensorFlow which regard the optimization of the hyperparameters of a DNN model. The dataset is the MNIST fashion model and the goal of the project is the classification of the images in 10 classes. There is no validation, so I'm going to create that set using the first 5k elements: A possible implementation of a simple DNN model is the following, using sequential Keras API: The book then suggests to study the hyper-parameter space to found the best ones, using RandomizedSearchCV. The example uses keras.wrappers.scikit_learn.KerasRegressor which is now deprecated in favor of KerasRegressor by SciKeras. I created a function containing the ML model: Then I defined the model hyperparameters to explore: I then used SciKeras to create a wrapper around the Keras model, feeding the parameter space: The last step is to define a RandomizedSearchCV object and start the research using the fit method: This last row gives me the following error, for each epoch: A factor 10 on the second dimension makes me thinking... I also checked the shapes of the data and they are fine... Can you please help me dealing with this error?",https://stackoverflow.com/questions/72392579,19206156.0,1
1410,44803314,is their a scatter_update() for placeholder in tensorflow,"I am coding a denoising autoencoder function with tensorflow (which is a little long so i won't post the entire code) and every thing is working well except when i am adding masking noise to a batch Masking noise is just taking a random proportion of the features to 0. So the problem is just taking some value in a matrix to 0.(trivial if i had a np.array for exepmle) So i see ,if it's a tf.variable, how to modify one element of a matrix thanks to tf.scatter_update() But then when I try with a placeholder it raises the error : ""TypeError: 'ScatterUpdate' Op requires that input 'ref' be a mutable tensor"" this is kind of problematic I could solve this by adding noise to the batch before doing the encoding routine(I would handle then np.array instead of tf.placeholder) but i found this problem kind of frustrating ... ps :maybe the code is not optimal i don't control random function very well thanks for your attention!!",https://stackoverflow.com/questions/44803314,8224883.0,1
1411,72360633,How to pass a *serialized* tensor to a TensorFlow Model Serving server?,"I implemented a simple TF model. The model received a serialized tensor of a gray image (simply a 2d ndarray), and restored it to a 2-d tensor. After then, some inference is applied on this 2-d tensor. I deployed the mode with TensorFlow Model Serving, and tried to send a JSON string to the REST port as follows: I tried something like tf.io.serialize_tensor etc to convert input image into a serialized tensor and to pass it to the server, but all failed. I would like to know how to send a serialized tensor to the serving server. And my saved model has following signature: and the definition of _get_serve_tf_examples_fn is, The above code segment received a serialized tensor of a gray image (simply a 2d ndarray), and restored it to a 2-d tensor. After then, the model is doing inference on this 2-d tensor. I would like to know how to send a serialized tensor to the REST port of the serving server. Any help would be appreciated.",https://stackoverflow.com/questions/72360633,9837747.0,1
1412,63129704,Problem with Keras Functional API using class to define a model,"I was trying to make a function for dense layer in keras for specifying number of units as per my requirement and it returned an object just as it would do when storing constant object in variable, but I don't know why this throws error. I have tried both lambda function and the usual function notation, none work. I am using Google Colab (tensorflow == 2.2.0) Here is the code to regenerate the error: And the complete error message: Please help me resolve this issue!",https://stackoverflow.com/questions/63129704,12898359.0,1
1413,68651622,EarlyStopping not stop training,"As the title suggests I am training my IRV2 network using the following EarlyStopping definition: However, the training doesn't stop when I get three equal values of val_loss: This is my model: This is the training output:",https://stackoverflow.com/questions/68651622,14498840.0,1
1414,72333486,How to add keras attention layer in seq2seq encoder decoder model?,"I was trying to perform character level translation using keras seq2seq model, but I'm unable to add attention layer. I took the reference of keras seq2seq documentation. https://keras.io/examples/nlp/lstm_seq2seq/ Model.summary() doesn't include attention layer. And when I try to compile and train the model I get following error. When I tried the same architecture without attention, it works. Please help me to solve this error. Thank you in advance.",https://stackoverflow.com/questions/72333486,8340447.0,1
1415,60618742,Adding tensorboard to federated setting,"I am new in using TensorBoard, and I want to add it to this project: https://github.com/TalwalkarLab/leaf My specific case is the FE-MNIST model, which is in here: https://github.com/TalwalkarLab/leaf/blob/master/models/femnist/cnn.py The challenge of adding tensorboard to Federated Setting for people who do not know the setting is that in here, have a server that aggregate the models, and we have random number of clients that does the training, and they have a Client_id. I want to have a tensorboard folder for each of the clients, and log for the server model (which no training is done there) I want to know how to access layers weights and biases, and store them based on the client ids, which is the place that is calling the training. I have seen How do I use tensor board with tf.layers? in here it says that we can use Code (which I am not sure where should I add it) How can I pass the client id to a session, so it can store in the respective folders?",https://stackoverflow.com/questions/60618742,12913958.0,1
1416,50980091,Tensorflow: What is difference of tf.constant(2) and 2,"I just started learning Tensorflow by myself. I got a question, what is the difference between following code? and The print(sess.run(x)) both return 8. So what difference does it make of using tf.constant?",https://stackoverflow.com/questions/50980091,9939644.0,1
1417,70542508,Inputs shape is uknown during training (model subclassing),"Consider following model Every custom layer here is not trainable, they just perform calculations - extract fractal features from images. The model is trained with the following code: The first batch comes with a normal shape (None, 224, 224, 3) but the second (None, None, None, None) and it break my model. Why does it happen?",https://stackoverflow.com/questions/70542508,15026098.0,1
1418,45376584,Decoding then encoding a jpeg file will cause the output to be rotated if there is Orientation exif metadata on the source jpeg,"The example here is a stripped-down version of an upscaling program I wrote while trying to learn how to use Tensorflow. If I feed it an image that has orientation exif metadata (my test image has Rotate 270 CW) then the output image will be rotated as if to ""correct"" that orientation. This doesn't seem to be documented anywhere. Is there a way to prevent this from happening, either by passing in a flag or value to the decode_jpeg / encode_jpeg functions, or by stripping out the metadata beforehand?",https://stackoverflow.com/questions/45376584,989477.0,1
1419,50071752,Why does tf.Variable change value randomly?,I have implemented a very basic operation graph to understand how Tensorflow works. However I am getting some unexpected behavior that I can't debug even though the program is so short: All that the program is doing is creating a constant value x and a variable value b that get added. The output of this program is: The value of b changes to 0.0 Does anybody know what is happening here?,https://stackoverflow.com/questions/50071752,2723396.0,1
1420,60248322,Parse field names and types from TFRecord,"I am trying to build a generic utility functions to help me work with TFRecord objects. For this, I am looking to parse field names and types from a TFRecord object (in Python). The TF documentation gives some example on how to print these. This prints output such as: I can even print the individual field info (knowing the name) as Which prints out So most of the information seems to be there. This data has two fields ""class"" (type tf.int64) and ""image"" (type tf.string). The Example object seems to be of type tensorflow.core.example.example_pb2.Example. Which has some functions such as keys(), items(), ... but none of these give me access to the feature names and types as far as I can see. There also seems to be some kind of generic ""id"" field in the output that is not part of the original list of fields. And the type tf.int64 seems to appear as a list with one item. So it is close but not quite. And I have trouble accessing the field names and types through the Python objects. I'd rather not start parsing the string output, and guessing type mappings from it. So I guess the question is, is it possible for me to parse the actual TFRecord format from the file itself?",https://stackoverflow.com/questions/60248322,1187237.0,1
1421,60595140,tensorflow: save model and load model,"Currently trying to make this repo works. I'm trying to save the trained model in the local machine so can be applied later. I read in tensorflow's doc, seems pretty intuitive to save the model, by calling tf.save_model.save(object). But I'm not sure how to apply. Original code is here: model.py Following is my changes: The code above produces ValueError as following: ValueError: Tensor(""ICON/CNN/embedding_matrix:0"", shape=(16832, 300), dtype=float32_ref) must be from the same graph as Tensor(""saver_filename:0"", shape=(), dtype=string).",https://stackoverflow.com/questions/60595140,10029273.0,1
1422,63869134,Converting TensorFlow tensor into Numpy array,"I am trying to write a custom loss function in TensorFlow 2.3.0. To calculate the loss, I need the y_pred parameter to be converted to a numpy array. However, I can't find a way to convert it from &lt;class 'tensorflow.python.framework.ops.Tensor'&gt; to numpy array, even though there seem to TensorFlow functions to do so. gives the error message: AttributeError: 'Tensor' object has no attribute 'make_ndarray after printing the type of the y_pred parameter: &lt;class 'tensorflow.python.framework.ops.Tensor'&gt; Looking for a solution I found this seems to be a common issue and there a couple of suggestions, but they did not work for me so far: 1. "" ... so just call .numpy() on the Tensor object."": How can I convert a tensor into a numpy array in TensorFlow? so I tried: giving me AttributeError: 'Tensor' object has no attribute 'numpy' 2. ""Use tensorflow.Tensor.eval() to convert a tensor to an array"": How to convert a TensorFlow tensor to a NumPy array in Python so I tried: giving me one of the longest trace of error messages I ever have seen with the core being: also having to call TensorFlow Compatibility Functions from Version 1.x does not feel very future-proof, so I do not like this approach too much anyhow. 3. Looking at the TensorFlow Docs there seemed to be the function I needed just waiting: tf.make_ndarray Create a numpy ndarray from a tensor. so I tried: giving me AttributeError: 'Tensor' object has no attribute 'tensor_shape' Looking at the example in the TF documentation they use this on a proto_tensor, so I tried converting to a proto first: but already the tf.make_tensor_proto(y_pred) raises the error: TypeError: Expected any non-tensor type, got a tensor instead. Also trying to make a const tensor first gives the same error: There are many more posts around this but it seems they are all coming back to these three basic ideas. Looking forward to your suggestions!",https://stackoverflow.com/questions/63869134,12207268.0,1
1423,63039969,Can someone explain the behaviour of tf.keras.layers.BatchNormalization?,"from the tensorflow documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization ""Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1."" therefore, I expect that this layer should first calculate the mean and standard deviation of the previous layer output, subtract it by the mean, and divide by the standard deviation for each sample in the batch. But apparently I'm wrong. output: Can someone please explain to me why these outputs are not the same or atleast similar? I dont see how this is normalizing anything.",https://stackoverflow.com/questions/63039969,8394098.0,1
1424,51059382,Print whole tensors in Keras using print_tensor,"I am using print_tensor to see the values of tensors in a custom loss function. However, this only prints the first three values! Like this: softmax = [[-0.245408952 -0.0407191925 -0.0813238621]...] In Tensorflow you can control this using the summarize parameter in tf.Print (not applicable in my case), but print_tensor for Keras has no such parameters, so how can I change this behaviour? So far I have tried: import numpy numpy.set_printoptions(threshold=numpy.nan)",https://stackoverflow.com/questions/51059382,5346123.0,1
1425,47139172,Neural network specified with tf.layers inserting undesired reshape operations,This simple neural network defined in python: Results the following graph topology: What is the purpose of the reshape operations between nodes 36 and 44? I am working with the Snapdragon Neural Processing Engine (SNPE) which does not permit reshape operations. Is there any way to express this model without the reshape ops?,https://stackoverflow.com/questions/47139172,592235.0,1
1426,74055856,Is it possible to quantize individual layers weights/activations post training?,"Quantization-aware training in Tensorflow allows me to quantize individual levels with different quantization configurations using tensorflow_model_optimization.quantization.keras.quantize_annotate_layer. I want to have a similar effect on an already-trained model. In the post-training quantization documentation of Tensorflow, the following is an example of quantizing a model to float16. However, I believe this quantizes all model layers' activations and weights. Is there a way to only select certain tensorflow.keras.Layer instances in the model after training and saving the model file?",https://stackoverflow.com/questions/74055856,8324585.0,1
