QuestionId,Title,Body,CleanedBody,QuestionURL,UserId,Issue Type,MyLabel,Sentence
55298323,TensorFlow 2.0 returns unexpected output on dtype=int32 with GradientTape,"<p>The following code should output the gradient of y=x*x for x=2, i.e. the value of 4. However the code prints a value of None when using TensorFlow 2.0.0-alpha0. When the definition of x changes to use <code>tf.float32</code> instead of <code>tf.int32</code> as shown in the next snippet, the output changes to the correct value of 4. Is there any documentation that clarifies the requirement for the data type to be a floating point number for GradientTape to work correctly in this scenario?</p>

<pre class=""lang-py prettyprint-override""><code>print(tf.__version__)

x = tf.constant(2, dtype=tf.int32)

with tf.GradientTape() as tape:
  tape.watch(x)
  y = x ** 2
  print(tape.gradient(y, x))
</code></pre>

<p>outputs:</p>

<pre><code>2.0.0-alpha0
None
</code></pre>

<p>Notice the change to <code>tf.float32</code> in the next snippet:</p>

<pre class=""lang-py prettyprint-override""><code>print(tf.__version__)

x = tf.constant(2, dtype=tf.float32)

with tf.GradientTape() as tape:
  tape.watch(x)
  y = x ** 2
  print(tape.gradient(y, x))
</code></pre>

<p>outputs:</p>

<pre><code>2.0.0-alpha0
tf.Tensor(4.0, shape=(), dtype=float32)
</code></pre>
","The following code should output the gradient of y=x*x for x=2, i.e. the value of 4. However the code prints a value of None when using TensorFlow 2.0.0-alpha0. When the definition of x changes to use tf.float32 instead of tf.int32 as shown in the next snippet, the output changes to the correct value of 4. Is there any documentation that clarifies the requirement for the data type to be a floating point number for GradientTape to work correctly in this scenario? outputs: Notice the change to tf.float32 in the next snippet: outputs:",https://stackoverflow.com/questions/55298323,3809616,Requesting (Additional) Resources,Requesting (Additional) Resources, Is there any documentation that clarifies the requirement for the data type to be a floating point number for GradientTape to work correctly in this scenario? 
44141986,Clarification on Tensorflow tensor shapes and matmul,"<p>I need some clarification on how Tensorflow treats the shape of its tensors. This is taken from the <a href=""https://www.tensorflow.org/get_started/mnist/pros"" rel=""nofollow noreferrer"">MNIST example</a>:</p>

<p>I define a placeholder that will at some later point be fed with some of my training data:</p>

<p><code>x = tf.placeholder(tf.float32, shape=[None, 784])</code></p>

<p>During runtime I feed it in batches of 100, so its shape during runtime is <code>(100, 784)</code>. I also define weights and biases: </p>

<pre><code>W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
</code></pre>

<p><code>W</code>is of shape <code>(784, 10)</code> and <code>b</code>is of shape <code>(10)</code>. Now I compute </p>

<pre><code>y = tf.matmul(x,W) + b
</code></pre>

<p>And this is where I am stuck. The matrix product of <code>x</code> and <code>W</code> is of shape <code>(None, 10)</code> or <code>(100, 10)</code> during runtime. However I can without error add vector <code>b</code> to it. This confuses me. How can this work? And is there some better documentation for this?</p>
","I need some clarification on how Tensorflow treats the shape of its tensors. This is taken from the MNIST example: I define a placeholder that will at some later point be fed with some of my training data: x = tf.placeholder(tf.float32, shape=[None, 784]) During runtime I feed it in batches of 100, so its shape during runtime is (100, 784). I also define weights and biases: Wis of shape (784, 10) and bis of shape (10). Now I compute And this is where I am stuck. The matrix product of x and W is of shape (None, 10) or (100, 10) during runtime. However I can without error add vector b to it. This confuses me. How can this work? And is there some better documentation for this?",https://stackoverflow.com/questions/44141986,578640,Requesting (Additional) Resources,Requesting (Additional) Resources,And is there some better documentation for this?
49285664,training a custom estimator in tensorflow,"<p>I am new to tensorflow and trying to train a custom CNN estimator with inputs being provided from <code>TFRecord</code> files. </p>

<p>The <code>Load_input()</code> function is supposed to look into <strong>DATA_DIR</strong> for <code>TFRecords</code> file and decode it through a call to <code>read_and_decode</code> function(which is supposed to do the actual decoding of the records), store the information into an instance of <strong>_image_object</strong> and return it.</p>

<p><code>cnn_model</code> is where I have defined the CNN architecture. And <code>generate_input_fn</code> is supposed to create the batches and feed it to the <code>estimator.train</code> while training.</p>

<p>I just have an abstract understanding of the codes, no idea of the internal mechanics which is the primary reason why I am not able to debug.</p>

<p>Here is my code :</p>

<pre><code>import tensorflow as tf 
import numpy as np 
import os 



DATA_DIR = ""./TFRecords/train""  #path to tfrecords directory
TRAINING_SET_SIZE = 3
BATCH_SIZE = 3
IMAGE_SIZE = 224


def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))

def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

# image object from protobuf
class _image_object:
    def __init__(self):
        self.image = tf.Variable([], dtype = tf.string)
        self.height = tf.Variable([], dtype = tf.int64)
        self.width = tf.Variable([], dtype = tf.int64)
        self.filename = tf.Variable([], dtype = tf.string)
        self.label = tf.Variable([], dtype = tf.int32)

def read_and_decode(filename_queue):
    # this module is responsible for extracting the features
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(serialized_example, features = {
        ""image/encoded"": tf.FixedLenFeature([], tf.string),
        ""image/height"": tf.FixedLenFeature([], tf.int64),
        ""image/width"": tf.FixedLenFeature([], tf.int64),
        ""image/filename"": tf.FixedLenFeature([], tf.string),
        ""image/class/label"": tf.FixedLenFeature([], tf.int64),})
    image_encoded = features[""image/encoded""]
    image_raw = tf.image.decode_jpeg(image_encoded, channels=3)
    image_object = _image_object()
    image_object.image = tf.image.resize_image_with_crop_or_pad(image_raw, IMAGE_SIZE, IMAGE_SIZE)#resizes and crops
    image_object.height = features[""image/height""]
    image_object.width = features[""image/width""]
    image_object.filename = features[""image/filename""]
    image_object.label = tf.cast(features[""image/class/label""], tf.int64)
    return image_object

def Load_input():

    print 'Generating data from tfrecords...'
    filenames = [os.path.join(DATA_DIR, ""train-0000%d-of-00002.tfrecord"" % i) for i in xrange(0, 1)]

    for f in filenames:
        if not tf.gfile.Exists(f):
            raise ValueError(""Failed to find file: "" + f)
    filename_queue = tf.train.string_input_producer(filenames)
    print 'decoding queue contents ::{}'.format(filename_queue)
    image_object = read_and_decode(filename_queue)
    image = tf.image.per_image_standardization(image_object.image)
#    image = image_object.image
#    image = tf.image.adjust_gamma(tf.cast(image_object.image, tf.float32), gamma=1, gain=1) # Scale image to (0, 1)
    label = image_object.label
    filename = image_object.filename
    return image,label,filename


def cnn_model(features,labels,mode):

    print 'creating layers...'  
    #Input layer
    #inp = tf.reshape(features['x'],[-1,28,28,1])
    inp = tf.reshape(features,[-1,224,224,3])
    print 'input shape ::{}'.format(inp.shape)
    #convolutional layer #1
    conv1 = tf.layers.conv2d(inputs=inp,filters=32,kernel_size=[5,5],padding='same',activation=tf.nn.relu)
    print 'convolution-1 shape ::{}'.format(conv1.shape)

    #pooling Layer
    pool1=tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2)
    print 'Pool-1 shape ::{}'.format(pool1.shape)
    #convolutional layer #2
    conv2 = tf.layers.conv2d(inputs=pool1,filters=64,kernel_size=[5,5],padding='same',activation=tf.nn.relu)
    print 'convolution-2 shape ::{}'.format(conv2.shape)
    #pooling layer
    pool2=tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2)
    print 'Pool-2 shape ::{}'.format(pool2.shape)
    #dense layer
    pool2_flat = tf.reshape(pool2,[-1,56*56*64]) #dimension = [BATCH_SIZE,HEIGHT*WIDTH*CHANNELS of the last pooled layers]
    dense = tf.layers.dense(inputs=pool2_flat,units=1024,activation=tf.nn.relu) # units = number of neurons per layer
    dropout=tf.layers.dropout(inputs=dense,rate=0.4,training = (mode == tf.estimator.ModeKeys.TRAIN))

    #Logits Layer
    logits = tf.layers.dense(inputs=dropout,units=2) #has shape [batch_size, no_of_labels]
    predictions ={'classes':tf.argmax(input=logits,axis=1),'probabilities':tf.nn.softmax(logits,name='softmax_tensor')}
    print 'Logits shape ::{}'.format(logits.shape)
    print 'Labels shape ::{}'.format(labels.shape)

    #Calculate loss for TRAIN and EVAL mode
    loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels,logits=logits)

    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())
    print 'Layers created...'
    return tf.estimator.EstimatorSpec(mode=mode,loss=loss,train_op=train_op)



def generate_input_fn(image,label,batch_size=BATCH_SIZE):
   print(""Filling queue with images before starting to train. "" ""This will take a few minutes."")
   num_preprocess_threads = 1
   def _input_fn():
      image_placeholder=tf.placeholder(tf.float32,shape=[batch_size,224,224,3])
      label_placeholder=tf.placeholder(tf.int64,shape=[batch_size,1])
      image_batch, label_batch= tf.train.shuffle_batch(
            [image_placeholder, label_placeholder],
            batch_size = batch_size,
            num_threads = num_preprocess_threads,
            capacity = 8 * BATCH_SIZE,
            min_after_dequeue = 4 * BATCH_SIZE)
      return image_batch, label_batch 
   return _input_fn



def main(unused_argv):
    print 'program started...'
    image_data, label_data, filename = Load_input()
    print 'image_data::{} label_data::{}'.format(type(image_data),type(label_data))

    estimator = tf.estimator.Estimator(model_fn=cnn_model,model_dir='./')
    print 'Estimator ready...'
    tensors_to_log = {'probabilities':'softmax_tensor'}
    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log,every_n_iter=1)
    print 'Logs ready...'
    print 'Starting training...'
    estimator.train(input_fn=generate_input_fn(image=image_data, label=label_data),steps=2,hooks=[logging_hook])


if __name__=='__main__':
  tf.app.run()
  print 'Program ended...'
</code></pre>

<p>it gives me the following error :</p>

<blockquote>
  <p>ValueError: Dimension 0 in both shapes must be equal, but are 9 and 3. Shapes are [9,2] and [3,3]. for 'softmax_cross_entropy_with_logits_sg' (op: 'SoftmaxCross
  EntropyWithLogits') with input shapes: [9,2], [3,3].</p>
</blockquote>

<p>also the layers shapes are as follows :</p>

<pre><code>conv1 output shape :: (9, 224, 224, 32)
pool1 shape :: (9, 112, 112, 32)
conv2 shape ::(9, 112, 112, 64)
pool2 shape :: (9, 56, 56, 64)
Logits shape :: (9, 2)
Labels shape :: (3, 3)
</code></pre>

<p>I don't understand why is the <code>batch size</code> <strong>9</strong> even if I try to explicitly set it to <strong>3</strong> in the code.</p>

<p><strong>Note</strong> : If anyone has a better/easier solution please post it. The aim is to <strong>use tfrecords to train a custom CNN</strong></p>
","I am new to tensorflow and trying to train a custom CNN estimator with inputs being provided from TFRecord files. The Load_input() function is supposed to look into DATA_DIR for TFRecords file and decode it through a call to read_and_decode function(which is supposed to do the actual decoding of the records), store the information into an instance of _image_object and return it. cnn_model is where I have defined the CNN architecture. And generate_input_fn is supposed to create the batches and feed it to the estimator.train while training. I just have an abstract understanding of the codes, no idea of the internal mechanics which is the primary reason why I am not able to debug. Here is my code : it gives me the following error : also the layers shapes are as follows : I don't understand why is the batch size 9 even if I try to explicitly set it to 3 in the code. Note : If anyone has a better/easier solution please post it. The aim is to use tfrecords to train a custom CNN",https://stackoverflow.com/questions/49285664,7713497,Requesting (Additional) Resources,Requesting (Additional) Resources,If anyone has a better/easier solution please post it.
64422727,What is tensorflow concrete function outputs correspond to structured_outputs?,"<p>I trained my customized ssd_mobilenet_v2 using <strong>TensorFlow2 Object Detection API</strong>. <br>
After training completed, I used exporter_main_v2.py to export a saved_model of my customized model.</p>
<p>If I load saved_model by TensorFlow2, it seem there are two kind of output format.</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
saved_model = tf.saved_model.load(&quot;saved_model&quot;)
detect_fn = saved_model[&quot;serving_default&quot;]
print(detect_fn.outputs)
'''
[&lt;tf.Tensor 'Identity:0' shape=(1, 100) dtype=float32&gt;,
 &lt;tf.Tensor 'Identity_1:0' shape=(1, 100, 4) dtype=float32&gt;,
 &lt;tf.Tensor 'Identity_2:0' shape=(1, 100) dtype=float32&gt;,
 &lt;tf.Tensor 'Identity_3:0' shape=(1, 100, 7) dtype=float32&gt;,
 &lt;tf.Tensor 'Identity_4:0' shape=(1, 100) dtype=float32&gt;,
 &lt;tf.Tensor 'Identity_5:0' shape=(1,) dtype=float32&gt;,
 &lt;tf.Tensor 'Identity_6:0' shape=(1, 1917, 4) dtype=float32&gt;,
 &lt;tf.Tensor 'Identity_7:0' shape=(1, 1917, 7) dtype=float32&gt;]
'''
print(detect_fn.structured_outputs)
'''
{'detection_classes': TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_classes'),
 'detection_scores': TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_scores'),
 'detection_multiclass_scores': TensorSpec(shape=(1, 100, 7), dtype=tf.float32, name='detection_multiclass_scores'),
 'num_detections': TensorSpec(shape=(1,), dtype=tf.float32, name='num_detections'),
 'raw_detection_boxes': TensorSpec(shape=(1, 1917, 4), dtype=tf.float32, name='raw_detection_boxes'),
 'detection_boxes': TensorSpec(shape=(1, 100, 4), dtype=tf.float32, name='detection_boxes'),
 'detection_anchor_indices': TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_anchor_indices'),
 'raw_detection_scores': TensorSpec(shape=(1, 1917, 7), dtype=tf.float32, name='raw_detection_scores')}
'''
</code></pre>
<p>Then, I try to convert this saved_model to onnx format using tf2onnx. <br>
However, the outputs of onnxruntime was a list. <br>
By the shape of result in the list, I think that the sequence is same as detect_fn.outputs</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import onnxruntime as rt

sess = rt.InferenceSession(&quot;model.onnx&quot;)
input_name = sess.get_inputs()[0].name
pred_onx = sess.run(None, {input_name: np.zeros((1,300,300,3), dtype=np.uint8)})
print(pred_onx) # a list
print([i.shape for i in pred_onx])
'''
[(1, 100),
 (1, 100, 4),
 (1, 100),
 (1, 100, 7),
 (1, 100),
 (1,),
 (1, 1917, 4),
 (1, 1917, 7)]
'''
</code></pre>
<p>Because there is some shape of result which is same as others, so it become hard to recognized.<br>
Is there any document talk about this relationship that I can refer?</p>
","I trained my customized ssd_mobilenet_v2 using TensorFlow2 Object Detection API. After training completed, I used exporter_main_v2.py to export a saved_model of my customized model. If I load saved_model by TensorFlow2, it seem there are two kind of output format. Then, I try to convert this saved_model to onnx format using tf2onnx. However, the outputs of onnxruntime was a list. By the shape of result in the list, I think that the sequence is same as detect_fn.outputs Because there is some shape of result which is same as others, so it become hard to recognized. Is there any document talk about this relationship that I can refer?",https://stackoverflow.com/questions/64422727,14148018,Requesting (Additional) Resources,Requesting (Additional) Resources,Is there any document talk about this relationship that I can refer?
71520085,Tensorflow 2.8 GPU out_of_mem when using multiprocessing,"<p>I'm trying to convert .ogg files to tfrecords. I'm running the below code on my GPU using multiprocessing but my GPU RAM gets allocated 100% and the program crashes. Anyone have some input on using multiprocessing with tensorflow or any documentation to best practices? I haven't been able to find what I'm looking for.</p>
<pre><code>import argparse
import math
import os

import numpy as np
import pandas as pd
from multiprocessing import Pool, cpu_count
import tqdm
import tensorflow as tf
import tensorflow_io as tfio

_DEFAULT_META_CSV = 'train_metadata.csv'
_DEFAULT_OUTPUT_DIR = 'tfrecords'

_DEFAULT_DURATION = 4
_DEFAULT_SAMPLE_RATE = 50000

_DEFAULT_TEST_SIZE = 0.1
_DEFAULT_VAL_SIZE = 0.1

_DEFAULT_NUM_SHARDS_TRAIN = 16
_DEFAULT_NUM_SHARDS_TEST = 4
_DEFAULT_NUM_SHARDS_VAL = 4

_SEED = 42


def _float_feature(list_of_floats):
    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))

def _int_features(list_of_ints):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[list_of_ints]))

def _bytes_feature(value):
  &quot;&quot;&quot;Returns a bytes_list from a string / byte.&quot;&quot;&quot;
  if isinstance(value, type(tf.constant(0))):
    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def _parallelize(func, data):

    processes = cpu_count() - 5
    with Pool(processes) as pool:
        list(tqdm.tqdm(pool.imap_unordered(func, data), total=len(data)))


class TFRecordsConverter:
    '''Convert audio to TFRecords'''
    def __init__(self, meta, output_dir, n_shards_train, n_shards_test,
                 n_shards_val, duration, sample_rate, test_size, val_size):        
        self.output_dir = output_dir
        self.duration = duration
        self.sample_rate = sample_rate
        
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        df = pd.read_csv(meta)
        # Shuffle the data
        self.df = df.sample(frac=1, random_state=_SEED)
        
        n_samples = len(df)
        self.n_test = math.ceil(n_samples * test_size)
        self.n_val = math.ceil(n_samples * val_size)
        self.n_train = n_samples - self.n_test - self.n_val
        
        if n_shards_train is None or n_shards_test is None or n_shards_val is None:
            self.n_shards_train = self._n_shards(self.n_train)
            self.n_shards_test = self._n_shards(self.n_test)
            self.n_shards_val = self._n_shards((self.n_val))
        else:
            self.n_shards_train = n_shards_train
            self.n_shards_test = n_shards_test
            self.n_shards_val = n_shards_val
            
        def __repr__(self):
            return ('{}.{}(output_dir={}, n_shards_train={}, n_shards_test={}, '
                    'n_shards_val={}, duration={}, sample_rate={}, n_train={}, '
                    'n_test={}, n_val={})').format(
                self.__class__.__module__,
                self.__class__.__name__,
                self.output_dir,
                self.n_shards_train,
                self.n_shards_test,
                self.n_shards_val,
                self.duration,
                self.sample_rate,
                self.n_train,
                self.n_test,
                self.n_val,
            )
    
    def _n_shards(self, n_samples):
        return math.ceil(n_samples /self._shard_size())
    
    def _shard_size(self):
        shard_max_bytes = 200 * 1024**2
        audio_bytes_per_second = self.sample_rate * 2
        audio_bytes_total = audio_bytes_per_second * self.duration
        shard_size = shard_max_bytes // audio_bytes_total
        return shard_size * self._COMPRESSION_SCALING_FACTOR
        
    def _get_shard_path(self, split, shard_id, shard_size):
        return os.path.join(self.output_dir, f'{split}-{shard_id}-{shard_size}.tfrecord')
    
    def _write_tfrecord_file(self, shard_data):
        shard_path, indices = shard_data
        with tf.io.TFRecordWriter(shard_path, options='ZLIB') as out:
            for index in indices:
                file_path = 'train_audio/' + self.df.filename.iloc[index]
                label = bytes(self.df.primary_label.iloc[index], 'utf-8')
            
                raw_audio = tf.io.read_file(file_path)
                audio = tfio.audio.decode_vorbis(raw_audio)
                
                example = tf.train.Example(features=tf.train.Features(feature={
                    'audio' :  _float_feature(audio.numpy().flatten().tolist()),
                    'label' : _bytes_feature(label)
                }))
                
                out.write(example.SerializeToString())
                
    def _split_data_into_shards(self):
        shards = []

        splits = ('train', 'test', 'validate')
        split_sizes = (self.n_train, self.n_test, self.n_val)
        split_n_shards = (self.n_shards_train, self.n_shards_test,
                          self.n_shards_val)

        offset = 0
        for split, size, n_shards in zip(splits, split_sizes, split_n_shards):
            print('Splitting {} set into TFRecord shards...'.format(split))
            shard_size = math.ceil(size / n_shards)
            cumulative_size = offset + size
            for shard_id in range(1, n_shards + 1):
                step_size = min(shard_size, cumulative_size - offset)
                shard_path = self._get_shard_path(split, shard_id, step_size)
                # Select a subset of indices to get only a subset of
                # audio-files/labels for the current shard.
                file_indices = np.arange(offset, offset + step_size)
                shards.append((shard_path, file_indices))
                offset += step_size

        return shards

    def convert(self):

        &quot;&quot;&quot;Convert to TFRecords.&quot;&quot;&quot;
        shard_splits = self._split_data_into_shards()
        _parallelize(self._write_tfrecord_file, shard_splits)

        print('Number of training examples: {}'.format(self.n_train))
        print('Number of testing examples: {}'.format(self.n_test))
        print('Number of validation examples: {}'.format(self.n_val))
        print('TFRecord files saved to {}'.format(self.output_dir))

def main():
    converter = TFRecordsConverter(_DEFAULT_META_CSV,
                                   _DEFAULT_OUTPUT_DIR,
                                   _DEFAULT_NUM_SHARDS_TRAIN,
                                   _DEFAULT_NUM_SHARDS_TEST,
                                   _DEFAULT_NUM_SHARDS_VAL,
                                   _DEFAULT_DURATION,
                                   _DEFAULT_SAMPLE_RATE,
                                   _DEFAULT_TEST_SIZE,
                                   _DEFAULT_VAL_SIZE)
    converter.convert()
        
if __name__ == '__main__':

    main()

</code></pre>
<p>Think i figured it out. I added the below code to the _write_tfrecord_file function:</p>
<pre><code>        if gpus:
          try:
            for gpu in gpus:
              tf.config.experimental.set_memory_growth(gpu, True)
          except RuntimeError as e:
            print(e) ```


It'd be great to see if anyone has any better or alternative solutions! 
</code></pre>
",I'm trying to convert .ogg files to tfrecords. I'm running the below code on my GPU using multiprocessing but my GPU RAM gets allocated 100% and the program crashes. Anyone have some input on using multiprocessing with tensorflow or any documentation to best practices? I haven't been able to find what I'm looking for. Think i figured it out. I added the below code to the _write_tfrecord_file function:,https://stackoverflow.com/questions/71520085,15891508,Requesting (Additional) Resources,Requesting (Additional) Resources,Anyone have some input on using multiprocessing with tensorflow or any documentation to best practices? I haven't been able to find what I'm looking for.
37388604,How can I use intersphinx with Tensorflow and numpydoc?,"<p>The main question here is where (if) there is an <code>objects.inv</code> for TensorFlow, but an example how to actually use it would be nice.</p>

<p>For example, I currently have the following docstring:</p>

<pre><code>""""""
Load the weights of a model stored in saver.

Parameters
----------
checkpoint_dir : str
    The directory of checkpoints.
sess : tf.Session
    A Session to use to restore the parameters.
saver : tf.train.Saver
""""""
</code></pre>

<p>How do I use intersphinx to automatically link the object to the TensorFlow documentation?</p>
","The main question here is where (if) there is an objects.inv for TensorFlow, but an example how to actually use it would be nice. For example, I currently have the following docstring: How do I use intersphinx to automatically link the object to the TensorFlow documentation?",https://stackoverflow.com/questions/37388604,562769,Requesting (Additional) Resources,Requesting (Additional) Resources,"The main question here is where (if) there is an objects.inv for TensorFlow, but an example how to actually use it would be nice."
38381887,How to read json files in Tensorflow?,"<p>I'm trying to write a function, that reads json files in tensorflow. The json files have the following structure: </p>

<pre><code>{
    ""bounding_box"": {
        ""y"": 98.5, 
        ""x"": 94.0, 
        ""height"": 197, 
        ""width"": 188
     }, 
    ""rotation"": {
        ""yaw"": -27.97019577026367,
        ""roll"": 2.206029415130615, 
        ""pitch"": 0.0}, 
        ""confidence"": 3.053506851196289, 
        ""landmarks"": {
            ""1"": {
                ""y"": 180.87722778320312, 
                ""x"": 124.47326660156205}, 
            ""0"": {
                ""y"": 178.60653686523438, 
                ""x"": 183.41931152343795}, 
            ""2"": {
                ""y"": 224.5936889648438, 
                ""x"": 141.62365722656205
}}}
</code></pre>

<p>I only need the bounding box information. There are a few examples on how to write read_and_decode-functions, and I'm trying to transform these examples into a function for json files, but there are still a lot of questions...: </p>

<pre><code>def read_and_decode(filename_queue):

  reader = tf.WhichKindOfReader() # ??? 
  _, serialized_example = reader.read(filename_queue)
  features = tf.parse_single_example( 
      serialized_example,

      features={

          'bounding_box':{ 

              'y': tf.VarLenFeature(&lt;whatstheproperdatatype&gt;) ???
              'x': 
              'height': 
              'width': 

          # I only need the bounding box... - do I need to write 
          # the format information for the other features...???

          }
      })

  y=tf.decode() # decoding necessary?
  x=
  height=
  width= 

  return x,y,height,width
</code></pre>

<p>I've done research on the internet for hours, but can't find anything really detailled on how to read json in tensorflow... </p>

<p>Maybe someone can give me a clue...</p>
","I'm trying to write a function, that reads json files in tensorflow. The json files have the following structure: I only need the bounding box information. There are a few examples on how to write read_and_decode-functions, and I'm trying to transform these examples into a function for json files, but there are still a lot of questions...: I've done research on the internet for hours, but can't find anything really detailled on how to read json in tensorflow... Maybe someone can give me a clue...",https://stackoverflow.com/questions/38381887,6539009,Lack of Alternative Solutions/Documentation,Requesting (Additional) Resources,"I've done research on the internet for hours, but can't find anything really detailled on how to read json in tensorflow. Maybe someone can give me a clue."
39770254,Fast softmax regression implementation in tensorflow,"<p>I am trying to implement the softmax regression model in tensorflow in order to make a benchmark with other mainstream deep-learning frameworks. The official documentation code is slow because of the <a href=""https://github.com/tensorflow/tensorflow/issues/2919"" rel=""nofollow"">feed_dict issue</a> in tensorflow. I am trying to serve the data as tensorflow constant but I don't know the most efficient way to do that. For now I just use the single batch as constant and trained through that batch. What are the efficient solutions of making minibatched solution of that code? Here is my code:</p>

<pre><code>from tensorflow.examples.tutorials.mnist import input_data

import tensorflow as tf
import numpy as np

mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)
batch_xs, batch_ys = mnist.train.next_batch(100)

x = tf.constant(batch_xs, name=""x"")
W = tf.Variable(0.1*tf.random_normal([784, 10]))
b = tf.Variable(tf.zeros([10]))
logits = tf.matmul(x, W) + b

batch_y = batch_ys.astype(np.float32)
y_ = tf.constant(batch_y, name=""y_"")

loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y_))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)
....
# Minitbatch is never updated during that for loop
for i in range(5500):
    sess.run(train_step)
</code></pre>
",I am trying to implement the softmax regression model in tensorflow in order to make a benchmark with other mainstream deep-learning frameworks. The official documentation code is slow because of the feed_dict issue in tensorflow. I am trying to serve the data as tensorflow constant but I don't know the most efficient way to do that. For now I just use the single batch as constant and trained through that batch. What are the efficient solutions of making minibatched solution of that code? Here is my code:,https://stackoverflow.com/questions/39770254,5251987,Requesting (Additional) Resources,Requesting (Additional) Resources,The official documentation code is slow because of the feed_dict issue in tensorflow. What are the efficient solutions of making minibatched solution of that code?
40668712,Enqueue and increment variable in Tensor Flow,"<p>How can I make a Tensor Flow graph push an incrementing number to a queue?</p>

<p>I am just doing this for learning purposes, so I'd prefer if you kept it similar to what I'm doing (and correct what I'm doing wrong). This is my code:</p>

<pre><code>import tensorflow as tf

# create queue
queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=1, dtypes=tf.float32)

# create variables, and ""add"" operation
push_var = tf.Variable(initial_value=1.0, trainable=False)
add = push_var.assign_add(1)

# enqueue operation
push = queue.enqueue(add)

# dequeue operation
pop = queue.dequeue()

sess = tf.InteractiveSession()

tf.initialize_all_variables().run()

# add var to stack
sess.run(push) # push_var = 2 after ran
sess.run(push) # push_var = 3 after ran
sess.run(push) # push_var = 4 after ran
sess.run(push) # push_var = 5 after ran
sess.run(push) # push_var = 6 after ran
sess.run(push) # push_var = 7 after ran
sess.run(push) # push_var = 8 after ran

# pop variable (random shuffle)
print sess.run(pop)
print sess.run(pop)

sess.close()
</code></pre>

<p>Output:</p>

<pre><code>8
8
</code></pre>

<p>I'm expecting it to be 2 random numbers between 2 and 8. Instead, it always is popping the current value of the variable.</p>

<p>Is this because instead of pushing the actual value of the variable I am instead pushing a pointer to the variable? Tensor Flow's <a href=""https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#Variable"" rel=""nofollow noreferrer"">documentation</a> says <code>assign_add</code> returns </p>

<blockquote>
  <p>A Tensor that will hold the new value of this variable after the
  addition has completed.</p>
</blockquote>

<p>Again, I'm trying to learn about Tensor Flow. I'd appreciate any learning resources (besides the TensorFlow website) if you have any! Thanks.</p>

<p><strong>EDIT:</strong></p>

<p>Changing <code>push = queue.enqueue(add)</code> to <code>push = queue.enqueue(add + 0)</code> results in expected behavior. Could someone explain this?</p>
","How can I make a Tensor Flow graph push an incrementing number to a queue? I am just doing this for learning purposes, so I'd prefer if you kept it similar to what I'm doing (and correct what I'm doing wrong). This is my code: Output: I'm expecting it to be 2 random numbers between 2 and 8. Instead, it always is popping the current value of the variable. Is this because instead of pushing the actual value of the variable I am instead pushing a pointer to the variable? Tensor Flow's documentation says assign_add returns Again, I'm trying to learn about Tensor Flow. I'd appreciate any learning resources (besides the TensorFlow website) if you have any! Thanks. EDIT: Changing push = queue.enqueue(add) to push = queue.enqueue(add + 0) results in expected behavior. Could someone explain this?",https://stackoverflow.com/questions/40668712,877651,Documentation Replication on Other Examples,Requesting (Additional) Resources,"Tensor Flow's documentation says assign_add returns Again, I'm trying to learn about Tensor Flow. I'd appreciate any learning resources (besides the TensorFlow website) if you have any."
42209854,The node 'Merge/MergeSummary' has inputs from different frames: what does it mean?,"<p>trying to merge all my summaries, I have an error saying that the inputs of <code>Merge/MergeSummary</code> comes from different frames. So, first of all: what is a <em>frame</em>? Could you please point me somewhere in the TF documentation about such stuff? -- of course, I googled a bit but could find almost nothing. How can I fix this issue? Below the code to reproduce the error. Thanks in advance.</p>

<pre><code>import numpy as np
import tensorflow as tf

tf.reset_default_graph()
tf.set_random_seed(23)

BATCH = 2
LENGTH = 4
SIZE = 5
ATT_SIZE = 3
NUM_QUERIES = 2

def linear(inputs, output_size, use_bias=True, activation_fn=None):
    """"""Linear projection.""""""

    input_shape = inputs.get_shape().as_list()
    input_size = input_shape[-1]
    output_shape = input_shape[:-1] + [output_size]
    if len(output_shape) &gt; 2:
        output_shape_tensor = tf.unstack(tf.shape(inputs))
        output_shape_tensor[-1] = output_size
        output_shape_tensor = tf.stack(output_shape_tensor)
        inputs = tf.reshape(inputs, [-1, input_size])

    kernel = tf.get_variable(""kernel"", [input_size, output_size])
    output = tf.matmul(inputs, kernel)
    if use_bias:
        output = output + tf.get_variable('bias', [output_size])

    if len(output_shape) &gt; 2:
        output = tf.reshape(output, output_shape_tensor)
        output.set_shape(output_shape)  # pylint: disable=I0011,E1101

    if activation_fn is not None:
        return activation_fn(output)
    return output


class Attention(object):
    """"""Attention mechanism implementation.""""""

    def __init__(self, attention_states, attention_size):
        """"""Initializes a new instance of the Attention class.""""""
        self._states = attention_states
        self._attention_size = attention_size
        self._batch = tf.shape(self._states)[0]
        self._length = tf.shape(self._states)[1]
        self._size = self._states.get_shape()[2].value
        self._features = None

    def _init_features(self):
        states = tf.reshape(
            self._states, [self._batch, self._length, 1, self._size])
        weights = tf.get_variable(
            ""kernel"", [1, 1, self._size, self._attention_size])
        self._features = tf.nn.conv2d(states, weights, [1, 1, 1, 1], ""SAME"")

    def get_weights(self, query, scope=None):
        """"""Reurns the attention weights for the given query.""""""
        with tf.variable_scope(scope or ""Attention""):
            if self._features is None:
                self._init_features()
            else:
                tf.get_variable_scope().reuse_variables()
            vect = tf.get_variable(""Vector"", [self._attention_size])
            with tf.variable_scope(""Query""):
                query_features = linear(query, self._attention_size, False)
                query_features = tf.reshape(
                    query_features, [-1, 1, 1, self._attention_size])

        activations = vect * tf.tanh(self._features + query_features)
        activations = tf.reduce_sum(activations, [2, 3])
        with tf.name_scope('summaries'):
            tf.summary.histogram('histogram', activations)
        return tf.nn.softmax(activations)

states = tf.placeholder(tf.float32, shape=[BATCH, None, SIZE])  # unknown length
queries = tf.placeholder(tf.float32, shape=[NUM_QUERIES, BATCH, ATT_SIZE])
attention = Attention(states, ATT_SIZE)
func = lambda x: attention.get_weights(x, ""Softmax"")
weights = tf.map_fn(func, queries)
for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):
    name = var.name.replace(':', '_')
    tf.summary.histogram(name, var)
summary_op = tf.summary.merge_all()

states_np = np.random.rand(BATCH, LENGTH, SIZE)
queries_np = np.random.rand(NUM_QUERIES, BATCH, ATT_SIZE)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    weights_np, summary_str = sess.run([weights, summary_op], {states: states_np, queries: queries_np})
    print weights_np
</code></pre>
","trying to merge all my summaries, I have an error saying that the inputs of Merge/MergeSummary comes from different frames. So, first of all: what is a frame? Could you please point me somewhere in the TF documentation about such stuff? -- of course, I googled a bit but could find almost nothing. How can I fix this issue? Below the code to reproduce the error. Thanks in advance.",https://stackoverflow.com/questions/42209854,1861627,Requesting (Additional) Resources,Requesting (Additional) Resources,Could you please point me somewhere in the TF documentation about such stuff?
47141359,How to calculate factorial in tensorflow?,"<p>I am new to tensorflow, I am trying to find a function that calculates the n!. 
I saw that one can use the gamma function, which was possible with theano, but did not work for tensorflow.</p>

<pre class=""lang-py prettyprint-override""><code>factorial = theano.tensor.gamma(v)
</code></pre>

<p>I am using a for loop to multiply number from n to 1, but I assume there is an easier and faster way. I saw functions related to gamma distribution, but couldn't figure out how to calculate the factorial. Would appreciate if one can point me to some documentation. </p>

<p>Here is the way I do it now</p>

<pre><code>import tensorflow as tf

factorial = tf.Variable(1, ""factorial"")
recursion = tf.Variable(1, ""recursion"")

# calculate factorial
mult = tf.multiply(recursion, factorial)
assign_fact = tf.assign(factorial, mult)

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init) 
    for i in range(2,10):
        counter = tf.assign(recursion, tf.constant(i))
        sess.run(counter)
        sess.run(assign_fact)

        print(i,""factorial is"", sess.run(factorial))

    sess.close()
</code></pre>

<p>Output is </p>

<pre><code>2 factorial is 2
3 factorial is 6
4 factorial is 24
5 factorial is 120
6 factorial is 720
7 factorial is 5040
8 factorial is 40320
9 factorial is 362880
</code></pre>
","I am new to tensorflow, I am trying to find a function that calculates the n!. I saw that one can use the gamma function, which was possible with theano, but did not work for tensorflow. I am using a for loop to multiply number from n to 1, but I assume there is an easier and faster way. I saw functions related to gamma distribution, but couldn't figure out how to calculate the factorial. Would appreciate if one can point me to some documentation. Here is the way I do it now Output is",https://stackoverflow.com/questions/47141359,1577800,Requesting (Additional) Resources,Requesting (Additional) Resources,Would appreciate if one can point me to some documentation.
52992821,Tensorflow graph fetch all consts in a scope,"<p>I create a graph and now I want to fetch their ops, how can I do this?</p>

<pre><code>g = tf.Graph()

with g.as_default():
    # Define inputs
    with tf.name_scope(""inputs""):
        a = tf.constant(2, tf.int32, name=""a"")
        b = tf.constant(3, tf.int32, name=""b"")

    # Ops
    with tf.name_scope(""ops""):
        c = tf.multiply(a, b, name=""c"")
        d = tf.add(a, b, name=""d"")
        e = tf.subtract(c, d, name=""e"")

sess = tf.InteractiveSession()

_c, _d, _e = ... &lt;-- (I need some code here!)
</code></pre>

<p>Can you show me document links about this?</p>
","I create a graph and now I want to fetch their ops, how can I do this? Can you show me document links about this?",https://stackoverflow.com/questions/52992821,6935676,Requesting (Additional) Resources,Requesting (Additional) Resources,Can you show me document links about this?
67533336,Implementing Cosine similarity loss gives different answer than Tensorflow's,"<p>I was implementing cosine similarity loss with my custom python script but it gives me a very different answer than TensorFlow. First see <code>TensorFlow's</code> answer:-</p>
<pre><code>y_true = [[0., 1.], [1., 1.]]
y_pred = [[0., 1.], [0., 1.]]
loss = tf.keras.losses.CosineSimilarity()
print(loss(y_true, y_pred).numpy())
</code></pre>
<p>Output:</p>
<pre><code>&gt;&gt;&gt; -0.8535534
</code></pre>
<p>According to the TensorFlow documentation, the formula to compute the loss is this:-</p>
<p><a href=""https://i.stack.imgur.com/ofbYZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ofbYZ.png"" alt=""enter image description here"" /></a></p>
<p>I implemented the same with plain python as this:-</p>
<pre><code>def cosine_similarity(y_true, y_pred):
    loss = -np.sum(np.linalg.norm(y_true) * np.linalg.norm(y_pred))
    return loss

print(cosine_similarity(y_true, y_pred))
</code></pre>
<p>Output:</p>
<pre><code>&gt;&gt;&gt; -2.4494897427831783
</code></pre>
<p>I don't why I am getting <code>-2.45</code> and <code>TensorFlow</code> is outputting <code>-0.85</code>. Any solution so my answer can match with TensorFlow's?</p>
","I was implementing cosine similarity loss with my custom python script but it gives me a very different answer than TensorFlow. First see TensorFlow's answer:- Output: According to the TensorFlow documentation, the formula to compute the loss is this:- I implemented the same with plain python as this:- Output: I don't why I am getting -2.45 and TensorFlow is outputting -0.85. Any solution so my answer can match with TensorFlow's?",https://stackoverflow.com/questions/67533336,,Requesting (Additional) Resources,Requesting (Additional) Resources,Any solution so my answer can match with TensorFlow's?
56834934,How to replace tensorflow softmax with max for generating one hot vector at the output layer of Neural Network?,"<p>For a classification problem, softmax function is used in the last layer of the Neural Network.<br>
I want to replace the softmax layer with the max layer that generates one hot vector with one set to the index where maximum value occurred and set all other entries to zero.</p>

<p>I can do it with tf.argmax as suggested in <a href=""https://stackoverflow.com/questions/44724948/tensorflow-dense-vector-to-one-hot"">TensorFlow - dense vector to one-hot</a> and <a href=""https://stackoverflow.com/questions/46841116/tensorflow-convert-output-tensor-to-one-hot"">Tensorflow: Convert output tensor to one-hot</a>, but these are not a differentiable way of doing it and gradients cannot be calculated.</p>

<p>If not exact 0's and 1's can be obtained then values should be close enough.  </p>

<p>I was thinking to apply softmax multiple times but it is not recommended and I do not understand the reason behind it.  </p>

<p>Please suggest a differentiable solution.</p>
","For a classification problem, softmax function is used in the last layer of the Neural Network. I want to replace the softmax layer with the max layer that generates one hot vector with one set to the index where maximum value occurred and set all other entries to zero. I can do it with tf.argmax as suggested in TensorFlow - dense vector to one-hot and Tensorflow: Convert output tensor to one-hot, but these are not a differentiable way of doing it and gradients cannot be calculated. If not exact 0's and 1's can be obtained then values should be close enough. I was thinking to apply softmax multiple times but it is not recommended and I do not understand the reason behind it. Please suggest a differentiable solution.",https://stackoverflow.com/questions/56834934,7930290,Requesting (Additional) Resources,Requesting (Additional) Resources,I was thinking to apply softmax multiple times but it is not recommended and I do not understand the reason behind it. Please suggest a differentiable solution.
55688621,How to apply mask to a tensor and keep its original shape,"<p>I have two tensors: one containing data and the other mask of boolean values. I would like to set all values in data tensor to zero, if boolean values are False, while keeping the original shape of data tensor. 
So far I can achieve it only while mask is a numpy array. </p>

<p>Since <a href=""https://www.tensorflow.org/api_docs/python/tf/boolean_mask"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/boolean_mask</a> influences shape of the tensor, I cannot use it.</p>

<p>How to do that?</p>

<pre><code>import numpy as np
import tensorflow as tf
tf.enable_eager_execution()

# create dummy data
data_np = np.ones((4,2,3))
mask_np = np.array([[True, True],[False, True],[True, True],[False, False]])

# prepare tensors
data = tf.convert_to_tensor(data_np)
mask = tf.convert_to_tensor(mask_np)

# how to perform the same while avoiding numpy?
mask = np.expand_dims(mask, -1)
data *= mask
</code></pre>
","I have two tensors: one containing data and the other mask of boolean values. I would like to set all values in data tensor to zero, if boolean values are False, while keeping the original shape of data tensor. So far I can achieve it only while mask is a numpy array. Since https://www.tensorflow.org/api_docs/python/tf/boolean_mask influences shape of the tensor, I cannot use it. How to do that?",https://stackoverflow.com/questions/55688621,1435046,Requesting (Additional) Resources,Requesting (Additional) Resources,"Since https://www.tensorflow.org/api_docs/python/tf/boolean_mask influences shape of the tensor, I cannot use it. How to do that?"
53175991,How can I make predictions from a trained model inside a Tensorflow input pipeline?,"<p>I am trying to train a model for emotion recognition, which uses one of VGG's layer's output as an input.</p>

<p>I could manage what I want by running the prediction in a first step, saving the extracted features and then using them as input to my network, but I am looking for a way to do the whole process at once.</p>

<p>The second model uses a concatenated array of feature maps as input (I am working with video data), so I am not able to simply wire it to the output of VGG.</p>

<p>I tried to use a map operation as depicted in the <code>tf.data.dataset</code> API documentations this way :</p>

<pre><code>def trimmed_vgg16():
  vgg16 = tf.keras.applications.vgg16.VGG16(input_shape=(224,224,3))
  trimmed = tf.keras.models.Model(inputs=vgg16.get_input_at(0),
                                  outputs=vgg16.layers[-3].get_output_at(0))
  return trimmed

vgg16 = trimmed_vgg16()

def _extract_vgg_features(images, labels):
    pred = vgg16_model.predict(images, batch_size=batch_size, steps=1)
    return pred, labels

dataset = #load the dataset (image, label) as usual
dataset = dataset.map(_extract_vgg_features)
</code></pre>

<p>But I'm getting this error : <code>Tensor Tensor(""fc1/Relu:0"", shape=(?, 4096), dtype=float32) is not an element of this graph</code> which is pretty explicit. I'm stuck here, as I don't see a good way of inserting the trained model in the same graph and getting predictions ""on the fly"".</p>

<p>Is there a clean way of doing this or something similar ?</p>

<p>Edit: missed a line.<br>
Edit2: added details</p>
","I am trying to train a model for emotion recognition, which uses one of VGG's layer's output as an input. I could manage what I want by running the prediction in a first step, saving the extracted features and then using them as input to my network, but I am looking for a way to do the whole process at once. The second model uses a concatenated array of feature maps as input (I am working with video data), so I am not able to simply wire it to the output of VGG. I tried to use a map operation as depicted in the tf.data.dataset API documentations this way : But I'm getting this error : Tensor Tensor(""fc1/Relu:0"", shape=(?, 4096), dtype=float32) is not an element of this graph which is pretty explicit. I'm stuck here, as I don't see a good way of inserting the trained model in the same graph and getting predictions ""on the fly"". Is there a clean way of doing this or something similar ? Edit: missed a line. Edit2: added details",https://stackoverflow.com/questions/53175991,10563517,Requesting (Additional) Resources,Requesting (Additional) Resources,"I tried to use a map operation as depicted in the tf.data.dataset API documentations this way: But I'm getting this error : Tensor Tensor(""fc1/Relu:0"", shape=(?, 4096), dtype=float32) is not an element of this graph which is pretty explicit. Is there a clean way of doing this or something similar ?"
49116343,Dataset API 'flat_map' method producing error for same code which works with 'map' method,"<p>I am trying to create a create a pipeline to read multiple CSV files using TensorFlow Dataset API and Pandas. However, using the <code>flat_map</code> method is producing errors. However, if I am using <code>map</code> method I am able to build the code and run it in session. This is the code I am using. I already opened <a href=""https://github.com/tensorflow/tensorflow/issues/17415"" rel=""nofollow noreferrer"">#17415</a> issue in TensorFlow Github repository. But apparently, it is not an error and they asked me to post here.</p>

<pre><code>folder_name = './data/power_data/'
file_names = os.listdir(folder_name)
def _get_data_for_dataset(file_name,rows=100):#
    print(file_name.decode())

    df_input=pd.read_csv(os.path.join(folder_name, file_name.decode()),
                         usecols =['Wind_MWh','Actual_Load_MWh'],nrows = rows)
    X_data = df_input.as_matrix()
    X_data.astype('float32', copy=False)

    return X_data
dataset = tf.data.Dataset.from_tensor_slices(file_names)
dataset = dataset.flat_map(lambda file_name: tf.py_func(_get_data_for_dataset, 
[file_name], tf.float64))
dataset= dataset.batch(2)
fiter = dataset.make_one_shot_iterator()
get_batch = iter.get_next()
</code></pre>

<p>I get the following error: <code>map_func must return a Dataset object</code>. The pipeline works without error when I use <code>map</code> but it doesn't give the output I want. For example, if Pandas is reading N rows from each of my CSV files I want the pipeline to concatenate data from B files and give me an array with shape (N*B, 2). Instead, it is giving me (B, N,2) where B is the Batch size. <code>map</code> is adding another axis instead of concatenating on the existing axis. From what I understood in the documentation <code>flat_map</code> is supposed to give a flatted output. In the documentation, both <code>map</code> and <code>flat_map</code> returns type Dataset. So how is my code working with map and not with flat_map?</p>

<p>It would also great if you could point me towards code where Dataset API has been used with Pandas module.</p>
","I am trying to create a create a pipeline to read multiple CSV files using TensorFlow Dataset API and Pandas. However, using the flat_map method is producing errors. However, if I am using map method I am able to build the code and run it in session. This is the code I am using. I already opened #17415 issue in TensorFlow Github repository. But apparently, it is not an error and they asked me to post here. I get the following error: map_func must return a Dataset object. The pipeline works without error when I use map but it doesn't give the output I want. For example, if Pandas is reading N rows from each of my CSV files I want the pipeline to concatenate data from B files and give me an array with shape (N*B, 2). Instead, it is giving me (B, N,2) where B is the Batch size. map is adding another axis instead of concatenating on the existing axis. From what I understood in the documentation flat_map is supposed to give a flatted output. In the documentation, both map and flat_map returns type Dataset. So how is my code working with map and not with flat_map? It would also great if you could point me towards code where Dataset API has been used with Pandas module.",https://stackoverflow.com/questions/49116343,7656080,Requesting (Additional) Resources,Requesting (Additional) Resources,It would also great if you could point me towards code where Dataset API has been used with Pandas module.
42608175,What does tf.gather_nd intuitively do?,"<p>Can you intuitively explain or give more examples about <code>tf.gather_nd</code> for indexing and slicing into high-dimensional tensors in Tensorflow? </p>

<p>I read the <a href=""https://www.tensorflow.org/api_docs/python/tf/gather_nd"" rel=""noreferrer"">API</a>, but it is kept quite concise that I find myself hard to follow the function's concept.</p>
","Can you intuitively explain or give more examples about tf.gather_nd for indexing and slicing into high-dimensional tensors in Tensorflow? I read the API, but it is kept quite concise that I find myself hard to follow the function's concept.",https://stackoverflow.com/questions/42608175,5098762,Requesting (Additional) Resources,Requesting (Additional) Resources,"Can you intuitively explain or give more examples about tf.gather_nd for indexing and slicing into high-dimensional tensors in Tensorflow? I read the API, but it is kept quite concise that I find myself hard to follow the function's concept."
66283913,Error in computing gradients in keras(tensorflow backend),"<p>I am trying to compute gradients of one of CNN filters from VGG16 w.r.t an image input using tensorflow-gpu version 2.4.1 and Keras version 2.4.3 with the following code:</p>
<pre><code>from keras.applications import VGG16
from keras import backend as K
model = VGG16(weights = 'imagenet', 
             include_top = False)
layer_name = 'block3_conv1'
filter_index = 0
layer_output = model.get_layer(layer_name).output
loss = K.mean(layer_output[:, :, :, filter_index])

grads = K.gradients(loss, model.input)[0]


</code></pre>
<p>this results in the following error:</p>
<blockquote>
<p>RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.</p>
</blockquote>
<p>Also trying to use <code>tf.GradientTape</code> raised another error:</p>
<pre><code>with tf.GradientTape() as gtape:
    grads = gtape.gradient(loss, model.input)
</code></pre>
<blockquote>
<p>AttributeError: 'KerasTensor' object has no attribute '_id'</p>
</blockquote>
<p>trying to disable eager execution did not work either:</p>
<pre><code>tf.compat.v1.disable_eager_execution()
</code></pre>
<p>since it returns gradients as None.
I would appreciate any kind of information about any way to resolve this issue.
Thanks in advance.</p>
",I am trying to compute gradients of one of CNN filters from VGG16 w.r.t an image input using tensorflow-gpu version 2.4.1 and Keras version 2.4.3 with the following code: this results in the following error: Also trying to use tf.GradientTape raised another error: trying to disable eager execution did not work either: since it returns gradients as None. I would appreciate any kind of information about any way to resolve this issue. Thanks in advance.,https://stackoverflow.com/questions/66283913,12654107,Requesting (Additional) Resources,Requesting (Additional) Resources, I would appreciate any kind of information about any way to resolve this issue.
38543850,How to Display Custom Images in Tensorboard (e.g. Matplotlib Plots)?,"<p>The <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#image-dashboard"" rel=""noreferrer"">Image Dashboard</a> section of the Tensorboard ReadMe says:</p>

<blockquote>
  <p>Since the image dashboard supports arbitrary pngs, you can use this to embed custom visualizations (e.g. matplotlib scatterplots) into TensorBoard.</p>
</blockquote>

<p>I see how a pyplot image could be written to file, read back in as a tensor, and then used with tf.image_summary() to write it to TensorBoard, but this statement from the readme suggests there is a more direct way. Is there? If so, is there any further documentation and/or examples of how to do this efficiently?  </p>
","The Image Dashboard section of the Tensorboard ReadMe says: I see how a pyplot image could be written to file, read back in as a tensor, and then used with tf.image_summary() to write it to TensorBoard, but this statement from the readme suggests there is a more direct way. Is there? If so, is there any further documentation and/or examples of how to do this efficiently?",https://stackoverflow.com/questions/38543850,5587428,Requesting (Additional) Resources,Requesting (Additional) Resources,"Is there? If so, is there any further documentation and/or examples of how to do this efficiently?"
55852943,How can i use tf.image.draw_bounding_boxes to draw bounding boxes on my original image to show where my object was detected?,"<p>Im new to Tensorflow and so far I've been able to build a classifier using data i got from Kaggle for a flower dataset and I have been able to train a CNN to identify a sunflower vs a daisy and plot the results with labels using the matplotlib.pyplot.figure() call.</p>

<p>Now I want to actually draw a bounding box on the original image itself to show where it detected the flower. I read about tf.image.draw_bounding_boxes but im a bit confused how to use it because technically the CNN has already drawn a bounding box over objects to be able to classify it. Is there a way to tap into that operation and draw abounding box the moment it frames an object in the source file?</p>

<p>Here is an example of what I want to do. I want to train my model on identifying sunflowers and then when I present a picture with sunflowers I want it to find where the sunflowers are and draw a bounding box around each sunflower.</p>

<p><img src=""https://i.stack.imgur.com/UJbxd.jpg"" alt=""sunflower""></p>

<p>and here is my code i'm using for this tutorial (assume the first three lines are just basic functions that create the labels and irrelevant for this question)</p>

<pre><code>training_images = train_data_with_label()
testing_images = test_data_with_label()
TTest = test_new_data()

# Assign images and labels
tr_img_data = np.array([i[0] for i in training_images]).reshape(-1, 64, 64, 1)
tr_lbl_data = np.array([i[1] for i in training_images])
tst_img_data = np.array([i[0] for i in testing_images]).reshape(-1, 64, 64, 1)
tst_lbl_data = np.array([i[1] for i in testing_images])

model = Sequential()

model.add(InputLayer(input_shape=[64, 64, 1]))

model.add(Conv2D(filters=16, kernel_size=5, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=5, padding='same'))

model.add(Conv2D(filters=32, kernel_size=5, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=5, padding='same'))

model.add(Conv2D(filters=50, kernel_size=5, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=5, padding='same'))

model.add(Conv2D(filters=80, kernel_size=5, strides=1, padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=5, padding='same'))

model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(rate=0.5))
model.add(Dense(classes, activation='softmax'))
optimizer = Adam(lr=1e-4)

model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(x=tr_img_data, y=tr_lbl_data, epochs=1000, batch_size=50)
model.summary()


# Save the model's weights
pth = 'S:/SavedWeights/Daisy_vs_Sunflower_vs_Tulip/weights.hdf5'
model.save_weights(pth, overwrite=True)
print(""Weights saved!!!"")


fig = plt.figure(figsize=(14, 14))

for cnt, data in enumerate(TTest[0:14]):

    y = fig.add_subplot(6, 5, cnt+1)
    img = data[0]
    data = img.reshape(1, 64, 64, 1)
    model_out = model.predict([data])

    if np.argmax(model_out) == 0:
        str_label = 'Daisy'
    elif np.argmax(model_out) == 1:
        str_label = 'Sunflower'
    else:
        str_label = 'Tulip'

    y.imshow(img, cmap='gray')
    plt.title(str_label)
    y.axes.get_xaxis().set_visible(False)
    y.axes.get_yaxis().set_visible(False)

plt.show()
</code></pre>

<p>What i would like to find is an example of how i can use this library on this kind of tutorial code and then take an arbitrary image and determine if there are sunflowers in that image and draw a box around them.</p>

<p>Thank you!</p>
",Im new to Tensorflow and so far I've been able to build a classifier using data i got from Kaggle for a flower dataset and I have been able to train a CNN to identify a sunflower vs a daisy and plot the results with labels using the matplotlib.pyplot.figure() call. Now I want to actually draw a bounding box on the original image itself to show where it detected the flower. I read about tf.image.draw_bounding_boxes but im a bit confused how to use it because technically the CNN has already drawn a bounding box over objects to be able to classify it. Is there a way to tap into that operation and draw abounding box the moment it frames an object in the source file? Here is an example of what I want to do. I want to train my model on identifying sunflowers and then when I present a picture with sunflowers I want it to find where the sunflowers are and draw a bounding box around each sunflower. and here is my code i'm using for this tutorial (assume the first three lines are just basic functions that create the labels and irrelevant for this question) What i would like to find is an example of how i can use this library on this kind of tutorial code and then take an arbitrary image and determine if there are sunflowers in that image and draw a box around them. Thank you!,https://stackoverflow.com/questions/55852943,3530309,Requesting (Additional) Resources,Requesting (Additional) Resources,What i would like to find is an example of how i can use this library on this kind of tutorial code and then take an arbitrary image and determine if there are sunflowers in that image and draw a box around them.
64231624,Where does a TensorFlow model instance get `input` property from?,"<p>I am <strong>not</strong> talking about how to pass an input to a model.</p>
<p>If you make a model, e.g. from the docs:</p>
<pre class=""lang-py prettyprint-override""><code>model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])
</code></pre>
<p><code>model</code> actually has a few properties (or attributes) which are not listed in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#attributes_1"" rel=""nofollow noreferrer"">documentation</a>... These include <code>input</code>, <code>inputs</code>, <code>name</code>, and much more. I've listed them with <code>dir()</code>, but surely its documented <strong>somewhere</strong>.</p>
<p>I would like to know what exactly these are. It really seems like a silly question. Maybe there is a different document I cannot find?</p>
","I am not talking about how to pass an input to a model. If you make a model, e.g. from the docs: model actually has a few properties (or attributes) which are not listed in the documentation... These include input, inputs, name, and much more. I've listed them with dir(), but surely its documented somewhere. I would like to know what exactly these are. It really seems like a silly question. Maybe there is a different document I cannot find?",https://stackoverflow.com/questions/64231624,7365866,Requesting (Additional) Resources,Requesting (Additional) Resources,Maybe there is a different document I cannot find?
75338588,Correct way to pass a set of images to a model for training,"<p>I'm trying to create a Keras model to train with a group of images, taken from a list of paths.
I know that the method <code>tf.keras.utils.image_dataset_from_directory</code> exists but it doesn't meet my needs because I want to learn the correct way to handle images and because I need to make a regression, not a classification.
Every approach I tried failed one way or another, mostly because the type of the x_train variable is wrong.</p>
<p>The most promising function I used to load a single image is:</p>
<pre><code>def encode_image(img_path):
  img = tf.keras.preprocessing.image.load_img(img_path)
  img_array = tf.keras.preprocessing.image.img_to_array(img)
  img_array = tf.expand_dims(img_array, 0)
  return img_array

x_train = df['filename'].apply(lambda i: encode_image(i))
</code></pre>
<p>This doesn't work because, when I call the .fit() method this way:</p>
<pre><code>history = model.fit(x_train, y_train, epochs=1)
</code></pre>
<p>I receive the following error:</p>
<pre><code>Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)
</code></pre>
<p>This makes me understand that I'm passing the data in a wrong format.
Can someone provide me a <strong>basic example</strong> of creating a (x_train, y_train) pair to feed a model for training using a set of images?
Thank you very much</p>
","I'm trying to create a Keras model to train with a group of images, taken from a list of paths. I know that the method tf.keras.utils.image_dataset_from_directory exists but it doesn't meet my needs because I want to learn the correct way to handle images and because I need to make a regression, not a classification. Every approach I tried failed one way or another, mostly because the type of the x_train variable is wrong. The most promising function I used to load a single image is: This doesn't work because, when I call the .fit() method this way: I receive the following error: This makes me understand that I'm passing the data in a wrong format. Can someone provide me a basic example of creating a (x_train, y_train) pair to feed a model for training using a set of images? Thank you very much",https://stackoverflow.com/questions/75338588,4795403,Requesting (Additional) Resources,Requesting (Additional) Resources,"Can someone provide me a basic example of creating a (x_train, y_train) pair to feed a model for training using a set of images? "
53194918,Tensorflow tf.layers Dense Neural Net function vs. Class Interface,"<p>I am trying to implement a helper class to create a standard Feedforward Neural network in python.
</p>

<p>Since I want the class to be general, there is a method called addHiddenLayer() which should append layers to the Flow Graph.
</p>

<p>To add layers to the flow graph I went through the tf.layers module which provides two options <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/dense"" rel=""nofollow noreferrer"">tf.layers.dense</a> : A function which returns an object which can act as the input to the next layer.
</p>

<p>There is also <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/Dense"" rel=""nofollow noreferrer"">tf.layers.Dense</a> : A class which has almost identical attributes as the parameters of tf.layers.dense(), and implements essentially the same operation on the inputs.
</p>

<p>After going through the documentation for both, I fail to see any extra functionality added by using the class version. I think the function implementation should suffice for my use case the skeleton for which is given below.</p>

<pre><code>class myNeuralNet:
def __init__(self, dim_input_data, dim_output_data): 
    #Member variable for dimension of Input Data Vectors (Number of features...)
    self.dim_input_data = dim_input_data
    #Variable for dimension of output labels
    self.dim_output_data = dim_output_data
    #TF Placeholder for input data   
    self.x =  tf.placeholder(tf.float32, [None, 784])
    #TF Placeholder for labels 
    self.y_ = tf.placeholder(tf.float32, [None, 10])
    #Container to store all the layers of the network 
    #Containter to hold layers of NN
    self.layer_list = []

def addHiddenLayer(self, layer_dim, activation_fn=None, regularizer_fn=None):
    # Add a layer to the network of layer_dim
    # append the new layer to the container of layers 
    pass

def addFinalLayer(self, activation_fn=None, regularizer_fn=None):
    pass

def setup_training(self, learn_rate):
    # Define loss, you might want to store it as self.loss
    # Define the train step as self.train_step = ..., use an optimizer from tf.train and call minimize(self.loss)
    pass

def setup_metrics(self):
    # Use the predicted labels and compare them with the input labels(placeholder defined in __init__)
    # to calculate accuracy, and store it as self.accuracy
    pass

# add other arguments to this function as given below
def train(self, sess, max_epochs, batch_size, train_size, print_step = 100):                
    pass
</code></pre>

<p>Can someone give an example of a situation where the class version would be required? 
References:</p>

<p><a href=""https://stackoverflow.com/questions/50029121/how-to-use-tf-layers-classes-instead-of-functions"">Related question</a> on SO</p>

<p><a href=""https://gist.github.com/koaning/c26b2dd5c2bdeaf6d7479a68bd7023bb"" rel=""nofollow noreferrer"">Example</a> of function usage </p>
","I am trying to implement a helper class to create a standard Feedforward Neural network in python. Since I want the class to be general, there is a method called addHiddenLayer() which should append layers to the Flow Graph. To add layers to the flow graph I went through the tf.layers module which provides two options tf.layers.dense : A function which returns an object which can act as the input to the next layer. There is also tf.layers.Dense : A class which has almost identical attributes as the parameters of tf.layers.dense(), and implements essentially the same operation on the inputs. After going through the documentation for both, I fail to see any extra functionality added by using the class version. I think the function implementation should suffice for my use case the skeleton for which is given below. Can someone give an example of a situation where the class version would be required? References: Related question on SO Example of function usage",https://stackoverflow.com/questions/53194918,3642162,Requesting (Additional) Resources,Requesting (Additional) Resources, Can someone give an example of a situation where the class version would be required? 
54162343,"tensorflow: object has no attribute 'matrix_inverse', how to verify it should be supported?","<p>I am running the following code on a server with a gpu, using tensorflow-gpu version=1.2:</p>

<blockquote>
  <p>matrix_b = tf.matrix_inverse(matrix_a)</p>
</blockquote>

<p>When running the same code on my laptop (no gpu) with tensorflow version=1.8 it works.</p>

<p>As I see in the <a href=""https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/matrix_inverse"" rel=""nofollow noreferrer"">documentation</a>, this is implemented for the tensorflow version I am using, so it should be supported. yet I get the following error:</p>

<blockquote>
  <p>AttributeError: 'module' object has no attribute 'matrix_inverse'</p>
</blockquote>

<p>so to my question - Can it be that the matrix_inverse() is not supported in tensorflow-gpu 1.2 but is supported in tensorflow 1.2?
and if so, where can I see the correct documentation?</p>
","I am running the following code on a server with a gpu, using tensorflow-gpu version=1.2: When running the same code on my laptop (no gpu) with tensorflow version=1.8 it works. As I see in the documentation, this is implemented for the tensorflow version I am using, so it should be supported. yet I get the following error: so to my question - Can it be that the matrix_inverse() is not supported in tensorflow-gpu 1.2 but is supported in tensorflow 1.2? and if so, where can I see the correct documentation?",https://stackoverflow.com/questions/54162343,9610896,Requesting (Additional) Resources,Requesting (Additional) Resources,Where can I see the correct documentation?
49820105,Tensorflow Mean Absolute Error (MAE) for evaluation,"<p>Looking at tensorflow docs for MAE, I saw that <a href=""https://www.tensorflow.org/api_docs/python/tf/metrics/mean_absolute_error"" rel=""noreferrer"">tf.metrics.mean_absolute_error</a> will return:</p>

<ul>
<li><code>mean_absolute_error</code>: A Tensor representing the current mean, the value of total divided by count.</li>
<li><code>update_op</code>: An operation that increments the total and count variables appropriately and whose value matches mean_absolute_error.</li>
</ul>

<p>How to implement this for evaluation purpose? As stated <a href=""https://github.com/tensorflow/tensorflow/issues/12252#issuecomment-322276355"" rel=""noreferrer"">here</a>:</p>

<blockquote>
  <p>mean_absolute_error is intended for evaluation and so it doesn't have a gradient. mean_absolute_error also returns an update op (which are you ignoring in the code above) that must be used to update the mean, so the concept of a gradient for this function doesn't really make sense. The update op for tf.metrics.mean_absolute_error(pred, y) must be called before the mean can be obtained.</p>
</blockquote>

<p>I don't know how to deal with returned value from <code>mean_absolute_error</code> function. Can someone write a simple example with this function? Thanks a lot.</p>
","Looking at tensorflow docs for MAE, I saw that tf.metrics.mean_absolute_error will return: How to implement this for evaluation purpose? As stated here: I don't know how to deal with returned value from mean_absolute_error function. Can someone write a simple example with this function? Thanks a lot.",https://stackoverflow.com/questions/49820105,3280050,Requesting (Additional) Resources,Requesting (Additional) Resources,Can someone write a simple example with this function?
43779129,Store a tf.Saver.save checkpoint in a variable (or in memory),"<p>I am using Tensorflow and storing the current ""best"" model on the hard drive for persistence, using <code>tf.Saver</code>:</p>

<pre><code>saver = tf.train.Saver(max_to_keep=1)

[...]

saver.save(
    sess,
    path_to_file,
    global_step=epoch
)
</code></pre>

<p>My network is rather small and very fast to run, a single epoch on the GPU runs in less than 10 seconds. However, saving the model to the hard drive takes between one to two minutes, taking up a lot time.</p>

<p>Is it possible to store the model in memory, to avoid taking up such a big chunk of the overall run time? If I somehow could store the ""best"" model in memory for a while, and dump it once I tell the model to, I could cut down the overall run time by a big factor.</p>

<p>I've looked at the <code>tf.Saver</code> documentation and implementation, and I can not see any way to achieve just what I want. Is there some other implementation or tool that can do what I want to?</p>
","I am using Tensorflow and storing the current ""best"" model on the hard drive for persistence, using tf.Saver: My network is rather small and very fast to run, a single epoch on the GPU runs in less than 10 seconds. However, saving the model to the hard drive takes between one to two minutes, taking up a lot time. Is it possible to store the model in memory, to avoid taking up such a big chunk of the overall run time? If I somehow could store the ""best"" model in memory for a while, and dump it once I tell the model to, I could cut down the overall run time by a big factor. I've looked at the tf.Saver documentation and implementation, and I can not see any way to achieve just what I want. Is there some other implementation or tool that can do what I want to?",https://stackoverflow.com/questions/43779129,921563,Requesting (Additional) Resources,Requesting (Additional) Resources,"I've looked at the tf.Saver documentation and implementation, and I can not see any way to achieve just what I want. Is there some other implementation or tool that can do what I want to?"
34706950,How many processes does TensorFlow open?,"<p>I am using torque to run some CNN-based learning using <code>tensorflow</code> library. (1 CPU per task)</p>

<p>When I run <code>top</code> on my server, I noticed that: <code>load average: 677.29, 668.59, 470.</code></p>

<p>I create a session like this: <code>sess = tf.Session()</code></p>

<p>So my question is there some place in documentation where I can read when and how many processes TensorFlow uses.</p>
","I am using torque to run some CNN-based learning using tensorflow library. (1 CPU per task) When I run top on my server, I noticed that: load average: 677.29, 668.59, 470. I create a session like this: sess = tf.Session() So my question is there some place in documentation where I can read when and how many processes TensorFlow uses.",https://stackoverflow.com/questions/34706950,1886138,Requesting (Additional) Resources,Requesting (Additional) Resources,So my question is there some place in documentation where I can read when and how many processes TensorFlow uses.
47432870,Can tf.contrib.training.batch_sequences_with_states handle input sequences with variable lengths?,"<p>I was trying to use <code>tf.contrib.training.batch_sequences_with_states</code> to create padded batches of variable length input sequences in order to train an LSTM network.</p>
<p>While reading the documentation I stumbled upon contradicting statements, concerning the capabilities of this function.</p>
<p>Specifically the parameter <code>input_sequences</code> is confusing to me.</p>
<blockquote>
<p><code>input_sequence</code> is a dict with values that are tensors with time as first dimension. This time dimension must be the same across those tensors of an example. <strong>It can vary across examples.</strong></p>
<p><code>input_sequences</code>: A dict mapping string names to Tensor values. <strong>The values must all have matching first dimension</strong>, called value_length. They may vary from input to input</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/training/batch_sequences_with_states"" rel=""nofollow noreferrer"">Source</a></p>
</blockquote>
<p>How do I supply this function with multiple examples?</p>
<h2>My first attempt</h2>
<pre><code>import tensorflow as tf
import numpy as np

batch_size = 10
num_unroll = 4
num_enqueue_threads = 2
lstm_size = 8

seq1 = np.random.rand(8, 8, 2)
seq2 = np.random.rand(16, 8, 2)

sequences = {&quot;seq1&quot;: seq1, &quot;seq2&quot;: seq2}
context = {&quot;seq1&quot;: 0, &quot;seq2&quot;: 1}

initial_states = {&quot;c&quot;: tf.zeros((lstm_size,), dtype=tf.float32),
                  &quot;h&quot;: tf.zeros((lstm_size,), dtype=tf.float32)}

batch = tf.contrib.training.batch_sequences_with_states(
    input_key=&quot;key&quot;,
    input_sequences=sequences,
    input_context=context,
    input_length=None,
    initial_states=initial_states,
    num_unroll=num_unroll,
    batch_size=batch_size,
    num_threads=num_enqueue_threads,
    capacity=batch_size * num_enqueue_threads * 2,
    make_keys_unique=True
)

inputs = batch.sequences[&quot;seq1&quot;]

with tf.Session() as sess:
    tf.train.start_queue_runners()
    print(sess.run([inputs]))
</code></pre>
<p>Executing this code snippet leads to the following error message:</p>
<pre><code>ERROR:tensorflow:Exception in QueueRunner: assertion failed: 
[All sequence lengths must match, but received lengths: 8 
 All sequence lengths must match, but received lengths: 16]
</code></pre>
<p>An example showing how to correctly supply this function with multiple examples of varying input_sequence lengths would be really helpful!</p>
","I was trying to use tf.contrib.training.batch_sequences_with_states to create padded batches of variable length input sequences in order to train an LSTM network. While reading the documentation I stumbled upon contradicting statements, concerning the capabilities of this function. Specifically the parameter input_sequences is confusing to me. How do I supply this function with multiple examples? Executing this code snippet leads to the following error message: An example showing how to correctly supply this function with multiple examples of varying input_sequence lengths would be really helpful!",https://stackoverflow.com/questions/47432870,5970048,Documentation Ambiguity,Requesting (Additional) Resources,An example showing how to correctly supply this function with multiple examples of varying input_sequence lengths would be really helpful!
72484718,"Tensorflow tf.dataset won't iterate with multiple inputs of different sizes ""Shapes of all inputs must match""","<p>I am trying to make a tensorflow model with two different inputs, one will have shape [9,10], the other will just have shape [8].</p>
<p>I am furthermore trying to use tf.dataset to iterate over my inputs.  However, whenever I try to do so it fails with the following error:</p>
<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [9,10] != values[1].shape = [8]
     [[{{node packed}}]] [Op:IteratorGetNext]
</code></pre>
<p>But surely it is possible to have differently sized inputs into different branches!  This is exactly the case in the example in tensorflow's functional API guide, however they do not use tf.dataset so I can't simply follow their example.</p>
<p>To give a little more specifics into the problem I am trying to solve and why I am using the tf.dataset api:</p>
<p>I am doing a time-series problem over multiple sites where my inputs are of two types: those that vary with time, and those that do not but do vary by site. For the time being, I'm just trying to estimate the next time step.</p>
<p>First, I get my dynamic covariates and targets in a sliding window using the timeseries_dataset_from_array util.</p>
<pre><code>    train_ds = tf.keras.preprocessing.timeseries_dataset_from_array(
        input_data, targets, sequence_length=window_size, batch_size=256)
</code></pre>
<p>This works perfectly and I can train models using this dataset as is.</p>
<p>However, I want to also use the static covariates from the specific site that the time series data is coming from.  The site id is included in the window input data in its own column, though it gets removed before training. Thus, what I am trying to do is grab the static covariates for the site and attach it as a separate input to my dataset.</p>
<pre><code>    train_ds = train_ds.map(lambda x, y: (tf.py_function(attach_static_covariates, [x, idindex, colnames], [tf.float64, tf.float64]), y))

    train_ds = train_ds.map(lambda x, y: ({'dynamic': x[0], 'static': x[1]}, y))
</code></pre>
<p>The code for the attach_static_covariates method is:</p>
<pre><code>def attach_static_covariates(x, idindex, colnames):
    id = x[0, idindex].numpy()
    static_cov = static_df.iloc[int(id)]
    #This just filters out the id column, now that it has served its purpose
    x = tf.gather(x, [i for i in range(len(colnames)) if i != idindex])

    return (x, static_cov)
</code></pre>
<p>I've confirmed that my code can run and train on multiple inputs provided by the above method provided they are the same size (e.g. if I return (x, x) I can run my model on two copies of the dynamic covariates inputted into two different branches of my model).  The problem is not due to a mismatch or a bad model definition because I get the same error from the following code:</p>
<pre><code>    for feature_batch, label_batch in train_ds.take(1):
        print(feature_batch)
</code></pre>
<p>I've looked everywhere on google and the tensorflow git and I can't find anyone else with this problem, and yet it surely MUST be possible to have differently shaped inputs using tf.dataset!  I can't imagine that such an incredibly common use case would be completely unsupported.  However, I can't find any examples online where someone has multiple inputs of different shapes and uses tf.dataset api.  Any help or links to such examples would be greatly appreciated.</p>
<p>Colab notebook to illustrate issue:
<a href=""https://colab.research.google.com/drive/1EnaJoUULl-fyAwlcG_5tcWfsRFVCOMtv#scrollTo=PHvsIOx6-Uux"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/1EnaJoUULl-fyAwlcG_5tcWfsRFVCOMtv#scrollTo=PHvsIOx6-Uux</a></p>
","I am trying to make a tensorflow model with two different inputs, one will have shape [9,10], the other will just have shape [8]. I am furthermore trying to use tf.dataset to iterate over my inputs. However, whenever I try to do so it fails with the following error: But surely it is possible to have differently sized inputs into different branches! This is exactly the case in the example in tensorflow's functional API guide, however they do not use tf.dataset so I can't simply follow their example. To give a little more specifics into the problem I am trying to solve and why I am using the tf.dataset api: I am doing a time-series problem over multiple sites where my inputs are of two types: those that vary with time, and those that do not but do vary by site. For the time being, I'm just trying to estimate the next time step. First, I get my dynamic covariates and targets in a sliding window using the timeseries_dataset_from_array util. This works perfectly and I can train models using this dataset as is. However, I want to also use the static covariates from the specific site that the time series data is coming from. The site id is included in the window input data in its own column, though it gets removed before training. Thus, what I am trying to do is grab the static covariates for the site and attach it as a separate input to my dataset. The code for the attach_static_covariates method is: I've confirmed that my code can run and train on multiple inputs provided by the above method provided they are the same size (e.g. if I return (x, x) I can run my model on two copies of the dynamic covariates inputted into two different branches of my model). The problem is not due to a mismatch or a bad model definition because I get the same error from the following code: I've looked everywhere on google and the tensorflow git and I can't find anyone else with this problem, and yet it surely MUST be possible to have differently shaped inputs using tf.dataset! I can't imagine that such an incredibly common use case would be completely unsupported. However, I can't find any examples online where someone has multiple inputs of different shapes and uses tf.dataset api. Any help or links to such examples would be greatly appreciated. Colab notebook to illustrate issue: https://colab.research.google.com/drive/1EnaJoUULl-fyAwlcG_5tcWfsRFVCOMtv#scrollTo=PHvsIOx6-Uux",https://stackoverflow.com/questions/72484718,15913381,Lack of Alternative Solutions/Documentation,Requesting (Additional) Resources,"However, I can't find any examples online where someone has multiple inputs of different shapes and uses tf.dataset api. Any help or links to such examples would be greatly appreciated."
56967648,Need help in writing the tf.estimator.export.ServingInputReceiver in Tensorflow 2.0.beta1,"<p>I am trying to serve my Keras model, but my model is trained on image of shape <code>(125,125,3)</code> and it expect an input as numpy array. But as I was learning the <code>tf.estimator.export.ServingInputReceiver</code> to pre-process my <code>b64_enoded</code> image to a numpy array and feed my model with it, I am stuck here.</p>

<p>All my model building and pre-processing is done in tensorflow 2.0. So I am  looking for a help to write the <code>tf.estimator.export.ServingInputReceiver</code> function for it.</p>

<p>Model Summary:</p>

<pre><code>Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_a (Conv2D)            (None, 125, 125, 32)      896       
_________________________________________________________________
Activation_a (Activation)    (None, 125, 125, 32)      0         
_________________________________________________________________
MaxPool_a (MaxPooling2D)     (None, 62, 62, 32)        0         
_________________________________________________________________
Conv2d_c (Conv2D)            (None, 62, 62, 64)        18496     
_________________________________________________________________
Activation_c (Activation)    (None, 62, 62, 64)        0         
_________________________________________________________________
MaxPool_b (MaxPooling2D)     (None, 31, 31, 64)        0         
_________________________________________________________________
Conv2d_d (Conv2D)            (None, 31, 31, 128)       73856     
_________________________________________________________________
Activation_d (Activation)    (None, 31, 31, 128)       0         
_________________________________________________________________
MaxPool_c (MaxPooling2D)     (None, 15, 15, 128)       0         
_________________________________________________________________
Flatten (Flatten)            (None, 28800)             0         
_________________________________________________________________
Dense_a (Dense)              (None, 512)               14746112  
_________________________________________________________________
dropout_a (Dropout)          (None, 512)               0         
_________________________________________________________________
Dense_b (Dense)              (None, 512)               262656    
_________________________________________________________________
dropout_b (Dropout)          (None, 512)               0         
_________________________________________________________________
output (Dense)               (None, 1)                 513       
=================================================================
Total params: 15,102,529
Trainable params: 15,102,529
Non-trainable params: 0
</code></pre>

<p>Here is my code :</p>

<pre class=""lang-py prettyprint-override""><code>
def build_serving_inputs(inputs):
    def decode_and_resize(image_str_tensor):
        image = tf.io.decode_base64(image_str_tensor)
        image = tf.image.decode_png(image, channels=3)
        image = tf.image.resize_with_crop_or_pad(image, 125, 125)
        image = image /255
        #image = tf.expand_dims(image, 0)
        #image = tf.cast(image, dtype=tf.float32)
        return image

    if not isinstance(inputs, np.ndarray):
        inputs = np.array([inputs])

    # Converting the B64 Image data to tensorflow tf.string
    inputs = tf.cast(inputs, tf.string)

    # Decoding the image and returning a numpy array
    decoded_images = tf.map_fn(decode_and_resize, inputs,
        dtype=tf.float32,back_prop=False)
    decoded_images = tf.identity(decoded_images, name=""output"")
    return tf.estimator.export.ServingInputReceiver()

estimator.export_savedmodel(""./model/my_model/"",
serving_input_receiver_fn=build_serving_inputs)

</code></pre>

<p>I want to export my model with the <code>ServingInput</code> Receiver as a pre-processing funtion to convert a <code>b64_encoded</code> image to numpy and feed it to the Model.</p>
","I am trying to serve my Keras model, but my model is trained on image of shape (125,125,3) and it expect an input as numpy array. But as I was learning the tf.estimator.export.ServingInputReceiver to pre-process my b64_enoded image to a numpy array and feed my model with it, I am stuck here. All my model building and pre-processing is done in tensorflow 2.0. So I am looking for a help to write the tf.estimator.export.ServingInputReceiver function for it. Model Summary: Here is my code : I want to export my model with the ServingInput Receiver as a pre-processing funtion to convert a b64_encoded image to numpy and feed it to the Model.",https://stackoverflow.com/questions/56967648,9887738,Requesting (Additional) Resources,Requesting (Additional) Resources,All my model building and pre-processing is done in tensorflow 2.0. So I am looking for a help to write the tf.estimator.export.ServingInputReceiver function for it.
55345384,Load (or combine) several pretrained checkpoints with tf.estimator.WarmStartSettings,"<p>I want to use pretrained weights for 2 parts of my model. I have 2 checkpoints from different models, from which I can load only one into my main model with tf.estimator.WarmStart as I'm using the estimator architecture.</p>

<pre><code>tf.WarmStartSettings(ckpt_to_initialize_from=X)
</code></pre>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/WarmStartSettings"" rel=""nofollow noreferrer"">from the doc</a>: </p>

<blockquote>
  <p>Either the directory or a specific checkpoint can be provided (in the case of the former, the latest checkpoint will be used).</p>
</blockquote>

<p>I can't see how I can add an additional checkpoint. Maybe there is a way to load the weights from both checkpoint into one and load that one?</p>
","I want to use pretrained weights for 2 parts of my model. I have 2 checkpoints from different models, from which I can load only one into my main model with tf.estimator.WarmStart as I'm using the estimator architecture. from the doc: I can't see how I can add an additional checkpoint. Maybe there is a way to load the weights from both checkpoint into one and load that one?",https://stackoverflow.com/questions/55345384,2368505,Requesting (Additional) Resources,Requesting (Additional) Resources,"From the doc, I can't see how I can add an additional checkpoint. Maybe there is a way to load the weights from both checkpoint into one and load that one?"
58228821,Tensorflow gradientTape explanation,"<p>I am trying to understand an API from tensorflow tf.gradientTape</p>

<p>Below is the code I get from the official website:</p>

<pre><code>x = tf.constant(3.0)
with tf.GradientTape(persistent=True) as g:
  g.watch(x)
  y = x * x
  z = y * y
dz_dx = g.gradient(z, x)  # 108.0 (4*x^3 at x = 3)
dy_dx = g.gradient(y, x)  # 6.0
</code></pre>

<p>I wanted to know how did they get dz_dx as 108 and dy_dx as 6? </p>

<p>I also did another test like below:</p>

<pre><code>x = tf.constant(3.0)
with tf.GradientTape(persistent=True) as g:
  g.watch(x)
  y = x * x * x
  z = y * y
dz_dx = g.gradient(z, x)  # 1458.0 
dy_dx = g.gradient(y, x)  # 6.0
</code></pre>

<p>this time the dz_dx becomes 1458 and I do not know why at all. Could any expert show me how the calculation being done? </p>
",I am trying to understand an API from tensorflow tf.gradientTape Below is the code I get from the official website: I wanted to know how did they get dz_dx as 108 and dy_dx as 6? I also did another test like below: this time the dz_dx becomes 1458 and I do not know why at all. Could any expert show me how the calculation being done?,https://stackoverflow.com/questions/58228821,11634815,Requesting (Additional) Resources,Requesting (Additional) Resources,I am trying to understand an API from tensorflow tf.gradientTape Below is the code I get from the official websitel. Could any expert show me how the calculation being done?
44064753,Multiply all elements of Tensor in Tensorflow,"<p>I have tensor with 3 elements which I want to multiply with each others.</p>

<p>My code currently looks like this:</p>

<pre><code>m1 = tf.multiply(y[0],y[1])
m2 = tf.multiply(m1,y[2])
</code></pre>

<p>Which imho is very unflexible, of course I could put a loop and iterate over the elements, but I was wondering if there is such functionallity already provded in tf ? I could not find anything in the docs</p>
","I have tensor with 3 elements which I want to multiply with each others. My code currently looks like this: Which imho is very unflexible, of course I could put a loop and iterate over the elements, but I was wondering if there is such functionallity already provded in tf ? I could not find anything in the docs",https://stackoverflow.com/questions/44064753,6786718,Requesting (Additional) Resources,Requesting (Additional) Resources,"I could put a loop and iterate over the elements, but I was wondering if there is such functionallity already provded in tf ? I could not find anything in the docs"
60106449,How to create a TensorFlow 2 SavedModel with more than 1 signatures?,"<p>I used <code>tf.saved_model.save</code> and <code>tf.saved_model.load</code> to save and load TF2 SavedModel. According to <a href=""https://www.tensorflow.org/api_docs/python/tf/saved_model/save#used-in-the-notebooks"" rel=""nofollow noreferrer"">this link</a>, I created a signature and this signature is <code>serving_default</code>. Then I try to add a new function with signature decorator in class <code>Adder</code>. But after I loaded the model according to <a href=""https://www.tensorflow.org/api_docs/python/tf/saved_model/load"" rel=""nofollow noreferrer"">this</a>, I find that the signatures disappear in the model, i.e., <code>print(adder1.signatures)</code> prints no signature names. I don't find any information about how to use multiple signatures while saving models. So can anyone provide me with some information? Thank you very much.  </p>

<p>Tensorflow <code>2.1.0</code>, on Google Colab. The code looks like this: </p>

<pre><code>import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import os
import pandas as pd

class Adder(tf.Module):

  @tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32), tf.TensorSpec(shape=None, dtype=tf.float32)])# 
  def add(self, x, y):
    return x + y ** 2 + 1

  @tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])
  def square(self, x):
    return x ** 2

to_export = Adder()
tf.saved_model.save(
    to_export, 
    '/tmp/adder'            
)

adder1 = tf.saved_model.load(""/tmp/adder"")
print(adder1.signatures)
adder1_sig = adder1.signatures[""serving_default""]
adder1_sig(x = tf.constant(1.), y = tf.constant(2.))


</code></pre>
","I used tf.saved_model.save and tf.saved_model.load to save and load TF2 SavedModel. According to this link, I created a signature and this signature is serving_default. Then I try to add a new function with signature decorator in class Adder. But after I loaded the model according to this, I find that the signatures disappear in the model, i.e., print(adder1.signatures) prints no signature names. I don't find any information about how to use multiple signatures while saving models. So can anyone provide me with some information? Thank you very much. Tensorflow 2.1.0, on Google Colab. The code looks like this:",https://stackoverflow.com/questions/60106449,12375578,Lack of Alternative Solutions/Documentation,Requesting (Additional) Resources,I don't find any information about how to use multiple signatures while saving models. So can anyone provide me with some information?
51507788,What are inputs and outputs in tf.saved_model.simple_save?,"<p>In tf.saved_model.simple_save, there are 4 params:</p>

<ul>
<li>session, the session</li>
<li>export_dir, the dir where the model will be saved</li>
<li>inputs, <strong>what it this?</strong></li>
<li>outputs, <strong>what is this?</strong></li>
</ul>

<p>I've been reading how to <a href=""https://www.tensorflow.org/guide/saved_model#simple_save"" rel=""noreferrer"">simple_save</a> but I haven't been able to figure out what to put in these two parameters (inputs and outputs). I know the model must have input values so that it can be either trained or predict. So I don't know what these two parameters should contain and wether they should map variables inside the model or what...</p>

<p>The docs aren't that great so any explaining would be much appreciated.</p>
","In tf.saved_model.simple_save, there are 4 params: I've been reading how to simple_save but I haven't been able to figure out what to put in these two parameters (inputs and outputs). I know the model must have input values so that it can be either trained or predict. So I don't know what these two parameters should contain and wether they should map variables inside the model or what... The docs aren't that great so any explaining would be much appreciated.",https://stackoverflow.com/questions/51507788,1071459,Requesting (Additional) Resources,Requesting (Additional) Resources,The docs aren't that great so any explaining would be much appreciated.
55063120,can anyone give a tiny example to explain the params of tf.random.categorical?,"<p>tensorflow's site gives this example</p>

<pre><code>tf.random.categorical(tf.log([[10., 10.]]), 5)
</code></pre>

<p>produces a tensor that ""has shape [1, 5], where each value is either 0 or 1 with equal probability""</p>

<p>I have already known, the basic <a href=""https://www.tensorflow.org/api_docs/python/tf/random/categorical"" rel=""noreferrer"">demo</a>, the meaning of <code>tf.log([[10., 10.]])</code>.</p>

<p>what I want to know is what does [batch_size, num_classes] do, can anyone give a tiny example to explain the params?</p>
","tensorflow's site gives this example produces a tensor that ""has shape [1, 5], where each value is either 0 or 1 with equal probability"" I have already known, the basic demo, the meaning of tf.log([[10., 10.]]). what I want to know is what does [batch_size, num_classes] do, can anyone give a tiny example to explain the params?",https://stackoverflow.com/questions/55063120,,Requesting (Additional) Resources,Requesting (Additional) Resources,"Tensorflow's site gives this example produces a tensor that ""has shape [1, 5], where each value is either 0 or 1 with equal probability"" I have already known, the basic demo, the meaning of tf.log([[10., 10.]]). what I want to know is what does [batch_size, num_classes] do, can anyone give a tiny example to explain the params?"
55491752,Workaround for using tf.matmul with two non-constant inputs,"<p>We are currently trying to convert a transformer model to a tensorflow-lite graph but it seems that the problem is the self-attention mechanism. </p>

<p>We're not able to process the graph. Looking into tf-lite code we narrowed it down to the <code>tf.matmul</code> lite-version.</p>

<p>The <a href=""https://www.tensorflow.org/lite/guide/ops_compatibility"" rel=""nofollow noreferrer"">docs</a> state:</p>

<blockquote>
  <p><code>tf.matmul</code> - <em>as long as the second argument is constant and transposition is not used</em></p>
</blockquote>

<p>However, this is the case in self-attention:</p>

<p><a href=""https://i.stack.imgur.com/r7I3G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/r7I3G.png"" alt=""enter image description here""></a></p>

<p>(source: <a href=""https://arxiv.org/pdf/1706.03762.pdf"" rel=""nofollow noreferrer"">Attention is all you need</a>)</p>

<p>Is there a known workaround for such a situation?</p>
","We are currently trying to convert a transformer model to a tensorflow-lite graph but it seems that the problem is the self-attention mechanism. We're not able to process the graph. Looking into tf-lite code we narrowed it down to the tf.matmul lite-version. The docs state: However, this is the case in self-attention: (source: Attention is all you need) Is there a known workaround for such a situation?",https://stackoverflow.com/questions/55491752,826983,Requesting (Additional) Resources,Requesting (Additional) Resources,"The docs state: However, this is the case in self-attention: (source: Attention is all you need) Is there a known workaround for such a situation?"
47521759,tf.metrics.accuracy not working as intended,"<p>I have linear regression model that seems to be working fine, but I want to display the accuracy of the model. </p>

<p>First, I initialize the variables and placeholders...</p>

<pre><code>X_train, X_test, Y_train, Y_test = train_test_split(
    X_data, 
    Y_data, 
    test_size=0.2
)

n_rows = X_train.shape[0]

X = tf.placeholder(tf.float32, [None, 89])
Y = tf.placeholder(tf.float32, [None, 1])

W_shape = tf.TensorShape([89, 1])
b_shape = tf.TensorShape([1])

W = tf.Variable(tf.random_normal(W_shape))
b = tf.Variable(tf.random_normal(b_shape))

pred = tf.add(tf.matmul(X, W), b)

cost = tf.reduce_sum(tf.pow(pred-Y, 2)/(2*n_rows-1))

optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate).minimize(cost)
</code></pre>

<p><code>X_train</code> has shape <code>(6702, 89)</code> and <code>Y_train</code> has shape <code>(6702, 1)</code>. Next I run the session and I display the cost per epoch as well as the total MSE...</p>

<pre><code>init = tf.global_variables_initializer()

with tf.Session() as sess:

    sess.run(init)

    for epoch in range(FLAGS.training_epochs):

        avg_cost = 0

        for (x, y) in zip(X_train, Y_train):

            x = np.reshape(x, (1, 89))
            y = np.reshape(y, (1,1))
            sess.run(optimizer, feed_dict={X:x, Y:y})

        # display logs per epoch step
        if (epoch + 1) % FLAGS.display_step == 0:

            c = sess.run(
                cost, 
                feed_dict={X:X_train, Y:Y_train}
            )

            y_pred = sess.run(pred, feed_dict={X:X_test})
            test_error = r2_score(Y_test, y_pred)
            print(test_error)

            print(""Epoch:"", '%04d' % (epoch + 1), ""cost="", ""{:.9f}"".format(c))

    print(""Optimization Finished!"")

    pred_y = sess.run(pred, feed_dict={X:X_test})
    mse = tf.reduce_mean(tf.square(pred_y - Y_test))

    print(""MSE: %4f"" % sess.run(mse))
</code></pre>

<p>This all seems to work correctly. However, now I want to see the accuracy of my model, so I want to implement <code>tf.metrics.accuracy</code>. The documentation says it has 2 arguments, <code>labels</code> and <code>predictions</code>. I added the following next...</p>

<pre><code>accuracy, accuracy_op = tf.metrics.accuracy(labels=Y_test, predictions=pred)

init_local = tf.local_variables_initializer()

sess.run(init_local)

print(sess.run(accuracy))
</code></pre>

<p>Apparently I need to initialize local variales, however I think I am doing something wrong because the accuracy result that gets printed out is <code>0.0</code>. </p>

<p>I searched everywhere for a working example but I cannot get it to work for my model, what is the proper way to implement it?</p>
","I have linear regression model that seems to be working fine, but I want to display the accuracy of the model. First, I initialize the variables and placeholders... X_train has shape (6702, 89) and Y_train has shape (6702, 1). Next I run the session and I display the cost per epoch as well as the total MSE... This all seems to work correctly. However, now I want to see the accuracy of my model, so I want to implement tf.metrics.accuracy. The documentation says it has 2 arguments, labels and predictions. I added the following next... Apparently I need to initialize local variales, however I think I am doing something wrong because the accuracy result that gets printed out is 0.0. I searched everywhere for a working example but I cannot get it to work for my model, what is the proper way to implement it?",https://stackoverflow.com/questions/47521759,4333347,Requesting (Additional) Resources,Requesting (Additional) Resources,"The documentation says it has 2 arguments, labels and predictions. I added the following next... Apparently I need to initialize local variales, however I think I am doing something wrong because the accuracy result that gets printed out is 0.0. I searched everywhere for a working example but I cannot get it to work for my model, what is the proper way to implement it?"
42364283,Tensorflow: calculate gradient for tf.multiply,"<p>I'm building a neural network that has the following two layers</p>

<pre><code>pseudo_inputs = tf.Variable(a_numpy_ndarray)
weights = tf.Variable(tf.truncated_normal(...))
</code></pre>

<p>I then want to multiply them using <code>tf.multiply</code> (which, unlike <code>tf.matmul</code> multiplies corresponding indices, i.e. c_ij = a_ij * b_ij)</p>

<pre><code>input = tf.multiply(pseudo_inputs, weights)
</code></pre>

<p>My goal is to learn <code>weights</code>. So I run</p>

<pre><code>train_step = tf.train.AdamOptimizer(learn_rate).minimize(loss, var_list=[weights])
</code></pre>

<p>But it doesn't work. The network doesn't change at all.</p>

<p>Looking at tensorboard, I could see that 'input' has no gradient, so I'm assuming that's the problem. Any ideas how to solve this?</p>

<p>From reading tensorflow docs it seems like I might have to write a gradient op for tf.multiply, but I find it hard to believe no one needed to do this before.</p>
","I'm building a neural network that has the following two layers I then want to multiply them using tf.multiply (which, unlike tf.matmul multiplies corresponding indices, i.e. c_ij = a_ij * b_ij) My goal is to learn weights. So I run But it doesn't work. The network doesn't change at all. Looking at tensorboard, I could see that 'input' has no gradient, so I'm assuming that's the problem. Any ideas how to solve this? From reading tensorflow docs it seems like I might have to write a gradient op for tf.multiply, but I find it hard to believe no one needed to do this before.",https://stackoverflow.com/questions/42364283,1660762,Requesting (Additional) Resources,Requesting (Additional) Resources,"From reading tensorflow docs it seems like I might have to write a gradient op for tf.multiply, but I find it hard to believe no one needed to do this before."
34141430,Tensorflow Tensor reshape and pad with zeros,"<p>Is there a way to reshape a tensor and pad any overflow with zeros? I know ndarray.reshape does this, but as I understand it, converting a Tensor to an ndarray would require flip-flopping between the GPU and CPU. </p>

<p>Tensorflow's reshape() documentation says the TensorShapes need to have the same number of elements, so perhaps the best way would be a pad() and then reshape()?</p>

<p>I'm trying to achieve:</p>

<pre><code>a = tf.Tensor([[1,2],[3,4]])
tf.reshape(a, [2,3])
a =&gt; [[1, 2, 3],
      [4, 0 ,0]]
</code></pre>
","Is there a way to reshape a tensor and pad any overflow with zeros? I know ndarray.reshape does this, but as I understand it, converting a Tensor to an ndarray would require flip-flopping between the GPU and CPU. Tensorflow's reshape() documentation says the TensorShapes need to have the same number of elements, so perhaps the best way would be a pad() and then reshape()? I'm trying to achieve:",https://stackoverflow.com/questions/34141430,4975126,Requesting (Additional) Resources,Requesting (Additional) Resources,"Is there a way to reshape a tensor and pad any overflow with zeros? I know ndarray.reshape does this, but as I understand it, converting a Tensor to an ndarray would require flip-flopping between the GPU and CPU. Tensorflow's reshape() documentation says the TensorShapes need to have the same number of elements, so perhaps the best way would be a pad() and then reshape()?"
48309707,When to use tf.resource and tf.variant?,"<p>TensorFlow DType has tf.resource and tf.variant with pretty vague description. Can someone please explain to me what those two types are for? It'd be great if there are examples. Thanks a lot!</p>
",TensorFlow DType has tf.resource and tf.variant with pretty vague description. Can someone please explain to me what those two types are for? It'd be great if there are examples. Thanks a lot!,https://stackoverflow.com/questions/48309707,5029595,Requesting (Additional) Resources,Requesting (Additional) Resources,TensorFlow DType has tf.resource and tf.variant with pretty vague description. Can someone please explain to me what those two types are for? It'd be great if there are examples.
53367063,"tensorflow python expected dense_input to have 2 dimensions, but got array with shape (5, 28, 5)","<p>I am a complete newbie to tensorflow, trying to learn about it and solve a problem.  I tried a lot of tutorials but they all talked about the same classify image or mnist stuff, so I followed the documentation and tried to figure something out.  </p>

<p>The goal is to find a pattern to predict the result when the input is [[1000,10, 5, 3, 1744...etc.  There are only 5 cases when the value is 300 400, 500, 600, 700, with shape 28,5 and the result for each is 28,2 list.  The data is loaded from file and assigned to tf.tensor.  </p>

<p>Here's my code:</p>

<pre><code>model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(28, activation=tf.nn.relu, input_shape=(5,)))
model.add(tf.keras.layers.Dense(28, activation=tf.nn.relu, input_shape=(5,)))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(28))

model.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['accuracy'])

model.fit(newData, newResults, epochs=3, steps_per_epoch=5)
</code></pre>

<p>newData:</p>

<pre><code>[[[300, 10, 5, 3, 1744], [300, 10, 5, 5, 2848], [300, 10, 5, 4, 2418], [300, 10, 5, 2, 1152], [300, 10, 5, 3, 1126], [300, 10, 5, 3, 1897], [300, 10, 5, 3, 1089], [300, 10, 5, 2, 1581], [300, 10, 5, 4, 1793], [300, 10, 5, 3, 1525], [300, 10, 5, 2, 1529], [300, 10, 5, 3, 1052], [300, 10, 5, 2, 1556], [300, 10, 5, 3, 1569], [300, 10, 5, 5, 2873], [300, 10, 5, 4, 2269], [300, 10, 5, 3, 3003], [300, 10, 5, 3, 1310], [300, 10, 5, 3, 1464], [300, 10, 5, 3, 2807], [300, 10, 5, 2, 1262], [300, 10, 5, 3, 1734], [300, 10, 5, 2, 2709], [300, 10, 5, 3, 2234], [300, 10, 5, 3, 1961], [300, 10, 5, 2, 1594], [300, 10, 5, 2, 1836], [300, 10, 5, 2, 1345]], 
[[400, 10, 5, 3, 1744], [400, 10, 5, 5, 2848], [400, 10, 5, 4, 2418], [400, 10, 5, 2, 1152], [400, 10, 5, 3, 1126], [400, 10, 5, 3, 1897], [400, 10, 5, 3, 1089], [400, 10, 5, 2, 1581], [400, 10, 5, 4, 1793], [400, 10, 5, 3, 1525], [400, 10, 5, 2, 1529], [400, 10, 5, 3, 1052], [400, 10, 5, 2, 1556], [400, 10, 5, 3, 1569], [400, 10, 5, 5, 2873], [400, 10, 5, 4, 2269], [400, 10, 5, 3, 3003], [400, 10, 5, 3, 1310], [400, 10, 5, 3, 1464], [400, 10, 5, 3, 2807], [400, 10, 5, 2, 1262], [400, 10, 5, 3, 1734], [400, 10, 5, 2, 2709], [400, 10, 5, 3, 2234], [400, 10, 5, 3, 1961], [400, 10, 5, 2, 1594], [400, 10, 5, 2, 1836], [400, 10, 5, 2, 1345]], 
[[500, 10, 5, 3, 1744], [500, 10, 5, 5, 2848], [500, 10, 5, 4, 2418], [500, 10, 5, 2, 1152], [500, 10, 5, 3, 1126], [500, 10, 5, 3, 1897], [500, 10, 5, 3, 1089], [500, 10, 5, 2, 1581], [500, 10, 5, 4, 1793], [500, 10, 5, 3, 1525], [500, 10, 5, 2, 1529], [500, 10, 5, 3, 1052], [500, 10, 5, 2, 1556], [500, 10, 5, 3, 1569], [500, 10, 5, 5, 2873], [500, 10, 5, 4, 2269], [500, 10, 5, 3, 3003], [500, 10, 5, 3, 1310], [500, 10, 5, 3, 1464], [500, 10, 5, 3, 2807], [500, 10, 5, 2, 1262], [500, 10, 5, 3, 1734], [500, 10, 5, 2, 2709], [500, 10, 5, 3, 2234], [500, 10, 5, 3, 1961], [500, 10, 5, 2, 1594], [500, 10, 5, 2, 1836], [500, 10, 5, 2, 1345]], 
[[600, 10, 5, 3, 1744], [600, 10, 5, 5, 2848], [600, 10, 5, 4, 2418], [600, 10, 5, 2, 1152], [600, 10, 5, 3, 1126], [600, 10, 5, 3, 1897], [600, 10, 5, 3, 1089], [600, 10, 5, 2, 1581], [600, 10, 5, 4, 1793], [600, 10, 5, 3, 1525], [600, 10, 5, 2, 1529], [600, 10, 5, 3, 1052], [600, 10, 5, 2, 1556], [600, 10, 5, 3, 1569], [600, 10, 5, 5, 2873], [600, 10, 5, 4, 2269], [600, 10, 5, 3, 3003], [600, 10, 5, 3, 1310], [600, 10, 5, 3, 1464], [600, 10, 5, 3, 2807], [600, 10, 5, 2, 1262], [600, 10, 5, 3, 1734], [600, 10, 5, 2, 2709], [600, 10, 5, 3, 2234], [600, 10, 5, 3, 1961], [600, 10, 5, 2, 1594], [600, 10, 5, 2, 1836], [600, 10, 5, 2, 1345]], 
[[700, 10, 5, 3, 1744], [700, 10, 5, 5, 2848], [700, 10, 5, 4, 2418], [700, 10, 5, 2, 1152], [700, 10, 5, 3, 1126], [700, 10, 5, 3, 1897], [700, 10, 5, 3, 1089], [700, 10, 5, 2, 1581], [700, 10, 5, 4, 1793], [700, 10, 5, 3, 1525], [700, 10, 5, 2, 1529], [700, 10, 5, 3, 1052], [700, 10, 5, 2, 1556], [700, 10, 5, 3, 1569], [700, 10, 5, 5, 2873], [700, 10, 5, 4, 2269], [700, 10, 5, 3, 3003], [700, 10, 5, 3, 1310], [700, 10, 5, 3, 1464], [700, 10, 5, 3, 2807], [700, 10, 5, 2, 1262], [700, 10, 5, 3, 1734], [700, 10, 5, 2, 2709], [700, 10, 5, 3, 2234], [700, 10, 5, 3, 1961], [700, 10, 5, 2, 1594], [700, 10, 5, 2, 1836], [700, 10, 5, 2, 1345]]]
</code></pre>

<p>newResult:</p>

<pre><code>[[[29.0, 8.92], [52.0, 21.67], [41.0, 14.38], [7.0, 1.49], [26.0, 8.25], [18.0, 4.53], [24.0, 6.61], [21.0, 9.54], [17.0, 5.53], [27.0, 9.61], [11.0, 0.35], [22.0, 8.11], [7.0, 1.22], [36.0, 15.49], [57.0, 31.44], [43.0, 16.52], [34.0, 11.46], [15.0, 2.49], [20.0, 2.34], [16.0, 4.86], [10.0, 0.8], [8.0, 0.4], [1.0, 0.0], [30.0, 7.57], [24.0, 7.21], [5.0, 0.58], [14.0, 0.73], [4.0, 0.15]], 
[[45.0, 8.17], [100.0, 43.28], [54.0, 16.05], [10.0, 2.77], [37.0, 8.86], [27.0, 6.12], [33.0, 9.13], [34.0, 14.03], [20.0, 5.06], [45.0, 15.42], [21.0, 0.69], [26.0, 8.83], [11.0, 2.14], [44.0, 17.74], [73.0, 43.39], [43.0, 18.8], [46.0, 21.56], [29.0, 9.16], [21.0, 3.76], [20.0, 7.39], [16.0, 2.54], [1.0, 1.63], [1.0, 0.02], [28.0, 12.14], [30.0, 12.35], [7.0, 1.18], [19.0, 3.29], [4.0, 0.16]], 
[[59.0, 18.74], [100.0, 75.18], [69.0, 32.13], [11.0, 3.04], [49.0, 15.76], [30.0, 10.33], [45.0, 14.51], [43.0, 20.82], [37.0, 8.2], [69.0, 24.53], [1.0, 0.3], [38.0, 12.57], [1.0, 3.67], [65.0, 24.77], [91.0, 57.39], [53.0, 18.22], [47.0, 27.07], [34.0, 16.31], [25.0, 5.39], [31.0, 11.5], [23.0, 5.73], [19.0, 4.11], [2.0, 0.11], [35.0, 15.52], [41.0, 18.15], [7.0, 1.48], [25.0, 7.53], [3.0, 0.14]], 
[[80.0, 30.29], [100.0, 85.22], [94.0, 52.73], [11.0, 2.45], [72.0, 30.7], [46.0, 14.75], [70.0, 22.81], [50.0, 28.26], [40.0, 14.19], [60.0, 26.82], [14.0, 0.28], [45.0, 19.1], [16.0, 4.72], [82.0, 40.98], [100.0, 78.96], [66.0, 27.05], [67.0, 31.09], [34.0, 16.92], [23.0, 7.03], [48.0, 21.28], [27.0, 8.19], [21.0, 3.95], [2.0, 0.17], [43.0, 19.96], [55.0, 23.54], [8.0, 1.47], [28.0, 12.04], [4.0, 0.13]], 
[[95.0, 38.09], [100.0, 92.88], [99.0, 58.96], [13.0, 3.54], [96.0, 45.78], [33.0, 12.05], [87.0, 38.11], [62.0, 34.97], [48.0, 15.49], [84.0, 33.13], [10.0, 0.09], [63.0, 25.52], [16.0, 4.87], [100.0, 55.9], [100.0, 91.32], [90.0, 34.24], [96.0, 45.36], [37.0, 15.13], [27.0, 9.28], [49.0, 26.3], [30.0, 10.92], [22.0, 3.72], [3.0, 0.14], [67.0, 24.82], [73.0, 31.32], [8.0, 1.36], [31.0, 15.03], [4.0, 0.2]]]
</code></pre>

<p>Getting this error when I run it:</p>

<pre><code>  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1536, in fit
    validation_split=validation_split)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 992, in _standardize_user_data
    class_weight, batch_size)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1117, in _standardize_weights
    exception_prefix='input')
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\keras\engine\training_utils.py"", line 323, in standardize_input_data
    'with shape ' + str(data_shape))
ValueError: Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (5, 28, 5)
</code></pre>

<p>I know my model definitely has something wrong with it, but I can't quite figure out what.  I have trouble finding information other than the afore mentioned examples.</p>
","I am a complete newbie to tensorflow, trying to learn about it and solve a problem. I tried a lot of tutorials but they all talked about the same classify image or mnist stuff, so I followed the documentation and tried to figure something out. The goal is to find a pattern to predict the result when the input is [[1000,10, 5, 3, 1744...etc. There are only 5 cases when the value is 300 400, 500, 600, 700, with shape 28,5 and the result for each is 28,2 list. The data is loaded from file and assigned to tf.tensor. Here's my code: newData: newResult: Getting this error when I run it: I know my model definitely has something wrong with it, but I can't quite figure out what. I have trouble finding information other than the afore mentioned examples.",https://stackoverflow.com/questions/53367063,10672298,Requesting (Additional) Resources,Requesting (Additional) Resources,I have trouble finding information other than the afore mentioned examples.
65734836,"Numpy Equivalent to ""tf.tensor_scatter_nd_add"" method","<p>Question is in the title really, I am looking for a method in scipy/numpy/etc. (not TensorFlow) which encapsulates the behaviour described in the <a href=""https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_add"" rel=""nofollow noreferrer"">tf.tensor_scatter_nd_add</a> but on Numpy arrays rather than tensors.</p>
<p>I have come across the <a href=""https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.ndimage.sum.html"" rel=""nofollow noreferrer"">scipy.ndimage.sum</a> method, but couldn't get this to reproduce the example I've given below.</p>
<p>Whichever method you think fits has to be able to reproduce the rank-3 example that is provided in the TF Documentation:</p>
<pre class=""lang-py prettyprint-override""><code>    indices = tf.constant([[0], [2]])
    updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],
                            [7, 7, 7, 7], [8, 8, 8, 8]],
                           [[5, 5, 5, 5], [6, 6, 6, 6],
                            [7, 7, 7, 7], [8, 8, 8, 8]]])
    tensor = tf.ones([4, 4, 4],dtype=tf.int32)
    updated = tf.tensor_scatter_nd_add(tensor, indices, updates)
    print(updated)
</code></pre>
<p>Hopefully someone has solved a similar problem before and can help here - Thanks in advance!</p>
","Question is in the title really, I am looking for a method in scipy/numpy/etc. (not TensorFlow) which encapsulates the behaviour described in the tf.tensor_scatter_nd_add but on Numpy arrays rather than tensors. I have come across the scipy.ndimage.sum method, but couldn't get this to reproduce the example I've given below. Whichever method you think fits has to be able to reproduce the rank-3 example that is provided in the TF Documentation: Hopefully someone has solved a similar problem before and can help here - Thanks in advance!",https://stackoverflow.com/questions/65734836,7861160,Requesting (Additional) Resources,Requesting (Additional) Resources,Whichever method you think fits has to be able to reproduce the rank-3 example that is provided in the TF Documentation: Hopefully someone has solved a similar problem before and can help here
41283115,"Tensorflow, difference between tf.nn.softmax_cross_entropy_with_logits and tf.nn.sparse_softmax_cross_entropy_with_logits","<p>I have read the <a href=""https://www.tensorflow.org/api_docs/python/nn/classification"" rel=""nofollow noreferrer"">docs of both functions</a>, but as far as I know, for function <code>tf.nn.softmax_cross_entropy_with_logits(logits, labels, dim=-1, name=None)</code>, the result is the cross entropy loss, in which the dimensions of <code>logits</code> and <code>labels</code> are the same.</p>

<p>But, for function <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code>, the dimensions of <code>logits</code> and <code>labels</code> are not the same?</p>

<p>Could you give a more detail example of <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code>?</p>
","I have read the docs of both functions, but as far as I know, for function tf.nn.softmax_cross_entropy_with_logits(logits, labels, dim=-1, name=None), the result is the cross entropy loss, in which the dimensions of logits and labels are the same. But, for function tf.nn.sparse_softmax_cross_entropy_with_logits, the dimensions of logits and labels are not the same? Could you give a more detail example of tf.nn.sparse_softmax_cross_entropy_with_logits?",https://stackoverflow.com/questions/41283115,5046896,Requesting (Additional) Resources,Requesting (Additional) Resources,"I have read the docs of both functions, but as far as I know, for function tf.nn.softmax_cross_entropy_with_logits(logits, labels, dim=-1, name=None), the result is the cross entropy loss, in which the dimensions of logits and labels are the same. But, for function tf.nn.sparse_softmax_cross_entropy_with_logits, the dimensions of logits and labels are not the same? Could you give a more detail example of tf.nn.sparse_softmax_cross_entropy_with_logits?"
42437115,"Tensorflow: Replacement for tf.nn.rnn_cell._linear(input, size, 0, scope)","<p>I am trying to get the SequenceGAN (<a href=""https://github.com/LantaoYu/SeqGAN"" rel=""noreferrer"">https://github.com/LantaoYu/SeqGAN</a>) from <a href=""https://arxiv.org/pdf/1609.05473.pdf"" rel=""noreferrer"">https://arxiv.org/pdf/1609.05473.pdf</a> to run.<br>
After fixing the obvious errors, like replacing <code>pack</code> with <code>stack</code>, it still doesn't run, since the highway-network part requires the <code>tf.nn.rnn_cell._linear</code> function:</p>

<pre><code># highway layer that borrowed from https://github.com/carpedm20/lstm-char-cnn-tensorflow
def highway(input_, size, layer_size=1, bias=-2, f=tf.nn.relu):
    """"""Highway Network (cf. http://arxiv.org/abs/1505.00387).

    t = sigmoid(Wy + b)
    z = t * g(Wy + b) + (1 - t) * y
    where g is nonlinearity, t is transform gate, and (1 - t) is carry gate.
    """"""
    output = input_
    for idx in range(layer_size):
        output = f(tf.nn.rnn_cell._linear(output, size, 0, scope='output_lin_%d' % idx)) #tf.contrib.layers.linear instad doesn't work either.
        transform_gate = tf.sigmoid(tf.nn.rnn_cell._linear(input_, size, 0, scope='transform_lin_%d' % idx) + bias)
        carry_gate = 1. - transform_gate

        output = transform_gate * output + carry_gate * input_

    return output
</code></pre>

<p>the <code>tf.nn.rnn_cell._linear</code> function doesn't appear to be there anymore in Tensorflow 1.0 or 0.12, and I have no clue what to replace it with. I can't find any new implementations of this, or any information on tensorflow's github or (unfortunately very sparse) documentation.</p>

<p>Does anybody know the new pendant of the function?
Thanks a lot in advance!</p>
","I am trying to get the SequenceGAN (https://github.com/LantaoYu/SeqGAN) from https://arxiv.org/pdf/1609.05473.pdf to run. After fixing the obvious errors, like replacing pack with stack, it still doesn't run, since the highway-network part requires the tf.nn.rnn_cell._linear function: the tf.nn.rnn_cell._linear function doesn't appear to be there anymore in Tensorflow 1.0 or 0.12, and I have no clue what to replace it with. I can't find any new implementations of this, or any information on tensorflow's github or (unfortunately very sparse) documentation. Does anybody know the new pendant of the function? Thanks a lot in advance!",https://stackoverflow.com/questions/42437115,5122790,Requesting (Additional) Resources,Requesting (Additional) Resources,"I can't find any new implementations of this, or any information on tensorflow's github or (unfortunately very sparse) documentation. Does anybody know the new pendant of the function? "
43367697,Batching and shuffling padded tf.train.SequenceExample,"<p>I have some training example of a sequence-to-sequence scenario which are stored as <code>tf.train.SequenceExample</code> in one (or more) file(s) written <code>TFRecordWriter</code>. I would like to read, decode them and feed shuffled batches of them into my network. I have been struggling with the documentation and some tutorials found here and there but I could not make anything out of such stuff. I am working on a self-contained example, here below. </p>

<pre><code>import random

import tensorflow as tf

from six.moves import xrange


MIN_LEN = 6
MAX_LEN = 12
NUM_EXAMPLES = 20
BATCH_SIZE = 3
PATH = 'ciaone.tfrecords'
MIN_AFTER_DEQUEUE = 10
NUM_THREADS = 2
SAFETY_MARGIN = 1
CAPACITY = MIN_AFTER_DEQUEUE + (NUM_THREADS + SAFETY_MARGIN) * BATCH_SIZE


def generate_example():
    # fake examples which are just useful to have a quick visualization.
    # The input is a sequence of random numbers.
    # The output is a sequence made of those numbers from the
    # input sequence which are greater or equal then the average.
    length = random.randint(MIN_LEN, MAX_LEN)
    input_ = [random.randint(0, 10) for _ in xrange(length)]
    avg = sum([1.0 * item for item in input_]) / len(input_)
    output = [item for item in input_ if item &gt;= avg]
    return input_, output


def encode(input_, output):
    length = len(input_)
    example = tf.train.SequenceExample(
        context=tf.train.Features(
            feature={
                'length': tf.train.Feature(
                    int64_list=tf.train.Int64List(value=[length]))
            }),
        feature_lists=tf.train.FeatureLists(
            feature_list={
                'input': tf.train.FeatureList(
                    feature=[
                        tf.train.Feature(
                            int64_list=tf.train.Int64List(value=[item]))
                        for item in input_]),
                'output': tf.train.FeatureList(
                    feature=[
                        tf.train.Feature(
                            int64_list=tf.train.Int64List(value=[item]))
                        for item in output])
            }
        )
    )
    return example


def decode(example):
    context_features = {
        'length': tf.FixedLenFeature([], tf.int64)
    }
    sequence_features = {
        'input': tf.FixedLenSequenceFeature([], tf.int64),
        'output': tf.FixedLenSequenceFeature([], tf.int64)
    }
    ctx, seq = tf.parse_single_sequence_example(
        example, context_features, sequence_features)
    input_ = seq['input']
    output = seq['output']
    return input_, output

if __name__ == '__main__':
    # STEP 1. -- generate a dataset.
    with tf.python_io.TFRecordWriter(PATH) as writer:
        for _ in xrange(NUM_EXAMPLES):
           record = encode(*generate_example())
           writer.write(record.SerializeToString())

    with tf.Session() as sess:
        queue = tf.train.string_input_producer([PATH])
        reader = tf.TFRecordReader()
        _, value = reader.read(queue)
        input_, output = decode(value)

        # HERE I AM STUCK!

        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        sess.run(tf.local_variables_initializer())
        sess.run(tf.global_variables_initializer())
        try:
            while True:
                # do something...
        except tf.errors.OutOfRangeError, e:
            coord.request_stop(e)
        finally:
            coord.request_stop()
            coord.join(threads)
        coord.request_stop()
        coord.join(threads)
</code></pre>

<p>Can anyone suggest me how to proceed?
Thanks in advance!</p>

<p>P.S. as a side request: any pointer about resources to better understand the input pipeline APIs of TensorFlow is appreciated.</p>
","I have some training example of a sequence-to-sequence scenario which are stored as tf.train.SequenceExample in one (or more) file(s) written TFRecordWriter. I would like to read, decode them and feed shuffled batches of them into my network. I have been struggling with the documentation and some tutorials found here and there but I could not make anything out of such stuff. I am working on a self-contained example, here below. Can anyone suggest me how to proceed? Thanks in advance! P.S. as a side request: any pointer about resources to better understand the input pipeline APIs of TensorFlow is appreciated.",https://stackoverflow.com/questions/43367697,1861627,Requesting (Additional) Resources,Requesting (Additional) Resources," I have been struggling with the documentation and some tutorials found here and there but I could not make anything out of such stuff. I am working on a self-contained example, here below. Can anyone suggest me how to proceed? "
45090843,Does sequence_length help performance of dynamic_rnn?,"<p>In <a href=""https://github.com/tensorflow/nmt"" rel=""nofollow noreferrer"">Google's recent nmt tutorial</a>, they say this: </p>

<blockquote>
  <p>Note that sentences have different lengths to avoid wasting computation, we tell dynamic_rnn the exact source sentence lengths through source_seqence_length</p>
</blockquote>

<p>with this code: 
<code>encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_emb_inp,
    sequence_length=source_seqence_length, time_major=True)
</code></p>

<p>However, I was reading <a href=""https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn.py"" rel=""nofollow noreferrer"">dynamic_rnn's documentation</a> and it says: </p>

<blockquote>
  <p>The parameter <code>sequence_length</code> is optional and is used to copy-through state
    and zero-out outputs when past a batch element's sequence length. So it's more
    for correctness than performance.</p>
</blockquote>

<p>I'm just wondering if sequence_length really helps performance of dynamic_rnn, e.g. they do some kind of dynamic bucketing? If they do, is there any place where I can read more about it? Thanks a lot.</p>
","In Google's recent nmt tutorial, they say this: with this code: encoder_outputs, encoder_state = tf.nn.dynamic_rnn( encoder_cell, encoder_emb_inp, sequence_length=source_seqence_length, time_major=True) However, I was reading dynamic_rnn's documentation and it says: I'm just wondering if sequence_length really helps performance of dynamic_rnn, e.g. they do some kind of dynamic bucketing? If they do, is there any place where I can read more about it? Thanks a lot.",https://stackoverflow.com/questions/45090843,5029595,Requesting (Additional) Resources,Requesting (Additional) Resources,"However, I was reading dynamic_rnn's documentation and it says: I'm just wondering if sequence_length really helps performance of dynamic_rnn, e.g. they do some kind of dynamic bucketing? If they do, is there any place where I can read more about it? "
48815906,Implement early stopping in tf.estimator.DNNRegressor using the available training hooks,"<p>I am new to tensorflow and want to implement early stopping in <code>tf.estimator.DNNRegressor</code> with  available training hooks<a href=""https://www.tensorflow.org/api_guides/python/train#Training_Hooks"" rel=""noreferrer"">Training Hooks</a> for the MNIST dataset. The early stopping hook will stop training if the loss does not improve for some specified number of steps. Tensorflow documentaton only provides example for <a href=""https://www.tensorflow.org/tutorials/layers#set_up_a_logging_hook"" rel=""noreferrer"">Logging hooks</a>. Can someone write a code snippet for implementing it?</p>
",I am new to tensorflow and want to implement early stopping in tf.estimator.DNNRegressor with available training hooksTraining Hooks for the MNIST dataset. The early stopping hook will stop training if the loss does not improve for some specified number of steps. Tensorflow documentaton only provides example for Logging hooks. Can someone write a code snippet for implementing it?,https://stackoverflow.com/questions/48815906,6533039,Requesting (Additional) Resources,Requesting (Additional) Resources,Tensorflow documentaton only provides example for Logging hooks. Can someone write a code snippet for implementing it?
49201832,How to use TensorBoard and summary operations with the tf.layers module,"<p>I have followed the <a href=""https://www.tensorflow.org/tutorials/layers"" rel=""nofollow noreferrer"">TensorFlow Layers tutorial</a> to create a CNN for MNIST digit classification using TensorFlow's tf.layers module. Now I'm trying to learn how to use TensorBoard from <a href=""https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"" rel=""nofollow noreferrer"">TensorBoard: Visualizing Learning</a>. Perhaps this tutorial hasn't been updated recently, because it says its example code is a modification of that tutorial's and links to it, but the code is completely different: it manually defines a single-hidden-layer fully-connected network.</p>

<p>The TensorBoard tutorial shows how to use tf.summary to attach summaries to a layer by creating operations on the layer's weights tensor, which is directly accessible because we manually defined the layer, and attaching tf.summary objects to those operations. To do this if I'm using tf.layers and its tutorial code, I believe I'd have to:</p>

<ol>
<li>Modify the Layers tutorial's example code to use the non-functional interface (Conv2D instead of conv2d and Dense instead of dense) to create the layers</li>
<li>Use the layer objects' trainable_weights() functions to get the weight tensors and attach tf.summary objects to those</li>
</ol>

<p>Is that the best way to use TensorBoard with tf.layers, or is there a way that's more directly compatible with tf.layers and the functional interface? If so, is there an updated official TensorBoard tutorial? It would be nice if the documentation and tutorials were more unified. </p>
","I have followed the TensorFlow Layers tutorial to create a CNN for MNIST digit classification using TensorFlow's tf.layers module. Now I'm trying to learn how to use TensorBoard from TensorBoard: Visualizing Learning. Perhaps this tutorial hasn't been updated recently, because it says its example code is a modification of that tutorial's and links to it, but the code is completely different: it manually defines a single-hidden-layer fully-connected network. The TensorBoard tutorial shows how to use tf.summary to attach summaries to a layer by creating operations on the layer's weights tensor, which is directly accessible because we manually defined the layer, and attaching tf.summary objects to those operations. To do this if I'm using tf.layers and its tutorial code, I believe I'd have to: Is that the best way to use TensorBoard with tf.layers, or is there a way that's more directly compatible with tf.layers and the functional interface? If so, is there an updated official TensorBoard tutorial? It would be nice if the documentation and tutorials were more unified.",https://stackoverflow.com/questions/49201832,2328207,Requesting (Additional) Resources,Requesting (Additional) Resources,"Is that the best way to use TensorBoard with tf.layers, or is there a way that's more directly compatible with tf.layers and the functional interface? If so, is there an updated official TensorBoard tutorial? It would be nice if the documentation and tutorials were more unified."
49686860,Side effect in tf.while_loop,"<p>I am currently having a hard time trying to understand how tensorflow works, and I feel like the python interface is somehow obscure.</p>

<p>I recently tried to run a simple print statement inside a tf.while_loop, and there are many things that remains unclear to me:</p>

<pre><code>import tensorflow as tf

nb_iter = tf.constant(value=10)
#This solution does not work at all
#nb_iter = tf.get_variable('nb_iter', shape=(1), dtype=tf.int32, trainable=False)
i = tf.get_variable('i', shape=(), trainable=False,
                     initializer=tf.zeros_initializer(), dtype=nb_iter.dtype)

loop_condition = lambda i: tf.less(i, nb_iter)
def loop_body(i):
    tf.Print(i, [i], message='Another iteration')
    return [tf.add(i, 1)]

i = tf.while_loop(loop_condition, loop_body, [i])

initializer_op = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(initializer_op)
    res = sess.run(i)
    print('res is now {}'.format(res))
</code></pre>

<p>Notice that if I initialize nb_iter with</p>

<pre><code>nb_iter = tf.get_variable('nb_iter', shape=(1), dtype=tf.int32, trainable=False)
</code></pre>

<p>I got the following error:</p>

<blockquote>
  <p>ValueError: Shape must be rank 0 but is rank 1 for 'while/LoopCond'
  (op: 'LoopCond') with input shapes: [1].</p>
</blockquote>

<p>It get even worse when I try to use the 'i' index for indexing a tensor (example not shown here), I then get the following error</p>

<blockquote>
  <p>alueError: Operation 'while/strided_slice' has been marked as not
  fetchable.</p>
</blockquote>

<p>Can someone point me to a documentation that explains how tf.while_loop works when used with tf.Variables, and if it possible to use side_effects (like print) inside the loop, as well as indexing tensor with the loop variable ?</p>

<p>Thank you in advance for your help</p>
","I am currently having a hard time trying to understand how tensorflow works, and I feel like the python interface is somehow obscure. I recently tried to run a simple print statement inside a tf.while_loop, and there are many things that remains unclear to me: Notice that if I initialize nb_iter with I got the following error: It get even worse when I try to use the 'i' index for indexing a tensor (example not shown here), I then get the following error Can someone point me to a documentation that explains how tf.while_loop works when used with tf.Variables, and if it possible to use side_effects (like print) inside the loop, as well as indexing tensor with the loop variable ? Thank you in advance for your help",https://stackoverflow.com/questions/49686860,2697831,Requesting (Additional) Resources,Requesting (Additional) Resources,"It get even worse when I try to use the 'i' index for indexing a tensor (example not shown here), I then get the following error Can someone point me to a documentation that explains how tf.while_loop works when used with tf.Variables, and if it possible to use side_effects (like print) inside the loop, as well as indexing tensor with the loop variable ?"
50210594,the function of 'bounding_boxes' and 'min_object_covered' in tf.image.sample_distorted_bounding_box?,"<p>How parameters 'bounding_boxes' and 'min_object_covered' control the generation of a single randomly distorted bounding box for an image in tf.image.sample_distorted_bounding_box? </p>

<p>I have read the <a href=""https://www.tensorflow.org/api_docs/python/tf/image/sample_distorted_bounding_box"" rel=""nofollow noreferrer"">function</a> in tensorflow api, but I still can not understand the proplem. Maybe I need a intuitive example.</p>
","How parameters 'bounding_boxes' and 'min_object_covered' control the generation of a single randomly distorted bounding box for an image in tf.image.sample_distorted_bounding_box? I have read the function in tensorflow api, but I still can not understand the proplem. Maybe I need a intuitive example.",https://stackoverflow.com/questions/50210594,8307005,Requesting (Additional) Resources,Requesting (Additional) Resources,"I have read the function in tensorflow api, but I still can not understand the proplem. Maybe I need a intuitive example."
54934603,"tensorflow documentation says ""WARNING: Avoid writing code which relies on the value of a Variable..."" what does it mean?","<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">tf.Variable documentation</a> 
contains the following warning:</p>

<blockquote>
  <p>WARNING: tf.Variable objects by default have a non-intuitive memory model. A Variable is represented internally as a mutable Tensor which can non-deterministically alias other Tensors in a graph. The set of operations which consume a Variable and can lead to aliasing is undetermined and can change across TensorFlow versions. Avoid writing code which relies on the value of a Variable either changing or not changing as other operations happen. For example, using Variable objects or simple functions thereof as predicates in a tf.cond is dangerous and error-prone:</p>
</blockquote>

<pre><code>v = tf.Variable(True)
tf.cond(v, lambda: v.assign(False), my_false_fn)  # Note: this is broken.
</code></pre>

<p>I don't quite understand what time means and why the example above is broken. What does it mean that one cannot rely on the value of a Variable? Is it possible to have an example where the code above works not as expected?</p>
",The tf.Variable documentation contains the following warning: I don't quite understand what time means and why the example above is broken. What does it mean that one cannot rely on the value of a Variable? Is it possible to have an example where the code above works not as expected?,https://stackoverflow.com/questions/54934603,1754568,Requesting (Additional) Resources,Requesting (Additional) Resources,The tf.Variable documentation contains the following warning: I don't quite understand what time means and why the example above is broken. What does it mean that one cannot rely on the value of a Variable? Is it possible to have an example where the code above works not as expected?
57970717,Using pretrained convolutional network as a GAN discriminator,"<p>I've pulled some code from TF2.0 documentation to generate images from a custom dataset. The code is <a href=""https://www.tensorflow.org/beta/tutorials/generative/dcgan"" rel=""nofollow noreferrer"">here</a> </p>

<p>Since the documentation uses Keras i figured i might change the discriminator network to a pretrained network e.g InceptionV3, and only train the top layers. I've found <a href=""https://keras.io/applications/"" rel=""nofollow noreferrer"">this</a> code (Fine-tune InceptionV3 on a new set of classes). I cant seem to figure out how to replace the the one with the other. I understand that im trying to replace Sequential mode with the Functional API. But i guess they are somehow interconnected. However, im not a frequent Keras user.</p>

<p>My questions is: How do i replace a custom CNN in Sequential mode with a pretrained one from the Functional API to use as a discriminator?</p>

<p>EDIT: I would be happy if anyone has examples of doing it with the GANEstimator instead as im more used to TF.</p>

<p><strong>Use the generator to generate a random image</strong></p>

<pre><code>def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 3)

    return model

generator = make_generator_model()
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
</code></pre>

<p><strong>The current discriminator and helpers (Outputs tf.Tensor([[-0.0003378]], shape=(1, 1), dtype=float32))</strong></p>

<pre><code>def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))

    return model

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
</code></pre>

<p><strong>The desired discriminator</strong></p>

<pre><code>def make_discriminator_model():
    # create the base pre-trained model
    model = InceptionV3(weights='imagenet', include_top=False)

    # ADD TOP LAYERS

    # FREEZE ALL LAYERS EXCEPT TOP LAYERS

    return model

# COMPILE

def discriminator_loss(real_output, fake_output):
    real_loss = ??? # Real Loss
    fake_loss = ??? # Fake loss
    total_loss = real_loss + fake_loss
    return total_loss

noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
</code></pre>

<p><strong>All imports</strong></p>

<pre><code>  from __future__ import absolute_import, division, print_function, unicode_literals

try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf
print('TF version: {}'.format(tf.__version__))

import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from PIL import Image
from tensorflow.keras import layers
import time

from IPython import display
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import vgg16
import os.path
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras import backend as K
</code></pre>

<p><strong>EDIT:
This was the discriminator i ended up with! Thanks to @pandrey</strong></p>

<pre><code>def make_discriminator_model():
    pre_trained = tf.keras.applications.InceptionV3(
        weights='imagenet', include_top=False, input_shape=IMG_SHAPE
    )
    pre_trained.trainable = False  # mark all weights as non-trainable
    model = tf.keras.Sequential([pre_trained])
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(1))   
    return model
</code></pre>
","I've pulled some code from TF2.0 documentation to generate images from a custom dataset. The code is here Since the documentation uses Keras i figured i might change the discriminator network to a pretrained network e.g InceptionV3, and only train the top layers. I've found this code (Fine-tune InceptionV3 on a new set of classes). I cant seem to figure out how to replace the the one with the other. I understand that im trying to replace Sequential mode with the Functional API. But i guess they are somehow interconnected. However, im not a frequent Keras user. My questions is: How do i replace a custom CNN in Sequential mode with a pretrained one from the Functional API to use as a discriminator? EDIT: I would be happy if anyone has examples of doing it with the GANEstimator instead as im more used to TF. Use the generator to generate a random image The current discriminator and helpers (Outputs tf.Tensor([[-0.0003378]], shape=(1, 1), dtype=float32)) The desired discriminator All imports EDIT: This was the discriminator i ended up with! Thanks to @pandrey",https://stackoverflow.com/questions/57970717,11825110,Requesting (Additional) Resources,Requesting (Additional) Resources,I would be happy if anyone has examples of doing it with the GANEstimator instead as im more used to TF.
58126494,How to Translate CSV Data into TFRecord Files,"<p>Currently I am working on a system that can take data from a CSV file and import it into a TFRecord file, However I have a few questions.</p>

<p>For starters, I need to know what type a TFRecord file can take, when using CSV types are removed.</p>

<p>Secondly, How can I convert data type:object into a type that a TFRecord can take?</p>

<p>I have two columns (will post example below) of two objects types that are strings, How can I convert that data to the correct type for TFRecords?</p>

<p>When importing Im hoping to append data from each row at a time into the TFRecord file, any advice or documentation would be great, I have been looking for some time at this problem and it seems there can only be ints,floats inputted into a TFRecord but what about a list/array of Integers?</p>

<p>Thankyou for reading!</p>

<p>Quick Note, I am using PANDAS to create a dataframe of the CSV file</p>

<p>Some Example Code Im using </p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
from ast import literal_eval
import numpy as np
import tensorflow as tf


tf.compat.v1.enable_eager_execution()


def Start():
    db = pd.read_csv(""I:\Github\ClubKeno\Keno Project\Database\..\LotteryDatabase.csv"")

    pd.DataFrame = db
    print(db['Winning_Numbers'])
    print(db.dtypes)

    training_dataset = (
        tf.data.Dataset.from_tensor_slices(
            (
                tf.cast(db['Draw_Number'].values, tf.int64),
                tf.cast(db['Winning_Numbers'].values, tf.int64),
                tf.cast(db['Extra_Numbers'].values, tf.int64),
                tf.cast(db['Kicker'].values, tf.int64)
            )
        )
    )

    for features_tensor, target_tensor in training_dataset:
        print(f'features:{features_tensor} target:{target_tensor}')
</code></pre>

<p>Error Message:</p>

<p><img src=""https://cdn.discordapp.com/attachments/279786369902051328/626967249395122213/Capture.PNG"" alt=""Error Message""></p>

<p><a href=""https://cdn.discordapp.com/attachments/502661247809093673/626946732239880194/LotteryDatabase.csv"" rel=""nofollow noreferrer"">CSV Data</a></p>

<p>Update:
Got Two Columns of dating working using the following function...</p>

<pre class=""lang-py prettyprint-override""><code>dataset = tf.data.experimental.make_csv_dataset(
        file_pattern=databasefile,
        column_names=['Draw_Number', 'Kicker'],
        column_defaults=[tf.int64, tf.int64],
    )
</code></pre>

<p>However when trying to include my two other column object types
(What data looks like in both those columns)
<code>""3,9,11,16,25,26,28,29,36,40,41,46,63,66,67,69,72,73,78,80""</code></p>

<p>I get an error, here is the function I tried for that</p>

<pre class=""lang-py prettyprint-override""><code>    dataset = tf.data.experimental.make_csv_dataset(
        file_pattern=databasefile,
        column_names=['Draw_Number', 'Winning_Numbers', 'Extra_Numbers', 'Kicker'],
        column_defaults=[tf.int64, tf.compat.as_bytes, tf.compat.as_bytes, tf.int64],
        header=True,
        batch_size=100,
        field_delim=',',
        na_value='NA'
    )
</code></pre>

<p>This Error Appears:</p>

<pre><code>TypeError: Failed to convert object of type &lt;class 'function'&gt; to Tensor. Contents: &lt;function as_bytes at 0x000000EA530908C8&gt;. Consider casting elements to a supported type.
</code></pre>

<p>Should I try to Cast those two types outside the function and try combining it later into the TFRecord file alongside the tf.data from the <code>make_csv_dataset</code> function? </p>
","Currently I am working on a system that can take data from a CSV file and import it into a TFRecord file, However I have a few questions. For starters, I need to know what type a TFRecord file can take, when using CSV types are removed. Secondly, How can I convert data type:object into a type that a TFRecord can take? I have two columns (will post example below) of two objects types that are strings, How can I convert that data to the correct type for TFRecords? When importing Im hoping to append data from each row at a time into the TFRecord file, any advice or documentation would be great, I have been looking for some time at this problem and it seems there can only be ints,floats inputted into a TFRecord but what about a list/array of Integers? Thankyou for reading! Quick Note, I am using PANDAS to create a dataframe of the CSV file Some Example Code Im using Error Message: CSV Data Update: Got Two Columns of dating working using the following function... However when trying to include my two other column object types (What data looks like in both those columns) ""3,9,11,16,25,26,28,29,36,40,41,46,63,66,67,69,72,73,78,80"" I get an error, here is the function I tried for that This Error Appears: Should I try to Cast those two types outside the function and try combining it later into the TFRecord file alongside the tf.data from the make_csv_dataset function?",https://stackoverflow.com/questions/58126494,9873122,Requesting (Additional) Resources,Requesting (Additional) Resources,"When importing Im hoping to append data from each row at a time into the TFRecord file, any advice or documentation would be great, I have been looking for some time at this problem and it seems there can only be ints,floats inputted into a TFRecord but what about a list/array of Integers?"
60143153,Is there a way in tensorflow to load batches of data each time?,"<p>So I'm running tensorflow 2+ python in google colab.</p>

<p>Each of my data file is a 3d image with shape [563, 563, 563, 1], so loading all of them throws a resource exhaustion error.</p>

<p>I've spent days and hours searching for a way to load only a batch of my dataset as tensor and unloading/loading new batch each iteration. I'm guessing there might be a way using tf.data.Dataset.list_files, but I can't find the exact way.</p>

<p>Is there any good suggestions on a way to do it or any documents I could try to read? I've read the tf.data document from tensorflow, but couldn't find the information I needed.</p>

<p>Thank you!</p>

<h1>Edit</h1>

<p>so this is the function I want to use to load my image</p>

<pre><code>def load_image(ind):
    file_brain = ""/content/drive/My Drive/brain/"" + str(ind) + "".mgz""
    file_mask = ""/content/drive/My Drive/mask/"" + str(ind) + "".mgz""
    data_brain, affine = load_nifti(file_brain)
    data_mask, affine = load_nifti(file_mask)
    data_brain = affine_transform(data_brain, affine)
    data_mask = affine_transform(data_mask, affine)
    data_brain = normalize(data_brain)
    data_brain = zoom(data_brain, (563/256, 563/256, 563/256))
    data_brain = tf.expand_dims(data_brain, axis=-1)
    data_mask = tf.expand_dims(data_mask, axis=-1)
    return data_brain, data_mask
</code></pre>

<p>and this was the way I was loading the dataset before, which exhausted the resource;</p>

<pre><code>def create_dataset():
    train_data = []
    train_label = []
    test_data = []
    test_label = []
    test_n = np.random.randint(1, 10, 1)
    for i in range(1, 10):
        data_brain, data_mask = load_image(i)
        if i in test_n:
            test_data.append(data_brain)
            test_label.append(data_mask)
            continue
        train_data.append(data_brain)
        train_label.append(data_mask)
        shifted_data = data_brain + tf.random.uniform(shape=(), minval=-0.05, maxval=0.05)
        scaled_data = data_brain * tf.random.uniform(shape=(), minval=0.85, maxval=1.3)
        train_data.append(shifted_data)
        train_label.append(data_mask)
        train_data.append(scaled_data)
        train_label.append(data_mask)
""""""
train_data = tf.data.Dataset.from_tensor_slices(train_data)
train_label = tf.data.Dataset.from_tensor_slices(train_label)
test_data = tf.data.Dataset.from_tensor_slices(test_data)
test_label = tf.data.Dataset.from_tensor_slices(test_label)
return train_data, train_label, test_data, test_label
""""""
</code></pre>
","So I'm running tensorflow 2+ python in google colab. Each of my data file is a 3d image with shape [563, 563, 563, 1], so loading all of them throws a resource exhaustion error. I've spent days and hours searching for a way to load only a batch of my dataset as tensor and unloading/loading new batch each iteration. I'm guessing there might be a way using tf.data.Dataset.list_files, but I can't find the exact way. Is there any good suggestions on a way to do it or any documents I could try to read? I've read the tf.data document from tensorflow, but couldn't find the information I needed. Thank you! so this is the function I want to use to load my image and this was the way I was loading the dataset before, which exhausted the resource;",https://stackoverflow.com/questions/60143153,12869645,Requesting (Additional) Resources,Requesting (Additional) Resources,"I've spent days and hours searching for a way to load only a batch of my dataset as tensor and unloading/loading new batch each iteration. I'm guessing there might be a way using tf.data.Dataset.list_files, but I can't find the exact way. Is there any good suggestions on a way to do it or any documents I could try to read? I've read the tf.data document from tensorflow, but couldn't find the information I needed."
61885570,Reading a tfrecord: DecodeError: Error parsing message,"<p>I am using colab to run a <a href=""https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/handling_sparse_features.ipynb"" rel=""nofollow noreferrer"">tutorial</a> on tensorflow ranking. It uses wget to fetch the tfrecord:</p>

<pre><code>!wget -O ""/tmp/train.tfrecords"" ""http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/ELWC/train.tfrecords""
</code></pre>

<p>I am using this code to try to look at the structure of the tfrecord:</p>

<pre><code>for example in tf.compat.v1.python_io.tf_record_iterator(""/tmp/train.tfrecords""):
    print(tf.train.Example.FromString(example))
    break
</code></pre>

<p>And I am getting:</p>

<pre><code>DecodeError: Error parsing message
</code></pre>

<p>How to generally look at the structure of tfrecords instead?</p>

<p>A second question: Where to find documentation on classes like <code>tf.train.Example</code>? I just find this <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Example"" rel=""nofollow noreferrer"">empty page</a>.</p>
",I am using colab to run a tutorial on tensorflow ranking. It uses wget to fetch the tfrecord: I am using this code to try to look at the structure of the tfrecord: And I am getting: How to generally look at the structure of tfrecords instead? A second question: Where to find documentation on classes like tf.train.Example? I just find this empty page.,https://stackoverflow.com/questions/61885570,8183621,Requesting (Additional) Resources,Requesting (Additional) Resources,Where to find documentation on classes like tf.train.Example? I just find this empty page.
63020800,"Understanding Tensorflow Object-Detection API, kwargs for Checkpoint class, what is `_base_tower_layers_for_heads`?","<p>Currently, I've been learning how to use Object-Detection API from Tensorflow. I follow a quick start tutorial for training with custom data with <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb"" rel=""nofollow noreferrer"">this notebook</a> as suggested by them. In the effort to understanding each line of the code, I stumbled upon this snippet code in the &quot;Create Model and Restore Weight&quot; part.</p>
<pre><code>fake_box_predictor = tf.compat.v2.train.Checkpoint(
    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,
    # _prediction_heads=detection_model._box_predictor._prediction_heads,
    #    (i.e., the classification head that we *will not* restore)
    _box_prediction_head=detection_model._box_predictor._box_prediction_head,
    )
</code></pre>
<p>I don't really understand what are the keyword arguments that are available for the <code>Checkpoint</code> class in that particular snippet code. My question is; is there any documentation out there that shows the list of the keyword arguments? or at least explain what are <code>_base_tower_layers_for_heads</code> and<code>_box_prediction_head</code>?</p>
<p>I've read the <code>tf.train.Checkpoint</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"" rel=""nofollow noreferrer"">documentation</a>. It says that we can provide <code>models</code> or <code>optimizers</code> for the constructor's keyword argument. I am already familiar with this class to restore the weights to my model, however, I find it is alien to see <code>_base_tower_layers_for_heads</code> or <code>_box_prediction_head</code> for the keyword argument.</p>
<p>I do know about 'heads' and different types of 'heads' in the object detection architecture and their relation to transfer learning, what I don't understand is in the context of their data structure. How do I know, these keyword arguments exist? and is there any other else? I would really appreciate it if somebody could give me insights or at least tell me where can I find documentation that I can read to understand it more.</p>
","Currently, I've been learning how to use Object-Detection API from Tensorflow. I follow a quick start tutorial for training with custom data with this notebook as suggested by them. In the effort to understanding each line of the code, I stumbled upon this snippet code in the ""Create Model and Restore Weight"" part. I don't really understand what are the keyword arguments that are available for the Checkpoint class in that particular snippet code. My question is; is there any documentation out there that shows the list of the keyword arguments? or at least explain what are _base_tower_layers_for_heads and_box_prediction_head? I've read the tf.train.Checkpoint documentation. It says that we can provide models or optimizers for the constructor's keyword argument. I am already familiar with this class to restore the weights to my model, however, I find it is alien to see _base_tower_layers_for_heads or _box_prediction_head for the keyword argument. I do know about 'heads' and different types of 'heads' in the object detection architecture and their relation to transfer learning, what I don't understand is in the context of their data structure. How do I know, these keyword arguments exist? and is there any other else? I would really appreciate it if somebody could give me insights or at least tell me where can I find documentation that I can read to understand it more.",https://stackoverflow.com/questions/63020800,8410038,Requesting (Additional) Resources,Requesting (Additional) Resources,I would really appreciate it if somebody could give me insights or at least tell me where can I find documentation that I can read to understand it more.
76380927,Tensorflow decode image,"<p>I am a beginner in tensorflow and I am training a small cnn, I am using the tf.io.decode_image function but I can't figure out if this function does preprocess.
The tensorflow documentation about it doesn't say anything.
When I open images with this function the values are between 0 and 1.
The images are single channel grayscale.
This is the code.</p>
<pre><code>def decode_img(self, imgs, channels):
        # Convert the compressed string to a 3D uint8 tensor
        images = []
        for element in imgs:

            dec_image = tf.io.decode_image(element, channels=channels, dtype=tf.float32)
            try:
                img = keras.utils.img_to_array(dec_image)
            except AttributeError:
                img = keras.preprocessing.image.img_to_array(dec_image)
            images.append(img)
        images = np.array(images)
        return images
</code></pre>
<p>I would like to have more explanations</p>
","I am a beginner in tensorflow and I am training a small cnn, I am using the tf.io.decode_image function but I can't figure out if this function does preprocess. The tensorflow documentation about it doesn't say anything. When I open images with this function the values are between 0 and 1. The images are single channel grayscale. This is the code. I would like to have more explanations",https://stackoverflow.com/questions/76380927,15460221,Requesting (Additional) Resources,Requesting (Additional) Resources,The tensorflow documentation about it doesn't say anything. When I open images with this function the values are between 0 and 1. The images are single channel grayscale. This is the code. I would like to have more explanations
76244268,Tensorflow: Build new model from input and middle layers of another model,"<p>I'm trying to build <code>new_model</code> from another model layers for class activation mapping purposes.</p>
<pre class=""lang-py prettyprint-override""><code>def vgg_sequential():
    input_shape = IMG_SIZE + (3,)
    model = Sequential()
    model.add(tf.keras.applications.vgg16.VGG16(input_shape=input_shape, include_top=False, weights='imagenet'))
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dense(1))
    return model
</code></pre>
<pre class=""lang-py prettyprint-override""><code>cam_model = tf.keras.Model(inputs=seq_vgg.layers[0].input, outputs=(seq_vgg.layers[-3].output, seq_vgg.layers[-1].output))
</code></pre>
<p>And with this code i get the following error:</p>
<pre><code>ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 480, 480, 3), dtype=tf.float32, name='vgg16_input'), name='vgg16_input', description=&quot;created by layer 'vgg16_input'&quot;) at layer &quot;vgg16&quot;. The following previous layers were accessed without issue: ['block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1']
</code></pre>
<p>Already tried functional model API, providing <code>Input()</code> layer inside <code>vgg_sequential()</code> with the same error that my Input layer is disconected from the rest of my model. Beside this when using <code>tf.keras.applications.efficientnet_v2</code> that provides input layers for rescaling and resizing images i don't have any problem.</p>
<p>Any help, information, tips or links to docs that getas me to a solution will be very much appreciated.</p>
<p>Thanks in advance.</p>
","I'm trying to build new_model from another model layers for class activation mapping purposes. And with this code i get the following error: Already tried functional model API, providing Input() layer inside vgg_sequential() with the same error that my Input layer is disconected from the rest of my model. Beside this when using tf.keras.applications.efficientnet_v2 that provides input layers for rescaling and resizing images i don't have any problem. Any help, information, tips or links to docs that getas me to a solution will be very much appreciated. Thanks in advance.",https://stackoverflow.com/questions/76244268,2103321,Inadequate Examples,Requesting (Additional) Resources,"Any help, information, tips or links to docs that getas me to a solution will be very much appreciated."
76447508,How to retrain a model that was saved using the tf.saved_model.save() function in Tensorflow,"<p>I am building a Neural Machine Translator for English to Konkani (a local language) language using the Transformer architecture proposed by (Vaswani et, al. 2017). I am following the tutorial code from <a href=""https://www.tensorflow.org/text/tutorials/transformer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/text/tutorials/transformer</a>. I have trained the model and used the <code>tf.saved_model.save()</code> method to save the model files locally.</p>
<p>I now want to retrain that saved model on a new dataset that I have gathered recently, but I've realised that after loading the model using the <code>tf.saved_model.load()</code> method, I am not able to train it again as the loaded model now lacks the necessary method <code>model.fit()</code> .</p>
<p>Here is a part of the model training code:</p>
<pre class=""lang-py prettyprint-override""><code>class Transformer(tf.keras.Model):
  def __init__(self, *, num_layers, d_model, num_heads, dff,
               input_vocab_size, target_vocab_size, dropout_rate=0.1):
    super().__init__()
    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=input_vocab_size,
                           dropout_rate=dropout_rate)

    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,
                           num_heads=num_heads, dff=dff,
                           vocab_size=target_vocab_size,
                           dropout_rate=dropout_rate)

    self.final_layer = tf.keras.layers.Dense(target_vocab_size)

  def call(self, inputs):
    # To use a Keras model with `.fit` you must pass all your inputs in the
    # first argument.
    context, x  = inputs

    context = self.encoder(context)  # (batch_size, context_len, d_model)

    x = self.decoder(x, context)  # (batch_size, target_len, d_model)

    # Final linear layer output.
    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)

    try:
      # Drop the keras mask, so it doesn't scale the losses/metrics.
      # b/250038731
      del logits._keras_mask
    except AttributeError:
      pass

    # Return the final output and the attention weights.
    return logits
#-----------------------------------------------------------------------

#...&lt;code to define optimizers and loss functions&gt;...

# This Class acts as an interface for the Transformer
class Translator(tf.Module):
  def __init__(self, context_tokenizers, target_tokenizers, transformer):
    self.context_tokenizers = context_tokenizers
    self.target_tokenizers = target_tokenizers
    self.transformer = transformer

  def __call__(self, sentence, max_length=MAX_TOKENS): #max_length=MAX_TOKENS
    assert isinstance(sentence, tf.Tensor)
    if len(sentence.shape) == 0:
      sentence = sentence[tf.newaxis]

    sentence = tokenize(sentence,self.context_tokenizers).to_tensor()

    encoder_input = sentence

    # As the output language is English, initialize the output with the
    # English `[START]` token.

    start_end = tokenize('',self.target_tokenizers)[0]
    start = start_end[0][tf.newaxis]
    end = start_end[-1][tf.newaxis]

    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)
    output_array = output_array.write(0, start)

    for i in tf.range(max_length):
      output = tf.transpose(output_array.stack())
      predictions = self.transformer([encoder_input, output], training=False)

      # Select the last token from the `seq_len` dimension.
      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.

      predicted_id = tf.argmax(predictions, axis=-1)

      # Concatenate the `predicted_id` to the output which is given to the
      # decoder as its input.
      output_array = output_array.write(i+1, predicted_id[0])

      if predicted_id == end:
        break

    output = tf.transpose(output_array.stack())
    # The output shape is `(1, tokens)`.

    text = self.target_tokenizers.detokenize(output)

    tokens = tf.gather(target_vocab, output)

    # `tf.function` prevents us from using the attention_weights that were
    # calculated on the last iteration of the loop.
    # So, recalculate them outside the loop.
    self.transformer([encoder_input, output[:,:-1]], training=False)
    attention_weights = self.transformer.decoder.last_attn_scores

    joined_text = tf.strings.reduce_join(text[0][1:-1], separator=' ', axis=-1)
    return joined_text, tokens, attention_weights
#-----------------------------------------------------------------------

class ExportTranslator(tf.Module):
  def __init__(self, translator):
    self.translator = translator

  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
  def __call__(self, sentence):
    (result,
     tokens,
     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)

    return result
#-----------------------------------------------------------------------

transformer = Transformer(
    num_layers=num_layers,
    d_model=d_model,
    num_heads=num_heads,
    dff=dff,
    input_vocab_size=context_vocab_size,
    target_vocab_size=target_vocab_size,
    dropout_rate=dropout_rate)

transformer.compile(
    loss=masked_loss,
    optimizer=optimizer,
    metrics=[masked_accuracy])

# training the model on the training data for some epochs
transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )

translator = Translator(context_tokenizer, target_tokenizer, transformer)

exp_translator = ExportTranslator(translator)

#saving the model
tf.saved_model.save(exp_translator, export_dir=MODEL_SAVED_FILES)

#-----------------------------------------------------------------------

#loading a saved model
reloaded = tf.saved_model.load(MODEL_SAVED_FILES)
</code></pre>
<p>Here's the error I get when I try to retrain the model using the following code:</p>
<pre class=""lang-py prettyprint-override""><code>reloaded = tf.saved_model.load(MODEL_SAVED_FILES)

#retraing the model on new dataset
reloaded.translator.transformer.fit(train_batches,
                epochs=20,
                validation_data=val_batches,
                callbacks=[
                  tf.keras.callbacks.EarlyStopping(patience=3)],
                )
</code></pre>
<p>The error:</p>
<pre class=""lang-py prettyprint-override""><code>
---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

&lt;ipython-input-41-ad1b625ff6c0&gt; in &lt;cell line: 2&gt;()
      1 #retraing the model on new dataset
----&gt; 2 reloaded.translator.transformer.fit(train_batches,
      3                 epochs=20,
      4                 validation_data=val_batches,
      5                 callbacks=[

AttributeError: '_UserObject' object has no attribute 'fit'
</code></pre>
<p>After reading the documentation I've realised that when saving the model in the above method, the <code>model.fit()</code> and other methods are not saved hence they are not callable.</p>
<p>I need help in finding a way to retrain my saved model, It is not feasible for me to train a new model on a combined dataset as It will take up lot of time and I have very limited resources. I have been looking up on the web for days but couldn't find a solution. Any help in this regards will be appreciated!</p>
","I am building a Neural Machine Translator for English to Konkani (a local language) language using the Transformer architecture proposed by (Vaswani et, al. 2017). I am following the tutorial code from https://www.tensorflow.org/text/tutorials/transformer. I have trained the model and used the tf.saved_model.save() method to save the model files locally. I now want to retrain that saved model on a new dataset that I have gathered recently, but I've realised that after loading the model using the tf.saved_model.load() method, I am not able to train it again as the loaded model now lacks the necessary method model.fit() . Here is a part of the model training code: Here's the error I get when I try to retrain the model using the following code: The error: After reading the documentation I've realised that when saving the model in the above method, the model.fit() and other methods are not saved hence they are not callable. I need help in finding a way to retrain my saved model, It is not feasible for me to train a new model on a combined dataset as It will take up lot of time and I have very limited resources. I have been looking up on the web for days but couldn't find a solution. Any help in this regards will be appreciated!",https://stackoverflow.com/questions/76447508,16851318,Inadequate Examples,Requesting (Additional) Resources,"After reading the documentation I've realised that when saving the model in the above method, the model.fit() and other methods are not saved hence they are not callable. I need help in finding a way to retrain my saved model, It is not feasible for me to train a new model on a combined dataset as It will take up lot of time and I have very limited resources. I have been looking up on the web for days but couldn't find a solution."
38111170,How is the input tensor for TensorFlow's tf.nn.dynamic_rnn operator structured?,"<p>I am trying to write a language model using word embeddings and recursive neural networks in TensorFlow 0.9.0 using the <code>tf.nn.dynamic_rnn</code> graph operation, but I don't understand how the <code>input</code> tensor is structured.</p>

<p>Let's say I have a corpus of <em>n</em> words. I embed each word in a vector of length <em>e</em>, and I want my RNN to unroll to <em>t</em> time steps. Assuming I use the default <code>time_major = False</code> parameter, what shape would my <code>input</code> tensor <code>[batch_size, max_time, input_size]</code> have?</p>

<p>Maybe a specific tiny example will make this question clearer. Say I have a corpus consisting of <em>n=8</em> words that looks like this.</p>

<pre><code>1, 2, 3, 3, 2, 1, 1, 2
</code></pre>

<p>Say I embed it in a vector of size <em>e=3</em> with the embeddings 1 -> [10, 10, 10], 2 -> [20, 20, 20], and 3 -> [30, 30, 30], what would my <code>input</code> tensor look like?</p>

<p>I've read the <a href=""https://www.tensorflow.org/versions/r0.9/tutorials/recurrent/index.html#recurrent-neural-networks"" rel=""nofollow"">TensorFlow Recurrent Neural Network tutorial</a>, but that doesn't use <code>tf.nn.dynamic_rnn</code>. I've also read the documentation for <code>tf.nn.dynamic_rnn</code>, but find it confusing. In particular I'm not sure what ""max_time"" and ""input_size"" mean here.</p>

<p>Can anyone give the shape of the <code>input</code> tensor in terms of <em>n</em>, <em>t</em>, and <em>e</em>, and/or an example of what that tensor would look like initialized with data from the small corpus I describe?</p>

<p><em>TensorFlow 0.9.0, Python 3.5.1, OS X 10.11.5</em></p>
","I am trying to write a language model using word embeddings and recursive neural networks in TensorFlow 0.9.0 using the tf.nn.dynamic_rnn graph operation, but I don't understand how the input tensor is structured. Let's say I have a corpus of n words. I embed each word in a vector of length e, and I want my RNN to unroll to t time steps. Assuming I use the default time_major = False parameter, what shape would my input tensor [batch_size, max_time, input_size] have? Maybe a specific tiny example will make this question clearer. Say I have a corpus consisting of n=8 words that looks like this. Say I embed it in a vector of size e=3 with the embeddings 1 -&gt; [10, 10, 10], 2 -&gt; [20, 20, 20], and 3 -&gt; [30, 30, 30], what would my input tensor look like? I've read the TensorFlow Recurrent Neural Network tutorial, but that doesn't use tf.nn.dynamic_rnn. I've also read the documentation for tf.nn.dynamic_rnn, but find it confusing. In particular I'm not sure what ""max_time"" and ""input_size"" mean here. Can anyone give the shape of the input tensor in terms of n, t, and e, and/or an example of what that tensor would look like initialized with data from the small corpus I describe? TensorFlow 0.9.0, Python 3.5.1, OS X 10.11.5",https://stackoverflow.com/questions/38111170,1120370,Documentation Replicability,Requesting (Additional) Resources,"Can anyone give the shape of the input tensor in terms of n, t, and e, and/or an example of what that tensor would look like initialized with data from the small corpus I describe? "
71315426,Using TFDS datasets with Keras Functional API,"<p>I'm trying to train a neural network made with the Keras Functional API with one of the default TFDS Datasets, but I keep getting dataset related errors.</p>
<p>The idea is doing a model for object detection, but for the first draft I was trying to do just plain image classification (img, label). The input would be (256x256x3) images. The input layer is as follows:</p>
<pre><code>img_inputs = keras.Input(shape=[256, 256, 3], name='image')
</code></pre>
<p>Then I'm trying to use the voc2007 dataset as available in TFDS (a very old and light version to make it faster)</p>
<pre><code>(train_ds, test_ds), ds_info = tfds.load(
'voc/2007',
split=['train', 'test'],
data_dir=&quot;/content/drive/My Drive&quot;,
with_info=True)
</code></pre>
<p>then preprocessing the data as follows:</p>
<pre><code>def resize_and_normalize_img(example):
  &quot;&quot;&quot;Normalizes images: `uint8` -&gt; `float32`.&quot;&quot;&quot;
  example['image'] = tf.image.resize(example['image'], [256, 256])
  example['image'] = tf.cast(example['image'], tf.float32) / 255.
  return example

def reduce_for_classification(example):
        for key in ['image/filename', 'labels_no_difficult', 'objects']:
            example.pop(key)
        return example

train_ds_class = train_ds.map(reduce_for_classification, num_parallel_calls=tf.data.AUTOTUNE)
train_ds_class = train_ds_class.map(resize_and_normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
train_ds_class = train_ds_class.cache()
train_ds_class = train_ds_class.shuffle(ds_info.splits['train'].num_examples)
train_ds_class = train_ds_class.batch(64)
train_ds_class = train_ds_class.prefetch(tf.data.AUTOTUNE)

test_ds_class = test_ds.map(reduce_for_classification, num_parallel_calls=tf.data.AUTOTUNE)
test_ds_class = test_ds_class.map(resize_and_normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
test_ds_class = test_ds_class.batch(64)
test_ds_class = test_ds_class.cache()
test_ds_class = test_ds_class.prefetch(tf.data.AUTOTUNE)
</code></pre>
<p>And then fitting the model like:</p>
<pre><code>epochs=8
history = model.fit(
  x=train_x, y =trian_y,
  validation_data=test_ds_clas,
  epochs=epochs
)
</code></pre>
<p>And after doing this is when I get an error saying that my model expects an input of shape [None, 256, 256, 3] but it's getting an input of shape [256, 256, 3].</p>
<p>I think it's an issue to do with the label. Before I got problems with the extra keys from the dictionary-like format of the data you get from tfds and tried to remove everything except the label, but now I'm still getting this and don't know how to go forward. I feel like after getting the dataset prepared with tfds it should be ready to be fed to a model, and after looking through the documentation, tutorials and stack overflow I haven't found the answer, I hope someone who comes across this can help.</p>
<p><strong>Update:</strong>
To give a bit more of information, this is the model I'm using:</p>
<p><strong>TLDR:</strong> Image input 256x256x3, a succession of convolutions and residual blocks, and an ending with average pooling, fully connected layer, and softmax that results in a (None, 1280) tensor. Using sparse categorical cross-entropy as loss and accuracy as metric.</p>
<pre><code>img_inputs = keras.Input(shape=[256, 256, 3], name='image')

# first convolution
conv_first = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', name='first_conv')
x = conv_first(img_inputs)

# Second convolution
x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=2, padding='same', name='second_conv')(x)

# First residual block
res = tf.keras.layers.Conv2D(32, kernel_size=(1, 1), name='res_block1_conv1')(x)
res = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same', name='res_block1_conv2')(res)
x = x + res

# Convolution after First residual block
x = tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same', name='first_post_res_conv')(x)

# Second residual Block
for i in range(2):
  shortcut = x
  res = tf.keras.layers.Conv2D(64, kernel_size=1, name=f'res_block2_conv1_loop{i}')(x)
  res = tf.keras.layers.Conv2D(128, kernel_size=3, padding='same', name=f'res_block2_conv2_loop{i}')(res)

  x = res + shortcut

# Convolution after Second residual block
x = tf.keras.layers.Conv2D(256, 3, strides=2, padding='same', name='second_post_res_conv')(x)

# Third residual Block
for i in range(8):
  shortcut = x
  res = tf.keras.layers.Conv2D(128, kernel_size=1, name=f'res_block3_conv1_loop{i}')(x)
  res = tf.keras.layers.Conv2D(256, kernel_size=3, padding='same', name=f'res_block3_conv2_loop{i}')(res)

  x = res + shortcut

# Convolution after Third residual block
x = tf.keras.layers.Conv2D(512, 3, strides=2, padding='same', name='third_post_res_conv')(x)

# Fourth residual Block
for i in range(8):
  shortcut = x
  res = tf.keras.layers.Conv2D(256, kernel_size=1, name=f'res_block4_conv1_loop{i}')(x)
  res = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', name=f'res_block4_conv2_loop{i}')(res)

  x = res + shortcut

# Convolution after Fourth residual block
x = tf.keras.layers.Conv2D(1024, 3, strides=2, padding='same', name='fourth_post_res_conv')(x)

# Fifth residual Block
for i in range(4):
  shortcut = x
  res = tf.keras.layers.Conv2D(512, kernel_size=1, name=f'res_block5_conv1_loop{i}')(x)
  res = tf.keras.layers.Conv2D(1024, kernel_size=3, padding='same', name=f'res_block5_conv2_loop{i}')(res)

  x = res + shortcut

# Global avg pooling
x = tf.keras.layers.GlobalAveragePooling2D(name='average_pooling')(x)

# Fully connected layer
x = tf.keras.layers.Dense(1280, name='fully_connected_layer')(x)

# Softmax
end_result = tf.keras.layers.Softmax(name='softmax')(x)

model = tf.keras.Model(inputs=img_inputs, outputs=end_result, name=&quot;darknet53&quot;)

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

</code></pre>
<p>After trying the solution proposed by AloneTogether I'm getting the following errors (I tried changing the axis in the tf.one_hot() function many times and same result):</p>
<pre><code>Node: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'
logits and labels must have the same first dimension, got logits shape [64,1280] and labels shape [1280]
     [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_20172]

</code></pre>
<p>Which seems to be related to the batching, but don't know exactly how to fix it.</p>
<p>The whole issue really seems related to the labels encoding, because when running that line without the tf.reduce_sum() function I get the same but with:</p>
<pre><code>First element had shape [2,20] and element 1 had shape [1,20].
</code></pre>
<p>And if I run the same without the one-hot encoding line, I get this error:</p>
<p>´´´
Node: 'IteratorGetNext'
Cannot batch tensors with different shapes in component 1. First element had shape [4] and element 1 had shape [1].
[[{{node IteratorGetNext}}]] [Op:__inference_train_function_18534]
´´´</p>
","I'm trying to train a neural network made with the Keras Functional API with one of the default TFDS Datasets, but I keep getting dataset related errors. The idea is doing a model for object detection, but for the first draft I was trying to do just plain image classification (img, label). The input would be (256x256x3) images. The input layer is as follows: Then I'm trying to use the voc2007 dataset as available in TFDS (a very old and light version to make it faster) then preprocessing the data as follows: And then fitting the model like: And after doing this is when I get an error saying that my model expects an input of shape [None, 256, 256, 3] but it's getting an input of shape [256, 256, 3]. I think it's an issue to do with the label. Before I got problems with the extra keys from the dictionary-like format of the data you get from tfds and tried to remove everything except the label, but now I'm still getting this and don't know how to go forward. I feel like after getting the dataset prepared with tfds it should be ready to be fed to a model, and after looking through the documentation, tutorials and stack overflow I haven't found the answer, I hope someone who comes across this can help. Update: To give a bit more of information, this is the model I'm using: TLDR: Image input 256x256x3, a succession of convolutions and residual blocks, and an ending with average pooling, fully connected layer, and softmax that results in a (None, 1280) tensor. Using sparse categorical cross-entropy as loss and accuracy as metric. After trying the solution proposed by AloneTogether I'm getting the following errors (I tried changing the axis in the tf.one_hot() function many times and same result): Which seems to be related to the batching, but don't know exactly how to fix it. The whole issue really seems related to the labels encoding, because when running that line without the tf.reduce_sum() function I get the same but with: And if I run the same without the one-hot encoding line, I get this error: ´´´ Node: 'IteratorGetNext' Cannot batch tensors with different shapes in component 1. First element had shape [4] and element 1 had shape [1]. [[{{node IteratorGetNext}}]] [Op:__inference_train_function_18534] ´´´",https://stackoverflow.com/questions/71315426,15934211,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I feel like after getting the dataset prepared with tfds it should be ready to be fed to a model, and after looking through the documentation, tutorials and stack overflow I haven't found the answer, I hope someone who comes across this can help."
43736089,How to use tf.contrib.seq2seq.BahdanauAttention,"<p>I am trying to produce a simple code for a seq2seq model with attention in tf 1.1. I am not sure what is the parameter ""depth of query mechanism "". I am getting an error on creation of Attention Mechanisms saying that: </p>

<pre class=""lang-html prettyprint-override""><code>TypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'
</code></pre>



<p>Here is my code. Am I on a right track? I could not find any detailed documentation.</p>



<pre class=""lang-html prettyprint-override""><code>import tensorflow as tf
from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, BasicLSTMCell, DropoutWrapper, MultiRNNCell, EmbeddingWrapper, static_rnn 
import tensorflow.contrib.seq2seq as seq2seq
import attention_wrapper as wrapper


tf.reset_default_graph()
try:
    sess.close()
except:

    pass
sess = tf.InteractiveSession()


## Place holders

encode_input = [tf.placeholder(tf.int32, 
                                shape=(None,),
                                name = ""ei_%i"" %i)
                                for i in range(input_seq_length)]

labels = [tf.placeholder(tf.int32,
                                shape=(None,),
                                name = ""l_%i"" %i)
                                for i in range(output_seq_length)]

decode_input = [tf.zeros_like(encode_input[0], dtype=np.int32, name=""GO"")] + labels[:-1]



############ Encoder
lstm_cell = BasicLSTMCell(embedding_dim)
encoder_cell = EmbeddingWrapper(lstm_cell, embedding_classes=input_vocab_size, embedding_size=embedding_dim)
encoder_outputs, encoder_state = static_rnn(encoder_cell, encode_input, dtype=tf.float32) 

############ Decoder
# Attention Mechanisms. Bahdanau is additive style attention
attn_mech = tf.contrib.seq2seq.BahdanauAttention(
    num_units = input_seq_length, # depth of query mechanism
    memory = encoder_outputs, # hidden states to attend (output of RNN)
    normalize=False, # normalize energy term
    name='BahdanauAttention')

lstm_cell_decoder = BasicLSTMCell(embedding_dim)

# Attention Wrapper: adds the attention mechanism to the cell
attn_cell = wrapper.AttentionWrapper(
    cell = lstm_cell_decoder,# Instance of RNNCell
    attention_mechanism = attn_mech, # Instance of AttentionMechanism
    attention_size = embedding_dim, # Int, depth of attention (output) tensor
    attention_history=False, # whether to store history in final output
    name=""attention_wrapper"")


# Decoder setup
decoder = tf.contrib.seq2seq.BasicDecoder(
          cell = lstm_cell_decoder,
          helper = helper, # A Helper instance
          initial_state = encoder_state, # initial state of decoder
          output_layer = None) # instance of tf.layers.Layer, like Dense

# Perform dynamic decoding with decoder object
outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)
</code></pre>


","I am trying to produce a simple code for a seq2seq model with attention in tf 1.1. I am not sure what is the parameter ""depth of query mechanism "". I am getting an error on creation of Attention Mechanisms saying that: Here is my code. Am I on a right track? I could not find any detailed documentation.",https://stackoverflow.com/questions/43736089,5579493,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I could not find any detailed documentation.
76103475,tensorflow dataset builder that runs download_and_prepare with multiprocessing,"<p>The TensorFlow Datasets <a href=""https://www.tensorflow.org/datasets/add_dataset"" rel=""nofollow noreferrer"">guide</a> on creating a dataset suggests subclassing the tfds.core.DatasetBuilder. Below is my subclass; it reads NetCDF files and extracts the relevant variables as examples.</p>
<p>How can I improve performance with parallel processing? When executing the <code>download_and_prepare</code> pethod, I'm only ever at 100% CPU and can't find any documentation on using multiple threads or cores. The fact that the class utilizes iteration in Python over a generator makes me afraid it's not possible. Is there an alternative approach?</p>
<pre><code>import tensorflow as tf
import tensorflow_datasets as tfds
import xarray as xr


class Builder(tfds.core.GeneratorBasedBuilder):

    VERSION = tfds.core.Version('0.1.0')

    def _info(self):
        keys = {'image': image_shape, 'label': label_shape}
        return self.dataset_info_from_configs(
            features=tfds.features.FeaturesDict({
                k: tfds.features.Tensor(shape=(v,), dtype=np.float32)
                for k, v in keys.items()
            }),
            supervised_keys=tuple(keys),
        )

    def _split_generators(self, *args):
        return {
            'train': self._generate_examples(path=DATA_DIR)
        }

    def _generate_examples(self, path):
        for item in path.iterdir():
            dataset = self.load_tensors(item)
            for j, jtem in enumerate(dataset.as_numpy_iterator()):
                yield f'{item.name}-{j}', jtem

    def load_tensors(self, path):
        vars = list(self.info.features)
        ds = xr.open_dataset(path)[vars]
        return tf.data.Dataset.from_tensor_slices({i: ds[i].values for i in vars})

</code></pre>
","The TensorFlow Datasets guide on creating a dataset suggests subclassing the tfds.core.DatasetBuilder. Below is my subclass; it reads NetCDF files and extracts the relevant variables as examples. How can I improve performance with parallel processing? When executing the download_and_prepare pethod, I'm only ever at 100% CPU and can't find any documentation on using multiple threads or cores. The fact that the class utilizes iteration in Python over a generator makes me afraid it's not possible. Is there an alternative approach?",https://stackoverflow.com/questions/76103475,687112,Documentation Completeness,Lack of Alternative Solutions/Documentation,I'm only ever at 100% CPU and can't find any documentation on using multiple threads or cores.
36339059,Exporter classification_signature,"<p>I'm trying to modify the <a href=""https://tensorflow.github.io/serving/serving_basic"" rel=""nofollow"">serving tutorial</a> to work with my model, which is basically the CIFAR example modified to work with a CSV file and JPEGs. I can't seem to find the documentation for the Exporter class, but here is what I have so far. It's in the train() function in the cifar10_train.py file:</p>

<pre><code>  # Save the model checkpoint periodically.
  if step % 10 == 0 or (step + 1) == FLAGS.max_steps:
    checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')
    saver.save(sess, checkpoint_path, global_step=step)

    export_dir = FLAGS.export_dir
    print 'Exporting trained model to ' + FLAGS.export_dir
    export_saver = tf.train.Saver(sharded=True)
    model_exporter = exporter.Exporter(export_saver)
    #
    # TODO: where to find x and y?
    #
    signature = exporter.classification_signature(input_tensor=x, scores_tensor=y)
    model_exporter.init(sess.graph.as_graph_def(),
                        default_graph_signature=signature)
    model_exporter.export(export_dir, tf.constant(FLAGS.export_version), sess)
</code></pre>

<p>Here is the code I use to train the model:</p>

<pre><code>  labels = numpy.fromfile(os.path.join(data_dir, 'labels.txt'), dtype=numpy.int32, count=-1, sep='\n')

  filenames_and_labels = []

  start_image_number = 1
  end_image_number = 8200

  for i in xrange(start_image_number, end_image_number):
    file_name = os.path.join(data_dir, 'image%d.jpg' % i)
    label = labels[i - 1]
    filenames_and_labels.append(file_name + "","" + str(label))


  print('Reading filenames for ' + str(len(filenames_and_labels)) + ' files (from ' + str(start_image_number) + ' to ' + str(end_image_number) + ')')

  for filename_and_label in filenames_and_labels:
    array = filename_and_label.split("","")
    f = array[0]
    # print(array)
    if not tf.gfile.Exists(f):
      raise ValueError('Failed to find file: ' + f)

  # Create a queue that produces the filenames to read.
  filename_and_label_queue = tf.train.string_input_producer(filenames_and_labels)

  filename_and_label_tensor = filename_and_label_queue.dequeue()
  filename, label = tf.decode_csv(filename_and_label_tensor, [[""""], [""""]], "","")
  file_contents = tf.read_file(filename)
  image = tf.image.decode_jpeg(file_contents)
</code></pre>

<p>Any ideas how I can set up Exporter correctly?</p>
","I'm trying to modify the serving tutorial to work with my model, which is basically the CIFAR example modified to work with a CSV file and JPEGs. I can't seem to find the documentation for the Exporter class, but here is what I have so far. It's in the train() function in the cifar10_train.py file: Here is the code I use to train the model: Any ideas how I can set up Exporter correctly?",https://stackoverflow.com/questions/36339059,563762,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I can't seem to find the documentation for the Exporter class, but here is what I have so far."
38788912,Tensorflow 'features' format,"<p>I'm a total begginer with AI and tensorflow, so please forgive if this is a dumb question.
I've trained a tensorflow network using a script based on this tutorial:</p>

<p><a href=""https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html"" rel=""nofollow"">https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html</a></p>

<p>I believe training was ok.
Now I whant to run this method to make a prediction for a single input:</p>

<pre><code>tf.contrib.learn.DNNClassifier.predict_proba(x=x)
</code></pre>

<p>But I cannot find any documentation on how to build the ""x"" parameter...
I tryed: </p>

<pre><code> x = {k: tf.SparseTensor(indices=[[0, 0]], values=[d_data[k]], shape=[1, 1]) for k in COLUMNS}
</code></pre>

<p>Where:
<strong>d_data</strong> is a dictionary containing about 150 key/value pairs.
<strong>COLUMNS</strong> is a list with all the keys needed. 
This same setup was used to train the network.</p>

<p>But got the error:  </p>

<pre><code>AttributeError: 'dict' object has no attribute 'dtype'
</code></pre>

<p>So... x should not be a 'dict'... but what should it be then?
Can anyone give me some directions?</p>

<p>Thanks a lot.</p>
","I'm a total begginer with AI and tensorflow, so please forgive if this is a dumb question. I've trained a tensorflow network using a script based on this tutorial: https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html I believe training was ok. Now I whant to run this method to make a prediction for a single input: But I cannot find any documentation on how to build the ""x"" parameter... I tryed: Where: d_data is a dictionary containing about 150 key/value pairs. COLUMNS is a list with all the keys needed. This same setup was used to train the network. But got the error: So... x should not be a 'dict'... but what should it be then? Can anyone give me some directions? Thanks a lot.",https://stackoverflow.com/questions/38788912,6430078,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"But I cannot find any documentation on how to build the ""x"" parameter."
42953781,How to restore variables in Tensorflow r1.0,"<p>After upgrading Tensorflow to r1.0, the restore command does not seem to work.
For example, can anyone tell me what is wrong with the following?</p>

<pre><code>def foo():
    v1 = tf.Variable(1., name=""v1"")
    v2 = tf.Variable(2., name=""v2"")
    v3 = v1 + v2

    saver = tf.train.Saver()

    with tf.Session() as sess:
        tf.global_variables_initializer().run()

        saver.save(sess, ""temp"")

        # do something

        saver.restore(sess, ""temp"") 
</code></pre>

<p>From the last line, I got an error:</p>

<pre><code>tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for temp
     [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
</code></pre>

<p>Tensorflow documentation still holds the explanation of old versions for this matter.</p>
","After upgrading Tensorflow to r1.0, the restore command does not seem to work. For example, can anyone tell me what is wrong with the following? From the last line, I got an error: Tensorflow documentation still holds the explanation of old versions for this matter.",https://stackoverflow.com/questions/42953781,3755060,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"From the last line, I got an error: Tensorflow documentation still holds the explanation of old versions for this matter."
44000781,Tensorflow aggregation_method for optimizers,"<p>I could not find documentation regarding the aggregation method in tensorflow optimizer</p>

<p>I have the following line of code </p>

<pre><code>train_op = optimizer.minimize(loss, global_step=batch, aggregation_method = tf.AggregationMethod.EXPERIMENTAL_TREE)
</code></pre>

<p>However, this property can be changed to be </p>

<pre><code>tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N
</code></pre>

<p>Does anyone know what does it do? (I just know that when I used the default with an LSTM it did not have enough memory to run) </p>
","I could not find documentation regarding the aggregation method in tensorflow optimizer I have the following line of code However, this property can be changed to be Does anyone know what does it do? (I just know that when I used the default with an LSTM it did not have enough memory to run)",https://stackoverflow.com/questions/44000781,6828367,Documentation Completeness,Lack of Alternative Solutions/Documentation,I could not find documentation regarding the aggregation method in tensorflow optimizer
44518790,"Are tensor names always prepended with ""import/"" when loaded from protobuf?","<p>When I load a (frozen) Tensorflow model from disk using:</p>

<pre><code>graph = tf.Graph()
  with graph.as_default():
        f = gfile.FastGFile(""frozen_graph.pb"", ""rb"")
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        tf.import_graph_def(graph_def)
</code></pre>

<p>It seems that all tensor names are prepended with  import/ .
 This is the code I use to print the names:</p>

<pre><code>with tf.Session(graph=graph) as sess:
        all_ops = sess.graph.get_operations()
        op_values =  [op.values() for op in all_ops]
        for values in op_values:
            for each in value:
                print each.name
</code></pre>

<p>Why? Is this some kind of default option that can be overriden? Or can I rely on this in my code? I could not find this documented anyhwere, can anybody point me to references regarding this?</p>
","When I load a (frozen) Tensorflow model from disk using: It seems that all tensor names are prepended with import/ . This is the code I use to print the names: Why? Is this some kind of default option that can be overriden? Or can I rely on this in my code? I could not find this documented anyhwere, can anybody point me to references regarding this?",https://stackoverflow.com/questions/44518790,7264906,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I could not find this documented anyhwere, can anybody point me to references regarding this?"
45288297,Meaning and dimensions of tf.contrib.learn.DNNClassifier's extracted weights and biases,"<p>I relatively new to tensorflow, but even with a lot of research I was unable to find a documentation of certain variable meanings.</p>

<p>For my current project, I want to train a DNN with the help of tensorflow, and afterwards I want to extract the weight and bias matrices from it to use it in another application OUTSIDE tensorflow. For the first try, I set up a simple network with a [4, 10, 2] structure, which predicts a binary outcome.</p>

<p>I used 3 real_valued_columns and a single sparse_column_with_keys (wrapped in an embedding_column) as features:</p>

<pre><code>def build_estimator(optimizer=None, activation_fn=tf.sigmoid):
    """"""Build an estimator""""""
    # Sparse base columns
    column_stay_point = tf.contrib.layers.sparse_column_with_keys(
        column_name='stay_point',
        keys=['no', 'yes'])

    # Continuous base columns
    column_heading = tf.contrib.layers.real_valued_column('heading')
    column_velocity = tf.contrib.layers.real_valued_column('velocity')
    column_acceleration = tf.contrib.layers.real_valued_column('acceleration')

    pedestrian_feature_columns = [column_heading, 
                                  column_velocity, 
                                  column_acceleration,
                                  tf.contrib.layers.embedding_column(
                                      column_stay_point, 
                                      dimension=8, 
                                      initializer=tf.truncated_normal_initializer)]

    # Create classifier
    estimator = tf.contrib.learn.DNNClassifier(
        hidden_units=[10],
        feature_columns=pedestrian_feature_columns,
        model_dir='./tmp/pedestrian_model',
        n_classes=2,
        optimizer=optimizer,
        activation_fn=activation_fn)

    return estimator
</code></pre>

<p>I called this function with default arguments and used estimator.fit(...) to train the DNN. Aside from some warnings concerning the deprecated 'scalar_summary' function, it ran successfully and produced reasonable results. I printed all variables of the model by using the following line:</p>

<pre><code>var = {k: estimator.get_variable_value(k) for k in estimator.get_variable_names())
</code></pre>

<p>I expected to get a weight matrices of size 10x4 and 2x10 as well as bias matrices of size 10x1 and 2x1. But I got the following:</p>

<pre><code>'dnn/binary_logistic_head/dnn/learning_rate': 0.05 (actual value, scalar)

'dnn/input_from_feature_columns/stay_point_embedding/weights': 2x8 array

'dnn/hiddenlayer_0/weights/hiddenlayer_0/weights/part_0/Adagrad': 11x10 array

'dnn/input_from_feature_columns/stay_point_embedding/weights/int_embedding/weights/part_0/Adagrad': 2x8 array

'dnn/hiddenlayer_0/weights': 11x10 array

'dnn/logits/biases': 1x1' array

'dnn/logits/weights/nn/dnn/logits/weights/part_0/Adagrad': 10x1 array

'dnn/logits/weights': 10x1 array

'dnn/logits/biases/dnn/dnn/logits/biases/part_0/Adagrad': 1x1 array

'global_step': 5800, (actual value, scalar)

'dnn/hiddenlayer_0/biases': 1x10 array

'dnn/hiddenlayer_0/biases//hiddenlayer_0/biases/part_0/Adagrad': 1x10 array
</code></pre>

<p>Is there any documentation what these cryptic names mean and why do the matrices have these weird dimensions? Also, why are there references to the Adagrad optimizer despite never specifying it?</p>

<p>Any help is highly appreciated!</p>
","I relatively new to tensorflow, but even with a lot of research I was unable to find a documentation of certain variable meanings. For my current project, I want to train a DNN with the help of tensorflow, and afterwards I want to extract the weight and bias matrices from it to use it in another application OUTSIDE tensorflow. For the first try, I set up a simple network with a [4, 10, 2] structure, which predicts a binary outcome. I used 3 real_valued_columns and a single sparse_column_with_keys (wrapped in an embedding_column) as features: I called this function with default arguments and used estimator.fit(...) to train the DNN. Aside from some warnings concerning the deprecated 'scalar_summary' function, it ran successfully and produced reasonable results. I printed all variables of the model by using the following line: I expected to get a weight matrices of size 10x4 and 2x10 as well as bias matrices of size 10x1 and 2x1. But I got the following: Is there any documentation what these cryptic names mean and why do the matrices have these weird dimensions? Also, why are there references to the Adagrad optimizer despite never specifying it? Any help is highly appreciated!",https://stackoverflow.com/questions/45288297,8334261,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I relatively new to tensorflow, but even with a lot of research I was unable to find a documentation of certain variable meanings."
45437572,Tensor Shape Error: Must be rank 2 but is rank 3,"<p>I am having difficulty searching for documentation, studies, or blogs that can help me in building text sequence (features) classifier. The text sequence that I have contains logs of network.</p>

<p>I am building a GRU model using TensorFlow, with an SVM as the classification function. I am having trouble with the tensor shapes. It says <code>ValueError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [?,23,1], [512,2]</code>. <a href=""https://gist.github.com/AFAgarap/61b17a3f02a9e13eb0c7aad9406a3408"" rel=""nofollow noreferrer"">Here is a sample</a> of the data I am using for training my neural network.</p>

<p>The goal of my project is to use this GRU-SVM model for intrusion detection on <a href=""http://www.takakura.com/Kyoto_data/"" rel=""nofollow noreferrer"">Kyoto University's honeypot system intrusion detection dataset</a>. The dataset has 23 features, and a label (if there is an intrusion in the network or none).</p>

<pre><code>import data
import numpy as np
import os
import tensorflow as tf


BATCH_SIZE = 200
CELLSIZE = 512
NLAYERS = 3
SVMC = 1
learning_rate = 0.01

TRAIN_PATH = '/home/darth/GitHub Projects/gru_svm/dataset/train/6'

def main():
    examples, labels, keys = data.input_pipeline(path=TRAIN_PATH, batch_size=BATCH_SIZE, num_epochs=1)

    seqlen = examples.shape[1]

    x = tf.placeholder(shape=[None, seqlen, 1], dtype=tf.float32)
    y = tf.placeholder(shape=[None, 2], dtype=tf.float32)
    Hin = tf.placeholder(shape=[None, CELLSIZE*NLAYERS], dtype=tf.float32)

    # cell = tf.contrib.rnn.GRUCell(CELLSIZE)
    network = []
    for index in range(NLAYERS):
        network.append(tf.contrib.rnn.GRUCell(CELLSIZE))

    mcell = tf.contrib.rnn.MultiRNNCell(network, state_is_tuple=False)
    Hr, H = tf.nn.dynamic_rnn(mcell, x, initial_state=Hin, dtype=tf.float32)

    Hf = tf.transpose(Hr, [1, 0, 2])
    last = tf.gather(Hf, int(Hf.get_shape()[0]) - 1)

    weight = tf.Variable(tf.truncated_normal([CELLSIZE, 2], stddev=0.01), tf.float32)
    bias = tf.Variable(tf.constant(0.1, shape=[2]))
    logits = tf.matmul(last, weight) + bias

    regularization_loss = 0.5 * tf.reduce_sum(tf.square(weight))
    hinge_loss = tf.reduce_sum(tf.maximum(tf.zeros([BATCH_SIZE, 1]), 1 - y * logits))
    loss = regularization_loss + SVMC * hinge_loss

    train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)

    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())

    with tf.Session() as sess:
        sess.run(init_op)

        train_loss = 0

        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)

        try:
            for index in range(100):
                for j in range(1000):
                    example_batch, label_batch, key_batch = sess.run([examples, labels, keys])
                    _, train_loss_ = sess.run([train_step, loss],
                        feed_dict = { x : example_batch,
                                        y : label_batch,
                                        Hin : np.zeros([BATCH_SIZE, CELLSIZE * NLAYERS])
                                    })
                    train_loss += train_loss_
                print('[{}] loss : {}'.format(index, (train_loss / 1000)))
                train_loss = 0
        except tf.errors.OutOfRangeError:
            print('EOF reached.')
        except KeyboardInterrupt:
            print('Interrupted by user at {}'.format(index))
        finally:
            coord.request_stop()
        coord.join(threads)

main()
</code></pre>

<p>Note: The reason why I built my <code>MultiRNNCell</code> as I did (snippet isolated below) is because I was having an error similar to this <a href=""https://stackoverflow.com/questions/44615147/valueerror-trying-to-share-variable-rnn-multi-rnn-cell-cell-0-basic-lstm-cell-k"">post</a>.</p>

<pre><code>network = []
for index in range(NLAYERS):
    network.append(tf.contrib.rnn.GRUCell(CELLSIZE))
</code></pre>

<p>Thank you in advance for your response!</p>

<p><strong>Update 08/01/2017</strong> 
The source was improved based on @jdehesa's sugestions:</p>

<pre><code>import data
import numpy as np
import os
import tensorflow as tf


BATCH_SIZE = 200
CELLSIZE = 512
NLAYERS = 3
SVMC = 1
learning_rate = 0.01

TRAIN_PATH = '/home/darth/GitHub Projects/gru_svm/dataset/train/6'

def main():
    examples, labels, keys = data.input_pipeline(path=TRAIN_PATH, batch_size=BATCH_SIZE, num_epochs=1)

    seqlen = examples.shape[1]

    x = tf.placeholder(shape=[None, seqlen, 1], dtype=tf.float32, name='x')
    y_input = tf.placeholder(shape=[None], dtype=tf.int32, name='y_input')
    y = tf.one_hot(y_input, 2, dtype=tf.float32, name='y')
    Hin = tf.placeholder(shape=[None, CELLSIZE*NLAYERS], dtype=tf.float32, name='Hin')

    network = []
    for index in range(NLAYERS):
        network.append(tf.contrib.rnn.GRUCell(CELLSIZE))

    mcell = tf.contrib.rnn.MultiRNNCell(network, state_is_tuple=False)
    Hr, H = tf.nn.dynamic_rnn(mcell, x, initial_state=Hin, dtype=tf.float32)

    Hf = tf.transpose(Hr, [1, 0, 2])
    last = tf.gather(Hf, int(Hf.get_shape()[0]) - 1)

    weight = tf.Variable(tf.truncated_normal([CELLSIZE, 2], stddev=0.01), tf.float32, name='weights')
    bias = tf.Variable(tf.constant(0.1, shape=[2]), name='bias')
    logits = tf.matmul(last, weight) + bias

    regularization_loss = 0.5 * tf.reduce_sum(tf.square(weight))
    hinge_loss = tf.reduce_sum(tf.maximum(tf.zeros([BATCH_SIZE, 1]), 1 - y * logits))
    loss = regularization_loss + SVMC * hinge_loss

    train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)

    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())

    with tf.Session() as sess:
        sess.run(init_op)

        train_loss = 0

        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)

        try:
            for index in range(100):
                example_batch, label_batch, key_batch = sess.run([examples, labels, keys])
                _, train_loss_ = sess.run([train_step, loss],
                    feed_dict = { x : example_batch[..., np.newaxis],
                                    y_input : label_batch,
                                    Hin : np.zeros([BATCH_SIZE, CELLSIZE * NLAYERS])
                                })
                train_loss += train_loss_
                print('[{}] loss : {}'.format(index, (train_loss / 1000)))
                print('Weights : {}'.format(sess.run(weight)))
                print('Biases : {}'.format(sess.run(bias)))
                train_loss = 0
        except tf.errors.OutOfRangeError:
            print('EOF reached.')
        except KeyboardInterrupt:
            print('Interrupted by user at {}'.format(index))
        finally:
            coord.request_stop()
        coord.join(threads)

main()
</code></pre>

<p>My next move is to validate if the results I'm getting are correct.</p>
","I am having difficulty searching for documentation, studies, or blogs that can help me in building text sequence (features) classifier. The text sequence that I have contains logs of network. I am building a GRU model using TensorFlow, with an SVM as the classification function. I am having trouble with the tensor shapes. It says ValueError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [?,23,1], [512,2]. Here is a sample of the data I am using for training my neural network. The goal of my project is to use this GRU-SVM model for intrusion detection on Kyoto University's honeypot system intrusion detection dataset. The dataset has 23 features, and a label (if there is an intrusion in the network or none). Note: The reason why I built my MultiRNNCell as I did (snippet isolated below) is because I was having an error similar to this post. Thank you in advance for your response! Update 08/01/2017 The source was improved based on @jdehesa's sugestions: My next move is to validate if the results I'm getting are correct.",https://stackoverflow.com/questions/45437572,6838049,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I am having difficulty searching for documentation, studies, or blogs that can help me in building text sequence (features) classifier."
48335842,Tensorflow: Exogenous feature key raises KeyError on StructuralEnsembleRegressor predict call,"<p>I have a tensorflow implementation for timeseries forecasting. My data contains exogeneous features, I provide them in my train input and evaluate inputs. In the prediction step <code>predict_continuation_input_fn</code> raises KeyError for my exogenous feature column. Here is the simplified version of my code:</p>

<pre class=""lang-py prettyprint-override""><code>features = (ex_0, ex_1, ex_2)
reader = tf.contrib.timeseries.CSVReader(
  _DATA_FILE,
  column_names=(tf.contrib.timeseries.TrainEvalFeatures.TIMES, tf.contrib.timeseries.TrainEvalFeatures.VALUES) + features,
  column_dtypes=(tf.int64,tf.float32,tf.float32,tf.float32,tf.float32),
  skip_header_lines=1)

estimator = tf.contrib.timeseries.StructuralEnsembleRegressor(
  periodicities=[20],
  num_features=1,
  exogenous_feature_columns= [tf.contrib.layers.real_valued_column(column_name=f, dimension=1) for f in features])

train_input_fn=tf.contrib.timeseries.RandomWindowInputFn(reader, batch_size=4, window_size=100)
estimator.train(input_fn=train_input_fn, steps=20)

evaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)
evaluation = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)

predict_input_fn = tf.contrib.timeseries.predict_continuation_input_fn(
      evaluation, steps=100)
(predictions,) = tuple(estimator.predict(input_fn=predict_input_fn))
</code></pre>

<p>At this point I get error <code>KeyError: 'ex_0'</code>. Error is obvious, since resulting <code>evaluation</code> variable does not contain my exogenous features. <code>predict_continuation_input_fn</code> has argument to get exogenous_features however I could not find any documentation on how to feed exogenous data from evaluation to that argument.</p>

<p>How should I provide those features to prediction? Is there a flaw in my implementation? Advises are very welcome.</p>
","I have a tensorflow implementation for timeseries forecasting. My data contains exogeneous features, I provide them in my train input and evaluate inputs. In the prediction step predict_continuation_input_fn raises KeyError for my exogenous feature column. Here is the simplified version of my code: At this point I get error KeyError: 'ex_0'. Error is obvious, since resulting evaluation variable does not contain my exogenous features. predict_continuation_input_fn has argument to get exogenous_features however I could not find any documentation on how to feed exogenous data from evaluation to that argument. How should I provide those features to prediction? Is there a flaw in my implementation? Advises are very welcome.",https://stackoverflow.com/questions/48335842,65071,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,However I could not find any documentation on how to feed exogenous data from evaluation to that argument.
48531039,Create variable of weights from array,"<p>I have an array : [1, 4, -10, 3, 5]. I'm trying to create a <code>Variable</code> of weights using that array.</p>

<p>After doing training, I print the weight as: </p>

<pre><code>result = sess.run(w)
print(result)
</code></pre>

<p>the <code>result</code> is just the array in the format [1, 4, -10, 3, 5].</p>

<p>How I tried to create a <code>Variable</code> from the array:</p>

<pre><code> c = [1, 4, -10, 3, 5]
 for i in range(len(c)): 
     w = tf.Variable(c[i], name='weights')
</code></pre>

<p>Obviously, this weight result is wrong, and I've spent hours looking at documentation and SO posts. How do I create a <code>Variable</code> using that array?</p>
","I have an array : [1, 4, -10, 3, 5]. I'm trying to create a Variable of weights using that array. After doing training, I print the weight as: the result is just the array in the format [1, 4, -10, 3, 5]. How I tried to create a Variable from the array: Obviously, this weight result is wrong, and I've spent hours looking at documentation and SO posts. How do I create a Variable using that array?",https://stackoverflow.com/questions/48531039,7933838,Requesting (Additional) Resources,Lack of Alternative Solutions/Documentation,"Obviously, this weight result is wrong, and I've spent hours looking at documentation and SO posts. How do I create a Variable using that array?"
49178891,Filtering a Tensor using Tensorflow,"<p>I'm attempting to filter a matrix that represents a point cloud in tensorflow. It is an <code>n x 3</code> matrix.</p>

<p>I only want to keep rows with <code>z &gt; eps</code>. This corresponds to column index 2 of the matrix.</p>

<p>I have the following code:</p>

<pre>
<code>
import numpy as np
import tensorflow as tf

point_cloud = tf.placeholder(tf.float32, shape=[None,3])
eps = tf.placeholder(tf.float32)

mask = tf.greater(point_cloud[:,2], eps)
reduced_cloud = tf.boolean_mask(point_cloud, mask)


init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    _cloud = np.random.rand(5000,3)
    feed = {point_cloud:_cloud, eps:0.0025}
    _filtered = sess.run(reduced_cloud, feed_dict=feed)

</code>
</pre> 

<p>When I run the above code I get this:</p>

<pre>
<code>
ValueError: Number of mask dimensions must be specified, even if some dimensions are None.  E.g. shape=[None] is ok, but shape=None is not.
</code>
</pre>

<p>I don't understand the error message, having tried to specify shape in a number of places with no success, and the documentation seems to suggest the <code>boolean_mask</code> only works with <code>np.array</code>s. Is there any way to do this entirely on the tensorflow graph?  </p>
","I'm attempting to filter a matrix that represents a point cloud in tensorflow. It is an n x 3 matrix. I only want to keep rows with z &gt; eps. This corresponds to column index 2 of the matrix. I have the following code: When I run the above code I get this: I don't understand the error message, having tried to specify shape in a number of places with no success, and the documentation seems to suggest the boolean_mask only works with np.arrays. Is there any way to do this entirely on the tensorflow graph?",https://stackoverflow.com/questions/49178891,1747088,Documentation Ambiguity,Lack of Alternative Solutions/Documentation,"I don't understand the error message, having tried to specify shape in a number of places with no success, and the documentation seems to suggest the boolean_mask only works with np.arrays. Is there any way to do this entirely on the tensorflow graph?"
49865446,Understanding next step after saving TensorFlow model,"<p>I've a simple MNIST which I've successfully saved, being the code the next:</p>

<pre><code>from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
import tensorflow as tf

sess = tf.InteractiveSession()
tf_save_file = './mnist-to-save-saved'
x = tf.placeholder(tf.float32, shape=[None, 784])
y_ = tf.placeholder(tf.float32, shape=[None, 10])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
saver = tf.train.Saver()

sess.run(tf.global_variables_initializer())

y = tf.matmul(x, W) + b
cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
saver.save(sess, tf_save_file)

for _ in range(1000):
    batch = mnist.train.next_batch(100)
    train_step.run(feed_dict={x: batch[0], y_: batch[1]})

correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
saver.save(sess, tf_save_file, global_step=1000)

print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
</code></pre>

<p>Then, the next <strong>files</strong> are <strong>generated</strong>:</p>

<pre><code>checkpoint
mnist-to-save-saved-1000.data-00000-of-00001
mnist-to-save-saved-1000.index
mnist-to-save-saved-1000.meta
mnist-to-save-saved.data-00000-of-00001
mnist-to-save-saved.index
mnist-to-save-saved.meta
</code></pre>

<p>Now, in order to use it in production (and so, for example, pass it a number image), I want to be able to <strong>execute the trained model</strong> by <strong>passing</strong> it any <strong>number image to make the prediction</strong> (I mean, not deploying yet a server but making this prediction ""<strong>locally</strong>"", having in the same directory that ""fixed"" number image, so using the model would be like when you run an executable).</p>

<p>But, considering the (mid-low?) API level of my code, I'm confused about what would be the easiest correct next step (if restoring, using an Estimator, etc...), and how to do it.</p>

<p>Although I've read the official documentation, I insist that they seem to be many ways, but some are a bit complex and ""noisy"" for a simple model like this.</p>

<p><strong>Edit:</strong></p>

<p>I've edit and re-run the mnist file, whose code is the same as above except for those lines:</p>

<pre><code>...

x = tf.placeholder(tf.float32, shape=[None, 784], name='input')

...

correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1), name='result')

...
</code></pre>

<p>Then, I try to run this another .py code (in the same directory as the above code) in order to pass a local handwritten number image (""mnist-input-image.png"") located in the same directory:</p>

<pre><code>import tensorflow as tf
from PIL import Image
import numpy as np

image_test = Image.open(""mnist-input-image.png"")
image = np.array(image_test)

with tf.Session() as sess:
    saver = tf.train.import_meta_graph('/Users/username/.meta')
    new = saver.restore(sess, tf.train.latest_checkpoint('/Users/username/'))

    graph = tf.get_default_graph()
    input_x = graph.get_tensor_by_name(""input:0"")
    result = graph.get_tensor_by_name(""result:0"")

    feed_dict = {input_x: image}

    predictions = result.eval(feed_dict=feed_dict)
    print(predictions)
</code></pre>

<p>Now, if I correctly understand,  I've to pass the image as numpy array. Then, my questions are:</p>

<p>1) Which is the exact file reference of those lines (since I've no .meta folder in my User folder)?</p>

<pre><code>saver = tf.train.import_meta_graph('/Users/username/.meta')
new = saver.restore(sess, tf.train.latest_checkpoint('/Users/username/'))
</code></pre>

<p>I mean, to which exact files refer those lines (from my generated files list above)?</p>

<p>2) Translasted to my case, is correct this line to pass my numpy array into the feed dict?</p>

<pre><code>feed_dict = {input_x: image}
</code></pre>
","I've a simple MNIST which I've successfully saved, being the code the next: Then, the next files are generated: Now, in order to use it in production (and so, for example, pass it a number image), I want to be able to execute the trained model by passing it any number image to make the prediction (I mean, not deploying yet a server but making this prediction ""locally"", having in the same directory that ""fixed"" number image, so using the model would be like when you run an executable). But, considering the (mid-low?) API level of my code, I'm confused about what would be the easiest correct next step (if restoring, using an Estimator, etc...), and how to do it. Although I've read the official documentation, I insist that they seem to be many ways, but some are a bit complex and ""noisy"" for a simple model like this. Edit: I've edit and re-run the mnist file, whose code is the same as above except for those lines: Then, I try to run this another .py code (in the same directory as the above code) in order to pass a local handwritten number image (""mnist-input-image.png"") located in the same directory: Now, if I correctly understand, I've to pass the image as numpy array. Then, my questions are: 1) Which is the exact file reference of those lines (since I've no .meta folder in my User folder)? I mean, to which exact files refer those lines (from my generated files list above)? 2) Translasted to my case, is correct this line to pass my numpy array into the feed dict?",https://stackoverflow.com/questions/49865446,9499989,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"Although I've read the official documentation, I insist that they seem to be many ways, but some are a bit complex and ""noisy"" for a simple model like this."
53144832,Tensorflow CNN 'tuple' object has no attribute 'initializer',"<p>Seems like I am messing up a step in preparing the dataset. Couldn't find a proper answer or look up the correct solution in documentation. I have pointed out the problem line with ###, bottom part.</p>

<pre><code>def parse_file(data_path):


    imagepaths = list()
    labels = list()
    # a working parser for os is here

    imagepaths = tf.constant(imagepaths, dtype=tf.string)
    labels = tf.constant(labels, dtype=tf.float32)

    return imagepaths, labels


def parse_image(imagepath, label):

    image_string = tf.read_file(imagepath)
    image_decoded = tf.image.decode_png(image_string, channels=3)
    # The image size is 425x425.
    image_resized = tf.image.resize_images(image_decoded, [img_size, img_size])
    image_normalized = image_resized * 1.0/255
    print(image_normalized)
    print(label)
    return image_normalized, label

dataset = tf.data.Dataset.from_tensor_slices((parsed_files))
dataset = dataset.map(parse_image)
dataset = dataset.batch(batch_size)

iterator = dataset.make_initializable_iterator()
iterator = iterator.get_next()

x = tf.placeholder(tf.float32, [None, img_size, img_size, channels])
y = tf.placeholder(tf.float32, [None, 1])
</code></pre>

<p>(Model goes here, irrelevant.)</p>

<pre><code>with tf.Session() as sess:

    ### AttributeError: 'tuple' object has no attribute 'initializer'
    sess.run(iterator.initializer)
    batch_x, batch_y = iterator.get_next()
    test1, test2 = sess.run([batch_x, batch_y])
    total_batch = int(total_input[0] / batch_size)
    # define the iterator for the network
    for epoch in range(epochs):
        avg_cost = 0
        for i in range(total_batch):
            batch_x, batch_y = sess.run(iterator)
            _, c = sess.run([optimiser, cross_entropy], feed_dict={x: batch_x, y: batch_y})
            avg_cost += c / total_batch

        test_acc = sess.run(accuracy,feed_dict={x: test_x, y: np.expand_dims(test_y, axis=-1)})
        print(""Epoch:"", (epoch + 1), ""cost ="", ""{:.3f}"".format(avg_cost), "" test accuracy: {:.3f}"".format(test_acc))
        summary = sess.run(merged, feed_dict={x: test_x, y: np.expand_dims(test_y, axis=-1)})

    print(""\nTraining complete!"")
    print(sess.run(accuracy, feed_dict={x: test_x, y: np.expand_dims(test_y, axis=-1)}))
</code></pre>
","Seems like I am messing up a step in preparing the dataset. Couldn't find a proper answer or look up the correct solution in documentation. I have pointed out the problem line with ###, bottom part. (Model goes here, irrelevant.)",https://stackoverflow.com/questions/53144832,10520111,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,Couldn't find a proper answer or look up the correct solution in documentation.
53965422,Training loss and accuracy don't change - stuck around a value -- Tensorflow,"<p>My LSTM model below in tensorflow works without any error, but the values of the loss and accuracy seem to swarm around specific values, leading to a misleading conclusion after all the epochs. </p>

<p><strong>My thoughts were/are:</strong> </p>

<ul>
<li><p>It might be a problem of <strong>feeding the same batch each time</strong>. I think this cannot be the problem because I get the printing after each 10th epoch; so that I'm feeding different batches of the data. </p></li>
<li><p>It might be a cause of the <strong>low complexity of the LSTM network</strong>. However, I believe this cannot be the problem because the training phase should somehow improve over time because of the optimization.</p></li>
<li><p>As the loss and accuracy are around some value, I might be <strong>calculating them or printing them wrongly</strong>, leading to this values althought I don't get my error in the code. </p></li>
<li><p>I think that this issue is due to <strong>some typo or misunderstanding in my code</strong>, because in some other case, I would see the loss and accuracy either increase or decrease, even with not constant patterns but not this way. </p></li>
<li><p>Finally, if all my code is well arranged, I think that this values could be due to bad hyperparameters settings. <strong>My following steps</strong> could be to increase the complexity of the LSTM network, lowering the learning rate and increasing the batch size.</p></li>
</ul>

<p>As there is not a lot of documentation (and due to my little experience) about linking the dataset API, together with RNNs, different batches and different datasets, I may have done something wrongly.</p>

<p>Please, I would appreciate any review or knowdledge that could add some light to this.</p>

<p>Many thanks for your time. </p>

<p><strong>CODE:</strong></p>

<pre><code>'''All the data is numeric. The dataset is scaled using the StandardScaler from scikit-learn and in the following shapes:'''

#The 3D xt array has a shape of: (11, 69579, 74)
#The 3D xval array has a shape of: (11, 7732, 74)

#y shape is: (69579, 3)
#yval shape is: (7732, 3)

N_TIMESTEPS_X = xt.shape[0] ## The stack number
BATCH_SIZE = 256
#N_OBSERVATIONS = xt.shape[1]
N_FEATURES = xt.shape[2]
N_OUTPUTS = yt.shape[1]
N_NEURONS_LSTM = 128 ## Number of units in the LSTMCell 
N_EPOCHS = 600
LEARNING_RATE = 0.1

### Define the placeholders anda gather the data.
xt = xt.transpose([1,0,2])
xval = xval.transpose([1,0,2])

train_data = (xt, yt)
validation_data = (xval, yval)

## We define the placeholders as a trick so that we do not break into memory problems, associated with feeding the data directly.

'''As an alternative, you can define the Dataset in terms of tf.placeholder() tensors, and feed the NumPy arrays when you initialize an Iterator over the dataset.'''

batch_size = tf.placeholder(tf.int64)

x = tf.placeholder(tf.float32, shape=[None, N_TIMESTEPS_X, N_FEATURES], name='XPlaceholder')

y = tf.placeholder(tf.float32, shape=[None, N_OUTPUTS], name='YPlaceholder')

# Creating the two different dataset objects.

train_dataset = tf.data.Dataset.from_tensor_slices((x,y)).batch(BATCH_SIZE).repeat()

val_dataset = tf.data.Dataset.from_tensor_slices((x,y)).batch(BATCH_SIZE)

# Creating the Iterator type that permits to switch between datasets.

itr = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)
train_init_op = itr.make_initializer(train_dataset)
validation_init_op = itr.make_initializer(val_dataset)

next_features, next_labels = itr.get_next()

### Create the graph 

cellType = tf.nn.rnn_cell.LSTMCell(num_units=N_NEURONS_LSTM, name='LSTMCell')

inputs = tf.unstack(next_features, axis=1)

'''inputs: A length T list of inputs, each a Tensor of shape [batch_size, input_size]'''

RNNOutputs, _ = tf.nn.static_rnn(cell=cellType, inputs=inputs, dtype=tf.float32)

out_weights = tf.get_variable(""out_weights"", shape=[N_NEURONS_LSTM, N_OUTPUTS], dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())
out_bias = tf.get_variable(""out_bias"", shape=[N_OUTPUTS], dtype=tf.float32, initializer=tf.zeros_initializer())

predictionsLayer = tf.matmul(RNNOutputs[-1], out_weights) + out_bias

### Define the cost function, that will be optimized by the optimizer. 

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predictionsLayer, labels=next_labels, name='Softmax_plus_Cross_Entropy'))

optimizer_type = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE, name='AdamOptimizer')

optimizer = optimizer_type.minimize(cost)

### Model evaluation 

correctPrediction = tf.equal(tf.argmax(predictionsLayer,1), tf.argmax(next_labels,1))

accuracy = tf.reduce_mean(tf.cast(correctPrediction,tf.float32))

N_BATCHES = train_data[0].shape[0] // BATCH_SIZE

## Saving variables so that we can restore them afterwards.

saver = tf.train.Saver()

save_dir = '/home/zmlaptop/Desktop/tfModels/{}_{}'.format(cellType.__class__.__name__, datetime.now().strftime(""%Y%m%d%H%M%S""))
os.mkdir(save_dir)

varDict = {'nTimeSteps':N_TIMESTEPS_X, 'BatchSize': BATCH_SIZE, 'nFeatures':N_FEATURES,
           'nNeuronsLSTM':N_NEURONS_LSTM, 'nEpochs':N_EPOCHS,
           'learningRate':LEARNING_RATE, 'optimizerType': optimizer_type.__class__.__name__}

varDicSavingTxt = save_dir + '/varDict.txt'
modelFilesDir = save_dir + '/modelFiles'
os.mkdir(modelFilesDir)

logDir = save_dir + '/TBoardLogs'
os.mkdir(logDir)

acc_summary = tf.summary.scalar('Accuracy', accuracy)
loss_summary = tf.summary.scalar('Cost_CrossEntropy', cost)
summary_merged = tf.summary.merge_all()

with open(varDicSavingTxt, 'w') as outfile:
    outfile.write(repr(varDict))

with tf.Session() as sess:

    tf.set_random_seed(2)
    sess.run(tf.global_variables_initializer())
    train_writer = tf.summary.FileWriter(logDir + '/train', sess.graph)
    validation_writer = tf.summary.FileWriter(logDir + '/validation')

    # initialise iterator with train data

    sess.run(train_init_op, feed_dict = {x : train_data[0], y: train_data[1], batch_size: BATCH_SIZE})

    print('¡Training starts!')
    for epoch in range(N_EPOCHS):

        batchAccList = []
        tot_loss = 0

        for batch in range(N_BATCHES):

            optimizer_output, loss_value, summary, accBatch = sess.run([optimizer, cost, summary_merged, accuracy], feed_dict = {x: train_data[0], y: train_data[1], batch_size: BATCH_SIZE})
            tot_loss += loss_value
            batchAccList.append(accBatch)

            if batch % 10 == 0:

                train_writer.add_summary(summary, batch)

        epochAcc = tf.reduce_mean(batchAccList)
        epochAcc_num = sess.run(epochAcc, feed_dict = {x: train_data[0], y: train_data[1], batch_size: BATCH_SIZE})

        if epoch%10 == 0:

            print(""Epoch: {}, Loss: {:.4f}, Accuracy: {}"".format(epoch, tot_loss / N_BATCHES, epochAcc_num))

    # initialise iterator with validation data

    sess.run(validation_init_op, feed_dict = {x: validation_data[0], y: validation_data[1], batch_size:len(validation_data[0])})

    valLoss, valAcc = sess.run([cost, accuracy], feed_dict = {x: train_data[0], y: train_data[1], batch_size: BATCH_SIZE})
    print('Validation Loss: {:4f}, Validation Accuracy: {}'.format(valLoss, valAcc))

    summary_val = sess.run(summary_merged, feed_dict = {x: validation_data[0], y: validation_data[1], batch_size: len(validation_data[0])})

    validation_writer.add_summary(summary_val)

    saver.save(sess, modelFilesDir)
</code></pre>

<p><strong>This is the output in tensorboard for accuracy and loss (stopped at around 250 epochs):</strong></p>

<p><a href=""https://i.stack.imgur.com/dz6aw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dz6aw.png"" alt=""enter image description here""></a></p>
","My LSTM model below in tensorflow works without any error, but the values of the loss and accuracy seem to swarm around specific values, leading to a misleading conclusion after all the epochs. My thoughts were/are: As there is not a lot of documentation (and due to my little experience) about linking the dataset API, together with RNNs, different batches and different datasets, I may have done something wrongly. Please, I would appreciate any review or knowdledge that could add some light to this. Many thanks for your time. CODE: This is the output in tensorboard for accuracy and loss (stopped at around 250 epochs):",https://stackoverflow.com/questions/53965422,9273596,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"As there is not a lot of documentation (and due to my little experience) about linking the dataset API, together with RNNs, different batches and different datasets, I may have done something wrongly."
55246768,Python: Multiply two or more numeric_column in tensorflow,"<p>I am new to tensorflow and could not find any documentation on how to define operations on <code>numeric_column</code>s.</p>

<p>I have 3 columns in my data (say) <code>col1</code>, <code>col2</code>, <code>col3</code>. All have numeric values. I want to multiply these and create a new column (say) 'product`. I tried the following.</p>

<pre><code>c1 = tf.feature_column.numeric_column('col1')
c2 = tf.feature_column.numeric_column('col2')
c3 = tf.feature_column.numeric_column('col3')

p = tf.multiply(c1, c2)
p = tf.multiple(p, c3)
</code></pre>

<p>When I run the snippet (via a unittest), I get </p>

<pre><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.feature_column.feature_column._NumericColumn'&gt; to Tensor.
</code></pre>

<p>How else can I get it done?</p>
","I am new to tensorflow and could not find any documentation on how to define operations on numeric_columns. I have 3 columns in my data (say) col1, col2, col3. All have numeric values. I want to multiply these and create a new column (say) 'product`. I tried the following. When I run the snippet (via a unittest), I get How else can I get it done?",https://stackoverflow.com/questions/55246768,1306819,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I am new to tensorflow and could not find any documentation on how to define operations on numeric_columns.
55421290,TensorFlow 2.0 Keras: How to write image summaries for TensorBoard,"<p>I'm trying to setup an image recognition CNN with TensorFlow 2.0. To be able to analyze my image augmentation I'd like to see the images I feed into the network in tensorboard.</p>

<p>Unfortunately, I cannot figure out, how to do this with TensorFlow 2.0 and Keras. I also didn't really find documentation on this.</p>

<p>For simplicity, I'm showing the code of an MNIST example. How would I add the image summary here?</p>

<pre><code>import tensorflow as tf
(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()

def scale(image, label):
    return tf.cast(image, tf.float32) / 255.0, label

def augment(image, label):
    return image, label  # do nothing atm

dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
dataset = dataset.map(scale).map(augment).batch(32)

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(dataset, epochs=5, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='D:\\tmp\\test')])
</code></pre>
","I'm trying to setup an image recognition CNN with TensorFlow 2.0. To be able to analyze my image augmentation I'd like to see the images I feed into the network in tensorboard. Unfortunately, I cannot figure out, how to do this with TensorFlow 2.0 and Keras. I also didn't really find documentation on this. For simplicity, I'm showing the code of an MNIST example. How would I add the image summary here?",https://stackoverflow.com/questions/55421290,820833,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"Unfortunately, I cannot figure out, how to do this with TensorFlow 2.0 and Keras. I also didn't really find documentation on this."
58527048,Accessing intermediate layers from a loaded saved_model in Tensorflow 2.0,"<p>When using SavedModels in Tensorflow 2.0, is it possible to access activations from intermediate layers? For example, with one of the models here: <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"" rel=""noreferrer"">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md</a>, I can run, for example,</p>

<pre><code>model = tf.saved_model.load('faster_rcnn_inception_v2_coco_2018_01_28/saved_model').signatures['serving_default']
outputs = model(input_tensor)
</code></pre>

<p>to get output predictions and bounding boxes. I would like to be able to access layers other than the outputs, but there doesn't seem to be any documentation for Tensorflow 2.0 on how to do this. The downloaded models also include checkpoint files, but there doesn't seem to be very good documentation for how to load those with Tensorflow 2.0 either...</p>
","When using SavedModels in Tensorflow 2.0, is it possible to access activations from intermediate layers? For example, with one of the models here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md, I can run, for example, to get output predictions and bounding boxes. I would like to be able to access layers other than the outputs, but there doesn't seem to be any documentation for Tensorflow 2.0 on how to do this. The downloaded models also include checkpoint files, but there doesn't seem to be very good documentation for how to load those with Tensorflow 2.0 either...",https://stackoverflow.com/questions/58527048,11357382,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I would like to be able to access layers other than the outputs, but there doesn't seem to be any documentation for Tensorflow 2.0 on how to do this."
58644349,Can the bias of a dense layer be set to zero in Tensorflow?,"<p>I'm trying to implement a neural network in which I need the kernel multiplication with the input only. The dense layer in Tensorflow also adds bias which I am trying to set to zero. From the documentation the only variable that is available to play with is <code>bias_regularizer</code>. So I tried doing the following:</p>

<pre class=""lang-py prettyprint-override""><code>def make_zero(_):
    return np.zeros(21,)

out1 = tf.layers.dense(inputs=codeword, units=21, activation=None, bias_regularizer=make_zero)
</code></pre>

<p>But I still see the bias values are not zero. Is there any other method to achieve this?</p>
",I'm trying to implement a neural network in which I need the kernel multiplication with the input only. The dense layer in Tensorflow also adds bias which I am trying to set to zero. From the documentation the only variable that is available to play with is bias_regularizer. So I tried doing the following: But I still see the bias values are not zero. Is there any other method to achieve this?,https://stackoverflow.com/questions/58644349,6997665,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,From the documentation the only variable that is available to play with is bias_regularizer.
58871822,How to combine multiple output in tensorflow to create a metric?,"<p>I am working on a multi-task neural net which has two outputs, a segmentation ""mask"" and a classification ""label"":</p>

<pre><code>inputs = tf.keras.Input(shape=(352, 512, 3), name='image')
outputs = base_model(inputs)

mask = tf.keras.layers.Conv2D(4, (3,3), strides=1, padding='same', activation='sigmoid', name='mask')(outputs)

label = tf.keras.layers.GlobalAveragePooling2D()(outputs)
label = tf.keras.layers.Dense(4, activation='sigmoid', name='label')(label)
model = tf.keras.models.Model(inputs, [mask, label])
</code></pre>

<p>From this model I obtain one prediction ""mask"" and one prediction ""label"". The question is: I want to create a metric such that it only evaluates the dice coefficient of ""mask"" when the corresponding ""label"" > 0.5.</p>

<p>I have been searching this for quite a while and from tensorflow official site I can only find how to calculate metrics for each output, but no documentation on how to access all the predictions and combine them.</p>

<pre><code>metrics = {'mask': [dice_coef(threshold=0.5)],
        'label': [tf.keras.metrics.binary_accuracy]}
</code></pre>

<p>here each metric only accept two arguments (y_true, y_pred).</p>

<p>Update:</p>

<p>I have figured out a work around myself, instead of combining results in the metrics, I added one lambda layer in the network and added one more output</p>

<pre><code>inputs = tf.keras.Input(shape=(352, 512, 3), name='image')
outputs = base_model(inputs)

mask = tf.keras.layers.Conv2D(4, (3,3), strides=1, padding='same', activation='sigmoid', name='mask')(outputs)

label = tf.keras.layers.GlobalAveragePooling2D()(outputs)
label = tf.keras.layers.Dense(4, activation='sigmoid', name='label')(label)

label_exp = tf.keras.layers.Lambda(lambda label: tf.cast(tf.math.greater(label, 0.5), tf.float32))(label)
label_exp = tf.keras.layers.Reshape([1,1,4])(label_exp)
filtered = tf.keras.layers.Multiply(name='filtered')([mask, label_exp])

model = tf.keras.models.Model(inputs, [mask, filtered, label])
</code></pre>

<p>And the metrics now is set to be:</p>

<pre><code>metrics = {'mask': [dice_coef(threshold=0.5)],
            'filtered': [dice_coef(threshold=0.5)],
            'label': [tf.keras.metrics.binary_accuracy]}
</code></pre>

<p>This works but seems like will cost additional memory. Still looking for a neat solution...</p>
","I am working on a multi-task neural net which has two outputs, a segmentation ""mask"" and a classification ""label"": From this model I obtain one prediction ""mask"" and one prediction ""label"". The question is: I want to create a metric such that it only evaluates the dice coefficient of ""mask"" when the corresponding ""label"" &gt; 0.5. I have been searching this for quite a while and from tensorflow official site I can only find how to calculate metrics for each output, but no documentation on how to access all the predictions and combine them. here each metric only accept two arguments (y_true, y_pred). Update: I have figured out a work around myself, instead of combining results in the metrics, I added one lambda layer in the network and added one more output And the metrics now is set to be: This works but seems like will cost additional memory. Still looking for a neat solution...",https://stackoverflow.com/questions/58871822,12376581,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I have been searching this for quite a while and from tensorflow official site I can only find how to calculate metrics for each output, but no documentation on how to access all the predictions and combine them."
60269407,Simpler way to avoid the UserWarning: Converting sparse IndexedSlices,"<p>I have a rnn network structure that looks like following</p>

<pre><code>        cells = rnn.MultiRNNCell(
            [self._one_rnn_cell(l + 1) for l in range(self.layers)],
            state_is_tuple=True
        ) if self.layers &gt; 1 else self._one_rnn_cell(1)


        out, _ = tf.nn.dynamic_rnn(cells, self.inputs,
                                   dtype=tf.float32, scope=""DyRNN"")
        out = tf.transpose(out, [1, 0, 2])
        num_time_steps = int(out.get_shape()[0])
        last_state = tf.gather(out, num_time_steps - 1, name=""last_lstm_state"")
</code></pre>

<p>Here while I am running the code, I am getting the following warning.</p>

<blockquote>
  <p>UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
    ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""</p>
</blockquote>

<p>Now I understand why this error is coming. I tried out several ideas and the most common one is the following</p>

<p><a href=""https://stackoverflow.com/questions/45882401/how-to-deal-with-userwarning-converting-sparse-indexedslices-to-a-dense-tensor"">How to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape</a></p>

<p>But the problem is this requires too many variable like </p>

<p>max_length
time_steps
seq_length
n_dim
partitions</p>

<p>this make the code very unreadable. I wanted to know if there is a simpler way I can avoid the problem.</p>

<p>Also if the sequence length remain same across all the batches, can I assume <code>max_length == time_steps == seq_length</code> ?</p>

<p>Please help, documentation is very less.</p>
","I have a rnn network structure that looks like following Here while I am running the code, I am getting the following warning. Now I understand why this error is coming. I tried out several ideas and the most common one is the following How to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape But the problem is this requires too many variable like max_length time_steps seq_length n_dim partitions this make the code very unreadable. I wanted to know if there is a simpler way I can avoid the problem. Also if the sequence length remain same across all the batches, can I assume max_length == time_steps == seq_length ? Please help, documentation is very less.",https://stackoverflow.com/questions/60269407,4037927,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation," Please help, documentation is very less."
60418931,How to create a custom pyfunc to make predictions using a model that requires an input shape with more than two dimensions using MLflow?,"<p>I'm new to TensorFlow and MLFlow and I have a similar problem to the one asked in <a href=""https://stackoverflow.com/questions/58917918/how-to-make-predictions-using-a-model-that-requires-an-input-shape-with-more-tha/60416642#60416642"">here</a>. I am implementing a TensorFlow model to predict timeseries values. With that aim, I used MLFlow's mlflow.tensorflow.autolog() to track and serve the models in my instance. Nevertheless, since my input shape has more than 2 dimensions, I was not able to use that method. </p>

<p>As previously <a href=""https://stackoverflow.com/a/60129726/8338272"">suggested</a>, I've tried to encode/decode the input data in prediction by using a custom pyfunc to do it. </p>

<p>In this way, I have a function <em>model_test.py</em> with a predict method that decode its input data that is:</p>

<pre class=""lang-py prettyprint-override""><code>import sys
import os
import json
import mlflow
import numpy as np
import pandas as pd
from mlflow.pyfunc import PythonModel
import tensorflow as tf
import base64



class ModelTest(PythonModel):

    def __init__(self, estimator=None,window_size = 64,batch_size = 256,shuffle_buffer_size = 100):
        # CODE TO CREATE THE EXPERIMENT
        self.window_size = window_size
        self.batch_size = batch_size
        self.shuffle_buffer_size = shuffle_buffer_size

    def windowed_dataset(self,series, window_size, batch_size, shuffle_buffer):
            series = tf.expand_dims(series, axis=-1)
            ds = tf.data.Dataset.from_tensor_slices(series)
            ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
            ds = ds.flat_map(lambda w: w.batch(window_size + 1))
            ds = ds.shuffle(shuffle_buffer)
            ds = ds.map(lambda w: (w[:-1], w[1:]))
            self.windowed_ds = ds.batch(batch_size).prefetch(1)
            return self

    def train(self, train_set, y = None, epochs = 500):

        model = tf.keras.models.Sequential([
                  tf.keras.layers.Conv1D(filters=60, kernel_size=5,
                                      strides=1, padding=""causal"",
                                      activation=""relu"",
                                      input_shape=[None, 1]),
                  tf.keras.layers.LSTM(60, return_sequences=True),
                  tf.keras.layers.Dense(10, activation=""relu""),
                  tf.keras.layers.Dense(1),
                  tf.keras.layers.Lambda(lambda x: x * 400)
                ])
        optimizer = tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9)
        model.compile(loss=tf.keras.losses.Huber(),optimizer=optimizer,metrics=[""mae""])
        model.fit(x=train_set, y=y,epochs=5)
        self.modelo = model

        return self

    def predict(self, series_encoded):
        # Decode the data that arrives to the method
        def decode_ts(x):
            return pd.Series(np.frombuffer(base64.b64decode(x)))
        series_decode = decode_ts(series_encoded)
        # Preprocess data
        series = np.expand_dims(series_decode, axis=1)
        ds = tf.data.Dataset.from_tensor_slices(series)
        # Replace the number by a variable window_size
        ds = ds.window(60, shift=1, drop_remainder=True)
        # Replace the number by a variable window_size
        ds = ds.flat_map(lambda w: w.batch(60))
        ds = ds.batch(32).prefetch(1)
        # Prediction
        forecast = self.modelo.predict(ds)

        return forecast
</code></pre>

<p>And a <em>run.py</em> file to train and save the model:</p>

<pre class=""lang-py prettyprint-override""><code>import os
import mlflow.pyfunc
import ModelTest as model_test
import sys
import json
import mlflow
import numpy as np
from pymongo import MongoClient
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import Preprocessing as pre

#@click(...) # define the click options according to MLproject file
def run():
    # Code to load time series data from MongoDB and preprocess it

    window_size = 64
    batch_size = 256
    shuffle_buffer_size = 100
    split_time = 400

    series = np.array(data_df['sensor_ts'])
    time = np.array(data_df['time'])
    time_train = time[:split_time]
    x_train = series[:split_time]
    time_valid = time[split_time:]
    x_valid = series[split_time:]


    modelo = modelo_tercero.ModelTest()
    modelo.windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)

    with mlflow.start_run() as run:
        model = modelo.train(modelo.windowed_ds)
        model_path = os.path.join('models', run.info.run_id)

        # Save model
        mlflow.pyfunc.save_model(
            path=model_path,
            python_model= modelo.train(modelo.windowed_ds),
            code_path=['Modelthird.py'],
            conda_env={
                'channels': ['defaults', 'conda-forge'],
                'dependencies': [
                    'mlflow=1.6.0',
                    'numpy=1.18.1',
                    'tensorflow=2.1.0',
                    'pandas=0.25.3',
                    'python=3.7.6',
                    'cloudpickle==0.5.8'
                ],
                'name': 'mlflow-env'
            }
        )


if __name__ == ""__main__"":
    run()

</code></pre>

<p>When I execute the run.py I get the next errors when the model is going to be saved:</p>

<pre><code> Traceback (most recent call last):

File ""run.py"", line 116, in &lt;module&gt;
    run()
  File ""run.py"", line 110, in run
    'name': 'mlflow-env'
  File ""/opt/conda/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py"", line 596, in save_model
    code_paths=code_path, mlflow_model=mlflow_model)
  File ""/opt/conda/lib/python3.7/site-packages/mlflow/pyfunc/model.py"", line 141, in _save_model_with_class_artifacts_params
    cloudpickle.dump(python_model, out)
  File ""/opt/conda/lib/python3.7/site-packages/cloudpickle/cloudpickle.py"", line 1109, in dump
    CloudPickler(file, protocol=protocol).dump(obj)
  File ""/opt/conda/lib/python3.7/site-packages/cloudpickle/cloudpickle.py"", line 482, in dump
    return Pickler.dump(self, obj)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 437, in dump
    self.save(obj)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 662, in save_reduce
    save(state)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File ""/opt/conda/lib/python3.7/pickle.py"", line 859, in save_dict
    self._batch_setitems(obj.items())
  File ""/opt/conda/lib/python3.7/pickle.py"", line 885, in _batch_setitems
    save(v)
  File ""/opt/conda/lib/python3.7/pickle.py"", line 524, in save
    rv = reduce(self.proto)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 873, in __reduce__
    return convert_to_tensor, (self._numpy(),)
  File ""/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 910, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""&lt;string&gt;"", line 3, in raise_from
</code></pre>

<p>I have looked at different documentation related to save and serialize TensorFlow models, but there is not so much documentation about TensorFlow models and custom pyfunc functions in MLFlow. Could anyone help me or give me any hint?</p>

<p>Thanks in advance!! :D</p>
","I'm new to TensorFlow and MLFlow and I have a similar problem to the one asked in here. I am implementing a TensorFlow model to predict timeseries values. With that aim, I used MLFlow's mlflow.tensorflow.autolog() to track and serve the models in my instance. Nevertheless, since my input shape has more than 2 dimensions, I was not able to use that method. As previously suggested, I've tried to encode/decode the input data in prediction by using a custom pyfunc to do it. In this way, I have a function model_test.py with a predict method that decode its input data that is: And a run.py file to train and save the model: When I execute the run.py I get the next errors when the model is going to be saved: I have looked at different documentation related to save and serialize TensorFlow models, but there is not so much documentation about TensorFlow models and custom pyfunc functions in MLFlow. Could anyone help me or give me any hint? Thanks in advance!! :D",https://stackoverflow.com/questions/60418931,8338272,Documentation Completeness,Lack of Alternative Solutions/Documentation,"I have looked at different documentation related to save and serialize TensorFlow models, but there is not so much documentation about TensorFlow models and custom pyfunc functions in MLFlow."
60463215,Can we use Microsoft TensorFlow as regular TensorFlow?,"<p>Most of the tutorials/guides I found on Microsoft ML are for sentiment analysis or image classification. For my project I need to use TensorFlow functions like it can be with Python. As TensorFlow nuget package is available I'm wondering if this can be used as original TensorFlow alternative. Asking reason of this question here is - I could not find a guide or documentation on this.</p>

<p>I can import TensorFlow after getting it from nuget package manager. But I can't access its regular methods or constants like it can be with Python.</p>

<p>The following code is valid:</p>

<pre><code>using System;
using Tensorflow;

namespace TF_Tests
{
    class Program
    {
        static void Main(string[] args)
        {
            var a = TensorInfo.Descriptor;

            Console.WriteLine(""Hello World! ""+a);
        }
    }
}
</code></pre>

<p>TensorFlow can be imported, but how can I use it in a regular way? For example: </p>

<pre><code>c = tf.strings.unicode_split(a, 'UTF-8').to_list() //how to access such method or atleast declare a constant?

print(c[0].__len__())

for i in c[0]:
    print(i)
</code></pre>
","Most of the tutorials/guides I found on Microsoft ML are for sentiment analysis or image classification. For my project I need to use TensorFlow functions like it can be with Python. As TensorFlow nuget package is available I'm wondering if this can be used as original TensorFlow alternative. Asking reason of this question here is - I could not find a guide or documentation on this. I can import TensorFlow after getting it from nuget package manager. But I can't access its regular methods or constants like it can be with Python. The following code is valid: TensorFlow can be imported, but how can I use it in a regular way? For example:",https://stackoverflow.com/questions/60463215,7291498,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I could not find a guide or documentation on this.
60876340,How can I save a trained TensorFlow Federated model as a .h5 model?,"<p>I want to save a TensorFlow federated model which was trained with the FedAvg Algorithm as a Keras/.h5 model. I couldn't find the documents on this and would like to know how it may be done.
Also if possible, I'd like to have access to both the aggregated server model and the models of the clients.</p>

<p>The code I use to train the federated model is below:</p>

<pre><code>def model_fn():
    model = tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(segment_size,num_input_channels)),
      tf.keras.layers.Flatten(), 
      tf.keras.layers.Dense(units=400, activation='relu'),
      tf.keras.layers.Dropout(dropout_rate),
      tf.keras.layers.Dense(units=100, activation='relu'),
      tf.keras.layers.Dropout(dropout_rate),
      tf.keras.layers.Dense(activityCount, activation='softmax'),
    ])
    return tff.learning.from_keras_model(
      model,
      dummy_batch=batch,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
trainer = tff.learning.build_federated_averaging_process(
    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learningRate))

def evaluate(num_rounds=communicationRound):
  state = trainer.initialize()
  roundMetrics = []
  evaluation = tff.learning.build_federated_evaluation(model_fn)

  for round_num in range(num_rounds):
    t1 = time.time()
    state, metrics = trainer.next(state, train_data)
    t2 = time.time()
    test_metrics = evaluation(state.model, train_data)

    roundMetrics.append('round {:2d}, metrics={}, loss={}'.format(round_num, metrics.sparse_categorical_accuracy , metrics.loss))
    roundMetrics.append(""The test accuracy is "" + str(test_metrics.sparse_categorical_accuracy))
    roundMetrics.append('round time={}'.format(t2 - t1))
    print('round {:2d}, accuracy={}, loss={}'.format(round_num, metrics.sparse_categorical_accuracy , metrics.loss))
    print(""The test accuracy is "" + str(test_metrics.sparse_categorical_accuracy))
    print('round time={}'.format(t2 - t1))
  outF = open(filepath+'stats'+architectureType+'.txt', ""w"")
  for line in roundMetrics:
    outF.write(line)
    outF.write(""\n"")
  outF.close()
</code></pre>
","I want to save a TensorFlow federated model which was trained with the FedAvg Algorithm as a Keras/.h5 model. I couldn't find the documents on this and would like to know how it may be done. Also if possible, I'd like to have access to both the aggregated server model and the models of the clients. The code I use to train the federated model is below:",https://stackoverflow.com/questions/60876340,12992742,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I couldn't find the documents on this and would like to know how it may be done.
61761477,What's the use for converter.build() in TensorRT?,"<p>The <a href=""https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html"" rel=""nofollow noreferrer"">official documentation on TensorRT</a> lists two ways to convert a TensorFlow SavedModel into a TensorRT SavedModel: the first is </p>

<pre class=""lang-py prettyprint-override""><code>from tensorflow.python.compiler.tensorrt import trt_convert as trt
converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir)
converter.convert()
converter.save(output_saved_model_dir)
</code></pre>

<p>and the second is </p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt

conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS
conversion_params = conversion_params._replace(
    max_workspace_size_bytes=(1&lt;&lt;32))
conversion_params = conversion_params._replace(precision_mode=""FP16"")
conversion_params = conversion_params._replace(
    maximum_cached_engiens=100)

converter = trt.TrtGraphConverterV2(
    input_saved_model_dir=input_saved_model_dir,
    conversion_params=conversion_params)
converter.convert()
def my_input_fn():
  for _ in range(num_runs):
    Inp1 = np.random.normal(size=(8, 16, 16, 3)).astype(np.float32)
    inp2 = np.random.normal(size=(8, 16, 16, 3)).astype(np.float32)
    yield inp1, inp2
converter.build(input_fn=my_input_fn)
converter.save(output_saved_model_dir)

saved_model_loaded = tf.saved_model.load(
    output_saved_model_dir, tags=[tag_constants.SERVING])
graph_func = saved_model_loaded.signatures[
    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
frozen_func = convert_to_constants.convert_variables_to_constants_v2(
    graph_func)
output = frozen_func(input_data)[0].numpy()
</code></pre>

<p>Stripping out all of the boilerplate code for imports, inference etc the difference seems to lie in the call to <code>converter.build()</code>. The documentation explains this function as such:</p>

<p>""This method optimizes the converted function (returned by convert()) by building TensorRT engines. This is useful in case the user wants to perform the optimizations before runtime. The optimization is done by running inference on the converted function using the input data received from the argument input_fn. This argument is a generator function that yields input data as a list or tuple. ""</p>

<p>What does ""before runtime"" mean in this context? Will the ""optimizations"" be performed upon model loading, upon the first inference, or upon every single inference using the converted model? What <em>are</em> those optimizations, even? Isn't converting the model to TensorRT an optimization in itself?</p>

<p>I am asking because if I call <code>converter.build()</code> the conversion seems to fail in unpredictable ways after taking a LOT of time (more than two hours) to run without producing any sensible output, so I was wondering how much am I losing by not calling it and whether there is more comprehensive documentation on using TF2.x SavedModels with TensorRT. </p>

<p>Thanks in advance to whoever can answer!!</p>
","The official documentation on TensorRT lists two ways to convert a TensorFlow SavedModel into a TensorRT SavedModel: the first is and the second is Stripping out all of the boilerplate code for imports, inference etc the difference seems to lie in the call to converter.build(). The documentation explains this function as such: ""This method optimizes the converted function (returned by convert()) by building TensorRT engines. This is useful in case the user wants to perform the optimizations before runtime. The optimization is done by running inference on the converted function using the input data received from the argument input_fn. This argument is a generator function that yields input data as a list or tuple. "" What does ""before runtime"" mean in this context? Will the ""optimizations"" be performed upon model loading, upon the first inference, or upon every single inference using the converted model? What are those optimizations, even? Isn't converting the model to TensorRT an optimization in itself? I am asking because if I call converter.build() the conversion seems to fail in unpredictable ways after taking a LOT of time (more than two hours) to run without producing any sensible output, so I was wondering how much am I losing by not calling it and whether there is more comprehensive documentation on using TF2.x SavedModels with TensorRT. Thanks in advance to whoever can answer!!",https://stackoverflow.com/questions/61761477,5623016,Documentation Ambiguity,Lack of Alternative Solutions/Documentation,I was wondering how much am I losing by not calling it and whether there is more comprehensive documentation on using TF2.x SavedModels with TensorRT.
62309757,"tf.data.Dataset.from_generator - TypeError: If shallow structure is a sequence, input must also be a sequence","<p>I am trying to build a generator function that will take multiple inputs and outputs to pass to a model using a series of memory mapped numpy arrays (larger than available RAM). All preprocessing has already been performed and I just need to access these arrays in batches.</p>

<pre><code>def generator_function(input1, input2, input3, input4, input5, input6, label1, label2):

    def generator():
        for input1, input2, input3, input4, input5, input6, label1, label2 in zip(input1, input2, input3, input4, input5, input6, label1, label2):
            yield {""x1_train_data"": input1, 
                   ""x2_train_data"": input2, 
                   ""x3_train_data"": input3, 
                   ""x4_train_data"": input4,
                   ""x5_train_data"": input5,
                   ""x6_train_data"": input6}, {""x1_train_label"": label1, ""x2_train_label"": label2}

    dataset = tf.data.Dataset.from_generator(generator, 
                                             output_types=({""x1_train_data"": tf.float32, 
                                                            ""x2_train_data"": tf.float32,
                                                            ""x3_train_data"": tf.float32,
                                                            ""x4_train_data"": tf.float32,
                                                            ""x5_train_data"": tf.int64,
                                                            ""x6_train_data"": tf.float32},{""x1_train_label"": tf.int64, ""x2_train_label"": tf.int64}),
                                            output_shapes=tf.TensorShape([50,150,150, 150, 150,9, 1,5]))
    dataset = dataset.batch(2)
    return dataset
</code></pre>

<p>When I attempt to fit the model:</p>

<pre><code>model.fit(generator_function(np_array1, np_array2, np_array3, np_array4, mp_array5, np_array6, np_array7, np_array8), epochs=10)
</code></pre>

<p>I get the following error:</p>

<pre><code>TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: &lt;class 'tensorflow.python.framework.tensor_shape.TensorShape'&gt;.
</code></pre>

<p>I've tried referring the official documentation and other SO posts but haven't been able to find a solution that used both multiple inputs and multiple labels. </p>
",I am trying to build a generator function that will take multiple inputs and outputs to pass to a model using a series of memory mapped numpy arrays (larger than available RAM). All preprocessing has already been performed and I just need to access these arrays in batches. When I attempt to fit the model: I get the following error: I've tried referring the official documentation and other SO posts but haven't been able to find a solution that used both multiple inputs and multiple labels.,https://stackoverflow.com/questions/62309757,4613042,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I've tried referring the official documentation and other SO posts but haven't been able to find a solution that used both multiple inputs and multiple labels.
63253714,"What numbers go into DCGAN Generator models, in order to produce larger images","<p>I really have tried to do my due diligence here but I can't find a lot of documentation on why certain numbers are chosen. I'm also fairly hazy on how convolutions work in generators (have a better understanding in terms of classifiers) so that's not helping my case. I think my question should be pretty simple to address for some more experiences folks out there though.</p>
<p>Take Google's tutorial for example, the Generator class:</p>
<pre><code>def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((7, 7, 256)))
    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 7, 7, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 14, 14, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 28, 28, 1)

    return model
</code></pre>
<p>Where is 7x7x256 coming from? I understand that 7x7 is a multiple of the eventual 28x28 size, so that makes sense somewhat, but what is the 256 all about? And then in the following layers, I notice a pattern but I'm not sure how to re-write it so it works for a wholly different image size. Any help or direction is appreciated.Thanks!</p>
<p>EDIT:
Thanks to the helpful input I changed my gen to:</p>
<pre><code>def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((8, 8, 256)))
    assert model.output_shape == (None, 8, 8, 256) # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 8, 8, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 16, 16, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 32, 32, 32)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 64, 64, 16)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(8, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 128, 128, 8)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 256, 256, 3)

    return model
</code></pre>
<p>and discriminator:</p>
<pre><code>def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(8, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[IMAGE_DIM[0], IMAGE_DIM[1], IMAGE_DIM[2]]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    print(model.output_shape)

    model.add(layers.Conv2D(16, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    print(model.output_shape)

    model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    print(model.output_shape)

    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    print(model.output_shape)

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    print(model.output_shape)

    model.add(layers.Conv2D(256, (5, 5), strides=(1, 1), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    print(model.output_shape)

    model.add(layers.Flatten())
    model.add(layers.Dense(1))
    #16384 65536
    return model
</code></pre>
","I really have tried to do my due diligence here but I can't find a lot of documentation on why certain numbers are chosen. I'm also fairly hazy on how convolutions work in generators (have a better understanding in terms of classifiers) so that's not helping my case. I think my question should be pretty simple to address for some more experiences folks out there though. Take Google's tutorial for example, the Generator class: Where is 7x7x256 coming from? I understand that 7x7 is a multiple of the eventual 28x28 size, so that makes sense somewhat, but what is the 256 all about? And then in the following layers, I notice a pattern but I'm not sure how to re-write it so it works for a wholly different image size. Any help or direction is appreciated.Thanks! EDIT: Thanks to the helpful input I changed my gen to: and discriminator:",https://stackoverflow.com/questions/63253714,1135125,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I really have tried to do my due diligence here but I can't find a lot of documentation on why certain numbers are chosen.
63574871,How to get the Keras history object when you abort training?,"<p>When I train with tensorflow 2.0 / Keras APIs, I usually do something like this</p>
<pre><code>model = tf.keras.Model(inputs, outputs)
history = model.fit(x, y, batch_size=64, epochs=10)
</code></pre>
<p>But sometimes things in life don't work out how I planned and I need to abort with ctrl-c or pressing stop in Jupyter notebook.
How can I still get the history object when I abort training early? I can't find any detailed documentation for how to get history.</p>
","When I train with tensorflow 2.0 / Keras APIs, I usually do something like this But sometimes things in life don't work out how I planned and I need to abort with ctrl-c or pressing stop in Jupyter notebook. How can I still get the history object when I abort training early? I can't find any detailed documentation for how to get history.",https://stackoverflow.com/questions/63574871,8202708,Documentation Completeness,Lack of Alternative Solutions/Documentation, I can't find any detailed documentation for how to get history.
65922990,"Nan losses using ""Learning Rate Step Decay"" Scheduler with Adam Optimizer in Keras?","<p>I have this very deep model:</p>
<pre><code>def get_model2(mask_kind):

decay = 0.0

    inp_1 = keras.Input(shape=(64, 101, 1), name=&quot;RST_inputs&quot;)
    x = layers.Conv2D(256, kernel_size=(3, 3), kernel_regularizer=l2(1e-6), strides=(3, 3), padding=&quot;same&quot;)(inp_1)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Conv2D(128, kernel_size=(3, 3), kernel_regularizer=l2(1e-6), strides=(3, 3), padding=&quot;same&quot;)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Conv2D(64, kernel_size=(2, 2), kernel_regularizer=l2(1e-6), strides=(2, 2), padding=&quot;same&quot;)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Conv2D(32, kernel_size=(2, 2), kernel_regularizer=l2(1e-6), strides=(2, 2), padding=&quot;same&quot;)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Flatten()(x)
    x = layers.Dense(512)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Dense(256)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    out1 = layers.Dense(128, name=&quot;ls_weights&quot;)(x)

    if mask_kind == 1:  # APPLICA LA PRIMA MASCHERA
        binary_mask = layers.Lambda(mask_layer1, name=&quot;lambda_layer1&quot;, dtype='float64')(out1)
        print('shape', binary_mask.shape[0])
    elif mask_kind == 2:  # APPLICA LA SECONDA MASCHERA
        binary_mask = layers.Lambda(mask_layer2, name=&quot;lambda_layer2&quot;, dtype='float64')(out1)
    else:  # NON APPLICA NULLA
        binary_mask = out1

    x = layers.Dense(256)(binary_mask)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Dense(512)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Dense(192)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Reshape((2, 2, 48))(x)
    x = layers.Conv2DTranspose(32, kernel_size=(2, 2), strides=(2, 2), padding=&quot;same&quot;)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=(3, 3), padding=&quot;same&quot;)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Conv2DTranspose(128, kernel_size=(3, 3), strides=(3, 3), padding=&quot;same&quot;)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    x = layers.Conv2DTranspose(256, kernel_size=(3, 3), strides=(5, 5), padding=&quot;same&quot;)(x)
    x = layers.LeakyReLU(alpha=0.3)(x)
    soundfield_layer = layers.Conv2DTranspose(1, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)
    # soundfield_layer = layers.Dense(40000, name=&quot;sf_vec&quot;)(x)

    if mask_kind == 1:
        model = keras.Model(inp_1, [binary_mask, soundfield_layer], name=&quot;2_out_model&quot;)
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1, decay=decay),  # in caso
                      # rimettere 0.001
                      loss=[&quot;mse&quot;, &quot;mse&quot;], loss_weights=[1, 1])
        # plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)
        model.summary()

    else:
        model = keras.Model(inp_1, [binary_mask, soundfield_layer], name=&quot;2_out_model&quot;)
        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1, decay=decay),  # in caso
                      # rimettere 0.001
                      loss=[&quot;mse&quot;, &quot;mse&quot;], loss_weights=[0, 1])
        # plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)
        model.summary()

    return model
</code></pre>
<p>and I'm trying to use Learning rate Step Decay to see if I can improve my validation loss function during training. I'm defining the class for the scheduler as follows:</p>
<pre><code>class StepDecay:
    def __init__(self, initAlpha=0.1, factor=0.25, dropEvery=30):
        # store the base initial learning rate, drop factor, and
        # epochs to drop every
        self.initAlpha = initAlpha
        self.factor = factor
        self.dropEvery = dropEvery
    
    def __call__(self, epoch):
        # compute the learning rate for the current epoch
        exp = np.floor((1 + epoch) / self.dropEvery)
        alpha = self.initAlpha * (self.factor ** exp)
        # return the learning rate
        return float(alpha)
</code></pre>
<p>and then I run my training:</p>
<pre><code>schedule = StepDecay(initAlpha=1e-1, factor=0.25, dropEvery=30)
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)
callbacks = [es, LearningRateScheduler(schedule)]

model = get_model2(mask_kind=1)

history = model.fit(X_train, [Y_train, Z_train], validation_data=(X_val, [Y_val, Z_val]), epochs=300,
                    batch_size=32,
                    callbacks=callbacks, verbose=1)

test_loss, _, _ = model.evaluate(X_test, [Y_test, Z_test], verbose=1)
print('Test: %.3f' % test_loss)
</code></pre>
<p>but when I train I get &quot;nan&quot; losses:</p>
<pre><code>25/25 [==============================] - 17s 684ms/step - loss: nan - lambda_layer1_loss: nan - conv2d_transpose_4_loss: nan - val_loss: nan - val_lambda_layer1_loss: nan etc....
</code></pre>
<p>and I don't understand why. The problem could be the decay rate which is a parameter present in the SGD optimizer but that from the documentation does not exists for Adam, but I get no error that so..any ideas?</p>
","I have this very deep model: and I'm trying to use Learning rate Step Decay to see if I can improve my validation loss function during training. I'm defining the class for the scheduler as follows: and then I run my training: but when I train I get ""nan"" losses: and I don't understand why. The problem could be the decay rate which is a parameter present in the SGD optimizer but that from the documentation does not exists for Adam, but I get no error that so..any ideas?",https://stackoverflow.com/questions/65922990,12863152,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,The problem could be the decay rate which is a parameter present in the SGD optimizer but that from the documentation does not exists for Adam
66477586,Loading Custom Data into TensorFlow with .get_file(),"<p>I'm relatively new to Tensor Flow and Stack overflow, so please be patient. My question is as follows: 'How do I load in a custom dataset spreadsheet into TensorFlow using the .get_file() method and pandas read method?' I  have searched the TensorFlow website, stack overflow, and other websites but they all seem to either use publically available data online or do some strange imports with different methods that I do not understand. Here is what I currently have:</p>
<pre><code>import tensorflow as tf
import pandas as pd


CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']
SPECIES = ['Setosa', 'Versicolor', 'Virginica']
# This is just some flower data online

train_path = tf.keras.utils.get_file(
    &quot;iris_training.csv&quot;, &quot;https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv&quot;)
test_path = tf.keras.utils.get_file(
    &quot;iris_test.csv&quot;, &quot;https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv&quot;)
    # I have a spreadsheet on my machine with the exact same data. I want to use those files instead

train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)
test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)
# Here I am reading a csv file inputting the data, labels, and defining header. Should I use pd.read_excel instead because the files on my machine are excel files?

train_y = train.pop('Species')
test_y = test.pop('Species') # removes answers/thing to predict and test against
</code></pre>
<p>Thank you so much for reading!</p>
","I'm relatively new to Tensor Flow and Stack overflow, so please be patient. My question is as follows: 'How do I load in a custom dataset spreadsheet into TensorFlow using the .get_file() method and pandas read method?' I have searched the TensorFlow website, stack overflow, and other websites but they all seem to either use publically available data online or do some strange imports with different methods that I do not understand. Here is what I currently have: Thank you so much for reading!",https://stackoverflow.com/questions/66477586,15290446,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I have searched the TensorFlow website, stack overflow, and other websites but they all seem to either use publically available data online or do some strange imports with different methods that I do not understand."
68651758,Printing outcome probabilities from a trained Keras Model,"<p>I am attempting to print the predicted probabilities of each class outcome from my trained model, when I present <strong>new</strong> raw data. This is a multi-class classification problem, with 8 outputs and 21 inputs.</p>
<p>I am able to print 1 outcome when I present new data, for example:</p>
<pre><code> &quot;Example 0 prediction: 1 (15.0%)&quot;
</code></pre>
<p>Instead, I would expect to see something similar to the below. Where the probabilities of each class (0, 1, 2, 3, 4, 6, Wide, Out) are shown:</p>
<pre><code>Example 0 prediction 0: (12.5%), prediction 1: (12.5%), prediction 2: (12.5%), prediction 3: (12.5%), prediction 4: (12.5%), prediction 6: (12.5%), prediction Wide: (12.5%), prediction Out: (12.5%)
</code></pre>
<p>Please note I have tried searching for similar issues including  <a href=""https://stackoverflow.com/questions/47599436/returning-probabilities-in-a-classification-prediction-in-keras"">here</a>, <a href=""https://stackoverflow.com/questions/50555434/keras-model-to-predict-probability-distribution"">here</a> and <a href=""https://stackoverflow.com/questions/48217119/keras-get-probability-per-each-class"">here</a> as well as consulted the TensorFlow documentation. However, these mainly discuss alterations to the model itself e.g. softmax activation on the final layer, categorical crossentropy as the loss function etc. so that probabilities are generated.</p>
<p>I have included the model architecture as well as the prediction code for full visibility.</p>
<p>Model:</p>
<pre><code>earlystopping = callbacks.EarlyStopping(monitor =&quot;val_loss&quot;, 
                                        mode =&quot;min&quot;, patience = 125, 
                                        restore_best_weights = True)
  
#define Keras
model = Sequential()
model.add(Dense(50, input_dim=21))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.5,input_shape=(50,)))
model.add(Dense(50))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.5,input_shape=(50,)))
model.add(Dense(8, activation='softmax'))

#compile the keras model
model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])   

model.fit(X, dummy_y, validation_split=0.25, epochs=1000, batch_size=100, verbose=1, callbacks=[earlystopping])

_, accuracy3 = model.evaluate(X, dummy_y, verbose=0)
print('Accuracy: %.2f' % (accuracy3*100))
</code></pre>
<p>Making predictions:</p>
<pre><code>class_names = ['0', '1', '2','3','4','6','Wide','Out']

predict_dataset = tf.convert_to_tensor([
  [1,5,1,0.459,0.322,0.041,0.002,0.103,0.032,0.041,14,0.404,0.284,0.052,0.008,0.128,0.044,0.037,0.043,54,0,],
    [1,18,5,0.512,0.286,0,0,0.083,0.024,0.095,13,0.24,0.44,0.08,0,0.08,0.08,0,0.08,173,3],
    [2,11,13,0.5,0.417,0,0,0.083,0,0.083,82,0.35,0.36,0.042,0.003,0.135,0.039,0.051,0.02,51,7]
])  

predictions = model(predict_dataset, training=False)

for i, logits in enumerate(predictions):
    class_idx = tf.argmax(logits).numpy()
    p = tf.nn.softmax(logits)[class_idx]
    name = class_names[class_idx]
    print(&quot;Example {} prediction: {} ({:4.1f}%)&quot;.format(i, name,100*p))
</code></pre>
<p>Output:</p>
<pre><code>Example 0 prediction: 1 (15.0%)
Example 1 prediction: 1 (16.0%)
Example 2 prediction: 0 (16.9%)
</code></pre>
<p>I have tried making changes to the for loop which makes use of TensorFlow's logits, but I am still unable to get it to print each outcome and associated probability.</p>
<p>Any guidance is much appreciated.</p>
","I am attempting to print the predicted probabilities of each class outcome from my trained model, when I present new raw data. This is a multi-class classification problem, with 8 outputs and 21 inputs. I am able to print 1 outcome when I present new data, for example: Instead, I would expect to see something similar to the below. Where the probabilities of each class (0, 1, 2, 3, 4, 6, Wide, Out) are shown: Please note I have tried searching for similar issues including here, here and here as well as consulted the TensorFlow documentation. However, these mainly discuss alterations to the model itself e.g. softmax activation on the final layer, categorical crossentropy as the loss function etc. so that probabilities are generated. I have included the model architecture as well as the prediction code for full visibility. Model: Making predictions: Output: I have tried making changes to the for loop which makes use of TensorFlow's logits, but I am still unable to get it to print each outcome and associated probability. Any guidance is much appreciated.",https://stackoverflow.com/questions/68651758,16306039,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"Please note I have tried searching for similar issues including here, here and here as well as consulted the TensorFlow documentation. However, these mainly discuss alterations to the model itself e.g. softmax activation on the final layer, categorical crossentropy as the loss function etc"
69693757,Loading checkpoints while training a Faster-RCNN model on a custom dataset,"<p>I'm trying to load checkpoints and populate model weights using The Faster-RCNN architecture (<code>Faster R-CNN ResNet50 V1 640x640</code> to be precise, from <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"" rel=""noreferrer"">here</a>. I'm trying to load the weights for this network similar to how it's done in the <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb"" rel=""noreferrer"">example notebook for RetinaNet</a>, where they do the following:</p>
<pre class=""lang-py prettyprint-override""><code>fake_box_predictor = tf.compat.v2.train.Checkpoint(
    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,
    _box_prediction_head=detection_model._box_predictor._box_prediction_head,
)

fake_model = tf.compat.v2.train.Checkpoint(
          _feature_extractor=detection_model._feature_extractor,
          _box_predictor=fake_box_predictor
)

ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)
ckpt.restore(checkpoint_path).expect_partial()
</code></pre>
<p>I'm trying to get a similar checkpoint loading mechanism going for the Faster-RCNN network I want to use, but the properties like <code>_base_tower_layers_for_heads</code>, <code>_box_prediction_head</code> only exist for the architecture used in the example, and not for anything else.</p>
<p>I also couldn't find documentation on which parts of the model to populate using <code>Checkpoint</code> for my particular use case. Would greatly appreciate any help on how to approach this!</p>
","I'm trying to load checkpoints and populate model weights using The Faster-RCNN architecture (Faster R-CNN ResNet50 V1 640x640 to be precise, from here. I'm trying to load the weights for this network similar to how it's done in the example notebook for RetinaNet, where they do the following: I'm trying to get a similar checkpoint loading mechanism going for the Faster-RCNN network I want to use, but the properties like _base_tower_layers_for_heads, _box_prediction_head only exist for the architecture used in the example, and not for anything else. I also couldn't find documentation on which parts of the model to populate using Checkpoint for my particular use case. Would greatly appreciate any help on how to approach this!",https://stackoverflow.com/questions/69693757,6274300,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I also couldn't find documentation on which parts of the model to populate using Checkpoint for my particular use case.
70163993,Replace tf.const with tf.variable in frozen graph for re-train frozen graph,"<p>I got trouble to re-train frozen graph Due to Const in Graph
Actually I checked out many reference codes
like <a href=""https://stackoverflow.com/questions/67702185/retrain-frozen-graph-in-tensorflow-2-x"">this</a> and <a href=""https://stackoverflow.com/questions/53085007/re-train-a-frozen-pb-model-in-tensorflow"">this</a>
Tried everything but no lock for me.</p>
<p>My environment below</p>
<pre><code>python 3.7.7
TensorFlow 2.1.0
</code></pre>
<p>My code below</p>
<pre><code>  graph_def = optimize_graph(graph)
  
  graph = tf.Graph()
  with tf.compat.v1.Session(graph=graph):
      tf.graph_util.import_graph_def(graph_def, name='')
  
  g = graph
  to_convert = [op.name for op in g.get_operations() if op.type == &quot;Const&quot;]
  const_var_name_pairs = []

  with g.as_default():
      for name in to_convert:
          tensor = g.get_tensor_by_name('{}:0'.format(name))
          with tf.compat.v1.Session() as sess:
              tensor_as_numpy_array = sess.run(tensor_cast(tensor, tensor.dtype))
          var_name = '{}_turned_var'.format(name)
          var = tf.Variable(name=var_name, dtype=tensor.dtype, shape=tensor.get_shape(),
                      initial_value=tensor_as_numpy_array
                      )
          var.assign(tensor_as_numpy_array)
          const_var_name_pairs.append((name, var_name))
    
  ge_graph = ge.Graph(g.as_graph_def())

  for const_name, var_name in const_var_name_pairs:
      const_op = ge_graph._node_name_to_node[const_name]
      var_reader_op = ge_graph._node_name_to_node[var_name]
      ge.swap_outputs(ge.sgv(const_op), ge.sgv(var_reader_op))
  
  detection_training_graph = ge_graph.to_tf_graph()
</code></pre>
<p>The problem is,</p>
<pre><code>/var/folders/2d/pqn3pzcj0qs_t6_wgtmd8p9r0000gn/T/ipykernel_50693/993434432.py in load_graph_model_and_signature_with_swap(model_dir, compat_mode)
     66       #var_reader_op = name_to_op[var_name + '/Read/ReadVariableOp']
     67       #print(var_reader_op)
---&gt; 68       ge.swap_outputs(ge.sgv(const_op), ge.sgv(var_reader_op))
     69 
     70 

ValueError: Dtypes &lt;dtype: 'float32'&gt; and &lt;dtype: 'resource'&gt; of tensors Const:0 and Const_turned_var:0 are not compatible.
</code></pre>
<p>When I replace variable by using below code</p>
<pre><code>  for const_name, var_name in const_var_name_pairs:
      const_op = ge_graph._node_name_to_node[const_name]
      var_reader_op = ge_graph._node_name_to_node[var_name + '/Read/ReadVariableOp']
      ge.swap_outputs(ge.sgv(const_op), ge.sgv(var_reader_op))
</code></pre>
<p>The model is modified well but, I could not inference by using this model due to initialize problem</p>
<pre><code>FailedPreconditionError:  Error while reading resource variable Const_99_turned_var_load_43352 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/Const_99_turned_var_load_43352/N10tensorflow3VarE does not exist.
     [[node Const_99_turned_var/Read/ReadVariableOp (defined at var/folders/2d/pqn3pzcj0qs_t6_wgtmd8p9r0000gn/T/ipykernel_50693/3656424118.py:3) ]] [Op:__inference_pruned_44901]
</code></pre>
<p>I'm struggling few weeks, I never know how TensorFlow Graph has been working inside. There is no exact document about it also. I read every document on Tensorflow page relevant. Please help me out from the dark</p>
","I got trouble to re-train frozen graph Due to Const in Graph Actually I checked out many reference codes like this and this Tried everything but no lock for me. My environment below My code below The problem is, When I replace variable by using below code The model is modified well but, I could not inference by using this model due to initialize problem I'm struggling few weeks, I never know how TensorFlow Graph has been working inside. There is no exact document about it also. I read every document on Tensorflow page relevant. Please help me out from the dark",https://stackoverflow.com/questions/70163993,4457567,Documentation Completeness,Lack of Alternative Solutions/Documentation,There is no exact document about it also. I read every document on Tensorflow page relevant.
70365874,Validation_split with BatchDataset,"<p>I am trying to split my dataset into validation and training.
I was unable to call a validation subset in model.fit() as y data is not accepted for datasets, and the validation_split works only for tensors or numpy arrays. I checked the documentation for tensorflow, and there is no documentation of casting of BatchDataset to tensor, unless the neural network is altered itself, which I am unable to do as I am using the resnet architecture using keras.</p>
<p>The following errors showed up respectively:</p>
<pre><code> raise ValueError(&quot;`y` argument is not supported when using &quot;
ValueError: `y` argument is not supported when using dataset as input.

 raise ValueError(
ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [&lt;class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'&gt;]
</code></pre>
<p>Here is the code I am currently working on:</p>
<pre><code>test = tf.keras.preprocessing.image_dataset_from_directory(
  &quot;/Users/***/***/data-aug&quot;,
  labels=&quot;inferred&quot;,
  label_mode=&quot;categorical&quot;,
  color_mode=&quot;rgb&quot;,
  batch_size=32,
  image_size=(224, 224),
  shuffle=True,
  seed=123,
  interpolation=&quot;bilinear&quot;,
  follow_links=False,
  crop_to_aspect_ratio=True
)

H = model.fit(test,
              validation_split=0.2,
              epochs=200,
              shuffle=True,
              verbose=1,
              callbacks=[mc,es,pm])
</code></pre>
<p>Thank you for your time</p>
","I am trying to split my dataset into validation and training. I was unable to call a validation subset in model.fit() as y data is not accepted for datasets, and the validation_split works only for tensors or numpy arrays. I checked the documentation for tensorflow, and there is no documentation of casting of BatchDataset to tensor, unless the neural network is altered itself, which I am unable to do as I am using the resnet architecture using keras. The following errors showed up respectively: Here is the code I am currently working on: Thank you for your time",https://stackoverflow.com/questions/70365874,17280417,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I checked the documentation for tensorflow, and there is no documentation of casting of BatchDataset to tensor, unless the neural network is altered itself, which I am unable to do as I am using the resnet architecture using keras."
73853604,how to include image input to a transformer model?,"<p>i am using this transformer architecture: <a href=""https://github.com/JanSchm/CapMarket/blob/master/bot_experiments/IBM_Transformer%2BTimeEmbedding.ipynb"" rel=""nofollow noreferrer"">https://github.com/JanSchm/CapMarket/blob/master/bot_experiments/IBM_Transformer%2BTimeEmbedding.ipynb</a></p>
<p>to make some binary clasification, i am adding some pictures as input, but i was wondering, how is the right way to do this?</p>
<p>my modified architecture is:</p>
<pre><code>'''Initialize time and transformer layers'''
    time_embedding = Time2Vector(seq_len)
    attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)
    attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)
    attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)
    '''Construct model'''
    liq_seq = Input(shape=(seq_len, XN_train.shape[2],))

    pic_seq = Input(name=&quot;input_images&quot;,shape=(500,700,3))
  
x_t = time_embedding(liq_seq)
x_liq= Concatenate(axis=-1)([liq_seq, x_t])
x_liq  = LSTM(
    units = 64, 
    return_sequences=False
    )(liq_seq)
x_liq=LayerNormalization()(x_liq)
x_liq = Dense(64)(x_liq)
x_liq=LayerNormalization()(x_liq)

x_pic = Conv2D(64, (10, 10), name=&quot;first_conv&quot;, activation='relu', input_shape=(500,700, 3))(pic_seq)
x_pic =MaxPooling2D((2, 2),name=&quot;first_pooling&quot;)(x_pic)
x_pic = Flatten(name=&quot;flatten&quot;)(x_pic)
x_pic =Dense(64, activation='tanh')(x_pic)
x_pic=LayerNormalization()(x_pic)


x_liq_pic = Concatenate(axis=1)([x_liq, x_pic])
x_liq_pic =Dense(seq_len*2, activation='tanh')(x_liq_pic)

x_liq_pic= Reshape((seq_len,2))(x_liq_pic)

#x_liq_pic = Concatenate(axis=-1)([x_liq_pic, x_t])  

x_liq_pic = attn_layer1((x_liq_pic, x_liq_pic, x_liq_pic))
x_liq_pic = attn_layer2((x_liq_pic, x_liq_pic, x_liq_pic))
x_liq_pic = attn_layer3((x_liq_pic, x_liq_pic, x_liq_pic))
x_liq_pic = GlobalAveragePooling1D(data_format='channels_first')(x_liq_pic)
x_liq_pic = Dropout(0.2)(x_liq_pic)
x_liq_pic = Dense(64, activation='tanh')(x_liq_pic)
x_liq_pic = Dropout(0.2)(x_liq_pic)
out = Dense(1, activation='softmax')(x_liq_pic)

model = Model(inputs=[pic_seq,liq_seq], outputs=out) 
</code></pre>
<p>here i am doing the concatenation of the time embedding beforethe first lstm(not sure is i should add this lstm layer and concatenate here) then i use the dense layer to make it have a common shape, then i put a convolutional 2d to start working whit the images, then it goes to the dense in order to make it have the desired shape</p>
<p>having this two outputs whit the same shape, i concatenate them and then pass it over a dense, then i reshape it, in order to do the time embedding concatenation again before sending all this mess up to the transformer's layers</p>
<p>here it is the the model's plot <a href=""https://i.stack.imgur.com/4rR5c.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4rR5c.png"" alt=""enter image description here"" /></a></p>
<p>i really feel like im doing this wrong but i can't find too much documentation over this topic, also i am using a tensorflow dataset to feed the network</p>
<p>here i put the time2vec, attention, multihead and transformer classes (almost identical to the github code)</p>
<pre><code>class Time2Vector(Layer):
  def __init__(self, seq_len, **kwargs):
    super(Time2Vector, self).__init__()
    self.seq_len = seq_len

  def build(self, input_shape):
    '''Initialize weights and biases with shape (batch, seq_len)'''
    self.weights_linear = self.add_weight(name='weight_linear',
                                shape=(int(self.seq_len),),
                                initializer='uniform',
                                trainable=True)
    
    self.bias_linear = self.add_weight(name='bias_linear',
                                shape=(int(self.seq_len),),
                                initializer='uniform',
                                trainable=True)
    
    self.weights_periodic = self.add_weight(name='weight_periodic',
                                shape=(int(self.seq_len),),
                                initializer='uniform',
                                trainable=True)

    self.bias_periodic = self.add_weight(name='bias_periodic',
                                shape=(int(self.seq_len),),
                                initializer='uniform',
                                trainable=True)

  def call(self, x):
    '''Calculate linear and periodic time features'''
    x = tf.math.reduce_mean(x[:,:,:1], axis=-1) 
    time_linear = self.weights_linear * x + self.bias_linear # Linear time feature
    time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)
    
    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)
    time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)
    return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)
   
  def get_config(self): # Needed for saving and loading model with custom layer
    config = super().get_config().copy()
    config.update({'seq_len': self.seq_len})
    return config


class SingleAttention(Layer):
  def __init__(self, d_k, d_v):
    super(SingleAttention, self).__init__()
    self.d_k = d_k
    self.d_v = d_v

  def build(self, input_shape):
    self.query = Dense(self.d_k, 
                       input_shape=input_shape, 
                       kernel_initializer='glorot_uniform', 
                       bias_initializer='glorot_uniform')
    
    self.key = Dense(self.d_k, 
                     input_shape=input_shape, 
                     kernel_initializer='glorot_uniform', 
                     bias_initializer='glorot_uniform')
    
    self.value = Dense(self.d_v, 
                       input_shape=input_shape, 
                       kernel_initializer='glorot_uniform', 
                       bias_initializer='glorot_uniform')

  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)
    q = self.query(inputs[0])
    k = self.key(inputs[1])

    attn_weights = tf.matmul(q, k, transpose_b=True)
    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)
    attn_weights = tf.nn.softmax(attn_weights, axis=-1)
    
    v = self.value(inputs[2])
    attn_out = tf.matmul(attn_weights, v)
    return attn_out    

#############################################################################

class MultiAttention(Layer):
  def __init__(self, d_k, d_v, n_heads):
    super(MultiAttention, self).__init__()
    self.d_k = d_k
    self.d_v = d_v
    self.n_heads = n_heads
    self.attn_heads = list()

  def build(self, input_shape):
    for n in range(self.n_heads):
      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  
    
    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 
    self.linear = Dense(input_shape[0][-1], 
                        input_shape=input_shape, 
                        kernel_initializer='glorot_uniform', 
                        bias_initializer='glorot_uniform')

  def call(self, inputs):
    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]
    concat_attn = tf.concat(attn, axis=-1)
    multi_linear = self.linear(concat_attn)
    return multi_linear   

#############################################################################

class TransformerEncoder(Layer):
  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):
    super(TransformerEncoder, self).__init__()
    self.d_k = d_k
    self.d_v = d_v
    self.n_heads = n_heads
    self.ff_dim = ff_dim
    self.attn_heads = list()
    self.dropout_rate = dropout

  def build(self, input_shape):
    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)
    self.attn_dropout = Dropout(self.dropout_rate)
    self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)
    self.ff_LSTM= LSTM(units=self.ff_dim,input_shape=input_shape,return_sequences=True)
    self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='sigmoid')
    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 
    self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) 
    self.ff_dropout = Dropout(self.dropout_rate)
    self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    
  
  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)
    attn_layer = self.attn_multi(inputs)
    attn_layer = self.attn_dropout(attn_layer)
    attn_layer = self.attn_normalize(inputs[0] + attn_layer)
    ff_layer = self.ff_LSTM(attn_layer)
    ff_layer = self.ff_conv1D_1(ff_layer)
    ff_layer = self.ff_conv1D_2(ff_layer)
    ff_layer = self.ff_dropout(ff_layer)
    ff_layer = self.ff_normalize(inputs[0] + ff_layer)
    return ff_layer 

  def get_config(self): 
    config = super().get_config().copy()
    config.update({'d_k': self.d_k,
                   'd_v': self.d_v,
                   'n_heads': self.n_heads,
                   'ff_dim': self.ff_dim,
                   'attn_heads': self.attn_heads,
                   'dropout_rate': self.dropout_rate})
    return config      
</code></pre>
","i am using this transformer architecture: https://github.com/JanSchm/CapMarket/blob/master/bot_experiments/IBM_Transformer%2BTimeEmbedding.ipynb to make some binary clasification, i am adding some pictures as input, but i was wondering, how is the right way to do this? my modified architecture is: here i am doing the concatenation of the time embedding beforethe first lstm(not sure is i should add this lstm layer and concatenate here) then i use the dense layer to make it have a common shape, then i put a convolutional 2d to start working whit the images, then it goes to the dense in order to make it have the desired shape having this two outputs whit the same shape, i concatenate them and then pass it over a dense, then i reshape it, in order to do the time embedding concatenation again before sending all this mess up to the transformer's layers here it is the the model's plot i really feel like im doing this wrong but i can't find too much documentation over this topic, also i am using a tensorflow dataset to feed the network here i put the time2vec, attention, multihead and transformer classes (almost identical to the github code)",https://stackoverflow.com/questions/73853604,11579387,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I really feel like im doing this wrong but I can't find too much documentation over this topic, also I am using a tensorflow dataset to feed the network."
33932901,What's the purpose of tf.app.flags in TensorFlow?,"<p>I am reading some example codes in Tensorflow, I found following code </p>

<pre><code>flags = tf.app.flags
FLAGS = flags.FLAGS
flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')
flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.')
flags.DEFINE_integer('hidden1', 128, 'Number of units in hidden layer 1.')
flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')
flags.DEFINE_integer('batch_size', 100, 'Batch size.  '
                 'Must divide evenly into the dataset sizes.')
flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.')
flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '
                 'for unit testing.')
</code></pre>

<p>in <code>tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py</code></p>

<p>But I can't find any docs about this usage of <code>tf.app.flags</code>. </p>

<p>And I found the implementation of this flags is in the 
<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/default/_flags.py""><code>tensorflow/tensorflow/python/platform/default/_flags.py</code></a></p>

<p>Obviously, this <code>tf.app.flags</code> is somehow used to configure a network, so why  is it not in the API docs? Can anyone explain what is going on here? </p>
","I am reading some example codes in Tensorflow, I found following code in tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py But I can't find any docs about this usage of tf.app.flags. And I found the implementation of this flags is in the tensorflow/tensorflow/python/platform/default/_flags.py Obviously, this tf.app.flags is somehow used to configure a network, so why is it not in the API docs? Can anyone explain what is going on here?",https://stackoverflow.com/questions/33932901,5607347,Documentation Completeness,Lack of Alternative Solutions/Documentation,But I can't find any docs about this usage of tf.app.flags.
36612247,Is it possible to make tensorflow raise an error on invalid flag?,"<p>I can't find any documentation for tf.app.flags, but I see that the command line parser will happily accept invalid syntax, flags that have never been defined, etc. Is there a way to configure it to raise an error in these cases? I wasted a lot of time trying to figure out why decreasing my learning rate didn't help when the problem was just that I had typed ""-learning_rate"" instead of ""--learning_rate"".</p>
","I can't find any documentation for tf.app.flags, but I see that the command line parser will happily accept invalid syntax, flags that have never been defined, etc. Is there a way to configure it to raise an error in these cases? I wasted a lot of time trying to figure out why decreasing my learning rate didn't help when the problem was just that I had typed ""-learning_rate"" instead of ""--learning_rate"".",https://stackoverflow.com/questions/36612247,378469,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I can't find any documentation for tf.app.flags, but I see that the command line parser will happily accept invalid syntax, flags that have never been defined, etc."
56917051,Set flags within python,"<p>I would like to run the <a href=""https://github.com/tensorflow/models/tree/master/research/object_detection"" rel=""nofollow noreferrer"">TensorFlow Object Detection API</a> within a Jupyter Notebook and not from the terminal. In particular, I would like to start the training by calling <code>train.py</code>, which has a <code>main</code> function</p>

<pre class=""lang-py prettyprint-override""><code>def main(_):
   pass
</code></pre>

<p>that gets called when running the file with <code>python train.py &lt;additional flags&gt;</code> because of this part in the file:</p>

<pre class=""lang-py prettyprint-override""><code>if __name__ == '__main__':
    tf.app.run()
</code></pre>

<p>I found out that this invokes the main function to start running after it sets the global variables from the flags passed in the terminal:</p>

<pre class=""lang-py prettyprint-override""><code>flags = tf.app.flags
flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')
...
</code></pre>

<p>Is there a way to set the global variable <code>flags</code> without changing the script <code>train.py</code> and then calling the main function by importing the file. Unfortunately, I couldn't find any documentation on <code>tf.app.flags</code>.</p>
","I would like to run the TensorFlow Object Detection API within a Jupyter Notebook and not from the terminal. In particular, I would like to start the training by calling train.py, which has a main function that gets called when running the file with python train.py &lt;additional flags&gt; because of this part in the file: I found out that this invokes the main function to start running after it sets the global variables from the flags passed in the terminal: Is there a way to set the global variable flags without changing the script train.py and then calling the main function by importing the file. Unfortunately, I couldn't find any documentation on tf.app.flags.",https://stackoverflow.com/questions/56917051,1902610,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"Unfortunately, I couldn't find any documentation on tf.app.flags."
51266268,Exception thrown when running tf.app.run(),"<p>I am toying around with flags at the moment and came across some weird behavior when using <code>tf.app.run()</code>. The following code snippet should simply print the string given via the command line.</p>

<pre><code>import tensorflow as tf

# command line flags
tf.app.flags.DEFINE_string('mystring', 'Hello World!',
                           '''String to print to console.''')

FLAGS = tf.app.flags.FLAGS


def main():

    print(FLAGS.mystring)

if __name__ == '__main__':
    tf.app.run()
</code></pre>

<p>During execution, this error is thrown:</p>

<blockquote>
  <p>Traceback (most recent call last):</p>
  
  <p>File """", line 1, in 
      runfile('/path/flags.py', wdir='/path')</p>
  
  <p>File
  ""/home/abc/anaconda3/envs/tensorflow/lib/python3.5/site-packages/spyder/utils/site/sitecustomize.py"",
  line 710, in runfile
      execfile(filename, namespace)</p>
  
  <p>File
  ""/home/abc/anaconda3/envs/tensorflow/lib/python3.5/site-packages/spyder/utils/site/sitecustomize.py"",
  line 101, in execfile
      exec(compile(f.read(), filename, 'exec'), namespace)</p>
  
  <p>File ""/path/flags.py"", line 19, in 
      tf.app.run()</p>
  
  <p>File
  ""/home/abc/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py"",
  line 126, in run
      _sys.exit(main(argv))</p>
  
  <p>TypeError: main() takes 0 positional arguments but 1 was given</p>
</blockquote>

<p>...which is strange because I do not give a single argument to main(). However, if I add an underscore <code>def main(_):</code>, it works without any errors.</p>

<p>I couldn't find a doc where this is use of the underscore is described. Does anybody know what happens here? Thank you!</p>
","I am toying around with flags at the moment and came across some weird behavior when using tf.app.run(). The following code snippet should simply print the string given via the command line. During execution, this error is thrown: ...which is strange because I do not give a single argument to main(). However, if I add an underscore def main(_):, it works without any errors. I couldn't find a doc where this is use of the underscore is described. Does anybody know what happens here? Thank you!",https://stackoverflow.com/questions/51266268,8334261,Documentation Completeness,Lack of Alternative Solutions/Documentation,I couldn't find a doc where this is use of the underscore is described
49770934,Prevent a Variable from being converted into a Const when freezing a TensorFlow graph,"<p>I'm trying to use the freeze_graph.py tool to save a model, but have run into an issue.</p>

<p>There is a variable in my tensorflow graph which I either assign to using tf.assign, or feed before each inference. I need it to remain a variable because tf.assign requires a mutable tensor and you also can't feed to a const, but the freeze_graph script converts all variables into constants.</p>

<p>I've noticed that freeze_graph has whitelist and blacklist parameters, but I can't for the life of me find any documentation on what these are or how to use them. What can I do here?</p>

<p><em>edit:</em></p>

<p><code>single_c</code> and <code>single_h</code> are the variables I'd like to preserve:</p>

<pre><code>single_c = tf.Variable(tf.random_uniform([num_lstm_cells], 0, 1), trainable=True)
expanded_c = tf.reshape(single_c, [1, num_lstm_cells])
batched_c = tf.tile(expanded_c, tiling_shape, name='c')

single_h = tf.Variable(tf.random_uniform([num_lstm_cells], 0, 1), trainable=True)
expanded_h = tf.reshape(single_h, [1, num_lstm_cells])
batched_h = tf.tile(expanded_h, tiling_shape, name='h')

state = tf.contrib.rnn.LSTMStateTuple(batched_c, batched_h)
</code></pre>

<p>because I assign them using:</p>

<pre><code>restore_c = tf.assign(single_c, c_holder)
restore_h = tf.assign(single_h, h_holder)
</code></pre>

<p>and I feed <code>state</code> using</p>

<pre><code>_, er, new = sess.run([train_nn_step, error, new_state], feed_dict={batch_ph: batch_size, prob: training_dropout, state: new})
</code></pre>

<p>I can't assign or feed if <code>single_c</code> and <code>single_h</code> become constants</p>
","I'm trying to use the freeze_graph.py tool to save a model, but have run into an issue. There is a variable in my tensorflow graph which I either assign to using tf.assign, or feed before each inference. I need it to remain a variable because tf.assign requires a mutable tensor and you also can't feed to a const, but the freeze_graph script converts all variables into constants. I've noticed that freeze_graph has whitelist and blacklist parameters, but I can't for the life of me find any documentation on what these are or how to use them. What can I do here? edit: single_c and single_h are the variables I'd like to preserve: because I assign them using: and I feed state using I can't assign or feed if single_c and single_h become constants",https://stackoverflow.com/questions/49770934,6936275,Requesting (Additional) Resources,Lack of Alternative Solutions/Documentation,"I've noticed that freeze_graph has whitelist and blacklist parameters, but I can't for the life of me find any documentation on what these are or how to use them."
60472754,Keras LearningRateScheduler callback on batches instead of epochs,"<p>I am using Tensorflow 2.x, The below is the custom learning rate scheduler which i have written</p>

<pre><code>def scheduler(epoch):
  if epoch == 1:
    return 3e-5
  else:
    return 3e-5 * (1/(1 + 0.01 * epoch ))
</code></pre>

<p>and i am calling it like this </p>

<pre><code>callback = tf.keras.callbacks.LearningRateScheduler(scheduler)

model.fit(inputs_train,tags_train,epochs=30,batch_size=32,validation_data=(inputs_val,tags_val),shuffle=False,callbacks=[callback])
</code></pre>

<p>But instead of calling it on epochs, i want to call it on each batch. I couldn't find anything below documentation regarding batches </p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler</a></p>

<p>Is it possible to call it on batches, if yes how to do that?</p>
","I am using Tensorflow 2.x, The below is the custom learning rate scheduler which i have written and i am calling it like this But instead of calling it on epochs, i want to call it on each batch. I couldn't find anything below documentation regarding batches https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler Is it possible to call it on batches, if yes how to do that?",https://stackoverflow.com/questions/60472754,6490241,Inadequate Examples,Lack of Alternative Solutions/Documentation,I couldn't find anything below documentation regarding batches https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler
42140211,Tensorflow - eval() error: You must feed a value for placeholder tensor,"<p>I'm trying to use eval() to understand what is happening in each learning step.</p>

<p>However, if I use eval() on an tf.matmul operation, then I would get an error <code>You must feed a value for placeholder tensor</code>.</p>

<p>If I removed the eval(), then everything would work properly as expected. </p>

<pre><code>num_steps = 3001

with tf.Session(graph=graph) as session:
    tf.global_variables_initializer().run()
    writer = tf.summary.FileWriter(""/home/ubuntu/tensorboard"", graph=tf.get_default_graph())
    for step in range(num_steps):
        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
        batch_data = train_dataset[offset:(offset + batch_size), :]
        batch_labels = train_labels[offset:(offset + batch_size), :]
        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
        _, l, predictions, summary = session.run([optimizer, loss, train_prediction, summary_op], feed_dict=feed_dict)
        writer.add_summary(summary, step)

        # If I removed this line, then it would work
        loss.eval()

batch_size = 128

graph = tf.Graph()
with graph.as_default():
    with tf.name_scope('tf_train_dataset'):
        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))
    with tf.name_scope('tf_train_labels'):
        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))
    with tf.name_scope('tf_valid_dataset'):
        tf_valid_dataset = tf.constant(valid_dataset)
    with tf.name_scope('tf_test_dataset'):
        tf_test_dataset = tf.constant(test_dataset)

    with tf.name_scope('weights'):
        weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))
    with tf.name_scope('biases'):
        biases = tf.Variable(tf.zeros([num_labels]))

    with tf.name_scope('logits'):
        logits = tf.matmul(tf_train_dataset, weights) + biases
    with tf.name_scope('loss'):
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))
        tf.summary.scalar(""loss"", loss)

    with tf.name_scope('optimizer'):
        optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

    with tf.name_scope(""train_prediction""):
        train_prediction = tf.nn.softmax(logits)
    with tf.name_scope(""valid_prediction""):
        valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)
    with tf.name_scope(""test_prediction""):
        test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)

    with tf.name_scope(""correct_prediction""):
        correct_prediction = tf.equal(tf.argmax(tf_train_labels,1), tf.argmax(train_prediction,1))

    with tf.name_scope(""accuracy""):
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        tf.summary.scalar(""training_accuracy"", accuracy)

    summary_op = tf.summary.merge_all()
</code></pre>

<p>The exact error is:</p>

<pre><code>InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'tf_train_dataset/Placeholder' with dtype float and shape [128,784]
     [[Node: tf_train_dataset/Placeholder = Placeholder[dtype=DT_FLOAT, shape=[128,784], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
</code></pre>

<p>Does anyone have a better way to log the variables? I've tried tensor_summary, but it doesn't show it on the website.</p>

<p>Thanks all</p>
","I'm trying to use eval() to understand what is happening in each learning step. However, if I use eval() on an tf.matmul operation, then I would get an error You must feed a value for placeholder tensor. If I removed the eval(), then everything would work properly as expected. The exact error is: Does anyone have a better way to log the variables? I've tried tensor_summary, but it doesn't show it on the website. Thanks all",https://stackoverflow.com/questions/42140211,1157751,Requesting (Additional) Resources,Lack of Alternative Solutions/Documentation,"Does anyone have a better way to log the variables? I've tried tensor_summary, but it doesn't show it on the website."
39112622,How do I set TensorFlow RNN state when state_is_tuple=True?,"<p>I have written an <a href=""https://github.com/wpm/tfrnnlm"" rel=""noreferrer"">RNN language model using TensorFlow</a>. The model is implemented as an <code>RNN</code> class. The graph structure is built in the constructor, while <code>RNN.train</code> and <code>RNN.test</code> methods run it.</p>

<p>I want to be able to reset the RNN state when I move to a new document in the training set, or when I want to run a validation set during training. I do this by managing the state inside the training loop, passing it into the graph via a feed dictionary.</p>

<p>In the constructor I define the the RNN like so</p>

<pre><code>    cell = tf.nn.rnn_cell.LSTMCell(hidden_units)
    rnn_layers = tf.nn.rnn_cell.MultiRNNCell([cell] * layers)
    self.reset_state = rnn_layers.zero_state(batch_size, dtype=tf.float32)
    self.state = tf.placeholder(tf.float32, self.reset_state.get_shape(), ""state"")
    self.outputs, self.next_state = tf.nn.dynamic_rnn(rnn_layers, self.embedded_input, time_major=True,
                                                  initial_state=self.state)
</code></pre>

<p>The training loop looks like this</p>

<pre><code> for document in document:
     state = session.run(self.reset_state)
     for x, y in document:
          _, state = session.run([self.train_step, self.next_state], 
                                 feed_dict={self.x:x, self.y:y, self.state:state})
</code></pre>

<p><code>x</code> and <code>y</code> are batches of training data in a document. The idea is that I pass the latest state along after each batch, except when I start a new document, when I zero out the state by running <code>self.reset_state</code>.</p>

<p>This all works.  Now I want to change my RNN to use the recommended <code>state_is_tuple=True</code>. However, I don't know how to pass the more complicated LSTM state object via a feed dictionary. Also I don't know what arguments to pass to the <code>self.state = tf.placeholder(...)</code> line in my constructor.</p>

<p>What is the correct strategy here? There still isn't much example code or documentation for <code>dynamic_rnn</code> available.</p>

<hr>

<p>TensorFlow issues <a href=""https://github.com/tensorflow/tensorflow/issues/2695"" rel=""noreferrer"">2695</a> and <a href=""https://github.com/tensorflow/tensorflow/issues/2838"" rel=""noreferrer"">2838</a> appear relevant.</p>

<p>A <a href=""http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/"" rel=""noreferrer"">blog post</a> on WILDML addresses these issues but doesn't directly spell out the answer.</p>

<p>See also <a href=""https://stackoverflow.com/questions/38241410/tensorflow-remember-lstm-state-for-next-batch-stateful-lstm"">TensorFlow: Remember LSTM state for next batch (stateful LSTM)</a>.</p>
","I have written an RNN language model using TensorFlow. The model is implemented as an RNN class. The graph structure is built in the constructor, while RNN.train and RNN.test methods run it. I want to be able to reset the RNN state when I move to a new document in the training set, or when I want to run a validation set during training. I do this by managing the state inside the training loop, passing it into the graph via a feed dictionary. In the constructor I define the the RNN like so The training loop looks like this x and y are batches of training data in a document. The idea is that I pass the latest state along after each batch, except when I start a new document, when I zero out the state by running self.reset_state. This all works. Now I want to change my RNN to use the recommended state_is_tuple=True. However, I don't know how to pass the more complicated LSTM state object via a feed dictionary. Also I don't know what arguments to pass to the self.state = tf.placeholder(...) line in my constructor. What is the correct strategy here? There still isn't much example code or documentation for dynamic_rnn available. TensorFlow issues 2695 and 2838 appear relevant. A blog post on WILDML addresses these issues but doesn't directly spell out the answer. See also TensorFlow: Remember LSTM state for next batch (stateful LSTM).",https://stackoverflow.com/questions/39112622,1120370,Requesting (Additional) Resources,Lack of Alternative Solutions/Documentation,There still isn't much example code or documentation for dynamic_rnn available.
39068703,"Tensorflow: Using weights trained in one model inside another, different model","<p>I'm trying to train an LSTM in Tensorflow using minibatches, but after training is complete I would like to use the model by submitting one example at a time to it.   I can set up the graph within Tensorflow to train my LSTM network, but I can't use the trained result afterward in the way I want.</p>

<p>The setup code looks something like this:</p>

<pre><code>#Build the LSTM model.
cellRaw = rnn_cell.BasicLSTMCell(LAYER_SIZE)
cellRaw = rnn_cell.MultiRNNCell([cellRaw] * NUM_LAYERS)

cell = rnn_cell.DropoutWrapper(cellRaw, output_keep_prob = 0.25)

input_data  = tf.placeholder(dtype=tf.float32, shape=[SEQ_LENGTH, None, 3])
target_data = tf.placeholder(dtype=tf.float32, shape=[SEQ_LENGTH, None])
initial_state = cell.zero_state(batch_size=BATCH_SIZE, dtype=tf.float32)

with tf.variable_scope('rnnlm'):
    output_w = tf.get_variable(""output_w"", [LAYER_SIZE, 6])
    output_b = tf.get_variable(""output_b"", [6])

outputs, final_state = seq2seq.rnn_decoder(input_list, initial_state, cell, loop_function=None, scope='rnnlm')
output = tf.reshape(tf.concat(1, outputs), [-1, LAYER_SIZE])
output = tf.nn.xw_plus_b(output, output_w, output_b)
</code></pre>

<p>...Note the two placeholders, input_data and target_data.  I haven't bothered including the optimizer setup.  After training is complete and the training session closed, I would like to set up a new session that uses the trained LSTM network whose input is provided by a completely different placeholder, something like:</p>

<pre><code>with tf.Session() as sess:
with tf.variable_scope(""simulation"", reuse=None):
    cellSim = cellRaw
    input_data_sim  = tf.placeholder(dtype=tf.float32, shape=[1, 1, 3])
    initial_state_sim = cell.zero_state(batch_size=1, dtype=tf.float32)
    input_list_sim = tf.unpack(input_data_sim)

    outputsSim, final_state_sim = seq2seq.rnn_decoder(input_list_sim, initial_state_sim, cellSim, loop_function=None, scope='rnnlm')
    outputSim = tf.reshape(tf.concat(1, outputsSim), [-1, LAYER_SIZE])

    with tf.variable_scope('rnnlm'):
        output_w = tf.get_variable(""output_w"", [LAYER_SIZE, nOut])
        output_b = tf.get_variable(""output_b"", [nOut])

    outputSim = tf.nn.xw_plus_b(outputSim, output_w, output_b)
</code></pre>

<p>This second part returns the following error:</p>

<pre><code>tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float
 [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
</code></pre>

<p>...Presumably because the graph I'm using still has the old training placeholders attached to the trained LSTM nodes.  What's the right way to 'extract' the trained LSTM and put it into a new, different graph that has a different style of inputs?  The Varible scoping features that Tensorflow has seem to address something like this, but the examples <a href=""https://www.tensorflow.org/versions/r0.10/how_tos/variable_scope/index.html"" rel=""noreferrer"">in the documentation</a> all talk about using variable scope as a way of managing variable names so that the same piece of code will generate similar subgraphs within the same graph.  The 'reuse' feature seems to be close to what I want, but I don't find the Tensorflow documentation linked above to be clear at all on what it does.  The cells themselves cannot be given a name (in other words, </p>

<pre><code>cellRaw = rnn_cell.MultiRNNCell([cellRaw] * NUM_LAYERS, name=""multicell"")
</code></pre>

<p>is not valid), and while I can give a name to a seq2seq.rnn_decoder(), I presumably wouldn't be able to remove the rnn_cell.DropoutWrapper() if I used that node unchanged.  </p>

<p>Questions:</p>

<p>What is the proper way to move trained LSTM weights from one graph to another?</p>

<p>Is it correct to say that starting a new session ""releases resources"", but doesn't erase the graph built in memory?</p>

<p>It seems to me like the 'reuse' feature allows Tensorflow to search outside of the current variable scope for variables with the same name (existing in a different scope), and use them in the current scope.  Is this correct?  If it is, what happens to all of the graph edges from the non-current scope that link to that variable?  If it isn't, why does Tensorflow throw an error if you try to have the same variable name within two different scopes?  It seems perfectly reasonable to define two variables with identical names in two different scopes, e.g. conv1/sum1 and conv2/sum1.</p>

<p>In my code I'm working within a new scope but the graph won't run without data to be fed into a placeholder from the initial, default scope.   Is the default scope always 'in-scope' for some reason?  </p>

<p>If graph edges can span different scopes, and names in different scopes can't be shared unless they refer to the exact same node, then that would seem to defeat the purpose of having different scopes in the first place.  What am I misunderstanding here?</p>

<p>Thanks!</p>
","I'm trying to train an LSTM in Tensorflow using minibatches, but after training is complete I would like to use the model by submitting one example at a time to it. I can set up the graph within Tensorflow to train my LSTM network, but I can't use the trained result afterward in the way I want. The setup code looks something like this: ...Note the two placeholders, input_data and target_data. I haven't bothered including the optimizer setup. After training is complete and the training session closed, I would like to set up a new session that uses the trained LSTM network whose input is provided by a completely different placeholder, something like: This second part returns the following error: ...Presumably because the graph I'm using still has the old training placeholders attached to the trained LSTM nodes. What's the right way to 'extract' the trained LSTM and put it into a new, different graph that has a different style of inputs? The Varible scoping features that Tensorflow has seem to address something like this, but the examples in the documentation all talk about using variable scope as a way of managing variable names so that the same piece of code will generate similar subgraphs within the same graph. The 'reuse' feature seems to be close to what I want, but I don't find the Tensorflow documentation linked above to be clear at all on what it does. The cells themselves cannot be given a name (in other words, is not valid), and while I can give a name to a seq2seq.rnn_decoder(), I presumably wouldn't be able to remove the rnn_cell.DropoutWrapper() if I used that node unchanged. Questions: What is the proper way to move trained LSTM weights from one graph to another? Is it correct to say that starting a new session ""releases resources"", but doesn't erase the graph built in memory? It seems to me like the 'reuse' feature allows Tensorflow to search outside of the current variable scope for variables with the same name (existing in a different scope), and use them in the current scope. Is this correct? If it is, what happens to all of the graph edges from the non-current scope that link to that variable? If it isn't, why does Tensorflow throw an error if you try to have the same variable name within two different scopes? It seems perfectly reasonable to define two variables with identical names in two different scopes, e.g. conv1/sum1 and conv2/sum1. In my code I'm working within a new scope but the graph won't run without data to be fed into a placeholder from the initial, default scope. Is the default scope always 'in-scope' for some reason? If graph edges can span different scopes, and names in different scopes can't be shared unless they refer to the exact same node, then that would seem to defeat the purpose of having different scopes in the first place. What am I misunderstanding here? Thanks!",https://stackoverflow.com/questions/39068703,3280780,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"The 'reuse' feature seems to be close to what I want, but I don't find the Tensorflow documentation linked above to be clear at all on what it does."
49890477,Log accuracy metric while training a tf.estimator,"<p>What's the simplest way to print accuracy metrics along with the loss when training a pre-canned estimator?</p>

<p>Most tutorials and documentations seem to address the issue of when you're creating a custom estimator -- which seems overkill if the intention is to use one of the available ones.</p>

<p>tf.contrib.learn had a few (now deprecated) Monitor hooks. TF now suggests using the hook API, but it appears that it doesn't actually come with anything that can utilize the labels and predictions to generate an accuracy number. </p>
","What's the simplest way to print accuracy metrics along with the loss when training a pre-canned estimator? Most tutorials and documentations seem to address the issue of when you're creating a custom estimator -- which seems overkill if the intention is to use one of the available ones. tf.contrib.learn had a few (now deprecated) Monitor hooks. TF now suggests using the hook API, but it appears that it doesn't actually come with anything that can utilize the labels and predictions to generate an accuracy number.",https://stackoverflow.com/questions/49890477,98975,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"Most tutorials and documentations seem to address the issue of when you're creating a custom estimator -- which seems overkill if the intention is to use one of the available ones. tf.contrib.learn had a few (now deprecated) Monitor hooks. TF now suggests using the hook API, but it appears that it doesn't actually come with anything that can utilize the labels and predictions to generate an accuracy number."
53000921,Tensorflow Sequence to Sequence CustomHelper,"<p>There are limited amount of documentation on Sequence to Sequence CustomHelper </p>

<p><code>helper = tf.contrib.seq2seq.CustomHelper(initialize_fn = initialize_fn,sample_fn = sample_fn, next_inputs_fn = next_inputs_fn)</code></p>

<p>in Tensorflow.</p>

<p>Would anyone explain the inputs of the Custom-helper, in terms of the input data</p>

<p><code>X = tf.placeholder(tf.float32, [batch_size x time_steps x features])</code></p>

<p>and encoder, </p>

<p><code>encoder_cell = tf.contrib.rnn.BasicLSTMCell(hidden_size)</code></p>

<p><code>initial_state = encoder_cell.zero_state(batch_size, dtype=tf.float32)</code></p>

<p>and/or possibly </p>

<p><code>rnn_output, rnn_states = tf.nn.dynamic_rnn(encoder_cell, X, dtype=tf.float32)</code>
?</p>
","There are limited amount of documentation on Sequence to Sequence CustomHelper helper = tf.contrib.seq2seq.CustomHelper(initialize_fn = initialize_fn,sample_fn = sample_fn, next_inputs_fn = next_inputs_fn) in Tensorflow. Would anyone explain the inputs of the Custom-helper, in terms of the input data X = tf.placeholder(tf.float32, [batch_size x time_steps x features]) and encoder, encoder_cell = tf.contrib.rnn.BasicLSTMCell(hidden_size) initial_state = encoder_cell.zero_state(batch_size, dtype=tf.float32) and/or possibly rnn_output, rnn_states = tf.nn.dynamic_rnn(encoder_cell, X, dtype=tf.float32) ?",https://stackoverflow.com/questions/53000921,7644642,Documentation Completeness,Lack of Alternative Solutions/Documentation,There are limited amount of documentation on Sequence to Sequence 
56092824,TF 2.0: Where can I find the upgrade of tf.contrib.training?,"<p>I want to use the HParams class from <strong>tf.contrib.training</strong> in tensorflow 2.0 version, but I can't find the replacement for this class neither in <em>tensorflow alpha</em> documentation nor in <em>tensorflow_addons</em></p>
","I want to use the HParams class from tf.contrib.training in tensorflow 2.0 version, but I can't find the replacement for this class neither in tensorflow alpha documentation nor in tensorflow_addons",https://stackoverflow.com/questions/56092824,6396977,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I want to use the HParams class from tf.contrib.training in tensorflow 2.0 version, but I can't find the replacement for this class neither in tensorflow alpha documentation nor in tensorflow_addons"
53845742,How to construct a multi-tower tensorflow graph from predefined models,"<p>I have a model that has been trained and stored to file in Tensorflow. It was a pretrained model that had some parameter tweaking done to produce the required results. Now I am looking to take that model and run it in parallel across multiple GPUs for inference.</p>

<p>I can only find resources showing how to produce multi-GPU towers when the graph is initially defined by using <code>tf.device</code> when defining the operations, but since I am reading in a GraphDef from file I don't have that option.</p>

<p>For reference, the model loading code (identical to what is on the tensorflow hub's <code>label_image.py</code>):</p>

<pre class=""lang-py prettyprint-override""><code>def load_graph(model_file):
  graph = tf.Graph()
  graph_def = tf.GraphDef()

  with open(model_file, ""rb"") as f:
    graph_def.ParseFromString(f.read())
  with graph.as_default():
    tf.import_graph_def(graph_def)

  return graph
</code></pre>
","I have a model that has been trained and stored to file in Tensorflow. It was a pretrained model that had some parameter tweaking done to produce the required results. Now I am looking to take that model and run it in parallel across multiple GPUs for inference. I can only find resources showing how to produce multi-GPU towers when the graph is initially defined by using tf.device when defining the operations, but since I am reading in a GraphDef from file I don't have that option. For reference, the model loading code (identical to what is on the tensorflow hub's label_image.py):",https://stackoverflow.com/questions/53845742,3773546,Requesting (Additional) Resources,Lack of Alternative Solutions/Documentation,"I can only find resources showing how to produce multi-GPU towers when the graph is initially defined by using tf.device when defining the operations, but since I am reading in a GraphDef from file I don't have that option."
46087294,using tf.nn.dynamic_rnn to make LSTM RNN of multiple hidden layers,"<p>I read the documentation of tf.dynamic.rnn in
<a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a></p>

<p>and used it to make a single layer rnn of multiple time-steps. I was wondering if I could use tf.dynamic.rnn to stack multiple hidden layers. Is it possible to do so? </p>
",I read the documentation of tf.dynamic.rnn in https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn and used it to make a single layer rnn of multiple time-steps. I was wondering if I could use tf.dynamic.rnn to stack multiple hidden layers. Is it possible to do so?,https://stackoverflow.com/questions/46087294,6147251,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I read the documentation of tf.dynamic.rnn in https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn and used it to make a single layer rnn of multiple time-steps. I was wondering if I could use tf.dynamic.rnn to stack multiple hidden layers. Is it possible to do so?
62490870,How to add random noise to the labels using DNNLinearCombinedClassifier for tf1.15?,"<p>Currently, I am working with the wide and deep classifier in tf1.15 (DNNLinearCombinedClassifier), and defined the following function to add random noise to the labels:</p>
<pre><code>def add_random_noise(labels):
    labels = tf.dtypes.cast(labels, tf.float32)
    rnd_noise = tf.random.uniform(tf.shape(labels))
    return tf.add(labels, tf.math.multiply_no_nan(0.05, rnd_noise))
</code></pre>
<p>This function is then applied to the dataset using <code>map</code> and applied only to the target column. However when I train my model, it generates the following output:</p>
<pre><code>(0) Invalid argument: assertion failed: [Labels must &lt;= n_classes - 1] [Condition x &lt;= y did not hold element-wise:] [x (head/labels:0) = ] [[0.00486446638][0.0133116841][0.0143840136]...] [y (head/assert_range/Const:0) = ] [1]
</code></pre>
<p>As far as I understand, <code>DNNLinearCombinedClassifier</code> is calculating the number of unique values in target and generated the error due to the difference between n_classes and the number of unique values. I reviewed the documentation of <code>DNNLinearCombinedEstimator</code>, but it uses MSE as loss, and I would definetely like to train my model using cross entropy as it is done in <code>DNNLinearCombinedClassifier</code>. I would like to ask you if there is a way to use wide and deep classifier with this <em>perturbed</em> label column and cross entropy as my training loss function.</p>
","Currently, I am working with the wide and deep classifier in tf1.15 (DNNLinearCombinedClassifier), and defined the following function to add random noise to the labels: This function is then applied to the dataset using map and applied only to the target column. However when I train my model, it generates the following output: As far as I understand, DNNLinearCombinedClassifier is calculating the number of unique values in target and generated the error due to the difference between n_classes and the number of unique values. I reviewed the documentation of DNNLinearCombinedEstimator, but it uses MSE as loss, and I would definetely like to train my model using cross entropy as it is done in DNNLinearCombinedClassifier. I would like to ask you if there is a way to use wide and deep classifier with this perturbed label column and cross entropy as my training loss function.",https://stackoverflow.com/questions/62490870,997333,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I reviewed the documentation of DNNLinearCombinedEstimator, but it uses MSE as loss, and I would definetely like to train my model using cross entropy as it is done in DNNLinearCombinedClassifier."
44217076,tf.extract_image_patches for 3D images,"<p><a href=""https://www.tensorflow.org/api_docs/python/tf/extract_image_patches"" rel=""nofollow noreferrer"">The documentation of tf.extract_image_patches</a></p>

<p>It is only for 2D image, could it be expand to 3D images, which is useful for the implementation for SSIM loss function?</p>

<p>I cannot find the source code. There is a similar function <code>skimage.util.view_as_windows</code>, however, when I try to use this function with the tensorflow as backend in keras, there are errors. The transition from numpy array to tensor confused me a lot.</p>
","The documentation of tf.extract_image_patches It is only for 2D image, could it be expand to 3D images, which is useful for the implementation for SSIM loss function? I cannot find the source code. There is a similar function skimage.util.view_as_windows, however, when I try to use this function with the tensorflow as backend in keras, there are errors. The transition from numpy array to tensor confused me a lot.",https://stackoverflow.com/questions/44217076,7845074,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"The documentation of tf.extract_image_patches It is only for 2D image, could it be expand to 3D images, which is useful for the implementation for SSIM loss function? I cannot find the source code."
52785019,Specify shape for categorical feature columns?,"<p>I know that I can use a <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_identity"" rel=""nofollow noreferrer""><code>categorical_column_with_identity</code></a> to turn a categorical feature into a series of one-hot features.</p>

<p>For instance, if my vocabulary is <code>[""ON"", ""OFF"", ""UNKNOWN""]</code>:<br>
<code>""OFF""</code> -> <code>[0, 1, 0]</code></p>

<pre><code>categorical_column = tf.feature_column.categorical_column_with_identity('column_name', num_buckets=3)
feature_column = tf.feature_column.indicator_column(categorical_column))
</code></pre>

<hr>

<p>However, I actually have an 1-dimensional array of categorical features. I would like to turn that into a 2-dimensional series of one-hot features:</p>

<p><code>[""OFF"", ""ON"", ""OFF"", ""UNKNOWN"", ""ON""]</code><br>
-><br>
<code>[[0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]]</code></p>

<p>Unlike every other feature column, it doesn't seem like there's a <code>shape</code> attribute on <code>categorical_column_with_identity</code> and I didn't find any help through Google or the docs.</p>

<p>Do I have to give up on <code>categorical_column_with_identity</code> and create the 2D array myself through a <code>numerical_column</code>?</p>
","I know that I can use a categorical_column_with_identity to turn a categorical feature into a series of one-hot features. For instance, if my vocabulary is [""ON"", ""OFF"", ""UNKNOWN""]: ""OFF"" -&gt; [0, 1, 0] However, I actually have an 1-dimensional array of categorical features. I would like to turn that into a 2-dimensional series of one-hot features: [""OFF"", ""ON"", ""OFF"", ""UNKNOWN"", ""ON""] -&gt; [[0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]] Unlike every other feature column, it doesn't seem like there's a shape attribute on categorical_column_with_identity and I didn't find any help through Google or the docs. Do I have to give up on categorical_column_with_identity and create the 2D array myself through a numerical_column?",https://stackoverflow.com/questions/52785019,2510391,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"Unlike every other feature column, it doesn't seem like there's a shape attribute on categorical_column_with_identity and I didn't find any help through Google or the docs."
41216576,Tensorflow: transfer learning from vgg16 .tfmodel file,"<p>I'm trying to make a TF implementation of an image classifier (with py3.5 and Windows 10, TF 0.12), so I'm re-using existing models <a href=""https://www.tensorflow.org/versions/master/how_tos/image_retraining/#using_the_retrained_model"" rel=""nofollow noreferrer"">as described here</a> but without all the weird Bazel stuff. After fixing a py2-to-3 bug on <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L887"" rel=""nofollow noreferrer"">this line</a> (wrapping the <code>keys()</code> in <code>list()</code>), it ran nicely on my 10 folders of different categories. However, the performance is lacking; the training success rate is around 83% and the validation set is never above 60% at best. So I'd like to do some transfer learning from a vgg16 model (which is one I've used before in Caffe/ubuntu); <a href=""https://github.com/ry/tensorflow-vgg16"" rel=""nofollow noreferrer"">one I've found is here</a> ready to be downloaded. </p>

<p>My question now is, how do you load a .tfmodel file in Tensorflow? The script is expecting a tar.gz to be downloaded, fair enough. It apparently contains a file called <code>classify_image_graph_def.pb</code>, which is not a .tfmodel file. Looking in <a href=""https://github.com/ry/tensorflow-vgg16/blob/master/tf_forward.py"" rel=""nofollow noreferrer"">some example code</a> I see that it's pretty easy to load a .tfmodel file, so I've modified the <code>create_inception_graph</code> function to point straight at the <code>vgg16-20160129.tfmodel</code> file. Upon running this, I get this error:</p>

<pre><code>File ""C:\Users\User\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\importer.py"", line 450, in import_graph_def
    ret.append(name_to_op[operation_name].outputs[output_index])
KeyError: 'pool_3/_reshape'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""retrain.py"", line 995, in &lt;module&gt;
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\platform\app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""retrain.py"", line 713, in main
    create_inception_graph())
  File ""retrain.py"", line 235, in create_inception_graph
    RESIZED_INPUT_TENSOR_NAME]))
  File ""C:\Users\User\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\importer.py"", line 453, in import_graph_def
    'Requested return_element %r not found in graph_def.' % name)
ValueError: Requested return_element 'pool_3/_reshape:0' not found in graph_def.
</code></pre>

<p>And this is the loading code:</p>

<pre><code>def create_inception_graph():
  """"""""Creates a graph from saved GraphDef file and returns a Graph object.
  Returns:
    Graph holding the trained Inception network, and various tensors we'll be
    manipulating.
  """"""
  with tf.Session() as sess:
    #model_filename = os.path.join(
    #    FLAGS.model_dir, 'classify_image_graph_def.pb')
    model_filename = os.path.join(
        FLAGS.model_dir, 'vgg16-20160129.tfmodel')
    with gfile.FastGFile(model_filename, 'rb') as f:
      graph_def = tf.GraphDef()
      graph_def.ParseFromString(f.read())
      bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (
          tf.import_graph_def(graph_def, name='', return_elements=[
              BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,
              RESIZED_INPUT_TENSOR_NAME]))
  return sess.graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor
</code></pre>

<p>Something seems to be going awry in the <code>tf.import_graph_def</code> call but there's no documentation for that function, weirdly. Is what I'm trying even possible? There's a whole bunch of bottleneck tensor and jpeg data and resized input tensor names that I don't know what they're there for, which the example doesn't replicate. </p>
","I'm trying to make a TF implementation of an image classifier (with py3.5 and Windows 10, TF 0.12), so I'm re-using existing models as described here but without all the weird Bazel stuff. After fixing a py2-to-3 bug on this line (wrapping the keys() in list()), it ran nicely on my 10 folders of different categories. However, the performance is lacking; the training success rate is around 83% and the validation set is never above 60% at best. So I'd like to do some transfer learning from a vgg16 model (which is one I've used before in Caffe/ubuntu); one I've found is here ready to be downloaded. My question now is, how do you load a .tfmodel file in Tensorflow? The script is expecting a tar.gz to be downloaded, fair enough. It apparently contains a file called classify_image_graph_def.pb, which is not a .tfmodel file. Looking in some example code I see that it's pretty easy to load a .tfmodel file, so I've modified the create_inception_graph function to point straight at the vgg16-20160129.tfmodel file. Upon running this, I get this error: And this is the loading code: Something seems to be going awry in the tf.import_graph_def call but there's no documentation for that function, weirdly. Is what I'm trying even possible? There's a whole bunch of bottleneck tensor and jpeg data and resized input tensor names that I don't know what they're there for, which the example doesn't replicate.",https://stackoverflow.com/questions/41216576,3234562,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"Something seems to be going awry in the tf.import_graph_def call but there's no documentation for that function, weirdly. Is what I'm trying even possible?"
56141142,"How to pass ""step"" to ExponentialDecay in GradientTape","<p>I tried to use an optimizers.schedules.ExponentialDecay isntance as the learning_rate to Adm optimizer, but i don't know how to pass ""step"" to it when train the model in GradientTape.</p>

<p>I use tensorflow-gpu-2.0-alpha0 and python3.6.
And i read the doc <a href=""https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/optimizers/schedules/ExponentialDecay"" rel=""nofollow noreferrer"">https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/optimizers/schedules/ExponentialDecay</a> but with no idea how to tackle it.</p>

<pre><code>initial_learning_rate = 0.1
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=100000,
    decay_rate=0.96)

optimizer = tf.optimizers.Adam(learning_rate = lr_schedule)

for epoch in range(self.Epoch):
    ...
    ...
    with GradientTape as tape:
        pred_label = model(images)
        loss = calc_loss(pred_label, ground_label)
    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))

# I tried this but the result seem not right.
# I want to pass ""epoch"" as ""step"" to lr_schedule
</code></pre>
","I tried to use an optimizers.schedules.ExponentialDecay isntance as the learning_rate to Adm optimizer, but i don't know how to pass ""step"" to it when train the model in GradientTape. I use tensorflow-gpu-2.0-alpha0 and python3.6. And i read the doc https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/optimizers/schedules/ExponentialDecay but with no idea how to tackle it.",https://stackoverflow.com/questions/56141142,3167681,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"And i read the doc, but with no idea how to tackle it."
42981493,Weights and biases in tf.layers module in TensorFlow 1.0,"<p>How do you access the weights and biases when using tf.layers module in TensorFlow 1.0? The advantage of tf.layers module is that you don't have to separately create the variables when making a fully connected layer or convolution layer. </p>

<p>I couldn't not find anything in the documentation regarding accessing them or adding them in summaries after they are created.</p>
",How do you access the weights and biases when using tf.layers module in TensorFlow 1.0? The advantage of tf.layers module is that you don't have to separately create the variables when making a fully connected layer or convolution layer. I couldn't not find anything in the documentation regarding accessing them or adding them in summaries after they are created.,https://stackoverflow.com/questions/42981493,7656080,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I couldn't not find anything in the documentation regarding accessing them or adding them in summaries after they are created.
52451656,Custom metric across rows in TensorFlow,"<p>I'm trying to calculate metrics for my TensorFlow model across rows with a common key -- specifically precision at k for an information retrieval task -- and I'm finding this extremely nontrivial.  My data include a field that indicates the session ID of each row, and there are variable number of rows for each session ID (but small, under 100).  My task is to train across the rows as independent observations, so I don't want to group on the session ID and train per-session as it will bias the model.  The entire point of the model is to train and evaluate on individual items independently of context, but evaluate the quality of that evaluation within the context, by session IDs.</p>

<p>As a side note, part of the challenge I'm concerned about is data locality as I'm performing distributed training.  <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">However it seems that there may be a single evaluator?</a>  (""Evaluator is a special task that is not part of the training cluster."")</p>

<p>Once I realized that tf.metrics.precision_at_k calculates precision at k within class predictions for a given row / data point and not , I have considered writing a custom metric function to call from within the Estimator train_and_evaluate method that keeps an internal dict of session ID to tuples of labels and predictions, and transforms these into Tensors to feed to tf.metrics.precision_at_k.</p>

<p>Caveats:</p>

<ul>
<li>I don't know if I can store this dict, as I don't think I can put it in the computational graph.  Can / should I try to store its state in the metric method itself?  Will that even be retained after the graph is created, and will it be correctly accessed on subsequent calls to the method?</li>
<li>I don't know how or if I can group items with the same session ID onto the same executor -- even if a method like group_by_window or group_by_reducer on the Dataset works, how does this affect locality in a distributed context?</li>
<li>I could reduce my eval set size to fit into memory but I don't know how to force this to run on only one executor.</li>
</ul>

<p>I haven't had much luck finding any examples or more information online about anything like this, and the TF code and docs can be somewhat unhelpful, so I'd appreciate any advice!  Thanks!</p>
","I'm trying to calculate metrics for my TensorFlow model across rows with a common key -- specifically precision at k for an information retrieval task -- and I'm finding this extremely nontrivial. My data include a field that indicates the session ID of each row, and there are variable number of rows for each session ID (but small, under 100). My task is to train across the rows as independent observations, so I don't want to group on the session ID and train per-session as it will bias the model. The entire point of the model is to train and evaluate on individual items independently of context, but evaluate the quality of that evaluation within the context, by session IDs. As a side note, part of the challenge I'm concerned about is data locality as I'm performing distributed training. However it seems that there may be a single evaluator? (""Evaluator is a special task that is not part of the training cluster."") Once I realized that tf.metrics.precision_at_k calculates precision at k within class predictions for a given row / data point and not , I have considered writing a custom metric function to call from within the Estimator train_and_evaluate method that keeps an internal dict of session ID to tuples of labels and predictions, and transforms these into Tensors to feed to tf.metrics.precision_at_k. Caveats: I haven't had much luck finding any examples or more information online about anything like this, and the TF code and docs can be somewhat unhelpful, so I'd appreciate any advice! Thanks!",https://stackoverflow.com/questions/52451656,5026110,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation," I haven't had much luck finding any examples or more information online about anything like this, and the TF code and docs can be somewhat unhelpful, so I'd appreciate any advice!"
60104249,Missing modules and attributes for training in TensorFlow's Object Detection API,"<p>I'm currently attempting to train an object detection model. I'm following Gilbert Tanner's tutorial on YouTube. I am running TF version 1.9.0.</p>

<p>It seems as though I'm missing the necessary modules. When I run the following command:</p>

<pre><code>python model_main.py --logtostderr --model_dir=training/ --pipeline_config_path=traini
ng/faster_rcnn_inception_v2_pets.config
</code></pre>

<p>I get the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""model_main.py"", line 26, in &lt;module&gt;
    from object_detection import model_lib
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\model_lib.py"", line 28, in &lt;module&gt;
    from object_detection import exporter as exporter_lib
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\exporter.py"", line 24, in &lt;module&gt;
    from object_detection.builders import model_builder
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\builders\model_builder.py"", line 35, in &lt;module&gt;
    from object_detection.models import faster_rcnn_inception_resnet_v2_feature_extractor as frcnn_inc_res
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\models\faster_rcnn_inception_resnet_v2_feature_extractor
.py"", line 30, in &lt;module&gt;
    from nets import inception_resnet_v2
  File ""C:\Users\Admin\Desktop\ObjectDetection\models\research\object_detection\nets\inception_resnet_v2.py"", line 375, in &lt;module&gt;
    batch_norm_updates_collections=tf.compat.v1.GraphKeys.UPDATE_OPS,
AttributeError: module 'tensorflow.compat' has no attribute 'v1'
</code></pre>

<p>For some reason, I've had to fix other problems with certain modules not being in the correct place (for instance, the nets module wasn't placed under the models/research/object_detection directory upon installation, it was instead placed under models/research/slim).</p>

<p>I'm not sure exactly how to fix this issue. I've tried bouncing between different 1.x versions of TensorFlow but each time I am met with similar errors, such as not having the 'v2' attribute. </p>

<p>I suspect I could be lacking a package that should be installed in my environment, but I'm not sure what it could be. I'm also unsure about why the necessary modules aren't properly installed. Here are all of the packages that are installed in my environment:</p>

<pre><code>Package Version Lastest Version
absl-py 0.9.0   0.8.1
astor   0.8.1   0.8.0
biwrap  0.1.6   
bleach  1.5.0   3.1.0
certifi 2019.11.28  2019.11.28
gast    0.3.3   0.3.2
grpcio  1.27.0  1.16.1
h5py    2.10.0  2.10.0
html5lib    0.9999999   1.0.1
keras-applications  1.0.8   1.0.8
keras-preprocessing 1.1.0   1.1.0
markdown    3.1.1   3.1.1
mock    3.0.5   3.0.5
numpy   1.18.1  1.18.1
object-detection    0.1 
pandas  1.0.0   1.0.0
pillow  7.0.0   7.0.0
pip 20.0.2  20.0.2
protobuf    3.11.3  3.11.2
pycocotools 2.0 
python  3.6.10  3.8.1
python-dateutil 2.8.1   2.8.1
pytz    2019.3  2019.3
setuptools  39.1.0  45.1.0
six 1.14.0  1.14.0
sqlite  3.31.1  3.31.1
tensorboard 1.9.0   2.0.0
tensorflow  1.9.0   2.0.0
tensorflow-estimator    1.13.0  2.0.0
tensorflow-plot 0.3.0   
tensorflow-tensorboard  1.5.1   
termcolor   1.1.0   1.1.0
vc  14.1    14.1
vs2015_runtime  14.16.27012 14.16.27012
werkzeug    0.16.1  0.16.1
wheel   0.34.2  0.34.2
wincertstore    0.2 0.2
</code></pre>

<p>Am I missing any necessary packages? Any help on this issue is appreciated. Please let me know if I have not included information that would be helpful.</p>

<p>EDIT:
Line 375 in C:\Users\Admin\Desktop\ObjectDetection\models\research\object_detection\nets\inception_resnet_v2.py is bolded below:</p>

<pre><code>def inception_resnet_v2_arg_scope(
    weight_decay=0.00004,
    batch_norm_decay=0.9997,
    batch_norm_epsilon=0.001,
    activation_fn=tf.nn.relu,
    **batch_norm_updates_collections=tf.compat.v1.GraphKeys.UPDATE_OPS**,
    batch_norm_scale=False):
</code></pre>

<p>Here is the link to the video I'm referring to. My problem is occurring when I run the command at 18:01.
<a href=""https://www.youtube.com/watch?v=HjiBbChYRDw"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=HjiBbChYRDw</a>
I realize the command I provided above is slightly different than the one shown in the video. However, in the written version of the tutorial, Gilbert Tanner has updated the command to the one I provided above.</p>

<p>Changing all references on tf.compat.v1.GraphKeys to tf.GraphKeys works, but more errors arise:</p>

<pre><code>AttributeError: module 'tensorflow.compat' has no attribute 'v2'
</code></pre>

<p>on this function signature:</p>

<pre><code>def global_pool(input_tensor, pool_op=tf.compat.v2.nn.avg_pool2d)
</code></pre>

<p>When I change it to this:</p>

<pre><code>def global_pool(input_tensor, pool_op=tf.nn.avg_pool2d)
</code></pre>

<p>I get this error:</p>

<pre><code>AttributeError: module 'tensorflow.nn' has no attribute 'avg_pool2d'
</code></pre>

<p>There is no documentation for avg_pool2d for TensorFlow 1.x and there is for TensorFlow 2.x, so I'm not sure why it's in this file if I have TensorFlow 1.9.</p>

<p>I notice tf.nn has attributes avg_pool and avg_pool3d, however, changing it to these causes a TypeError:</p>

<pre><code>Traceback (most recent call last):
  File ""model_main.py"", line 109, in &lt;module&gt;
    tf.app.run()
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\training.py"", line 531, in run
    return self.run_local()
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\training.py"", line 669, in run_local
    hooks=train_hooks)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 366, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1119, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1129, in _train_model_default
    input_fn, model_fn_lib.ModeKeys.TRAIN))
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 985, in _get_features_and_labels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1074, in _call_input_fn
    return input_fn(**kwargs)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\inputs.py"", line 504, in _train_input_fn
    params=params)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\inputs.py"", line 607, in train_input
    batch_size=params['batch_size'] if params else train_config.batch_size)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\builders\dataset_builder.py"", line 155, in build
    dataset = data_map_fn(process_fn, num_parallel_calls=num_parallel_calls)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 882, in map
    return ParallelMapDataset(self, map_func, num_parallel_calls)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1899, in __init__
    super(ParallelMapDataset, self).__init__(input_dataset, map_func)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1868, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\framework\function.py"", line 475, in add_to_graph
    self._create_definition_if_needed()
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\framework\function.py"", line 331, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\framework\function.py"", line 340, in _create_definition_if_needed_impl
    self._capture_by_value, self._caller_device)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\framework\function.py"", line 804, in func_graph_from_py_func
    outputs = func(*func_graph.inputs)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1833, in tf_map_func
    ret = map_func(nested_args)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\builders\dataset_builder.py"", line 134, in process_fn
    processed_tensors = decoder.decode(value)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\data_decoders\tf_example_decoder.py"", line 388, in decod
e
    tensors = decoder.decode(serialized_example, items=keys)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\contrib\slim\python\slim\data\tfexample_decoder.py"", line 520, in decode
    outputs.append(handler.tensors_to_item(keys_to_tensors))
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\data_decoders\tf_example_decoder.py"", line 129, in tenso
rs_to_item
    item = self._handler.tensors_to_item(keys_to_tensors)
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\data_decoders\tf_example_decoder.py"", line 98, in tensor
s_to_item
    return tf.maximum(self._name_to_id_table.lookup(unmapped_tensor),
  File ""C:\Users\Admin\Anaconda3\envs\object_detection\lib\site-packages\tensorflow\python\ops\lookup_ops.py"", line 223, in lookup
    (self._key_dtype, keys.dtype))
TypeError: Signature mismatch. Keys must be dtype &lt;dtype: 'float32'&gt;, got &lt;dtype: 'string'&gt;.


</code></pre>

<p>Here is line 98 in tensors_to_item:</p>

<pre><code>    return tf.maximum(self._name_to_id_table.lookup(unmapped_tensor),
                      self._display_name_to_id_table.lookup(unmapped_tensor))
</code></pre>

<p>I'm not sure how to handle this issue and it seems like I shouldn't have changed the function signature. Is having to make this many changes to the modules normal?  </p>
","I'm currently attempting to train an object detection model. I'm following Gilbert Tanner's tutorial on YouTube. I am running TF version 1.9.0. It seems as though I'm missing the necessary modules. When I run the following command: I get the following error: For some reason, I've had to fix other problems with certain modules not being in the correct place (for instance, the nets module wasn't placed under the models/research/object_detection directory upon installation, it was instead placed under models/research/slim). I'm not sure exactly how to fix this issue. I've tried bouncing between different 1.x versions of TensorFlow but each time I am met with similar errors, such as not having the 'v2' attribute. I suspect I could be lacking a package that should be installed in my environment, but I'm not sure what it could be. I'm also unsure about why the necessary modules aren't properly installed. Here are all of the packages that are installed in my environment: Am I missing any necessary packages? Any help on this issue is appreciated. Please let me know if I have not included information that would be helpful. EDIT: Line 375 in C:\Users\Admin\Desktop\ObjectDetection\models\research\object_detection\nets\inception_resnet_v2.py is bolded below: Here is the link to the video I'm referring to. My problem is occurring when I run the command at 18:01. https://www.youtube.com/watch?v=HjiBbChYRDw I realize the command I provided above is slightly different than the one shown in the video. However, in the written version of the tutorial, Gilbert Tanner has updated the command to the one I provided above. Changing all references on tf.compat.v1.GraphKeys to tf.GraphKeys works, but more errors arise: on this function signature: When I change it to this: I get this error: There is no documentation for avg_pool2d for TensorFlow 1.x and there is for TensorFlow 2.x, so I'm not sure why it's in this file if I have TensorFlow 1.9. I notice tf.nn has attributes avg_pool and avg_pool3d, however, changing it to these causes a TypeError: Here is line 98 in tensors_to_item: I'm not sure how to handle this issue and it seems like I shouldn't have changed the function signature. Is having to make this many changes to the modules normal?",https://stackoverflow.com/questions/60104249,11477760,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"There is no documentation for avg_pool2d for TensorFlow 1.x and there is for TensorFlow 2.x, so I'm not sure why it's in this file if I have TensorFlow 1.9."
58527671,Finding the input Tensors of a Tensorflow Operation,"<p>I am trying to generate some kind of textual representation for the TensorFlow Computational Graph. I know that Tensorboard can provide me with the visualization. However, I need some kind of representation (adjacency matrix or adjacency list) from where I can parse information associated with graphs.</p>

<p>So far, I have tried the following:</p>

<pre><code>import tensorflow as tf

a = tf.constant(1.3, name = const_a)
b = tf.constant(3.1, name = const_b)
c = tf.add(a,b, name = 'addition')
d = tf.multiply(c,a, name = 'multiplication')
e = tf.add(d,c, name = 'addition_1')

with tf.Session() as sess:
     print(sess.run([c,d,e]))
</code></pre>

<p>After this, I decided to keep the graph object in a separate variable and tried to parse information from there:</p>

<pre><code>graph = tf.get_default_graph()
</code></pre>

<p>I found out how to get the list of all operations from <a href=""https://www.tensorflow.org/api_docs/python/tf/Operation"" rel=""nofollow noreferrer"">this</a> documentation.</p>

<pre><code>for op in graph.get_operations():
     print(op.values())
</code></pre>

<p>This part actually provides me with the information of the nodes of the computation graph.</p>

<pre><code>(&lt;tf.Tensor 'const_a:0' shape=() dtype=float32&gt;,)
(&lt;tf.Tensor 'const_b:0' shape=() dtype=float32&gt;,)
(&lt;tf.Tensor 'addition:0' shape=() dtype=float32&gt;,)
(&lt;tf.Tensor 'multiplication:0' shape=() dtype=float32&gt;,)
(&lt;tf.Tensor 'addition_1:0' shape=() dtype=float32&gt;,)
</code></pre>

<p>However, I cannot seem to find any method that can provide me with information regarding the edges of the computation graph. I cannot find any method that can give me the input tensors associated with each operation. I would like to know that the operation named <code>addition_1</code> has input tensors produced by the operations <code>addition</code> and <code>multiplication;</code> or something that can be used to derive this information. From the <a href=""https://www.tensorflow.org/api_docs/python/tf/Operation"" rel=""nofollow noreferrer"">documentation</a>, it seems that the <code>Operation</code> object has a property named <code>inputs</code> which may be the thing I am looking for. Nonetheless, I don't see a method that can be called to return this property.</p>
","I am trying to generate some kind of textual representation for the TensorFlow Computational Graph. I know that Tensorboard can provide me with the visualization. However, I need some kind of representation (adjacency matrix or adjacency list) from where I can parse information associated with graphs. So far, I have tried the following: After this, I decided to keep the graph object in a separate variable and tried to parse information from there: I found out how to get the list of all operations from this documentation. This part actually provides me with the information of the nodes of the computation graph. However, I cannot seem to find any method that can provide me with information regarding the edges of the computation graph. I cannot find any method that can give me the input tensors associated with each operation. I would like to know that the operation named addition_1 has input tensors produced by the operations addition and multiplication; or something that can be used to derive this information. From the documentation, it seems that the Operation object has a property named inputs which may be the thing I am looking for. Nonetheless, I don't see a method that can be called to return this property.",https://stackoverflow.com/questions/58527671,6868602,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"From the documentation, it seems that the Operation object has a property named inputs which may be the thing I am looking for. Nonetheless, I don't see a method that can be called to return this property."
44764887,How to restore trained LinearClassifier from tensorflow high level API and make predictions,"<p>I have trained a logistic regression model model using tensorflow's LinearClassifier() class, and set the model_dir parameter, which specifies the location where to save metagrahps of checkpoints during model training:</p>

<pre><code># Create temporary directory where metagraphs will evenually be saved
model_dir = tempfile.mkdtemp()

logistic_model = tf.contrib.learn.LinearClassifier(
    feature_columns=feature_columns, 
    n_classes=num_labels, model_dir=model_dir)
</code></pre>

<p>I've been reading about restoring models from metagraphs, but have found nothing about how to do so for models created using the high level api.  LinearClassifier() has a predict() function, but I can't find any documentation on how to run prediction using an instance of the model that has been restored via checkpoint metagraph. How would I go about doing this?  Once the model is restored, my understanding is that I am working with a tf.Sess object, which lacks all of the built in functionality of the LinearClassifier class, like this:</p>

<pre><code>with tf.Session() as sess:
  new_saver = tf.train.import_meta_graph('my-save-dir/my-model-10000.meta')
  new_saver.restore(sess, 'my-save-dir/my-model-10000')
  # Run prediction algorithm...
</code></pre>

<p>How do I run the same prediction algorithm used by the high-level api to make predictions on a restored model? Is there a better way to approach this?</p>

<p>Thanks for your input.</p>
","I have trained a logistic regression model model using tensorflow's LinearClassifier() class, and set the model_dir parameter, which specifies the location where to save metagrahps of checkpoints during model training: I've been reading about restoring models from metagraphs, but have found nothing about how to do so for models created using the high level api. LinearClassifier() has a predict() function, but I can't find any documentation on how to run prediction using an instance of the model that has been restored via checkpoint metagraph. How would I go about doing this? Once the model is restored, my understanding is that I am working with a tf.Sess object, which lacks all of the built in functionality of the LinearClassifier class, like this: How do I run the same prediction algorithm used by the high-level api to make predictions on a restored model? Is there a better way to approach this? Thanks for your input.",https://stackoverflow.com/questions/44764887,5540936,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I can't find any documentation on how to run prediction using an instance of the model that has been restored via checkpoint metagraph. 
44462550,Keras + Tensorflow : Debug NaNs,"<p>Here is a great question on how to find the first occurence of Nan in a tensorflow graph:</p>

<p><a href=""https://stackoverflow.com/questions/34046048/debugging-nans-in-the-backward-pass"">Debugging nans in the backward pass</a></p>

<p>The answer is quite helpful, here is the code from it:</p>

<pre><code>train_op = ...
check_op = tf.add_check_numerics_ops()

sess = tf.Session()
sess.run([train_op, check_op])  # Runs training and checks for NaNs
</code></pre>

<p>Apparently, running the training and the numerical check at the same time will result in an error report as soon as Nan is encountered for the first time.</p>

<p>How do I integrate this into Keras ?
In the documentation, I can't find anything that looks like this.</p>

<p>I checked the code, too.
The update step is executed here:
<a href=""https://github.com/fchollet/keras/blob/master/keras/engine/training.py"" rel=""noreferrer"">https://github.com/fchollet/keras/blob/master/keras/engine/training.py</a></p>

<p>There is a function called <code>_make_train_function</code> where an operation to compute the loss and apply updates is created. This is later called to train the network.</p>

<p>I could change the code like this (always assuming that we're running on a tf backend):</p>

<pre><code>check_op = tf.add_check_numerics_ops()

self.train_function = K.function(inputs, 
    [self.total_loss] + self.metrics_tensors + [check_op],
    updates=updates, name='train_function', **self._function_kwargs)
</code></pre>

<p>I'm currently trying to set this up properly and not sure whether the code above actually works.
Maybe there is an easier way ?</p>
","Here is a great question on how to find the first occurence of Nan in a tensorflow graph: Debugging nans in the backward pass The answer is quite helpful, here is the code from it: Apparently, running the training and the numerical check at the same time will result in an error report as soon as Nan is encountered for the first time. How do I integrate this into Keras ? In the documentation, I can't find anything that looks like this. I checked the code, too. The update step is executed here: https://github.com/fchollet/keras/blob/master/keras/engine/training.py There is a function called _make_train_function where an operation to compute the loss and apply updates is created. This is later called to train the network. I could change the code like this (always assuming that we're running on a tf backend): I'm currently trying to set this up properly and not sure whether the code above actually works. Maybe there is an easier way ?",https://stackoverflow.com/questions/44462550,497600,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"How do I integrate this into Keras ? In the documentation, I can't find anything that looks like this. "
43126116,Range of size of tensor's dimension - tf.range,"<p>I'm trying to define an operation for a NN I'm implementing, but to do so I need to iterate over the dimension of a tensor. I have a small working example below.</p>

<pre><code>X = tf.placeholder(tf.float32, shape=[None, 10])
idx = [[i] for i in tf.range(X.get_shape()[0])]
</code></pre>

<p>This produces an error stating</p>

<pre><code>ValueError: Cannot convert an unknown Dimension to a Tensor: ?
</code></pre>

<p>When using the same code but using <code>tf.shape</code> instead, resulting in the code being</p>

<pre><code>X = tf.placeholder(tf.float32, shape=[None, 10])
idx = [[i] for i in tf.range(tf.shape(X)[0])]
</code></pre>

<p>Gives the following error</p>

<pre><code>TypeError: 'Tensor' object is not iterable.
</code></pre>

<p>The way that I'm implementing this NN, the <code>batch_size</code> isn't defined until the training function, which is at the end of the code. This is just where I'm building the graph itself, so the <code>batch_size</code> isn't known by this point, and it can't be fixed as the training <code>batch_size</code> and the test set batch_sizes are different. </p>

<p>What is the best way to fix this? This is the last thing keeping my code from running, as I got it to run with a fixed <code>batch_size</code>, though those results aren't useful. I've been pouring over the TensorFlow API Documentation and stack overflow for weeks to no avail.</p>

<p>I've also tried to feed in a placeholder into the range, so when I'm running the test/training set the code would be the following</p>

<pre><code>X = tf.placeholder(tf.float32, shape=[None, 10])
bs = tf.placeholder(tf.int32)

def My_Function(X):
    # Do some stuff to X
    idx = [[i] for i in tf.range(bs)]
    # return some tensor

A = tf.nn.relu(My_Function(X))
</code></pre>

<p>However, this gives the same error as above</p>

<pre><code>TypeError: 'Tensor' object is not iterable.
</code></pre>
","I'm trying to define an operation for a NN I'm implementing, but to do so I need to iterate over the dimension of a tensor. I have a small working example below. This produces an error stating When using the same code but using tf.shape instead, resulting in the code being Gives the following error The way that I'm implementing this NN, the batch_size isn't defined until the training function, which is at the end of the code. This is just where I'm building the graph itself, so the batch_size isn't known by this point, and it can't be fixed as the training batch_size and the test set batch_sizes are different. What is the best way to fix this? This is the last thing keeping my code from running, as I got it to run with a fixed batch_size, though those results aren't useful. I've been pouring over the TensorFlow API Documentation and stack overflow for weeks to no avail. I've also tried to feed in a placeholder into the range, so when I'm running the test/training set the code would be the following However, this gives the same error as above",https://stackoverflow.com/questions/43126116,1560300,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,I've been pouring over the TensorFlow API Documentation and stack overflow for weeks to no avail.
50442156,Loading a model from tensorflow SavedModel onto mutliple GPUs,"<p>Let's say someone hands me a TF SavedModel and I would like to replicate this model on the 4 GPUs I have on my machine so I can run inference in parallel on batches of data. Are there any good examples of how to do this? </p>

<p>I can load a saved model in this way:</p>

<pre><code>def load_model(self, saved_model_dirpath):
    '''Loads a model from a saved model directory - this should 
       contain a .pb file and a variables directory'''

    signature_key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY
    input_key = 'input'
    output_key = 'output'

    meta_graph_def = tf.saved_model.loader.load(self.sess, [tf.saved_model.tag_constants.SERVING],
                                                saved_model_dirpath)
    signature = meta_graph_def.signature_def

    input_tensor_name = signature[signature_key].inputs[input_key].name
    output_tensor_name = signature[signature_key].outputs[output_key].name

    self.input_tensor = self.sess.graph.get_tensor_by_name(input_tensor_name)
    self.output_tensor = self.sess.graph.get_tensor_by_name(output_tensor_name)
</code></pre>

<p>..but this would require that I have a handle to the session. For models that I have written myself, I would have access to the inference function and I could just call it and wrap it using <code>with tf.device()</code>, but in this case, I'm not sure how to extract the inference function out of a Saved Model. Should I load 4 separate sessions or is there a better way? Couldn't find much documentation on this, but apologies in advance if I missed something. Thanks!</p>
","Let's say someone hands me a TF SavedModel and I would like to replicate this model on the 4 GPUs I have on my machine so I can run inference in parallel on batches of data. Are there any good examples of how to do this? I can load a saved model in this way: ..but this would require that I have a handle to the session. For models that I have written myself, I would have access to the inference function and I could just call it and wrap it using with tf.device(), but in this case, I'm not sure how to extract the inference function out of a Saved Model. Should I load 4 separate sessions or is there a better way? Couldn't find much documentation on this, but apologies in advance if I missed something. Thanks!",https://stackoverflow.com/questions/50442156,3953896,Inadequate Examples,Lack of Alternative Solutions/Documentation,"Couldn't find much documentation on this, but apologies in advance if I missed something."
50724495,Train and validate using tensorflow estimator,"<p>I have created a shallow NN using tf.estimator API. I would like to something similar to the hyperparameter search explained in here <a href=""https://www.youtube.com/watch?time_continue=948&amp;v=eBbEDRsCmv4"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?time_continue=948&amp;v=eBbEDRsCmv4</a> at TensorFlow Dev Summit.</p>

<p>I could not find any updated documentation about how can you do this. I have the following code (I will try to simplify as much as possible):</p>

<pre><code># Define nn architecture
def neural_net(features):
    input_layer = tf.cast(features['x'], tf.float32)
    hidden_layer = nn_layer(input_layer, 10, 'hidden_layer', act=tf.nn.relu)
    out_layer = nn_layer(hidden_layer, 2, 'out_layer', act=tf.nn.relu)
    return out_layer

# Define model function
def model_fn(features, labels, mode):
    # Build the neural network
    logits = neural_net(features&lt;9


    with tf.name_scope('loss'):
    # Define loss and optimizer
        loss = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)

    # Configure the Training
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(
        loss=loss,
        global_step=tf.train.get_global_step())

        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)


nn_classifier = tf.estimator.Estimator(model_fn=model_fn)


train_input_fn = tf.estimator.inputs.numpy_input_fn(
            x={""x"": train_data},
            y=train_labels,
            batch_size=100,
            num_epochs=None,
            shuffle=True)

nn_classifier.train(
        input_fn=train_input_fn,
        steps=20000
        )
</code></pre>

<p>Executing this code I can obtain the summary for the loss and observe it in Tensorboard. But imagine I want to obtain different curves. Let's say that I want to see how the loss evolves with the number of samples, so I would train two models with different sample size. Or two models with a different architecture... whatever.</p>

<p>How can I get these two curves in Tensorboard?</p>
","I have created a shallow NN using tf.estimator API. I would like to something similar to the hyperparameter search explained in here https://www.youtube.com/watch?time_continue=948&amp;v=eBbEDRsCmv4 at TensorFlow Dev Summit. I could not find any updated documentation about how can you do this. I have the following code (I will try to simplify as much as possible): Executing this code I can obtain the summary for the loss and observe it in Tensorboard. But imagine I want to obtain different curves. Let's say that I want to see how the loss evolves with the number of samples, so I would train two models with different sample size. Or two models with a different architecture... whatever. How can I get these two curves in Tensorboard?",https://stackoverflow.com/questions/50724495,8380638,Documentation Replication on Other Examples,Lack of Alternative Solutions/Documentation,I could not find any updated documentation about how can you do this.
52234780,Reading from .tfrecord files using tf.data.Dataset,"<p>I want to read the dataset generated by <a href=""https://github.com/tensorflow/models/blob/master/research/slim/datasets/download_and_convert_cifar10.py"" rel=""nofollow noreferrer"">this code</a> with the <code>tf.data.Dataset</code> api. The repo shows it was written like this:</p>

<pre><code>def image_to_tfexample(image_data, image_format, height, width, class_id):
  return tf.train.Example(features=tf.train.Features(feature={
      'image/encoded': bytes_feature(image_data),
      'image/format': bytes_feature(image_format),
      'image/class/label': int64_feature(class_id),
      'image/height': int64_feature(height),
      'image/width': int64_feature(width),
  }))
</code></pre>

<p>with <code>(encoded byte-string, b'png', 32, 32, label)</code> as parameters.</p>

<p>So, to read the .tfrecord file, the data format would have to be:</p>

<pre><code>example_fmt = {
    'image/encoded': tf.FixedLenFeature((), tf.string, """"),
    'image/format': tf.FixedLenFeature((), tf.string, """"),
    'image/class/label': tf.FixedLenFeature((), tf.int64, -1),
    'image/height': tf.FixedLenFeature((), tf.int64, -1),
    'image/width': tf.FixedLenFeature((), tf.int64, -1)
}
parsed = tf.parse_single_example(example, example_fmt)
image = tf.decode_raw(parsed['image/encoded'], out_type=tf.uint8)
</code></pre>

<p>But it doesn't work. The dataset is empty after reading and generating an iterator with it raises <code>OutOfRangeError: End of sequence</code>.</p>

<p>A short python script for reproduction can be found <a href=""https://pastebin.com/zEG4GKm9"" rel=""nofollow noreferrer"">here</a>. I'm struggling to find exact documentation or examples for this problem.</p>
","I want to read the dataset generated by this code with the tf.data.Dataset api. The repo shows it was written like this: with (encoded byte-string, b'png', 32, 32, label) as parameters. So, to read the .tfrecord file, the data format would have to be: But it doesn't work. The dataset is empty after reading and generating an iterator with it raises OutOfRangeError: End of sequence. A short python script for reproduction can be found here. I'm struggling to find exact documentation or examples for this problem.",https://stackoverflow.com/questions/52234780,4443082,Documentation Replication on Other Examples,Lack of Alternative Solutions/Documentation,I'm struggling to find exact documentation or examples for this problem.
52254253,How does tf.layers.dense() interact with inputs of higher dim?,"<p>In tensorflow layers.dense(inputs, units, activation) implements a Multi-Layer Perceptron layer with arbitrary activation function. </p>

<p>Output = activation(matmul(input, weights) + bias)</p>

<p>Typically input has shape=[batch_size, input_size] and might look like this: (units = 128 and activation = tf.nn.relu are chosen arbitrarily)</p>

<pre><code>inputx = tf.placeholder(float, shape=[batch_size, input_size])
dense_layer = tf.layers.dense(inputx, 128, tf.nn.relu)
</code></pre>

<p>I have not found any documentation on what would happen, if i fed higher dimensional input, e.g. because one might have time_steps resulting in a tensor of shape=[time_step, batch_size, input_size]. What one would want here is that the layer is applied to each single input_vector for each timestep for each element of the batch. To put it a bit differently, the internal matmul of layers.dense() should simply use broadcasting in numpy style. Is the behaviour i expect here what actually happens? I.e. is: </p>

<pre><code>inputx = tf.placeholder(float, shape=[time_step, batch_size, input_size])
dense_layer = tf.layers.dense(inputx, 128, tf.nn.relu)
</code></pre>

<p>applying the dense layer to each input of size input_size for each time_step for each element in batch_size? This should then result in a tensor(in dense_layer above) of shape=[time_step, batch_size, 128]
I'm asking, as e.g. tf.matmul does not support broadcasting in the numpy style, so i'm not sure, how tensorflow handles these cases.</p>

<p>Edit: <a href=""https://stackoverflow.com/questions/46697389/reshape-3d-tensor-before-dense-layer"">This post is related, but does not finally answer my question</a></p>
","In tensorflow layers.dense(inputs, units, activation) implements a Multi-Layer Perceptron layer with arbitrary activation function. Output = activation(matmul(input, weights) + bias) Typically input has shape=[batch_size, input_size] and might look like this: (units = 128 and activation = tf.nn.relu are chosen arbitrarily) I have not found any documentation on what would happen, if i fed higher dimensional input, e.g. because one might have time_steps resulting in a tensor of shape=[time_step, batch_size, input_size]. What one would want here is that the layer is applied to each single input_vector for each timestep for each element of the batch. To put it a bit differently, the internal matmul of layers.dense() should simply use broadcasting in numpy style. Is the behaviour i expect here what actually happens? I.e. is: applying the dense layer to each input of size input_size for each time_step for each element in batch_size? This should then result in a tensor(in dense_layer above) of shape=[time_step, batch_size, 128] I'm asking, as e.g. tf.matmul does not support broadcasting in the numpy style, so i'm not sure, how tensorflow handles these cases. Edit: This post is related, but does not finally answer my question",https://stackoverflow.com/questions/52254253,6917400,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,"I have not found any documentation on what would happen, if i fed higher dimensional input, e.g. because one might have time_steps resulting in a tensor of shape=[time_step, batch_size, input_size]."
47231777,how to use tf.metrics.__ with estimator model predict output,"<p>I try to follow the tensorflow API 1.4 document to achieve what I need in a learning process.</p>

<p>I am now at this stage, can produce a predict object for example:</p>

<pre><code>classifier = tf.estimator.DNNClassifier(feature_columns=feature_cols,hidden_units=[10, 20, 10], n_classes=3, model_dir=""/tmp/xlz_model"")

predict = classifier.predict(input_fn=input_pd_fn_prt (test_f),predict_keys=[""class_ids""])
label =tf.constant(test_l.values, tf.int64)
</code></pre>

<p>how can I use predict and label in <code>tf.metrics.auc</code> for example:</p>

<pre><code>out, opt = tf.metrics.auc(label, predict)
</code></pre>

<p>I have tried so many different options. there are no clear documentation how these tensorflow APIs can be should be used. </p>
","I try to follow the tensorflow API 1.4 document to achieve what I need in a learning process. I am now at this stage, can produce a predict object for example: how can I use predict and label in tf.metrics.auc for example: I have tried so many different options. there are no clear documentation how these tensorflow APIs can be should be used.",https://stackoverflow.com/questions/47231777,1203186,Documentation Replicability,Lack of Alternative Solutions/Documentation,"I try to follow the tensorflow API 1.4 document to achieve what I need in a learning process. I am now at this stage, can produce a predict object for example: how can I use predict and label in tf.metrics.auc for example: I have tried so many different options. there are no clear documentation how these tensorflow APIs can be should be used."
41156460,tensorflow doing gradients on sparse variable,"<p>I am trying to train a sparse variable in tensorflow, As far as I know current tensorflow doesn't allow for sparse variable. </p>

<p>I found two threads discussing similar issue: <a href=""https://stackoverflow.com/questions/37001686/using-sparsetensor-as-a-trainable-variable"">using-sparsetensor-as-a-trainable-variable</a> and <a href=""https://stackoverflow.com/questions/35803425/update-only-part-of-the-word-embedding-matrix-in-tensorflow"">update-only-part-of-the-word-embedding-matrix-in-tensorflow</a>. I am not quitely understand the answer, and it would be good if there is any example code</p>

<p>one way I have tried is:</p>

<pre><code># initialize the sparse variable sp_weights
# assuming w_s is the input sparse matrix contains indices information
dim=20
identity = tf.constant(np.identity(dim), dtype=tf.float32)
A=tf.sparse_tensor_dense_matmul(w_s, identity)  # convert w_s to dense
w_init = tf.random_normal([dim, dim], mean=0.0, stddev=0.1) 
w_tensor = tf.mul(A, w_init) # random initialize sparse tensor
vars['sp_weights'] = tf.Variable(w_tensor)

# doing some operations...
</code></pre>

<p>when compute the gradients, according to the <a href=""https://stackoverflow.com/questions/35803425/update-only-part-of-the-word-embedding-matrix-in-tensorflow"">second link</a> using <code>tf.IndexedSlices</code> </p>

<pre><code>grad = opt.compute_gradients(loss)
train_op = opt.apply_gradients(
    [tf.IndexedSlices(grad, indices)]) # indices is extracted from w_s
</code></pre>

<p>the above code of course don't work, and I am confused here. tf.IndexedSlices make the input to be IndexedSlices instance, how to use it to update the gradients given the indices? Also, many people mentioned using tf.scatter_add/sub/update. The official document doesn't contain any example code on how to use and where to use for gradient update. should I use tf.IndexedSlices or tf.scatter? it would be much helpful if there is any example code. Thank you!</p>
","I am trying to train a sparse variable in tensorflow, As far as I know current tensorflow doesn't allow for sparse variable. I found two threads discussing similar issue: using-sparsetensor-as-a-trainable-variable and update-only-part-of-the-word-embedding-matrix-in-tensorflow. I am not quitely understand the answer, and it would be good if there is any example code one way I have tried is: when compute the gradients, according to the second link using tf.IndexedSlices the above code of course don't work, and I am confused here. tf.IndexedSlices make the input to be IndexedSlices instance, how to use it to update the gradients given the indices? Also, many people mentioned using tf.scatter_add/sub/update. The official document doesn't contain any example code on how to use and where to use for gradient update. should I use tf.IndexedSlices or tf.scatter? it would be much helpful if there is any example code. Thank you!",https://stackoverflow.com/questions/41156460,6233298,Inadequate Examples,Inadequate Examples,The official document doesn't contain any example code on how to use and where to use for gradient update. 
65725030,How can I manage Queues in Tensorflow 2.0?,"<p>Well, I'm trying to understand the Threading and Queues.</p>
<p>I saw many documents on the web, but surprisingly there is not even a single example of this topic in tensorflow 2.0.</p>
<p>What I want my queues to do is to,</p>
<ol>
<li>Define an operation that generates examples.</li>
<li>Define a queue.</li>
<li>Define an enqueue_operation that enqueue examples in the queue made above using multiple threads.</li>
<li>Control this queue to dequeue batches.</li>
</ol>
<p>What I have in mind is,</p>
<pre><code>import tensorflow as tf
import threading

batch_size = 2
example = tf.random.normal([1, 2]) # Generate an example, shape = [1, 2]
queue = tf.queue.RandomShuffleQueue(capacity=10, min_after_dequeue=0, \
    dyptes=tf.float32, shapes=[1, 2])
enqueue_op = queue.enqueue(example)
# inputs = queue.dequeue(2) # Don't run this. This would stop your computer.
</code></pre>
<p>I have no idea what I'm doing. I also learned that how to manage multiple threads using <code>tf.train.Coordinator()</code> but I don't know where to use this..</p>
<p>While asking this, I have a suspicion that many APIs in the <code>tf.data.Dataset</code> replace all of these and multiple threads can be replaced with the <code>tf.data.experimental.AUTOTUNE</code>.</p>
<p>Sorry for all the mess here. I can't arrange this properly even during asking. <br/>
Any comments will be appreciated. Thanks in advance.</p>
","Well, I'm trying to understand the Threading and Queues. I saw many documents on the web, but surprisingly there is not even a single example of this topic in tensorflow 2.0. What I want my queues to do is to, What I have in mind is, I have no idea what I'm doing. I also learned that how to manage multiple threads using tf.train.Coordinator() but I don't know where to use this.. While asking this, I have a suspicion that many APIs in the tf.data.Dataset replace all of these and multiple threads can be replaced with the tf.data.experimental.AUTOTUNE. Sorry for all the mess here. I can't arrange this properly even during asking. Any comments will be appreciated. Thanks in advance.",https://stackoverflow.com/questions/65725030,7820717,Inadequate Examples,Inadequate Examples,"I saw many documents on the web, but surprisingly there is not even a single example of this topic in tensorflow 2.0."
71734880,Any example workflow from TensorFlow to OpenMV?,"<p>I have trained an image multi classification model based on MobileNet-V2(Only the Dense layer has been added), and have carried out full integer quantization(INT8), and then exported model.tflite file, using TF Class () to call this model.</p>
<p>Here is my code to quantify it:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np
import pathlib


def representative_dataset():
    for _ in range(100):
        data = np.random.rand(1, 96, 96, 3)  // random tensor for test
        yield [data.astype(np.float32)]


converter = tf.lite.TFLiteConverter.from_saved_model('saved_model/my_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
tflite_quant_model = converter.convert()

tflite_models_dir = pathlib.Path(&quot;/tmp/mnist_tflite_models/&quot;)
tflite_models_dir.mkdir(exist_ok=True, parents=True)

tflite_model_quant_file = tflite_models_dir/&quot;mnist_model_quant.tflite&quot;
tflite_model_quant_file.write_bytes(tflite_quant_model)
</code></pre>
<p>The accuracy of this model is quite good in the test while training. However, when tested on openmv, the same label is output for all objects (although the probability is slightly different).</p>
<p>I looked up some materials, one of them mentioned TF Classify() has offset and scale parameters, which is related to compressing RGB values to [- 1,0] or [0,1] during training, but this parameter is not available in the official API document.</p>
<pre class=""lang-py prettyprint-override""><code>for obj in tf.classify(self.net , img1, min_scale=1.0, scale_mul=0.5, x_overlap=0.0, y_overlap=0.0):
          print(&quot;**********\nTop 1 Detections at [x=%d,y=%d,w=%d,h=%d]&quot; % obj.rect())
          sorted_list = sorted(zip(self.labels, obj.output()), key = lambda x: x[1], reverse = True)
          for i in range(1):
          print(&quot;%s = %f&quot; % (sorted_list[i][0], sorted_list[i][1]))
          return sorted_list[i][0]
</code></pre>
<p>So are there any examples of workflow from tensorflow training model to deployment to openmv?</p>
","I have trained an image multi classification model based on MobileNet-V2(Only the Dense layer has been added), and have carried out full integer quantization(INT8), and then exported model.tflite file, using TF Class () to call this model. Here is my code to quantify it: The accuracy of this model is quite good in the test while training. However, when tested on openmv, the same label is output for all objects (although the probability is slightly different). I looked up some materials, one of them mentioned TF Classify() has offset and scale parameters, which is related to compressing RGB values to [- 1,0] or [0,1] during training, but this parameter is not available in the official API document. So are there any examples of workflow from tensorflow training model to deployment to openmv?",https://stackoverflow.com/questions/71734880,17221142,Lack of Alternative Solutions/Documentation,Inadequate Examples,So are there any examples of workflow from tensorflow training model to deployment to opencv?
39638468,What is the right way to make a barrier in distributed tensorflow?,"<p>During distributed training I want to sync after each epoch, do some calculations on chief worker and proceed or stop training depending on these calculations. I need a barrier to do so.</p>

<p>I don't see anything similar in documentation, so I implemented solution based on queues (similar to how gradients are stored and applied in distributed training):</p>

<pre><code>def build_barrier(tasks, task_index, barrier_name):
    queues = []
    for i, task in enumerate(tasks):
        with tf.device('%s/cpu:0' % task):
            with tf.name_scope(barrier_name):
                queues.append(
                    tf.FIFOQueue(
                        len(tasks),
                        (tf.float32),
                        shapes=(()),
                        name=str(i),
                        shared_name=str(i)))

    with tf.control_dependencies([queue.enqueue(1.) for queue in queues]):
        return queues[task_index].dequeue_many(len(tasks))
</code></pre>

<p>The idea is to create a queue per worker. For 'signal' I push a token in each queue and for 'join' I dequeue so many tokens from corresponding queue how many tasks I want to synchronize.</p>

<p>The question is: is it the right way to do or there is a better way?</p>
","During distributed training I want to sync after each epoch, do some calculations on chief worker and proceed or stop training depending on these calculations. I need a barrier to do so. I don't see anything similar in documentation, so I implemented solution based on queues (similar to how gradients are stored and applied in distributed training): The idea is to create a queue per worker. For 'signal' I push a token in each queue and for 'join' I dequeue so many tokens from corresponding queue how many tasks I want to synchronize. The question is: is it the right way to do or there is a better way?",https://stackoverflow.com/questions/39638468,2570037,Inadequate Examples,Inadequate Examples,"I don't see anything similar in documentation, so I implemented solution based on queues (similar to how gradients are stored and applied in distributed training)"
41164274,Creating a Tensor using a pre-populated pd dataframe?,"<p>I am trying to create a item-item based collaborative filtering recommendation engine. Because of the large volume of data flowing through, I have had to use TensorFlow. However I even after spending hours on the documentation and on the internet, I am unable to figure out how to create a tensor using a pre-populated ndarray. </p>

<p>I am trying to transpose a ndarray with user item actions to record the information in a tensor. I have debugged multiple errors including shape mismatches only to find a new error I can't find any information around. Below is the code. Any help/suggestions is highly appreciated.</p>

<pre><code>user_item_matrix = tf.Variable(np.zeros(shape = (num_usr,num_prd)),dtype=tf.int32)
init_op = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init_op)
for index,row in user_item_action.iterrows():
    update_row = usr_ht[row['user_id']]
    update_col = prd_ht[row['product_id']]
# Updating row slices of the tensor
update = [0]*num_prd
update[update_col] = row['action_score']
user_item_matrix = sess.run(tf.scatter_add(user_item_matrix,update_row,np.transpose(update)))
sess.close()
</code></pre>

<p>TypeError: Input 'ref' of 'ScatterAdd' Op requires l-value input</p>

<p>user_item_action.head():
        user_id     product_id        action_score
1354    76864       196823            10
2626    23364       234437            10
6422     8055       231014            10
9877    81965       200476            10
13334   88132       240015            10</p>
","I am trying to create a item-item based collaborative filtering recommendation engine. Because of the large volume of data flowing through, I have had to use TensorFlow. However I even after spending hours on the documentation and on the internet, I am unable to figure out how to create a tensor using a pre-populated ndarray. I am trying to transpose a ndarray with user item actions to record the information in a tensor. I have debugged multiple errors including shape mismatches only to find a new error I can't find any information around. Below is the code. Any help/suggestions is highly appreciated. TypeError: Input 'ref' of 'ScatterAdd' Op requires l-value input user_item_action.head(): user_id product_id action_score 1354 76864 196823 10 2626 23364 234437 10 6422 8055 231014 10 9877 81965 200476 10 13334 88132 240015 10",https://stackoverflow.com/questions/41164274,4425827,Inadequate Examples,Inadequate Examples,"However I even after spending hours on the documentation and on the internet, I am unable to figure out how to create a tensor using a pre-populated ndarray. "
42598841,using validation monitor in tflearn.regression to create confusion matrix,"<p>So I have been trying to create a confusion metrics in my autoencoder</p>

<pre><code>from __future__ import division, print_function, absolute_import

import numpy as np
#import matplotlib.pyplot as plt
import tflearn
import tensorflow as tf
from random import randint
from tensorflow.contrib import metrics as ms 
# Data loading and preprocessing
import tflearn.datasets.mnist as mnist
Images, Lables, testImages, testLables = mnist.load_data(one_hot=True)


f = randint(0,20)

x = tf.placeholder(""float"",[None, 784])
y = tf.placeholder(""float"",[None, 10])
# Building the encoder
encoder = tflearn.input_data(shape=[None, 784])
encoder = tflearn.fully_connected(encoder, 256)
encoder = tflearn.fully_connected(encoder, 64)
encoder = tflearn.fully_connected(encoder, 10)

acc= tflearn.metrics.Accuracy()

# Regression, with mean square error
net = tflearn.regression(encoder, optimizer='adam', learning_rate=0.001,
                         loss='mean_square', metric=acc, shuffle_batches=True, validation_monitors = ?)


model = tflearn.DNN(net, tensorboard_verbose=0)

model.fit(Images, Lables, n_epoch=20, validation_set=(testImages, testLables),
          run_id=""auto_encoder"", batch_size=256,show_metric=True)

#Applying the above model on test Images and evaluating as well as prediction of the labels

evali= model.evaluate(testImages,testLables)
print(""Accuracy of the model is :"", evali)
lables = model.predict_label(testImages)
print(""The predicted labels are :"",lables[f])
prediction = model.predict(testImages)
print(""The predicted probabilities are :"", prediction[f])
</code></pre>

<p>I have gone through the documantation but they were not very useful to me.</p>

<p>How would I configure to get the confusion matrix?</p>

<pre><code>validation_monitors ={?}
</code></pre>
",So I have been trying to create a confusion metrics in my autoencoder I have gone through the documantation but they were not very useful to me. How would I configure to get the confusion matrix?,https://stackoverflow.com/questions/42598841,5540592,Inadequate Examples,Inadequate Examples,So I have been trying to create a confusion metrics in my autoencoder I have gone through the documantation but they were not very useful to me.
42838796,"Value error: Cannot feed value of shape (5, 15) for Tensor 'one_hot:0', which has shape '(5, 15, 2)'","<p>this is the code </p>

<pre><code>num_epochs = 100
total_series_length = 50000
truncated_backprop_length = 15
state_size = 4
num_classes = 2
echo_step = 3
batch_size = 5
num_batches = total_series_length//batch_size//truncated_backprop_length
</code></pre>

<p>genreating data{...}</p>

<pre><code>batchX_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])
batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])

#and one for the RNN state, 5,4 
init_state = tf.placeholder(tf.float32, [batch_size, state_size])

batchX_placeholder = tf.one_hot(batchX_placeholder, num_classes)
inputs_series = tf.unstack(batchX_placeholder, axis=1)

cell = tf.contrib.rnn.BasicRNNCell(state_size)
rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, inputs_series, initial_state=init_state)
</code></pre>

<p>some optimization code{....}
and then creating the graph</p>

<pre><code>#Step 3 Training the network
with tf.Session() as sess:
    #we stupidly have to do this everytime, it should just know
    #that we initialized these vars. v2 guys, v2..
    sess.run(tf.initialize_all_variables())
    #interactive mode
    plt.ion()
    #initialize the figure
    plt.figure()
    #show the graph
    plt.show()
    #to show the loss decrease
    loss_list = []

    for epoch_idx in range(num_epochs):
        #generate data at eveery epoch, batches run in epochs
        x,y = generateData()
        #initialize an empty hidden state
        _current_state = np.zeros((batch_size, state_size))

        print(""New data, epoch"", epoch_idx)
        #each batch
        for batch_idx in range(num_batches):
            #starting and ending point per batch
            #since weights reoccuer at every layer through time
            #These layers will not be unrolled to the beginning of time, 
            #that would be too computationally expensive, and are therefore truncated 
            #at a limited number of time-steps
            start_idx = batch_idx * truncated_backprop_length
            end_idx = start_idx + truncated_backprop_length

            batchX = x[:,start_idx:end_idx]
            batchY = y[:,start_idx:end_idx]

            #run the computation graph, give it the values
            #we calculated earlier
            _total_loss, _train_step, _final_state, _predictions_series = sess.run(
                [total_loss, train_step, final_state, predictions],
                feed_dict={
                    batchX_placeholder:batchX,
                    batchY_placeholder:batchY,
                    init_state:_current_state
                })

            loss_list.append(_total_loss)

            if batch_idx%100 == 0:
                print(""Step"",batch_idx, ""Loss"", _total_loss)
                plot(loss_list, _predictions_series, batchX, batchY)

plt.ioff()
plt.show()
</code></pre>

<p>and this the error:</p>

<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-9-7c3d1289d16b&gt; in &lt;module&gt;()
     40                     batchX_placeholder:batchX,
     41                     batchY_placeholder:batchY,
---&gt; 42                     init_state:_current_state
     43                 })
     44 

/home/pranshu_44/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    765     try:
    766       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 767                          run_metadata_ptr)
    768       if run_metadata:
    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/pranshu_44/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    942                 'Cannot feed value of shape %r for Tensor %r, '
    943                 'which has shape %r'
--&gt; 944                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
    945           if not self.graph.is_feedable(subfeed_t):
    946             raise ValueError('Tensor %s may not be fed.' % subfeed_t)

ValueError: Cannot feed value of shape (5, 15) for Tensor 'one_hot:0', which has shape '(5, 15, 2)'
</code></pre>

<p>i looked the docs but that does not helpful at all
if there is any other easy way that also will be helpful</p>
",this is the code genreating data{...} some optimization code{....} and then creating the graph and this the error: i looked the docs but that does not helpful at all if there is any other easy way that also will be helpful,https://stackoverflow.com/questions/42838796,7018732,Inadequate Examples,Inadequate Examples,I looked the docs but that does not helpful at all if there is any other easy way that also will be helpful.
43834529,"Tensorflow - dimensions of data, placeholder","<p>I am a complete beginner in Tensorflow, and I apologize if my question is trivial, but I have looked into both the documentation and Google and I couldn't find the answer. (I also apologize for my english)</p>

<p>I'd like to do something like</p>

<pre><code>sess.run(train, {x:x_train, y:x_train}
</code></pre>

<p>where x_train is an array of size 3190 containing my input data (arrays of dimension 60*4)</p>

<p>My question is, should x be :</p>

<pre><code>x = tf.placeholder(tf.bool, [60,4])
</code></pre>

<p>or</p>

<pre><code>x = tf.placeholder(tf.bool, [None,60,4])
</code></pre>

<p>?</p>

<p>The first one gives the following error :</p>

<pre><code>ValueError: Cannot feed value of shape (3190, 60, 4) for Tensor u'Placeholder:0', which has shape '(60, 4)'
</code></pre>

<p>and if I use the second one, how can I reach x[i][j] with 0&lt;=i&lt;60 and 0&lt;=j&lt;4 if I want to compute for example</p>

<pre><code>tf.logical_and(x[i1][j1],x[i2][j2])
</code></pre>

<p>?</p>

<p>Thanking you in advance for your answer.</p>
","I am a complete beginner in Tensorflow, and I apologize if my question is trivial, but I have looked into both the documentation and Google and I couldn't find the answer. (I also apologize for my english) I'd like to do something like where x_train is an array of size 3190 containing my input data (arrays of dimension 60*4) My question is, should x be : or ? The first one gives the following error : and if I use the second one, how can I reach x[i][j] with 0&lt;=i&lt;60 and 0&lt;=j&lt;4 if I want to compute for example ? Thanking you in advance for your answer.",https://stackoverflow.com/questions/43834529,7976712,Inadequate Examples,Inadequate Examples,"I am a complete beginner in Tensorflow, and I apologize if my question is trivial, but I have looked into both the documentation and Google and I couldn't find the answer."
43848414,How is memory managed during tensor transformations?,"<p>Even if the question involves TensorFlow, I will use normal math terminology to describe my question.</p>

<p>Let's say that</p>

<ul>
<li>I have a matrix <code>W</code> of dimension <code>n x k</code></li>
<li>An input vector <code>x</code> of size <code>1 x k</code></li>
<li>I need to compare <code>x</code> to each element in <code>W</code></li>
</ul>

<p>After reading some code examples, the way I do it now is as it follows (<code>n = self.nNodes</code>, <code>k=self.inputShape</code>):</p>

<pre><code>inputShape = (10,)

W = tf.Variable(tf.random_uniform( (nNodes, ) + inputShape, 0.0, 1.0, dtype=tf.float32), dtype=tf.float32, name='W' )

x = tf.placeholder(self.__datatype, inputShape, name='input')

x_M = tf.expand_dims(x, 0, name='x_m')

x_MM = tf.tile(x_M, (nNodes, 1), name='x_mm')

spatDiffs = tf.subtract(x_MM, self.W)
</code></pre>

<p>It seems to be - but I am not sure - that, after a while, TensorFlow has some difficulties in managing the memory (especially on the GPU) since the <code>expand_dims</code> and <code>tile</code> operations return <em>new</em> tensors.</p>

<p>Is there any way to allocate a tensor for <code>X_MM</code> (as I do for <code>W</code>) and <strong>copy</strong> the input value <code>x</code> into each element of <code>X_MM</code>. In this way the memory for <code>X_MM</code> would be allocated only once.</p>

<p>Is there an ""atomic"" instructions for copying a vector, line by line, into another (a sort of tiling without allocating new memory)? Should I use a TensorFlow iterator for obtaining this?</p>

<p>More in general, should I worry about memory management with TensorFlow? It seems to me it is an important topic, but cannot find any relevant info on the documentation and all of the examples I see use operators that allocate new memory.</p>
","Even if the question involves TensorFlow, I will use normal math terminology to describe my question. Let's say that After reading some code examples, the way I do it now is as it follows (n = self.nNodes, k=self.inputShape): It seems to be - but I am not sure - that, after a while, TensorFlow has some difficulties in managing the memory (especially on the GPU) since the expand_dims and tile operations return new tensors. Is there any way to allocate a tensor for X_MM (as I do for W) and copy the input value x into each element of X_MM. In this way the memory for X_MM would be allocated only once. Is there an ""atomic"" instructions for copying a vector, line by line, into another (a sort of tiling without allocating new memory)? Should I use a TensorFlow iterator for obtaining this? More in general, should I worry about memory management with TensorFlow? It seems to me it is an important topic, but cannot find any relevant info on the documentation and all of the examples I see use operators that allocate new memory.",https://stackoverflow.com/questions/43848414,774133,Lack of Alternative Solutions/Documentation,Inadequate Examples,"It seems to me it is an important topic, but cannot find any relevant info on the documentation and all of the examples I see use operators that allocate new memory"
45469356,Number of steps doesn't match when using tf.estimator.Estimator,"<p>I am figuring out the TensorFlow estimator framework. I finally have code for a model that trains. I am using a simple MNIST autoencoder for my tests. I have two questions. The first question is why the number of steps reported by training is different from the number of steps I specify in estimator train() method? The second one is how to use training hooks to do things like periodic evaluations, loss output every X steps etc? The docs seem to say to use training hooks, but I cannot seem to find any actual examples of how to use these.</p>

<p>Here is my code:</p>

<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import time
import shutil
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

from IPython import display
from tensorflow.examples.tutorials.mnist import input_data

data = input_data.read_data_sets('.')
display.clear_output()

def _model_fn(features, labels, mode=None, params=None):
    # define inputs
    image = tf.feature_column.numeric_column('images', shape=(784, ))
    inputs = tf.feature_column.input_layer(features, [image, ])
    # encoder
    e1 = tf.layers.dense(inputs, 512, activation=tf.nn.relu)
    e2 = tf.layers.dense(e1, 256, activation=tf.nn.relu)
    # decoder
    d1 = tf.layers.dense(e2, 512, activation=tf.nn.relu)
    model = tf.layers.dense(d1, 784, activation=tf.nn.relu)
    # training ops
    loss = tf.losses.mean_squared_error(labels, model)
    train = tf.train.AdamOptimizer().minimize(loss, global_step=tf.train.get_global_step())
    if mode == tf.estimator.ModeKeys.TRAIN:
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          train_op=train)

_train_input_fn = tf.estimator.inputs.numpy_input_fn({'images': data.train.images},
                                                     y=np.array(data.train.images),
                                                     batch_size=100,
                                                     shuffle=True)

shutil.rmtree(""logs"", ignore_errors=True)
tf.logging.set_verbosity(tf.logging.INFO)
estimator = tf.estimator.Estimator(_model_fn, 
                                   model_dir=""logs"", 
                                   config=tf.contrib.learn.RunConfig(save_checkpoints_steps=1000),
                                   params={})
estimator.train(_train_input_fn, steps=1000)
</code></pre>

<p>And here is the output I get (notice how training stops at 550 steps where the code explicitely calls for a 1000)</p>

<pre><code>INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x12b9fa630&gt;, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1
}
, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_session_config': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'logs'}
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Saving checkpoints for 1 into logs/model.ckpt.
INFO:tensorflow:loss = 0.102862, step = 1
INFO:tensorflow:global_step/sec: 41.8119
INFO:tensorflow:loss = 0.0191228, step = 101 (2.393 sec)
INFO:tensorflow:global_step/sec: 39.9923
INFO:tensorflow:loss = 0.0141014, step = 201 (2.500 sec)
INFO:tensorflow:global_step/sec: 40.9806
INFO:tensorflow:loss = 0.0116138, step = 301 (2.440 sec)
INFO:tensorflow:global_step/sec: 40.0043
INFO:tensorflow:loss = 0.00998991, step = 401 (2.500 sec)
INFO:tensorflow:global_step/sec: 39.2571
INFO:tensorflow:loss = 0.0124132, step = 501 (2.548 sec)
INFO:tensorflow:Saving checkpoints for 550 into logs/model.ckpt.
INFO:tensorflow:Loss for final step: 0.00940801.

&lt;tensorflow.python.estimator.estimator.Estimator at 0x12b9fa780&gt;
</code></pre>

<p><strong>Update #1</strong> I found the answer to the first question. The reason training stopped at step 550 was because numpy_input_fn() defaults to num_epochs=1. I am still looking for help with training hooks though.</p>
","I am figuring out the TensorFlow estimator framework. I finally have code for a model that trains. I am using a simple MNIST autoencoder for my tests. I have two questions. The first question is why the number of steps reported by training is different from the number of steps I specify in estimator train() method? The second one is how to use training hooks to do things like periodic evaluations, loss output every X steps etc? The docs seem to say to use training hooks, but I cannot seem to find any actual examples of how to use these. Here is my code: And here is the output I get (notice how training stops at 550 steps where the code explicitely calls for a 1000) Update #1 I found the answer to the first question. The reason training stopped at step 550 was because numpy_input_fn() defaults to num_epochs=1. I am still looking for help with training hooks though.",https://stackoverflow.com/questions/45469356,302268,Inadequate Examples,Inadequate Examples,"The docs seem to say to use training hooks, but I cannot seem to find any actual examples of how to use these."
47399201,How to store a dictionary and map words to ints when using Tensorflow Serving?,"<p>I have trained an LSTM RNN classification model on Tensorflow. I was saving and restoring checkpoints to retrain and use the model for testing. Now I want to use Tensorflow serving so that I can use the model in production.</p>

<p>Initially, I would parse through a corpus to create my dictionary which is then used to map words in a string to integers. I would then store this dictionary in a pickle file which could be reloaded when restoring a checkpoint and retraining on a data set or just for using the model so that the mapping is consistent. How do I store this dictionary when saving the model using SavedModelBuilder?</p>

<p>My code for the neural network is as follows. The code for saving the model is towards the end (I am including an overview of the whole structure for context):</p>

<pre><code>...


# Read files and store them in variables
with open('./someReview.txt', 'r') as f:
    reviews = f.read()
with open('./someLabels.txt', 'r') as f:
    labels = f.read()

...

#Pre-processing functions
#Parse through dataset and create a vocabulary
vocab_to_int, reviews = RnnPreprocessing.map_vocab_to_int(reviews)
with open(pickle_path, 'wb') as handle:
    pickle.dump(vocab_to_int, handle, protocol=pickle.HIGHEST_PROTOCOL)

#More preprocessing functions
...


# Building the graph
lstm_size = 256
lstm_layers = 2
batch_size = 1000
learning_rate = 0.01            
n_words = len(vocab_to_int) + 1 

# Create the graph object
tf.reset_default_graph()
with tf.name_scope('inputs'):
    inputs_ = tf.placeholder(tf.int32, [None, None], name=""inputs"")
    labels_ = tf.placeholder(tf.int32, [None, None], name=""labels"")
    keep_prob = tf.placeholder(tf.float32, name=""keep_prob"")

#Create embedding layer LSTM cell, LSTM Layers

...

# Forward pass
with tf.name_scope(""RNN_forward""):
    outputs, final_state = tf.nn.dynamic_rnn(cell, embed, initial_state=initial_state)


# Output. We are only interested in the latest output of the lstm cell
with tf.name_scope('predictions'):
    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)
    tf.summary.histogram('predictions', predictions)
#More functions for cost, accuracy, optimizer initialization

... 

# Training
epochs = 1
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    iteration = 1
    for e in range(epochs):
        state = sess.run(initial_state)

        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):
            feed = {inputs_: x,
                    labels_: y[:, None],
                    keep_prob: 0.5,
                    initial_state: state}
            summary, loss, state, _ = sess.run([merged, cost, final_state, optimizer], feed_dict=feed)

            train_writer.add_summary(summary, iteration)

            if iteration%1==0:
                print(""Epoch: {}/{}"".format(e, epochs),
                      ""Iteration: {}"".format(iteration),
                      ""Train loss: {:.3f}"".format(loss))

            if iteration%2==0:
                val_acc = []
                val_state = sess.run(cell.zero_state(batch_size, tf.float32))
                for x, y in get_batches(val_x, val_y, batch_size):
                    feed = {inputs_: x,
                            labels_: y[:, None],
                            keep_prob: 1,
                            initial_state: val_state}
                    summary, batch_acc, val_state = sess.run([merged, accuracy, final_state], feed_dict=feed)
                    val_acc.append(batch_acc)
                print(""Val acc: {:.3f}"".format(np.mean(val_acc)))
            iteration +=1
            test_writer.add_summary(summary, iteration)



    #Saving the model
    export_path = './SavedModel'
    print ('Exporting trained model to %s'%(export_path))

    builder = saved_model_builder.SavedModelBuilder(export_path)

    # Build the signature_def_map.    
    classification_inputs = utils.build_tensor_info(inputs_)
    classification_outputs_classes = utils.build_tensor_info(labels_)

    classification_signature = signature_def_utils.build_signature_def(
        inputs={signature_constants.CLASSIFY_INPUTS: classification_inputs},
        outputs={
          signature_constants.CLASSIFY_OUTPUT_CLASSES:
              classification_outputs_classes,
        },
      method_name=signature_constants.CLASSIFY_METHOD_NAME)


    legacy_init_op = tf.group(
        tf.tables_initializer(), name='legacy_init_op')
    #add the sigs to the servable
    builder.add_meta_graph_and_variables(
        sess, [tag_constants.SERVING],
        signature_def_map={
            signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
                classification_signature
        },
        legacy_init_op=legacy_init_op)
    print (""added meta graph and variables"")

    #save it!
    builder.save()
    print(""model saved"")
</code></pre>

<p>I am not entirely sure if this is the correct way to save a model such as this but this is the only implementation I have found in the documentation and online tutorials.</p>

<p>I haven't found any example or any explicit guide to saving the dictionary or how to use it when restoring a savedModel in the documentation.</p>

<p>When using checkpoints, I would just load the pickle file before running the session. How do I restore this savedModel so that I can use the same word to int mapping using the dictionary? Is there any specific way I should be saving the model or loading it?</p>

<p>I have also added inputs_ as the input for the input signature. This is a sequence of integeres 'after' the words have been mapped. I can't specify a string as input because I get an <code>AttributeError: 'str' object has no attribute 'dtype'</code> . In such cases, how exactly are words mapped to integers in models that are in production?</p>
","I have trained an LSTM RNN classification model on Tensorflow. I was saving and restoring checkpoints to retrain and use the model for testing. Now I want to use Tensorflow serving so that I can use the model in production. Initially, I would parse through a corpus to create my dictionary which is then used to map words in a string to integers. I would then store this dictionary in a pickle file which could be reloaded when restoring a checkpoint and retraining on a data set or just for using the model so that the mapping is consistent. How do I store this dictionary when saving the model using SavedModelBuilder? My code for the neural network is as follows. The code for saving the model is towards the end (I am including an overview of the whole structure for context): I am not entirely sure if this is the correct way to save a model such as this but this is the only implementation I have found in the documentation and online tutorials. I haven't found any example or any explicit guide to saving the dictionary or how to use it when restoring a savedModel in the documentation. When using checkpoints, I would just load the pickle file before running the session. How do I restore this savedModel so that I can use the same word to int mapping using the dictionary? Is there any specific way I should be saving the model or loading it? I have also added inputs_ as the input for the input signature. This is a sequence of integeres 'after' the words have been mapped. I can't specify a string as input because I get an AttributeError: 'str' object has no attribute 'dtype' . In such cases, how exactly are words mapped to integers in models that are in production?",https://stackoverflow.com/questions/47399201,6021490,Inadequate Examples,Inadequate Examples, I haven't found any example or any explicit guide to saving the dictionary or how to use it when restoring a savedModel in the documentation.
48092772,Add operation to graph without with-as-clause,"<p>Since you are able to do a </p>

<pre><code>with tf.Session() as sess:
    #  Run stuff here with sess.run()
</code></pre>

<p>but also</p>

<pre><code>init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
sess.run(x)
</code></pre>

<p>I was wondering whether it is possible to do a similar thing with Graph creation, like:</p>

<pre><code>a_graph = tf.Graph()
x = tf.placeholder(dtype=tf.float32, name='test')
a_graph.add(x)
</code></pre>

<p>The conventional way to add a node/operation to a graph is of course...</p>

<pre><code>with a_graph.as_default():
    x = tf.placeholder(dtype=tf.float32, name='test')
</code></pre>

<p>I couldn't read anything about this in the docs.. and <code>dir(a_graph)</code> does not show me a simple <code>.add()</code> method. The only thing I could think of are add some operation to a collection... but I am not sure how to do that.</p>
","Since you are able to do a but also I was wondering whether it is possible to do a similar thing with Graph creation, like: The conventional way to add a node/operation to a graph is of course... I couldn't read anything about this in the docs.. and dir(a_graph) does not show me a simple .add() method. The only thing I could think of are add some operation to a collection... but I am not sure how to do that.",https://stackoverflow.com/questions/48092772,6329284,Inadequate Examples,Inadequate Examples,I couldn't read anything about this in the docs and dir(a_graph) does not show me a simple .add() method.
48283090,Inverted Colours when Writing an Image using TensorFlow and PIL,"<p>I am trying to save images with bounding boxes displayed on them, just to test that my annotations file is working correctly. </p>

<p>Everything works out fine: the image is written to disk, the bounding box is there in the right place and so on. Except all the colours are inverted. So it looks like a negative of the original image.</p>

<p>Here is my code:</p>

<p>```</p>

<pre><code>import tensorflow as tf
import numpy as np
from PIL import Image

def read_processed_data(filename, num_show):
    """""" Reads in the processed data file and displays the
        given number of images, along with the bounding boxes.
    """"""
    with open(filename, 'r') as f:
        i = 0

        while i &lt; num_show:
            for line in f:
                filename = line.rstrip()
                next_line = f.readline()
                num_faces = int(next_line.rstrip())
                face_num = 0

                #while face_num &lt; num_faces:
                bb_line = f.readline().rstrip()
                y1, x1, y2, x2 = bb_line.split(',')
                y1 = float(y1)
                x1 = float(x1)
                y2 = float(y2)
                x2 = float(x2)

                box = [y1, x1, y2, x2]

                return box, filename


with tf.Session() as sess:
    bb, fn = read_processed_data(""processed.txt"", 1)
    image = tf.image.decode_image(tf.read_file(fn))

    image_as_float = tf.cast(image, dtype = tf.float32)
    image_4d = tf.expand_dims(image_as_float, 0)

    bb_2d = tf.expand_dims(bb, 0)
    bb_3d = tf.expand_dims(bb_2d, 0) # Box has to be 3d for the drawing to work
    bb_image = tf.image.draw_bounding_boxes(image_4d, bb_3d)
    bb_image_uint = tf.image.convert_image_dtype(bb_image, dtype = tf.uint8)
    bb_image_uint_3d = tf.reshape(bb_image_uint, [940, 650, 3]) # Reduce rank from 4 to 3
    data = bb_image_uint_3d.eval()

    base_fn = fn.split('.')[0]
    Image.fromarray(data).save(base_fn + ""_bb.jpg"")
</code></pre>

<p>```</p>

<p>I have searched the tensorflow documentation to no avail. I have also attempted <code>np.roll()</code> and the other suggestions from <a href=""https://stackoverflow.com/questions/4661557/pil-rotate-image-colors-bgr-rgb"">PIL rotate image colors (BGR -&gt; RGB)</a> again with no luck; those methods were able to change the colour, but not to the correct colours.</p>

<p><a href=""https://i.stack.imgur.com/N23ia.jpg"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/N23ia.jpg</a> shows the original image (without bounding box) at the top, and the resulting image (with the colour issue, as well as bounding box) below.</p>
","I am trying to save images with bounding boxes displayed on them, just to test that my annotations file is working correctly. Everything works out fine: the image is written to disk, the bounding box is there in the right place and so on. Except all the colours are inverted. So it looks like a negative of the original image. Here is my code: ``` ``` I have searched the tensorflow documentation to no avail. I have also attempted np.roll() and the other suggestions from PIL rotate image colors (BGR -&gt; RGB) again with no luck; those methods were able to change the colour, but not to the correct colours. https://i.stack.imgur.com/N23ia.jpg shows the original image (without bounding box) at the top, and the resulting image (with the colour issue, as well as bounding box) below.",https://stackoverflow.com/questions/48283090,5280140,Inadequate Examples,Inadequate Examples,I have searched the tensorflow documentation to no avail.
48354243,"tensorflow estimator from_generator, how to set TensorShape?","<p>I am trying use a generator to feed data into estimator. The following is the code. However, when try to run, I got the following error:</p>

<p>Update2: I finally made it work.   So the correct tensorshape is 
([], [], [])</p>

<p>Update: I added tensorshape ([None], [None], [None]), then I changed ds.batch(10), to an assignment ds = ds.batch(10)  </p>

<p>but still got error.  </p>

<pre><code>Traceback (most recent call last):
  File ""xyz.py"", line 79, in &lt;module&gt;
    tf.app.run(main=main, argv=None)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""xyz.py"", line 67, in main
    model.train(input_fn=lambda: input_fn(100))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 783, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1024, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 827, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: exceptions.ValueError: `generator` yielded an element of shape () where an element of shape (?,) was expected.
         [[Node: PyFunc = PyFunc[Tin=[DT_INT64], Tout=[DT_INT64, DT_STRING, DT_FLOAT], token=""pyfunc_1""](arg0)]]
         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?], [?,?], [?,?]], output_types=[DT_INT64, DT_STRING, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]
</code></pre>

<p>So my question, how to set the TensorShape? The from generator takes a third argument of TensorShape but I cannot find any example/doc on how to set it. Any help?  </p>

<p>Thanks,</p>

<pre><code>def gen(nn):
    ii = 0
    while ii &lt; nn:
        ii += 1
        yield ii, 't{0}'.format(ii), ii*2

def input_fn(n):
    ds = tf.data.Dataset.from_generator(lambda: gen(n), (tf.int64, tf.string, tf.float32), ([None], [None], [None])) 
    ds = ds.batch(10)
    x, y, z = ds.make_one_shot_iterator().get_next()
    return {'x': x, 'y': y}, tf.greater_equal(z, 10)

def build_columns():
    x = tf.feature_column.numeric_column('x')
    y = tf.feature_column.categorical_column_with_hash_bucket('y', hash_bucket_size=5)
    return [x, y]

def build_estimator():
    run_config = tf.estimator.RunConfig().replace(
            session_config=tf.ConfigProto(device_count={'GPU': 0}))
    return tf.estimator.LinearClassifier(model_dir=FLAGS.model_dir, feature_columns=build_columns(), config=run_config)

def main(unused):
  # Clean up the model directory if present
  shutil.rmtree(FLAGS.model_dir, ignore_errors=True)
  model = build_estimator()

  # Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.
  for n in range(FLAGS.train_epochs // FLAGS.epochs_per_eval):
    model.train(input_fn=lambda: input_fn(100))
    results = model.evaluate(input_fn=lambda: input_fn(20))
</code></pre>
","I am trying use a generator to feed data into estimator. The following is the code. However, when try to run, I got the following error: Update2: I finally made it work. So the correct tensorshape is ([], [], []) Update: I added tensorshape ([None], [None], [None]), then I changed ds.batch(10), to an assignment ds = ds.batch(10) but still got error. So my question, how to set the TensorShape? The from generator takes a third argument of TensorShape but I cannot find any example/doc on how to set it. Any help? Thanks,",https://stackoverflow.com/questions/48354243,9243582,Inadequate Examples,Inadequate Examples,The from generator takes a third argument of TensorShape but I cannot find any example/doc on how to set it.
57114360,"TypeError: float() argument must be a string or a number, not 'builtin_function_or_method'","<p>I am running a CNN that check for images but does not classify. In fact, the output layer is a dense layer that have as argument the size of the images in the labels in 1d.</p>

<p>As shown below in the code, I am using model.fit_generator() instead of model.fit and when it comes to start training the model the following error comes up:</p>

<p>TypeError: float() argument must be a string or a number, not 
  'builtin_function_or_method'</p>

<p>I am not really getting why this is happening. 
Here attached is the summary of the model:</p>

<hr>

<h1>Layer (type)                 Output Shape              Param #</h1>

<p>conv2d_4 (Conv2D)            (None, 26, 877, 32)       544       </p>

<hr>

<p>activation_5 (Activation)    (None, 26, 877, 32)       0         </p>

<hr>

<p>max_pooling2d_4 (MaxPooling2 (None, 13, 438, 32)       0         </p>

<hr>

<p>conv2d_5 (Conv2D)            (None, 12, 437, 16)       2064      </p>

<hr>

<p>activation_6 (Activation)    (None, 12, 437, 16)       0         </p>

<hr>

<p>max_pooling2d_5 (MaxPooling2 (None, 6, 218, 16)        0         </p>

<hr>

<p>conv2d_6 (Conv2D)            (None, 5, 217, 8)         520       </p>

<hr>

<p>activation_7 (Activation)    (None, 5, 217, 8)         0         </p>

<hr>

<p>max_pooling2d_6 (MaxPooling2 (None, 2, 108, 8)         0         </p>

<hr>

<p>activation_8 (Activation)    (None, 2, 108, 8)         0         </p>

<hr>

<p>flatten_2 (Flatten)          (None, 1728)              0         </p>

<hr>

<p>dropout_2 (Dropout)          (None, 1728)              0         </p>

<hr>

<p>dense_2 (Dense)              (None, 19316)             33397364  </p>

<p>=================================================================</p>

<p>Total params: 33,400,492
Trainable params: 33,400,492
Non-trainable params: 0</p>

<hr>

<p>Any suggestions ? 
Thanks a lot in advance!</p>

<p>I have already looked up many of the online forums/websites but I don't seem to find one that suits my case. </p>

<pre><code>def generator(data_arr, batch_size = 10):

num = len(data_arr) 

if num % batch_size != 0 : 
    num = int(num/batch_size)

# Loop forever so the generator never terminates
while True: 

    for offset in range(0, num, batch_size):

        batch_samples = (data_arr[offset:offset+batch_size])

        samples = []
        labels = []

        for batch_sample in batch_samples:

            samples.append(batch_sample[0])
            labels.append((np.array(batch_sample[1].flatten)).transpose())

        X_ = np.array(samples)
        Y_ = np.array(labels)

        X_ = X_[:, :, :, newaxis]

        print(X_.shape)
        print(Y_.shape)

        yield (X_, Y_)

# compile and train the model using the generator function
train_generator = generator(training_data, batch_size = 10)
validation_generator = generator(val_data, batch_size = 10)

run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)

model = Sequential()

model.add(Conv2D(32, (4, 4), strides=(2, 2), input_shape = (55, 1756, 
1)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2, 2)))

model.add(Conv2D(16, (2, 2)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2, 2)))

model.add(Conv2D(8, (2, 2)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size = (2, 2)))

model.add(Activation('softmax'))
model.add(Flatten())  # this converts our 3D feature maps to 1D feature 
vectors
model.add(Dropout(0.3))
model.add(Dense(19316))

model.compile(loss = 'sparse_categorical_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'],
              options = run_opts)

model.summary()

batch_size = 20
nb_epoch = 6

model.fit_generator(train_generator, 
                    steps_per_epoch = len(training_data) ,
                    epochs = nb_epoch,
                    validation_data = validation_generator,
                    validation_steps = len(val_data))
</code></pre>
","I am running a CNN that check for images but does not classify. In fact, the output layer is a dense layer that have as argument the size of the images in the labels in 1d. As shown below in the code, I am using model.fit_generator() instead of model.fit and when it comes to start training the model the following error comes up: TypeError: float() argument must be a string or a number, not 'builtin_function_or_method' I am not really getting why this is happening. Here attached is the summary of the model: conv2d_4 (Conv2D) (None, 26, 877, 32) 544 activation_5 (Activation) (None, 26, 877, 32) 0 max_pooling2d_4 (MaxPooling2 (None, 13, 438, 32) 0 conv2d_5 (Conv2D) (None, 12, 437, 16) 2064 activation_6 (Activation) (None, 12, 437, 16) 0 max_pooling2d_5 (MaxPooling2 (None, 6, 218, 16) 0 conv2d_6 (Conv2D) (None, 5, 217, 8) 520 activation_7 (Activation) (None, 5, 217, 8) 0 max_pooling2d_6 (MaxPooling2 (None, 2, 108, 8) 0 activation_8 (Activation) (None, 2, 108, 8) 0 flatten_2 (Flatten) (None, 1728) 0 dropout_2 (Dropout) (None, 1728) 0 dense_2 (Dense) (None, 19316) 33397364 ================================================================= Total params: 33,400,492 Trainable params: 33,400,492 Non-trainable params: 0 Any suggestions ? Thanks a lot in advance! I have already looked up many of the online forums/websites but I don't seem to find one that suits my case.",https://stackoverflow.com/questions/57114360,11782908,Inadequate Examples,Inadequate Examples,I have already looked up many of the online forums/websites but I don't seem to find one that suits my case.
57376829,"How can I filter and balance a Windowed Tensorflow dataset with a binary classification label, based on the label?","<p>I have an unbalanced tensorflow windowed dataset with labels (over 90% negative examples) which I am trying to balance by filtering. I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation.</p>

<p>I'm working on a model to predict a binary classification based on time series data. I start with a time series dataframe with a number of columns (price, volume, etc.) where each row is one minute.</p>

<p>Currently I am still stuck on filtering the different labels. My next step after filtering would be to get the size of both filtered datasets, find the smaller size (n), and then concatenate the smaller dataset with (n) elements from the bigger dataset, after shuffling the bigger dataset. This way I would have a balanced dataset with an equal number of 1 and 0 labels. If you have a better Idea I would be happy to hear it.</p>

<p><strong>EXPLAINING MY CODE:</strong>
DFrame is a pandas dataframe with columns such as price, volume, etc., and each row is a different minute, with the first row being the earliest/oldest time period. The last column of DFrame is the classifier 0 or 1.</p>

<p>I then create a tensorflow dataset from slices with the first input being all the DFrame columns except for the label which is in the last column, and the second input (the label) being the last column which is the classifier.</p>

<p>I then use the window function to create windows of size (hindsight) which is currently 512, meaning (If i'm not mistaken) it takes the previous 511 minutes as well as the current minute and uses this as a rolling window to associate with the label of the current minute. So my understanding is that x is then an array of 512 arrays, from the row of the current minute to the row of 511 minutes ago, and the y is the label of the current minute. So x is an array of 512 arrays (rows for each minute, from the dataframe), and y is just one integer, 1 or 0.</p>

<p>Ideally I would like to be able to apply the same balancing logic to a multiclass classification problem, where I essentially add additional labels for additional price movement ranges.</p>

<p>The error comes from the filter. The model seems to run without that, and even trains my keras model. as explained I would actually want to add more code after the filter once I get it working to balance the dataset but I need to filter it first.</p>

<pre><code>tensor= tf.data.Dataset.from_tensor_slices((tf.constant(DFrame[DFrame.columns.values[:-1]].values), tf.constant(DFrame[DFrame.columns.values[-1]].values)))

tensor = tensor.window(hindsight,1,1,True)

tensor = tensor.shuffle(1000)

tensor = tensor.filter(lambda x,y: tf.equal(y, 0))

tensor = tensor.flat_map(lambda x,y:tf.data.Dataset.zip((x.batch(hindsight), y.batch(1))))

tensor = tensor.batch(Batch_size).prefetch(1)



TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt; to Tensor. Contents: &lt;_VariantDataset shapes: (), types: tf.int64&gt;. Consider casting elements to a supported type.
</code></pre>
","I have an unbalanced tensorflow windowed dataset with labels (over 90% negative examples) which I am trying to balance by filtering. I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation. I'm working on a model to predict a binary classification based on time series data. I start with a time series dataframe with a number of columns (price, volume, etc.) where each row is one minute. Currently I am still stuck on filtering the different labels. My next step after filtering would be to get the size of both filtered datasets, find the smaller size (n), and then concatenate the smaller dataset with (n) elements from the bigger dataset, after shuffling the bigger dataset. This way I would have a balanced dataset with an equal number of 1 and 0 labels. If you have a better Idea I would be happy to hear it. EXPLAINING MY CODE: DFrame is a pandas dataframe with columns such as price, volume, etc., and each row is a different minute, with the first row being the earliest/oldest time period. The last column of DFrame is the classifier 0 or 1. I then create a tensorflow dataset from slices with the first input being all the DFrame columns except for the label which is in the last column, and the second input (the label) being the last column which is the classifier. I then use the window function to create windows of size (hindsight) which is currently 512, meaning (If i'm not mistaken) it takes the previous 511 minutes as well as the current minute and uses this as a rolling window to associate with the label of the current minute. So my understanding is that x is then an array of 512 arrays, from the row of the current minute to the row of 511 minutes ago, and the y is the label of the current minute. So x is an array of 512 arrays (rows for each minute, from the dataframe), and y is just one integer, 1 or 0. Ideally I would like to be able to apply the same balancing logic to a multiclass classification problem, where I essentially add additional labels for additional price movement ranges. The error comes from the filter. The model seems to run without that, and even trains my keras model. as explained I would actually want to add more code after the filter once I get it working to balance the dataset but I need to filter it first.",https://stackoverflow.com/questions/57376829,11743037,Requesting (Additional) Resources,Inadequate Examples,"I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation."
58254297,How to check gradient computation via unit test,"<p>I am trying to unit-test a custom layer. Writing the feed-forward test was pretty straight forward, but I have no idea how to implement the test for gradients.</p>

<p>I found out there is a function in the tensorflow test package called <code>compute_gradient</code> but I can't find any resource on how to use it. The documentation basically says it computes the gradients (jacobian matrix) which is what I want, but when I try to use it, I get <code>EagerTensor is not callable</code></p>

<p>This I the code that fails:</p>

<pre class=""lang-py prettyprint-override""><code>class LayerGradientTest(tf.test.TestCase):
    def test_gradient(self):
        with self.test_session():
            input_tensor = [...]
            expected_output = [...]
            expected_gradients = [...]
            test_layer = MyLayer()
            output_tensor = test_layer(tf.Variable(input_tensor))
            grad_computed = tf.test.compute_gradient(output_tensor, expected_output)
            self.assertAllEqual(grad_computed, expected_gradients)

</code></pre>

<p>I would expect the test to either pass or fail at the assertion but I get a
<code>TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable</code> from <code>compute_gradient</code></p>

<p><strong>Edit:</strong>
Of course gradients need a loss function, I'm an idiot... but still the output is of nonsense shape. I now use the following code:</p>

<pre class=""lang-py prettyprint-override""><code>function = tf.losses.mean_squared_error
grad_computed = tf.test.compute_gradient(function, [output_tensor, expected_output])
</code></pre>

<p>The input's shapes to my layer are (1, 2, 2, 3) and (1, 2, 2, 2) but the gradients are a zip object of 4 12x4 matrices but since I have no parameters in my layer I expected to get the error values at the input. Please correct me if I messed something up again. Just to clarify, my layer is just transforming data and therefore has no gradients on its own but must propagate them backwards correctly.</p>
","I am trying to unit-test a custom layer. Writing the feed-forward test was pretty straight forward, but I have no idea how to implement the test for gradients. I found out there is a function in the tensorflow test package called compute_gradient but I can't find any resource on how to use it. The documentation basically says it computes the gradients (jacobian matrix) which is what I want, but when I try to use it, I get EagerTensor is not callable This I the code that fails: I would expect the test to either pass or fail at the assertion but I get a TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable from compute_gradient Edit: Of course gradients need a loss function, I'm an idiot... but still the output is of nonsense shape. I now use the following code: The input's shapes to my layer are (1, 2, 2, 3) and (1, 2, 2, 2) but the gradients are a zip object of 4 12x4 matrices but since I have no parameters in my layer I expected to get the error values at the input. Please correct me if I messed something up again. Just to clarify, my layer is just transforming data and therefore has no gradients on its own but must propagate them backwards correctly.",https://stackoverflow.com/questions/58254297,12044023,Inadequate Examples,Inadequate Examples,"I found out there is a function in the tensorflow test package called compute_gradient but I can't find any resource on how to use it. The documentation basically says it computes the gradients (jacobian matrix) which is what I want, but when I try to use it, I get EagerTensor is not callable"
60607402,Style Transfer : Save&Restore checkpoint/model in tensorflow 1.15.0,"<p>i am a bit frustrated about saving and restoring models in tensorflow 1.15.0. I want to achieve it in a jupyter notebook / google colab notebook environment. The application is style-transfer of images.</p>

<p>I simply want to save the model and restore it in order to apply the style transfer for a larger number of images.</p>

<p>The tensorflow documentation is a bit confusing, (i did not find examples for this), so i never really know what the right syntax looks like.</p>

<p>I am at a point now where i want to achieve 1 thing:</p>

<ol>
<li>Restore the model
correctly.</li>
</ol>

<p>I will write the relevant lines now:</p>

<pre><code>model = get_model()  
opt = tf.train.AdamOptimizer(learning_rate=2.5,beta1=0.99, epsilon=1e-1)
saver = tf.train.Checkpoint(model=model, optimizer=opt)
saver.save('/content/sample_data/test/_____NEU____')
</code></pre>

<p>When i want to restore the model, i use the command:</p>

<pre><code>saver.restore('/content/sample_data/test/_____NEU____')
</code></pre>

<p>How can i fix this issue, and load my checkpoint files correctly? Thank you</p>

<hr>

<p>The google colab project is here:</p>

<p><a href=""https://colab.research.google.com/drive/12hTitoQ2-tH8pYEsfMDR5jtsg8a96PgC"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/12hTitoQ2-tH8pYEsfMDR5jtsg8a96PgC</a></p>

<hr>
","i am a bit frustrated about saving and restoring models in tensorflow 1.15.0. I want to achieve it in a jupyter notebook / google colab notebook environment. The application is style-transfer of images. I simply want to save the model and restore it in order to apply the style transfer for a larger number of images. The tensorflow documentation is a bit confusing, (i did not find examples for this), so i never really know what the right syntax looks like. I am at a point now where i want to achieve 1 thing: I will write the relevant lines now: When i want to restore the model, i use the command: How can i fix this issue, and load my checkpoint files correctly? Thank you The google colab project is here: https://colab.research.google.com/drive/12hTitoQ2-tH8pYEsfMDR5jtsg8a96PgC",https://stackoverflow.com/questions/60607402,8092502,Documentation Completeness,Inadequate Examples,"The tensorflow documentation is a bit confusing, (i did not find examples for this), so i never really know what the right syntax looks like."
60701451,"In Tensorflow Classification, how are the labels ordered when using ""predict""?","<p>I'm using the MNIST handwritten numerals dataset to train a CNN.</p>

<p>After training the model, i use predict like this:</p>

<pre><code>predictions = cnn_model.predict(test_images)
predictions[0]
</code></pre>

<p>and i get output as:</p>

<pre><code>array([2.1273775e-06, 2.9292005e-05, 1.2424786e-06, 7.6307842e-05,
       7.4305902e-08, 7.2301691e-07, 2.5368356e-08, 9.9952960e-01,
       1.2401938e-06, 1.2787555e-06], dtype=float32)
</code></pre>

<p>In the output, there are 10 probabilities, one for each of numeral from 0 to 9. But how do i know which probability refers to which numeral ?</p>

<p>In this particular case, the probabilities are arranged sequentially for numerals 0 to 9. But why is that ? I didn't define that anywhere.</p>

<p>I tried going over documentation and example implementations found elsewhere on the internet, but no one seems to have addressed this particular behaviour.</p>

<p>Edit:</p>

<p>For context, I've defined my train/test data by:</p>

<pre><code>mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = (np.expand_dims(train_images, axis=-1)/255.).astype(np.float32)
train_labels = (train_labels).astype(np.int64)
test_images = (np.expand_dims(test_images, axis=-1)/255.).astype(np.float32)
test_labels = (test_labels).astype(np.int64)
</code></pre>

<p>And my model consists of a a few convulution and pooling layers, then a Flatten layer, then a Dense layer with 128 neurons and an output Dense layer with 10 neurons.</p>

<p>After that I simply fit my model and use predict like this:</p>

<pre><code>model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)
predictions = cnn_model.predict(test_images)
</code></pre>

<p>I don't see where I've instructed my code to output first neuron as digit 0, second neuron as digit 1 etc
And if i wanted to change the the sequence in which the resulting digits are output, where do i do that ?
This is really confusing me a lot.</p>
","I'm using the MNIST handwritten numerals dataset to train a CNN. After training the model, i use predict like this: and i get output as: In the output, there are 10 probabilities, one for each of numeral from 0 to 9. But how do i know which probability refers to which numeral ? In this particular case, the probabilities are arranged sequentially for numerals 0 to 9. But why is that ? I didn't define that anywhere. I tried going over documentation and example implementations found elsewhere on the internet, but no one seems to have addressed this particular behaviour. Edit: For context, I've defined my train/test data by: And my model consists of a a few convulution and pooling layers, then a Flatten layer, then a Dense layer with 128 neurons and an output Dense layer with 10 neurons. After that I simply fit my model and use predict like this: I don't see where I've instructed my code to output first neuron as digit 0, second neuron as digit 1 etc And if i wanted to change the the sequence in which the resulting digits are output, where do i do that ? This is really confusing me a lot.",https://stackoverflow.com/questions/60701451,11501160,Documentation Ambiguity,Inadequate Examples,"I tried going over documentation and example implementations found elsewhere on the internet, but no one seems to have addressed this particular behaviour."
60974077,How to save Keras model as frozen graph?,"<p>I am working with Tensorflow 2.0 and want to store the following Keras model as frozen graph. </p>

<pre><code>import tensorflow as tf
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(64, input_shape=[100]))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dense(2, activation='softmax'))
model.summary()
model.save('./models/')
</code></pre>

<p>I can't find any good examples how to do this in Tensorflow 2.0. I have found the <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py"" rel=""noreferrer"">freeze_graph.py</a> file in the Tensorflow Github repository but find it hard to wrap my head around it.</p>

<p>I load the file mentioned above using:</p>

<pre><code>from tensorflow.python.tools.freeze_graph import freeze_graph
</code></pre>

<p>But what exactly do I have to provide to the <code>freeze_graph</code> function itself? Here I marked the arguments where I am not sure with a questionmark.</p>

<pre><code>freeze_graph(input_graph=?,
             input_saver='',
             input_binary=False,
             input_checkpoint=?,
             output_node_names=?,
             restore_op_name='',
             filename_tensor_name='',
             output_graph='./frozen_graph.pb',
             clear_devices=True,
             initializer_nodes='')
</code></pre>

<p>Can someone provide a simple example that shows how I can store the model above as a frozen graph using the <code>freeeze_graph</code> function?</p>
",I am working with Tensorflow 2.0 and want to store the following Keras model as frozen graph. I can't find any good examples how to do this in Tensorflow 2.0. I have found the freeze_graph.py file in the Tensorflow Github repository but find it hard to wrap my head around it. I load the file mentioned above using: But what exactly do I have to provide to the freeze_graph function itself? Here I marked the arguments where I am not sure with a questionmark. Can someone provide a simple example that shows how I can store the model above as a frozen graph using the freeeze_graph function?,https://stackoverflow.com/questions/60974077,3861775,Requesting (Additional) Resources,Inadequate Examples,I can't find any good examples how to do this in Tensorflow 2.0.
64092664,"KerasClassifier fails to fit model, despite everything working fine otherwise","<p>I'm trying to use a <code>KerasClassifier</code> wrapper in order to make my workflow
scikit-friendly. However, when I try to use it with the following function, it
gives an error; training the model using native Keras model <code>fit()</code> works.
(this is Tensorflow 2.2.0, running in a conda environment)</p>
<pre class=""lang-py prettyprint-override""><code>def model_arch(n_features: int):
    i = tf.keras.layers.Input(shape=(n_features,))

    hidden_dense = tf.keras.layers.Dense(64)(i)
    hidden_dense = tf.keras.layers.BatchNormalization()(hidden_dense)
    hidden_dense = tf.keras.layers.Activation(tf.nn.tanh)(hidden_dense)

    o = tf.keras.layers.Dense(1)(hidden_dense)
    o = tf.keras.layers.BatchNormalization()(o)
    o = tf.keras.layers.Activation(&quot;sigmoid&quot;)(o)

    classifier = tf.keras.models.Model(inputs=i, outputs=o)

    opt = tf.keras.optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)
    classifier.compile(
        loss=&quot;binary_crossentropy&quot;,
        optimizer=opt,
        metrics=[&quot;accuracy&quot;],
    )
    
    return classifier
</code></pre>
<p>The following works:</p>
<pre class=""lang-py prettyprint-override""><code>X = np.random.random((100,3))
y = np.random.random((100,)) # 'y' is a binary vector in reality

clf = model_arch(3)
clf.fit(X, y, epochs=10)
</code></pre>
<p>However, when I try to use <code>KerasClassifier</code> wrapper, I get an error:</p>
<pre class=""lang-py prettyprint-override""><code>clf = KerasClassifier(model_arch(3), epochs=10)
clf.fit(X, y)

# ValueError: The first argument to `Layer.call` must always be passed.
</code></pre>
<p>Every example I have seen on the internet seems to do the same as I: define a
function that returns a compiled keras model, then pass it to the wrapper, and
fit it or use in a pipeline. The only difference I notice is that most (if not
all) examples use the <code>Sequential</code> API instead of the functional API, but afaik
that should not be a problem, right?</p>
<p>Tensorflow documentation doesn't seem to give any example of what kind of
function we should pass to the wrapper, but since every example uses one similar
to mine, I think that's correct.</p>
<p>Can anyone shed some light? Thanks.</p>
<p><strong>EDIT</strong> (after comments):</p>
<p>I import the KerasClassifier like this:</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
</code></pre>
<p>Error log:</p>
<pre><code>Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;/home/adrian/miniconda3/envs/kaggle/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py&quot;, line 223, in fit
    return super(KerasClassifier, self).fit(x, y, **kwargs)
  File &quot;/home/adrian/miniconda3/envs/kaggle/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py&quot;, line 154, in fit
    self.model = self.build_fn(
  File &quot;/home/adrian/miniconda3/envs/kaggle/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py&quot;, line 799, in __call__
    raise ValueError(
ValueError: The first argument to `Layer.call` must always be passed.
</code></pre>
","I'm trying to use a KerasClassifier wrapper in order to make my workflow scikit-friendly. However, when I try to use it with the following function, it gives an error; training the model using native Keras model fit() works. (this is Tensorflow 2.2.0, running in a conda environment) The following works: However, when I try to use KerasClassifier wrapper, I get an error: Every example I have seen on the internet seems to do the same as I: define a function that returns a compiled keras model, then pass it to the wrapper, and fit it or use in a pipeline. The only difference I notice is that most (if not all) examples use the Sequential API instead of the functional API, but afaik that should not be a problem, right? Tensorflow documentation doesn't seem to give any example of what kind of function we should pass to the wrapper, but since every example uses one similar to mine, I think that's correct. Can anyone shed some light? Thanks. EDIT (after comments): I import the KerasClassifier like this: Error log:",https://stackoverflow.com/questions/64092664,6560267,Inadequate Examples,Inadequate Examples,"Tensorflow documentation doesn't seem to give any example of what kind of function we should pass to the wrapper, but since every example uses one similar to mine, I think that's correct."
71590479,GradientTape returning None when run in a loop,"<p>The following gradient descent is failing 'coz the gradients returned by <code>tape.gradient()</code> are none when the loop runs second time.</p>
<pre class=""lang-py prettyprint-override""><code>w = tf.Variable(tf.random.normal((3, 2)), name='w')
b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')
x = tf.constant([[1., 2., 3.]])


for i in range(10):
  print(&quot;iter {}&quot;.format(i))
  with tf.GradientTape() as tape:
    #forward prop
    y = x @ w + b  
    loss = tf.reduce_mean(y**2)
    print(&quot;loss is \n{}&quot;.format(loss))
    print(&quot;output- y is \n{}&quot;.format(y))
    #vars getting dropped after couple of iterations
    print(tape.watched_variables()) 
  
  #get the gradients to minimize the loss
  dl_dw, dl_db = tape.gradient(loss,[w,b]) 

  #descend the gradients
  w = w.assign_sub(0.001*dl_dw)
  b = b.assign_sub(0.001*dl_db)
</code></pre>
<pre><code>iter 0
loss is 
23.328645706176758
output- y is 
[[ 6.8125362  -0.49663293]]
(&lt;tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=
array([[-1.3461215 ,  0.43708783],
       [ 1.5931423 ,  0.31951016],
       [ 1.6574576 , -0.52424705]], dtype=float32)&gt;, &lt;tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)&gt;)
iter 1
loss is 
22.634033203125
output- y is 
[[ 6.7103477  -0.48918355]]
()

TypeError                                 Traceback (most recent call last)
c:\projects\pyspace\mltest\test.ipynb Cell 7' in &lt;cell line: 1&gt;()
     11 dl_dw, dl_db = tape.gradient(loss,[w,b]) 
     13 #descend the gradients
---&gt; 14 w = w.assign_sub(0.001*dl_dw)
     15 b = b.assign_sub(0.001*dl_db)

TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'
</code></pre>
<p>I checked the documentation which explains the possibilities of the gradients becoming <code>None</code>, but none of them are helping.</p>
","The following gradient descent is failing 'coz the gradients returned by tape.gradient() are none when the loop runs second time. I checked the documentation which explains the possibilities of the gradients becoming None, but none of them are helping.",https://stackoverflow.com/questions/71590479,3151330,Inadequate Examples,Inadequate Examples,"I checked the documentation which explains the possibilities of the gradients becoming None, but none of them are helping."
75552310,How to use my pretrained LSTM saved model to make new classifications,"<p>I have a simple pretrained LSTM model builded with Keras and Tensorflow, I trained, compiled and fitted it, and make a test prediction with a simple sentence, and it works, then I saved my model using <code>model.save(sentanalysis.h5</code> and everything OK. Then, I loaded this model with <code>model.load_model()</code>, and it loads without error, but when I tried <code>model.predict()</code> I got an array with floats that doesn't shows anything related to the classes:</p>
<p>How can I use my pretrained model to make new classifications?
The dataset I use to train it is very simple, a csv with <code>text</code> and <code>sentiment</code> columns, nothing else.
Can you help me?
This is the code of the model:</p>
<pre><code>import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import nlp
import random
from keras.preprocessing.text import Tokenizer
from keras_preprocessing.sequence import pad_sequences

dataset = nlp.load_dataset('csv', data_files={'train':'/content/drive/MyDrive/Proyect/BehaviorClassifier/tass2019_pe_train_final.csv',
                                              'test': '/content/drive/MyDrive/Proyect/BehaviorClassifier/tass2019_pe_test_final.csv',
                                              'validation': '/content/drive/MyDrive/Proyect/BehaviorClassifier/tass2019_pe_val_final.csv'})
train = dataset['train']
val = dataset['validation']
test = dataset['test']

def get_tweet(data):
    tweets = [x['Text'] for x in data]
    labels = [x['behavior'] for x in data]
    return tweets, labels

tweets, labels = get_tweet(train)

tokenizer = Tokenizer(num_words=10000, oov_token='&lt;UNK&gt;')
tokenizer.fit_on_texts(tweets)

maxlen = 140

def get_sequences(tokenizer, tweets):
    sequences = tokenizer.texts_to_sequences(tweets)
    padded = pad_sequences(sequences, truncating='post', padding='post', maxlen=maxlen)
    return padded

padded_train_seq = get_sequences(tokenizer, tweets)

classes = set(labels)
class_to_index = dict((c, i) for i, c in enumerate(classes))
index_to_class = dict((v, k) for k, v in class_to_index.items())
names_to_ids = lambda labels: np.array([class_to_index.get(x) for x in labels])
train_labels = names_to_ids(labels)

model = tf.keras.models.Sequential([
    tf.keras.layers.Embedding(10000, 16, input_length=maxlen),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),
    tf.keras.layers.Dense(6, activation='softmax')
])
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

val_tweets, val_labels = get_tweet(val)
val_seq = get_sequences(tokenizer, val_tweets)
val_labels= names_to_ids(val_labels)
h = model.fit(
     padded_train_seq, train_labels,
     validation_data=(val_seq, val_labels),
     epochs=8#,
     #callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]
)

test_tweets, test_labels=get_tweet(test)
test_seq = get_sequences(tokenizer, test_tweets)
test_labels=names_to_ids(test_labels)
model.evaluate(test_seq, test_labels)

# This code works when I loaded the previos code
sentence = 'I am very happy now'
sequence = tokenizer.texts_to_sequences([sentence])
paddedSequence = pad_sequences(sequence, truncating = 'post', padding='post', maxlen=maxlen)
p = model.predict(np.expand_dims(paddedSequence[0], axis=0))[0]
pred_class=index_to_class[np.argmax(p).astype('uint8')]
print('Sentence: ', sentence)
print('Sentiment: ', pred_class)
</code></pre>
<p>And this is how I save and load my model withouth loading previous code:</p>
<pre><code>model.save('/content/drive/MyDrive/Proyect/BehaviorClassifier/twitterBehaviorClassifier.h5')
model = keras.models.load_model('/content/drive/MyDrive/Proyect/BehaviorClassifier/twitterBehaviorClassifier.h5')

#### ISSUE HERE
new = [&quot;I am very happy&quot;]
tokenizer = Tokenizer(num_words=10000, oov_token='&lt;UNK&gt;')
tokenizer.fit_on_texts(new)
seq = tokenizer.texts_to_sequences(new)
padded = pad_sequences(seq, maxlen=140)
pred = model.predict(padded)
</code></pre>
<p>And I get this:</p>
<pre><code>1/1 [==============================] - 0s 29ms/step
[[7.0648360e-01 1.1568426e-01 1.7581969e-01 7.2872970e-04 4.2903548e-04
  8.5460022e-04]]
</code></pre>
<p>I've reading some doc, but nothing helped me.</p>
","I have a simple pretrained LSTM model builded with Keras and Tensorflow, I trained, compiled and fitted it, and make a test prediction with a simple sentence, and it works, then I saved my model using model.save(sentanalysis.h5 and everything OK. Then, I loaded this model with model.load_model(), and it loads without error, but when I tried model.predict() I got an array with floats that doesn't shows anything related to the classes: How can I use my pretrained model to make new classifications? The dataset I use to train it is very simple, a csv with text and sentiment columns, nothing else. Can you help me? This is the code of the model: And this is how I save and load my model withouth loading previous code: And I get this: I've reading some doc, but nothing helped me.",https://stackoverflow.com/questions/75552310,19156897,Inadequate Examples,Inadequate Examples,"I've reading some doc, but nothing helped me."
38800965,What does the column and rows for images in TensorBoard mean?,"<p>I was trying to use the tensorflow <code>tf. image_summary</code> but it wasn't clear to me how to use it. In the <a href=""https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/tensorboard/README.md"" rel=""nofollow noreferrer"">tensorboard readme</a> file they have the following sentence that confuses me:</p>

<blockquote>
  <p>The dashboard is set up so that each row corresponds to a different
  tag, and each column corresponds to a run.</p>
</blockquote>

<p>I don't understand the sentence and thus, I am having a hard time figuring out what the columns and rows mean for TensorBoard image visualization. What exactly is a ""tag"" and what exactly is a ""run""? How do I get multiple ""tags"" and multiple ""runs"" to display? Why would I want multiple ""tags"" and ""runs"" to display? </p>

<p>Does someone have a very simple but non-trivial example of how to use this?</p>

<p>Ideally, what I want to use is compare how my model performs with respect to PCA so in my head it would be nice to compare how the reconstructions compare to PCA reconstruction at each step. Not sure if this is a good idea but I also want to see what the activation images look like and how the templates look like.</p>

<hr>

<p>Curenttly I have a very simple script with the following lines:</p>

<pre><code>with tf.name_scope('input_reshape'):
    x_image = tf.to_float(x, name='ToFloat')
    image_shaped_input = tf.reshape(x_image, [-1, 28, 28, 1])
    tf.image_summary('input', image_shaped_input, 10)
</code></pre>

<p>currently I have managed to discover that the rows are of length 10 so i assume its showing me 10 images that have something to do with the current run/batch.</p>

<p><a href=""https://i.stack.imgur.com/1KUEP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1KUEP.png"" alt=""enter image description here""></a></p>

<p>however, if possible I'd like to see reconstruction, filters (currently I am doing fully connected to keep things simple but eventually it would be nice to see a conv net examples), activation units (with any number of units that I choose), etc. </p>
","I was trying to use the tensorflow tf. image_summary but it wasn't clear to me how to use it. In the tensorboard readme file they have the following sentence that confuses me: I don't understand the sentence and thus, I am having a hard time figuring out what the columns and rows mean for TensorBoard image visualization. What exactly is a ""tag"" and what exactly is a ""run""? How do I get multiple ""tags"" and multiple ""runs"" to display? Why would I want multiple ""tags"" and ""runs"" to display? Does someone have a very simple but non-trivial example of how to use this? Ideally, what I want to use is compare how my model performs with respect to PCA so in my head it would be nice to compare how the reconstructions compare to PCA reconstruction at each step. Not sure if this is a good idea but I also want to see what the activation images look like and how the templates look like. Curenttly I have a very simple script with the following lines: currently I have managed to discover that the rows are of length 10 so i assume its showing me 10 images that have something to do with the current run/batch. however, if possible I'd like to see reconstruction, filters (currently I am doing fully connected to keep things simple but eventually it would be nice to see a conv net examples), activation units (with any number of units that I choose), etc.",https://stackoverflow.com/questions/38800965,1601580,Inadequate Examples,Inadequate Examples,I was trying to use the tensorflow tf. image_summary but it wasn't clear to me how to use it.
38810424,How does one debug NaN values in TensorFlow?,"<p>I was running TensorFlow and I happen to have something yielding a NaN. I'd like to know what it is but I do not know how to do this. The main issue is that in a ""normal"" procedural program I would just write a print statement just before the operation is executed. The issue with TensorFlow is that I cannot do that because I first declare (or define) the graph, so adding print statements to the graph definition does not help. Are there any rules, advice, heuristics, anything to track down what might be causing the NaN?</p>

<hr>

<p>In this case I know more precisely what line to look at because I have the following:</p>

<pre><code>Delta_tilde = 2.0*tf.matmul(x,W) - tf.add(WW, XX) #note this quantity should always be positive because its pair-wise euclidian distance
Z = tf.sqrt(Delta_tilde)
Z = Transform(Z) # potentially some transform, currently I have it to return Z for debugging (the identity)
Z = tf.pow(Z, 2.0)
A = tf.exp(Z) 
</code></pre>

<p>when this line is present I have it that it returns NaN as declared by my summary writers. Why is this? Is there a way to at least explore what value Z has after its being square rooted?</p>

<hr>

<p>For the specific example I posted, I tried <code>tf.Print(0,Z)</code> but with no success it printed nothing. As in:</p>

<pre><code>Delta_tilde = 2.0*tf.matmul(x,W) - tf.add(WW, XX) #note this quantity should always be positive because its pair-wise euclidian distance
Z = tf.sqrt(Delta_tilde)
tf.Print(0,[Z]) # &lt;-------- TF PRINT STATMENT
Z = Transform(Z) # potentially some transform, currently I have it to return Z for debugging (the identity)
Z = tf.pow(Z, 2.0)
A = tf.exp(Z) 
</code></pre>

<p>I actually don't understand what <code>tf.Print</code> is suppose to do. Why does it need two arguments? If I want to print 1 tensor why would I need to pass 2? Seems bizarre to me.</p>

<hr>

<p>I was looking at the function <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/control_flow_ops.html#add_check_numerics_ops"" rel=""noreferrer"">tf.add_check_numerics_ops()</a> but it doesn't say how to use it (plus the docs seem to not be super helpful). Does anyone know how to use this?</p>

<hr>

<p>Since I've had comments addressing the data might be bad, I am using standard MNIST. However, I am computing a quantity that is positive (pair-wise eucledian distance) and then square rooting it. Thus, I wouldn't see how the data specifically would be an issue.</p>
","I was running TensorFlow and I happen to have something yielding a NaN. I'd like to know what it is but I do not know how to do this. The main issue is that in a ""normal"" procedural program I would just write a print statement just before the operation is executed. The issue with TensorFlow is that I cannot do that because I first declare (or define) the graph, so adding print statements to the graph definition does not help. Are there any rules, advice, heuristics, anything to track down what might be causing the NaN? In this case I know more precisely what line to look at because I have the following: when this line is present I have it that it returns NaN as declared by my summary writers. Why is this? Is there a way to at least explore what value Z has after its being square rooted? For the specific example I posted, I tried tf.Print(0,Z) but with no success it printed nothing. As in: I actually don't understand what tf.Print is suppose to do. Why does it need two arguments? If I want to print 1 tensor why would I need to pass 2? Seems bizarre to me. I was looking at the function tf.add_check_numerics_ops() but it doesn't say how to use it (plus the docs seem to not be super helpful). Does anyone know how to use this? Since I've had comments addressing the data might be bad, I am using standard MNIST. However, I am computing a quantity that is positive (pair-wise eucledian distance) and then square rooting it. Thus, I wouldn't see how the data specifically would be an issue.",https://stackoverflow.com/questions/38810424,1601580,Documentation Completeness,Inadequate Examples,I was looking at the function tf.add_check_numerics_ops() but it doesn't say how to use it (plus the docs seem to not be super helpful).
49287202,How to periodically save tensorflow model using saved_model API?,"<p>So for various reasons (such as its language-independence) I want to use tensorflow's <a href=""https://www.tensorflow.org/programmers_guide/saved_model#apis_to_build_and_load_a_savedmodel"" rel=""nofollow noreferrer"">saved_model</a> API for saving/loading models.  I can save everything (and restore it successfully) with a call to <code>builder.add_meta_graph_and_variables()</code> at the end of training, but I don't see any way to save periodically.  Tensorflow docs on this are very sparse, and the template code they provide (<a href=""https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder"" rel=""nofollow noreferrer"">here</a>) doesn't help me:</p>

<pre><code>...
builder = tf.saved_model.builder.SavedModelBuilder(export_dir)

with tf.Session(graph=tf.Graph()) as sess:
  ...
  builder.add_meta_graph_and_variables(sess,
                                  [""foo-tag""],
                                  signature_def_map=foo_signatures,
                                  assets_collection=foo_assets)
...

with tf.Session(graph=tf.Graph()) as sess:
  ...
  builder.add_meta_graph([""bar-tag"", ""baz-tag""])
...

builder.save()
</code></pre>

<p>Calling <code>builder.save()</code> does not save the new variables into the model.  It just updates the model protobuf.  </p>

<p>What am I missing?  How do I save after e.g. the nth epoch using <code>saved_model</code>?</p>
","So for various reasons (such as its language-independence) I want to use tensorflow's saved_model API for saving/loading models. I can save everything (and restore it successfully) with a call to builder.add_meta_graph_and_variables() at the end of training, but I don't see any way to save periodically. Tensorflow docs on this are very sparse, and the template code they provide (here) doesn't help me: Calling builder.save() does not save the new variables into the model. It just updates the model protobuf. What am I missing? How do I save after e.g. the nth epoch using saved_model?",https://stackoverflow.com/questions/49287202,8721926,Inadequate Examples,Inadequate Examples,"Tensorflow docs on this are very sparse, and the template code they provide (here) doesn't help me"
47379766,Replacing a node in a frozen Tensorflow model,"<p>I have a <code>frozen inference graph</code> stored in a <code>.pb file</code>, which was obtained from a <code>trained Tensorflow model</code> by the <code>freeze_graph</code> function. </p>

<p><strong>Suppose, for simplicity,</strong> that I would like to change some of the <code>sigmoid activations</code> in the model to <code>tanh activations</code> (and let's not discuss whether this is a good idea). </p>

<p><strong>How can this be done with access only to the frozen graph in the .pb file, and without the possibility to retrain the model?</strong></p>

<p>I am aware of the <code>Graph Editor library in tf.contrib</code>, which should be able to do this kind of job, but I wasn't able to figure out a simple way to do this in the documentation.</p>
","I have a frozen inference graph stored in a .pb file, which was obtained from a trained Tensorflow model by the freeze_graph function. Suppose, for simplicity, that I would like to change some of the sigmoid activations in the model to tanh activations (and let's not discuss whether this is a good idea). How can this be done with access only to the frozen graph in the .pb file, and without the possibility to retrain the model? I am aware of the Graph Editor library in tf.contrib, which should be able to do this kind of job, but I wasn't able to figure out a simple way to do this in the documentation.",https://stackoverflow.com/questions/47379766,7869068,Inadequate Examples,Inadequate Examples,"I am aware of the Graph Editor library in tf.contrib, which should be able to do this kind of job, but I wasn't able to figure out a simple way to do this in the documentation."
55040014,How to weight clip in tensorflow?,"<p>I am coding a wgan in tensorflow on mnist dataset and it works well but I am finding it difficult to clip weights of discriminator model <code>[-0.01,0.01]</code> in tensorflow. In <a href=""https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py"" rel=""nofollow noreferrer"">keras</a> we can do weight clipping using.</p>

<pre><code>for l in self.discriminator.layers:
    weights = l.get_weights()
    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]
    l.set_weights(weights)
</code></pre>

<p>I have found a tensorflow doc for <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/gan/features/clip_discriminator_weights"" rel=""nofollow noreferrer"">weight clipping discrimantor</a> </p>

<pre><code>tf.contrib.gan.features.clip_discriminator_weights(
    optimizer,
    model,
    weight_clip
)
</code></pre>

<p>Other than this there is not much is given to how use this function.</p>

<pre><code>#my tf code
def generator(z):
    h=tf.nn.relu(layer_mlp(z,""g1"",[10,128]))
    prob=tf.nn.sigmoid(layer_mlp(h,""g2"",[128,784]))
    return prob


def discriminator(x):
    h=tf.nn.relu(layer_mlp(x,""d1"",[784,128]))
    logit=layer_mlp(h,""d2"",[128,1])
    prob=tf.nn.sigmoid(logit)
    return prob

G_sample=generator(z)
D_real= discriminator(x)
D_fake= discriminator(G_sample)


D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)
G_loss = -tf.reduce_mean(D_fake)

for epoch in epochs:
    #training the model
</code></pre>
","I am coding a wgan in tensorflow on mnist dataset and it works well but I am finding it difficult to clip weights of discriminator model [-0.01,0.01] in tensorflow. In keras we can do weight clipping using. I have found a tensorflow doc for weight clipping discrimantor Other than this there is not much is given to how use this function.",https://stackoverflow.com/questions/55040014,996366,Inadequate Examples,Inadequate Examples,I have found a tensorflow doc for weight clipping discrimantor Other than this there is not much is given to how use this function.
41705377,What is the right initializer one should give to the tf.contrib.layers.convolution2d function in TensorFlow?,"<p>I was reading the documentation for <a href=""https://www.tensorflow.org/api_docs/python/contrib.layers/higher_level_ops_for_building_neural_network_layers_#convolution2d"" rel=""nofollow noreferrer"">making 2d convolutional layers</a> in tensorflow from the contrib section and was wondering what was the right or best way to initialize the weights when using the <a href=""https://www.tensorflow.org/api_docs/python/contrib.layers/higher_level_ops_for_building_neural_network_layers_#convolution2d"" rel=""nofollow noreferrer"">tf.contrib.layers.convolution2d</a> function. Unfortunately they don't really say explicitly nor provide an example, so it was unclear to me what is the intended way to use this. The function has a <code>weights_initializer</code> parameter which can be set. I have tried setting it to both:</p>

<ol>
<li>tf.contrib.layers.xavier_initializer</li>
<li>tf.contrib.layers.xavier_initializer_conv2d</li>
</ol>

<p>neither seem to return an error and the first one seems to train fine (as far as I can tell). However, it would be awesome to check if this is the right way of using this contrib layer (or maybe since it seems to be a contrib function, how does one check the ""official"" source code maybe to see their docs or test cases or maybe address the my question in their gitissues, if appropriate).</p>
","I was reading the documentation for making 2d convolutional layers in tensorflow from the contrib section and was wondering what was the right or best way to initialize the weights when using the tf.contrib.layers.convolution2d function. Unfortunately they don't really say explicitly nor provide an example, so it was unclear to me what is the intended way to use this. The function has a weights_initializer parameter which can be set. I have tried setting it to both: neither seem to return an error and the first one seems to train fine (as far as I can tell). However, it would be awesome to check if this is the right way of using this contrib layer (or maybe since it seems to be a contrib function, how does one check the ""official"" source code maybe to see their docs or test cases or maybe address the my question in their gitissues, if appropriate).",https://stackoverflow.com/questions/41705377,1601580,Inadequate Examples,Inadequate Examples,"I was reading the documentation for making 2d convolutional layers in tensorflow from the contrib section and was wondering what was the right or best way to initialize the weights when using the tf.contrib.layers.convolution2d function. Unfortunately they don't really say explicitly nor provide an example, so it was unclear to me what is the intended way to use this."
48481873,how to set stride to zero when using tf.layers.conv2d,"<p>is there a way that I can turn off stride in tensor flow when using: tf.layers.conv2d()? According to the docs, the default is (1,1) but when I try to change this to (0,0) I get an error telling me that it has to be a positive number.</p>

<p>Thanks.</p>
","is there a way that I can turn off stride in tensor flow when using: tf.layers.conv2d()? According to the docs, the default is (1,1) but when I try to change this to (0,0) I get an error telling me that it has to be a positive number. Thanks.",https://stackoverflow.com/questions/48481873,9278090,Inadequate Examples,Inadequate Examples,"is there a way that I can turn off stride in tensor flow when using: tf.layers.conv2d()? According to the docs, the default is (1,1) but when I try to change this to (0,0) I get an error telling me that it has to be a positive number. Thanks."
46219326,How to use tf.losses.log_loss in tensorflow?,"<p>What is the input of tf.losses.log_loss ?</p>

<pre><code>cross_entropy = tf.losses.log_loss(labels, predictions)
</code></pre>

<p>Anybody can show me some examples about it ?
Official guide has no examples .</p>
",What is the input of tf.losses.log_loss ? Anybody can show me some examples about it ? Official guide has no examples .,https://stackoverflow.com/questions/46219326,6407393,Inadequate Examples,Inadequate Examples,Anybody can show me some examples about it ? Official guide has no examples .
55368272,"How do you index a RaggedTensor along the ragged dimension, in TensorFlow?","<p>I need to get values in a ragged tensor by indexing along the ragged dimension. Some indexing works (<code>[:, :x]</code>, <code>[:, -x:]</code> or <code>[:, x:y]</code>), but not direct indexing (<code>[:, x]</code>):</p>

<pre class=""lang-py prettyprint-override""><code>R = tf.RaggedTensor.from_tensor([[1, 2, 3], [4, 5, 6]])
print(R[:, :2]) # RaggedTensor([[1, 2], [4, 5]])
print(R[:, 1:2]) # RaggedTensor([[2], [5]])
print(R[:, 1])  # ValueError: Cannot index into an inner ragged dimension.
</code></pre>

<p>The <a href=""https://www.tensorflow.org/guide/ragged_tensors"" rel=""noreferrer"">documentation</a> explains why this fails:</p>

<blockquote>
  <p>RaggedTensors supports multidimensional indexing and slicing, with one
  restriction: indexing into a ragged dimension is not allowed. This
  case is problematic because the indicated value may exist in some rows
  but not others. In such cases, it's not obvious whether we should (1)
  raise an IndexError; (2) use a default value; or (3) skip that value
  and return a tensor with fewer rows than we started with. Following
  the guiding principles of Python (""In the face of ambiguity, refuse
  the temptation to guess"" ), we currently disallow this operation.</p>
</blockquote>

<p>This makes sense, but how do I actually implement options 1, 2 and 3? Must I convert the ragged array into a Python array of Tensors, and manually iterate over them? Is there a more efficient solution? One that would work 100% in a TensorFlow graph, without going through the Python interpreter?</p>
","I need to get values in a ragged tensor by indexing along the ragged dimension. Some indexing works ([:, :x], [:, -x:] or [:, x:y]), but not direct indexing ([:, x]): The documentation explains why this fails: This makes sense, but how do I actually implement options 1, 2 and 3? Must I convert the ragged array into a Python array of Tensors, and manually iterate over them? Is there a more efficient solution? One that would work 100% in a TensorFlow graph, without going through the Python interpreter?",https://stackoverflow.com/questions/55368272,38626,Inadequate Examples,Inadequate Examples,"The documentation explains why this fails: This makes sense, but how do I actually implement options 1, 2 and 3? Must I convert the ragged array into a Python array of Tensors, and manually iterate over them? Is there a more efficient solution?"
46735542,How to interpret histogram plot in tensorflow/tensorboard?,"<p>I compute <code>(n_samples,1)</code> rotation angles and pass them to histogram summary</p>

<pre><code>angles_histogram = tf.summary.histogram(""angles_histogram"", angles)
</code></pre>

<p>and pass it to writer with the following command</p>

<pre><code>angles_histogram_value = sess.run([self.angles_histogram])
rotations_writer.add_summary(angles_histogram_value, global_count - 1)
</code></pre>

<p>Angles are in radians and <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/histogram"" rel=""nofollow noreferrer"">in docs it is said</a> that all values are used to build histogram. Unfortunately, I see nothing similar to what I would expect</p>

<p><a href=""https://i.stack.imgur.com/6cdRt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6cdRt.png"" alt=""enter image description here""></a></p>

<p>How to interpet this plot?</p>
","I compute (n_samples,1) rotation angles and pass them to histogram summary and pass it to writer with the following command Angles are in radians and in docs it is said that all values are used to build histogram. Unfortunately, I see nothing similar to what I would expect How to interpet this plot?",https://stackoverflow.com/questions/46735542,258483,Inadequate Examples,Inadequate Examples,"Angles are in radians and in docs it is said that all values are used to build histogram. Unfortunately, I see nothing similar to what I would expect How to interpet this plot?"
52484694,TF Eager mode: Load a complete model from disk if possible,"<p><em>Update: ""AttributeError: 'AdamOptimizer' object has no attribute 'name'"" might be an alternative title for this question. If this can be solved then the whole thing might work right.</em></p>

<p>Have a new jupyter notebook that has NO model saving code.  The trained model was already saved using another notebook like this. The iris dataset was used here and the model is all trained up:</p>

<pre><code>#This might be the way:
#https://www.tensorflow.org/guide/eager#object_based_saving
#https://stackoverflow.com/questions/47852516/tensorflow-eager-mode-how-to-restore-a-model-from-a-checkpoint
savePrefix = ""/tmp/iris""
root = tfe.Checkpoint(optimizer=optimizer, model=model, optimizer_step=global_step)
restorePrefix = root.save(savePrefix)
# '/tmp/iris-1'
print(restorePrefix)
print(root)
print(""The model was saved to {}\nRestore the model using {}"".format(savePrefix, restorePrefix))
# Try loading this in a different notebook to prove it worked.

&gt;/tmp/iris-1
&gt;&lt;tensorflow.contrib.eager.python.checkpointable_utils.Checkpoint object at 0x7fb308799e80&gt;
&gt;The model was saved to /tmp/iris
&gt;Restore the model using /tmp/iris-1
</code></pre>

<p>I grabbed the output path from the above and then tried to load the model in a new notebook using tf.contrib.eager code but it fails:</p>

<pre><code>s = tfe.Saver([optimizer, model, global_step])
s.restore(file_prefix=""/tmp/iris-1"")

&gt;NameError: name 'optimizer' is not defined
</code></pre>

<p>So what is an actually WORKING use case code to load a previously developed model with the tf.contrib.eager api (not the session api) WHEN THE CODE IN THE MODEL-LOADING NOTEBOOK DOES NOT SAVE THE MODEL AND DOES NOT HAVE THE MODEL'S PARTS IN MEMORY ALREADY like optimizer, graph definition, and global_state?</p>

<p>The TF docs always choose to demo a pointless example of loading a model we already have in memory.  I can't tell if ""With the TF.contrib.eager API you have to have explicit model creation code and optimizer creation code and global step code right in your notebook because TFE cannot load this stuff from disk"" or ""its a new API and some features are missing"", or ""you have to also use session and graph coding api along with tf.contrib.eager api"" or ""just use Microsoft cntk which actually works with imperative code and they didnt forget critical parts of the API"". </p>

<p>Thanks if you know something. If speculating, please state.</p>

<p>I suspect it's some superset and subset combination of the following if it's going to work. (Scraped from SO posts on the subject.)</p>

<pre><code>tfe.restore_variables_on_create 
tf.train.import_meta_graph() 
new_saver.restore()
tf.train.latest_checkpoint()
tfe.save_network_checkpoint()
tfe.restore_network_checkpoint()
</code></pre>

<p>Update - I added code to first manually recreate the model, optimizer, etc into memory, and then ran the restore() code. Error - optimizer does not have a name. But, oddly, it actually does have a name attribute according to the documentation:</p>

<pre><code>#OK I'll just try to use code to create the model artifacts first. 
# I'd rather load it all from disk but maybe at least it might work.

optimizer = tf.train.AdamOptimizer() #ga
global_step = tf.train.get_or_create_global_step()  # what is a global_step?
model = tf.keras.Sequential([
  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required
  tf.keras.layers.Dense(10, activation=tf.nn.relu, kernel_initializer='glorot_uniform'),
  tf.keras.layers.Dense(3)
])
s = tfe.Saver([optimizer, model, global_step])
s.restore(file_prefix=""/tmp/iris-1"")
</code></pre>

<p>INFO:tensorflow:Restoring parameters from /tmp/iris-1</p>

<hr>

<p>AttributeError: 'AdamOptimizer' object has no attribute 'name'</p>

<p>The documentation says:</p>

<pre><code>__init__(
    learning_rate=0.001,
    beta1=0.9,
    beta2=0.999,
    epsilon=1e-08,
    use_locking=False,
    name='Adam'
)
</code></pre>

<p>It sure looks like Adam optimizer has a name!  That's funny. What's the problem then?</p>

<p>Maybe the TF error is really saying that an optimizer and a model and a global_state variable cannot be restored.  So then what would be restored from a checkpoint -- specifically what variables would go in the save and corresponding restore?  Thanks if you know anything.</p>
","Update: ""AttributeError: 'AdamOptimizer' object has no attribute 'name'"" might be an alternative title for this question. If this can be solved then the whole thing might work right. Have a new jupyter notebook that has NO model saving code. The trained model was already saved using another notebook like this. The iris dataset was used here and the model is all trained up: I grabbed the output path from the above and then tried to load the model in a new notebook using tf.contrib.eager code but it fails: So what is an actually WORKING use case code to load a previously developed model with the tf.contrib.eager api (not the session api) WHEN THE CODE IN THE MODEL-LOADING NOTEBOOK DOES NOT SAVE THE MODEL AND DOES NOT HAVE THE MODEL'S PARTS IN MEMORY ALREADY like optimizer, graph definition, and global_state? The TF docs always choose to demo a pointless example of loading a model we already have in memory. I can't tell if ""With the TF.contrib.eager API you have to have explicit model creation code and optimizer creation code and global step code right in your notebook because TFE cannot load this stuff from disk"" or ""its a new API and some features are missing"", or ""you have to also use session and graph coding api along with tf.contrib.eager api"" or ""just use Microsoft cntk which actually works with imperative code and they didnt forget critical parts of the API"". Thanks if you know something. If speculating, please state. I suspect it's some superset and subset combination of the following if it's going to work. (Scraped from SO posts on the subject.) Update - I added code to first manually recreate the model, optimizer, etc into memory, and then ran the restore() code. Error - optimizer does not have a name. But, oddly, it actually does have a name attribute according to the documentation: INFO:tensorflow:Restoring parameters from /tmp/iris-1 AttributeError: 'AdamOptimizer' object has no attribute 'name' The documentation says: It sure looks like Adam optimizer has a name! That's funny. What's the problem then? Maybe the TF error is really saying that an optimizer and a model and a global_state variable cannot be restored. So then what would be restored from a checkpoint -- specifically what variables would go in the save and corresponding restore? Thanks if you know anything.",https://stackoverflow.com/questions/52484694,39123,Documentation Completeness,Inadequate Examples,The TF docs always choose to demo a pointless example of loading a model we already have in memory.
46781847,How periodicaly evaluate the Performance of Models in TF-Slim?,"<p>I am trying to use <a href=""https://github.com/pudae/tensorflow-densenet"" rel=""nofollow noreferrer"">DensNet</a> for regression problem with TF-Slim. My data contains 60000 jpeg images with 37 float labels for each image. I divided my data into three different tfrecords files of a train set (60%), a validation set (20%) and a test set (20%). </p>

<p>I need to evaluate validation set during training loop and make a plot like <a href=""https://i.stack.imgur.com/HzLPq.jpg"" rel=""nofollow noreferrer"">image</a>. 
In TF-Slim documentation they just explain train loop and evaluation loop separately. I can just evaluate validation or test set after training loop finished. While as I said I need to evaluate during training.</p>

<p>I tried to use slim.evaluation.evaluation_loop function instead of slim.evaluation.evaluate_once. But it doesn't help.</p>

<pre><code>slim.evaluation.evaluation_loop(
    master=FLAGS.master,
    checkpoint_dir=checkpoint_path,
    logdir=FLAGS.eval_dir,
    num_evals=num_batches,
    eval_op=list(names_to_updates.values()) + print_ops,
    variables_to_restore=variables_to_restore,
    summary_op = tf.summary.merge(summary_ops),
    eval_interval_secs = eval_interval_secs )
</code></pre>

<p>I tried evaluation.evaluate_repeatedly as well.</p>

<pre><code>from tensorflow.contrib.training.python.training import evaluation

evaluation.evaluate_repeatedly(
    master=FLAGS.master,
    checkpoint_dir=checkpoint_path,
    eval_ops=list(names_to_updates.values()) + print_ops,
    eval_interval_secs = eval_interval_secs )
</code></pre>

<p>In both of these functions, they just read the latest available checkpoint from checkpoint_dir and apparently waiting for the next one, however when the new checkpoints are generated, they don't perform at all.</p>

<p>I use Python 2.7.13 and Tensorflow 1.3.0 on CPU.</p>

<p>Any help will be highly appreciated.</p>
","I am trying to use DensNet for regression problem with TF-Slim. My data contains 60000 jpeg images with 37 float labels for each image. I divided my data into three different tfrecords files of a train set (60%), a validation set (20%) and a test set (20%). I need to evaluate validation set during training loop and make a plot like image. In TF-Slim documentation they just explain train loop and evaluation loop separately. I can just evaluate validation or test set after training loop finished. While as I said I need to evaluate during training. I tried to use slim.evaluation.evaluation_loop function instead of slim.evaluation.evaluate_once. But it doesn't help. I tried evaluation.evaluate_repeatedly as well. In both of these functions, they just read the latest available checkpoint from checkpoint_dir and apparently waiting for the next one, however when the new checkpoints are generated, they don't perform at all. I use Python 2.7.13 and Tensorflow 1.3.0 on CPU. Any help will be highly appreciated.",https://stackoverflow.com/questions/46781847,8161718,Inadequate Examples,Inadequate Examples,In TF-Slim documentation they just explain train loop and evaluation loop separately. I can just evaluate validation or test set after training loop finished.
48944611,How can I read binary file in Tensorflow,"<p>I'm trying to read binary file in <strong>tensorflow</strong>.
I want to ask, which method should I use, and how for reading binary file.
In tensorflow, they recommends use dataset in tf.data.
But I can't find simple example of using dataset, especially FixedLengthRecordDataset. I think I should use this method, but I don't know how to use. </p>

<pre><code>[hg file] := [file header] [image1] [image2] [image3] ...

[file header] := ""hg  "" (8 bytes)

[imageN] := [image header] [image data]

[image header] := [code(2 bytes)] [width (1 byte)] [height(1 byte)] [reserved(2 bytes)]

[image data] := 256 gray data (width * height bytes, row-major format)
</code></pre>

<p>This is the format of my binary file.</p>

<p>Please give me some advice for this work.</p>

<p>EDIT : All images have different size. So maybe I can't use FixedLengthRecordDatasest. I think I have to convert all images to same size of dataset</p>
","I'm trying to read binary file in tensorflow. I want to ask, which method should I use, and how for reading binary file. In tensorflow, they recommends use dataset in tf.data. But I can't find simple example of using dataset, especially FixedLengthRecordDataset. I think I should use this method, but I don't know how to use. This is the format of my binary file. Please give me some advice for this work. EDIT : All images have different size. So maybe I can't use FixedLengthRecordDatasest. I think I have to convert all images to same size of dataset",https://stackoverflow.com/questions/48944611,9400682,Inadequate Examples,Inadequate Examples,"In tensorflow, they recommends use dataset in tf.data. But I can't find simple example of using dataset, especially FixedLengthRecordDataset."
50204609,Is there a way to partition a tf.Dataset with TensorFlow’s Dataset API?,"<p>I checked <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">the doc</a> but I could not find a method for it. I want to de cross validation, so I kind of need it.</p>

<p>Note that I'm not asking how to split a tensor, as I know that TensorFlow provides an API for that an has been answered in another question. I'm asking on how to partition a tf.Dataset (which is an abstraction).</p>
","I checked the doc but I could not find a method for it. I want to de cross validation, so I kind of need it. Note that I'm not asking how to split a tensor, as I know that TensorFlow provides an API for that an has been answered in another question. I'm asking on how to partition a tf.Dataset (which is an abstraction).",https://stackoverflow.com/questions/50204609,1120410,Inadequate Examples,Inadequate Examples,I checked the doc but I could not find a method for it.
50825446,Restoring a trained generator network in DCGAN,"<p>I have a question regarding the saving and storing models in tensorflow. I know how to save a model with tf.train.Saver() and load it later through meta file. My problem is this:</p>

<p>I have trained a variant of DCGAN (Deep Convolution GAN), now I want to use only generator network for other tasks. Unfortunately, I do not know how to get entire generator network such that if I feed it with a new vector z, it generates an output based on the trained parameters. All the example I found in the stackoverflow, or tensorflow documentation, just mention very simple operations with two numbers. This is not I want. I want to understand if you have trained a giant network, say with 50 layers, how to load it and feed it with new input and get the output without going into the different parameters and layers in the trained network. I want to load it as a blackbox.</p>
","I have a question regarding the saving and storing models in tensorflow. I know how to save a model with tf.train.Saver() and load it later through meta file. My problem is this: I have trained a variant of DCGAN (Deep Convolution GAN), now I want to use only generator network for other tasks. Unfortunately, I do not know how to get entire generator network such that if I feed it with a new vector z, it generates an output based on the trained parameters. All the example I found in the stackoverflow, or tensorflow documentation, just mention very simple operations with two numbers. This is not I want. I want to understand if you have trained a giant network, say with 50 layers, how to load it and feed it with new input and get the output without going into the different parameters and layers in the trained network. I want to load it as a blackbox.",https://stackoverflow.com/questions/50825446,9932068,Documentation Replication on Other Examples,Inadequate Examples,"All the example I found in the stackoverflow, or tensorflow documentation, just mention very simple operations with two numbers. This is not I want. "
52597523,How to load_weights to a Keras model from a Tensorflow checkpoint,"<p>I have some python code to train a network using Tensorflow's TFRecords and Dataset APIs. I have built the network using tf.Keras.layers, this being arguably the easiest and fastest way. The handy function model_to_estimator()</p>

<pre><code>modelTF = tf.keras.estimator.model_to_estimator(
    keras_model=model,
    custom_objects=None,
    config=run_config,
    model_dir=checkPointDirectory
)
</code></pre>

<p>converts a Keras model to an estimator, which allows us to take advantage of the Dataset API nicely, and automatically save checkpoints to checkPointDirectory during training, and upon training completion. The estimator API presents some invaluable features, such as automatically distributing the workload over multiple GPUs, with, e.g.</p>

<pre><code>distribution = tf.contrib.distribute.MirroredStrategy()
run_config = tf.estimator.RunConfig(train_distribute=distribution)
</code></pre>

<p>Now for big models and lots of data, it is often useful to execute predictions after training using some form of saved model. It seems that as of Tensorflow 1.10 (see <a href=""https://github.com/tensorflow/tensorflow/issues/19295"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/issues/19295</a>), a tf.keras.model object supports load_weights() from a Tensorflow checkpoint. This is mentioned briefly in the Tensorflow docs, but not the Keras docs, and I can't find anyone showing an example of this. After defining the model layers again in some new .py, I have tried </p>

<pre><code>checkPointPath = os.path.join('.', 'tfCheckPoints', 'keras_model.ckpt.index')
model.load_weights(filepath=checkPointPath, by_name=False)
</code></pre>

<p>but this gives a NotImplementedError:</p>

<pre><code>Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.

2018-10-01 14:24:49.912087:
Traceback (most recent call last):
  File ""C:/Users/User/PycharmProjects/python/mercury.classifier reductions/V3.2/wikiTestv3.2/modelEvaluation3.2.py"", line 141, in &lt;module&gt;
    model.load_weights(filepath=checkPointPath, by_name=False)
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\network.py"", line 1526, in load_weights
    checkpointable_utils.streaming_restore(status=status, session=session)
  File ""C:\Users\User\Anaconda3\lib\site-packages\tensorflow\python\training\checkpointable\util.py"", line 880, in streaming_restore
    ""Streaming restore not supported from name-based checkpoints. File a ""
NotImplementedError: Streaming restore not supported from name-based checkpoints. File a feature request if this limitation bothers you.
</code></pre>

<p>I would like to do as suggested by the Warning and use the 'object-based saver' instead, but I haven't found a way to do this via a RunConfig passed to estimator.train(). </p>

<p>So is there a better way to get the saved weights back into an estimator for use in prediction? The github thread seems to suggest that this is already implemented (though based on the error, probably in a different way than I am attempting above). Has anyone successfully used load_weights() on a TF checkpoint? I haven't been able to find any tutorials/examples on how this can be done, so any help is appreciated. </p>
","I have some python code to train a network using Tensorflow's TFRecords and Dataset APIs. I have built the network using tf.Keras.layers, this being arguably the easiest and fastest way. The handy function model_to_estimator() converts a Keras model to an estimator, which allows us to take advantage of the Dataset API nicely, and automatically save checkpoints to checkPointDirectory during training, and upon training completion. The estimator API presents some invaluable features, such as automatically distributing the workload over multiple GPUs, with, e.g. Now for big models and lots of data, it is often useful to execute predictions after training using some form of saved model. It seems that as of Tensorflow 1.10 (see https://github.com/tensorflow/tensorflow/issues/19295), a tf.keras.model object supports load_weights() from a Tensorflow checkpoint. This is mentioned briefly in the Tensorflow docs, but not the Keras docs, and I can't find anyone showing an example of this. After defining the model layers again in some new .py, I have tried but this gives a NotImplementedError: I would like to do as suggested by the Warning and use the 'object-based saver' instead, but I haven't found a way to do this via a RunConfig passed to estimator.train(). So is there a better way to get the saved weights back into an estimator for use in prediction? The github thread seems to suggest that this is already implemented (though based on the error, probably in a different way than I am attempting above). Has anyone successfully used load_weights() on a TF checkpoint? I haven't been able to find any tutorials/examples on how this can be done, so any help is appreciated.",https://stackoverflow.com/questions/52597523,9731282,Inadequate Examples,Inadequate Examples," This is mentioned briefly in the Tensorflow docs, but not the Keras docs, and I can't find anyone showing an example of this."
52878311,How to extract rows and columns from a 3D array in Tensorflow,"<p>I wanted to do the following indexing operation on a TensorFlow tensor.
What should be the equivalent operations in TensorFlow to get <code>b</code> and <code>c</code> as output? Although <code>tf.gather_nd</code> documentation has several examples but I could not generate equivalent <code>indices</code> tensor to get these results.</p>
<pre><code>import tensorflow as tf
import numpy as np

a=np.arange(18).reshape((2,3,3))

idx=[2,0,1] #it can be any validing re-ordering index list

#These are the two numpy operations that I want to do in Tensorflow
b=a[:,idx,:]
c=a[:,:,idx] 

# TensorFlow operations

aT=tf.constant(a)
idxT=tf.constant(idx)

# what should be these two indices  
idx1T=tf.reshape(idxT, (3,1)) 
idx2T=tf.reshape(idxT, (1,1,3))

bT=tf.gather_nd(aT, idx1T ) #does not work
cT=tf.gather_nd(aT, idx2T)  #does not work

with tf.Session() as sess:
    b1,c1=sess.run([bT,cT])

print(np.allclose(b,b1))
print(np.allclose(c,c1))
</code></pre>
<p>I am not restricted to <code>tf.gather_nd</code> Any other suggestion to achieve the same operations on GPU will be helpful.</p>
<h1>Edit: I have updated the question for a typo:</h1>
<p>old statement: <code>c=a[:,idx]</code>,</p>
<p>New statement: <code>c=a[:,:,idx]</code>
What I wanted to achieve was re-ordering of columns as well.</p>
","I wanted to do the following indexing operation on a TensorFlow tensor. What should be the equivalent operations in TensorFlow to get b and c as output? Although tf.gather_nd documentation has several examples but I could not generate equivalent indices tensor to get these results. I am not restricted to tf.gather_nd Any other suggestion to achieve the same operations on GPU will be helpful. old statement: c=a[:,idx], New statement: c=a[:,:,idx] What I wanted to achieve was re-ordering of columns as well.",https://stackoverflow.com/questions/52878311,4082304,Inadequate Examples,Inadequate Examples, Although tf.gather_nd documentation has several examples but I could not generate equivalent indices tensor to get these results. 
71951333,Prepare data input for tensorflow from numpy and scipy.sparse,"<p>How to prepare data for input into a tensorflow model (say a keras Sequential one) ?</p>
<p>I know how to prepare <code>x_train</code>, <code>y_train</code>, <code>x_test</code> and <code>y_test</code> using numpy and scipy (eventually pandas, <code>sklearn</code> style) where <code>train</code>/<code>test</code> datas are train and test datas for training a neural model, and <code>x</code>/<code>y</code> stand for a 2D sparse matrix and a 1D numpy array representing integer labels of the same size as the number of raws in the <code>x</code> data.</p>
<p>I'm struggling with the <a href=""https://www.tensorflow.org/guide/data#reading_input_data"" rel=""nofollow noreferrer"">Dataset documentation</a> without many insight so far ...</p>
<p>So far, I could only convert the scipy.sparse matrix into a <a href=""https://www.tensorflow.org/guide/sparse_tensor"" rel=""nofollow noreferrer"">tensorflow.SparseTensor</a> using something like</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import tensorflow as tf
from scipy import sparse as sp

x = sp.csr_matrix( ... )
x = tf.SparseTensor(indices=np.vstack([*x.nonzero()]).T, 
                    values=x.data, 
                    dense_shape=x.shape)
</code></pre>
<p>and I can convert the numpy array into a <a href=""https://www.tensorflow.org/api_docs/python/tf/Tensor"" rel=""nofollow noreferrer"">tensorflow.Tensor</a> using something like</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
import tensorflow as tf

y = np.array( ... ) # 1D array of len == x.shape[0]
y = tf.constant(y)
</code></pre>
<ul>
<li>How to align the <code>x</code> and <code>y</code> into a single Dataset in order to construct the batch, buffers, ... and benefit from the Dataset utilities ?</li>
<li>Should I use either <code>zip</code>, <code>from_tensor_slices</code>, or any other method of the <a href=""https://www.tensorflow.org/guide/data"" rel=""nofollow noreferrer"">tensorflow.data.Dataset</a> module ?</li>
</ul>
<p>Examples of <code>x</code> and <code>y</code> are</p>
<pre class=""lang-py prettyprint-override""><code>x = tf.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])
y = tf.constant(np.array(range(3)))
</code></pre>
","How to prepare data for input into a tensorflow model (say a keras Sequential one) ? I know how to prepare x_train, y_train, x_test and y_test using numpy and scipy (eventually pandas, sklearn style) where train/test datas are train and test datas for training a neural model, and x/y stand for a 2D sparse matrix and a 1D numpy array representing integer labels of the same size as the number of raws in the x data. I'm struggling with the Dataset documentation without many insight so far ... So far, I could only convert the scipy.sparse matrix into a tensorflow.SparseTensor using something like and I can convert the numpy array into a tensorflow.Tensor using something like Examples of x and y are",https://stackoverflow.com/questions/71951333,8844500,Requesting (Additional) Resources,Inadequate Examples,I'm struggling with the Dataset documentation without many insight so far.
54812292,I try to print in TensorBoard an audio with tf.summary.audio any audio is shown,"<p>I'm using Python 3.6 and TensorFlow 1.8 in a Linux environment. I'm trying to print an audio in TensorBoard with the following code, and even is storing a file, no audio is printed.</p>

<pre><code>import tensorflow as tf
with tf.Session() as sess:
    writer = tf.summary.FileWriter('graphs', sess.graph)
    audio = tf.reshape(tf.linspace(0.0, 100.0, 4 * 10 * 2), (4, 10, 2))
    tf.summary.audio('k488', audio, 2)
    writer.close()
</code></pre>

<p>I have been looking examples or information, but there is no much about tf.summary.audio. This is a example that I found but can't make it work.</p>

<p>Thank you</p>
","I'm using Python 3.6 and TensorFlow 1.8 in a Linux environment. I'm trying to print an audio in TensorBoard with the following code, and even is storing a file, no audio is printed. I have been looking examples or information, but there is no much about tf.summary.audio. This is a example that I found but can't make it work. Thank you",https://stackoverflow.com/questions/54812292,11097109,Inadequate Examples,Inadequate Examples,"I have been looking examples or information, but there is no much about tf.summary.audio. This is a example that I found but can't make it work."
38641887,How to save a trained tensorflow model for later use for application?,"<p>I am a bit of a beginner with tensorflow so please excuse if this is a stupid question and the answer is obvious. </p>

<p>I have created a Tensorflow graph where starting with placeholders for X and y I have optimized some tensors which represent my model. Part of the graph is something where a vector of predictions can be calculated, e.g. for linear regression something like </p>

<pre class=""lang-py prettyprint-override""><code>y_model = tf.add(tf.mul(X,w),d)
y_vals = sess.run(y_model,feed_dict={....})
</code></pre>

<p>After training has been completed I have acceptable values for w and d and now I want to save my model for later. Then, in a different python session I want to restore the model so that I can again run</p>

<pre class=""lang-py prettyprint-override""><code>## Starting brand new python session
import tensorflow as tf
## somehow restor the graph and the values here: how????
## so that I can run this:
y_vals = sess.run(y_model,feed_dict={....})
</code></pre>

<p>for some different data and get back the y-values. </p>

<p>I want this to work in a way where the graph for calculating the y-values from the placeholders is also stored and restored - as long as the placeholders get fed the correct data, this should work transparently without the user (the one who applies the model) needing to know what the graph looks like). </p>

<p>As far as I understand tf.train.Saver().save(..) only saves the variables but I also want to save the graph. I think that tf.train.export_meta_graph could be relevant here but I do not understand how to use it correctly, the documentation is a bit cryptic to me and the examples do not even use export_meta_graph anywhere. </p>
","I am a bit of a beginner with tensorflow so please excuse if this is a stupid question and the answer is obvious. I have created a Tensorflow graph where starting with placeholders for X and y I have optimized some tensors which represent my model. Part of the graph is something where a vector of predictions can be calculated, e.g. for linear regression something like After training has been completed I have acceptable values for w and d and now I want to save my model for later. Then, in a different python session I want to restore the model so that I can again run for some different data and get back the y-values. I want this to work in a way where the graph for calculating the y-values from the placeholders is also stored and restored - as long as the placeholders get fed the correct data, this should work transparently without the user (the one who applies the model) needing to know what the graph looks like). As far as I understand tf.train.Saver().save(..) only saves the variables but I also want to save the graph. I think that tf.train.export_meta_graph could be relevant here but I do not understand how to use it correctly, the documentation is a bit cryptic to me and the examples do not even use export_meta_graph anywhere.",https://stackoverflow.com/questions/38641887,1382437,Inadequate Examples,Inadequate Examples,"I think that tf.train.export_meta_graph could be relevant here but I do not understand how to use it correctly, the documentation is a bit cryptic to me and the examples do not even use export_meta_graph anywhere."
45595419,Is it possible to have multiple conditions defined in tf.while_loop,"<p>Is it possible to define to multiple conditions for termination of a tf.while_loop in tensorflow? For example depending on the two tensor values achieving two specific values. eg. <code>i==2</code> and <code>j==3</code> ?</p>

<p>Also can I have several blocks of code in the body? In all the examples in the documentation, it seems that the body is more like a single statement returning a value or a tuple. I want to execute a set of several ""<strong>sequential</strong>"" statements in the body.</p>
","Is it possible to define to multiple conditions for termination of a tf.while_loop in tensorflow? For example depending on the two tensor values achieving two specific values. eg. i==2 and j==3 ? Also can I have several blocks of code in the body? In all the examples in the documentation, it seems that the body is more like a single statement returning a value or a tuple. I want to execute a set of several ""sequential"" statements in the body.",https://stackoverflow.com/questions/45595419,8348464,Inadequate Examples,Inadequate Examples,"In all the examples in the documentation, it seems that the body is more like a single statement returning a value or a tuple. I want to execute a set of several ""sequential"" statements in the body"
46752071,Feed a Tensor of SparseTensors to estimators,"<p>To get started with TF, I wanted to learn a predictor of match outcomes for a game. There are three features: the 5 heros on team 0, the 5 heroes on team 1, and the map. The winner is the label, 0 or 1.  I want to represent the teams and the maps as SparseTensors. Out of a possible 71 heroes, five will be selected. Likewise for maps, out of a possible 13, one will be selected.</p>

<pre><code>import tensorflow as tf
import packunpack as source
import tempfile
from collections import namedtuple

GameRecord = namedtuple('GameRecord', 'team_0 team_1 game_map winner')
def parse(line):
    parts = line.rstrip().split(""\t"")
    return GameRecord(
        game_map = parts[1], 
        team_0 = parts[2].split("",""), 
        team_1 = parts[3].split("",""), 
        winner = int(parts[4]))

def conjugate(record):
    return GameRecord(
        team_0 = record.team_1, 
        team_1 = record.team_0, 
        game_map = record.game_map, 
        winner = 0 if record.winner == 1 else 1)

def sparse_team(team):
    indices = list(map(lambda x: [x], map(source.encode_hero, team)))
    return tf.SparseTensor(indices=indices, values = [1] * len(indices), dense_shape=[len(source.heroes_array)])

def sparse_map(map_name):
    return tf.SparseTensor(indices=[[source.encode_hero(map_name)]], values = [1], dense_shape=[len(source.maps_array)])

def make_input_fn(filename, shuffle = True, add_conjugate_games = True):
    def _fn():
        records = []
        with open(filename, ""r"") as raw:
            i = 0
            for line in raw:
                record = parse(line)
                records.append(record)
                if add_conjugate_games:
                # since 0 and 1 are arbitrary team labels, learn and test the conjugate game whenever
                # learning the original inference
                    records.append(conjugate(record))

        print(""Making team 0"")
        team_0s = tf.constant(list(map(lambda r: sparse_team(r.team_0), records)))
        print(""Making team 1"")
        team_1s = tf.constant(list(map(lambda r: sparse_team(r.team_1), records)))
        print(""making maps"")
        maps = tf.constant(list(map(lambda r: sparse_map(r.game_map), records)))
        print(""Making winners"")
        winners = tf.constant(list(map(lambda r: tf.constant([r.winner]), records)))

        return {
                    ""team_0"": team_0s,
                    ""team_1"": team_1s,
                    ""game_map"": maps,
                }, winners
        #Please help me finish this function?

    return _fn

team_0 = tf.feature_column.embedding_column(
    tf.feature_column.categorical_column_with_vocabulary_list(""team_0"", source.heroes_array), len(source.heroes_array))
team_1 = tf.feature_column.embedding_column(
    tf.feature_column.categorical_column_with_vocabulary_list(""team_1"", source.heroes_array), len(source.heroes_array))
game_map = tf.feature_column.embedding_column(
    tf.feature_column.categorical_column_with_vocabulary_list(""game_map"", source.maps_array), len(source.maps_array))

model_dir = tempfile.mkdtemp()
m = tf.estimator.DNNClassifier(
    model_dir=model_dir,
    hidden_units = [1024, 512, 256], 
    feature_columns=[team_0, team_1, game_map])

def main():
    m.train(input_fn=make_input_fn(""tiny.txt""), steps = 100)

if __name__ == ""__main__"":
    main()
</code></pre>

<p>This fails on <code>team_0s = tf.constant(list(map(lambda r: sparse_team(r.team_0), records)))</code></p>

<p>It's very difficult to understand what tf wants me to return in my input_fn, because all of the examples I can find in the docs ultimately call out to a pandas or numpy helper function, and I'm not familiar with those frameworks. I thought that each dictionary value should be a Tensor containing all examples of a single feature. Each of my examples is a SparseTensor, and I want to simply embed them as their dense versions for the sake of the DNNClassifier.</p>

<p>I'm sure my mental model is horribly broken right now, and I appreciate any help setting it straight.</p>

<p>Error output:</p>

<pre><code>python3 estimator.py
Making team 0
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 468, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 468, in &lt;listcomp&gt;
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe8
b4d7aef0&gt;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""estimator.py"", line 79, in &lt;module&gt;
    main()
  File ""estimator.py"", line 76, in main
    m.train(input_fn=make_input_fn(""tiny.txt""), steps = 100)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 709, in _train_model
    input_fn, model_fn_lib.ModeKeys.TRAIN)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 577, in _get_features_and_l
abels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py"", line 663, in _call_input_fn
    return input_fn(**kwargs)
  File ""estimator.py"", line 44, in _fn
    team_0s = tf.constant(list(map(lambda r: sparse_team(r.team_0), records)))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py"", line 472, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type &lt;class 'list'&gt; to Tensor. Contents: [&lt;tensorflow.python.framework.sparse_tenso
r.SparseTensor object at 0x7fe8b4d7aef0&gt;, &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe8b4d7af28
&gt;, &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fe8b4d7af60&gt;, &lt;tensorflow.python.framework.sparse_
tensor.SparseTensor object at 0x7fe8b4d7aeb8&gt; ... ]
</code></pre>
","To get started with TF, I wanted to learn a predictor of match outcomes for a game. There are three features: the 5 heros on team 0, the 5 heroes on team 1, and the map. The winner is the label, 0 or 1. I want to represent the teams and the maps as SparseTensors. Out of a possible 71 heroes, five will be selected. Likewise for maps, out of a possible 13, one will be selected. This fails on team_0s = tf.constant(list(map(lambda r: sparse_team(r.team_0), records))) It's very difficult to understand what tf wants me to return in my input_fn, because all of the examples I can find in the docs ultimately call out to a pandas or numpy helper function, and I'm not familiar with those frameworks. I thought that each dictionary value should be a Tensor containing all examples of a single feature. Each of my examples is a SparseTensor, and I want to simply embed them as their dense versions for the sake of the DNNClassifier. I'm sure my mental model is horribly broken right now, and I appreciate any help setting it straight. Error output:",https://stackoverflow.com/questions/46752071,86432,Inadequate Examples,Inadequate Examples,"It's very difficult to understand what tf wants me to return in my input_fn, because all of the examples I can find in the docs ultimately call out to a pandas or numpy helper function, and I'm not familiar with those frameworks."
46885191,tf.nn.conv2d_transpose output_shape dynamic batch_size,"<p>The documentation of tf.nn.conv2d_transpose says:</p>

<pre><code>tf.nn.conv2d_transpose(
    value,
    filter,
    output_shape,
    strides,
    padding='SAME',
    data_format='NHWC',
    name=None
)
</code></pre>

<p>The output_shape argument requires a 1D tensor specifying the shape of the tensor output by this op. Here, since my conv-net part has been built entirely on dynamic batch_length placeholders, I can't seem to device a workaround to the static <code>batch_size</code> requirement of the output_shape for this op. </p>

<p>There are many discussions around the web for this, however, I couldn't find any solid solution to this issue. Most of them are hacky ones with a <code>global_batch_size</code> variable defined. I wish to know the best possible solution to this problem. This trained model is going be shipped as a deployed service.</p>
","The documentation of tf.nn.conv2d_transpose says: The output_shape argument requires a 1D tensor specifying the shape of the tensor output by this op. Here, since my conv-net part has been built entirely on dynamic batch_length placeholders, I can't seem to device a workaround to the static batch_size requirement of the output_shape for this op. There are many discussions around the web for this, however, I couldn't find any solid solution to this issue. Most of them are hacky ones with a global_batch_size variable defined. I wish to know the best possible solution to this problem. This trained model is going be shipped as a deployed service.",https://stackoverflow.com/questions/46885191,4341842,Inadequate Examples,Inadequate Examples,I couldn't find any solid solution to this issue.
48427269,What's the efficient way to feed elements from Iterator (from tf.data.Dataset) into TensorFlow model?,"<p>I'm using TensrFlow's new API for importing data via <code>tf.data.Dataset</code> and iterators. It is working fine, but I'm not sure if what I do is efficient. </p>

<p>What I'm doing at the moment is evaluating an iterator's <code>get_next()</code> method, which gives me a bunch of elements like the actual image, its label, filename, etc. I then feed the image into my model using the <code>feed_dict</code>. </p>

<p>I know that <code>feed_dict</code> is very slow, so am I losing benefits of <code>Dataset</code> and Iterators and having serialised dataset in <code>TFRecord</code>s by evaluating the entries and feeding them into the graph via <code>feed_dict</code>? I haven't found any examples in TF's documentation which shows how one's expected to use Iterator's <code>get_next()</code> to feed elements into the model. Is it better to unpack <code>get_next()</code> and use the result directly in my graph? </p>
","I'm using TensrFlow's new API for importing data via tf.data.Dataset and iterators. It is working fine, but I'm not sure if what I do is efficient. What I'm doing at the moment is evaluating an iterator's get_next() method, which gives me a bunch of elements like the actual image, its label, filename, etc. I then feed the image into my model using the feed_dict. I know that feed_dict is very slow, so am I losing benefits of Dataset and Iterators and having serialised dataset in TFRecords by evaluating the entries and feeding them into the graph via feed_dict? I haven't found any examples in TF's documentation which shows how one's expected to use Iterator's get_next() to feed elements into the model. Is it better to unpack get_next() and use the result directly in my graph?",https://stackoverflow.com/questions/48427269,298209,Inadequate Examples,Inadequate Examples,I haven't found any examples in TF's documentation which shows how one's expected to use Iterator's get_next() to feed elements into the model.
51859776,lambda layer function definition without tf.keras.backend (Python Keras Package),"<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda"" rel=""nofollow noreferrer"">tf.keras.layers.Lambda</a> documentation explains how a function can be defined in a lambda layer. That document provides the following function as an example,</p>

<pre><code>def antirectifier(x):

    x -= K.mean(x, axis=1, keepdims=True)
    x = K.l2_normalize(x, axis=1)

    pos = K.relu(x)
    neg = K.relu(-x)

    return K.concatenate([pos, neg], axis=1)

model.add(Lambda(antirectifier))
</code></pre>

<p>But according to that, <code>tf.keras.backend</code> must be used to conduct operations on the input Tensor object.</p>

<p>Is there any way we can use default python packages and user-defined function to define the steps of a lambda function.</p>

<p>If it's possible, please be kind enough to provide some examples.</p>
","tf.keras.layers.Lambda documentation explains how a function can be defined in a lambda layer. That document provides the following function as an example, But according to that, tf.keras.backend must be used to conduct operations on the input Tensor object. Is there any way we can use default python packages and user-defined function to define the steps of a lambda function. If it's possible, please be kind enough to provide some examples.",https://stackoverflow.com/questions/51859776,261433,Inadequate Examples,Inadequate Examples,"That document provides the following function as an example, But according to that, tf.keras.backend must be used to conduct operations on the input Tensor object. Is there any way we can use default python packages and user-defined function to define the steps of a lambda function. If it's possible, please be kind enough to provide some examples."
54897832,Feeding large numpy arrays into TensorFlow estimators via tf.data.Dataset,"<p>TensorFlow's <a href=""https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code> documentation on consuming numpy arrays</a> states that in order to use numpy arrays in combination with the <code>Dataset</code> API, the arrays have to be small enough (&lt;2 GB in total) to be used as tensors, or they can be fed into the dataset via placeholders.</p>

<p>However, if you use <code>Dataset</code> in conjunction with estimators (where placeholders are not available), the documentation does not provide a solution on working with large arrays without placeholders. </p>

<p>Are there other options for passing placeholder values into estimators that can be used or is the solution to provide the data in <code>tfrecord</code> or <code>csv</code> format?</p>
","TensorFlow's tf.data.Dataset documentation on consuming numpy arrays states that in order to use numpy arrays in combination with the Dataset API, the arrays have to be small enough (&lt;2 GB in total) to be used as tensors, or they can be fed into the dataset via placeholders. However, if you use Dataset in conjunction with estimators (where placeholders are not available), the documentation does not provide a solution on working with large arrays without placeholders. Are there other options for passing placeholder values into estimators that can be used or is the solution to provide the data in tfrecord or csv format?",https://stackoverflow.com/questions/54897832,4443082,Inadequate Examples,Inadequate Examples,"However, if you use Dataset in conjunction with estimators (where placeholders are not available), the documentation does not provide a solution on working with large arrays without placeholders. "
57134808,tf.keras.optimizers.Adam with tf.estimator model in Tensorflow 2.0.beta is crashing,"<p>I am using <code>Tensorflow 2.0.beta</code> with <code>Python 3.6.6</code> on <code>Mac OS</code> (nightly: <code>tf-nightly-2.0-preview</code> <code>2.0.0.dev20190721</code> but I never managed to have it working with compat module in <code>Tensorflow 2.0</code>).</p>

<p>I am traying to migrate a <code>tf.estimator</code> model from <code>Tensorflow 1.12</code> (fully working) to <code>Tensorflow 2.0</code>. Here is the code:</p>

<pre><code># estimator model
def baseline_estimator_model(features, labels, mode, params):
    """"""
    Model function for Estimator
    """"""
    print('model based on keras layer but return an estimator model')

    # gettings the bulding blocks
    model = keras_building_blocks(params['dim_input'], params['num_classes'])

    dense_inpout = features['dense_input']

    # Logits layer
    if mode == tf.estimator.ModeKeys.TRAIN:
        logits = model(dense_inpout, training=True)
    else:
        logits = model(dense_inpout, training=False)


    # Compute predictions
    probabilities = tf.nn.softmax(logits)
    classes = tf.argmax(input=probabilities, axis=1, )

    # made prediction
    predictions = {
        'classes': classes,
        'probabilities': probabilities,
    }

    # to be tested
    predictions_output = tf.estimator.export.PredictOutput(predictions)

    # Provide an estimator spec for `ModeKeys.PREDICT`
    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode,
                                          predictions=predictions,
                                          export_outputs={tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: predictions_output})

    # Compute loss for both TRAIN and EVAL modes
    # old -&gt; loss = tf.compat.v1.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)
    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, logits)

    # Generate necessary evaluation metrics
    # old -&gt; accuracy = tf.compat.v1.metrics.accuracy(labels=tf.argmax(input=labels, axis=1), predictions=classes, name='accuracy')
    accuracy = tf.keras.metrics.CategoricalAccuracy()
    accuracy.update_state(labels, logits)

    eval_metrics = {'accuracy': accuracy}

    tf.summary.scalar('accuracy', accuracy.result())

    # Provide an estimator spec for `ModeKeys.EVAL`
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          eval_metric_ops=eval_metrics)

    # Provide an estimator spec for `ModeKeys.TRAIN`
    if mode == tf.estimator.ModeKeys.TRAIN:

        # old but working -&gt; optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta1=0.9)
        # crashing
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, epsilon=1e-07)

        # old -&gt; train_op = optimizer.minimize(loss, tf.compat.v1.train.get_or_create_global_step())
        train_op = optimizer.minimize(loss,var_list=model.weights)

        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          train_op=train_op)
</code></pre>

<p>predictions=predictions, loss=loss, train_op=train_op, export_outputs=predictions_output)</p>

<p>If I keep the compat.v1 module it is working:</p>

<pre><code>optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta1=0.9)
</code></pre>

<p>If I try to use something without compat.v1 it is crashing:</p>

<pre><code>optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9,epsilon=1e-07)
</code></pre>

<p>with the following error (I am running the code locally for the moment, not on <code>GCP</code>):</p>

<pre><code>I0721 17:33:04.812453 4526515648 estimator.py:209] Using config: {'_model_dir': 'results/Models/Mnist/tf_1_12/estimator/v3/ckpt/', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x1c37b11b70&gt;, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0721 17:33:04.815697 4526515648 estimator_training.py:186] Not using Distribute Coordinator.
I0721 17:33:04.817899 4526515648 training.py:612] Running training and evaluation locally (non-distributed).
I0721 17:33:04.818665 4526515648 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10 or save_checkpoints_secs None.
I0721 17:33:04.834385 4526515648 model.py:211] input_dataset_fn: TRAIN, train

using keras layer and estimator (recommended way)
exporter &lt;tensorflow_estimator.python.estimator.exporter.LatestExporter object at 0x1c37b115f8&gt;

I0721 17:33:05.117963 4526515648 estimator.py:1145] Calling model_fn.

model based on keras layer but return an estimator model

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;timed exec&gt; in &lt;module&gt;

~/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/src/model_mnist_2_0_v1/trainer/model.py in train_and_evaluate(FLAGS, use_keras)
    589                                       exporters=exporter)
    590 
--&gt; 591     tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
    592 
    593 def train_and_evaluate_old(FLAGS, use_keras):

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    471         '(with task id 0).  Given task id {}'.format(config.task_id))
    472 
--&gt; 473   return executor.run()
    474 
    475 

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in run(self)
    611         config.task_type != run_config_lib.TaskType.EVALUATOR):
    612       logging.info('Running training and evaluation locally (non-distributed).')
--&gt; 613       return self.run_local()
    614 
    615     # Distributed case.

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py in run_local(self)
    712         max_steps=self._train_spec.max_steps,
    713         hooks=train_hooks,
--&gt; 714         saving_listeners=saving_listeners)
    715 
    716     eval_result = listener_for_eval.eval_result or _EvalResult(

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    365 
    366       saving_listeners = _check_listeners_type(saving_listeners)
--&gt; 367       loss = self._train_model(input_fn, hooks, saving_listeners)
    368       logging.info('Loss for final step: %s.', loss)
    369       return self

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1156       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1157     else:
-&gt; 1158       return self._train_model_default(input_fn, hooks, saving_listeners)
   1159 
   1160   def _train_model_default(self, input_fn, hooks, saving_listeners):

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
   1186       worker_hooks.extend(input_hooks)
   1187       estimator_spec = self._call_model_fn(
-&gt; 1188           features, labels, ModeKeys.TRAIN, self.config)
   1189       global_step_tensor = training_util.get_global_step(g)
   1190       return self._train_with_estimator_spec(estimator_spec, worker_hooks,

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
   1144 
   1145     logging.info('Calling model_fn.')
-&gt; 1146     model_fn_results = self._model_fn(features=features, **kwargs)
   1147     logging.info('Done calling model_fn.')
   1148 

~/Desktop/Work/Data_Science/Tutorials_Codes/Python/proj_DL_models_and_pipelines_with_GCP/src/model_mnist_2_0_v1/trainer/model.py in baseline_estimator_model(features, labels, mode, params)
    442         #train_op = optimizer.minimize(loss, tf.compat.v1.train.get_or_create_global_step())
    443         #train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())
--&gt; 444         train_op = optimizer.minimize(loss,var_list=model.weights)
    445 
    446         print('step 8')

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in minimize(self, loss, var_list, grad_loss, name)
    315     """"""
    316     grads_and_vars = self._compute_gradients(
--&gt; 317         loss, var_list=var_list, grad_loss=grad_loss)
    318 
    319     return self.apply_gradients(grads_and_vars, name=name)

~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in _compute_gradients(self, loss, var_list, grad_loss)
    349       if not callable(var_list):
    350         tape.watch(var_list)
--&gt; 351       loss_value = loss()
    352     if callable(var_list):
    353       var_list = var_list()

TypeError: 'Tensor' object is not callable
</code></pre>

<p>Any idea how to fix that ? The error messages was changing over time since <code>Tensorflow 2.0 alpha</code>.</p>

<p>I am also looking for a full working example of tf.estimator working with <code>Tensorflow 2.0</code>. I have issue to export the model as well. In the official documentation of <code>Tensorflow 2.0</code> they only use in their example <code>compat.v1</code> and don't export the model. All the online course on tf.estimator from GCP are using  older version of Tensorflow (1.12 - 1.14).</p>
","I am using Tensorflow 2.0.beta with Python 3.6.6 on Mac OS (nightly: tf-nightly-2.0-preview 2.0.0.dev20190721 but I never managed to have it working with compat module in Tensorflow 2.0). I am traying to migrate a tf.estimator model from Tensorflow 1.12 (fully working) to Tensorflow 2.0. Here is the code: predictions=predictions, loss=loss, train_op=train_op, export_outputs=predictions_output) If I keep the compat.v1 module it is working: If I try to use something without compat.v1 it is crashing: with the following error (I am running the code locally for the moment, not on GCP): Any idea how to fix that ? The error messages was changing over time since Tensorflow 2.0 alpha. I am also looking for a full working example of tf.estimator working with Tensorflow 2.0. I have issue to export the model as well. In the official documentation of Tensorflow 2.0 they only use in their example compat.v1 and don't export the model. All the online course on tf.estimator from GCP are using older version of Tensorflow (1.12 - 1.14).",https://stackoverflow.com/questions/57134808,6430839,Inadequate Examples,Inadequate Examples,I am also looking for a full working example of tf.estimator working with Tensorflow 2.0. I have issue to export the model as well. In the official documentation of Tensorflow 2.0 they only use in their example compat.v1 and don't export the model.
58096095,How does tf.audio.decode_wav get its contents?,"<p>I'm trying to pull some audio files into Tensorflow by using <code>tf.audio.decode_wav</code>.</p>

<p>I can see someone is looking into providing more info in the docs, but does anyone have any examples of how this should work?</p>

<pre><code>tf.audio.decode_wav(
 contents,
 desired_channels=-1,
 desired_samples=-1,
 name=None
)
</code></pre>

<p><strong>Args:</strong></p>

<ul>
<li>contents: A Tensor of type string. The WAV-encoded audio, usually from a file.</li>
<li>desired_channels: An optional int. Defaults to -1. Number of sample channels wanted.</li>
<li>desired_samples: An optional int. Defaults to -1. Length of audio requested.</li>
<li>name: A name for the operation (optional).</li>
</ul>

<p>I'm guessing the contents is a tensor which has already been pulled from a file rather than a path?</p>
","I'm trying to pull some audio files into Tensorflow by using tf.audio.decode_wav. I can see someone is looking into providing more info in the docs, but does anyone have any examples of how this should work? Args: I'm guessing the contents is a tensor which has already been pulled from a file rather than a path?",https://stackoverflow.com/questions/58096095,12118244,Inadequate Examples,Inadequate Examples,"I can see someone is looking into providing more info in the docs, but does anyone have any examples of how this should work?"
58112355,"What, exactly, is eager execution from a programming point of view?","<p>I am trying to understand eager execution. Pages returned by Google describe what it does for you, and I'm ok with that. I am trying to understand it from the point of view of program code. Here is an example from <a href=""https://towardsdatascience.com/eager-execution-tensorflow-8042128ca7be"" rel=""nofollow noreferrer"">this article</a>.</p>

<pre><code>a = tf.constant([[1,2],[3,4]])
</code></pre>

<p>The article says this statement does something different depending on whether you are in eager mode or not. Without eager mode, print(a) gives:</p>

<pre><code>Tensor(""Const:0"", shape=(2, 2), dtype=int32)
</code></pre>

<p>With eager mode, print(a) gives:</p>

<pre><code>tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32)
</code></pre>

<p>Please could someone explain what these two return values are. If they are two different object types, a Tensor and a tf.Tensor, what is the difference between these objects?</p>

<p>I have searched the TensorFlow documentation and can't see anything that addresses this distinction. Any pointers gratefully received.</p>

<p>Thanks,</p>

<p>Julian</p>
","I am trying to understand eager execution. Pages returned by Google describe what it does for you, and I'm ok with that. I am trying to understand it from the point of view of program code. Here is an example from this article. The article says this statement does something different depending on whether you are in eager mode or not. Without eager mode, print(a) gives: With eager mode, print(a) gives: Please could someone explain what these two return values are. If they are two different object types, a Tensor and a tf.Tensor, what is the difference between these objects? I have searched the TensorFlow documentation and can't see anything that addresses this distinction. Any pointers gratefully received. Thanks, Julian",https://stackoverflow.com/questions/58112355,6691564,Inadequate Examples,Inadequate Examples,I have searched the TensorFlow documentation and can't see anything that addresses this distinction.
60311184,how to loop over a tensor object until a condition met,"<p>I have a tensor like this:</p>

<pre><code>masked_bad_col = [[False  True  True False  True  True  True  True  True  True  True False]]
</code></pre>

<p>I want to loop through this tensor untill all elements get <code>True</code>.
So I have another function, which will update this tensor, lets call it <code>uniqueness</code>.</p>

<pre><code>def uniqueness():

   'blah blah blha'
   return tensor1, updated_masked_bad_col
</code></pre>

<p>I looked at the documentation and got to know that I can do that using <code>tf.while_loop</code>. Although, I could not find any example working on boolean stuff.
This is what I have done so far:</p>

<pre><code>tensor1, _ = tf.while_loop(masked_bad_col != True, uniqueness)
</code></pre>

<p>It is obviously incorrect, but don't know how to use each element of <code>masked_bad_col</code> as a condition to continue looping through <code>uniqueness</code> function.</p>

<p><strong>Update 1</strong>
This is the method I am trying to call in the loop:</p>

<pre><code>corpus = load_corpus('path_to_corpus/train.corpus')
topics = []
vocab, docs = corpus['vocab'], corpus['docs']
number_of_topics = 0
encoder_model = load_keras_model(
    'path_to_model/encoder_model',
    custom_objects={""KCompetitive"": KCompetitive})
weights = encoder_model.get_weights()[0]
for idx in range(encoder_model.output_shape[1]):
    token_idx = np.argsort(weights[:, idx])[::-1][:20]
    topics.append([(revdict(vocab)[x]) for x in token_idx])
    number_of_topics += 1

nparr = np.asarray(topics)
# print nparr.shape

unique, indices, count = np.unique(nparr, return_inverse=True, return_counts=True)

tensor1 = (np.sum(count[indices].reshape(nparr.shape), axis=1).reshape(1, nparr.shape[0]) / (
        number_of_topics * 20))

def uniqueness_score():
    corpus = load_corpus('path_to_corpus/train.corpus')
    topics = []
    vocab, docs = corpus['vocab'], corpus['docs']
    number_of_topics = 0
    encoder_model = load_keras_model(
        'path_to_model/encoder_model',
        custom_objects={""KCompetitive"": KCompetitive})
    weights = encoder_model.get_weights()[0]
    for idx in range(encoder_model.output_shape[1]):
        token_idx = np.argsort(weights[:, idx])[::-1][:20]
        topics.append([(revdict(vocab)[x]) for x in token_idx])
        number_of_topics += 1

    nparr = np.asarray(topics)

    unique, indices, count = np.unique(nparr, return_inverse=True, return_counts=True)

    tensor1 = (np.sum(count[indices].reshape(nparr.shape), axis=1).reshape(1, nparr.shape[0]) / (
            number_of_topics * 20))
    return tensor1
</code></pre>

<p>And this is the way I called this method in the <code>while_loop</code></p>

<pre><code>with tf.Session() as sess:

        tensor2, _ = tf.while_loop(
            # Loop condition (negated goal condition)
            lambda tensor1: ~tf.math.reduce_all(tensor1 &gt; tf.reduce_mean(tensor1)),
            # Loop body
            lambda tensor1: uniqueness_score(),
            # Loop variables
            [tensor1])
        # Returned loop value
        print(tensor2.eval())
</code></pre>
","I have a tensor like this: I want to loop through this tensor untill all elements get True. So I have another function, which will update this tensor, lets call it uniqueness. I looked at the documentation and got to know that I can do that using tf.while_loop. Although, I could not find any example working on boolean stuff. This is what I have done so far: It is obviously incorrect, but don't know how to use each element of masked_bad_col as a condition to continue looping through uniqueness function. Update 1 This is the method I am trying to call in the loop: And this is the way I called this method in the while_loop",https://stackoverflow.com/questions/60311184,7934786,Inadequate Examples,Inadequate Examples,"I looked at the documentation and got to know that I can do that using tf.while_loop. Although, I could not find any example working on boolean stuff."
61522019,Is it still necessary to implement `compute_output_shape()` when defining a custom tf.keras Layer?,"<p>I have implemented a custom <code>Layer</code> in <code>tf.keras</code>, using TensorFlow 2.1.0.</p>

<p>In the past, when using the stand-alone Keras, it was important to define the <code>compute_output_shape(input_shape)</code> method in any custom layer so that the computational graph could be created. </p>

<p>Now, having moved to TF2, I found out that even if I remove that method from my custom implementation the layer still works as expected. Apparently, it works both in eager and graph mode.
This is an example of what I mean: </p>

<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras.layers import Layer, Input
from tensorflow.keras.models import Sequential
import numpy as np


class MyLayer(Layer):
    def call(self, inputs):
        return inputs[:, :-1]  # Do something that changes the shape


m = Sequential([MyLayer(), MyLayer()])
m.predict(np.ones((10, 3)))  # This would not have worked in the past
</code></pre>

<p>Is it safe to say that <code>compute_output_shape()</code> is not necessary anymore? Am I missing something important?</p>

<p>In the documentation there's no explicit mention of removing <code>compute_output_shape()</code>, although none of the examples implements it explicitly. </p>

<p>Thanks</p>
","I have implemented a custom Layer in tf.keras, using TensorFlow 2.1.0. In the past, when using the stand-alone Keras, it was important to define the compute_output_shape(input_shape) method in any custom layer so that the computational graph could be created. Now, having moved to TF2, I found out that even if I remove that method from my custom implementation the layer still works as expected. Apparently, it works both in eager and graph mode. This is an example of what I mean: Is it safe to say that compute_output_shape() is not necessary anymore? Am I missing something important? In the documentation there's no explicit mention of removing compute_output_shape(), although none of the examples implements it explicitly. Thanks",https://stackoverflow.com/questions/61522019,5499527,Inadequate Examples,Inadequate Examples,"In the documentation there's no explicit mention of removing compute_output_shape(), although none of the examples implements it explicitly."
64119612,Join ragged character tensor,"<p>I have a ragged tensor of characters (copy/pastable code to reproduce):</p>
<pre class=""lang-py prettyprint-override""><code>flat_values = [
    b'7', b'2', b'1', b'0', b'4', b'1', b'4', b'5', b'0', b'6', b'0',
    b'1', b'5', b'7', b'8', b'4', b'6', b'6', b'5', b'4', b'0', b'7',
    b'4', b'0', b'1', b'3', b'1', b'3', b'4', b'7', b'2', b'7', b'1',
    b'2', b'1', b'1', b'7', b'4', b'2', b'3', b'5', b'1', b'2', b'4',
    b'4', b'6', b'3', b'5', b'5', b'6', b'0', b'4', b'1', b'5', b'7',
    b'8', b'3', b'7', b'4', b'6', b'4', b'3', b'0', b'7', b'0', b'2',
    b'1', b'7', b'3', b'2', b'7', b'7', b'6', b'2', b'7', b'8', b'4',
    b'7', b'3', b'6', b'1', b'3', b'6', b'3', b'1', b'4', b'1', b'7',
    b'6', b'6', b'0', b'5', b'4', b'2', b'1', b'4', b'8', b'7', b'3',
    b'7', b'4', b'4', b'2', b'5', b'4', b'7', b'6', b'7', b'0', b'5',
    b'8', b'5', b'6', b'6', b'5', b'7', b'8', b'1', b'0', b'1', b'6',
    b'4', b'6', b'7', b'3', b'1', b'7', b'1', b'8', b'2', b'0', b'2',
]

row_lengths = [
    6, 4, 4, 5, 6, 6, 6, 6, 6, 5, 5, 6,
    5, 5, 6, 5, 5, 4, 4, 4, 5, 6, 6, 6, 6,
]

x = tf.RaggedTensor.from_nested_row_lengths(
    flat_values,
    (row_lengths,),
)
</code></pre>
<p>I want to join the rows as strings, but I would like to do it in the graph. I can accomplish this by evaluating the tensor:</p>
<pre><code>&gt;&gt;&gt; [''.join([c.decode() for c in i]) for i in x.to_list()]
['721041',
 '4506',
 '0157',
 '84665',
 '407401',
 '313472',
 '712117',
 '423512',
 '446355',
 '60415',
 '78374',
 '643070',
 '21732',
 '77627',
 '847361',
 '36314',
 '17660',
 '5421',
 '4873',
 '7442',
 '54767',
 '058566',
 '578101',
 '646731',
 '718202']
</code></pre>
<p>But as this is the output of my network (trained in graph mode) I would like to be able to express this operation in tensorflow so that it can be evaluated in validation steps. Two things I've tried that do not work:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; tf.strings.join(x)
InvalidArgumentError: Input shapes do not match: [6] vs. [4] [Op:StringJoin]

&gt;&gt;&gt; tf.ragged.map_flat_values(tf.strings.join, x)
ValueError: Shape () must have rank at least 1
</code></pre>
<p>Frustratingly, the <a href=""https://tensorflow.google.cn/api_docs/python/tf/strings/join#used-in-the-notebooks"" rel=""nofollow noreferrer"">documentation for <code>tf.strings.join</code></a> mentions ragged tensors but does not give an example of them. What am I missing? It seems there should be an obvious solution to this.</p>
","I have a ragged tensor of characters (copy/pastable code to reproduce): I want to join the rows as strings, but I would like to do it in the graph. I can accomplish this by evaluating the tensor: But as this is the output of my network (trained in graph mode) I would like to be able to express this operation in tensorflow so that it can be evaluated in validation steps. Two things I've tried that do not work: Frustratingly, the documentation for tf.strings.join mentions ragged tensors but does not give an example of them. What am I missing? It seems there should be an obvious solution to this.",https://stackoverflow.com/questions/64119612,3015734,Inadequate Examples,Inadequate Examples,"Frustratingly, the documentation for tf.strings.join mentions ragged tensors but does not give an example of them."
65779087,How to use tf.gradients within a model and still use a custom training loop?,"<p>I would like to make a TensorFlow model where the outputs respect a mathematical condition, namely that output 0 is a scalar function and all subsequent outputs are its partial derivatives w.r.t. the input. This is because my observations are the scalar function and its partials, and not using the partials for training would be a waste of information.</p>
<p>For now, using simply tf.gradients works if I don't build a custom training loop, i.e. when I don't utilize eager execution. The model is built like this, and training works as expected:</p>
<pre><code>import tensorflow as tf


from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras import callbacks

# Creating a model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Dense,
    Dropout,
    Flatten,
    Concatenate,
    Input,
    Lambda,
)

# Custom activation function
from tensorflow.keras.layers import Activation
from tensorflow.keras import backend as K

import numpy
import matplotlib.pyplot as plt

import tensorboard

layer_width = 200
dense_layer_number = 3

def lambda_gradient(args):
    layer = args[0]
    inputs = args[1]
    return tf.gradients(layer, inputs)[0]

# Input is a 2 dimensional vector
inputs = tf.keras.Input(shape=(2,), name=&quot;coordinate_input&quot;)

# Build `dense_layer_number` times a dense layers of width `layer_width`
stream = inputs
for i in range(dense_layer_number):
    stream = Dense(
        layer_width, activation=&quot;relu&quot;, name=f&quot;dense_layer_{i}&quot;
    )(stream)

# Build one dense layer that reduces the 200 nodes to a scalar output
scalar = Dense(1, name=&quot;network_to_scalar&quot;, activation=custom_activation)(stream)

# Take the gradient of the scalar w.r.t. the model input
gradient = Lambda(lambda_gradient, name=&quot;gradient_layer&quot;)([scalar, inputs])

# Combine them to form the model output
concat = Concatenate(name=&quot;concat_scalar_gradient&quot;)([scalar, gradient])

# Wrap everything in a model
model = tf.keras.Model(inputs=inputs, outputs=concat)

loss = &quot;MSE&quot;
optimizer = &quot;Adam&quot;

# And compile
model.compile(loss=loss, optimizer=optimizer)
</code></pre>
<p>However, them problem now comes when I want to do online training (i.e. with an incremental dataset). In this case, I wouldn't compile my model at the very end. Instead, I write a loop as such (before calling model.compile):</p>
<pre><code># ... continue from previous minus model.compile

loss_fn = tf.keras.losses.MeanSquaredError()
optimizer = tf.keras.optimizers.Adam()

# Iterate over the batches of a dataset and train.
for i_batch in range(number_of_batches):

    with tf.GradientTape() as tape:
        # Predict w.r.t. the inputs X
        prediction_Y = model(batches_X[i_batch])
        
        # Compare batch prediction to batch observation
        loss_value = loss_fn(batches_Y[i_batch], prediction_Y)

    gradients = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(gradients, model.trainable_weights))
</code></pre>
<p>This however gives the following exception at <code>prediction_Y = model(batches_X[i_batch])</code>:</p>
<pre><code>RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
</code></pre>
<p>As most examples, tutorials and documentation solely deal with using gradients to do training, and not within the model, I can't find any good resources how to deal with this. I tried to find how to use gradient tape, but I can't figure out how to use it in the model design phase. Any pointers would be appreciated!</p>
<p>Versions used:</p>
<pre><code>$ python --version                                         
Python 3.8.5
$ python -c &quot;import tensorflow as tf;print(tf.__version__);print(tf.keras.__version__)&quot;
2.2.0
2.3.0-tf
</code></pre>
","I would like to make a TensorFlow model where the outputs respect a mathematical condition, namely that output 0 is a scalar function and all subsequent outputs are its partial derivatives w.r.t. the input. This is because my observations are the scalar function and its partials, and not using the partials for training would be a waste of information. For now, using simply tf.gradients works if I don't build a custom training loop, i.e. when I don't utilize eager execution. The model is built like this, and training works as expected: However, them problem now comes when I want to do online training (i.e. with an incremental dataset). In this case, I wouldn't compile my model at the very end. Instead, I write a loop as such (before calling model.compile): This however gives the following exception at prediction_Y = model(batches_X[i_batch]): As most examples, tutorials and documentation solely deal with using gradients to do training, and not within the model, I can't find any good resources how to deal with this. I tried to find how to use gradient tape, but I can't figure out how to use it in the model design phase. Any pointers would be appreciated! Versions used:",https://stackoverflow.com/questions/65779087,6848887,Inadequate Examples,Inadequate Examples,"As most examples, tutorials and documentation solely deal with using gradients to do training, and not within the model, I can't find any good resources how to deal with this."
65794527,"Example of output_signature , output_types & output_shapes for complex object called by tf.data.Dataset.from_generator","<p>I've a generator function that yields the following tuple: <code>yield (transformed_input_array, set_y)</code></p>
<p><em>transformed_input_array</em> is a list of ndarrays with the following shape: <em>(1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140)</em>  and the following types: <em>tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64</em>
<em>set_y</em> is a ndarray of shape <em>1024</em> and type of <em>int64</em></p>
<p>I've wrapped my generator with tf.data.Dataset.from_generator function, here is the code:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(
    generator,
    # output_signature=(
    #     tf.TensorSpec(shape=(), dtype=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64)),
    #     tf.TensorSpec(shape=1024, dtype=tf.int64))
    output_types=(tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64, tf.int64),
    output_shapes=((1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140), 1024)
)
</code></pre>
<p>But when I run the training, I get the following error:</p>
<blockquote>
<p>ValueError: Data is expected to be in format <code>x</code>, <code>(x,)</code>, <code>(x, y)</code>,
or <code>(x, y, sample_weight)</code>, found: (&lt;tf.Tensor 'IteratorGetNext:0'
shape=(1024, 104) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:1'
shape=(1024, 142) dtype=float64&gt;, &lt;tf.Tensor 'IteratorGetNext:2'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'It eratorGetNext:3'
shape=(1024, 1) dtype=int16&gt;, &lt;tf.Tensor 'IteratorGetNext:4'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:5'
shape=(1024, 1) dtype=int8&gt;, &lt;tf.Tensor 'IteratorGetNext:6'
shape=(1024, 140) dtype=float64&gt;, &lt;tf.Tensor 'ExpandDims:0'
shape=(1024, 1) dtype=int64&gt;)</p>
</blockquote>
<p>If I try to run with output_signature param (commented out code), I get the following error:</p>
<blockquote>
<p>TypeError: Cannot convert value (tf.float64, tf.float64, tf.int8,
tf.int16, tf.int8, tf.int8, tf.float64) to a TensorFlow DType.</p>
</blockquote>
<p><strong>Can someone provide an example, of how I should treat complex type (list of ndarrays)?</strong> Couldn't find any example in TF documentation..</p>
","I've a generator function that yields the following tuple: yield (transformed_input_array, set_y) transformed_input_array is a list of ndarrays with the following shape: (1024, 104), (1024, 142), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 140) and the following types: tf.float64, tf.float64, tf.int8, tf.int16, tf.int8, tf.int8, tf.float64 set_y is a ndarray of shape 1024 and type of int64 I've wrapped my generator with tf.data.Dataset.from_generator function, here is the code: But when I run the training, I get the following error: If I try to run with output_signature param (commented out code), I get the following error: Can someone provide an example, of how I should treat complex type (list of ndarrays)? Couldn't find any example in TF documentation..",https://stackoverflow.com/questions/65794527,336558,Inadequate Examples,Inadequate Examples,"Can someone provide an example, of how I should treat complex type (list of ndarrays)? Couldn't find any example in TF documentation."
66038861,Why are both branches in tf.cond being executed? And why does tf.while_loop finish the loop even though the condition still true?,"<p>I am using keras for a while now, but usually I don't have to use customized layers or perform some more complex flow control, so I'm struggling trying to understand somethings.</p>
<p>I am modeling a neural network with a customized layer on the top. This customized layer calls another function (<code>search_sigma</code>)  and inside this function I execute <code>tf.while_loop</code> and inside of <code>tf.while_loop</code> I execute <code>tf.cond</code>.</p>
<p>I cannot understand why the conditions are not working.</p>
<ul>
<li><code>tf.while_loop</code> stops even though the condition (<code>l1</code>) still true</li>
<li><code>tf.cond executes</code> both <code>f1</code> and <code>f2</code> (callables <code>true_fn</code> and <code>false_fn</code>)</li>
</ul>
<p>Could someone help me understand what I am missing?</p>
<p>I already tried to change both tf.cond and tf.while_loop conditions for true tensors, just to see what would happen. The behavior (exactly same errors) remained the same.</p>
<p>I also tried to write this code without implementing a class (using just functions). Nothing changed.</p>
<p>I tried to find solutions looking at tensorflow documentation, other stack overflow doubts and websites talking about tf.while_loop and tf.cond.</p>
<p>I left some <code>print()</code>s in the body of the code to try to track what was happening.</p>
<pre><code>class find_sigma:
    
    def __init__ (self, t_inputs,  inputs,  expected_perp=10. ):       
        self.sigma, self.cluster = t_inputs
        self.inputs = inputs
        self.expected_perp = expected_perp
        self.min_sigma=tf.constant([0.01],tf.float32)
        self.max_sigma=tf.constant([50.],tf.float32)
 

    def search_sigma(self):

        
        def cond(s,sigma_not_found): return sigma_not_found


        def body(s,sigma_not_found):   

            print('loop')
            pi = K.exp( - K.sum( (K.expand_dims(self.inputs, axis=1) - self.cluster)**2, axis=2  )/(2*s**2) )        
            pi = pi / K.sum(pi)
            MACHINE_EPSILON = np.finfo(np.double).eps
            pi = K.maximum(pi, MACHINE_EPSILON)
            H = - K.sum ( pi*(K.log(pi)/K.log(2.)) , axis=0 )
            perp = 2**H

            print('0')

            l1 = tf.logical_and (tf.less(perp , self.expected_perp), tf.less(0.01, self.max_sigma-s))
            l2 = tf.logical_and (tf.less(  self.expected_perp , perp) , tf.less(0.01, s-self.min_sigma) )
    
            def f1():
                print('f1')
                self.min_sigma = s 
                s2 = (s+self.max_sigma)/2 
                return  [s2, tf.constant([True])]
                

            def f2(l2): 
                tf.cond( l2, true_fn=f3 , false_fn = f4)

            def f3(): 
                print('f3')
                self.max_sigma = s 
                s2 = (s+self.min_sigma)/2
                return [s2, tf.constant([True])]

            def f4(): 
                print('f4')
                return [s, tf.constant([False])]
            
            output = tf.cond( l1, f1 ,  f4 ) #colocar f2 no lugar de f4

            s, sigma_not_found = output
            
            print('sigma_not_found = ',sigma_not_found)
            return [s,sigma_not_found]

        print('01')

        sigma_not_found = tf.constant([True])

        new_sigma,sigma_not_found=sigma_not_found = tf.while_loop(
            cond , body, loop_vars=[self.sigma,sigma_not_found]
        )

        print('saiu')
        
        print(new_sigma)

        return new_sigma
</code></pre>
<p>The piece of code that calls the above code is:</p>
<pre><code>self.sigma = tf.map_fn(fn=lambda t: find_sigma(t,  inputs).search_sigma() , elems=(self.sigma,self.clusters), dtype=tf.float32)
</code></pre>
<p>'inputs' is a <code>(None, 10)</code> size tensor</p>
<p>'self.sigma' is a <code>(10,)</code> size tensor</p>
<p>'self.clusters' is a <code>(N, 10)</code> size tensor</p>
","I am using keras for a while now, but usually I don't have to use customized layers or perform some more complex flow control, so I'm struggling trying to understand somethings. I am modeling a neural network with a customized layer on the top. This customized layer calls another function (search_sigma) and inside this function I execute tf.while_loop and inside of tf.while_loop I execute tf.cond. I cannot understand why the conditions are not working. Could someone help me understand what I am missing? I already tried to change both tf.cond and tf.while_loop conditions for true tensors, just to see what would happen. The behavior (exactly same errors) remained the same. I also tried to write this code without implementing a class (using just functions). Nothing changed. I tried to find solutions looking at tensorflow documentation, other stack overflow doubts and websites talking about tf.while_loop and tf.cond. I left some print()s in the body of the code to try to track what was happening. The piece of code that calls the above code is: 'inputs' is a (None, 10) size tensor 'self.sigma' is a (10,) size tensor 'self.clusters' is a (N, 10) size tensor",https://stackoverflow.com/questions/66038861,15141021,Inadequate Examples,Inadequate Examples,"I tried to find solutions looking at tensorflow documentation, other stack overflow doubts and websites talking about tf.while_loop and tf.cond."
71130645,Correct axes to use dot product to evaluate the final output of a listwise learning to rank model,"<p>I'm not being able to find the correct configuration to pass to a tf.keras.layers.Dot to make a pairwise dot product when the entries each have lists of values, like from a listwise learning to rank model. For instance, suppose:</p>
<pre><code>repeated_query_vector = [
  [[1, 2], [1, 2]],
  [[3, 4], [3, 4]]
]

document_vectors = [
  [[5, 6], [7, 8]],
  [[9, 10], [11, 12]],
]
</code></pre>
<p>Calling tf.keras.layers.Dot(axes=??)([repeated_query_vector, document_vectors]) I want the output to be like:</p>
<pre><code>[
  [1*5 + 2*6, 1*7 + 2*8]
  [3*9 + 4*10, 3*11 + 4*12]
]
</code></pre>
<p>All examples I found in the documentation have one dimension less than my use case. What would be the correct value of axes for this call?</p>
","I'm not being able to find the correct configuration to pass to a tf.keras.layers.Dot to make a pairwise dot product when the entries each have lists of values, like from a listwise learning to rank model. For instance, suppose: Calling tf.keras.layers.Dot(axes=??)([repeated_query_vector, document_vectors]) I want the output to be like: All examples I found in the documentation have one dimension less than my use case. What would be the correct value of axes for this call?",https://stackoverflow.com/questions/71130645,13262684,Inadequate Examples,Inadequate Examples,All examples I found in the documentation have one dimension less than my use case.
44357675,Documentation on how to use tf.estimator in TensorFlow,"<p>I understand that we can write custom models and encapsulate it using tf.estimator. But I just can't seem to find any documentation with an example.</p>

<p>I know that you have to define your model inside a 'model_fn' but what exactly should I return from this function. Also am I supposed to put the the loss and the training step within the 'model_fn' or just the network.  How should I modify the code give below to make it work with tf.estimator. Would really appreciate some help.</p>

<pre><code>def test_model(features,labels):
    X = tf.placeholder(tf.float32,shape=(None,1),name=""Data_Input"")
    #Output
    Y = tf.placeholder(tf.float32,shape=(None,1),name=""Target_Labels"")
    W =  tf.Variable(tf.random_normal([0],stddev=stddev0)) 
    b = tf.Variable(tf.random_normal([0],stddev=stddev0))

    Ypredict = W*X + b
    return Ypredict

 estimator = tf.estimator.Estimator(model_fn = test_model)
</code></pre>
",I understand that we can write custom models and encapsulate it using tf.estimator. But I just can't seem to find any documentation with an example. I know that you have to define your model inside a 'model_fn' but what exactly should I return from this function. Also am I supposed to put the the loss and the training step within the 'model_fn' or just the network. How should I modify the code give below to make it work with tf.estimator. Would really appreciate some help.,https://stackoverflow.com/questions/44357675,7656080,Documentation Replicability,Inadequate Examples,But I just can't seem to find any documentation with an example.
49868782,How to use tf.argmax,"<p>I want to test the function of tf.argmax(),but when I run the code , I encountered an error. Here is my code</p>
<pre><code>import tensorflow as tf
 
a=tf.argmax([1,0,0],1)
with tf.Session() as sess:
    print(sess.run(a))
</code></pre>
<p>My environment is python3 + tf1.3.</p>
<p>What's wrong with the code?</p>
","I want to test the function of tf.argmax(),but when I run the code , I encountered an error. Here is my code My environment is python3 + tf1.3. What's wrong with the code?",https://stackoverflow.com/questions/49868782,9639109,Documentation Replication on Other Examples,Documentation Replication on Other Examples,
50017241,Converting grayscale to RGB in tfrecord,"<p>I have a dataset of grayscale images, and I'd like to use the sdd-mobilenet checkpoints for training my object detection.
What is the proper way to convert grayscale images to RGB that I can convert my dataset to tfrecord?
Here is the code that I use (notice that the commented parts didn't work for me)</p>

<pre><code>with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
    encoded_jpg = fid.read()
# rgb_image = tf.image.grayscale_to_rgb(
#     tf.image.encode_jpeg(encoded_jpg),
#     name=None
# )
encoded_jpg_io = io.BytesIO(encoded_jpg)
encoded_jpg_io = tf.stack([encoded_jpg_io, encoded_jpg_io, encoded_jpg_io], axis=-1)
image = Image.open(encoded_jpg_io)
width, height = image.size

filename = group.filename.encode('utf8')
image_format = b'jpg'
xmins = []
xmaxs = []
ymins = []
ymaxs = []
classes_text = []
classes = []

for index, row in group.object.iterrows():
    xmins.append(row['xmin'] / width)
    xmaxs.append(row['xmax'] / width)
    ymins.append(row['ymin'] / height)
    ymaxs.append(row['ymax'] / height)
    classes_text.append(row['class'].encode('utf8'))
    classes.append(class_text_to_int(row['class']))

tf_example = tf.train.Example(features=tf.train.Features(feature={
    'image/height': dataset_util.int64_feature(height),
    'image/width': dataset_util.int64_feature(width),
    'image/filename': dataset_util.bytes_feature(filename),
    'image/source_id': dataset_util.bytes_feature(filename),
    # 'image/channels': dataset_util.int64_feature(),
    'image/encoded': dataset_util.bytes_feature(encoded_jpg),
    'image/format': dataset_util.bytes_feature(image_format),
    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
    'image/object/class/label': dataset_util.int64_list_feature(classes),
}))
return tf_example
</code></pre>
","I have a dataset of grayscale images, and I'd like to use the sdd-mobilenet checkpoints for training my object detection. What is the proper way to convert grayscale images to RGB that I can convert my dataset to tfrecord? Here is the code that I use (notice that the commented parts didn't work for me)",https://stackoverflow.com/questions/50017241,8130289,Documentation Replication on Other Examples,Documentation Replication on Other Examples, Here is the code that I use (notice that the commented parts didn't work for me)
36585071,"Cannot feed value of shape (500,) for Tensor 'x_17:0', which has shape '(?, 500)'","<p>I'm just learning TensorFlow, so sorry if this is obvious. I've checked the documentation and experimented quite a bit and I just can't seem to get this to work.</p>

<pre><code>def train_network():
    OUT_DIMS = 1
    FIN_SIZE = 500
    x = tf.placeholder(tf.float32, [OUT_DIMS, FIN_SIZE], name=""x"")
    w = tf.Variable(tf.zeros([FIN_SIZE, OUT_DIMS]), name=""w"")
    b = tf.Variable(tf.zeros([OUT_DIMS]), name=""b"")
    y = tf.tanh(tf.matmul(x, w) + b)

    yhat = tf.placeholder(tf.float32, [None, OUT_DIMS])
    cross_entropy = -tf.reduce_sum(yhat*tf.log(y))

    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)

    # Launch the model
    init = tf.initialize_all_variables()
    sess = tf.Session()
    sess.run(init)

    for this_x, this_y in yield_financials():
        sess.run(train_step, feed_dict={x:    this_x,
                                        yhat: this_y})
        print(end=""."")
        sys.stdout.flush()
</code></pre>

<p>yield_financials() outputs an numpy array of 500 numbers and the number that I want it to guess. I've tried shuffling OUT_DIMS and FIN_SIZE around, I tried accumulating them into batches to more closely match what the tutorial looked like, I tried setting OUT_DIMS to 0, removing it entirely, and I tried replacing None with other numbers, but have not made any progress.</p>
","I'm just learning TensorFlow, so sorry if this is obvious. I've checked the documentation and experimented quite a bit and I just can't seem to get this to work. yield_financials() outputs an numpy array of 500 numbers and the number that I want it to guess. I've tried shuffling OUT_DIMS and FIN_SIZE around, I tried accumulating them into batches to more closely match what the tutorial looked like, I tried setting OUT_DIMS to 0, removing it entirely, and I tried replacing None with other numbers, but have not made any progress.",https://stackoverflow.com/questions/36585071,3471004,Inadequate Examples,Documentation Replication on Other Examples,I've checked the documentation and experimented quite a bit and I just can't seem to get this to work.
39251552,"TensorFlow first attempt, bad results","<p>I can't solve my problem, help me please. It's my first attempt of neural networks, i tried to make nn which can check is number betwen (3:6) or not. I used several docs in internet and make some listing. But it has not working results. It's always ""not in (3:6)"". And I can't to understand what I'm doing wrong.</p>

<pre><code>#Is number between (3:6)
import tensorflow as tf
import numpy as np
import random

def is_num_between(num):
    right_border = 6
    left_border = 3
    if num &lt; right_border and num &gt; left_border:
        return 1
    return 0

def is_num_around(num):
    right_border = 6
    left_border = 3
    if num &lt;= left_border or num &gt;= right_border:
        return 1
    return 0

def init_weights(shape):
    return tf.Variable(tf.random_normal(shape, stddev=0.01))

def model(X, w_h, w_o):
    h = tf.nn.tanh(tf.matmul(X, w_h))
    return tf.nn.sigmoid(tf.matmul(h, w_o))

def included_or_not(i, prediction):
    return [str(i) + "" is in (3:6)"", str(i) + "" not in (3:6)""][prediction]

NUM_COUNT = 2
NUM_HIDDEN = 10
BATCH_SIZE = 10000

pre_trX = [np.random.random_sample() * 10 for i in range(100000)]
pre_trY1 = [is_num_between(i) for i in pre_trX]
pre_trY2 = [is_num_around(i) for i in pre_trX]

trX = np.array([np.array([pre_trX[i], 1]) for i in range(len(pre_trX))])
trY = np.array([np.array([pre_trY1[i], pre_trY2[i]]) for i in range(len(pre_trX))])


# print(type(trX))
# print(pre_trX)
# print(pre_trY1)
# print(pre_trY2)
# print(trX[0])
# exit()

X = tf.placeholder(""float"", [None, NUM_COUNT])
Y = tf.placeholder(""float"", [None, 2])

w_h = init_weights([NUM_COUNT, NUM_HIDDEN])
w_o = init_weights([NUM_HIDDEN, 2])

py_X = model(X, w_h, w_o)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_X, Y))
train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost)

predict_op = tf.argmax(py_X, 1)


with tf.Session() as sess:
    tf.initialize_all_variables().run()

    for epoch in range(200):
        p = np.random.permutation(range(len(trX)))
        trX, trY = trX[p], trY[p]

        for start in range(0, len(trX), BATCH_SIZE):
            end = start + BATCH_SIZE
            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})

        print(epoch, np.mean(np.argmax(trY, axis=1) ==
                         sess.run(predict_op, feed_dict={X: trX, Y: trY})))


    # Tipo natrenirovana, nado ee potestit
    def check_nnetwork():
        numbers = [np.array([np.random.random_sample()*10, 1])]
        teX = np.array(numbers)
        teY = sess.run(predict_op, feed_dict={X: teX})
        output = np.vectorize(included_or_not)(""%.3f"" % numbers[0][0], teY)
        print(output)

    for i in range(40):
        check_nnetwork()
</code></pre>
","I can't solve my problem, help me please. It's my first attempt of neural networks, i tried to make nn which can check is number betwen (3:6) or not. I used several docs in internet and make some listing. But it has not working results. It's always ""not in (3:6)"". And I can't to understand what I'm doing wrong.",https://stackoverflow.com/questions/39251552,3178853,Requesting (Additional) Resources,Documentation Replication on Other Examples,I used several docs in internet and make some listing. But it has not working results.
42535815,How to add more layers to Convolutional Neural Network text classification TensorFlow example?,"<p>According to the documentation, the model presented in <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification_character_cnn.py"" rel=""nofollow noreferrer"">this example</a> is similar to the following paper:
""<a href=""https://arxiv.org/abs/1509.01626"" rel=""nofollow noreferrer"">Character-level Convolutional Networks for Text Classification</a>""</p>

<p>I found that the original model (presented in the paper) contains 9 layers deep with 6 convolutional layers and 3 fully-connected layers, but the implemented example contains only two convolutional layers:</p>

<pre><code>with tf.variable_scope('CNN_Layer1'):
    # Apply Convolution filtering on input sequence.
    conv1 = tf.contrib.layers.convolution2d(
                 byte_list, N_FILTERS, FILTER_SHAPE1, padding='VALID')
    # Add a RELU for non linearity.
    conv1 = tf.nn.relu(conv1)
    # Max pooling across output of Convolution+Relu.
    pool1 = tf.nn.max_pool(
            conv1,
            ksize=[1, POOLING_WINDOW, 1, 1],
            strides=[1, POOLING_STRIDE, 1, 1],
            padding='SAME')
    # Transpose matrix so that n_filters from convolution becomes width.
    pool1 = tf.transpose(pool1, [0, 1, 3, 2])
with tf.variable_scope('CNN_Layer2'):
    # Second level of convolution filtering.
    conv2 = tf.contrib.layers.convolution2d(
                 pool1, N_FILTERS, FILTER_SHAPE2, padding='VALID')
    # Max across each filter to get useful features for classification.
    pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1])
</code></pre>

<p>If anybody can help me to extend this model for more layers?</p>
","According to the documentation, the model presented in this example is similar to the following paper: ""Character-level Convolutional Networks for Text Classification"" I found that the original model (presented in the paper) contains 9 layers deep with 6 convolutional layers and 3 fully-connected layers, but the implemented example contains only two convolutional layers: If anybody can help me to extend this model for more layers?",https://stackoverflow.com/questions/42535815,3052875,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"According to the documentation, the model presented in this example is similar to the following paper"
42560998,Tensorflow classification labels datatype,"<p>I am using Tensorflow DNN model to do some <strong>classification</strong>.</p>

<p>I have a numerical (float32) data input but <strong>string type output</strong>.</p>

<pre><code>x = tf.placeholder(""float"", [None, n_input])
y = tf.placeholder(tf.string, [None, n_classes])
</code></pre>

<p>When I try to define the loss and optimizer as below:</p>

<pre><code>cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))
</code></pre>

<p>I encounter an error that </p>

<blockquote>
  <p>TypeError: sigmoid_cross_entropy_with_logits() got an unexpected
  keyword argument 'labels'</p>
</blockquote>

<p>I looked up the document from <a href=""https://www.tensorflow.org/versions/r0.10/api_docs/python/nn/classification"" rel=""nofollow noreferrer"">here</a>, it said that</p>

<blockquote>
  <p>logits and targets must have the same type and shape.</p>
</blockquote>

<p>Do I need to convert the class into a floating number(hashing string to number)?</p>

<pre><code>output_y = [[""apple"", ""apple"", ""orange"", ""banana""]]
encoded_y = [[1], [1], [2], [3]]
</code></pre>
","I am using Tensorflow DNN model to do some classification. I have a numerical (float32) data input but string type output. When I try to define the loss and optimizer as below: I encounter an error that I looked up the document from here, it said that Do I need to convert the class into a floating number(hashing string to number)?",https://stackoverflow.com/questions/42560998,6343552,Requesting (Additional) Resources,Documentation Replication on Other Examples,When I try to define the loss and optimizer as below: I encounter an error that I looked up the document from here
42939426,Tensorflow placeholder error,"<p>I have been playing around with tensorflow, I have managed to train the mode and serve it but when i try run the client to send data for classification i get this error</p>

<blockquote>
  <p>grpc.framework.interfaces.face.face.AbortionError:
  AbortionError(code=StatusCode.INVALID_ARGUMENT, details=""You must feed
  a value for placeholder tensor 'Placeholder_1' with dtype float<br>
  [[Node: Placeholder_1 = Placeholder_output_shapes=[[]],
  dtype=DT_FLOAT, shape=[],
  _device=""/job:localhost/replica:0/task:0/cpu:0""]]"")</p>
</blockquote>

<p>I do not quite understand this error, here are my placeholders</p>

<pre><code>X = tf.placeholder(tf.float32,[None,n_dim])
y = tf.placeholder(tf.float32,[None,n_classes])
</code></pre>

<p>And i used the builder as in the documentation, writing the prediction_signature as well as classification signatures.</p>

<p>If any may know why this is happening i would be extremely grateful </p>
","I have been playing around with tensorflow, I have managed to train the mode and serve it but when i try run the client to send data for classification i get this error I do not quite understand this error, here are my placeholders And i used the builder as in the documentation, writing the prediction_signature as well as classification signatures. If any may know why this is happening i would be extremely grateful",https://stackoverflow.com/questions/42939426,6664161,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I get this error I do not quite understand this error, here are my placeholders. And i used the builder as in the documentation, writing the prediction_signature as well as classification signatures."
45022315,Tensorflow ValueError: Too many vaues to unpack (expected 2),"<p>I have looked this up on Reddit, Stack Overflow, tech forums, documentation, GitHub issues etc etc and still can't solve this issue.</p>

<p>For reference, I am using <code>Python 3 TensorFlow</code> on Windows 10, 64 Bit.</p>

<p>I am trying to use my own dataset (300 pics of cats, 512x512, .png format) in <code>Tensorflow</code> to train it to know what a cat looks like. If this works I will train it with other animals and eventually objects.</p>

<p>I can't seem to figure out why I am getting the error <code>ValueError: too many values to unpack (expected 2)</code>. The error appears in the line <code>images,labal = create_batches(10)</code>, which points to my function <code>create_batches</code> (see below). I don't know what could be causing this as I am fairly new to <code>TensorFlow</code>. I am trying to make my own Neural Network based on the MNIST Dataset. Code below:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np
import os
import sys
import cv2


content = []
labels_list = []
with open(""data/cats/files.txt"") as ff:
    for line in ff:
        line = line.rstrip()
        content.append(line)

with open(""data/cats/labels.txt"") as fff:
    for linee in fff:
        linee = linee.rstrip()
        labels_list.append(linee)

def create_batches(batch_size):
    images = []
    for img in content:
        #f = open(img,'rb')
        #thedata = f.read().decode('utf8')
        thedata = cv2.imread(img)
        thedata = tf.contrib.layers.flatten(thedata)
        images.append(thedata)
    images = np.asarray(images)

    labels =tf.convert_to_tensor(labels_list,dtype=tf.string)

    print(content)
    #print(labels_list)

    while(True):
        for i in range(0,298,10):
            yield images[i:i+batch_size],labels_list[i:i+batch_size]


imgs = tf.placeholder(dtype=tf.float32,shape=[None,262144])
lbls = tf.placeholder(dtype=tf.float32,shape=[None,10])

W = tf.Variable(tf.zeros([262144,10]))
b = tf.Variable(tf.zeros([10]))

y_ = tf.nn.softmax(tf.matmul(imgs,W) + b)

cross_entropy = tf.reduce_mean(-tf.reduce_sum(lbls * tf.log(y_),reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)

sess = tf.InteractiveSession()
tf.global_variables_initializer().run()
for i in range(10000):
    images,labal = create_batches(10)
    sess.run(train_step, feed_dict={imgs:images, lbls: labal})

correct_prediction = tf.equal(tf.argmax(y_,1),tf.argmax(lbls,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))

print(sess.run(accuracy, feed_dict={imgs:content, lbls:labels_list}))
</code></pre>

<p>And the Error:</p>

<pre><code>Traceback (most recent call last):
  File ""B:\Josh\Programming\Python\imgpredict\predict.py"", line 54, in &lt;module&gt;

    images,labal = create_batches(2)
ValueError: too many values to unpack (expected 2)
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
(A few hundred lines of this)
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
libpng warning: iCCP: known incorrect sRGB profile
</code></pre>

<p>My <a href=""https://github.com/supamonkey2000/jm-uofa"" rel=""nofollow noreferrer"" title=""GitHub"">GitHub link</a> link if anyone needs it. The project folder is the ""imgpredict"".</p>
","I have looked this up on Reddit, Stack Overflow, tech forums, documentation, GitHub issues etc etc and still can't solve this issue. For reference, I am using Python 3 TensorFlow on Windows 10, 64 Bit. I am trying to use my own dataset (300 pics of cats, 512x512, .png format) in Tensorflow to train it to know what a cat looks like. If this works I will train it with other animals and eventually objects. I can't seem to figure out why I am getting the error ValueError: too many values to unpack (expected 2). The error appears in the line images,labal = create_batches(10), which points to my function create_batches (see below). I don't know what could be causing this as I am fairly new to TensorFlow. I am trying to make my own Neural Network based on the MNIST Dataset. Code below: And the Error: My GitHub link link if anyone needs it. The project folder is the ""imgpredict"".",https://stackoverflow.com/questions/45022315,,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I have looked this up on Reddit, Stack Overflow, tech forums, documentation, GitHub issues etc etc and still can't solve this issue."
50066313,Tensorflow - 2D convolution with mutliple channels,"<p>I am defining my input and my kernels in this way</p>

<pre><code>import numpy as np
k = np.array([[
    [1, 0, 1],
    [2, 1, 0],
    [0, 0, 1]
],[
    [1, 0, 1],
    [2, 1, 0],
    [0, 0, 1]
]
], dtype=np.float32)
i = np.array([
    [4, 3, 1, 0],
    [2, 1, 0, 1],
    [1, 2, 4, 1],
    [3, 1, 0, 2]
], dtype=np.float32)
</code></pre>

<p>And convolve the two using</p>

<pre><code>import tensorflow as tf
kernel = tf.reshape(k, [3, 3, 1, 2], name='kernel')
image  = tf.reshape(i, [1, 4, 4, 1], name='image')
res = tf.squeeze(tf.nn.conv2d(image, kernel, [1, 1, 1, 1], ""VALID""))
with tf.Session() as sess:
   print sess.run(res)
</code></pre>

<p>Yielding a result of </p>

<pre><code>[[[11. 12.]
  [ 8.  6.]]

 [[11. 11.]
  [ 8.  8.]]]
</code></pre>

<p>What I want to do is to perform one convolution with one ""subfilter""</p>

<pre><code>[
[1, 0, 1],
[2, 1, 0],
[0, 0, 1]
]
</code></pre>

<p>over the input at the time. Doing it myself with pen and paper, I get</p>

<pre><code>[[[14.  6.]
  [ 6. 12.]]

 [[14.  6.]
  [ 6. 12.]]]
</code></pre>

<p>All other permutations of the ""reshape-parameters"" yield errors and I cannot find what I am doing wrong in the TF documentation. Does anyone know what I am doing wrong?</p>
","I am defining my input and my kernels in this way And convolve the two using Yielding a result of What I want to do is to perform one convolution with one ""subfilter"" over the input at the time. Doing it myself with pen and paper, I get All other permutations of the ""reshape-parameters"" yield errors and I cannot find what I am doing wrong in the TF documentation. Does anyone know what I am doing wrong?",https://stackoverflow.com/questions/50066313,4308982,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"Doing it myself with pen and paper, I get All other permutations of the ""reshape-parameters"" yield errors and I cannot find what I am doing wrong in the TF documentation."
50421555,Argmax function of Tensorflow does not print value when evaluated on a constant tensor,"<p>I'm new at Tensorflow. I am having a litte trouble at understanding its constants. I have this simple code mentioned below:</p>

<pre><code>import tensorflow as tf
vector = tf.constant([[1,2,3,4],[4,5,6,7],[8,9,1,2]],tf.int32,name=""vector"")
with tf.Session() as sess:
    v = sess.run(vector)
    argm = tf.argmax(v,1)
    print(argm)
</code></pre>

<p>I expect this to return something like <code>[4,7,8]</code>, as I understood from the documentation. Instead, I get this: </p>

<pre><code> Tensor(""ArgMax:0"", shape=(3,), dtype=int64). 
</code></pre>

<p>So, i don't know what am I doing wrong.</p>
","I'm new at Tensorflow. I am having a litte trouble at understanding its constants. I have this simple code mentioned below: I expect this to return something like [4,7,8], as I understood from the documentation. Instead, I get this: So, i don't know what am I doing wrong.",https://stackoverflow.com/questions/50421555,7070099,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I expect this to return something like [4,7,8], as I understood from the documentation."
50600661,Tensorflow TFRecordDataset.map Error,"<p>I am making an input pipeline in tensorflow for a task I want to do. I have set up a TFRecord dataset which has been saved out to a file on disk. </p>

<p>I am trying to load in the dataset (to be batched and sent to the actual ML algorithm) using the following code:</p>

<pre><code>dataset = tf.data.TFRecordDataset(filename)

print(""Starting mapping..."")

dataset = dataset.map(map_func = read_single_record)
print(""Mapping complete"")

buffer = 500 # How large of a buffer will we sample from?
batch_size = 125
capacity = buffer + 2 * batch_size

print(""Shuffling dataset..."")
dataset = dataset.shuffle(buffer_size = buffer)
print(""Batching dataset..."")
dataset = dataset.batch(batch_size)
dataset = dataset.repeat()

print(""Creating iterator..."")
iterator = dataset.make_one_shot_iterator()
examples_batch, labels_batch = iterator.get_next()
</code></pre>

<p>However, I get an error on the dataset.map() line. The error I get looks like this: <code>TypeError: Expected int64, got &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000000085F74A8&gt; of type 'SparseTensor' instead.</code></p>

<p>The <code>read_single_record()</code> function looks like this:</p>

<pre><code>keys_to_features = {
                ""image/pixels"": tf.FixedLenFeature([], tf.string, default_value = """"),
                ""image/label/class"": tf.FixedLenFeature([], tf.int64, default_value = 0),
                ""image/label/numbb"": tf.FixedLenFeature([], tf.int64, default_value = 0),
                ""image/label/by"": tf.VarLenFeature(tf.float32),
                ""image/label/bx"": tf.VarLenFeature(tf.float32),
                ""image/label/bh"": tf.VarLenFeature(tf.float32),
                ""image/label/bw"": tf.VarLenFeature(tf.float32)
            }

features = tf.parse_single_example(record, keys_to_features)

image_pixels = tf.image.decode_image(features[""image/pixels""])
print(""Features: {0}"".format(features))

example = image_pixels  # May want to do some processing on this at some point

label = [features[""image/label/class""],
        features[""image/label/numbb""],
        features[""image/label/by""],
        features[""image/label/bx""],
        features[""image/label/bh""],
        features[""image/label/bw""]]

return example, label
</code></pre>

<p>I'm not sure where the issue lies. I got the idea for this code from the tensorflow API documentation, slightly modified for my purposes. I really have no idea where to start trying to fix this.</p>

<p>For reference, here is the code I have for generating the TFRecord file:</p>

<pre><code>def parse_annotations(in_file, img_filename, cell_width, cell_height):
    """""" Parses the annotations file to obtain the bounding boxes for a single image
    """"""
    y_mins = []
    x_mins = []
    heights = []
    widths = []
    grids_x = []
    grids_y = []
    classes = [0]

    num_faces = int(in_file.readline().rstrip())

    img_width, img_height = get_image_dims(img_filename)

    for i in range(num_faces):
        clss,  x, y, width, height = in_file.readline().rstrip().split(',')

        x = float(x)
        y = float(y)
        width = float(width)
        height = float(height)

        x = x - (width / 2.0)
        y = y - (height / 2.0)

        y_mins.append(y)
        x_mins.append(x)
        heights.append(height)
        widths.append(width)

        grid_x, grid_y = get_grid_loc(x, y, width, height, img_width, img_height, cell_width, cell_height)

    pixels = get_image_pixels(img_filename)

    example = tf.train.Example(features = tf.train.Features(feature = {
        ""image/pixels"": bytes_feature(pixels),
        ""image/label/class"": int_list_feature(classes),
        ""image/label/numbb"": int_list_feature([num_faces]),
        ""image/label/by"": float_list_feature(y_mins), 
        ""image/label/bx"": float_list_feature(x_mins), 
        ""image/label/bh"": float_list_feature(heights), 
        ""image/label/bw"": float_list_feature(widths)
    }))

    return example, num_faces

if len(sys.argv) &lt; 4:
    print(""Usage: python convert_to_tfrecord.py [path to processed annotations file] [path to training output file] [path to validation output file] [training fraction]"")

else:
    processed_fn = sys.argv[1]
    train_fn = sys.argv[2]
    valid_fn = sys.argv[3]
    train_frac = float(sys.argv[4])

    if(train_frac &gt; 1.0 or train_frac &lt; 0.0):
        print(""Training fraction (f) must be 0 &lt;= f &lt;= 1"")

    else:
        with tf.python_io.TFRecordWriter(train_fn) as writer:
            with tf.python_io.TFRecordWriter(valid_fn) as valid_writer:
                with open(processed_fn) as f:
                    for line in f:
                        ex, n_faces = parse_annotations(f, line.rstrip(), 30, 30)

                        randVal = rand.random()

                        if(randVal &lt; train_frac):
                            writer.write(ex.SerializeToString())

                        else:
                            valid_writer.write(ex.SerializeToString())
</code></pre>

<p>Note that I've removed some code that isn't to do with the actual serialisation/creation of the TFRecords file.</p>
","I am making an input pipeline in tensorflow for a task I want to do. I have set up a TFRecord dataset which has been saved out to a file on disk. I am trying to load in the dataset (to be batched and sent to the actual ML algorithm) using the following code: However, I get an error on the dataset.map() line. The error I get looks like this: TypeError: Expected int64, got &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000000085F74A8&gt; of type 'SparseTensor' instead. The read_single_record() function looks like this: I'm not sure where the issue lies. I got the idea for this code from the tensorflow API documentation, slightly modified for my purposes. I really have no idea where to start trying to fix this. For reference, here is the code I have for generating the TFRecord file: Note that I've removed some code that isn't to do with the actual serialisation/creation of the TFRecords file.",https://stackoverflow.com/questions/50600661,5280140,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I got the idea for this code from the tensorflow API documentation, slightly modified for my purposes."
51783265,in add_summary for value in summary.value: AttributeError: 'Tensor' object has no attribute 'value',"<p>This is a very basic tensorboard scalar log:</p>

<pre><code>import numpy as np
import tensorflow as tf
a = np.arange(10)
x = tf.convert_to_tensor(a, dtype=tf.float32)
x_summ = tf.summary.scalar(""X"", x)
writer = tf.summary.FileWriter('/tmp/logdir')
writer.add_summary(x_summ)
</code></pre>

<p>However, I get an error in add_summary for value in summary.value: </p>

<pre><code>AttributeError: 'Tensor' object has no attribute 'value'. 
</code></pre>

<p>Any solution for this?</p>

<p>TensorFlow documentation says ValueError is raised when the summary tensor has a wrong shape or type. When I print <code>x_summ</code> it shows:</p>

<pre><code>Tensor(""X:0"", shape=(), dtype=string)
</code></pre>

<p>I don't understand why is the shape <code>NULL</code> here.</p>
","This is a very basic tensorboard scalar log: However, I get an error in add_summary for value in summary.value: Any solution for this? TensorFlow documentation says ValueError is raised when the summary tensor has a wrong shape or type. When I print x_summ it shows: I don't understand why is the shape NULL here.",https://stackoverflow.com/questions/51783265,8713329,Requesting (Additional) Resources,Documentation Replication on Other Examples,TensorFlow documentation says ValueError is raised when the summary tensor has a wrong shape or type. When I print x_summ it shows: I don't understand why is the shape NULL here.
53998796,IPython Notebook Kernel Crashes when Assessing CNN Accuracy,"<p>I'm relatively new to TensorFlow. I have built a Logistic Regression classifier and a MultiLayer Perceptron in the past that have worked. Now that I have moved on to the Convolutional Neural Network, I am having some problems with testing accuracy. My code is below. The line I am having trouble with is only the <strong>very last line</strong> where I am attempting to print the test accuracy figure. The print 1, 2, 3 statements are intended to show this.</p>

<pre><code>### import libraries ###

import tensorflow as tf
import numpy as np
from tqdm import trange

### import mnist data ###

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""MNIST_data/"", one_hot = True)

##### Begin Computational Graph #####

## initial variable values chosen for ease of use with ReLU ##

# input image vector and reshape to 28x28x1
# 28x28x1 is a single image
# the first dimension will be minibatch size
x = tf.placeholder(
    dtype = tf.float32,
    shape = [None, 784],
    name = ""x"")

xReshape = tf.reshape(x, [-1, 28, 28, 1])

# placeholder for data labels
y_ = tf.placeholder(
    dtype = tf.float32,
    shape = [None, 10],
    name = ""y_"")

### First Convolutional Layer ###

# define kernel for first convolution layer
# initial values are random small numbers
K1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32],
                                     stddev = 0.01))

# define bias for first convolution layer
# initial values of 0.1
b1 = tf.Variable(tf.ones([32]) / 10)

# perform convolution
C1 = tf.nn.conv2d(
    input = xReshape,
    filter = K1,
    strides = [1, 1, 1, 1],
    padding = ""SAME"") + b1

# use activation function
C1_act = tf.nn.relu(C1)

# 2x2 max pool
maxPool1 = tf.nn.max_pool(
    value = C1_act,
    ksize = [1,2,2,1],
    strides = [1,2,2,1],
    padding = ""SAME"")

### Second Convolutional Layer ###

# define kernel for first convolution layer
# initial values are random small numbers
K2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64],
                                     stddev = 0.01))

# define bias for first convolution layer
# initial values of 0.1
b2 = tf.Variable(tf.ones([64]) / 10)

# perform convolution
C2 = tf.nn.conv2d(
    input = maxPool1,
    filter = K2,
    strides = [1, 1, 1, 1],
    padding = ""SAME"") + b2

# use activation function
C2_act = tf.nn.relu(C2)

# 2x2 max pool
maxPool2 = tf.nn.max_pool(
    value = C2_act,
    ksize = [1,2,2,1],
    strides = [1,2,2,1],
    padding = ""SAME"")

### First Fully Connected Layer w/ 256 Hidden Units ###

# flatten maps into one vector
fVect = tf.reshape(maxPool2, [-1, 7 * 7 * 64])

W1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 256],
                                     stddev = 0.01))

fcBias1 = tf.Variable(tf.ones([256]) / 10)

prob_y1 = tf.nn.relu(tf.matmul(fVect, W1) + fcBias1)

### Final Fully Connected layer with 10 hidden Units ###

W2 = tf.Variable(tf.truncated_normal([256, 10],
                                     stddev = 0.01))

fcBias2 = tf.Variable(tf.ones([10]) / 10)

prob_y2 = tf.nn.softmax(logits = (tf.matmul(prob_y1, W2) + fcBias2))

### Loss Function and Optimizer ###

# define loss function
cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(prob_y2), axis = 1))

# set up gradient descent optimizer

train_step = tf.train.GradientDescentOptimizer(learning_rate =     0.05).minimize(cross_entropy_loss)

##### Train the Network #####

### start the session and initialize global variables ###

# Variable Initializer
init_op = tf.global_variables_initializer()

# Create a Session object, initialize all variables
sess = tf.Session()
sess.run(init_op)

for _ in trange(1000): 
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict = {x: batch_xs, y_: batch_ys})

### Test Prediction Accuracy ###

# test trained model
print(1)
correct_prediction = tf.equal(tf.argmax(prob_y2, axis = 1), tf.argmax(y_, axis = 1))
print(2)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(3)
print('Test accuracy: {0}'.format(sess.run(accuracy, feed_dict = {x: mnist.test.images, y_: mnist.test.labels})))

sess.close()
</code></pre>

<p>Apologies for the big code dump. I want make sure the issue is reproducible. The result of this code in my notebook is a pop-up window that says, ""The kernel appears to have died. It will restart automatically."" I'm hoping this is some small error in my syntax or something, but I've search all the functional documentation and forums and haven't identified my issue.</p>

<p>Any help is appreciated!</p>
","I'm relatively new to TensorFlow. I have built a Logistic Regression classifier and a MultiLayer Perceptron in the past that have worked. Now that I have moved on to the Convolutional Neural Network, I am having some problems with testing accuracy. My code is below. The line I am having trouble with is only the very last line where I am attempting to print the test accuracy figure. The print 1, 2, 3 statements are intended to show this. Apologies for the big code dump. I want make sure the issue is reproducible. The result of this code in my notebook is a pop-up window that says, ""The kernel appears to have died. It will restart automatically."" I'm hoping this is some small error in my syntax or something, but I've search all the functional documentation and forums and haven't identified my issue. Any help is appreciated!",https://stackoverflow.com/questions/53998796,4882698,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I'm hoping this is some small error in my syntax or something, but I've search all the functional documentation and forums and haven't identified my issue."
54041135,Multiclass U-Net segmentation in TensorFlow,"<p>I've seen variations of this question all over, but am still struggling to implement it correctly.  I have brain MRI images with ground-truth segmented masks with 4 classes (0- background, 1-tissue type1, 2-tissue type2, 3-inexplicably skipped, and 4-tissue type 4...BrATs dataset)</p>

<p><a href=""https://i.stack.imgur.com/IVMU5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IVMU5.png"" alt=""enter image description here""></a></p>

<p>I have a basic U-Net architecture implemented, but am having trouble extending it to non-binary classification.  Particularly, the loss function.</p>

<p>This is what I have implemented, but I'm obviously overlooking important details:</p>

<pre><code>[...]
output = tf.layers.conv2d_transpose(
conv18,
filters=5,
kernel_size=1,
strides=1,
padding='same',
data_format='channels_last',
activation=None,
use_bias=True,
kernel_initializer=None,
bias_initializer=tf.zeros_initializer(),
kernel_regularizer=tf.contrib.layers.l2_regularizer(reg),
bias_regularizer=None,
activity_regularizer=None,
kernel_constraint=None,
bias_constraint=None,
trainable=True,
name='output',
reuse=None
)
</code></pre>

<p>I thought 5 filters for the (0,1,2,3,4) possible mask values would be correct.  I then used the following loss function:</p>

<pre><code>loss = tf.nn.sparse_softmax_cross_entropy_with_logits(
_sentinel=None,
labels=label,
logits=output,
name='cross_ent_loss'
)

return tf.reduce_mean(loss)
</code></pre>

<p>Where the logits would get passed the output from above, and the labels would be my stacked mask images [n_batch, x_dim, y_dim, 1]. Looking at the documentation, I know I am not passing labels the correct tensor.  </p>

<p>Am I even going about this correctly?  How do I implement the loss with multi-class labels contained within the 1 mask image?</p>
","I've seen variations of this question all over, but am still struggling to implement it correctly. I have brain MRI images with ground-truth segmented masks with 4 classes (0- background, 1-tissue type1, 2-tissue type2, 3-inexplicably skipped, and 4-tissue type 4...BrATs dataset) I have a basic U-Net architecture implemented, but am having trouble extending it to non-binary classification. Particularly, the loss function. This is what I have implemented, but I'm obviously overlooking important details: I thought 5 filters for the (0,1,2,3,4) possible mask values would be correct. I then used the following loss function: Where the logits would get passed the output from above, and the labels would be my stacked mask images [n_batch, x_dim, y_dim, 1]. Looking at the documentation, I know I am not passing labels the correct tensor. Am I even going about this correctly? How do I implement the loss with multi-class labels contained within the 1 mask image?",https://stackoverflow.com/questions/54041135,6749743,Requesting (Additional) Resources,Documentation Replication on Other Examples,"Looking at the documentation, I know I am not passing labels the correct tensor."
54194053,"AttributeError: Layer has no inbound nodes, or AttributeError: The layer has never been called","<p>I need a way to get the shape of output tensor for any type of layer (i.e. Dense, Conv2D, etc) in TensorFlow. According to documentation, there is <code>output_shape</code> property which solves the problem. However every time I access it I get <code>AttributedError</code>.</p>

<p>Here is code sample showing the problem:</p>

<pre><code>import numpy as np
import tensorflow as tf


x = np.arange(0, 8, dtype=np.float32).reshape((1, 8))
x = tf.constant(value=x, dtype=tf.float32, verify_shape=True)

dense = tf.layers.Dense(units=2)

out = dense(x)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    res = sess.run(fetches=out)
    print(res)
    print(dense.output_shape)
</code></pre>

<p>The <code>print(dense.output_shape)</code> statement will produce error message:</p>

<pre><code>AttributeError: The layer has never been called and thus has no defined output shape.
</code></pre>

<p>or <code>print(dense.output)</code> will produce:</p>

<pre><code>AttributeError('Layer ' + self.name + ' has no inbound nodes.')
AttributeError: Layer dense_1 has no inbound nodes.
</code></pre>

<p>Is there any way to fix the error?</p>

<p><strong>P.S.:</strong>
I know that in example above I can get shape of output tensor via <code>out.get_shape()</code>. However I want to know why <code>output_shape</code> property doesn't work and how I can fix it?</p>
","I need a way to get the shape of output tensor for any type of layer (i.e. Dense, Conv2D, etc) in TensorFlow. According to documentation, there is output_shape property which solves the problem. However every time I access it I get AttributedError. Here is code sample showing the problem: The print(dense.output_shape) statement will produce error message: or print(dense.output) will produce: Is there any way to fix the error? P.S.: I know that in example above I can get shape of output tensor via out.get_shape(). However I want to know why output_shape property doesn't work and how I can fix it?",https://stackoverflow.com/questions/54194053,9565342,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"According to documentation, there is output_shape property which solves the problem. However every time I access it I get AttributedError."
57510115,cifar100 with MobiletNetV2,"<p>I am trying to train MobileNetV2 on CIFAR100 using keras.applications
Here is my code:</p>

<pre><code>(x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')

x_test = x_test.astype(""float32"")
x_train = x_train.astype(""float32"")

x_test /=255
x_train /=255

y_test = tf.keras.utils.to_categorical(y_test,100)
y_train = tf.keras.utils.to_categorical(y_train,100)
model = MobileNetV2(input_shape=(32,32,3),
                    alpha=1.0,
                    include_top=True,
                    weights=None,
                    classes=100)
epochs = 200
batch_size = 64
print('Using real-time data augmentation.')
    # This will do preprocessing and realtime data augmentation:
datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        zca_epsilon=1e-06,  # epsilon for ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        # randomly shift images horizontally (fraction of total width)
        width_shift_range=0.1,
        # randomly shift images vertically (fraction of total height)
        height_shift_range=0.1,
        shear_range=0.,  # set range for random shear
        zoom_range=0.,  # set range for random zoom
        channel_shift_range=0.,  # set range for random channel shifts
        # set mode for filling points outside the input boundaries
        fill_mode='nearest',
        cval=0.,  # value used for fill_mode = ""constant""
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False,  # randomly flip images
        # set rescaling factor (applied before any other transformation)
        rescale=None,
        # set function that will be applied on each input
        preprocessing_function=None,
        # image data format, either ""channels_first"" or ""channels_last""
        data_format=None,
        # fraction of images reserved for validation (strictly between 0 and 1)
        validation_split=0.0)
datagen.fit(x_train)

model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'])
history = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),
                        epochs=epochs,
                        validation_data=(x_test, y_test)
                             )
</code></pre>

<p>The issue is with the validation accuracy, after 200 epochs the acc is almost 40%. 
I tried to fine_tune the optimizer/loss params but still the same. My guess is the dim of the input is too small for the model as the default is 224*224, however according to the documentation you could use whatever you want!</p>

<p>Any advice? (I do not want to change the dim of cifar100 to 224*224 because of some assumptions related to this experiment)!</p>
","I am trying to train MobileNetV2 on CIFAR100 using keras.applications Here is my code: The issue is with the validation accuracy, after 200 epochs the acc is almost 40%. I tried to fine_tune the optimizer/loss params but still the same. My guess is the dim of the input is too small for the model as the default is 224*224, however according to the documentation you could use whatever you want! Any advice? (I do not want to change the dim of cifar100 to 224*224 because of some assumptions related to this experiment)!",https://stackoverflow.com/questions/57510115,458105,Requesting (Additional) Resources,Documentation Replication on Other Examples,"My guess is the dim of the input is too small for the model as the default is 224*224, however according to the documentation you could use whatever you want! Any advice?"
57721804,"setting sample_weight_mode=""temporal"" doesn't seem to work","<p>I am working with LSTM in tensorflow 2.0 and I am trying to assign a weight to the training samples (I've already tried with class_weights dictionary but it complains that 3-d arrays are not supported for it. my array shape is (26000, 7, 1)).</p>

<p>As suggested in the documentation, I am setting sample_weight_mode to ""temporal"" in compile, but after that when I try to fit the model I still get the error below:</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-100-1bb94008291c&gt; in &lt;module&gt;
      1 with tf.device(""/device:GPU:0""):
----&gt; 2     model.fit(X, y, epochs=500, batch_size=4096, verbose=1, validation_split=0.2, sample_weight=cw.reshape(26000,7,1))

C:\ProgramData\Anaconda3\envs\thesis-gpu\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    641         max_queue_size=max_queue_size,
    642         workers=workers,
--&gt; 643         use_multiprocessing=use_multiprocessing)
    644 
    645   def evaluate(self,

C:\ProgramData\Anaconda3\envs\thesis-gpu\lib\site-packages\tensorflow\python\keras\engine\training_arrays.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    630         steps=steps_per_epoch,
    631         validation_split=validation_split,
--&gt; 632         shuffle=shuffle)
    633 
    634     if validation_data:

C:\ProgramData\Anaconda3\envs\thesis-gpu\lib\site-packages\tensorflow\python\keras\engine\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)
   2459           training_utils.standardize_weights(ref, sw, cw, mode)
   2460           for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,
-&gt; 2461                                          feed_sample_weight_modes)
   2462       ]
   2463       # Check that all arrays have the same length.

C:\ProgramData\Anaconda3\envs\thesis-gpu\lib\site-packages\tensorflow\python\keras\engine\training.py in &lt;listcomp&gt;(.0)
   2458       sample_weights = [
   2459           training_utils.standardize_weights(ref, sw, cw, mode)
-&gt; 2460           for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,
   2461                                          feed_sample_weight_modes)
   2462       ]

C:\ProgramData\Anaconda3\envs\thesis-gpu\lib\site-packages\tensorflow\python\keras\engine\training_utils.py in standardize_weights(y, sample_weight, class_weight, sample_weight_mode)
    839     if sample_weight is not None and len(sample_weight.shape) != 1:
    840       raise ValueError('Found a sample_weight array with shape ' +
--&gt; 841                        str(sample_weight.shape) + '. '
    842                        'In order to use timestep-wise sample weights, '
    843                        'you should specify '

ValueError: Found a sample_weight array with shape (26000, 7, 1). In order to use timestep-wise sample weights, you should specify sample_weight_mode=""temporal"" in compile(). If you just mean to use sample-wise weights, make sure your sample_weight array is 1D.
</code></pre>

<p>I have already tried changing the shape of the sample_weights passed in fit (also tried to flatten it), setting shuffle to False and removing the validation split without success.</p>

<p>Here's the code I am using</p>

<pre><code>import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math

# Import TensorFlow
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop, Adam, SGD
from tensorflow.keras.layers import SimpleRNN, LSTM, Dense
from tensorflow.keras.models import Sequential

from sklearn.utils import class_weight

class_weights = class_weight.compute_class_weight('balanced',
                                                 np.unique(y_train),
                                                 y_train)

cw = class_weight.compute_sample_weight({False:1, True:50},#'balanced',
                                                 #np.unique(y_train),
                                                 y.flatten())

model = Sequential()
model.add(LSTM(160, return_sequences=True, dropout=0.05))
model.add(LSTM(80, return_sequences=True, dropout=0.05, activation='relu'))
model.add(LSTM(40, return_sequences=True, dropout=0.05, activation='relu'))
model.add(LSTM(10, return_sequences=True, dropout=0.05))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', tf.keras.metrics.AUC()], sample_weight_mode=""temporal"")

with tf.device(""/device:GPU:0""):
    model.fit(X, y, epochs=500, batch_size=4096, verbose=1, validation_split=0.2, sample_weight=cw.reshape(26000,7,1))
</code></pre>
","I am working with LSTM in tensorflow 2.0 and I am trying to assign a weight to the training samples (I've already tried with class_weights dictionary but it complains that 3-d arrays are not supported for it. my array shape is (26000, 7, 1)). As suggested in the documentation, I am setting sample_weight_mode to ""temporal"" in compile, but after that when I try to fit the model I still get the error below: I have already tried changing the shape of the sample_weights passed in fit (also tried to flatten it), setting shuffle to False and removing the validation split without success. Here's the code I am using",https://stackoverflow.com/questions/57721804,9961790,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"As suggested in the documentation, I am setting sample_weight_mode to ""temporal"" in compile, but after that when I try to fit the model I still get the error below"
58259247,"object is not callable, when using tf.optimizers.Adam.minimize()","<p>I am new to tensorflow (2.0), so i wanted to ease with a simple linear regression. I have the following code but i dont know why it is wrong .</p>

<p>I have tried with the documentation but so far i have no answer.</p>

<pre class=""lang-py prettyprint-override""><code>x = np.random.normal(loc=10., scale = 0.1, size=170)
y = np.repeat(10.,170)
a_init = tf.random_normal_initializer()
a = tf.Variable(initial_value=a_init(shape = [1], dtype = 'float32'),trainable=True)
pred = tf.multiply(a,x)
loss = tf.nn.l2_loss(pred-y)
optim = tf.optimizers.Adam(lr = 0.002)
entreno = optim.minimize(loss, [a])
</code></pre>

<p>I get the following error,</p>

<pre class=""lang-py prettyprint-override""><code>Traceback (most recent call last)
&lt;ipython-input-45-e1a191781d0a&gt; in &lt;module&gt;
      2 loss = tf.nn.l2_loss(pred-y)
      3 optim = tf.optimizers.Adam(lr = 0.002)
----&gt; 4 entreno = optim.minimize(loss, [a])

TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable
</code></pre>

<p>If it helps i have a tensorflow 1 code:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow
import numpy as np
tf = tensorflow.compat.v1
x = np.random.normal(loc=1.,scale=0.1, size = 220)
y = np.repeat(14.37,220)
tf.disable_eager_execution()
x_d = tf.placeholder(shape = [1], dtype=tf.float32)
y_t = tf.placeholder(shape = [1], dtype = tf.float32)
A = tf.Variable(tf.random_normal(shape=[1]))
my_pred = tf.multiply(A,x_d)
loss = tf.square(my_pred-y_t)
optim = tf.train.GradientDescentOptimizer(learning_rate=0.02)
train_step = optim.minimize(loss)
init = tf.global_variables_initializer()
session = tf.Session()
session.run(init)
for _ in range(241):
    idx = np.random.choice(220)
    ranx = [x[idx]]
    rany = [y[idx]]
    session.run(train_step, feed_dict ={x_d : ranx, y_t : rany})
    if _%20 == 0:
        print(""A = {}, Loss : {}"".format(session.run(A), session.run(loss, feed_dict={x_d:ranx, y_t:rany})))

</code></pre>
","I am new to tensorflow (2.0), so i wanted to ease with a simple linear regression. I have the following code but i dont know why it is wrong . I have tried with the documentation but so far i have no answer. I get the following error, If it helps i have a tensorflow 1 code:",https://stackoverflow.com/questions/58259247,10942287,Documentation Replication on Other Examples,Documentation Replication on Other Examples,I have tried with the documentation but so far i have no answer.
58666537,Error while feeding tf.Dataset to fit(): KeyError: 'embedding_input',"<p>I'm using TensorFlow 2.0 Datasets to feed my model's fit function. Here is the code:</p>

<pre><code>def build_model(self):
    self.g_Model = Sequential()
    self.g_Model.add(Embedding(self.g_Max_features, output_dim=256))
    self.g_Model.add(LSTM(128))
    self.g_Model.add(Dropout(0.5))
    self.g_Model.add(Dense(1, activation='sigmoid'))
    self.g_Model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

def train_model(self, filenames):
    lstm_feature_description = {
        'X': tf.io.FixedLenFeature(CONFIG.g_keras_lstm_max_document_length, tf.float32),
        'y': tf.io.FixedLenFeature((), tf.int64),
    }

    def _parse_lstm_function(example_proto):
        return tf.io.parse_single_example(serialized=example_proto, features=lstm_feature_description)

    self.build_model()

    # Start Preparing The Data
    raw_lstm_dataset = tf.data.TFRecordDataset(CONFIG.g_record_file_lstm)

    parsed_lstm_dataset = raw_lstm_dataset.map(_parse_lstm_function)
    parsed_lstm_dataset = parsed_lstm_dataset.shuffle(CONFIG.g_shuffle_s).batch(CONFIG.g_Batch_size)

    self.g_Model.fit(parsed_lstm_dataset, epochs=2)
</code></pre>

<p>But I receive the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""keras_lstm_v2.py"", line 79, in train_model
      1/Unknown - 0s 0s/step    self.g_Model.fit(parsed_lstm_dataset, epochs=2)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 86, in execution_function
    distributed_function(input_fn))
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 457, in __call__
    result = self._call(*args, **kwds)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 503, in _call
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 408, in _initialize
    *args, **kwds))
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1848, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\eager\function.py"", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\framework\func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 66, in distributed_function
    model, input_iterator, mode)
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 118, in _prepare_feed_values
    inputs = [inputs[key] for key in model._feed_input_names]
  File ""venv_tf_new\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 118, in &lt;listcomp&gt;
    inputs = [inputs[key] for key in model._feed_input_names]
KeyError: 'embedding_input'
</code></pre>

<p>I've seen this <a href=""https://github.com/tensorflow/tensorflow/issues/19912"" rel=""nofollow noreferrer"">thread</a>, however it doesn't clarify things up for me. As far as I understood there is a problem with the loaded data, but according to documentation for Datasets it should work out of the box, so I couldn't figure out how to fix it.</p>

<p>Any help is appreciated. Thanks!</p>
","I'm using TensorFlow 2.0 Datasets to feed my model's fit function. Here is the code: But I receive the following error: I've seen this thread, however it doesn't clarify things up for me. As far as I understood there is a problem with the loaded data, but according to documentation for Datasets it should work out of the box, so I couldn't figure out how to fix it. Any help is appreciated. Thanks!",https://stackoverflow.com/questions/58666537,4541899,Documentation Ambiguity,Documentation Replication on Other Examples,"As far as I understood there is a problem with the loaded data, but according to documentation for Datasets it should work out of the box, so I couldn't figure out how to fix it."
58933545,Using Tensorflow 2.0 and eager execution without Keras,"<p>So this question might stem from a lack of knowledge about tensorflow. But I am trying to build a multilayer perceptron with <code>tensorflow 2.0</code>, but without <code>Keras</code>.</p>
<p>The reason being that it is a requirement for my machine learning course that we do not use keras. Why you might ask? I am not sure.</p>
<p>I already have implemented our model in <code>tensorflow 2.0</code> with Keras ease, and now I want to do the exact same thing without <code>keras</code>.</p>
<pre><code>model = Sequential()
model.add(Dense(64, activation='relu', input_dim=784))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',
              optimizer=Adam(),
              metrics=['accuracy'])

X_train = X[:7000]
y_train = tf.keras.utils.to_categorical(y[:7000], num_classes=5)
X_dev = X[7000:]
y_dev = tf.keras.utils.to_categorical(y[7000:], num_classes=5)

model.fit(X_train, y_train,
          epochs=100,
          batch_size=128)
score = model.evaluate(X_dev, y_dev, batch_size=128)
print(score)
</code></pre>
<p>Here is my problem. Whenever I look up the documentation on <code>Tensorflow 2.0</code>, then even the guides on custom training are using Keras.</p>
<p>As placeholders and sessions are a thing of the past in <code>tensorflow 2.0</code>, as I understand it, then I am a bit unsure of how to structure it.</p>
<p>I can make tensor objects. I have the impression that I need to use eager execution and use gradient tape. But I still am unsure of how to put these things together.</p>
<p>Now my question is. Where should I look to get a better understanding? Which direction has the greatest descent?</p>
<p>Please do tell me if I am doing this stack overflow post wrong. It is my first time here.</p>
","So this question might stem from a lack of knowledge about tensorflow. But I am trying to build a multilayer perceptron with tensorflow 2.0, but without Keras. The reason being that it is a requirement for my machine learning course that we do not use keras. Why you might ask? I am not sure. I already have implemented our model in tensorflow 2.0 with Keras ease, and now I want to do the exact same thing without keras. Here is my problem. Whenever I look up the documentation on Tensorflow 2.0, then even the guides on custom training are using Keras. As placeholders and sessions are a thing of the past in tensorflow 2.0, as I understand it, then I am a bit unsure of how to structure it. I can make tensor objects. I have the impression that I need to use eager execution and use gradient tape. But I still am unsure of how to put these things together. Now my question is. Where should I look to get a better understanding? Which direction has the greatest descent? Please do tell me if I am doing this stack overflow post wrong. It is my first time here.",https://stackoverflow.com/questions/58933545,12397330,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I already have implemented our model in tensorflow 2.0 with Keras ease, and now I want to do the exact same thing without keras. Here is my problem. Whenever I look up the documentation on Tensorflow 2.0, then even the guides on custom training are using Keras."
60797147,Embedding layer output shape is 2D,"<p>I'm encountering some issue with the output shape of my embedding layer, as per the keras documentation, the embedding layer should have an output shape of 3D tensor, but my embedding layer is only outputting 2D tensor.</p>

<pre><code>class MyModel(Model):
  def __init__(self, vocab_size, embedding_matrix, max_length):
      super(MyModel, self).__init__()
      self.embedding_l1 = tf.keras.layers.Embedding(input_dim=vocab_size,
                                                    output_dim=max_length, 
                                                    input_length=max_length,
                                                    weights=[embedding_matrix], 
                                                    trainable=False)
      self.bidirectional_l1 = Bidirectional(
                             tf.compat.v1.keras.layers.CuDNNLSTM(32, 
                                                                 return_sequences=False))
      self.dense_l1 = Dense(units=256, activation='relu')
      self.dropout_l1 = Dropout(rate=2e-5)
      self.dense_l2 = Dense(units=1, activation='sigmoid')

  def call(self, x):
      embedding_out = self.embedding_l1(x)
      print(""SHAPE:"",embedding_out.shape)
      bid_out1 = self.bidirectional_l1(self.reshape_l1(embedding_out))
      dense_out1 = self.dense_l1(bid_out1)
      drop_out1 = self.dropout_l2(dense_out1)
      dense_out2 = self.dense_l2(drop_out2)
      return dense_out2
</code></pre>

<p>It outputs the shape of the embedding layer out as a 2D (300,300) tensor. which causes error on the bidirectional lstm:</p>

<p><code>ValueError: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [300, 300]</code></p>
","I'm encountering some issue with the output shape of my embedding layer, as per the keras documentation, the embedding layer should have an output shape of 3D tensor, but my embedding layer is only outputting 2D tensor. It outputs the shape of the embedding layer out as a 2D (300,300) tensor. which causes error on the bidirectional lstm: ValueError: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [300, 300]",https://stackoverflow.com/questions/60797147,11000852,Lack of Alternative Solutions/Documentation,Documentation Replication on Other Examples,"I'm encountering some issue with the output shape of my embedding layer, as per the keras documentation, the embedding layer should have an output shape of 3D tensor, but my embedding layer is only outputting 2D tensor."
61561253,AttributeError: module 'tensorflow' has no attribute 'RunOptions',"<p>I'm a beginner. 
I'm working with python - TensorFlow '2.2.0' on python IDLE. </p>

<pre><code>run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)
</code></pre>

<p>I got the following error while running the previous code.:</p>

<pre><code>AttributeError: module 'tensorflow' has no attribute 'RunOptions'"" 
</code></pre>

<p>however, according to example 18 from this <a href=""https://www.programcreek.com/python/example/90595/tensorflow.RunOptions"" rel=""nofollow noreferrer"">link</a> on the official page on Tensorflow, there's no error! </p>

<p>what's wrong in my case? How should I resolve this issue?</p>
","I'm a beginner. I'm working with python - TensorFlow '2.2.0' on python IDLE. I got the following error while running the previous code.: however, according to example 18 from this link on the official page on Tensorflow, there's no error! what's wrong in my case? How should I resolve this issue?",https://stackoverflow.com/questions/61561253,13454942,Requesting (Additional) Resources,Documentation Replication on Other Examples,"However, according to example 18 from this link on the official page on Tensorflow, there's no error! what's wrong in my case? "
61767723,get_config missing while loading previously saved model without custom layers,"<p>I have a problem with loading the previously saved model.</p>

<p>This is my save:</p>

<pre><code>def build_rnn_lstm_model(tokenizer, layers):
    model = tf.keras.Sequential([
        tf.keras.layers.Embedding(len(tokenizer.word_index) + 1, layers,input_length=843),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(layers, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))),
        tf.keras.layers.Dense(layers, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),
        tf.keras.layers.Dense(layers/2, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    model.summary()
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1,precision, recall])
    print(""Layers: "", len(model.layers))
    return model

model_path = str(Path(__file__).parents[2]) + os.path.sep + 'model'
data_train_sequence, data_test_sequence, labels_train, labels_test, tokenizer = get_training_test_data_local()
model = build_rnn_lstm_model(tokenizer, 32)
model.fit(data_train_sequence, labels_train, epochs=num_epochs, validation_data=(data_test_sequence, labels_test))
model.save(model_path + os.path.sep + 'auditor_model', save_format='tf')
</code></pre>

<p>After this I can see that <code>auditor_model</code> is saved in <code>model</code> directory.</p>

<p>now I would like to load this model with:</p>

<pre><code>model = tf.keras.models.load_model(model_path + os.path.sep + 'auditor_model')
</code></pre>

<p>but I get:</p>

<blockquote>
  <p>ValueError: Unable to restore custom object of type _tf_keras_metric
  currently. Please make sure that the layer implements <code>get_config</code>and
  <code>from_config</code> when saving. In addition, please use the
  <code>custom_objects</code> arg when calling <code>load_model()</code>.</p>
</blockquote>

<p>I have read about <code>custom_objects</code> in <code>TensorFlow</code> docs but I don't understand how to implement it while I use no custom layers but the predefined ones.</p>

<p>Could anyone give me a hint how to make it work? I use TensorFlow 2.2 and Python3</p>
",I have a problem with loading the previously saved model. This is my save: After this I can see that auditor_model is saved in model directory. now I would like to load this model with: but I get: I have read about custom_objects in TensorFlow docs but I don't understand how to implement it while I use no custom layers but the predefined ones. Could anyone give me a hint how to make it work? I use TensorFlow 2.2 and Python3,https://stackoverflow.com/questions/61767723,1394504,Documentation Ambiguity,Documentation Replication on Other Examples,I have read about custom_objects in TensorFlow docs but I don't understand how to implement it while I use no custom layers but the predefined ones.
62008061,TypeError when fitting keras model,"<p>I am a new to tensorflow, I am trying to build a simple neural network. But every time I get close, there are a list of errors stopping me. I followed tutorials and documentations and kept most of the code and changed only things I need to.</p>

<p>Here is my code:</p>

<pre><code>###
# Import
###

import tensorflow as tf
import pandas as pd
from tensorflow import keras

###
# Loading Data
###


# Training Data

# path of the training data
train_data_path = ""C:/Users/User/Desktop/Machine_Learning/Neural_Network/addition_train_data.csv""
train_data = pd.read_csv(train_data_path)  # loads the data using pandas

# Evalution Data

# path of the evalution data
eval_data_path = ""C:/Users/User/Desktop/Machine_Learning/Neural_Network/addition_eval_data.csv""
eval_data = pd.read_csv(eval_data_path)  # loads the data using pandas (again)


# Target Columns
train_target = train_data.pop(""Sum"")
eval_target = eval_data.pop(""Sum"")


###
# Creating the Model
###

model = keras.Sequential()
model.add(keras.layers.Flatten(input_shape=(35, 2)))
model.add(keras.layers.Lambda(
    lambda x: tf.expand_dims(model.output, axis=-1)))
model.add(keras.layers.Dense(10, activation=""tanh""))
model.add(keras.layers.Dense(1, activation=""tanh""))

###
# Compiling the Model
###

model.compile(
    optimizer='adam',
    loss='mean_absolute_error',
    metrics=['accuracy']
)

###
# Training the Model
###

model.fit(
    eval_data, eval_target, epochs=10
)
</code></pre>

<p>Console Output:</p>

<pre><code>2020-05-25 10:53:35.491127: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not 
load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found                                                           
2020-05-25 10:53:35.493137: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart 
dlerror if you do not have a GPU set up on your machine.                                                                                
2020-05-25 10:53:37.162913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully 
opened dynamic library nvcuda.dll                                                                                                   
2020-05-25 10:53:37.194951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with 
properties:                                                                                                                         
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5                                                                                                                                                                         
coreClock: 1.755GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s                                                                                                                                               
2020-05-25 10:53:37.200604: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not 
load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found                                                           
2020-05-25 10:53:37.206365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully 
opened dynamic library cublas64_10.dll                                                                                              
2020-05-25 10:53:37.212086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully 
opened dynamic library cufft64_10.dll                                                                                               
2020-05-25 10:53:37.214531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully 
opened dynamic library curand64_10.dll                                                                                              
2020-05-25 10:53:37.219340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully 
opened dynamic library cusolver64_10.dll                                                                                            
2020-05-25 10:53:37.224932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully 
opened dynamic library cusparse64_10.dll                                                                                            
2020-05-25 10:53:37.233220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully 
opened dynamic library cudnn64_7.dll                                                                                                
2020-05-25 10:53:37.235711: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some 
GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would 
like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup 
the required libraries for your platform.                                                                                                                     
Skipping registering GPU devices...                                                                                                                                                                                                          
2020-05-25 10:53:37.241553: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports 
instructions that this TensorFlow binary was not compiled to use: AVX2                                                                    
2020-05-25 10:53:37.249295: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d9e0a5c5f0 
initialized for platform Host (this does not guarantee that XLA will be used). Devices:                                              
2020-05-25 10:53:37.252889: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device 
(0): Host, Default Version                                                                                                             
2020-05-25 10:53:37.255179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect 
StreamExecutor with strength 1 edge matrix:                                                                                         
2020-05-25 10:53:37.258151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]                                                                                                                                                         
Epoch 1/10                                                                                                                                                                                                                                   
WARNING:tensorflow:Model was constructed with shape (None, 35, 2) for input Tensor(""flatten_input:0"", 
shape=(None, 35, 2), dtype=float32), but it was called on an input with incompatible shape (None, 2).                                  
WARNING:tensorflow:Model was constructed with shape (None, 35, 2) for input Tensor(""flatten_input:0"", 
shape=(None, 35, 2), dtype=float32), but it was called on an input with incompatible shape (None, 2).                                  
Traceback (most recent call last):                                                                                                                                                                                                             
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in 
quick_execute                                                                                                                                 
inputs, attrs, num_outputs)                                                                                                                                                                                                              
TypeError: An op outside of the function building code is being passed                                                                                                                                                                       
a ""Graph"" tensor. It is possible to have Graph tensors                                                                                                                                                                                       
leak out of the function building context by including a                                                                                                                                                                                     
tf.init_scope in your function building code.                                                                                                                                                                                                
For example, the following function will fail:                                                                                                                                                                                                 
@tf.function                                                                                                                                                                                                                                 
def has_init_scope():                                                                                                                                                                                                                          
my_constant = tf.constant(1.)                                                                                                                                                                                                                
with tf.init_scope():                                                                                                                                                                                                                          
added = my_constant * 2                                                                                                                                                                                                                
The graph tensor has name: dense_1/Identity:0                                                                                                                                                                                                                                                                                                                                                                                                                                             
During handling of the above exception, another exception occurred:                                                                                                                                                                                                                                                                                                                                                                                                                       
Traceback (most recent call last):                                                                                                                                                                                                             
File ""addition.py"", line 58, in &lt;module&gt;                                                                                                                                                                                                       
eval_data, eval_target, epochs=10                                                                                                                                                                                                          
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 66, in 
_method_wrapper                                                                                                                       
return method(self, *args, **kwargs)                                                                                                                                                                                                       
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 848, in 
fit                                                                                                                                  
tmp_logs = train_function(iterator)                                                                                                                                                                                                        
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 580, in 
__call__                                                                                                                                
result = self._call(*args, **kwds)                                                                                                                                                                                                         
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 644, in 
_call                                                                                                                                   
return self._stateless_fn(*args, **kwds)                                                                                                                                                                                                   
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 2420, in 
__call__                                                                                                                                   
return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access                                                                                                                                                     
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1665, in 
_filtered_call                                                                                                                             
self.captured_inputs)                                                                                                                                                                                                                      
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1746, in 
_call_flat                                                                                                                                 
ctx, args, cancellation_manager=cancellation_manager))                                                                                                                                                                                     
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 598, in call                                                                                                                                        
ctx=ctx)                                                                                                                                                                                                                                   
File ""C:\Users\User\anaconda3\lib\site-packages\tensorflow\python\eager\execute.py"", line 74, in 
quick_execute                                                                                                                                 
""tensors, but found {}"".format(keras_symbolic_tensors))                                                                                                                                                                                  
tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras 
symbolic tensors, but found [&lt;tf.Tensor 'dense_1/Identity:0' shape=(None, 70, 1) dtype=float32&gt;]
</code></pre>

<p>Any help, tips, and advice is greatly appreciated.</p>
","I am a new to tensorflow, I am trying to build a simple neural network. But every time I get close, there are a list of errors stopping me. I followed tutorials and documentations and kept most of the code and changed only things I need to. Here is my code: Console Output: Any help, tips, and advice is greatly appreciated.",https://stackoverflow.com/questions/62008061,8620607,Documentation Replication on Other Examples,Documentation Replication on Other Examples,I followed tutorials and documentations and kept most of the code and changed only things I need to.
62704943,Tensorflow Custom Gradient in a Custom Layer,"<p>I am setting up a custom layer with a custom gradient. The inputs are a single 2-D tensor of shape (?, 2). The outputs are also a single 2-D tensor with shape (?, 2).</p>
<p>I am struggling with understanding how these objects behave. What I've gathered from the documentation is that for a given input, the gradient will have the same shape as the output and that I need to return a list of gradients for each input. I've been assuming that since my inputs look like (?, 2) and my outputs look like (?, 2), then the grad function should return a length-2 list: [input_1_grad, input_2_grad], where both list items are tensors with the shape of the output, (?, 2).</p>
<p>This is not working, which is why I'm hoping someone here could help.</p>
<p>Here is my error (appears to occur at compile time):</p>
<blockquote>
<p>ValueError: Num gradients 3 generated for op name:
&quot;custom_layer/IdentityN&quot; op: &quot;IdentityN&quot; input:
&quot;custom_layer_2/concat&quot; input: &quot;custom_layer_1/concat&quot; attr {   key:
&quot;T&quot;   value {
list {
type: DT_FLOAT
type: DT_FLOAT
}   } } attr {   key: &quot;_gradient_op_type&quot;   value {
s: &quot;CustomGradient-28729&quot;   } }  do not match num inputs 2</p>
</blockquote>
<p>The other wrinkle is that the input to the custom layer is itself also a custom layer (though without a custom gradient). I will provide the code for both layers, in case it's helpful.</p>
<p>Also, note that the network compiles and runs if I don't try to specify a custom gradient. But, since my functions need help differentiating themselves, I need to manually intervene, so having a working custom gradient is critical.</p>
<p><strong>First Custom Layer (no custom gradient):</strong></p>
<pre><code>class custom_layer_1(tensorflow.keras.layers.Layer):
    def __init__(self):
        super(custom_layer_1, self).__init__()
    
    def build(self, input_shape):
        self.term_1 = self.add_weight('term_1', trainable=True)
        self.term_2 = self.add_weight('term_2', trainable=True)
    
    def call(self, x):
        self.term_1 = formula in terms of x
        self.term_2 = another formula in terms of x
        
        return tf.concat([self.term_1, self.term_2], axis=1)
</code></pre>
<p><strong>Second Custom Layer (with the custom gradient):</strong></p>
<pre><code>class custom_layer_2(tensorflow.keras.layers.Layer):
    ### the inputs
    # x is the concatenation of term_1 and term_2
    def __init__(self):
        super(custom_layer_2, self).__init__()
    
    def build(self, input_shape):
        #self.weight_1 = self.add_weight('weight_1', trainable=True)
        #self.weight_2 = self.add_weight('weight_2', trainable=True)
    
    def call(self, x):
        return custom_function(x)
</code></pre>
<p><strong>The Custom Function:</strong></p>
<pre><code>@tf.custom_gradient
def custom_function(x):
    ### the inputs
    # x is a concatenation of term_1 and term_2
    
    weight_1 = function in terms of x
    weight_2 = another function in terms of x
    
    ### the gradient
    def grad(dy):
        # assuming dy has the output shape of (?, 2). could be wrong.
        d_weight_1 = K.reshape(dy[:, 0], shape=(K.shape(x)[0], 1))
        d_weight_1 = K.reshape(dy[:, 1], shape=(K.shape(x)[0], 1))
        
        term_1 = K.reshape(x[:, 0], shape=(K.shape(x)[0], 1))
        term_2 = K.reshape(x[:, 1], shape=(K.shape(x)[0], 1))
        
        d_weight_1_d_term_1 = tf.where(K.equal(term_1, K.zeros_like(term_1)), K.zeros_like(term_1), -term_2 / term_1) * d_weight_1
        d_weight_1_d_term_2 = tf.where(K.equal(term_1, K.zeros_like(term_1)), K.zeros_like(term_1), 1 / term_1) * d_weight_1
        
        d_weight_2_d_term_1 = tf.where(K.equal(term_2, K.zeros_like(term_2)), K.zeros_like(term_1), 2 * term_1 / term_2) * d_weight_2
        d_weight_2_d_term_2 = tf.where(K.equal(term_2, K.zeros_like(term_2)), K.zeros_like(term_1), -K.square(term_1 / term_2)) * d_weight_2
        
        return tf.concat([d_weight_1_d_term_1, d_weight_1_d_term_2], axis=1), tf.concat([d_weight_2_d_term_1, d_weight_2_d_term_2], axis=1)
  
  return tf.concat([weight_1, weight_2], axis=1), grad
</code></pre>
<p>Any help would be much appreciated!</p>
","I am setting up a custom layer with a custom gradient. The inputs are a single 2-D tensor of shape (?, 2). The outputs are also a single 2-D tensor with shape (?, 2). I am struggling with understanding how these objects behave. What I've gathered from the documentation is that for a given input, the gradient will have the same shape as the output and that I need to return a list of gradients for each input. I've been assuming that since my inputs look like (?, 2) and my outputs look like (?, 2), then the grad function should return a length-2 list: [input_1_grad, input_2_grad], where both list items are tensors with the shape of the output, (?, 2). This is not working, which is why I'm hoping someone here could help. Here is my error (appears to occur at compile time): The other wrinkle is that the input to the custom layer is itself also a custom layer (though without a custom gradient). I will provide the code for both layers, in case it's helpful. Also, note that the network compiles and runs if I don't try to specify a custom gradient. But, since my functions need help differentiating themselves, I need to manually intervene, so having a working custom gradient is critical. First Custom Layer (no custom gradient): Second Custom Layer (with the custom gradient): The Custom Function: Any help would be much appreciated!",https://stackoverflow.com/questions/62704943,13855733,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I am struggling with understanding how these objects behave. What I've gathered from the documentation is that for a given input, the gradient will have the same shape as the output and that I need to return a list of gradients for each input. "
62912769,Min_delta on callbacks function of Keras model seems to not take effect,"<p>I am using the following callbacks function on a Keras model and I initialize the minimum delta to 0.002, so based on the documentation of Tensorflow/Keras any improvement in the validation loss function less than 0.002 won't be counted for an improvement. However, this seems to not get implemented in my case.</p>
<p>callback function:</p>
<pre class=""lang-py prettyprint-override""><code>def callback(folder_path, saved_model_name, patience_value, logdir, hparams):
    
    # Initialize parameters
    monitor_metric = 'val_loss'
    minimum_delta = 0.002
    patience_limit = patience_value
    verbose_value = 1
    mode_value = 'min'
    weights_fname = os.path.join(os.getcwd(), '{0}/{1}.h5'.format(folder_path, saved_model_name))
    
    # Initialize callbacks
    callbacks = [
        
        EarlyStopping(monitor=monitor_metric,
                      min_delta=minimum_delta,
                      patience=patience_limit,
                      verbose=verbose_value,
                      mode=mode_value,
                      restore_best_weights=True),

        ModelCheckpoint(filepath=weights_fname,
                        monitor=monitor_metric,
                        verbose=verbose_value,
                        save_best_only=True,
                        save_weights_only=True),
        
        tf.keras.callbacks.TensorBoard(logdir),
        
        hp.KerasCallback(logdir, hparams)
    ]
    
    return callbacks
</code></pre>
<p>The output per training epoch</p>
<p><a href=""https://i.stack.imgur.com/K4U1q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/K4U1q.png"" alt=""enter image description here"" /></a></p>
<p>You can see that in two highlighted epochs the validation loss improved from</p>
<ul>
<li>0.02129 - 0.02015 = 0.00114 &lt; 0.002 (although it was counted as an improvement)</li>
<li>0.01880 - 0.01803 = 0.00077 &lt; 0.002 (also counted as an improvement in validation loss)</li>
</ul>
<p>What is going wrong?</p>
<p>Please also check my colab <a href=""https://colab.research.google.com/drive/1FqQjjB2xFFQCiAqZacvVsl5SU0kcJwGd?usp=sharing"" rel=""nofollow noreferrer"">notebook</a>, in order to check the whole training process</p>
","I am using the following callbacks function on a Keras model and I initialize the minimum delta to 0.002, so based on the documentation of Tensorflow/Keras any improvement in the validation loss function less than 0.002 won't be counted for an improvement. However, this seems to not get implemented in my case. callback function: The output per training epoch You can see that in two highlighted epochs the validation loss improved from What is going wrong? Please also check my colab notebook, in order to check the whole training process",https://stackoverflow.com/questions/62912769,10623444,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I am using the following callbacks function on a Keras model and I initialize the minimum delta to 0.002, so based on the documentation of Tensorflow/Keras any improvement in the validation loss function less than 0.002 won't be counted for an improvement. However, this seems to not get implemented in my case."
63758810,Use my model to predict output in tensor flow 2 without using keras,"<p>I am new to TensorFlow and I have a very basic question. I have found several posts regarding this question for the previous TensorFlow versions but I could not use the answer for TensorFlow 2 which I am using. The examples I found in the documentation in the original site use Keras.</p>
<p>Now, about my question, say, I have built my own model using only TensorFlow without using Keras. I have finished training my model and now I want to use my trained model to predict output for some input I give.</p>
<p>I am starting out very simple in order to learn to use TensorFlow 2. I am stuck here and it would be of great help if someone provides me a solution. I have attached my snippet of code herewith.</p>
<pre><code># Defining input and output placeholders
x = tf.compat.v1.placeholder(tf.float32, shape=(128, 128, 1, 1)) # Placeholder for input
y = tf.compat.v1.placeholder(tf.float32, shape=(128, 128, 1, 1)) # Placeholder for ground truth 

inp = np.ones([128,128,1,1]).astype(np.float32) # Dummy input dataset I made
                                                # I will use it both for input and ground truth to train my model
# My neural network model
pred = my_model(x)

# Defining my optimizer, I am using gradient descent and l2 norm loss
l2_loss = tf.nn.l2_loss(tf.subtract(pred, y), name=None)
optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.000001

# Training the model
training_iters = 300
init = tf.compat.v1.global_variables_initializer()
with tf.compat.v1.Session() as sess:
  sess.run(init)
  summary_writer = tf.compat.v1.summary.FileWriter('./Output', sess.graph)
  for i in range(training_iters):
        dataset_dict = {x: inp, y: batch_y}
        opt = sess.run(optimizer.minimize(l2_loss), feed_dict = dataset_dict)
        loss = sess.run(l2_loss, feed_dict={x: batch_x, y: batch_y})
        print(loss)
  summary_writer.close()

# Use my trained model to predict output for some input I give
# ??
# ??
</code></pre>
","I am new to TensorFlow and I have a very basic question. I have found several posts regarding this question for the previous TensorFlow versions but I could not use the answer for TensorFlow 2 which I am using. The examples I found in the documentation in the original site use Keras. Now, about my question, say, I have built my own model using only TensorFlow without using Keras. I have finished training my model and now I want to use my trained model to predict output for some input I give. I am starting out very simple in order to learn to use TensorFlow 2. I am stuck here and it would be of great help if someone provides me a solution. I have attached my snippet of code herewith.",https://stackoverflow.com/questions/63758810,7341905,Documentation Replicability,Documentation Replication on Other Examples,"The examples I found in the documentation in the original site use Keras. Now, about my question, say, I have built my own model using only TensorFlow without using Keras."
65013199,StopIteration error while trying to build data input for a model,"<pre><code>from __future__ import print_function

import tensorflow as tf
import os

#Dataset Parameters - CHANGE HERE
MODE = 'folder' # or 'file', if you choose a plain text file (see above).
DATASET_PATH = &quot;D:\\Downloads\\Work\\&quot; # the dataset file or root folder path.

# Image Parameters
N_CLASSES = 7 # CHANGE HERE, total number of classes
IMG_HEIGHT = 64 # CHANGE HERE, the image height to be resized to
IMG_WIDTH = 64 # CHANGE HERE, the image width to be resized to
CHANNELS = 3 # The 3 color channels, change to 1 if grayscale

# Reading the dataset
# 2 modes: 'file' or 'folder'
def read_images(dataset_path, mode, batch_size):
    imagepaths, labels = list(), list()
    if mode == 'file':
        # Read dataset file
        data = open(dataset_path, 'r').read().splitlines()
        for d in data:
            imagepaths.append(d.split(' ')[0])
            labels.append(int(d.split(' ')[1]))
    elif mode == 'folder':
        # An ID will be affected to each sub-folders by alphabetical order
        label = 0
        # List the directory
        #try:  # Python 2
        classes = next(os.walk(dataset_path))[1]
        #except Exception:  # Python 3
        #    classes = sorted(os.walk(dataset_path).__next__()[1])
        # List each sub-directory (the classes)
        for c in classes:
            c_dir = os.path.join(dataset_path, c)
            try:  # Python 2
                walk = os.walk(c_dir).next()
            except Exception:  # Python 3
                walk = os.walk(c_dir).__next__()
            # Add each image to the training set
            for sample in walk[2]:
                # Only keeps jpeg images
                if sample.endswith('.bmp'):
                    imagepaths.append(os.path.join(c_dir, sample))
                    labels.append(label)
            label += 1
    else:
        raise Exception(&quot;Unknown mode.&quot;)

    # Convert to Tensor
    imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)
    labels = tf.convert_to_tensor(labels, dtype=tf.int32)
    # Build a TF Queue, shuffle data
    image, label = tf.train.slice_input_producer([imagepaths, labels],
                                                 shuffle=True)

    # Read images from disk
    image = tf.read_file(image)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)

    # Resize images to a common size
    image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])

    # Normalize
    image = image * 1.0/127.5 - 1.0

    # Create batches
    X, Y = tf.train.batch([image, label], batch_size=batch_size,
                          capacity=batch_size * 8,
                          num_threads=4)

    return X, Y

# Parameters
learning_rate = 0.001
num_steps = 10000
batch_size = 32
display_step = 100

# Network Parameters
dropout = 0.75 # Dropout, probability to keep units

# Build the data input
X, Y = read_images(DATASET_PATH, MODE, batch_size)
</code></pre>
<p>Gives an error</p>
<pre><code>StopIteration                             Traceback (most recent call last)
&lt;ipython-input-27-510f945ab86c&gt; in &lt;module&gt;()
      9 
     10 # Build the data input
---&gt; 11 X, Y = read_images(DATASET_PATH, MODE, batch_size)

&lt;ipython-input-26-c715e653cf59&gt; in read_images(dataset_path, mode, batch_size)
     14         # List the directory
     15         #try:  # Python 2
---&gt; 16         classes = next(os.walk(dataset_path))[1]
     17         #except Exception:  # Python 3
     18         #    classes = sorted(os.walk(dataset_path).__next__()[1])

StopIteration: 
</code></pre>
<p>I saw the documentation for next() and found that you can no longer use at as .next but after correction, it still gives me StopIteration error
I checked the value of <em>classes</em> on my local Python and it gives me a list ['Class0', 'Class1', 'Class2', 'Class3', 'Class4', 'Class5', 'Class6']</p>
","Gives an error I saw the documentation for next() and found that you can no longer use at as .next but after correction, it still gives me StopIteration error I checked the value of classes on my local Python and it gives me a list ['Class0', 'Class1', 'Class2', 'Class3', 'Class4', 'Class5', 'Class6']",https://stackoverflow.com/questions/65013199,14709369,Documentation Completeness,Documentation Replication on Other Examples,"Gives an error I saw the documentation for next() and found that you can no longer use at as .next but after correction, it still gives me StopIteration error"
65716925,Tensorflow dataset from numpy array,"<p>I have two numpy Arrays (X, Y) which I want to convert to a tensorflow dataset. <a href=""https://www.tensorflow.org/tutorials/load_data/numpy#load_numpy_arrays_with_tfdatadataset"" rel=""nofollow noreferrer"">According to the documentation</a> it should be possible to run</p>
<pre><code>train_dataset = tf.data.Dataset.from_tensor_slices((X, Y))
model.fit(train_dataset)
</code></pre>
<p>When doing this however I get the error:
<code>ValueError: Shapes (15, 1) and (768, 15) are incompatible</code></p>
<p>This would make sense if the shapes of the numpy Arrays would be incompatible to the expected inputs/outputs.
But if I run it with the numpy arrays by using <code>model.fit(X,Y)</code> it runs without any problems, so the shapes seem to be okay.</p>
<p>In a next step I checked the output sizes:</p>
<pre><code>&gt;&gt;&gt; train_dataset.batch(4)
&lt;BatchDataset shapes: ((None, 768), (None, 15)), types: (tf.int64, tf.uint8)&gt;
</code></pre>
<p>The input layer for the neural network expect (None, None) and the output (None, 15). So this also seems to match.</p>
<p>My dataset is rather large, so it's difficult to share that, but here is a minimal reproducible example which shows the problem. It's the same error, and the fit with just the numpy arrays works.</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras import Model
import numpy as np

a = np.random.randint(10,size=(10,20,1))
b = np.random.rand(10,15)
train_dataset = tf.data.Dataset.from_tensor_slices((a,b))

inp = Input(shape=(None,), dtype=&quot;int32&quot;)
embedding = Embedding(12, 300, trainable=False, mask_zero=True)(inp)
gru = Bidirectional(GRU(128, recurrent_dropout=0.5))(embedding)
out = Dense(64, activation=tf.nn.relu)(gru)
out = Dropout(0.5)(out)
out = Dense(15, activation='sigmoid')(out)
m = Model(inputs=inp, outputs = out)
m.compile(&quot;adam&quot;, 'categorical_crossentropy')

m.fit(a,b)
m.fit(train_dataset)
</code></pre>
<p>Can someone point me into the right direction on how to solve this?</p>
<p>Tensorflow version is 2.3.1.</p>
","I have two numpy Arrays (X, Y) which I want to convert to a tensorflow dataset. According to the documentation it should be possible to run When doing this however I get the error: ValueError: Shapes (15, 1) and (768, 15) are incompatible This would make sense if the shapes of the numpy Arrays would be incompatible to the expected inputs/outputs. But if I run it with the numpy arrays by using model.fit(X,Y) it runs without any problems, so the shapes seem to be okay. In a next step I checked the output sizes: The input layer for the neural network expect (None, None) and the output (None, 15). So this also seems to match. My dataset is rather large, so it's difficult to share that, but here is a minimal reproducible example which shows the problem. It's the same error, and the fit with just the numpy arrays works. Can someone point me into the right direction on how to solve this? Tensorflow version is 2.3.1.",https://stackoverflow.com/questions/65716925,5632058,Documentation Replication on Other Examples,Documentation Replication on Other Examples,According to the documentation it should be possible to run. When doing this however I get the error:
66320198,Keras fit with generator function always execute in the main thread,"<p>How can I make Keras Models <code>fit</code> method execute a generator in the main thread? From the docs, it looks like that setting workers=0 would execute the code in the main thread.</p>
<blockquote>
<p>workers   Integer. Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1. <strong>If 0, will execute the generator on the main thread.</strong></p>
</blockquote>
<p>However when I do:</p>
<pre><code>import tensorflow as tf
import threading
model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(loss = &quot;mse&quot;, optimizer = &quot;adam&quot;)

def gen ():
  for i in range(100):
    print(threading.current_thread())
    yield (tf.random.normal(shape=(100,1)), tf.random.normal(shape = (100,)))

model.fit(gen(), epochs = 1, workers = 0, verbose = 0, steps_per_epoch = 3)
</code></pre>
<p>I get</p>
<pre><code>&lt;_MainThread(MainThread, started 140516450817920)&gt;
&lt;_DummyThread(Dummy-5, started daemon 140514709206784)&gt;
&lt;_DummyThread(Dummy-4, started daemon 140514717599488)&gt;
&lt;tensorflow.python.keras.callbacks.History at 0x7fcc1e8a8d68&gt;
</code></pre>
<p>Which I interpret as only the first step in the iterator has been executed in the main thread.</p>
<p>In my use case this is problematic because I need that the code inside the generator to always be executed in the main thread otherwise the program crashes.</p>
","How can I make Keras Models fit method execute a generator in the main thread? From the docs, it looks like that setting workers=0 would execute the code in the main thread. However when I do: I get Which I interpret as only the first step in the iterator has been executed in the main thread. In my use case this is problematic because I need that the code inside the generator to always be executed in the main thread otherwise the program crashes.",https://stackoverflow.com/questions/66320198,3297472,Lack of Alternative Solutions/Documentation,Documentation Replication on Other Examples,"From the docs, it looks like that setting workers=0 would execute the code in the main thread. However when I do:"
67275213,3d input for Dense Layer Keras,"<p>Is there any example of how Keras <code>Dense</code> layer handles <code>3D</code> input.</p>
<p>The documentation explains the following:</p>
<blockquote>
<p>If the input to the layer has a rank greater than 2, then Dense
computes the dot product between the inputs and the kernel along the
last axis of the inputs and axis 1 of the kernel (using tf.tensordot).</p>
</blockquote>
<p>But I could not understand the internal <code>matrix calculation</code></p>
<p>For example:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Dense
sample_3d_input = tf.constant(tf.random.normal(shape=(4,3,2)))
dense_layer  = Dense(5)
op = dense_layer(sample_3d_input)
</code></pre>
<p>based on the documentation for a <code>3D</code> input of shape <code>(m,d0,d1)</code>, the shape of <code>Layer's weight_matrix (or) kernel</code> will have the shape <code>(d1, units) which is (2,5)</code> in this case. But I don't understand how the op is calculated to have the shape <code>(m,d0, units)</code></p>
","Is there any example of how Keras Dense layer handles 3D input. The documentation explains the following: But I could not understand the internal matrix calculation For example: based on the documentation for a 3D input of shape (m,d0,d1), the shape of Layer's weight_matrix (or) kernel will have the shape (d1, units) which is (2,5) in this case. But I don't understand how the op is calculated to have the shape (m,d0, units)",https://stackoverflow.com/questions/67275213,5927701,Documentation Ambiguity,Documentation Replication on Other Examples,"Based on the documentation for a 3D input of shape (m,d0,d1), the shape of Layer's weight_matrix (or) kernel will have the shape (d1, units) which is (2,5) in this case. But I don't understand how the op is calculated to have the shape (m,d0, units)"
67497418,TensorFlow accuracy metrics,"<p>The following is a very simple <code>TensorFlow</code> 2 image classification model.
Note that the loss function is not the usual <code>SparseCategoricalCrossentropy</code>. Also, the last layer has only 1 output, so this is not the usual classification setting. The accuracy here does not have meaning, but I am just curious.</p>
<p>So this code does not work well as we expected, but still produces outputs with an accuracy of around 10%, which seems reasonable.</p>
<p>My question is how this accuracy is calculated? The prediction from this model is a continuous value and the y_true is an integer value. It is not impossible to have an x.0 for the prediction, then the accuracy is too high.</p>
<pre><code>import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1)
])

model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])

model.fit(x_train, y_train, epochs=10)

===

Epoch 1/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8237 - accuracy: 0.0922
Epoch 2/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8266 - accuracy: 0.0931
Epoch 3/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8335 - accuracy: 0.0921
Epoch 4/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8109 - accuracy: 0.0931
Epoch 5/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8210 - accuracy: 0.0926
Epoch 6/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8067 - accuracy: 0.0921
Epoch 7/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8028 - accuracy: 0.0925
Epoch 8/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8070 - accuracy: 0.0929
Epoch 9/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.7879 - accuracy: 0.0925
Epoch 10/10
1875/1875 [==============================] - 3s 1ms/step - loss: 1.8055 - accuracy: 0.0914
&lt;tensorflow.python.keras.callbacks.History at 0x7f65db17df10&gt;
</code></pre>
<p>So, I have searched the <code>TensorFlow</code> API document to find the following example. And it makes sense.</p>
<pre><code>m = tf.keras.metrics.Accuracy()
m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [4]])
m.result().numpy()

===

0.75
</code></pre>
<p>So I have tried the following code and get the 0.0 accuracy.</p>
<pre><code>m = tf.keras.metrics.Accuracy()
m.update_state(model.predict(x_train), y_train)
m.result().numpy()

===

0.0
</code></pre>
<p>Is there any explanation for this?</p>
","The following is a very simple TensorFlow 2 image classification model. Note that the loss function is not the usual SparseCategoricalCrossentropy. Also, the last layer has only 1 output, so this is not the usual classification setting. The accuracy here does not have meaning, but I am just curious. So this code does not work well as we expected, but still produces outputs with an accuracy of around 10%, which seems reasonable. My question is how this accuracy is calculated? The prediction from this model is a continuous value and the y_true is an integer value. It is not impossible to have an x.0 for the prediction, then the accuracy is too high. So, I have searched the TensorFlow API document to find the following example. And it makes sense. So I have tried the following code and get the 0.0 accuracy. Is there any explanation for this?",https://stackoverflow.com/questions/67497418,11381722,Requesting (Additional) Resources,Documentation Replication on Other Examples,I have searched the TensorFlow API document to find the following example. And it makes sense. So I have tried the following code and get the 0.0 accuracy.
69709010,"Keras/Conv2D: Strange, I use padding=SAME, but the size is still reduced","<p>I set padding to SAME or same, but the output is still being reduced, what's wrong then?
😅, as I understand according to the official doc, the output size shall be the same to the input one, do I forget what is important?</p>
<pre><code>import tensorflow as tf

x = tf.keras.Input([120, 120, 3])

conv = tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3), strides=(2, 2), padding=&quot;SAME&quot;)(x)
conv = tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3), strides=(2, 2), padding=&quot;SAME&quot;)(conv)

model = tf.keras.Model(inputs=[x], outputs=[conv])

model.summary()

image_batch = tf.random.normal(shape=[10, 120, 120, 3])
y_pred = model(image_batch)
print(y_pred.shape)
</code></pre>
<p>Output</p>
<pre class=""lang-py prettyprint-override""><code>odel: &quot;model_7&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 120, 120, 3)]     0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 60, 60, 3)         84        
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 30, 30, 3)         84        
=================================================================
Total params: 168
Trainable params: 168
Non-trainable params: 0
_________________________________________________________________
(10, 30, 30, 3)
</code></pre>
","I set padding to SAME or same, but the output is still being reduced, what's wrong then? 😅, as I understand according to the official doc, the output size shall be the same to the input one, do I forget what is important? Output",https://stackoverflow.com/questions/69709010,1835650,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"as I understand according to the official doc, the output size shall be the same to the input one, do I forget what is important? "
70495270,"ValueError: Dimensions must be equal, but are 100 and 19 with input shapes: [?,100], [?,100,19]","<p>I have an error in my code, and I've done read the documentation but it still error, How this error can be fixed?</p>
<p><strong>Code:</strong></p>
<pre><code>import tensorflow.keras.backend as K
import tensorflow_addons as tfa
from tensorflow_addons.layers import CRF
from keras_crf import CRFModel
def create_model(): #
  max_words=length_long_sentence
  MAX_SENTENCE_NUM=100
  embedding_size=100
  lstm_size=128
  learn_rate=0.01
  output_size=len(unique_tag_set)

  current_input=Input(shape=(MAX_SENTENCE_NUM,max_words,)) 
  emb_current = Embedding(vocab_size, embedding_size, weights= 
  [embedding_matrix],input_length=max_words, name='current_embed',trainable=False)(current_input)
  hidden_vectors=TimeDistributed(Bidirectional(LSTM(units=lstm_size, return_sequences=False))) 
  (emb_current ) 
  hidden_vectors=Bidirectional(LSTM(units=lstm_size, return_sequences=True))(hidden_vectors ) 
  
  base = tf.keras.Model(inputs=current_input, outputs=hidden_vectors)
  model = CRFModel(base, 19)
  opt = tf.keras.optimizers.Adam(learning_rate=learn_rate)
  model.compile(optimizer=opt, metrics=['acc'])
  print(model.summary())
  return model
model_2=create_model()
</code></pre>
<p>and here is the model summary:
<a href=""https://i.stack.imgur.com/umzIB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/umzIB.png"" alt=""enter image description here"" /></a></p>
<p>Here is the code to fit in training data:</p>
<pre><code>history_2=model_2.fit(x_train_split,y_train_split,
                    epochs=1,batch_size=16,
                    shuffle = False, verbose = 1,
                    validation_split=0.2,
                    sample_weight=sample_weights)
</code></pre>
<p>And I got this error:</p>
<p>ValueError: in user code:</p>
<pre><code>File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 878, in train_function  *
    return step_function(self, iterator)
File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 867, in step_function  **
    outputs = model.distribute_strategy.run(run_step, args=(data,))
File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 860, in run_step  **
    outputs = model.train_step(data)
File &quot;/usr/local/lib/python3.7/dist-packages/keras_crf/crf_model.py&quot;, line 49, in train_step
    crf_loss = -tfa.text.crf_log_likelihood(potentials, y, sequence_length, kernel)[0]
File &quot;/usr/local/lib/python3.7/dist-packages/tensorflow_addons/text/crf.py&quot;, line 242, in crf_log_likelihood
    inputs, tag_indices, sequence_lengths, transition_params
File &quot;/usr/local/lib/python3.7/dist-packages/tensorflow_addons/text/crf.py&quot;, line 104, in crf_sequence_score
    return tf.cond(tf.equal(tf.shape(inputs)[1], 1), _single_seq_fn, _multi_seq_fn)
File &quot;/usr/local/lib/python3.7/dist-packages/tensorflow_addons/text/crf.py&quot;, line 97, in _multi_seq_fn
    unary_scores = crf_unary_score(tag_indices, sequence_lengths, inputs)
File &quot;/usr/local/lib/python3.7/dist-packages/tensorflow_addons/text/crf.py&quot;, line 277, in crf_unary_score
    flattened_tag_indices = tf.reshape(offsets + tag_indices, [-1])

ValueError: Dimensions must be equal, but are 100 and 19 for '{{node cond/add_1}} = AddV2[T=DT_INT32](cond/add, cond/add_1/Cast)' with input shapes: [?,100], [?,100,19].
</code></pre>
","I have an error in my code, and I've done read the documentation but it still error, How this error can be fixed? Code: and here is the model summary: Here is the code to fit in training data: And I got this error: ValueError: in user code:",https://stackoverflow.com/questions/70495270,3499140,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I have an error in my code, and I've done read the documentation but it still error, How this error can be fixed? "
70979815,How to crop an image using TensorFlow?,"<p>I'm trying to crop an image where I have a detected object. From TensorFlow's documentation there is a function.</p>
<pre><code>tf.image.crop_to_bounding_box(image, offset_height, offset_width, target_height, target_width)
</code></pre>
<p>I'm trying to work out how to get the given arguments but not sure what information to use. Here's the code I'm working with.</p>
<pre><code>img = cv2.imread(IMAGE_PATH)
image_np = np.array(img)

input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)
detections = detect_fn(input_tensor)

num_detections = int(detections.pop('num_detections'))
detections = {key: value[0, :num_detections].numpy()
              for key, value in detections.items()}


detections['num_detections'] = num_detections
# detection_classes should be ints.
detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

label_id_offset = 1
image_np_with_detections = image_np.copy()

viz_utils.visualize_boxes_and_labels_on_image_array(
            image_np_with_detections,
            detections['detection_boxes'],
            detections['detection_classes']+label_id_offset,
            detections['detection_scores'],
            category_index,
            use_normalized_coordinates=True,
            max_boxes_to_draw=9,
            min_score_thresh=.5,
            agnostic_mode=False)

#print(detections['detection_boxes'])
plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))
plt.show()
</code></pre>
<p>With this being the result, I'm trying to crop out everything but the bounding box -
<a href=""https://i.stack.imgur.com/AXrAU.png"" rel=""nofollow noreferrer"">Identified object</a></p>
","I'm trying to crop an image where I have a detected object. From TensorFlow's documentation there is a function. I'm trying to work out how to get the given arguments but not sure what information to use. Here's the code I'm working with. With this being the result, I'm trying to crop out everything but the bounding box - Identified object",https://stackoverflow.com/questions/70979815,18114544,Requesting (Additional) Resources,Documentation Replication on Other Examples, From TensorFlow's documentation there is a function. I'm trying to work out how to get the given arguments but not sure what information to use.
76262758,TF2.3 - More model outputs than targets,"<p>I am trying to write a model in which there are three outputs, the latter two of which are to be trained with respect to targets present in the dataset, the former should just be a non-trainable output.</p>
<p>First, defining a dataset:</p>
<pre class=""lang-py prettyprint-override""><code>from typing import Tuple

import numpy as np
import tensorflow as tf

def ds_fn(in_shape: Tuple[int],
          out_shape: Tuple[int],
          dtype: tf.DType = tf.float32) -&gt; tf.data.Dataset:
  # Generator function.
  def gen() -&gt; Tuple[Tuple[np.array], Tuple[np.array]]:
    for _ in range(1000):
      # Inputs.
      x0 = np.ones(in_shape, dtype=np.float32)
      x1 = 2 * x0

      # Outputs.
      y0 = np.ones(out_shape, dtype=np.float32)
      y1 = 2 * np.ones_like(y0)
      y2 = 3 * np.ones_like(y1)

      # Targets correspond to outputs 1 and 2 of the network. Output 0 has
      # no target.
      yield (x0, x1), (y1, y2)

  return tf.data.Dataset.from_generator(gen,
                                        output_types=((dtype,) * 2, # Input
                                                      (dtype,) * 2), # Output
                                        output_shapes=((in_shape,) * 2, # Input
                                                       (out_shape,) * 2)) # Output
</code></pre>
<p>In the above, the dataset has two targets, corresponding to the last two outputs of the model defined below.</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow import keras

class ExampleModel(keras.Model):
  def __init__(self, out_dim: int):
    super().__init__()

    self.dense_a = keras.layers.Dense(out_dim)
    self.dense_b = keras.layers.Dense(out_dim)

  def call(self, inputs, training=False):
    a, b = inputs

    x0 = self.dense_a(a)
    x1 = self.dense_b(b)

    x = (x0 + x1) / 2

    return (x, # Output 0 - should not be trained.
            2 * x,
            3 * x)
</code></pre>
<p>From reading the Keras documentation, to handle this case where there are a greater number of model outputs than there are targets in the dataset (with the surplus outputs considered to be non-trainable), it appears that the <code>Model.compile</code> arg <code>loss_weights</code> should handle the matching between targets and losses. More concretely, given the following.</p>
<pre class=""lang-py prettyprint-override""><code>def model_fn(out_dim: int) -&gt; ExampleModel:

  m = ExampleModel(out_dim)

  losses = [
    None, # Output 0 - should not be trainable.
    'mse',
    'mse'
  ]

  loss_weights = [
    0, # Output 0 - should not be trainable.
    1,
    1
  ]

  m.compile(loss=losses,
            loss_weights=loss_weights,
            optimizer='sgd')

  return m
</code></pre>
<p>I would expect that Keras would disregard the first model output when computing the loss, given the <code>None</code> loss provided and the <code>0</code> loss weight, however I am seeing the following error.</p>
<pre><code>ValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.
</code></pre>
<p>Which seems to indicate that this is not the case when run as follows.</p>
<pre class=""lang-py prettyprint-override""><code>if __name__ == &quot;__main__&quot;:
  bs = 16
  in_dim = 4
  out_dim = 8
  epochs = 10

  ds = ds_fn((bs, 1, in_dim), (bs, 1, out_dim))
  ds = ds.repeat(epochs)

  m = model_fn(out_dim)

  m.fit(ds,
        epochs=epochs,
        batch_size=bs)
</code></pre>
<p>If I provide an additional target in <code>data_fn</code> and <code>gen</code>, combined with a dummy loss (<code>lambda x, y: 0.0</code>. for example), then training commences. However, this will not scale to a non toy problem with potentially large outputs and targets (images, for example).</p>
<p>If I instead return a <code>dict</code> from the model <code>call</code> method and provide <code>dict</code> for <code>losses</code> and <code>loss_weights</code> (both with keys matching that returned from <code>call</code>), there is no change (I thought that the explicit output naming might allow Keras to match outputs, losses and targets).</p>
<p>Am I misunderstanding the intended purpose of lists as <code>losses</code> (in which <code>None</code> is allowed) and <code>loss_weights</code>?</p>
","I am trying to write a model in which there are three outputs, the latter two of which are to be trained with respect to targets present in the dataset, the former should just be a non-trainable output. First, defining a dataset: In the above, the dataset has two targets, corresponding to the last two outputs of the model defined below. From reading the Keras documentation, to handle this case where there are a greater number of model outputs than there are targets in the dataset (with the surplus outputs considered to be non-trainable), it appears that the Model.compile arg loss_weights should handle the matching between targets and losses. More concretely, given the following. I would expect that Keras would disregard the first model output when computing the loss, given the None loss provided and the 0 loss weight, however I am seeing the following error. Which seems to indicate that this is not the case when run as follows. If I provide an additional target in data_fn and gen, combined with a dummy loss (lambda x, y: 0.0. for example), then training commences. However, this will not scale to a non toy problem with potentially large outputs and targets (images, for example). If I instead return a dict from the model call method and provide dict for losses and loss_weights (both with keys matching that returned from call), there is no change (I thought that the explicit output naming might allow Keras to match outputs, losses and targets). Am I misunderstanding the intended purpose of lists as losses (in which None is allowed) and loss_weights?",https://stackoverflow.com/questions/76262758,588959,Documentation Replicability,Documentation Replication on Other Examples,"From reading the Keras documentation, to handle this case where there are a greater number of model outputs than there are targets in the dataset (with the surplus outputs considered to be non-trainable), it appears that the Model.compile arg loss_weights should handle the matching between targets and losses."
44191070,"Tensorflow, update the Variable to have arbitrary shape","<p>So, according to the <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">documentation</a>, we can use tf.assign with validate_shape=False to change the shape. It does change the shape of the content of the variable, but the shape you can get from get_shape() doesn't get updated. For example:</p>

<pre><code>&gt;&gt;&gt; a = tf.Variable([1, 1, 1, 1])
&gt;&gt;&gt; sess.run(tf.global_variables_initializer())
&gt;&gt;&gt; tf.assign(a, [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], validate_shape=False).eval()
array([[1, 1, 1, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 1]], dtype=int32)
&gt;&gt;&gt; a.get_shape()
TensorShape([Dimension(4)])
</code></pre>

<p>It's pretty annoying that the later layers of the network base their shapes on the get_shape() value of this variable. So, even though the actual shape is correct, Tensorflow will complain the dimensions doesn't match. So any ideas on how to update the ""believed"" shape of each Variable?</p>
","So, according to the documentation, we can use tf.assign with validate_shape=False to change the shape. It does change the shape of the content of the variable, but the shape you can get from get_shape() doesn't get updated. For example: It's pretty annoying that the later layers of the network base their shapes on the get_shape() value of this variable. So, even though the actual shape is correct, Tensorflow will complain the dimensions doesn't match. So any ideas on how to update the ""believed"" shape of each Variable?",https://stackoverflow.com/questions/44191070,4434038,Requesting (Additional) Resources,Documentation Replication on Other Examples,"So, according to the documentation, we can use tf.assign with validate_shape=False to change the shape. It does change the shape of the content of the variable, but the shape you can get from get_shape() doesn't get updated."
49012907,How to initialize intitial_state for LSTM in tf.nn.dynamic_rnn?,"<p>I am not sure how to pass a value for initial_state when the cell is a LSTMCell. I am using LSTMStateTuple as it is shown in the following piece of code:</p>

<pre><code>c_placeholder = tf.placeholder(tf.float32, [ None, config.state_dim], name='c_lstm')

h_placeholder = tf.placeholder(tf.float32, [ None, config.state_dim], name='h_lstm')

state_tuple = tf.nn.rnn_cell.LSTMStateTuple(c_placeholder, h_placeholder)

cell = tf.contrib.rnn.LSTMCell(num_units=config.state_dim, state_is_tuple=True, reuse=not is_training)  

rnn_outs, states = tf.nn.dynamic_rnn(cell=cell, inputs=x,sequence_length=seqlen, initial_state=state_tuple, dtype= tf.float32)
</code></pre>

<p>However, the execution returns this error:</p>

<pre><code>TypeError: 'Tensor' object is not iterable.
</code></pre>

<p>Here is the link of the documentation for <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">dynamic_rnn</a></p>
","I am not sure how to pass a value for initial_state when the cell is a LSTMCell. I am using LSTMStateTuple as it is shown in the following piece of code: However, the execution returns this error: Here is the link of the documentation for dynamic_rnn",https://stackoverflow.com/questions/49012907,8628566,Documentation Replication on Other Examples,Documentation Replication on Other Examples," I am using LSTMStateTuple as it is shown in the following piece of code: However, the execution returns this error: Here is the link of the documentation for dynamic_rnn"
38527096,Run a tensorflow with a list of fetches does not work,"<p>I'm playing around with Tensorflow and implemented a k means clustering algorithm. Everything works well, but if I want to run the session with a couple of fetches in a <code>list</code> I always get the error, that a <code>list</code> can not be converted to a <code>Tensor</code> or <code>Operation</code>.</p>

<p>The <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/client.html#Session"" rel=""nofollow"">documentation</a> explicitly says, that I can call <code>Session.run()</code> with a list. Am I doing anything wrong?</p>

<p>Here is the source code:</p>

<pre><code>import tensorflow as tf
import numpy as np

def tf_k_means(k, data, eps_=0.1):
    eps = tf.constant(eps_)

    cluster_means = tf.placeholder(tf.float32, [None, 2])
    tf_data = tf.placeholder(tf.float32, [None, 2], name='data')

    model = tf.initialize_all_variables()

    expanded_data = tf.expand_dims(tf_data, 0)
    expanded_means = tf.expand_dims(cluster_means, 1)
    distances = tf.reduce_sum(tf.square(tf.sub(expanded_means, expanded_data)), 2)
    mins = tf.to_int32(tf.argmin(distances, 0))

    clusters = tf.dynamic_partition(tf_data, mins, k)
    old_cluster_means = tf.identity(cluster_means)
    new_means = tf.concat(0, [tf.expand_dims(tf.reduce_mean(cluster, 0), 0) for cluster in clusters])

    clusters_moved = tf.reduce_sum(tf.square(tf.sub(old_cluster_means, new_means)), 1)
    converged = tf.reduce_all(tf.less(clusters_moved, eps))

    cms = data[np.random.randint(data.shape[0],size=k), :]

    with tf.Session() as sess:
        sess.run(model)
        conv = False
        while not conv:
            #####################################
            # THE FOLLOWING LINE DOES NOT WORK: #
            #####################################
            (cs, cms, conv) = sess.run([clusters, new_means, converged], 
                                        feed_dict={tf_data: data, cluster_means: cms})    

    return cs, cms
</code></pre>

<p>Here is the error message:</p>

<pre><code>TypeError: Fetch argument [&lt;tf.Tensor 'DynamicPartition_25:0' shape=(?, 2) dtype=float32&gt;, 
&lt;tf.Tensor 'DynamicPartition_25:1' shape=(?, 2) dtype=float32&gt;, 
&lt;tf.Tensor 'DynamicPartition_25:2' shape=(?, 2) dtype=float32&gt;, 
&lt;tf.Tensor 'DynamicPartition_25:3' shape=(?, 2) dtype=float32&gt;] of 
[&lt;tf.Tensor 'DynamicPartition_25:0' shape=(?, 2) dtype=float32&gt;, 
&lt;tf.Tensor 'DynamicPartition_25:1' shape=(?, 2) dtype=float32&gt;, 
&lt;tf.Tensor 'DynamicPartition_25:2' shape=(?, 2) dtype=float32&gt;, 
&lt;tf.Tensor 'DynamicPartition_25:3' shape=(?, 2) dtype=float32&gt;] has 
invalid type &lt;class 'list'&gt;, must be a string or Tensor. (Can not 
convert a list into a Tensor or Operation.)
</code></pre>
","I'm playing around with Tensorflow and implemented a k means clustering algorithm. Everything works well, but if I want to run the session with a couple of fetches in a list I always get the error, that a list can not be converted to a Tensor or Operation. The documentation explicitly says, that I can call Session.run() with a list. Am I doing anything wrong? Here is the source code: Here is the error message:",https://stackoverflow.com/questions/38527096,1264252,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"The documentation explicitly says, that I can call Session.run() with a list. Am I doing anything wrong? "
47932738,TensorFlow: restoring model in a MonitoredSession,"<p>I have a model that contains multiple variables including a global step. I've been able to successfully use a MonitoredSession to save checkpoints and summaries every 100 steps. I was expecting the MonitoredSession to automatically restore all my variables when the session is run in multiple passes (based on <a href=""https://www.tensorflow.org/api_docs/python/tf/train/MonitoredSession"" rel=""nofollow noreferrer"">this</a> documentation), however this does not happen. If I take a look at the global step after running the training session again, I find that it starts back from zero. This is a simplified version of my code without the actual model. Let me know if more code is needed to solve this problem</p>

<pre><code>train_graph = tf.Graph()
with train_graph.as_default():
  # I create some datasets using the Dataset API
  # ...

  global_step = tf.train.create_global_step()

  # Create all the other variables and the model here
  # ...

  saver_hook = tf.train.CheckpointSaverHook(
      checkpoint_dir='checkpoint/',
      save_secs=None,
      save_steps=100,
      saver=tf.train.Saver(),
      checkpoint_basename='model.ckpt',
      scaffold=None)
  summary_hook = tf.train.SummarySaverHook(
      save_steps=100,
      save_secs=None,
      output_dir='summaries/',
      summary_writer=None,
      scaffold=None,
      summary_op=train_step_summary)
  num_steps_hook = tf.train.StopAtStepHook(num_steps=500) # Just for testing


  with tf.train.MonitoredSession(
      hooks=[saver_hook, summary_hook, num_steps_hook]) as sess:
    while not sess.should_stop():
      step = sess.run(global_step)
      if (step % 100 == 0):
        print(step)
      sess.run(optimizer)
</code></pre>

<p>When I run this code the first time, I get this output</p>

<pre><code>0
100
200
300
400
</code></pre>

<p>The checkpoint folder at this point has checkpoints for every hundredth step up to 500. If I run the program again I would expect to see the counter start at 500 and the increase up to 900, but instead I just get the same thing and all of my checkpoints get overwritten. Any ideas?</p>
","I have a model that contains multiple variables including a global step. I've been able to successfully use a MonitoredSession to save checkpoints and summaries every 100 steps. I was expecting the MonitoredSession to automatically restore all my variables when the session is run in multiple passes (based on this documentation), however this does not happen. If I take a look at the global step after running the training session again, I find that it starts back from zero. This is a simplified version of my code without the actual model. Let me know if more code is needed to solve this problem When I run this code the first time, I get this output The checkpoint folder at this point has checkpoints for every hundredth step up to 500. If I run the program again I would expect to see the counter start at 500 and the increase up to 900, but instead I just get the same thing and all of my checkpoints get overwritten. Any ideas?",https://stackoverflow.com/questions/47932738,6642285,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I was expecting the MonitoredSession to automatically restore all my variables when the session is run in multiple passes (based on this documentation), however this does not happen. "
66079584,tensorflow.dataset.shuffle = tensorflow.dataset.prefetch + then shuffle internally?,"<p>According to the documentation of tf.dataset.<a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"" rel=""nofollow noreferrer"">shuffle</a>, it will fill in a buffer with size <code>k</code> then shuffle inside of it. Tho I don't want the order of data to be changed, I want it to be buffered. Then I found there is tf.dataset.<a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch"" rel=""nofollow noreferrer"">prefetch</a>, which says &quot;This allows later elements to be prepared while the current element is being processed.&quot;</p>
<p>From the description I guess <code>prefetch</code> is what I want (i.e. pre-loading the data while the pervious data are being used in training), but while trying to look into the code of <code>tf.dataset.shuffle</code> to see if they actually call <code>tf.dataset.prefetch</code>, I got stuck in <a href=""https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/data/ops/dataset_ops.py#L3829-L3835"" rel=""nofollow noreferrer"">these</a> lines (paste them below), cannot find where is <code>shuffle_dataset_v3</code> defined.</p>
<pre><code>      variant_tensor = gen_dataset_ops.shuffle_dataset_v3(
          input_dataset._variant_tensor,  # pylint: disable=protected-access
          buffer_size=self._buffer_size,
          seed=self._seed,
          seed2=self._seed2,
          seed_generator=gen_dataset_ops.dummy_seed_generator(),
          reshuffle_each_iteration=self._reshuffle_each_iteration,
          **self._flat_structure)
</code></pre>
<p>My major question is whether <code>prefetch</code> is the replacement of <code>shuffle</code> in terms of buffering the data, and it would also be nice if someone can point me to where <code>shuffle_dataset_v3</code> was implemented?</p>
","According to the documentation of tf.dataset.shuffle, it will fill in a buffer with size k then shuffle inside of it. Tho I don't want the order of data to be changed, I want it to be buffered. Then I found there is tf.dataset.prefetch, which says ""This allows later elements to be prepared while the current element is being processed."" From the description I guess prefetch is what I want (i.e. pre-loading the data while the pervious data are being used in training), but while trying to look into the code of tf.dataset.shuffle to see if they actually call tf.dataset.prefetch, I got stuck in these lines (paste them below), cannot find where is shuffle_dataset_v3 defined. My major question is whether prefetch is the replacement of shuffle in terms of buffering the data, and it would also be nice if someone can point me to where shuffle_dataset_v3 was implemented?",https://stackoverflow.com/questions/66079584,13112529,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"According to the documentation of tf.dataset.shuffle, it will fill in a buffer with size k then shuffle inside of it. Tho I don't want the order of data to be changed, I want it to be buffered. "
61131730,Tensorflow Datasets with string inputs do not preserve data type,"<p>All <strong>reproducible</strong> code below is run at Google Colab with TF 2.2.0-rc2.</p>

<p>Adapting the simple example from the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">documentation</a> for creating a dataset from a simple Python list:</p>

<pre><code>import numpy as np
import tensorflow as tf
tf.__version__
# '2.2.0-rc2'
np.version.version
# '1.18.2'

dataset1 = tf.data.Dataset.from_tensor_slices([1, 2, 3]) 
for element in dataset1: 
  print(element) 
  print(type(element.numpy()))
</code></pre>

<p>we get the result</p>

<pre><code>tf.Tensor(1, shape=(), dtype=int32)
&lt;class 'numpy.int32'&gt;
tf.Tensor(2, shape=(), dtype=int32)
&lt;class 'numpy.int32'&gt;
tf.Tensor(3, shape=(), dtype=int32)
&lt;class 'numpy.int32'&gt;
</code></pre>

<p>where all data types are <code>int32</code>, as expected.</p>

<p>But changing this simple example to feed a list of strings instead of integers:</p>

<pre><code>dataset2 = tf.data.Dataset.from_tensor_slices(['1', '2', '3']) 
for element in dataset2: 
  print(element) 
  print(type(element.numpy()))
</code></pre>

<p>gives the result</p>

<pre><code>tf.Tensor(b'1', shape=(), dtype=string)
&lt;class 'bytes'&gt;
tf.Tensor(b'2', shape=(), dtype=string)
&lt;class 'bytes'&gt;
tf.Tensor(b'3', shape=(), dtype=string)
&lt;class 'bytes'&gt;
</code></pre>

<p>where, surprisingly, and despite the tensors themselves being of <code>dtype=string</code>, their evaluations are of type <code>bytes</code>.</p>

<p>This behavior is not confined to the <code>.from_tensor_slices</code> method; here is the situation with <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files"" rel=""nofollow noreferrer""><code>.list_files</code></a> (the following snippet runs straightforward in a fresh Colab notebook):</p>

<pre><code>disc_data = tf.data.Dataset.list_files('sample_data/*.csv') # 4 csv files
for element in disc_data: 
  print(element) 
  print(type(element.numpy()))
</code></pre>

<p>the result being:</p>

<pre><code>tf.Tensor(b'sample_data/california_housing_test.csv', shape=(), dtype=string)
&lt;class 'bytes'&gt;
tf.Tensor(b'sample_data/mnist_train_small.csv', shape=(), dtype=string)
&lt;class 'bytes'&gt;
tf.Tensor(b'sample_data/california_housing_train.csv', shape=(), dtype=string)
&lt;class 'bytes'&gt;
tf.Tensor(b'sample_data/mnist_test.csv', shape=(), dtype=string)
&lt;class 'bytes'&gt;
</code></pre>

<p>where again, the file names in the evaluated tensors are returned as <code>bytes</code>, instead of <code>string</code>, despite that the tensors themselves are of <code>dtype=string</code>.</p>

<p>Similar behavior is observed also with the <code>.from_generator</code> method (not shown here).</p>

<p>A final demonstration: as shown in the <code>.as_numpy_iterator</code> method <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator"" rel=""nofollow noreferrer"">documentation</a>, the following equality condition is evaluated as <code>True</code>:</p>

<pre><code>dataset3 = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), 
                                               'b': [5, 6]}) 

list(dataset3.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5}, 
                                       {'a': (2, 4), 'b': 6}] 
# True
</code></pre>

<p>but if we change the elements of <code>b</code> to be strings, the equality condition is now surprisingly evaluated as <code>False</code>!</p>

<pre><code>dataset4 = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), 
                                               'b': ['5', '6']})   # change elements of b to strings

list(dataset4.as_numpy_iterator()) == [{'a': (1, 3), 'b': '5'},   # here
                                       {'a': (2, 4), 'b': '6'}]   # also
# False
</code></pre>

<p>probably due to the different data types, since the values themselves are evidently identical.</p>

<hr>

<p>I didn't stumble upon this behavior by academic experimentation; I am trying to pass my data to TF Datasets using custom functions that read pairs of files from the disk of the form</p>

<pre><code>f = ['filename1', 'filename2']
</code></pre>

<p>which custom functions work perfectly well on their own, but mapped through TF Datasets give</p>

<pre><code>RuntimeError: not a string
</code></pre>

<p>which, after this digging, seems at least not unexplained, if the returned data types are indeed <code>bytes</code> and not <code>string</code>.</p>

<p>So, is this a bug (as it seems), or am I missing something here?</p>
","All reproducible code below is run at Google Colab with TF 2.2.0-rc2. Adapting the simple example from the documentation for creating a dataset from a simple Python list: we get the result where all data types are int32, as expected. But changing this simple example to feed a list of strings instead of integers: gives the result where, surprisingly, and despite the tensors themselves being of dtype=string, their evaluations are of type bytes. This behavior is not confined to the .from_tensor_slices method; here is the situation with .list_files (the following snippet runs straightforward in a fresh Colab notebook): the result being: where again, the file names in the evaluated tensors are returned as bytes, instead of string, despite that the tensors themselves are of dtype=string. Similar behavior is observed also with the .from_generator method (not shown here). A final demonstration: as shown in the .as_numpy_iterator method documentation, the following equality condition is evaluated as True: but if we change the elements of b to be strings, the equality condition is now surprisingly evaluated as False! probably due to the different data types, since the values themselves are evidently identical. I didn't stumble upon this behavior by academic experimentation; I am trying to pass my data to TF Datasets using custom functions that read pairs of files from the disk of the form which custom functions work perfectly well on their own, but mapped through TF Datasets give which, after this digging, seems at least not unexplained, if the returned data types are indeed bytes and not string. So, is this a bug (as it seems), or am I missing something here?",https://stackoverflow.com/questions/61131730,4685471,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"Adapting the simple example from the documentation for creating a dataset from a simple Python list: we get the result where all data types are int32, as expected. But changing this simple example to feed a list of strings instead of integers: gives the result where, surprisingly, and despite the tensors themselves being of dtype=string, their evaluations are of type bytes. This behavior is not confined to the .from_tensor_slices method."
73691788,Tensorflow dataset not saved in multiple shards,"<p>I want to use the tensorflow dataset saving and loading functions but I am not sure to understand the sharding method.</p>
<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#save"" rel=""noreferrer"">documentation</a> indicates :</p>
<blockquote>
<p>The saved dataset is saved in multiple file &quot;shards&quot;. By default, the dataset output is divided to shards in a round-robin fashion but custom sharding can be specified via the shard_func function.</p>
</blockquote>
<p>But when I save a dataset through the save function, it seems that only one huge shard is generated.</p>
<pre><code>import tempfile
import tensorflow as tf

path = os.path.join(tempfile.gettempdir(), &quot;saved_data&quot;)
dataset = tf.data.Dataset.range(10**8)

dataset.save(path)
</code></pre>
<p><a href=""https://i.stack.imgur.com/K2Qkh.png"" rel=""noreferrer"">generated dataset screenshot</a></p>
<p>Am I missing something ?</p>
<p>I use Tensorflow 2.10.0 and Python 3.9.7</p>
","I want to use the tensorflow dataset saving and loading functions but I am not sure to understand the sharding method. The documentation indicates : But when I save a dataset through the save function, it seems that only one huge shard is generated. generated dataset screenshot Am I missing something ? I use Tensorflow 2.10.0 and Python 3.9.7",https://stackoverflow.com/questions/73691788,5130199,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"The documentation indicates : But when I save a dataset through the save function, it seems that only one huge shard is generated. "
38937984,"distributed tensorflow on localhosts failed by ""socket error, connection refused""","<p>I am experimenting distributed tensorflow using a slight modification of an <a href=""https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html"" rel=""nofollow noreferrer"">official example</a>.</p>

<p>My experiment code is (you can skip this for now and scroll down to the problem),</p>

<pre><code>import tensorflow as tf
import numpy as np

# Flags for defining the tf.train.ClusterSpec
tf.app.flags.DEFINE_string(""ps_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")

# Flags for defining the tf.train.Server
tf.app.flags.DEFINE_string(""job_name"", """", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

FLAGS = tf.app.flags.FLAGS


def main(_):
    ps_hosts = FLAGS.ps_hosts.split("","")
    worker_hosts = FLAGS.worker_hosts.split("","")

    # Create a cluster from the parameter server and worker hosts.
    cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

    # Create and start a server for the local task.
    server = tf.train.Server(cluster,
                             job_name=FLAGS.job_name,
                             task_index=FLAGS.task_index)

    if FLAGS.job_name == ""ps"":
        server.join()
    elif FLAGS.job_name == ""worker"":
        # Assigns ops to the local worker by default.
        with tf.device(tf.train.replica_device_setter(
                worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
                cluster=cluster)):

            # Build model...
            x = tf.placeholder(""float"", [10, 10], name=""x"")
            y = tf.placeholder(""float"", [10, 1], name=""y"")
            initial_w = np.zeros((10, 1))
            w = tf.Variable(initial_w, name=""w"", dtype=""float32"")
            loss = tf.pow(tf.add(y,-tf.matmul(x,w)),2,name=""loss"")
            global_step = tf.Variable(0)

            saver = tf.train.Saver()
            summary_op = tf.merge_all_summaries()
            init_op = tf.initialize_all_variables()

        # Create a ""supervisor"", which oversees the training process.
        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                                 logdir=""/tmp/train_logs"",
                                 init_op=init_op,
                                 summary_op=summary_op,
                                 saver=saver,
                                 global_step=global_step,
                                 save_model_secs=600)

        # The supervisor takes care of session initialization, restoring from
        # a checkpoint, and closing when done or an error occurs.
        with sv.managed_session(server.target) as sess:
            # Loop until the supervisor shuts down or 1000000 steps have completed.
            step = 0
            while not sv.should_stop() and step &lt; 1000000:
                # Run a training step asynchronously.
                # See `tf.train.SyncReplicasOptimizer` for additional details on how to
                # perform *synchronous* training.
                _, step = sess.run([loss, global_step])
                print(""job_name: %s; task_index: %s; step: %d"" % (FLAGS.job_name,FLAGS.task_index,step))

        # Ask for all the services to stop.
        sv.stop()


if __name__ == ""__main__"":
    tf.app.run()
</code></pre>

<p>Then I run the following commands as instructed by the official document (the script is named hello_distributed.py),</p>

<pre><code>sudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=ps --task_index=0

sudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=ps --task_index=1

sudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=worker --task_index=0

sudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=worker --task_index=1
</code></pre>

<p>The first two lines for running ""ps"" are good. The last two lines get the following ""connection refused"" error. </p>

<p><a href=""https://i.stack.imgur.com/zkGPi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zkGPi.png"" alt=""enter image description here""></a></p>

<p>Thank you!</p>
","I am experimenting distributed tensorflow using a slight modification of an official example. My experiment code is (you can skip this for now and scroll down to the problem), Then I run the following commands as instructed by the official document (the script is named hello_distributed.py), The first two lines for running ""ps"" are good. The last two lines get the following ""connection refused"" error. Thank you!",https://stackoverflow.com/questions/38937984,4089301,Documentation Replication on Other Examples,Documentation Replication on Other Examples,I am experimenting distributed tensorflow using a slight modification of an official example. 
47856852,Estimator predict infinite loop,"<p>I don't understand how to make a single prediction using TensorFlow Estimator API - my code results in an endless loop that keeps predicting for the same input.</p>

<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#predict"" rel=""noreferrer"">documentation</a>, the prediction is supposed to stop when input_fn raises a StopIteration exception:</p>

<blockquote>
  <p>input_fn: Input function returning features which is a dictionary of
  string feature name to Tensor or SparseTensor. If it returns a tuple,
  first item is extracted as features. Prediction continues until
  input_fn raises an end-of-input exception (OutOfRangeError or
  StopIteration).</p>
</blockquote>

<p>Here's the relevant part in my code:</p>

<pre><code>classifier = tf.estimator.Estimator(model_fn=image_classifier, model_dir=output_dir,
                                    config=training_config, params=hparams)

def make_predict_input_fn(filename):
    queue = [ filename ]
    def _input_fn():
        if len(queue) == 0:
            raise StopIteration
        image = model.read_and_preprocess(queue.pop())
        return {'image': image}
    return _input_fn

predictions = classifier.predict(make_predict_input_fn('garden-rose-red-pink-56866.jpeg'))
for i, p in enumerate(predictions):
    print(""Prediction %s: %s"" % (i + 1, p[""class""]))
</code></pre>

<p>What am I missing?</p>
","I don't understand how to make a single prediction using TensorFlow Estimator API - my code results in an endless loop that keeps predicting for the same input. According to the documentation, the prediction is supposed to stop when input_fn raises a StopIteration exception: Here's the relevant part in my code: What am I missing?",https://stackoverflow.com/questions/47856852,2375105,Documentation Replicability,Documentation Replication on Other Examples,"I don't understand how to make a single prediction using TensorFlow Estimator API - my code results in an endless loop that keeps predicting for the same input. According to the documentation, the prediction is supposed to stop when input_fn raises a StopIteration exception."
55537333,How to use tensorflow sequence_numeric_column with an RNNClassifier?,"<p>I was looking throw the tensorflow contrib API and I wanted to use the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/RNNClassifier#__init__"" rel=""nofollow noreferrer"">RNNClassifier</a> available with Tensorflow 1.13. Contrary to non sequence estimators, this one needs sequence feature columns only. However I was not able to make it work on a toy dataset. I keep getting an error while using <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/feature_column/sequence_numeric_column"" rel=""nofollow noreferrer"">sequence_numeric_column</a>.</p>

<p>Here is the structure of my toy dataset:</p>

<pre><code>idSeq,kind,label,size
0,0,dwarf,117.6
0,0,dwarf,134.4
0,0,dwarf,119.0
0,1,human,168.0
0,1,human,145.25
0,2,elve,153.9
0,2,elve,218.49999999999997
0,2,elve,210.9
1,0,dwarf,166.6
1,0,dwarf,168.0
1,0,dwarf,131.6
1,1,human,150.5
1,1,human,208.25
1,1,human,210.0
1,2,elve,199.5
1,2,elve,161.5
1,2,elve,197.6
</code></pre>

<p>where idSeq allow us to see which rows belong to which sequence.
I want to predict the ""kind"" column thanks to the ""size"" column.</p>

<p>Below there is my code about make my RNN training on my dataset.</p>

<pre><code>import numpy as np
import pandas as pd
import tensorflow as tf


os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
tf.logging.set_verbosity(tf.logging.INFO)

dataframe = pd.read_csv(""data_rnn.csv"")
dataframe_test = pd.read_csv(""data_rnn_test.csv"")


train_x = dataframe
train_y = dataframe.loc[:,([""kind""])]


size_feature_col = tf.contrib.feature_column.sequence_numeric_column('size ')


estimator = tf.contrib.estimator.RNNClassifier(
    sequence_feature_columns=[size_feature_col ],
    num_units=[32, 16],
    cell_type='lstm',
    model_dir=None,
    n_classes=3,
    optimizer='Adagrad'
)



def make_dataset(
    batch_size, 
    x, 
    y=None, 
    shuffle=False, 
    shuffle_buffer_size=1000,
    shuffle_seed=1):
    """"""
    An input function for training, evaluation or prediction.

    Parameters
    ----------------------
    batch_size: integer
        the size of the batch to use for the training of the neural network
    x: pandas dataframe 
        dataframe that contains the features of the samples to study
    y: pandas dataframe or array (Default: None)
        dataframe or array that contains the values to predict of the samples
        to study. If none, we want a dataset for evaluation or prediction.
    shuffle: boolean (Default: False)
        if True, we shuffle the elements of the dataset
    shuffle_buffer_size: integer (Default: 1000)
        if we shuffle the elements of the dataset, it is the size of the buffer
        used for it.
    shuffle_seed : integer
        the random seed for the shuffling

    Returns
    ---------------------
    dataset.make_one_shot_iterator().get_next(): Tensor
        a nested structure of tf.Tensors containing the next element of the 
        dataset to study
    """"""

    def input_fn():
        if y is not None:
            dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))
        else:
            dataset = tf.data.Dataset.from_tensor_slices(dict(x))
        if shuffle:
            dataset = dataset.shuffle(
                buffer_size=shuffle_buffer_size,
                seed=shuffle_seed).batch(batch_size).repeat()
        else:
            dataset = dataset.batch(batch_size)
        return dataset.make_one_shot_iterator().get_next()

    return input_fn



batch_size = 50
random_seed = 1


input_fn_train = make_dataset(
            batch_size=batch_size, 
            x=train_x, 
            y=train_y, 
            shuffle=True, 
            shuffle_buffer_size=len(train_x),
            shuffle_seed=random_seed)

estimator.train(input_fn=input_fn_train, steps=5000)

</code></pre>

<p>But I only got the following error :</p>

<pre><code>INFO:tensorflow:Calling model_fn.
Traceback (most recent call last):
  File ""main.py"", line 125, in &lt;module&gt;
    estimator.train(input_fn=input_fn_train, steps=5000)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1124, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1154, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1112, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/contrib/estimator/python/estimator/rnn.py"", line 512, in _model_fn
    config=config)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/contrib/estimator/python/estimator/rnn.py"", line 332, in _rnn_model_fn
    logits, sequence_length_mask = logit_fn(features=features, mode=mode)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/contrib/estimator/python/estimator/rnn.py"", line 226, in rnn_logit_fn
    features=features, feature_columns=sequence_feature_columns)
  File ""/root/.local/lib/python3.5/site-packages/tensorflow/contrib/feature_column/python/feature_column/sequence_feature_column.py"", line 120, in sequence_input_layer
    trainable=trainable)
  File ""/root/.local/lib/python3.5/site-packages/tensorflow/contrib/feature_column/python/feature_column/sequence_feature_column.py"", line 496, in _get_sequence_dense_tensor
    sp_tensor, default_value=self.default_value)
  File ""/root/.local/lib/python3.5/site-packages/tensorflow/python/ops/sparse_ops.py"", line 1432, in sparse_tensor_to_dense
    sp_input = _convert_to_sparse_tensor(sp_input)
  File ""/root/.local/lib/python3.5/site-packages/tensorflow/python/ops/sparse_ops.py"", line 68, in _convert_to_sparse_tensor
    raise TypeError(""Input must be a SparseTensor."")
TypeError: Input must be a SparseTensor.

</code></pre>

<p>So I don't understand what I've done wrong because on the documentation, it is written that we have to give a sequence column to the RNNEstimator. They do not say anything about giving sparse tensor.</p>

<p>Thanks in advance for your help and advices.</p>
","I was looking throw the tensorflow contrib API and I wanted to use the RNNClassifier available with Tensorflow 1.13. Contrary to non sequence estimators, this one needs sequence feature columns only. However I was not able to make it work on a toy dataset. I keep getting an error while using sequence_numeric_column. Here is the structure of my toy dataset: where idSeq allow us to see which rows belong to which sequence. I want to predict the ""kind"" column thanks to the ""size"" column. Below there is my code about make my RNN training on my dataset. But I only got the following error : So I don't understand what I've done wrong because on the documentation, it is written that we have to give a sequence column to the RNNEstimator. They do not say anything about giving sparse tensor. Thanks in advance for your help and advices.",https://stackoverflow.com/questions/55537333,5218377,Documentation Replication on Other Examples,Documentation Replication on Other Examples," So I don't understand what I've done wrong because on the documentation, it is written that we have to give a sequence column to the RNNEstimator. They do not say anything about giving sparse tensor."
56588353,How to use Tensorflow BatchNormalization with GradientTape?,"<p>Suppose we have a simple Keras model that uses BatchNormalization:</p>

<pre><code>model = tf.keras.Sequential([
                     tf.keras.layers.InputLayer(input_shape=(1,)),
                     tf.keras.layers.BatchNormalization()
])
</code></pre>

<p>How to actually use it with GradientTape? The following doesn't seem to work as it doesn't update the moving averages?</p>

<pre><code># model training... we want the output values to be close to 150
for i in range(1000):
  x = np.random.randint(100, 110, 10).astype(np.float32)
  with tf.GradientTape() as tape:
    y = model(np.expand_dims(x, axis=1))
    loss = tf.reduce_mean(tf.square(y - 150))
  grads = tape.gradient(loss, model.variables)
  opt.apply_gradients(zip(grads, model.variables))
</code></pre>

<p>In particular, if you inspect the moving averages, they remain the same (inspect model.variables, averages are always 0 and 1). I know one can use .fit() and .predict(), but I would like to use the GradientTape and I'm not sure how to do this. Some version of the documentation suggests to update update_ops, but that doesn't seem to work in eager mode.</p>

<p>In particular, the following code will not output anything close to 150 after the above training.</p>

<pre><code>x = np.random.randint(200, 210, 100).astype(np.float32)
print(model(np.expand_dims(x, axis=1)))
</code></pre>
","Suppose we have a simple Keras model that uses BatchNormalization: How to actually use it with GradientTape? The following doesn't seem to work as it doesn't update the moving averages? In particular, if you inspect the moving averages, they remain the same (inspect model.variables, averages are always 0 and 1). I know one can use .fit() and .predict(), but I would like to use the GradientTape and I'm not sure how to do this. Some version of the documentation suggests to update update_ops, but that doesn't seem to work in eager mode. In particular, the following code will not output anything close to 150 after the above training.",https://stackoverflow.com/questions/56588353,1048214,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I know one can use .fit() and .predict(), but I would like to use the GradientTape and I'm not sure how to do this. Some version of the documentation suggests to update update_ops, but that doesn't seem to work in eager mode."
51396366,TensorFlow with keras: Where is the ReLU layer in tf version 1.8?,"<p>Update: Found it: The class is <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation#__init__"" rel=""nofollow noreferrer"">tf.keras.layers.Activation</a>; needs to be called with argument activation='relu'....</p>

<hr>

<p>Trying to access tf.keras.layers.ReLU gives the error:</p>

<blockquote>
  <p>AttributeError: module
  'tensorflow.tools.api.generator.api.keras.layers' has no attribute
  'ReLU'.</p>
</blockquote>

<p>In the docs, version <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/keras/layers/ReLU"" rel=""nofollow noreferrer"">master</a> has such a layer. Version 1.8 (and 1.9) only seems to have leaky relu, PReLU, and other derivatives. </p>

<p>Right now I'm using <a href=""https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/keras/layers/ThresholdedReLU"" rel=""nofollow noreferrer"">ThresholdedReLU</a> with theta of 0.0, I hope this results in a standard ReLU. But there must be a simple 'ReLU' layer as well?</p>

<p>Where can I find keras' ReLU layer in tensorflow 1.8?
I want a keras layer class, i.e., not <a href=""https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/keras/backend/relu"" rel=""nofollow noreferrer"">tf.keras.backend.relu</a>.</p>

<p>It feels as if I'm overlooking something completely obvious. I haven't used keras before, so, sorry if this is a super stupid question.</p>
","Update: Found it: The class is tf.keras.layers.Activation; needs to be called with argument activation='relu'.... Trying to access tf.keras.layers.ReLU gives the error: In the docs, version master has such a layer. Version 1.8 (and 1.9) only seems to have leaky relu, PReLU, and other derivatives. Right now I'm using ThresholdedReLU with theta of 0.0, I hope this results in a standard ReLU. But there must be a simple 'ReLU' layer as well? Where can I find keras' ReLU layer in tensorflow 1.8? I want a keras layer class, i.e., not tf.keras.backend.relu. It feels as if I'm overlooking something completely obvious. I haven't used keras before, so, sorry if this is a super stupid question.",https://stackoverflow.com/questions/51396366,4726173,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"In the docs, version master has such a layer. Version 1.8 (and 1.9) only seems to have leaky relu, PReLU, and other derivatives. Right now I'm using ThresholdedReLU with theta of 0.0, I hope this results in a standard ReLU. But there must be a simple 'ReLU' layer as well?"
51586693,"Tensor has shape [?, 0] -- how to reshape to [?,]","<p>When <code>src</code> has shape <code>[?]</code>, <code>tf.gather(src, tf.where(src != 0))</code> returns a tensor with shape <code>[?, 0]</code>. I'm not sure how a dimension can have size 0, and I'm especially unsure how to change the tensor back. I didn't find anything in the documentation to explain this, either.</p>

<p>I tried to <code>tf.transpose(tensor)[0]</code>, but the first dimension of the transposed tensor has size 0 and cannot be accessed! What's wrong?</p>
","When src has shape [?], tf.gather(src, tf.where(src != 0)) returns a tensor with shape [?, 0]. I'm not sure how a dimension can have size 0, and I'm especially unsure how to change the tensor back. I didn't find anything in the documentation to explain this, either. I tried to tf.transpose(tensor)[0], but the first dimension of the transposed tensor has size 0 and cannot be accessed! What's wrong?",https://stackoverflow.com/questions/51586693,6772171,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I'm not sure how a dimension can have size 0, and I'm especially unsure how to change the tensor back. I didn't find anything in the documentation to explain this, either."
51776390,how to use tensorboard debugger with datalab which uses tf.estimator on google cloud platform,"<p>When I start tensorboard via datalab it uses the google syntax which is described <a href=""https://googledatalab.github.io/pydatalab/google.datalab.ml.html"" rel=""nofollow noreferrer"">here</a>.  This document only mentions start, stop and list.  However, there is a debugger pane which I can not use.</p>

<p><a href=""https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/debugger"" rel=""nofollow noreferrer"">This</a> document describes how to use tensorboard debugger with a tf.estimator but it uses a different syntax.</p>

<p>Is there someway to blend the two so the debugger is usable with datalab?</p>
","When I start tensorboard via datalab it uses the google syntax which is described here. This document only mentions start, stop and list. However, there is a debugger pane which I can not use. This document describes how to use tensorboard debugger with a tf.estimator but it uses a different syntax. Is there someway to blend the two so the debugger is usable with datalab?",https://stackoverflow.com/questions/51776390,1008596,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"When I start tensorboard via datalab it uses the google syntax which is described here. This document only mentions start, stop and list. However, there is a debugger pane which I can not use. This document describes how to use tensorboard debugger with a tf.estimator but it uses a different syntax. "
52073782,Computations (such as tf.greater and tf.cond) on random value tensors not working as expected,"<p>I am a tensorflow beginner. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/greater"" rel=""nofollow noreferrer"">documentation</a>, <strong>tf.greater returns the truth value of (x>y) element-wise</strong></p>

<p>My code is as below:</p>

<pre><code>x = tf.random_uniform([])  # Empty array as shape creates a scalar.
y = tf.random_uniform([])
print('x: '+str(x.eval()))
print('y: ' +str(y.eval()))
out = tf.cond(tf.greater(x, y), lambda: x + y, lambda: x - y)
print(sess.run(tf.greater(x, y)))
print(sess.run(out))
</code></pre>

<p>The output I got is:</p>

<pre><code>x: 0.79379404
y: 0.30891895
False
0.3438499
</code></pre>

<p>x is bigger than y so it should return True and x+y should be 1.10271299
why is my expected output different than the actual output?</p>
","I am a tensorflow beginner. According to the documentation, tf.greater returns the truth value of (x&gt;y) element-wise My code is as below: The output I got is: x is bigger than y so it should return True and x+y should be 1.10271299 why is my expected output different than the actual output?",https://stackoverflow.com/questions/52073782,8496110,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"According to the documentation, tf.greater returns the truth value of (x&gt;y) element-wise. My code is as below: The output I got is: x is bigger than y so it should return True and x+y should be 1.10271299 why is my expected output different than the actual output?"
52572275,tensorflow: how to interleave columns of two tensors (e.g. using tf.scatter_nd)?,"<p>I've read the <a href=""https://www.tensorflow.org/api_docs/python/tf/manip/scatter_nd"" rel=""nofollow noreferrer"">tf.scatter_nd documentation</a> and run the example code for 1D and 3D tensors... and now I'm trying to do it for a 2D tensor.  I want to 'interleave' the columns of two tensors.  For 1D tensors, one can do this via</p>

<pre><code>'''
We want to interleave elements of 1D tensors arr1 and arr2, where
arr1 = [10, 11, 12]
arr2 = [1, 2, 3, 4, 5, 6]
such that
desired result = [1, 2, 10, 3, 4, 11, 5, 6, 12]
'''

import tensorflow as tf

with tf.Session() as sess:

    updates1 = tf.constant([1,2,3,4,5,6])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)

    updates2 = tf.constant([10,11,12])
    indices2 = tf.constant([[2], [5], [8]])
    scatter2 = tf.scatter_nd(indices2, updates2, shape)

    result = scatter1 + scatter2

    print(sess.run(result))
</code></pre>

<p>(aside: is there a <em>better</em> way to do this?  I'm all ears.)</p>

<p>This gives the output</p>

<p><code>[ 1  2 10  3  4 11  5  6 12]</code></p>

<p>Yay! that worked!</p>

<p>Now lets' try to extend this to 2D.</p>

<pre><code>    '''
    We want to interleave the *columns* (not rows; rows would be easy!) of

    arr1 = [[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]]
    arr2 = [[10 11 12], [10 11 12], [10 11 12]]
    such that
    desired result = [[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12],[1,2,10,3,4,11,5,6,12]]
    '''

    updates1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,6],[1,2,3,4,5,6]])
    indices1 = tf.constant([[0], [1], [3], [4], [6], [7]])
    shape = tf.constant([3, 9])
    scatter1 = tf.scatter_nd(indices1, updates1, shape)
</code></pre>

<p>This gives the error
<code>ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1
dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but
are 6 and 3. Shapes are [6] and [3]. for 'ScatterNd_2' (op: 'ScatterNd') with
input shapes: [6,1], [3,6], [2].</code></p>

<p>Seems like my <code>indices</code> is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean
I need to <em>explicitly</em> specify every single pair of indices for every element in <code>updates1</code>?
Or is there some kind of 'wildcard' specification I can use for the rows? (Note <code>indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]])</code> gives syntax errors, as it probably should.)</p>

<p>Would it be easier to just do a transpose, interleave the rows, then transpose back?
Because I tried that...</p>

<pre><code>scatter1 = tf.scatter_nd(indices1, tf.transpose(updates1), tf.transpose(shape))
print(sess.run(tf.transpose(scatter1)))
</code></pre>

<p>...and got a <em>much</em> longer error message, that I don't feel like posting unless someone requests it. </p>

<p>PS- I searched to make sure this isn't a duplicate -- I find it hard to imagine that someone else hasn't asked this before -- but turned up nothing. </p>
","I've read the tf.scatter_nd documentation and run the example code for 1D and 3D tensors... and now I'm trying to do it for a 2D tensor. I want to 'interleave' the columns of two tensors. For 1D tensors, one can do this via (aside: is there a better way to do this? I'm all ears.) This gives the output [ 1 2 10 3 4 11 5 6 12] Yay! that worked! Now lets' try to extend this to 2D. This gives the error ValueError: The outer 1 dimensions of indices.shape=[6,1] must match the outer 1 dimensions of updates.shape=[3,6]: Dimension 0 in both shapes must be equal, but are 6 and 3. Shapes are [6] and [3]. for 'ScatterNd_2' (op: 'ScatterNd') with input shapes: [6,1], [3,6], [2]. Seems like my indices is specifying row indices instead of column indices, and given the way that arrays are ""connected"" in numpy and tensorflow (i.e. row-major order), does that mean I need to explicitly specify every single pair of indices for every element in updates1? Or is there some kind of 'wildcard' specification I can use for the rows? (Note indices1 = tf.constant([[:,0], [:,1], [:,3], [:,4], [:,6], [:,7]]) gives syntax errors, as it probably should.) Would it be easier to just do a transpose, interleave the rows, then transpose back? Because I tried that... ...and got a much longer error message, that I don't feel like posting unless someone requests it. PS- I searched to make sure this isn't a duplicate -- I find it hard to imagine that someone else hasn't asked this before -- but turned up nothing.",https://stackoverflow.com/questions/52572275,4259243,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I've read the tf.scatter_nd documentation and run the example code for 1D and 3D tensors and now I'm trying to do it for a 2D tensor. I want to 'interleave' the columns of two tensors. For 1D tensors, one can do this via (aside: is there a better way to do this? I'm all ears.) This gives the output [ 1 2 10 3 4 11 5 6 12] Yay! that worked! Now lets' try to extend this to 2D. This gives the error ValueErro"
52731151,Tesnorflow: How to provide your own `sampled_values` for tf.nn.sampled_softmax_loss?,"<p>In tf.nn.sampled_softmax_loss, one of the optional inputs is to put your own samples values. I would like to provide my own samples values so that I can use float16 (half precision) variables. If <code>sampled_values</code> is left blank, Tensorflow will use <code>log_uniform_candidate_sampler</code> to get values, which can only return float32. </p>

<p>Here are all the inputs. </p>

<pre><code>tf.nn.sampled_softmax_loss(
    weights,
    biases,
    labels,
    inputs,
    num_sampled,
    num_classes,
    num_true=1,
    sampled_values=None,
    remove_accidental_hits=True,
    partition_strategy='mod',
    name='sampled_softmax_loss',
    seed=None
)
</code></pre>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss</a></p>

<p>This is the information they give for the sampled_values arg :</p>

<blockquote>
  <p>sampled_values: a tuple of (sampled_candidates, true_expected_count,
  sampled_expected_count) returned by a *_candidate_sampler function.
  (if None, we default to log_uniform_candidate_sampler)</p>
</blockquote>

<p>I'm trying to figure out how to provide this tuple. What exactly are the <code>sampled_candidates</code>, <code>true_expected_count</code>, <code>sampled_expected_count</code> ? </p>

<p>I know that it's sampling the weights and corresponding biases, so do I put them together in it's own tuple for <code>sampled_candidates</code> ? Also, am I putting the int for the place of the weight in the matrix, or am I putting the whole embedding itself?</p>

<p>I've also looked at Tensorflow's math supplimental on negative sampling but I couldn't find any information for my issue <a href=""https://www.tensorflow.org/extras/candidate_sampling.pdf"" rel=""noreferrer"">https://www.tensorflow.org/extras/candidate_sampling.pdf</a></p>

<p>In my search, I found this very similar question on a google forum</p>

<p><a href=""https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/6IDJ-XAIb9M"" rel=""noreferrer"">https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/6IDJ-XAIb9M</a></p>

<p>The Answer given is </p>

<blockquote>
  <p><code>sampled_values</code> is the tuple returned by our *candidate_sampler
  classes. These classes implement methods that sample contrastive
  labels (not observed, but used during training) according to some
  distribution Q for use in approximate training methods like
  noise-contrastive estimation (NCE) and Sampled Softmax. An example is
  the log_uniform_candidate_sampler, which samples labels according to
  the log-uniform distribution. </p>
  
  <p>You almost never need to provide these yourself. You would simply pass
  in the result of a call to a *candidate_sampler function in the tf.nn
  module (where * can be ""uniform"", ""log_uniform"", ""zipfian_binned"",
  etc), e.g.</p>
  
  <p>sampled_values = tf.nn.zipfian_binned_candidate_sampler(...)</p>
  
  <p>If you just want to get it to work, just leave it to None, and it
  would default to the log_uniform_candidate_sampler (often a good
  choice).</p>
  
  <p>If you are interested in the math behind this, see this document:
  <a href=""https://www.tensorflow.org/versions/r0.8/extras/candidate_sampling.pdf"" rel=""noreferrer"">https://www.tensorflow.org/versions/r0.8/extras/candidate_sampling.pdf</a>.</p>
  
  <p>But to answer your question: For each batch of observed labels L, and
  a candidate sampling distribution Q, the tuple consists of:</p>
  
  <ul>
  <li>the tensor with the actual sampled contrastive labels N, </li>
  <li>the tensor with the log-expected-values of the observed labels L under Q, i.e. log Q(L), and </li>
  <li>the tensor with the log-expected values of the contrastive labels under Q, i.e. log Q(N).</li>
  </ul>
  
  <p>The latter are required for the math to go through (see above
  document). So sampled_values contains(with a hopefully clear abuse of
  notation): </p>
  
  <p>sampled_values = (N, log Q(L), log Q(N)).</p>
</blockquote>

<p>However, I still don't know how to input a value. I'm not sure what the datatypes should be, and if N is the int place in the embedding matrix, or the embedding itself. Also, I'm guessing N should be a list of values itself, the size of the number of negative labels we have to sample. </p>

<p>I was wondering if I could get a example with some values. For example, for a negative sampling of 3, do I do something like this? </p>

<p>sampled_values = ([4,29, 12], [1, 1, 1], [0, 0, 0])</p>

<p>Also, the documentation says that the tuple should be "" returned by a *_candidate_sampler function""</p>

<p>Does that mean I need to provide a function that returns the tuple, instead of the tuple itself?</p>
","In tf.nn.sampled_softmax_loss, one of the optional inputs is to put your own samples values. I would like to provide my own samples values so that I can use float16 (half precision) variables. If sampled_values is left blank, Tensorflow will use log_uniform_candidate_sampler to get values, which can only return float32. Here are all the inputs. https://www.tensorflow.org/api_docs/python/tf/nn/sampled_softmax_loss This is the information they give for the sampled_values arg : I'm trying to figure out how to provide this tuple. What exactly are the sampled_candidates, true_expected_count, sampled_expected_count ? I know that it's sampling the weights and corresponding biases, so do I put them together in it's own tuple for sampled_candidates ? Also, am I putting the int for the place of the weight in the matrix, or am I putting the whole embedding itself? I've also looked at Tensorflow's math supplimental on negative sampling but I couldn't find any information for my issue https://www.tensorflow.org/extras/candidate_sampling.pdf In my search, I found this very similar question on a google forum https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/6IDJ-XAIb9M The Answer given is However, I still don't know how to input a value. I'm not sure what the datatypes should be, and if N is the int place in the embedding matrix, or the embedding itself. Also, I'm guessing N should be a list of values itself, the size of the number of negative labels we have to sample. I was wondering if I could get a example with some values. For example, for a negative sampling of 3, do I do something like this? sampled_values = ([4,29, 12], [1, 1, 1], [0, 0, 0]) Also, the documentation says that the tuple should be "" returned by a *_candidate_sampler function"" Does that mean I need to provide a function that returns the tuple, instead of the tuple itself?",https://stackoverflow.com/questions/52731151,3259896,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"Also, the documentation says that the tuple should be "" returned by a *_candidate_sampler function"" Does that mean I need to provide a function that returns the tuple, instead of the tuple itself?"
52814880,Neuron freezing in Tensorflow,"<p>I need to implement <strong>neurons freezing</strong> in CNN for a deep learning research,
I tried to find any function in the Tensorflow docs, but I didn't find anything.
How can I freeze specific neuron when I implemented the layers with tf.nn.conv2d?</p>
","I need to implement neurons freezing in CNN for a deep learning research, I tried to find any function in the Tensorflow docs, but I didn't find anything. How can I freeze specific neuron when I implemented the layers with tf.nn.conv2d?",https://stackoverflow.com/questions/52814880,6194504,Documentation Replicability,Documentation Replication on Other Examples,"I need to implement neurons freezing in CNN for a deep learning research, I tried to find any function in the Tensorflow docs, but I didn't find anything."
52976606,Global step not incrementing with batch norm and custom estimator,"<p>I have a customer estimator that has several layers that look like the following in the model function:</p>

<pre><code>natural_layer = tf.layers.dense(inputs = natural_layer, 
                                units = units, 
                                activation = None,
                                use_bias = False,
                                kernel_regularizer = params['regularizer'],
                                name = 'pre_batch_norm_layer_' + str(i + 1))

natural_layer = tf.layers.batch_normalization(natural_layer,
                                              axis = 1,
                                              center = True,
                                              scale = True,
                                              training = (mode == tf.estimator.ModeKeys.TRAIN),
                                              name = 'batch_norm_layer_' + str(i + 1))

natural_layer = params['natural_layer_activation'](natural_layer, name = 'activation_layer_' + str(i + 1))
</code></pre>

<p>Because I'm using batch norm, the training op is set up like this:</p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    optimizer = tf.contrib.opt.MultitaskOptimizerWrapper(params['optimization_algorithm'](params['training_rate']))
    train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())
</code></pre>

<p>Where the optimizer is usually tf.train.AdamOptimizer.</p>

<p>However, when I go to train the estimator the global step never increments (so training will run forever), and I get this:</p>

<p>WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.</p>

<p>I am passing tf.train.get_global_step() to minimize, so I'm not sure why it never gets updated. My hunch is that it has something to do with the batch normalization because when I remove that or replace it with dropout, everything works fine (even when keeping the update ops lines that are required for batch normalization per the documentation).</p>

<p>Anyone know what is going on? Happy to post more code if helpful. </p>
","I have a customer estimator that has several layers that look like the following in the model function: Because I'm using batch norm, the training op is set up like this: Where the optimizer is usually tf.train.AdamOptimizer. However, when I go to train the estimator the global step never increments (so training will run forever), and I get this: WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize. I am passing tf.train.get_global_step() to minimize, so I'm not sure why it never gets updated. My hunch is that it has something to do with the batch normalization because when I remove that or replace it with dropout, everything works fine (even when keeping the update ops lines that are required for batch normalization per the documentation). Anyone know what is going on? Happy to post more code if helpful.",https://stackoverflow.com/questions/52976606,9226290,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"My hunch is that it has something to do with the batch normalization because when I remove that or replace it with dropout, everything works fine (even when keeping the update ops lines that are required for batch normalization per the documentation). Anyone know what is going on? "
53032922,TensorFlow while loop with condition dependent on body,"<p>I want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don't know how to accomplish this with <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop()</code></a>.</p>

<p>My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by</p>

<pre><code>import numpy as np
import tensorflow as tf
IMAGE_SHAPE = [960, 720]
CROP_SHAPE = [320, 240]
max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE)
crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index)
img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])
</code></pre>

<p>and the condition is</p>

<pre><code>cond = tf.count_nonzero(img_crop &gt; 0) &gt; 0.5 * tf.size(img_crop)
</code></pre>

<p>Going over the documentation and examples of <code>tf.while_loop(cond, body, loop_vars, ...)</code>, what I understand is that both <code>cond</code> and <code>body</code> should take the same arguments given in <code>loop_vars</code>.
I don't see how I can have <code>cond</code> depend on <code>img_crop</code> which would be calculated inside <code>body</code>, and isn't provided in <code>loop_vars</code>.</p>

<p>I could equivalently compute <code>cond</code> using <code>crop_begin_index</code> without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem.</p>

<p>Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use <code>tf.while_loop()</code>?</p>
","I want to have a while loop with the condition dependent on a tensor computed in the loop body, but I don't know how to accomplish this with tf.while_loop(). My input processing includes random cropping, but some crops can lead to low-quality examples and I want to discard those and try a new random crop until an example of sufficient quality is obtained. The inputs are cropped by and the condition is Going over the documentation and examples of tf.while_loop(cond, body, loop_vars, ...), what I understand is that both cond and body should take the same arguments given in loop_vars. I don't see how I can have cond depend on img_crop which would be calculated inside body, and isn't provided in loop_vars. I could equivalently compute cond using crop_begin_index without actually cropping, but it depends on the random values computed inside the loop, so I have the same problem. Is this indeed a limitation of TF looping? If not, how can I rewrite my code to use tf.while_loop()?",https://stackoverflow.com/questions/53032922,2260153,Documentation Replication on Other Examples,Documentation Replication on Other Examples," Going over the documentation and examples of tf.while_loop(cond, body, loop_vars, ...), what I understand is that both cond and body should take the same arguments given in loop_vars. I don't see how I can have cond depend on img_crop which would be calculated inside body, and isn't provided in loop_vars."
53079436,tensorflow Tf.cond giving unexpected output,"<p>I seem to be having a misunderstanding on how <code>tf.cond</code> works. In the tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/cond"" rel=""nofollow noreferrer"">documentation</a>, it gives the following example:</p>

<pre><code>z = tf.multiply(a, b)
result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))
</code></pre>

<p>The result of the example, if <code>x&lt;y</code> is <code>True</code> is <code>tf.add(x,z)</code> else <code>tf.square(y)</code></p>

<p>Following this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation.</p>

<p>in my example, <code>deterministic_action = 4</code>, <code>random_action = 11</code>, <code>chose_random=False</code>. The <code>stochastic_action</code> should be <code>4</code>, instead it is <code>1</code>.
Where did the value 1 come from?</p>

<pre><code>#!/usr/bin/env python3

import tensorflow as tf
import numpy as np

with tf.Graph().as_default():
    with tf.device('/cpu:0'):
        stochastic_ph = tf.placeholder(tf.bool, (), name=""stochastic"")
        eps = tf.get_variable(""eps"", (), initializer=tf.constant_initializer(0))
        with tf.variable_scope('test_cond') as sc:
            deterministic_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=0) # 4
            random_action = tf.random_uniform([], minval=0, maxval=15, dtype=tf.int64, seed=1) # 11
            chose_random = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32) &lt; eps # False because eps = 0
            stochastic_action = tf.cond(chose_random, lambda: random_action, lambda: deterministic_action) # S_action should be 4 but it is 1
            #output_action = tf.cond(stochastic_ph, lambda: stochastic_action, lambda: deterministic_action)


    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init, feed_dict={stochastic_ph: True})
    print (""s_ph = "", stochastic_ph)
    d_action = sess.run(deterministic_action)
    print (""det_action= "", d_action)
    r_action = sess.run(random_action)
    print (""rand_action= "", r_action)
    e = sess.run(eps)
    c_action = sess.run(chose_random)
    print (""chose_rand= "", c_action)
    s_action = sess.run(stochastic_action)
    print (""s_action= "", s_action)
    #output = sess.run(output_action)
</code></pre>

<p>here is the output:</p>

<pre><code>python random_vec.py
2018-10-31 09:46:15.028376: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)
det_action=  4
rand_action=  11
chose_rand=  False
s_action=  1
</code></pre>
","I seem to be having a misunderstanding on how tf.cond works. In the tensorflow documentation, it gives the following example: The result of the example, if x&lt;y is True is tf.add(x,z) else tf.square(y) Following this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation. in my example, deterministic_action = 4, random_action = 11, chose_random=False. The stochastic_action should be 4, instead it is 1. Where did the value 1 come from? here is the output:",https://stackoverflow.com/questions/53079436,1059860,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"In the tensorflow documentation, it gives the following example: The result of the example, if x&lt;y is True is tf.add(x,z) else tf.square(y) Following this example, I am trying to build a small example with tf.cond and the result doesnt go along the lines mentioned in the documentation."
42697341,"How to use softmax activation function at the output layer, but relus in the middle layers in TensorFlow?","<p>I have a neural net of 3 hidden layers (so I have 5 layers in total). I want to use <strong>Rectified Linear Units</strong> at each of the hidden layers, but at the outermost layer I want to apply <strong>Softmax</strong> on the logits. I want to use the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier"" rel=""nofollow noreferrer""><code>DNNClassifier</code></a>. I have read the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier"" rel=""nofollow noreferrer"">official documentation</a> of the TensorFlow where for setting value of the parameter <code>activation_fn</code> they say: </p>

<blockquote>
  <p>activation_fn: Activation function applied to each layer. If None, will use tf.nn.relu.</p>
</blockquote>

<p>I know I can always write my own model and use any arbitrary combination of the activation functions. But as the <code>DNNClassifier</code> is more concrete, I want to resort to that. So far I have:</p>

<pre><code>classifier = tf.contrib.learn.DNNClassifier(
  feature_columns=features_columns,
  hidden_units=[10,20,10],
  n_classes=3
  # , activation_fn:::: I want something like below
  # activation_fn = [relu,relu,relu,softmax]
)
</code></pre>
","I have a neural net of 3 hidden layers (so I have 5 layers in total). I want to use Rectified Linear Units at each of the hidden layers, but at the outermost layer I want to apply Softmax on the logits. I want to use the DNNClassifier. I have read the official documentation of the TensorFlow where for setting value of the parameter activation_fn they say: I know I can always write my own model and use any arbitrary combination of the activation functions. But as the DNNClassifier is more concrete, I want to resort to that. So far I have:",https://stackoverflow.com/questions/42697341,4933403,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I have read the official documentation of the TensorFlow where for setting value of the parameter activation_fn they say: I know I can always write my own model and use any arbitrary combination of the activation functions. But as the DNNClassifier is more concrete, I want to resort to that."
66171799,Tensorflow incompatible matrix size when using GradientTape,"<p>I am trying to run code that previously worked on tensorflow 2.2.0 on version 2.4.0-rc0 for apple silicon (using python 3.8), but it is now generating the following error regarding the matrix dimensions:</p>
<p><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: GetOutputShape: Matrix size-incompatible: In[0]: [256,4], In[1]: [4,400]</code></p>
<p>I am using nested gradient tapes to compute the gradient of my MLP model wrt the inputs (which form part of the loss), after which I compute the gradient of the loss wrt the trainable variables as below:</p>
<pre><code>    def get_grad_and_loss(self, x, y):
        with tf.GradientTape(persistent=True) as gl_tape:
            gl_tape.watch(x)

            with tf.GradientTape(persistent=True) as l_tape:
                l_tape.watch(x)
                y_pred = self.call(x)

            grad_mat = l_tape.gradient(y_pred, x)
            loss = tf.reduce_mean(tf.math.square(y_pred - y[:, tf.newaxis])) + tf.reduce_mean(tf.maximum(0, -1 * (grad_mat[:, 0])))

        g = gl_tape.gradient(loss, self.trainable_weights)

        return g, loss
</code></pre>
<p>In words I am computing the MSE and trying to force the sign of the gradient to be positive (as a soft constraint). I have read through the documentation on <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">gradient tape</a> and as I understand it, setting <code>persistent=True</code> should allow me to recompute gradients freely. As a side note my code works fine if I omit the nested gradient tape and simply use the MSE metric, so I don't think the issue lies anywhere else in the code. Any pointers would be much appreciated, thanks in advance :)</p>
","I am trying to run code that previously worked on tensorflow 2.2.0 on version 2.4.0-rc0 for apple silicon (using python 3.8), but it is now generating the following error regarding the matrix dimensions: tensorflow.python.framework.errors_impl.InvalidArgumentError: GetOutputShape: Matrix size-incompatible: In[0]: [256,4], In[1]: [4,400] I am using nested gradient tapes to compute the gradient of my MLP model wrt the inputs (which form part of the loss), after which I compute the gradient of the loss wrt the trainable variables as below: In words I am computing the MSE and trying to force the sign of the gradient to be positive (as a soft constraint). I have read through the documentation on gradient tape and as I understand it, setting persistent=True should allow me to recompute gradients freely. As a side note my code works fine if I omit the nested gradient tape and simply use the MSE metric, so I don't think the issue lies anywhere else in the code. Any pointers would be much appreciated, thanks in advance :)",https://stackoverflow.com/questions/66171799,12860541,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I have read through the documentation on gradient tape and as I understand it, setting persistent=True should allow me to recompute gradients freely. As a side note my code works fine if I omit the nested gradient tape and simply use the MSE metric, so I don't think the issue lies anywhere else in the code"
38400360,Working with tensorflow's shuffle_batch method,"<p>I'm experimenting with <a href=""https://www.tensorflow.org/"" rel=""nofollow"">tensorflow</a> and I'm trying to read from a <code>csv</code> file and print out a batch of its data via <code>shuffle_batch</code>. I've gone throw the <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/io_ops.html#decode_csv"" rel=""nofollow"">decode_csv docs</a> and the <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/io_ops.html#shuffle_batch"" rel=""nofollow"">shuffle_batch docs</a>, but I'm still unable to get it working.</p>

<p>Here's what I have:
import tensorflow as tf</p>

<pre><code>sess = tf.InteractiveSession()

filename_queue = tf.train.string_input_producer(
    [""./data/train.csv""], num_epochs=1, shuffle=True) # total record count in csv is 30K
reader = tf.TextLineReader()
key, value = reader.read(filename_queue)

record_defaults = [[""1""], [""2""]] # irrelevant for this discussion
input, outcome = tf.decode_csv(value, record_defaults=record_defaults)

min_after_dequeue = 1000
batch_size = 10
capacity = min_after_dequeue + 3 * batch_size

example_batch = tf.train.shuffle_batch([outcome], batch_size, capacity, min_after_dequeue)
coord = tf.train.Coordinator()
tf.train.start_queue_runners(sess, coord=coord)
example_batch.eval(session = sess)
</code></pre>

<p>Running this will generate this exception:</p>

<pre><code>OutOfRangeError: RandomShuffleQueue
    '_3_shuffle_batch_1/random_shuffle_queue' is closed 
    and has insufficient elements (requested 10, current size 0)
</code></pre>

<p>I'm not sure what the issue is. I have a feeling it's due to the session and the way I'm handling it; I'm probably not doing it properly. </p>
","I'm experimenting with tensorflow and I'm trying to read from a csv file and print out a batch of its data via shuffle_batch. I've gone throw the decode_csv docs and the shuffle_batch docs, but I'm still unable to get it working. Here's what I have: import tensorflow as tf Running this will generate this exception: I'm not sure what the issue is. I have a feeling it's due to the session and the way I'm handling it; I'm probably not doing it properly.",https://stackoverflow.com/questions/38400360,409865,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I'm experimenting with tensorflow and I'm trying to read from a csv file and print out a batch of its data via shuffle_batch. I've gone throw the decode_csv docs and the shuffle_batch docs, but I'm still unable to get it working."
66685673,tf.io.decode_raw return tensor how to make it bytes or string,"<p>I'm struggling with this for a while. I searched stack and check tf2
doc a bunch of times. There is one solution indicated, but
I don't understand why my solution doesn't work.</p>
<p>In my case, I store a binary string (i.e., bytes) in tfrecords.
if I iterate over dataset via as_numpy_list or directly call numpy()
on each item, I can get back binary string.
while iterating the dataset, it does work.</p>
<p>I'm not sure what exactly map() passes to test_callback.
I see doesn't have a method nor property numpy, and the same about type
tf.io.decode_raw return. (it is Tensor, but it has no numpy as well)</p>
<p>Essentially I need to take a binary string, parse it via my
x = decoder.FromString(y) and then pass it my encoder
that will transform x binary string to tensor.</p>
<pre><code>def test_callback(example_proto):

    # I tried to figure out. can I use bytes?decode 
    # directly and what is the most optimal solution.

    parsed_features = tf.io.decode_raw(example_proto, out_type=tf.uint8)
    # tf.io.decoder returns tensor with N bytes.

    x = creator.FromString(parsed_features.numpy)
    encoded_seq = midi_encoder.encode(x)
    return encoded_seq

raw_dataset = tf.data.TFRecordDataset(filenames=[&quot;main.tfrecord&quot;])
raw_dataset = raw_dataset.map(test_callback)

</code></pre>
<p>Thank you, folks.</p>
","I'm struggling with this for a while. I searched stack and check tf2 doc a bunch of times. There is one solution indicated, but I don't understand why my solution doesn't work. In my case, I store a binary string (i.e., bytes) in tfrecords. if I iterate over dataset via as_numpy_list or directly call numpy() on each item, I can get back binary string. while iterating the dataset, it does work. I'm not sure what exactly map() passes to test_callback. I see doesn't have a method nor property numpy, and the same about type tf.io.decode_raw return. (it is Tensor, but it has no numpy as well) Essentially I need to take a binary string, parse it via my x = decoder.FromString(y) and then pass it my encoder that will transform x binary string to tensor. Thank you, folks.",https://stackoverflow.com/questions/66685673,9063497,Requesting (Additional) Resources,Documentation Replication on Other Examples,"I'm struggling with this for a while. I searched stack and check tf2 doc a bunch of times. There is one solution indicated, but I don't understand why my solution doesn't work."
49543158,How to use weights in tf.metrics.auc?,"<p>The docs for the <a href=""https://www.tensorflow.org/api_docs/python/tf/metrics/auc"" rel=""nofollow noreferrer"">tf.metrics.auc function in tensorflow</a> say</p>

<blockquote>
  <p>weights: Optional Tensor whose rank is either 0, or the same rank as labels, and must be broadcastable to labels (i.e., all dimensions must be either 1, or the same as the corresponding labels dimension).</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>If weights is None, weights default to 1. Use weights of 0 to mask values.</p>
</blockquote>

<p>Suppose I want to use the weights to measure two AUCs: one for men, one for women.</p>

<p>Can you give an example of how to do that?</p>

<p><strong>EDIT</strong>: And suppose I have enough classes that I don't want to divide the data into all the different classes, and enough data that I don't want to read it all into memory.  That is, I want to do it in a streaming fashion.</p>
","The docs for the tf.metrics.auc function in tensorflow say and Suppose I want to use the weights to measure two AUCs: one for men, one for women. Can you give an example of how to do that? EDIT: And suppose I have enough classes that I don't want to divide the data into all the different classes, and enough data that I don't want to read it all into memory. That is, I want to do it in a streaming fashion.",https://stackoverflow.com/questions/49543158,34935,Requesting (Additional) Resources,Documentation Replication on Other Examples,"The docs for the tf.metrics.auc function in tensorflow say and Suppose I want to use the weights to measure two AUCs: one for men, one for women. Can you give an example of how to do that?"
58044469,Gaussian Process Regression in Tensorflow 2.0 leads to no gradients?,"<p>The following code is basically from the documentation, slightly converted to run in tensorflow 2.0. The gradients are all None. I'm not sure if this is a bug or just something I am missing:</p>

<p>(corrected code)</p>

<pre><code>import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp

tfd = tfp.distributions
psd_kernels = tfp.positive_semidefinite_kernels

tf.keras.backend.set_floatx('float64')

f = lambda x: np.sin(10*x[..., 0]) * np.exp(-x[..., 0]**2)

observation_index_points = np.random.uniform(-1., 1., 50)[..., np.newaxis]
observations = f(observation_index_points) + np.random.normal(0., .05, 50)


class Model(tf.keras.models.Model):
    def __init__(self):
        super().__init__()
        self.amplitude_ = tf.Variable(np.float64(0), trainable=True)
        self.amplitude = tf.exp(self.amplitude_, name='amplitude')
        self.length_scale_ = tf.Variable(np.float64(0), trainable=True)
        self.length_scale = tf.exp(self.length_scale_, name='length_scale')
        self.kernel = psd_kernels.ExponentiatedQuadratic(self.amplitude, self.length_scale)
        self.observation_noise_variance_ = tf.Variable(np.float64(-5), trainable=True)
        self.observation_noise_variance = tf.exp(self.observation_noise_variance_, name='observation_noise_variance')


    def gp(self, observation_index_points):
        return tfd.GaussianProcess(
            kernel=self.kernel,
            index_points=observation_index_points,
            observation_noise_variance=self.observation_noise_variance)

    def call(self, observation_index_points, observations, index_points):
        return tfd.GaussianProcessRegressionModel(
        kernel=self.kernel,
        index_points=index_points,
        observation_index_points=observation_index_points,
        observations=observations,
        observation_noise_variance=self.observation_noise_variance)

optimizer = tf.keras.optimizers.Adam(learning_rate=.05)

# We can construct the posterior at a new set of `index_points` using the same
# kernel (with the same parameters, which we'll optimize below).
index_points = np.linspace(-1., 1., 100)[..., np.newaxis]

model = Model()
gprm = model(observation_index_points, observations, index_points)
gp = model.gp(observation_index_points)
gp.log_prob(observations)
samples = gprm.sample(10)

trainable_variables = [model.amplitude_, model.length_scale_, model.observation_noise_variance_]
with tf.GradientTape() as tape:
    loss = -gp.log_prob(observations)
print(loss)
g = tape.gradient(loss, trainable_variables)
print(g)
</code></pre>

<p>UPDATE:</p>

<p>The following example now works. Am wondering if there is a better pattern for organizing this flow in tf 2.0? </p>

<pre><code> import numpy as np
import tensorflow as tf
import tensorflow_probability as tfp
tfb = tfp.bijectors
tfd = tfp.distributions
psd_kernels = tfp.positive_semidefinite_kernels

m = 1000
n = 3
x = np.random.randn(m, n).astype(np.float32)
y = np.random.randn(m).astype(np.float32)
x_  = np.random.randn(100, n).astype(np.float32)


class GPRMatern(tf.keras.models.Model):
    def __init__(self, feature_ndims=1):
        super().__init__()
        self.kernel = psd_kernels.MaternFiveHalves()
        self.observation_noise_variance = tf.Variable(np.float32(.01), name='obs_noise_variance')

    def gprm(self, x_obs, y_obs, x):
        return tfd.GaussianProcessRegressionModel(
            kernel=self.kernel,
            index_points=x,
            observation_index_points=x_obs,
            observations=y_obs,
            observation_noise_variance=self.observation_noise_variance)

    def nll_for_train(self, x_obs, y_obs):
        gp = tfd.GaussianProcess(
            kernel=self.kernel,
            index_points=x_obs,
            observation_noise_variance=self.observation_noise_variance)
        return -tf.reduce_mean(gp.log_prob(y_obs))

class GPRExpQuad(tf.keras.models.Model):
    def __init__(self):
        super().__init__()
        self.amplitude = tf.Variable(np.float32(0.0), name='amplitude')
        self.length_scale = tf.Variable(np.float32(0.0), name='length_scale')
        self.observation_noise_variance = tf.Variable(np.float32(-5.0), name='obs_noise_variance')

    @property
    def kernel(self):
        return psd_kernels.ExponentiatedQuadratic(tf.exp(self.amplitude), tf.exp(self.length_scale))

    def nll_for_train(self, x_obs, y_obs):
        gp = tfd.GaussianProcess(
            kernel=self.kernel,
            index_points=x_obs,
            observation_noise_variance=tf.exp(self.observation_noise_variance))
        return -tf.reduce_mean(gp.log_prob(y_obs))

    def gprm(self, x_obs, y_obs, x):
        return tfd.GaussianProcessRegressionModel(
            kernel=self.kernel,
            index_points=x,
            observation_index_points=x_obs,
            observations=y_obs,
            observation_noise_variance=tf.exp(self.observation_noise_variance))

def test_model(model=GPRMatern):
    model = model()
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
    # model.fit(x, y, epochs=steps)
    for i in range(10):
        with tf.GradientTape() as tape:
            l = model.nll_for_train(x, y)
        g = tape.gradient(l, model.trainable_variables)
        optimizer.apply_gradients(zip(g, model.trainable_variables))
        print({x.name: x.numpy() for x in model.trainable_variables})

matern = GPRMatern()
expquad = GPRExpQuad()

test_matern = lambda : test_model(model=GPRMatern)
test_expquad = lambda : test_model(model=GPRExpQuad)
</code></pre>
","The following code is basically from the documentation, slightly converted to run in tensorflow 2.0. The gradients are all None. I'm not sure if this is a bug or just something I am missing: (corrected code) UPDATE: The following example now works. Am wondering if there is a better pattern for organizing this flow in tf 2.0?",https://stackoverflow.com/questions/58044469,287238,Documentation Replication on Other Examples,Documentation Replicability,"The following code is basically from the documentation, slightly converted to run in tensorflow 2.0."
65264697,How to set signature in keras.models.save_ model,"<h1>My environment</h1>
<p>tf:2.3
system:ubuntu 18</p>
<h1>My question</h1>
<p>I updated from tf14 to tf2.3. The model I used is a model of keras type. After viewing the official document, adding signature failed</p>
<h1>My main code</h1>
<pre><code>model = VGG16(weights = weights_dir)
...
keras.models.save_model(model, model_dir_saved_model)
</code></pre>
<p>This function has the input of signature, but I don't know how to organize it</p>
<h1>Here's my try</h1>
<pre><code>
def saveKerasModelAsProtobuf(model, outputPath):
    inputs = {'image': utils.build_tensor_info(model.input)}
    outputs = {'scores': utils.build_tensor_info(model.output)}

    signature = tf.saved_model.signature_def_utils.build_signature_def(
        inputs, outputs, 'name')

    builder = tf.saved_model.builder.SavedModelBuilder(outputPath)
    builder.add_meta_graph_and_variables(
        sess=keras.backend.get_session(),
        tags=['serving_default'],
        signature_def_map={'serving_default': signature})
    builder.save()
</code></pre>
<p>So, what's the right way to keep it</p>
","tf:2.3 system:ubuntu 18 I updated from tf14 to tf2.3. The model I used is a model of keras type. After viewing the official document, adding signature failed This function has the input of signature, but I don't know how to organize it So, what's the right way to keep it",https://stackoverflow.com/questions/65264697,14812957,Documentation Replicability,Documentation Replicability,"After viewing the official document, adding signature failed."
66149002,How to convert .pb file to .tflite. in tensorflow 2.1.0,"<p>I have trained my model using <strong>SSD MobileNet V2 FPNLite 640x640</strong> and <strong>tensorflow 2.1.0</strong>. To create .pb file used file <em>export_tflite_graph_tf2.py</em>. Now , want to convert .pb file to .tflite.
I used following code code recommended by tensorflow community .But it is converting the model to 1kb tflite file.</p>
<p>I tried also using tf-nightly  but same converts into 1kb</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
</code></pre>
","I have trained my model using SSD MobileNet V2 FPNLite 640x640 and tensorflow 2.1.0. To create .pb file used file export_tflite_graph_tf2.py. Now , want to convert .pb file to .tflite. I used following code code recommended by tensorflow community .But it is converting the model to 1kb tflite file. I tried also using tf-nightly but same converts into 1kb",https://stackoverflow.com/questions/66149002,11311304,Inadequate Examples,Documentation Replicability,I used following code code recommended by tensorflow community. But it is converting the model to 1kb tflite file.
76440119,Can't fold BatchNorm with Conv2D in Keras QAT basic example,"<p>I'm currently trying to use Keras' Quantization Aware Training, specifically because I need to do 8bit inference on a low-precision device. For this reason, I need to fold the batch norm onto the Convolution to avoid having the 32-bit moving mean and variance. The sample code I'm starting with is the following (tf1.15, tensorflow-model-optimization 0.6.0):</p>
<pre><code>    model = tf.keras.Sequential([
        tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),
        tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Activation('relu'),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1000)
    ])



    quantize_model = tfmot.quantization.keras.quantize_model

    # q_aware stands for for quantization aware.
    q_aware_model = quantize_model(model)

    # `quantize_model` requires a recompile.
    q_aware_model.compile(optimizer='adam',
                loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=smooth),
                metrics=['accuracy'])

    q_aware_model.summary()
</code></pre>
<p>The documentation states that 'Conv2D+BN+ReLU' should have the BatchNorm folded but that isn't the case in the .h5 file produced.</p>
","I'm currently trying to use Keras' Quantization Aware Training, specifically because I need to do 8bit inference on a low-precision device. For this reason, I need to fold the batch norm onto the Convolution to avoid having the 32-bit moving mean and variance. The sample code I'm starting with is the following (tf1.15, tensorflow-model-optimization 0.6.0): The documentation states that 'Conv2D+BN+ReLU' should have the BatchNorm folded but that isn't the case in the .h5 file produced.",https://stackoverflow.com/questions/76440119,21807405,Documentation Replication on Other Examples,Documentation Replicability,The documentation states that 'Conv2D+BN+ReLU' should have the BatchNorm folded but that isn't the case in the .h5 file produced.
41195121,Tensorflow.strided_slice missing argument 'strides'?,"<p>I am trying to run <code>cifar10_train.py</code> according to tutorials, but I got </p>

<pre><code>""cifar10_input.py"", line 87, in read_cifar10
tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)
TypeError: strided_slice() missing 1 required positional argument: 'strides'
</code></pre>

<p>The document says that <code>strides</code> is optional, and it did work properly on Ubuntu before.</p>

<p>My tensorflow version is 0.12.0rc1-cp35-cp35m-win_amd64. I have already installed the newest release.</p>

<p>May I have to pass this argument? I have no idea about it...</p>

<p>UPDATE: I replaced strided_slice with slice, and it works. According to issue#754, <code>strides</code> will be optional at 1.0 release. (maybe?)</p>
","I am trying to run cifar10_train.py according to tutorials, but I got The document says that strides is optional, and it did work properly on Ubuntu before. My tensorflow version is 0.12.0rc1-cp35-cp35m-win_amd64. I have already installed the newest release. May I have to pass this argument? I have no idea about it... UPDATE: I replaced strided_slice with slice, and it works. According to issue#754, strides will be optional at 1.0 release. (maybe?)",https://stackoverflow.com/questions/41195121,7244589,Documentation Completeness,Documentation Replicability,"The document says that strides is optional, and it did work properly on Ubuntu before."
42818842,Transitioning to Tensorflow 1.0.0,"<p>I am trying to translate <a href=""https://github.com/yenchenlin/pix2pix-tensorflow/blob/e0ef0323c5ccbd066fea117a012f5d7e748ee6ce/model.py"" rel=""nofollow noreferrer"">this</a> pix2pix GAN code to Tensorflow 1.0.0 using the following <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/compatibility/tf_upgrade.py"" rel=""nofollow noreferrer"">script</a> as described in Tensorflow Documentation, but I keep getting the following error: </p>

<blockquote>
  <p>ValueError: Variable d_h0_conv/w/Adam/ does not exist, or was not
  created with tf.get_variable(). Did you mean to set reuse=None in
  VarScope?</p>
</blockquote>

<p>This is the Adam optimizer part: </p>

<pre><code> d_optim = tf.train.AdamOptimizer(args.lr, beta1=args.beta1) \
.minimize(self.d_loss, var_list=self.d_vars)
</code></pre>

<p>Where d_vars is:</p>

<pre><code>t_vars = tf.trainable_variables()

self.d_vars = [var for var in t_vars if 'd_' in var.name]
</code></pre>

<p>And the discriminator code: </p>

<pre><code>    def discriminator(self, image, y=None, reuse=False):
        # image is 256 x 256 x (input_c_dim + output_c_dim)
        if reuse:
            tf.get_variable_scope().reuse_variables()
        else:
            assert tf.get_variable_scope().reuse == False

        h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))
        # h0 is (128 x 128 x self.df_dim)
        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv')))
        # h1 is (64 x 64 x self.df_dim*2)
        h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*4, name='d_h2_conv')))
        # h2 is (32x 32 x self.df_dim*4)
        h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*8, d_h=1, d_w=1, name='d_h3_conv')))
        # h3 is (16 x 16 x self.df_dim*8)
        h4 = linear(tf.reshape(h3, [self.batch_size, -1]), 1, 'd_h3_lin')
  return tf.nn.sigmoid(h4), h4
</code></pre>
","I am trying to translate this pix2pix GAN code to Tensorflow 1.0.0 using the following script as described in Tensorflow Documentation, but I keep getting the following error: This is the Adam optimizer part: Where d_vars is: And the discriminator code:",https://stackoverflow.com/questions/42818842,7671750,Documentation Replicability,Documentation Replicability,"I am trying to translate this pix2pix GAN code to Tensorflow 1.0.0 using the following script as described in Tensorflow Documentation, but I keep getting the following error."
43315068,Tensorflow: has no attribute 'numpy_input_fn',"<p>I am using Eclipse's PyDev for tensorflow version:0.12.1<br>
I directly copy the sample code from tensorflow documentation,<br>
but a attribute is not found and it returned  </p>

<pre><code>input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x}, y, batch_size=4,
AttributeError: module 'tensorflow.contrib.learn.python.learn.learn_io' has no attribute 'numpy_input_fn'  
</code></pre>

<p>Tried to re-download pydev and tensorflow but none of them work  </p>

<p>The source code:  </p>

<pre><code>import tensorflow as tf
import numpy as np

features = [tf.contrib.layers.real_valued_column(""x"", dimension=1)]

estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)

x = np.array([1., 2., 3., 4.])
y = np.array([0., -1., -2., -3.])
input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x}, y, batch_size=4,num_epochs=1000)

estimator.fit(input_fn=input_fn, steps=1000)

estimator.evaluate(input_fn=input_fn)
</code></pre>
","I am using Eclipse's PyDev for tensorflow version:0.12.1 I directly copy the sample code from tensorflow documentation, but a attribute is not found and it returned Tried to re-download pydev and tensorflow but none of them work The source code:",https://stackoverflow.com/questions/43315068,3026820,Documentation Replicability,Documentation Replicability,"I am using Eclipse's PyDev for tensorflow version:0.12.1 I directly copy the sample code from tensorflow documentation, but a attribute is not found and it returned Tried to re-download pydev and tensorflow but none of them work."
44472358,Handling large image dataset in tensorflow,"<p>I have a dataset of over 1.5 million images and I have to classify them into 62 classes. I have created two numpy array features (path of png images)  and labels (int label). Now I want to load these images using opencv, but handing such large loaded input in RAM is inefficient. </p>

<p>So I also tried following using tensorflow input pipeline documentation:</p>

<pre><code>import tensorflow as tf

filename_queue = 
tf.train.string_input_producer(['batch1.csv','batch2.csv'])
reader = tf.TextLineReader(skip_header_lines=1)
key,value = reader.read(filename_queue)

record_defaults = [['1'],['1']]
paths, labels = tf.decode_csv(value, record_defaults=record_defaults)

features_path = tf.stack([paths])
labels = tf.stack([labels])

with tf.Session() as sess:
    coord = tf.train.Coordinator()
    #Start all QueueRunners added into the graph
    threads = tf.train.start_queue_runners(coord=coord)

    for _ in range(1):
        # d_features, d_labels = sess.run([features_path, labels])
        # print len(d_features), len(d_labels)

        min_after_dequeue = 5
        batch_size = 32
        capacity = 30
        #capacity = min_after_dequeue + 3 * batch_size

        example_batch, label_batch = tf.train.shuffle_batch(
            [features_path, labels], batch_size=batch_size, 
            capacity=capacity,
            min_after_dequeue=min_after_dequeue
        )
        print sess.run([example_batch])
</code></pre>

<p>But this is getting stuck when I run it ( I tried printing the shape of tensor, which is coming as expected, but its not printing the batch of my features). </p>

<p>It will be really helpful if someone can guide me a better way to create batches and load images which can be later fed into the tensorflow model.</p>
","I have a dataset of over 1.5 million images and I have to classify them into 62 classes. I have created two numpy array features (path of png images) and labels (int label). Now I want to load these images using opencv, but handing such large loaded input in RAM is inefficient. So I also tried following using tensorflow input pipeline documentation: But this is getting stuck when I run it ( I tried printing the shape of tensor, which is coming as expected, but its not printing the batch of my features). It will be really helpful if someone can guide me a better way to create batches and load images which can be later fed into the tensorflow model.",https://stackoverflow.com/questions/44472358,3316461,Documentation Replicability,Documentation Replicability,"So I also tried following using tensorflow input pipeline documentation: But this is getting stuck when I run it ( I tried printing the shape of tensor, which is coming as expected, but its not printing the batch of my features)."
45308755,No scalar data in tensorboard,"<p>I have been reading tensorboard documentation about scalars and I have a problem with presenting it in tensorboard.</p>

<p>I have pip install tensorflow in windows 10</p>

<p>my code looks like this:</p>

<pre><code>import tensorflow as tf

a = tf.constant(7, name='test_variable')
tf.summary.scalar('variable', a)

with tf.Session() as sess:
    tf.summary.FileWriter('my_folder', graph=sess.graph)
    X = tf.global_variables_initializer()
    sess.run(X)
</code></pre>

<p>I see there is a file in <code>my_folder</code></p>

<p>in command prompt: <code>tensorboard --logdir=my_folder --port 6006</code></p>

<p>out:</p>

<pre><code>C:\Users\MM&gt;tensorboard --logdir=my_folder --port 6006
Starting TensorBoard b'54' at http://DESKTOP-9S2D9VF:6006
(Press CTRL+C to quit)
</code></pre>

<p>When I open browser i get:</p>

<pre><code>No scalar data was found. 
Probable causes: etc. etc.
</code></pre>
",I have been reading tensorboard documentation about scalars and I have a problem with presenting it in tensorboard. I have pip install tensorflow in windows 10 my code looks like this: I see there is a file in my_folder in command prompt: tensorboard --logdir=my_folder --port 6006 out: When I open browser i get:,https://stackoverflow.com/questions/45308755,8053410,Documentation Replicability,Documentation Replicability,I have been reading tensorboard documentation about scalars and I have a problem with presenting it in tensorboard.
45316382,tensorflow: initialization of variables inside function,"<p>Newbee to tensorflow. I'm trying to write some simple net with following code:</p>

<pre><code>import tensorflow as tf 
import tensorflow.contrib as tfc
import tensorflow.contrib.layers as tfcl

def generator_deconv(z, kernel):
    with tf.variable_scope(""generator"", reuse=True):
        weights = tf.get_variable(""weights"")
        biases = tf.get_variable(""biases"")
        result = tf.matmul(z, weights)
        result = tf.add(result, biases)
        result = tf.reshape(result, tf.stack([tf.shape(result)[0],13,4,1]))
        result = tf.nn.conv2d_transpose(result, kernel, 
                output_shape=[tf.shape(result)[0],25,8,1], 
                strides=[1,2,2,1], 
                padding=""SAME"")
        result = tf.nn.conv2d_transpose(result, kernel, 
                output_shape=[tf.shape(result)[0],50,15,1], 
                strides=[1,2,2,1], 
                padding=""SAME"")
        result = tf.nn.conv2d_transpose(result, kernel, 
                output_shape=[tf.shape(result)[0],100,30,1], 
                strides=[1,2,2,1], 
                padding=""SAME"")    
        return result

kernel = tf.constant(1.0, shape=[4,4,1,1])
protype = tf.constant(1.0, shape=[3,4])
init = tf.global_variables_initializer()

config = tf.ConfigProto()
config.gpu_options.allocator_type = 'BFC'
config.gpu_options.allow_growth=True

with tf.variable_scope(""generator""):
    t1 = tf.get_variable(""weights"",shape=[4,52])
    t2 = tf.get_variable(""biases"", shape=[52])

test = generator_deconv(protype,kernel)

with tf.Session(config=config) as sess:
    sess.run(init)
    sess.run(tf.shape(t1))
    sess.run(tf.shape(t2))
    sess.run(tf.shape(test))
</code></pre>

<p>but got error: </p>

<blockquote>
  <p>tensorflow.python.framework.errors_impl.FailedPreconditionError:
  Attempting to use uninitialized value generator/weights</p>
</blockquote>

<p>for the <strong>last line</strong></p>

<pre><code>sess.run(tf.shape(test))
</code></pre>

<p>checked official api of tensorflow but still don't know what's wrong with the code.</p>

<p>================================UPDATE==========================</p>

<p>found 2 ways to fix it</p>

<p>1.if replace</p>

<pre><code>sess.run(init)
</code></pre>

<p>by</p>

<pre><code>sess.run(tf.global_variables_initializer())
</code></pre>

<p>then whole code works.</p>

<p>OR</p>

<p>2.run</p>

<pre><code>init = tf.global_variables_initializer()
with tf.Session(config=config) as sess:
    sess.run(init)
    sess.run(tf.shape(t1))
    sess.run(tf.shape(t2))
    sess.run(tf.shape(test))
</code></pre>

<p>again it also works.</p>

<p>BUT don't understand why</p>
",Newbee to tensorflow. I'm trying to write some simple net with following code: but got error: for the last line checked official api of tensorflow but still don't know what's wrong with the code. ================================UPDATE========================== found 2 ways to fix it 1.if replace by then whole code works. OR 2.run again it also works. BUT don't understand why,https://stackoverflow.com/questions/45316382,5155829,Requesting (Additional) Resources,Documentation Replicability,I'm trying to write some simple net with following code: but got error: for the last line checked official api of tensorflow but still don't know what's wrong with the code.
46080421,"Tensorflow, printing loss function causes error without feed_dictionary","<p>I am just reading Tensorflow documentation. In following code, I just changed last line. I pushed last line in iteration, to see what exactly is going on...</p>

<pre><code>import tensorflow as tf

# linear_model = W*x+B

W = tf.Variable(.3, dtype=tf.float32)
B = tf.Variable(-3., dtype=tf.float32)
x = tf.placeholder(dtype=tf.float32) #data_X
linear_model = W*x+B

y = tf.placeholder(dtype=tf.float32) #data_Y

loss = tf.reduce_sum(tf.square(linear_model-y))

optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)

X_train = [1.0,2.0,3.0,4.0] #data_X
y_train = [0.0,-1.0,-2.0,-3.0] #data_y

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(1000):
        sess.run(train,{x:X_train, y:y_train})
        print(sess.run([W,B,loss], {x:X_train, y:y_train}))
</code></pre>

<p>Please check the very last line: <code>print(sess.run([W,B,loss], {x:X_train, y:y_train}))</code></p>

<p>Why do I need to include </p>

<pre><code>{x:X_train, y:y_train}
</code></pre>

<p>in order to print statement out? If you exclude this from the last line, you will get error. It makes no sense, because loss is already calculated in line before. Thanks</p>
","I am just reading Tensorflow documentation. In following code, I just changed last line. I pushed last line in iteration, to see what exactly is going on... Please check the very last line: print(sess.run([W,B,loss], {x:X_train, y:y_train})) Why do I need to include in order to print statement out? If you exclude this from the last line, you will get error. It makes no sense, because loss is already calculated in line before. Thanks",https://stackoverflow.com/questions/46080421,6709460,Documentation Ambiguity,Documentation Replicability,"I am just reading Tensorflow documentation. In following code, I just changed last line."
48767184,Tensorflow running session multiple times in a loop,"<p>I'm trying out a simple Tensorflow code to compute the product of two matrices multiple times. My code is as follows:</p>

<pre><code>import numpy as np
import tensorflow as tf

times = 10
alpha = 2
beta = 3

graph = tf.Graph()

with graph.as_default():
    A = tf.placeholder(tf.float32)
    B = tf.placeholder(tf.float32)
    C = tf.placeholder(tf.float32)
    alpha = tf.constant(2.0, shape=[1, 1])
    beta = tf.constant(3.0, shape=[1, 1])
    D = alpha*tf.matmul(A, B) + beta*C          

with tf.Session(graph=graph) as session:
    tf.initialize_all_variables().run()
    for time in xrange(1, 2):
        N = 10**time
        a = tf.constant(np.random.random((N, N)))
        b = tf.constant(np.random.random((N, N)))
        c = tf.constant(np.random.random((N, N)))

        for num in xrange(1, 3):
            print num
            session.run(D, feed_dict={A:a.eval(), B:b.eval(), C:c.eval()})      
            c = D
</code></pre>

<p>Upon running session.run() in the for loop:</p>

<pre><code>for num in xrange(1, 3):
    print num
    session.run(D, feed_dict={A:a.eval(), B:b.eval(), C:c.eval()})      
    c = D
</code></pre>

<p>I get the following error:</p>

<p><a href=""https://i.stack.imgur.com/Rh7N5.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Rh7N5.jpg"" alt=""Error on running session.run() in a loop""></a></p>

<p>I looked at the sample code for MNIST on the Tensorflow website but they run 'session.run()' in a similar manner in a for loop. I'm looking for any insight on why 'session.run()' in my code does not work inside a for loop.</p>

<p>Thank you.</p>
",I'm trying out a simple Tensorflow code to compute the product of two matrices multiple times. My code is as follows: Upon running session.run() in the for loop: I get the following error: I looked at the sample code for MNIST on the Tensorflow website but they run 'session.run()' in a similar manner in a for loop. I'm looking for any insight on why 'session.run()' in my code does not work inside a for loop. Thank you.,https://stackoverflow.com/questions/48767184,5279281,Requesting (Additional) Resources,Documentation Replicability,I looked at the sample code for MNIST on the Tensorflow website but they run 'session.run()' in a similar manner in a for loop.
49017930,Errors implementing Sampled Softmax Tensorflow,"<p>I have been trying for a while to implement sampled softmax because I have half a million output classes.</p>

<p>I have tried to follow the official documentation exactly, but I always get an error. This is my code:</p>

<pre><code>def forward_propagation_sampled(X, parameters):

W1 = parameters['W1']
b1 = parameters['b1']
W2 = parameters['W2']
b2 = parameters['b2']
W3 = parameters['W3']
b3 = parameters['b3']


Z1 = tf.add(tf.matmul(W1, X), b1)
A1 = tf.nn.relu(Z1)
Z2 = tf.add(tf.matmul(W2,A1), b2)
A2 = tf.nn.relu(Z2)
Z3 = tf.add(tf.matmul(W3,A2), b3)


return Z3, W3, b3
</code></pre>

<p>This is the cost computation function:</p>

<pre><code>def compute_cost(Z3, W3, b3, Y, mode):
Z3.set_shape([1144,1])
if mode == ""train"":
    loss = tf.nn.sampled_softmax_loss(
    weights=tf.transpose(W3),
    biases=tf.Variable(b3),
    labels = tf.reshape(tf.argmax(Y, 1), [-1,1]), #Since Y is one hot encoded
    inputs=tf.Variable(initial_value=Z3,dtype=tf.float32, expected_shape=[1144,1]),
    num_sampled = 2000,
    num_classes = 1144,
    partition_strategy=""div""
    )

elif mode == ""eval"":
    logits = tf.matmul(inputs, tf.transpose(weights))
    logits = tf.nn.bias_add(logits, biases)
    labels_one_hot = tf.one_hot(labels, n_classes)
    loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels_one_hot,logits=logits)
cost = tf.reduce_mean(loss)
return cost
</code></pre>

<p>For the purpose of just testing this out, I am using 1144 output classes, which would otherwise scale to 500,000. There are 3144 training examples.</p>

<p>I get this error:</p>

<pre><code>Shape must be rank 1 but is rank 2 for 'sampled_softmax_loss/Slice_1' (op: 'Slice') with input shapes: [3144,1], [1], [1].
</code></pre>

<p>I am unable to debug this or make any sense out of it. Any help would be really appreciated.</p>
","I have been trying for a while to implement sampled softmax because I have half a million output classes. I have tried to follow the official documentation exactly, but I always get an error. This is my code: This is the cost computation function: For the purpose of just testing this out, I am using 1144 output classes, which would otherwise scale to 500,000. There are 3144 training examples. I get this error: I am unable to debug this or make any sense out of it. Any help would be really appreciated.",https://stackoverflow.com/questions/49017930,5054785,Documentation Replicability,Documentation Replicability," I have tried to follow the official documentation exactly, but I always get an error."
51777643,Tensorflow: Identifying the final state in MultiRNN,"<p>I am new to TF and I am trying to implement multiple GRU cells into the NN. However, I am unable to identify the final state of the MultiRNN cell.</p>

<p>For instance, when I use the following code:</p>

<pre><code>num_units = [128, 128]
tf.reset_default_graph()
x = tf.placeholder(tf.int32, [None, 134])
y = tf.placeholder(tf.int32, [None]) 
embedding_matrix = tf.Variable(tf.random_uniform([153, 128], -1.0, 1.0))
embeddings = tf.nn.embedding_lookup(embedding_matrix, x) 
cells = [tf.contrib.rnn.GRUCell(num_units=n) for n in num_units]
cell_type = tf.contrib.rnn.MultiRNNCell(cells=cells, state_is_tuple=True)
cell_type = tf.contrib.rnn.DropoutWrapper(cell=cell_type, output_keep_prob=0.75)
_, (encoding, _) = tf.nn.dynamic_rnn(cell_type, embeddings, dtype=tf.float32)
</code></pre>

<p>The output of the final line of code is:</p>

<pre><code>(&lt;tf.Tensor 'rnn/transpose_1:0' shape=(?, 134, 128) dtype=float32&gt;, (&lt;tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 128) dtype=float32&gt;, &lt;tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 128) dtype=float32&gt;))
</code></pre>

<p>I believe that the format is:</p>

<blockquote>
  <p><strong>Output Format</strong>: (a,[b, c])</p>
</blockquote>

<p>The documentation says that the output is in the format (output, state=[batch_size, cell.state_size]). However, I am unable to identify which of these is the final state of this memory cell. I think that it should be b.</p>

<p>Also, when I run the same code above with 4 GRU cells:</p>

<pre><code>num_units = [128, 128, 128, 128]
</code></pre>

<p>The output is even more confusing:</p>

<blockquote>
  <p><strong>Output Format</strong>: (a,[b, c, d, e])</p>
</blockquote>

<p>I am confused about which one of the above is the final memory state which I could then process further for loss calculation and making predictions.</p>
","I am new to TF and I am trying to implement multiple GRU cells into the NN. However, I am unable to identify the final state of the MultiRNN cell. For instance, when I use the following code: The output of the final line of code is: I believe that the format is: The documentation says that the output is in the format (output, state=[batch_size, cell.state_size]). However, I am unable to identify which of these is the final state of this memory cell. I think that it should be b. Also, when I run the same code above with 4 GRU cells: The output is even more confusing: I am confused about which one of the above is the final memory state which I could then process further for loss calculation and making predictions.",https://stackoverflow.com/questions/51777643,6657232,Documentation Replicability,Documentation Replicability,"The documentation says that the output is in the format (output, state=[batch_size, cell.state_size]). However, I am unable to identify which of these is the final state of this memory cell."
52785827,Run 1-D Conv using tensorflow,"<p>I'm a beginner in TensorFlow. I want to train a 1-D conv model. 
I have one-rowed csv files for each row of my original data.</p>

<p>csv files look like this</p>

<pre><code>csv_file1: 1.1, 1.3, 1.5, 1.5, 1
csv_file2: 2.1, 2.3, 2.7, 2.9, 0
</code></pre>

<p>The last column(containing 1 &amp; 0) are the labels for the single-row csv files</p>

<p>Following the <a href=""https://stackoverflow.com/questions/45427637/numpy-to-tfrecords-is-there-a-more-simple-way-to-handle-batch-inputs-from-tfrec/45428167#45428167"">link</a> I wrote the following pieces of code. </p>

<p>I converted the csv files to TFRecord using the following code</p>

<pre><code>    with tf.python_io.TFRecordWriter(filename) as writer:
        features, label = df_values[:, 1:-1], df_values[:, -1:]
        example = tf.train.Example()
        example.features.feature[""features""].float_list.value.extend(features[0])
        example.features.feature[""label""].int64_list.value.append(label[0])
        writer.write(example.SerializeToString())
</code></pre>

<p>I want to now read the files and this is the code I'm using. </p>

<pre><code>def _parse_function(data_record):
    features = {
        'label': tf.FixedLenSequenceFeature([], tf.int64, allow_missing = True),
        'features': tf.FixedLenSequenceFeature([], tf.float32, allow_missing = True),
    }
    sample = tf.parse_single_example(data_record, features)
    return sample['features'], sample['label']

filenames = glob.glob(""*.tfrecords"")
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(_parse_function)  
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(batch_len)
# Create a one-shot iterator
iterator = dataset.make_one_shot_iterator()

X,y = iterator.get_next()
</code></pre>

<p>From here the problem starts,
From the documentation I understand what session does but failing to put it into code.
Assuming I'll later figure out how to use</p>

<blockquote>
  <p>tf.seesion.run()</p>
</blockquote>

<p>I wrote the below code but don't know how to actually include it into my main script and further use it to train my model.</p>

<pre><code>x_train_batch, y_train_batch = tf.train.shuffle_batch(
tensors=[X_train, y_train],
batch_size=batch_size,
capacity=capacity,
min_after_dequeue=min_after_dequeue,
enqueue_many=True,
num_threads=8)

x_train_batch = tf.cast(x_train_batch, tf.float32)
x_train_batch = tf.reshape(x_train_batch, shape=(batch_size, 1,65281))

y_train_batch = tf.cast(y_train_batch, tf.int64)
y_train_batch = tf.one_hot(y_train_batch, num_classes)
</code></pre>

<p>Any help regarding how to proceed further will help. </p>

<p>PS: Assuming my data was loaded into an np.array
the dimension would be, (6571, 65281).
Since it's astronomical data, each star has 65781 points.</p>
","I'm a beginner in TensorFlow. I want to train a 1-D conv model. I have one-rowed csv files for each row of my original data. csv files look like this The last column(containing 1 &amp; 0) are the labels for the single-row csv files Following the link I wrote the following pieces of code. I converted the csv files to TFRecord using the following code I want to now read the files and this is the code I'm using. From here the problem starts, From the documentation I understand what session does but failing to put it into code. Assuming I'll later figure out how to use I wrote the below code but don't know how to actually include it into my main script and further use it to train my model. Any help regarding how to proceed further will help. PS: Assuming my data was loaded into an np.array the dimension would be, (6571, 65281). Since it's astronomical data, each star has 65781 points.",https://stackoverflow.com/questions/52785827,8115171,Documentation Ambiguity,Documentation Replicability,From the documentation I understand what session does but failing to put it into code.
53963654,Error running Tensorflow Object Detection with custom dataset,"<p>I've been trying to use tensorflow's object detection api for a school project and I've managed to follow their instructions in the documentation, but I'm getting this error I can't find anywhere online.
This is the output in the console:</p>

<pre><code>WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
WARNING:tensorflow:Estimator's model_fn (&lt;function create_model_fn.&lt;locals&gt;.model_fn at 0x7f118aa30e18&gt;) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/pipas/School/tensorflow-models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From /home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /home/pipas/School/tensorflow-models/research/object_detection/core/preprocessor.py:1218: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From /home/pipas/School/tensorflow-models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
2018-12-28 19:39:31.314235: E tensorflow/core/util/events_writer.cc:108] Write failed because file could not be opened.
2018-12-28 19:39:32.354316: E tensorflow/core/util/events_writer.cc:108] Write failed because file could not be opened.
2018-12-28 19:39:33.177681: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-28 19:39:33.246316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-28 19:39:33.246780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.176
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.59GiB
2018-12-28 19:39:33.246813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-28 19:39:33.798306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-28 19:39:33.798331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-28 19:39:33.798337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-28 19:39:33.798491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3310 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 109, in &lt;module&gt;
    tf.app.run()
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 471, in train_and_evaluate
    return executor.run()
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 610, in run
    return self.run_local()
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 711, in run_local
    saving_listeners=saving_listeners)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 354, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1207, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1241, in _train_model_default
    saving_listeners)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1468, in _train_with_estimator_spec
    log_step_count_steps=log_step_count_steps) as mon_sess:
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 504, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 921, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 643, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1107, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1112, in _create_session
    return self._sess_creator.create_session()
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 807, in create_session
    hook.after_create_session(self.tf_sess, self.coord)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 559, in after_create_session
    ""graph.pbtxt"")
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/framework/graph_io.py"", line 71, in write_graph
    text_format.MessageToString(graph_def))
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 434, in atomic_write_string_to_file
    write_string_to_file(temp_pathname, contents)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 314, in write_string_to_file
    f.write(file_content)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 108, in write
    self._prewrite_check()
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 94, in _prewrite_check
    compat.as_bytes(self.__name), compat.as_bytes(self.__mode), status)
  File ""/home/pipas/.pyenv/versions/vcom/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.FailedPreconditionError: /home/pipas/School/tensorflow-models/research/porto-recognition/data/labels.pbtxt/graph.pbtxt.tmp13ac703bc82a469eaec2c658091efd80; Not a directory
</code></pre>

<p>This is what I'm running</p>

<pre><code>PIPELINE_CONFIG_PATH=/home/pipas/School/tensorflow-models/research/porto-recognition/models/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config
MODEL_DIR=/home/pipas/School/tensorflow-models/research/porto-recognition/data/labels.pbtxt
NUM_TRAIN_STEPS=5000
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
python object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
    --alsolog
</code></pre>

<p>and here is the pipeline.config file</p>

<pre><code>model {
  ssd {
    num_classes: 5
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    feature_extractor {
      type: ""ssd_mobilenet_v1""
      depth_multiplier: 1.0
      min_depth: 16
      conv_hyperparams {
        regularizer {
          l2_regularizer {
            weight: 3.99999989895e-05
          }
        }
        initializer {
          truncated_normal_initializer {
            mean: 0.0
            stddev: 0.0299999993294
          }
        }
        activation: RELU_6
        batch_norm {
          decay: 0.999700009823
          center: true
          scale: true
          epsilon: 0.0010000000475
          train: true
        }
      }
    }
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    box_predictor {
      convolutional_box_predictor {
        conv_hyperparams {
          regularizer {
            l2_regularizer {
              weight: 3.99999989895e-05
            }
          }
          initializer {
            truncated_normal_initializer {
              mean: 0.0
              stddev: 0.0299999993294
            }
          }
          activation: RELU_6
          batch_norm {
            decay: 0.999700009823
            center: true
            scale: true
            epsilon: 0.0010000000475
            train: true
          }
        }
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.800000011921
        kernel_size: 1
        box_code_size: 4
        apply_sigmoid_to_scores: false
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.20000000298
        max_scale: 0.949999988079
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.333299994469
      }
    }
    post_processing {
      batch_non_max_suppression {
        score_threshold: 0.300000011921
        iou_threshold: 0.600000023842
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
    normalize_loss_by_num_matches: true
    loss {
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_loss {
        weighted_sigmoid {
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.990000009537
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 0
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
  }
}
train_config {
  batch_size: 24
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
  optimizer {
    rms_prop_optimizer {
      learning_rate {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.00400000018999
          decay_steps: 800720
          decay_factor: 0.949999988079
        }
      }
      momentum_optimizer_value: 0.899999976158
      decay: 0.899999976158
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""/home/pipas/School/tensorflow-models/research/porto-recognition/models/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  num_steps: 200000
}
train_input_reader {
  label_map_path: ""/home/pipas/School/tensorflow-models/research/porto-recognition/data/labels.pbtxt""
  tf_record_input_reader {
    input_path: ""/home/pipas/School/tensorflow-models/research/porto-recognition/data/porto_train.record""
  }
}
eval_config {
  num_examples: 8000
  max_evals: 10
  use_moving_averages: false
}
eval_input_reader {
  label_map_path: ""/home/pipas/School/tensorflow-models/research/porto-recognition/data/labels.pbtxt""
  shuffle: false
  num_readers: 1
  tf_record_input_reader {
    input_path: ""/home/pipas/School/tensorflow-models/research/porto-recognition/data/porto_val.record""
  }
}
</code></pre>
","I've been trying to use tensorflow's object detection api for a school project and I've managed to follow their instructions in the documentation, but I'm getting this error I can't find anywhere online. This is the output in the console: This is what I'm running and here is the pipeline.config file",https://stackoverflow.com/questions/53963654,,Documentation Replicability,Documentation Replicability,"I've been trying to use tensorflow's object detection api for a school project and I've managed to follow their instructions in the documentation, but I'm getting this error I can't find anywhere online."
54657542,How to get subset of 10K MNIST images from Dataset class in tensorflow?,"<p>I found the following way to get mnist dataset in tensorflow:</p>

<pre><code>def get_input_fn(dataset_split, batch_size, capacity=10000, min_after_dequeue=3000):

  def _input_fn():
    images_batch, labels_batch = tf.train.shuffle_batch(
        tensors=[dataset_split.images, dataset_split.labels.astype(np.int32)],
        batch_size=batch_size,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue,
        enqueue_many=True,
        num_threads=4)
    features_map = {'images': images_batch}
    return features_map, labels_batch

  return _input_fn

    data = tf.contrib.learn.datasets.mnist.load_mnist()

    train_input_fn = get_input_fn(data.train, batch_size=256)
    eval_input_fn = get_input_fn(data.validation, batch_size=5000)
</code></pre>

<p>data variable is Dataset object. 
This approach is quite unclear to me and I cannot figure out how to convert 60K dataset into 10K dataset.</p>

<p>When I do the following:</p>

<pre><code>data = tf.contrib.learn.datasets.mnist.load_mnist().take(10000)
</code></pre>

<p>I get error:</p>

<pre><code>AttributeError: 'Datasets' object has no attribute 'take'
</code></pre>

<p>But docs provide this method:
<a href=""https://i.stack.imgur.com/o6v4Q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/o6v4Q.png"" alt=""enter image description here""></a></p>

<p>Thank you for help!</p>
",I found the following way to get mnist dataset in tensorflow: data variable is Dataset object. This approach is quite unclear to me and I cannot figure out how to convert 60K dataset into 10K dataset. When I do the following: I get error: But docs provide this method: Thank you for help!,https://stackoverflow.com/questions/54657542,3849781,Documentation Replicability,Documentation Replicability,When I do the following: I get error: But docs provide this method
58571072,How to load local images in tensorflow?,"<p>I found from the tensorflow documentation that the code to load a dataset named ""flower_photos "" is</p>

<blockquote>
  <p>data_dir = tf.keras.utils.get_file(origin='<a href=""https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"" rel=""nofollow noreferrer"">https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz</a>',
                                           fname='flower_photos', untar=True)</p>
</blockquote>

<p>I'm having some images in my local machine and want to load and use it for doing some neural network algorithms like CNN. How to load and preprocess a locally stored image in tensorflow?</p>
","I found from the tensorflow documentation that the code to load a dataset named ""flower_photos "" is I'm having some images in my local machine and want to load and use it for doing some neural network algorithms like CNN. How to load and preprocess a locally stored image in tensorflow?",https://stackoverflow.com/questions/58571072,6733836,Requesting (Additional) Resources,Documentation Replicability,"I found from the tensorflow documentation that the code to load a dataset named ""flower_photos "" is I'm having some images in my local machine and want to load and use it for doing some neural network algorithms like CNN."
58711366,Simple keras dense model freezes while fitting,"<p>I am learning NLP with Keras and I am going through a tutorial.  The code is the following:</p>

<pre><code>import tensorflow_datasets as tfds
imdb, info = tfds.load(""imdb_reviews"", with_info=True, as_supervised=True)


import numpy as np

train_data, test_data = imdb['train'], imdb['test']

training_sentences = []
training_labels = []

testing_sentences = []
testing_labels = []

# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()
for s,l in train_data:
  training_sentences.append(str(s.numpy()))
  training_labels.append(l.numpy())


training_labels_final = np.array(training_labels)
testing_labels_final = np.array(testing_labels)

vocab_size = 10000
embedding_dim = 16
max_length = 120
trunc_type='post'
oov_tok = ""&lt;OOV&gt;""


from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# CREATE AN INSTANCE OF THE Tokenizer.  WE DECIDE HOW MANY WORDS THE TOKENIZER WILL READ.

tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)


# FIT THE TOKENIZER ON THE TEXTS. NOW THE TOKENIZER HAS SEEN THE WORDS IN THE TEXT.

tokenizer.fit_on_texts(training_sentences) # the training_sentences is a list of words.  Each word is considered a token.


# CREATE A DICTIONARY THAT INCLUDES ALL THE WORDS IN THE TEXT (UP TO THE MAXIMUM NUMBER DEFINED WHEN CREATING THE INSTANCE
# OF THE TOKENIZER)

word_index = tokenizer.word_index # the tokenizer creates a word_index with the words encountered in the text.  Each word
                                  # is assigned an integer which is the key while the word is the value.

# CONVERT THE SEQUENCES OF WORDS TO SEQUENCES OF INTEGERS

sequences = tokenizer.texts_to_sequences(training_sentences)  # the texts_to_sequences method converts the sequences of
                                            # words to sequences of integers using the key of each word in the dictionary

# PAD THE SEQUENCES OR TRUNCATE THEM ACCORDINGLY SO THAT ALL HAVE THE GIVEN max_length. NOW ALL SEQUENCES HAVE THE SAME LENGTH.

padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)

# THE SAME FOR THE SEQUENCES WHICH WILL BE USED FOR TESTING

testing_sequences = tokenizer.texts_to_sequences(testing_sentences)
testing_padded = pad_sequences(testing_sequences,maxlen=max_length)

# REVERSE THE DICTIONARY, MAKING KEYS THE WORDS AND VALUES THE INTEGERS WHICH REPRESENT THE WORDS

reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])




# CREATE A FUNCTION THAT TURNS THE INTEGERS COMPRISING A SEQUENCE TO WORDS THUS DECODING THE SEQUENCE AND CONVERTING IT TO
# NATURAL LANGUAGE

def decode_review(text):
    return ' '.join([reverse_word_index.get(i, '?') for i in text])


model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),

    # The Embedding layer gets as first argumnet the vocab_size which has been set to 10,000 and which was the value
    # passed to the Tokenizer.  On the other hand the vocabulary that was created using the training text was less
    # than vocab_size, it was 86539

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(6, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary()


num_epochs = 10
model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))
</code></pre>

<p>Towards the end of the first epoch the model freezes and makes no further progress:</p>

<p><a href=""https://i.stack.imgur.com/2YM0N.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2YM0N.png"" alt=""enter image description here""></a></p>

<p>When I dropped the last 1,000 sentences and repeated the process I got the same situation but now at an earlier point:</p>

<p><a href=""https://i.stack.imgur.com/wUJbO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wUJbO.png"" alt=""enter image description here""></a></p>

<p>I restarted my PC (Windows 10) but this did not solve the problem.</p>

<p>I then uninstalled tensorflow and reinstalled.  Then I run the following code found in the official documentation of tensorflow 2.0:</p>

<p><a href=""https://i.stack.imgur.com/pE6mL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pE6mL.png"" alt=""enter image description here""></a></p>

<p>But when I rerun the NLP code again the model froze while fitting the data:</p>

<pre><code>num_epochs = 10
model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))
Train on 24000 samples
Epoch 1/10
23968/24000 [============================&gt;.] - ETA: 6:09 - loss: 0.6878 - accuracy: 0.53 - ETA: 1:22 - loss: 0.6904 - accuracy: 0.56 - ETA: 50s - loss: 0.6927 - accuracy: 0.5069 - ETA: 37s - loss: 0.6932 - accuracy: 0.495 - ETA: 31s - loss: 0.6925 - accuracy: 0.492 - ETA: 26s - loss: 0.6923 - accuracy: 0.492 - ETA: 24s - loss: 0.6925 - accuracy: 0.490 - ETA: 21s - loss: 0.6925 - accuracy: 0.493 - ETA: 20s - loss: 0.6929 - accuracy: 0.490 - ETA: 19s - loss: 0.6931 - accuracy: 0.487 - ETA: 18s - loss: 0.6929 - accuracy: 0.490 - ETA: 17s - loss: 0.6929 - accuracy: 0.492 - ETA: 16s - loss: 0.6930 - accuracy: 0.489 - ETA: 15s - loss: 0.6927 - accuracy: 0.494 - ETA: 15s - loss: 0.6925 - accuracy: 0.498 - ETA: 14s - loss: 0.6925 - accuracy: 0.501 - ETA: 14s - loss: 0.6924 - accuracy: 0.504 - ETA: 14s - loss: 0.6925 - accuracy: 0.502 - ETA: 13s - loss: 0.6926 - accuracy: 0.503 - ETA: 13s - loss: 0.6925 - accuracy: 0.503 - ETA: 13s - loss: 0.6924 - accuracy: 0.506 - ETA: 12s - loss: 0.6926 - accuracy: 0.506 - ETA: 12s - loss: 0.6924 - accuracy: 0.508 - ETA: 12s - loss: 0.6924 - accuracy: 0.508 - ETA: 12s - loss: 0.6922 - accuracy: 0.508 - ETA: 12s - loss: 0.6920 - accuracy: 0.509 - ETA: 11s - loss: 0.6921 - accuracy: 0.509 - ETA: 11s - loss: 0.6917 - accuracy: 0.514 - ETA: 11s - loss: 0.6917 - accuracy: 0.513 - ETA: 11s - loss: 0.6918 - accuracy: 0.512 - ETA: 11s - loss: 0.6915 - accuracy: 0.515 - ETA: 11s - loss: 0.6911 - accuracy: 0.517 - ETA: 10s - loss: 0.6911 - accuracy: 0.517 - ETA: 10s - loss: 0.6911 - accuracy: 0.516 - ETA: 10s - loss: 0.6910 - accuracy: 0.517 - ETA: 10s - loss: 0.6909 - accuracy: 0.517 - ETA: 10s - loss: 0.6907 - accuracy: 0.516 - ETA: 10s - loss: 0.6902 - accuracy: 0.518 - ETA: 10s - loss: 0.6900 - accuracy: 0.518 - ETA: 9s - loss: 0.6896 - accuracy: 0.518 - ETA: 9s - loss: 0.6898 - accuracy: 0.51 - ETA: 9s - loss: 0.6893 - accuracy: 0.51 - ETA: 9s - loss: 0.6891 - accuracy: 0.52 - ETA: 9s - loss: 0.6887 - accuracy: 0.52 - ETA: 9s - loss: 0.6883 - accuracy: 0.52 - ETA: 9s - loss: 0.6880 - accuracy: 0.52 - ETA: 9s - loss: 0.6878 - accuracy: 0.52 - ETA: 9s - loss: 0.6874 - accuracy: 0.52 - ETA: 8s - loss: 0.6868 - accuracy: 0.52 - ETA: 8s - loss: 0.6863 - accuracy: 0.52 - ETA: 8s - loss: 0.6857 - accuracy: 0.52 - ETA: 8s - loss: 0.6853 - accuracy: 0.52 - ETA: 8s - loss: 0.6851 - accuracy: 0.52 - ETA: 8s - loss: 0.6845 - accuracy: 0.52 - ETA: 8s - loss: 0.6838 - accuracy: 0.53 - ETA: 8s - loss: 0.6829 - accuracy: 0.53 - ETA: 8s - loss: 0.6819 - accuracy: 0.53 - ETA: 8s - loss: 0.6803 - accuracy: 0.53 - ETA: 8s - loss: 0.6799 - accuracy: 0.53 - ETA: 8s - loss: 0.6791 - accuracy: 0.54 - ETA: 7s - loss: 0.6785 - accuracy: 0.54 - ETA: 7s - loss: 0.6779 - accuracy: 0.54 - ETA: 7s - loss: 0.6773 - accuracy: 0.54 - ETA: 7s - loss: 0.6765 - accuracy: 0.55 - ETA: 7s - loss: 0.6751 - accuracy: 0.55 - ETA: 7s - loss: 0.6745 - accuracy: 0.55 - ETA: 7s - loss: 0.6732 - accuracy: 0.55 - ETA: 7s - loss: 0.6722 - accuracy: 0.56 - ETA: 7s - loss: 0.6714 - accuracy: 0.56 - ETA: 7s - loss: 0.6699 - accuracy: 0.56 - ETA: 7s - loss: 0.6691 - accuracy: 0.56 - ETA: 7s - loss: 0.6680 - accuracy: 0.57 - ETA: 7s - loss: 0.6667 - accuracy: 0.57 - ETA: 6s - loss: 0.6657 - accuracy: 0.57 - ETA: 6s - loss: 0.6642 - accuracy: 0.57 - ETA: 6s - loss: 0.6632 - accuracy: 0.57 - ETA: 6s - loss: 0.6624 - accuracy: 0.58 - ETA: 6s - loss: 0.6614 - accuracy: 0.58 - ETA: 6s - loss: 0.6598 - accuracy: 0.58 - ETA: 6s - loss: 0.6591 - accuracy: 0.58 - ETA: 6s - loss: 0.6580 - accuracy: 0.59 - ETA: 6s - loss: 0.6573 - accuracy: 0.59 - ETA: 6s - loss: 0.6563 - accuracy: 0.59 - ETA: 6s - loss: 0.6554 - accuracy: 0.59 - ETA: 6s - loss: 0.6548 - accuracy: 0.59 - ETA: 6s - loss: 0.6538 - accuracy: 0.60 - ETA: 6s - loss: 0.6524 - accuracy: 0.60 - ETA: 6s - loss: 0.6521 - accuracy: 0.60 - ETA: 5s - loss: 0.6506 - accuracy: 0.60 - ETA: 5s - loss: 0.6497 - accuracy: 0.60 - ETA: 5s - loss: 0.6485 - accuracy: 0.61 - ETA: 5s - loss: 0.6472 - accuracy: 0.61 - ETA: 5s - loss: 0.6461 - accuracy: 0.61 - ETA: 5s - loss: 0.6451 - accuracy: 0.61 - ETA: 5s - loss: 0.6438 - accuracy: 0.61 - ETA: 5s - loss: 0.6428 - accuracy: 0.61 - ETA: 5s - loss: 0.6426 - accuracy: 0.62 - ETA: 5s - loss: 0.6416 - accuracy: 0.62 - ETA: 5s - loss: 0.6403 - accuracy: 0.62 - ETA: 5s - loss: 0.6393 - accuracy: 0.62 - ETA: 5s - loss: 0.6380 - accuracy: 0.62 - ETA: 5s - loss: 0.6368 - accuracy: 0.62 - ETA: 5s - loss: 0.6354 - accuracy: 0.63 - ETA: 4s - loss: 0.6345 - accuracy: 0.63 - ETA: 4s - loss: 0.6335 - accuracy: 0.63 - ETA: 4s - loss: 0.6323 - accuracy: 0.63 - ETA: 4s - loss: 0.6313 - accuracy: 0.63 - ETA: 4s - loss: 0.6300 - accuracy: 0.63 - ETA: 4s - loss: 0.6291 - accuracy: 0.64 - ETA: 4s - loss: 0.6281 - accuracy: 0.64 - ETA: 4s - loss: 0.6270 - accuracy: 0.64 - ETA: 4s - loss: 0.6260 - accuracy: 0.64 - ETA: 4s - loss: 0.6246 - accuracy: 0.64 - ETA: 4s - loss: 0.6238 - accuracy: 0.64 - ETA: 4s - loss: 0.6228 - accuracy: 0.64 - ETA: 4s - loss: 0.6216 - accuracy: 0.65 - ETA: 4s - loss: 0.6204 - accuracy: 0.65 - ETA: 4s - loss: 0.6199 - accuracy: 0.65 - ETA: 4s - loss: 0.6189 - accuracy: 0.65 - ETA: 3s - loss: 0.6176 - accuracy: 0.65 - ETA: 3s - loss: 0.6165 - accuracy: 0.65 - ETA: 3s - loss: 0.6150 - accuracy: 0.66 - ETA: 3s - loss: 0.6144 - accuracy: 0.66 - ETA: 3s - loss: 0.6132 - accuracy: 0.66 - ETA: 3s - loss: 0.6118 - accuracy: 0.66 - ETA: 3s - loss: 0.6108 - accuracy: 0.66 - ETA: 3s - loss: 0.6096 - accuracy: 0.66 - ETA: 3s - loss: 0.6088 - accuracy: 0.66 - ETA: 3s - loss: 0.6077 - accuracy: 0.66 - ETA: 3s - loss: 0.6064 - accuracy: 0.67 - ETA: 3s - loss: 0.6054 - accuracy: 0.67 - ETA: 3s - loss: 0.6046 - accuracy: 0.67 - ETA: 3s - loss: 0.6037 - accuracy: 0.67 - ETA: 3s - loss: 0.6028 - accuracy: 0.67 - ETA: 3s - loss: 0.6021 - accuracy: 0.67 - ETA: 3s - loss: 0.6012 - accuracy: 0.67 - ETA: 2s - loss: 0.6006 - accuracy: 0.67 - ETA: 2s - loss: 0.5997 - accuracy: 0.67 - ETA: 2s - loss: 0.5988 - accuracy: 0.67 - ETA: 2s - loss: 0.5974 - accuracy: 0.68 - ETA: 2s - loss: 0.5965 - accuracy: 0.68 - ETA: 2s - loss: 0.5960 - accuracy: 0.68 - ETA: 2s - loss: 0.5952 - accuracy: 0.68 - ETA: 2s - loss: 0.5941 - accuracy: 0.68 - ETA: 2s - loss: 0.5925 - accuracy: 0.68 - ETA: 2s - loss: 0.5918 - accuracy: 0.68 - ETA: 2s - loss: 0.5907 - accuracy: 0.68 - ETA: 2s - loss: 0.5900 - accuracy: 0.68 - ETA: 2s - loss: 0.5893 - accuracy: 0.69 - ETA: 2s - loss: 0.5888 - accuracy: 0.69 - ETA: 2s - loss: 0.5880 - accuracy: 0.69 - ETA: 2s - loss: 0.5873 - accuracy: 0.69 - ETA: 2s - loss: 0.5867 - accuracy: 0.69 - ETA: 1s - loss: 0.5854 - accuracy: 0.69 - ETA: 1s - loss: 0.5848 - accuracy: 0.69 - ETA: 1s - loss: 0.5844 - accuracy: 0.69 - ETA: 1s - loss: 0.5837 - accuracy: 0.69 - ETA: 1s - loss: 0.5829 - accuracy: 0.69 - ETA: 1s - loss: 0.5822 - accuracy: 0.69 - ETA: 1s - loss: 0.5817 - accuracy: 0.69 - ETA: 1s - loss: 0.5810 - accuracy: 0.70 - ETA: 1s - loss: 0.5803 - accuracy: 0.70 - ETA: 1s - loss: 0.5798 - accuracy: 0.70 - ETA: 1s - loss: 0.5789 - accuracy: 0.70 - ETA: 1s - loss: 0.5786 - accuracy: 0.70 - ETA: 1s - loss: 0.5782 - accuracy: 0.70 - ETA: 1s - loss: 0.5772 - accuracy: 0.70 - ETA: 1s - loss: 0.5767 - accuracy: 0.70 - ETA: 1s - loss: 0.5761 - accuracy: 0.70 - ETA: 1s - loss: 0.5756 - accuracy: 0.70 - ETA: 0s - loss: 0.5751 - accuracy: 0.70 - ETA: 0s - loss: 0.5747 - accuracy: 0.70 - ETA: 0s - loss: 0.5739 - accuracy: 0.70 - ETA: 0s - loss: 0.5733 - accuracy: 0.70 - ETA: 0s - loss: 0.5727 - accuracy: 0.71 - ETA: 0s - loss: 0.5720 - accuracy: 0.71 - ETA: 0s - loss: 0.5712 - accuracy: 0.71 - ETA: 0s - loss: 0.5705 - accuracy: 0.71 - ETA: 0s - loss: 0.5698 - accuracy: 0.71 - ETA: 0s - loss: 0.5692 - accuracy: 0.71 - ETA: 0s - loss: 0.5685 - accuracy: 0.71 - ETA: 0s - loss: 0.5680 - accuracy: 0.71 - ETA: 0s - loss: 0.5676 - accuracy: 0.71 - ETA: 0s - loss: 0.5670 - accuracy: 0.71 - ETA: 0s - loss: 0.5663 - accuracy: 0.71 - ETA: 0s - loss: 0.5657 - accuracy: 0.71 - ETA: 0s - loss: 0.5650 - accuracy: 0.71 - ETA: 0s - loss: 0.5643 - accuracy: 0.7185
</code></pre>
","I am learning NLP with Keras and I am going through a tutorial. The code is the following: Towards the end of the first epoch the model freezes and makes no further progress: When I dropped the last 1,000 sentences and repeated the process I got the same situation but now at an earlier point: I restarted my PC (Windows 10) but this did not solve the problem. I then uninstalled tensorflow and reinstalled. Then I run the following code found in the official documentation of tensorflow 2.0: But when I rerun the NLP code again the model froze while fitting the data:",https://stackoverflow.com/questions/58711366,8270077,Requesting (Additional) Resources,Documentation Replicability,Then I run the following code found in the official documentation of tensorflow 2.0: But when I rerun the NLP code again the model froze while fitting the data
59406059,Tensorflow Keras GPU uses,"<p>I'm trying to make tensorflow and keras go on GPU in my code but I'm having problem that the uses are partially (the CPU is still used by both)</p>

<ul>
<li><strong>Force keras to GPU</strong>
to force keras to GPU I added this code before keras importation, I just force it to the first GPU, I didn't configure how to run on multiple GPU (when I tried 
<code>os.environ[""CUDA_VISIBLE_DEVICES""] = ""0,1,2,3""</code> an error occurred when running the project, I have 4 GPU) </li>
</ul>

<pre><code>import os
os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""  
os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""

</code></pre>

<ul>
<li><strong>Force tensorflow to GPU</strong></li>
</ul>

<p>for tensorflow I installed tensorflow-gpu then i run this code as mentioned in the tensorflow official page
<a href=""https://www.tensorflow.org/guide/gpu"" rel=""nofollow noreferrer"">tensorflow official </a></p>

<pre><code>gpus = tf.config.experimental.list_physical_devices('GPU')

        if gpus:
            # Restrict TensorFlow to only use the first GPU
            try:
                tf.config.experimental.set_visible_devices(gpus[0], 'GPU')
                logical_gpus = tf.config.experimental.list_logical_devices('GPU')
                logger.info(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPU"")
            except RuntimeError as e:
                # Visible devices must be set before GPUs have been initialized
                logger.error(""Error inn workig on GPU %s "" % e) 
</code></pre>

<p>the problem persist and the use of the GPU is not passing 15% and the cpu is at 40% of uses.</p>

<p><a href=""https://i.stack.imgur.com/sE2O1.png"" rel=""nofollow noreferrer"">tensorflow is runing  GPU  15%</a></p>

<p><a href=""https://i.stack.imgur.com/2W9o6.png"" rel=""nofollow noreferrer"">tensorflow is runing  CPU 40%</a></p>
",I'm trying to make tensorflow and keras go on GPU in my code but I'm having problem that the uses are partially (the CPU is still used by both) for tensorflow I installed tensorflow-gpu then i run this code as mentioned in the tensorflow official page tensorflow official the problem persist and the use of the GPU is not passing 15% and the cpu is at 40% of uses. tensorflow is runing GPU 15% tensorflow is runing CPU 40%,https://stackoverflow.com/questions/59406059,7479290,Documentation Replication on Other Examples,Documentation Replicability,For tensorflow I installed tensorflow-gpu then i run this code as mentioned in the tensorflow official page
59438904,Applying callbacks in a custom training loop in Tensorflow 2.0,"<p>I'm writing a custom training loop using the code provided in the Tensorflow DCGAN implementation guide. I wanted to add callbacks in the training loop. In Keras I know we pass them as an argument to the 'fit' method, but can't find resources on how to use these callbacks in the custom training loop. I'm adding the code for the custom training loop from the Tensorflow documentation:</p>

<pre><code># Notice the use of `tf.function`
# This annotation causes the function to be ""compiled"".
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      train_step(image_batch)

    # Produce images for the GIF as we go
    display.clear_output(wait=True)
    generate_and_save_images(generator,
                             epoch + 1,
                             seed)

    # Save the model every 15 epochs
    if (epoch + 1) % 15 == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # Generate after the final epoch
  display.clear_output(wait=True)
  generate_and_save_images(generator,
                           epochs,
                           seed)
</code></pre>
","I'm writing a custom training loop using the code provided in the Tensorflow DCGAN implementation guide. I wanted to add callbacks in the training loop. In Keras I know we pass them as an argument to the 'fit' method, but can't find resources on how to use these callbacks in the custom training loop. I'm adding the code for the custom training loop from the Tensorflow documentation:",https://stackoverflow.com/questions/59438904,7694977,Documentation Replication on Other Examples,Documentation Replicability,I'm adding the code for the custom training loop from the Tensorflow documentation
59751851,I get an error when I load a tensorflow2.0 model,"<p>I am learning a simple model to perform a linear regression and then I save the model </p>

<pre><code>class NN(tf.keras.Model):
  def __init__(self):
    super(NN, self).__init__()
    L = 20
    self.W1 = tf.Variable(tf.random.truncated_normal([1, L], stddev=math.sqrt(3)))
    self.B1 = tf.Variable(tf.random.truncated_normal([1, L], stddev=1.0))
    self.W2 = tf.Variable(tf.random.truncated_normal([L, 1], stddev=math.sqrt(3/L)))
    self.B2 = tf.Variable(tf.zeros([1]))
  def call(self, inputs):
    Z1 = tf.matmul(inputs, self.W1) + self.B1
    Y1 = tf.nn.tanh(Z1)
    Y = tf.matmul(Y1, self.W2) + self.B2
    return Y

# The loss function to be optimized
def loss(model, X, Y_):
  error = model(X) - Y_
  return tf.reduce_mean(tf.square(error))

model = NN()
optimizer = tf.optimizers.Adam(learning_rate=0.001)
bsize = 20

# You can call this function in a loop to train the model, bsize samples at a time
def training_step(i):
  # read data
  x_batch, y_batch = func.next_batch(bsize)
  x_batch = np.reshape(x_batch, (bsize,1))
  y_batch = np.reshape(y_batch, (bsize,1))
  # compute training values
  loss_fn = lambda: loss(model, x_batch, y_batch)
  optimizer.minimize(loss_fn, [model.W1, model.B1, model.W2, model.B2])
  if i%5000 == 0:
    l = loss(model, x_batch, y_batch)
    print(str(i) + "": epoch: "" + str(func._epochs_completed) + "": loss: "" + str(l.numpy()))

for i in range(50001): 
  training_step(i)

# save the model
tf.saved_model.save(model, ""my_file"")
</code></pre>

<p>and then I am trying to load the model with the following lines following tensorflow documentation:</p>

<pre><code>model = tf.saved_model.load(""my_file"")
f = model.signatures[""serving_default""]
y = f(x)
</code></pre>

<p>However I get the following error message:</p>

<pre><code> f = model.signatures[""serving_default""]
File ""my_file/signature_serialization.py"", line 195, in __getitem__
    return self._signatures[key]
KeyError: 'serving_default'
</code></pre>

<p>What is wrong ? Why serving_default is not defined ?</p>
",I am learning a simple model to perform a linear regression and then I save the model and then I am trying to load the model with the following lines following tensorflow documentation: However I get the following error message: What is wrong ? Why serving_default is not defined ?,https://stackoverflow.com/questions/59751851,9427880,Documentation Replicability,Documentation Replicability,I am learning a simple model to perform a linear regression and then I save the model and then I am trying to load the model with the following lines following tensorflow documentation: However I get the following error message
63068695,Getting error when trying to load data using keras.utils.get_file(),"<p>I am getting an error when trying to load a dataset using TensorFlow Keras. Here is the code:</p>
<pre><code>dataset_url = &quot;https://storage.googleapis.com/sample_org/sample_file.zip&quot;
data_dir = tf.keras.utils.get_file(origin=dataset_url, 
                                   fname='sample_file', 
                                   extract=True)
data_dir = pathlib.Path(data_dir)
</code></pre>
<p><strong>I have changed the URL to 'sample_file.zip' for security reasons.</strong></p>
<p>This is the error that I am getting:</p>
<pre><code>---------------------------------------------------------------------------
FileExistsError                           Traceback (most recent call last)
&lt;ipython-input-12-1cdc186b0389&gt; in &lt;module&gt;()
      2 data_dir = tf.keras.utils.get_file(origin=dataset_url, 
      3                                    fname='sample_file',
----&gt; 4                                    extract=True)
      5 data_dir = pathlib.Path(data_dir)

3 frames
/usr/lib/python3.6/zipfile.py in _extract_member(self, member, targetpath, pwd)
   1572         if member.is_dir():
   1573             if not os.path.isdir(targetpath):
-&gt; 1574                 os.mkdir(targetpath)
   1575             return targetpath
   1576 

FileExistsError: [Errno 17] File exists: '/root/.keras/datasets/sample_file'
</code></pre>
<p>What is causing this error? How can I fix it?</p>
<p>This is the first block of code run after imports so I don't know why 'FileExistsError' happens.</p>
<p>I have tried changing the name of the file.</p>
<p>I have checked TensorFlow documentation and it uses code like this:</p>
<pre><code>dataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;
data_dir = tf.keras.utils.get_file(origin=dataset_url, 
                                   fname='flower_photos', 
                                   untar=True)
data_dir = pathlib.Path(data_dir)
</code></pre>
<p>I have run this above code and it is working. But I cannot figure out why the same code is showing error for my data. Please advice.</p>
",I am getting an error when trying to load a dataset using TensorFlow Keras. Here is the code: I have changed the URL to 'sample_file.zip' for security reasons. This is the error that I am getting: What is causing this error? How can I fix it? This is the first block of code run after imports so I don't know why 'FileExistsError' happens. I have tried changing the name of the file. I have checked TensorFlow documentation and it uses code like this: I have run this above code and it is working. But I cannot figure out why the same code is showing error for my data. Please advice.,https://stackoverflow.com/questions/63068695,12424846,Documentation Replication on Other Examples,Documentation Replicability,I have tried changing the name of the file. I have checked TensorFlow documentation and it uses code like this: I have run this above code and it is working. But I cannot figure out why the same code is showing error for my data. 
63587813,Tensorflow - Conv2D batch_input_shape array shape error,"<p>I am trying to create a basic CNN in tensor flow using some custom dataset from 2D np arrays.
I cant seem to get the input data to line up with the input_shape or batch_input_shape parameter for the convolutional layer. I have tried every order of variables and the same as the documentation, but am unsure why it still produces an error.</p>
<p>Any help would be greatly appreciated!</p>
<pre><code>import os 
import pickle
import pandas as pd
import matplotlib as plt
import numpy as np

import tensorflow as tf

from tensorflow.keras import models, datasets, layers
</code></pre>
<pre><code>BATCH_SIZE = 4
TRAIN_SPLIT = 0.8
VAL_SPLIT = 0.1
TEST_SPLIT = 0.1
</code></pre>
<pre><code>with open((CWD+'/CLNY_X.npy'), mode='rb') as f:
    Xt = np.load(f, allow_pickle=True)
with open((CWD+'/CLNY_Y.npy'), mode='rb') as f:
    Y = np.load(f, allow_pickle=True)

X = Xt.reshape(Xt.shape + (1,))
DATASIZE = Y.shape[0]
print(&quot;Datasize: &quot;, DATASIZE)
</code></pre>
<pre><code>Datasize:  172
</code></pre>
<pre><code># test out with different period moving averages, so we take the
dataset = tf.data.Dataset.from_tensor_slices((X, Y))
</code></pre>
<pre><code>for feat, targ in dataset.take(1):
    print('NRows: {}, NCols: {}, Target: {}\nFeat: {}'.format(len(feat), len(feat[0]), targ, feat))
</code></pre>
<pre><code>NRows: 10000, NCols: 10, Target: 0.2587999999523163
Feat: [[[5.0292000e+01]
  [1.5998565e-01]
  [7.5094378e-01]
  ...
  [1.0000000e+00]
  [2.5231593e-05]
  [1.4535466e-01]]

 [[5.0492001e+01]
  [2.9965147e-01]
  [1.4065099e+00]
  ...
  [1.8729897e+00]
  [4.7258512e-05]
  [2.7224776e-01]]

 [[5.0692001e+01]
  [2.9965451e-01]
  [1.4065243e+00]
  ...
  [1.8730087e+00]
  [4.7258993e-05]
  [2.7225053e-01]]

 ...

 [[0.0000000e+00]
  [0.0000000e+00]
  [0.0000000e+00]
  ...
  [0.0000000e+00]
  [0.0000000e+00]
  [0.0000000e+00]]

 [[0.0000000e+00]
  [0.0000000e+00]
  [0.0000000e+00]
  ...
  [0.0000000e+00]
  [0.0000000e+00]
  [0.0000000e+00]]

 [[0.0000000e+00]
  [0.0000000e+00]
  [0.0000000e+00]
  ...
  [0.0000000e+00]
  [0.0000000e+00]
  [0.0000000e+00]]]
</code></pre>
<pre><code>train_size = int(DATASIZE*TRAIN_SPLIT)
val_size = int(DATASIZE*VAL_SPLIT)
test_size = int(DATASIZE*TEST_SPLIT)

dataset = dataset.shuffle(DATASIZE)
train_dataset = dataset.take(train_size).batch(BATCH_SIZE)
test_dataset = dataset.skip(train_size)
val_dataset = dataset.skip(test_size)
test_dataset = dataset.take(test_size)

CONVERTED_LENGTH = 10000
CONVERTED_WIDTH = 10
</code></pre>
<pre><code>model = models.Sequential()
#model.add(layers.Conv1D(32, kernel_size=(10), activation='relu', data_format='channels_last', batch_input_shape=(CONVERTED_LENGTH, CONVERTED_WIDTH, 1)))
model.add(layers.Conv2D(32, kernel_size=(2, 2), activation='relu', batch_input_shape=(CONVERTED_LENGTH, CONVERTED_WIDTH, BATCH_SIZE, 1)))
model.add(layers.Flatten())
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(1, activation='softmax'))
model.summary()
</code></pre>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (10000, 9, 3, 32)         160       
_________________________________________________________________
flatten (Flatten)            (10000, 864)              0         
_________________________________________________________________
dense (Dense)                (10000, 32)               27680     
_________________________________________________________________
dense_1 (Dense)              (10000, 1)                33        
=================================================================
Total params: 27,873
Trainable params: 27,873
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<pre><code>model.compile(optimizer='adam',
             loss=tf.keras.losses.MeanSquaredError(),
             metrics=['accuracy'])

history = model.fit(train_dataset, epochs=10, validation_data=(val_dataset)) # add the validation_data=(test_data, test_targets)
</code></pre>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-9-c0e1d31b7f23&gt; in &lt;module&gt;
      3              metrics=['accuracy'])
      4 
----&gt; 5 history = model.fit(train_dataset, epochs=10, validation_data=(val_dataset)) # add the validation_data=(test_data, test_targets)

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--&gt; 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    233           max_queue_size=max_queue_size,
    234           workers=workers,
--&gt; 235           use_multiprocessing=use_multiprocessing)
    236 
    237       total_samples = _get_total_number_of_samples(training_data_adapter)

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    591         max_queue_size=max_queue_size,
    592         workers=workers,
--&gt; 593         use_multiprocessing=use_multiprocessing)
    594     val_adapter = None
    595     if validation_data:

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    704       max_queue_size=max_queue_size,
    705       workers=workers,
--&gt; 706       use_multiprocessing=use_multiprocessing)
    707 
    708   return adapter

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\data_adapter.py in __init__(self, x, y, sample_weights, standardize_function, **kwargs)
    700 
    701     if standardize_function is not None:
--&gt; 702       x = standardize_function(x)
    703 
    704     # Note that the dataset instance is immutable, its fine to reusing the user

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in standardize_function(dataset)
    682           return x, y
    683         return x, y, sample_weights
--&gt; 684       return dataset.map(map_fn, num_parallel_calls=dataset_ops.AUTOTUNE)
    685 
    686   if mode == ModeKeys.PREDICT:

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py in map(self, map_func, num_parallel_calls)
   1589     else:
   1590       return ParallelMapDataset(
-&gt; 1591           self, map_func, num_parallel_calls, preserve_cardinality=True)
   1592 
   1593   def flat_map(self, map_func):

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py in __init__(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)
   3924         self._transformation_name(),
   3925         dataset=input_dataset,
-&gt; 3926         use_legacy_function=use_legacy_function)
   3927     self._num_parallel_calls = ops.convert_to_tensor(
   3928         num_parallel_calls, dtype=dtypes.int32, name=&quot;num_parallel_calls&quot;)

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)
   3145       with tracking.resource_tracker_scope(resource_tracker):
   3146         # TODO(b/141462134): Switch to using garbage collection.
-&gt; 3147         self._function = wrapper_fn._get_concrete_function_internal()
   3148 
   3149         if add_to_graph:

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _get_concrete_function_internal(self, *args, **kwargs)
   2393     &quot;&quot;&quot;Bypasses error checking when getting a graph function.&quot;&quot;&quot;
   2394     graph_function = self._get_concrete_function_internal_garbage_collected(
-&gt; 2395         *args, **kwargs)
   2396     # We're returning this concrete function to someone, and they may keep a
   2397     # reference to the FuncGraph without keeping a reference to the

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2387       args, kwargs = None, None
   2388     with self._lock:
-&gt; 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2390     return graph_function
   2391 

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-&gt; 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--&gt; 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py in wrapper_fn(*args)
   3138           attributes=defun_kwargs)
   3139       def wrapper_fn(*args):  # pylint: disable=missing-docstring
-&gt; 3140         ret = _wrapper_helper(*args)
   3141         ret = structure.to_tensor_list(self._output_structure, ret)
   3142         return [ops.convert_to_tensor(t) for t in ret]

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py in _wrapper_helper(*args)
   3080         nested_args = (nested_args,)
   3081 
-&gt; 3082       ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
   3083       # If `func` returns a list of tensors, `nest.flatten()` and
   3084       # `ops.convert_to_tensor()` would conspire to attempt to stack

C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\autograph\impl\api.py in wrapper(*args, **kwargs)
    235       except Exception as e:  # pylint:disable=broad-except
    236         if hasattr(e, 'ag_error_metadata'):
--&gt; 237           raise e.ag_error_metadata.to_exception(e)
    238         else:
    239           raise

ValueError: in converted code:

    C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py:677 map_fn
        batch_size=None)
    C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training.py:2410 _standardize_tensors
        exception_prefix='input')
    C:\ProgramData\Miniconda3\lib\site-packages\tensorflow_core\python\keras\engine\training_utils.py:582 standardize_input_data
        str(data_shape))

    ValueError: Error when checking input: expected conv2d_input to have shape (10, 4, 1) but got array with shape (10000, 10, 1)
</code></pre>
<p>It always says that either the input data is not in the expected format or that the ndims is wrong as it adds None to some of the values. I just can't make it run!!</p>
","I am trying to create a basic CNN in tensor flow using some custom dataset from 2D np arrays. I cant seem to get the input data to line up with the input_shape or batch_input_shape parameter for the convolutional layer. I have tried every order of variables and the same as the documentation, but am unsure why it still produces an error. Any help would be greatly appreciated! It always says that either the input data is not in the expected format or that the ndims is wrong as it adds None to some of the values. I just can't make it run!!",https://stackoverflow.com/questions/63587813,9807578,Documentation Replicability,Documentation Replicability,"I have tried every order of variables and the same as the documentation, but am unsure why it still produces an error."
64941304,Unable to give Keras neural network multiple inputs,"<p>I am trying to get a data pipeline of text based data into a neural network with two heads. Made use of the official documentation that tells you to zip it into a dictionary of values, but it did not work.</p>
<pre><code>&lt;MapDataset shapes: (None, 32), types: tf.int64&gt;
&lt;MapDataset shapes: (None, 32), types: tf.int64&gt;
</code></pre>
<p>These are the shapes of the data that will go into each head. Have been converted into sequences of ints using the <code>VectorizeLayer()</code></p>
<p>This is the graph of the neural network</p>
<p><a href=""https://i.stack.imgur.com/6DHCH.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>I am constructing the final dataset using</p>
<pre><code>final_dataset=tf.data.Dataset.from_tensors((
    {&quot;input_1&quot;:vectorized_sen1,&quot;input_2&quot;:vectorized_sen2},
    {&quot;output&quot;:label_db}
)).batch(64)
</code></pre>
<p>But this is the error it keeps throwing</p>
<pre><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset_ops._NestedVariant'&gt; to Tensor. Contents: &lt;tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x7f9b073af780&gt;. Consider casting elements to a supported type.
</code></pre>
","I am trying to get a data pipeline of text based data into a neural network with two heads. Made use of the official documentation that tells you to zip it into a dictionary of values, but it did not work. These are the shapes of the data that will go into each head. Have been converted into sequences of ints using the VectorizeLayer() This is the graph of the neural network enter image description here I am constructing the final dataset using But this is the error it keeps throwing",https://stackoverflow.com/questions/64941304,14680310,Documentation Replicability,Documentation Replicability,"Made use of the official documentation that tells you to zip it into a dictionary of values, but it did not work."
65321954,Tensorflow custom preprocessing with tf.py_function losing shape,"<p>Im writing a model and doing the preprocessing part: I have a method which preprocesses my tensorflow dataset by calling:</p>
<p><code>ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)</code></p>
<p>I followed the tensorflow documentation and got this code for process_path:</p>
<pre><code>def process_path(filename):
  label = get_label(filename)

  image = tf.io.read_file(filename)
  image = tf.image.decode_jpeg(image, channels=3)
  image = tf.image.rgb_to_grayscale(image)
  image = tf.image.convert_image_dtype(image, tf.float32)
  image = tf.image.resize(image, [224, 224])
  
  return image, label
</code></pre>
<p>Then I want to add my own preprocessing, such as rotating the image so I created a rotate method wrapped with py_function as the documentation suggests:</p>
<pre><code>def rotate_image(image):
  return tfa.image.rotate(image, random.randrange(-5, 5)/1.0)

def tf_rotate_image(image, label):
  [image,] = tf.py_function(rotate_image, [image], [tf.float32])
  return image, label
</code></pre>
<p>However when I add this to my process_path the model seems to break and freezes... I added print statements with image.shape after each adjustment and it shows that after the rotate method the image shape becomes <code>&lt;unknown&gt;</code> so I believe this to be the error:</p>
<pre><code>def process_path(filename):
  label = get_label(filename)

  image = tf.io.read_file(filename)
  print(image.shape)
  image = tf.image.decode_jpeg(image, channels=3)
  print(image.shape)
  image = tf.image.rgb_to_grayscale(image)
  print(image.shape)
  image = tf.image.convert_image_dtype(image, tf.float32)
  print(image.shape)
  image = tf.image.resize(image, [224, 224])
  print(image.shape)

  image, label = tf_rotate_image(image, label)
  print(image.shape)
  
  return image, label
</code></pre>
<p>Output:</p>
<pre><code>()
(None, None, 3)
(None, None, 1)
(None, None, 1)
(224, 224, 1)
&lt;unknown&gt;
</code></pre>
<p>Any help is greatly appreciated.</p>
","Im writing a model and doing the preprocessing part: I have a method which preprocesses my tensorflow dataset by calling: ds = ds.map(process_path, num_parallel_calls=AUTOTUNE) I followed the tensorflow documentation and got this code for process_path: Then I want to add my own preprocessing, such as rotating the image so I created a rotate method wrapped with py_function as the documentation suggests: However when I add this to my process_path the model seems to break and freezes... I added print statements with image.shape after each adjustment and it shows that after the rotate method the image shape becomes &lt;unknown&gt; so I believe this to be the error: Output: Any help is greatly appreciated.",https://stackoverflow.com/questions/65321954,9209390,Documentation Replicability,Documentation Replicability,I followed the tensorflow documentation and got this code for process_path
66015216,How can I save a Tensorflow Core model?,"<p>I'm a beginner in Tensorflow and I found this neural network for binary classification which is giving me decent results, I would like to know after I run the session how can I save the model? I already try from the official website but nothing is working.</p>
<pre><code>class AnnMLP():

def train(self,X_input,y_input,test,range_iteration,learning_rate): X = tf.compat.v1.placeholder(tf.float32, [None,27]) Y = tf.compat.v1.placeholder(tf.float32, [None,1])

# input
W1 = tf.Variable(tf.random.normal([27,60], seed=0), name='weight1')
b1 = tf.Variable(tf.random.normal([60], seed=0), name='bias1')
layer1 = tf.nn.sigmoid(tf.matmul(X,W1) + b1)
dropout_layer = keras.layers.Dropout(rate=0.4)
layer1=dropout_layer(layer1)

# hidden1
W2 = tf.Variable(tf.random.normal([60,60], seed=0), name='weight2')
b2 = tf.Variable(tf.random.normal([60], seed=0), name='bias2')
layer2 = tf.nn.sigmoid(tf.matmul(layer1,W2) + b2)

dropout_layer = keras.layers.Dropout(rate=0.4)
layer2=dropout_layer(layer2)

# hidden2
W3 = tf.Variable(tf.random.normal([60,90], seed=0), name='weight3')
b3 = tf.Variable(tf.random.normal([90], seed=0), name='bias3')
layer3 = tf.nn.sigmoid(tf.matmul(layer2,W3) + b3)
dropout_layer = keras.layers.Dropout(rate=0.4)
layer3=dropout_layer(layer3)

# output
W4 = tf.Variable(tf.random.normal([90,1], seed=0), name='weight4')
b4 = tf.Variable(tf.random.normal([1], seed=0), name='bias4')

logits = tf.matmul(layer3,W4) + b4
hypothesis = tf.nn.sigmoid(logits)


cost_i = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y)
cost = tf.reduce_mean(cost_i)
train =tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)
#train = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost) train = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)

prediction = tf.cast(hypothesis &gt; 0.5, dtype=tf.float32)
correct_prediction = tf.equal(prediction, Y)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))
print(&quot;\n============Processing============&quot;)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for step in range(range_iteration):
        sess.run(train, feed_dict={X: X_input, Y: y_input})

        if step % 1000 == 0:

          loss, acc = sess.run([cost, accuracy], feed_dict={X: X_input, Y: y_input})
          print(&quot;Step: {:5}\tLoss: {:.3f}\tAcc: {:.2%}&quot;.format(step, loss, acc))



        train_acc = sess.run(accuracy, feed_dict={X: X_input, Y: y_input})
        if test == True:
          test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: X_test, Y: y_test})

return test_predict

 
</code></pre>
","I'm a beginner in Tensorflow and I found this neural network for binary classification which is giving me decent results, I would like to know after I run the session how can I save the model? I already try from the official website but nothing is working.",https://stackoverflow.com/questions/66015216,14473036,Documentation Ambiguity,Documentation Replicability, I already try from the official website but nothing is working.
67803574,Weights were not updated using Gradient Tape and apply_gradients(),"<p>I am building a DNN with a custom loss function and I am training this DNN using Gradient Tape in TensorFlow.keras<code>enter code here</code>. The code runs without any errors, however, as far as I can check the weights of the DNN, the weights were not being updated at all. I followed exactly what recommends from the TensorFlow website and search for the answers but still don't understand what is the reason. Here is my code:</p>
<pre><code>import numpy as np

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, LeakyReLU, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
from tensorflow.keras import optimizers

# Generate a random train data
c0_train = np.array([30 * np.random.uniform() for i in range(10000)])

# Build a simple DNN
c0_input = Input(shape=(1,), name='c0')
hidden_1 = Dense(100)(c0_input)
activation_1 = LeakyReLU(alpha=0.1)(hidden_1)
hidden_2 = Dense(100)(activation_1)
activation_2 = LeakyReLU(alpha=0.1)(hidden_2)
hidden_3 = Dense(100)(activation_2)
activation_3 = LeakyReLU(alpha=0.1)(hidden_3)
x0_output = Dense(1, name='x0')(activation_3)

model = Model(inputs=c0_input, outputs=x0_output)

# Calculating the loss function 
def cal_loss(c0_input):
  x0_output = model(c0_input)
  loss = tf.reduce_mean(
      tf.multiply(c0_input, tf.square(tf.subtract(x0_output, c0_input))))
  return loss

# Compute the gradient calculation
@tf.function
def compute_loss_grads(c0_input):
  with tf.GradientTape() as tape:
    loss = cal_loss(c0_input)
  grads = tape.gradient(loss, model.trainable_variables)
  return loss, grads

# Optimizer
opt = optimizers.Adam(learning_rate=0.01)

# Start looping
for epoch in range(50):
  print('Epoch = ', epoch)
  # Compute the loss and gradients
  [loss, grads] = compute_loss_grads(tf.cast(c0_train, tf.float32))
  # Adjust the weights of the model
  opt.apply_gradients(zip(grads, model.trainable_variables))

</code></pre>
<p>I have checked the weights of the model using <code>model.get_weights()</code> and they look exactly the same before and after running the loop. So what is the problem here? And one more question, how can I print out the loss for every epoch?</p>
","I am building a DNN with a custom loss function and I am training this DNN using Gradient Tape in TensorFlow.kerasenter code here. The code runs without any errors, however, as far as I can check the weights of the DNN, the weights were not being updated at all. I followed exactly what recommends from the TensorFlow website and search for the answers but still don't understand what is the reason. Here is my code: I have checked the weights of the model using model.get_weights() and they look exactly the same before and after running the loop. So what is the problem here? And one more question, how can I print out the loss for every epoch?",https://stackoverflow.com/questions/67803574,16104905,Documentation Replicability,Documentation Replicability,I followed exactly what recommends from the TensorFlow website and search for the answers but still don't understand what is the reason.
75020232,Get input shape with Keras custom layer,"<p>I am writing a custom layer using Keras that returns a tensors of zeros the first three times it is invoked and does nothing the other times. The code is the following</p>
<pre class=""lang-py prettyprint-override""><code>class MyLayer(tf.keras.layers.Layer):

    def __init__(self, **kwargs):
        super(MyLayer, self).__init__(**kwargs)
        self.__iteration = 0
        self.__returning_zeros = None

    def build(self, input_shape):
        self.__returning_zeros = tf.zeros(shape=input_shape, dtype=tf.float32)

    def call(self, inputs):
        self.__iteration += 1

        if self.__iteration &lt;= 3:
            return self.__returning_zeros
        else:
            return inputs
</code></pre>
<p>Unfortunately if I try to build a model using this layer like this</p>
<pre class=""lang-py prettyprint-override""><code>def build_model(input_shape, num_classes):
    input_layer = keras.Input(shape=input_shape, name='input')
    conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation=&quot;relu&quot;, name='conv1')(input_layer)
    maxpool1 = layers.MaxPooling2D(pool_size=(2, 2), name='maxpool1')(conv1)
    conv2 = layers.Conv2D(64, kernel_size=(3, 3), activation=&quot;relu&quot;, name='conv2')(maxpool1)
    mylayer = MyLayer()(conv2)
    maxpool2 = layers.MaxPooling2D(pool_size=(2, 2), name='maxpool2')(mylayer)
    flatten = layers.Flatten(name='flatten')(maxpool2)
    dropout = layers.Dropout(0.5, name='dropout')(flatten)
    dense = layers.Dense(num_classes, activation=&quot;softmax&quot;, name='dense')(dropout)

    return keras.Model(inputs=(input_layer,), outputs=dense)
</code></pre>
<p>I get the following error message</p>
<pre><code>  File &quot;customlayerkeras.py&quot;, line 25, in build
    self.__returning_zeros = tf.zeros(shape=input_shape, dtype=tf.float32)
ValueError: Cannot convert a partially known TensorShape (None, 13, 13, 64) to a Tensor.
</code></pre>
<p>Where it seems that, despite using the build function as suggested in the documentation I am not able to retrieve the correct shape of the input.
How can I fix this problem?</p>
<p>EDIT:
I was complicating the problem without thinking, the best solution is to just multiply the inputs per zero like this</p>
<pre><code>def call(self, inputs):
        self.__iteration += 1

        if self.__iteration &lt;= 3:
            return inputs*0
        else:
            return inputs
</code></pre>
","I am writing a custom layer using Keras that returns a tensors of zeros the first three times it is invoked and does nothing the other times. The code is the following Unfortunately if I try to build a model using this layer like this I get the following error message Where it seems that, despite using the build function as suggested in the documentation I am not able to retrieve the correct shape of the input. How can I fix this problem? EDIT: I was complicating the problem without thinking, the best solution is to just multiply the inputs per zero like this",https://stackoverflow.com/questions/75020232,7286547,Documentation Replicability,Documentation Replicability,Despite using the build function as suggested in the documentation I am not able to retrieve the correct shape of the input.
41604616,Save and load Tensorflow model,"<p>I want to save a Tensorflow (0.12.0) model, including graph and variable values, then later load and execute it. I have the read the docs and other posts on this but cannot get the basics to work. I am using the technique from <a href=""https://www.tensorflow.org/versions/r0.10/how_tos/meta_graph/"" rel=""nofollow noreferrer"">this page in the Tensorflow docs</a>. Code:</p>

<p>Save a simple model:</p>

<pre><code>myVar = tf.Variable(7.1)
tf.add_to_collection('modelVariables', myVar) # why?
init_op = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init_op)
    print sess.run(myVar)
    saver0 = tf.train.Saver()
    saver0.save(sess, './myModel.ckpt')
    saver0.export_meta_graph('./myModel.meta')
</code></pre>

<p>Later, load and execute the model:</p>

<pre><code>with tf.Session() as sess:
    saver1 = tf.train.import_meta_graph('./myModel.meta')
    saver1.restore(sess, './myModel.meta')
    print sess.run(myVar)
</code></pre>

<p><strong>Question 1:</strong>  The saving code seems to work but the loading code produces this error:</p>

<pre><code>W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open ./myModel.meta: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?
</code></pre>

<p>How to fix this?.</p>

<p><strong>Question 2:</strong> I included this line to follow the pattern in the TF docs...</p>

<pre><code>tf.add_to_collection('modelVariables', myVar)
</code></pre>

<p>... but why is that line necessary? Doesn't <code>expert_meta_graph</code>export the entire graph by default? If not then does one need to add every variable in the graph to the collection before saving? Or do we just add to the collection those variables that will be accessed after the restore?</p>

<p>---------------------- <em>Update January 12 2017</em> -----------------------------</p>

<p>Partial success based on Kashyap's suggestion below but a mystery still exists. The code below works <em>but</em> only if I include the lines containing <code>tf.add_to_collection</code> and <code>tf.get_collection</code>. Without those lines, 'load' mode throws an error in the last line:
<code>NameError: name 'myVar' is not defined</code>. My understanding was that by default <code>Saver.save</code> saves and restores all variables in the graph, so why is it necessary to specify the name of variables that will be used in the collection? I assume this has to do with mapping Tensorflow's variable names to Python names, but what are the rules of the game here? For which variables does this need to be done?</p>

<pre><code>mode = 'load' # or 'save'
if mode == 'save':
    myVar = tf.Variable(7.1)
    init_op = tf.global_variables_initializer()
    saver0 = tf.train.Saver()
    tf.add_to_collection('myVar', myVar) ### WHY NECESSARY?
    with tf.Session() as sess:
        sess.run(init_op)
        print sess.run(myVar)
        saver0.save(sess, './myModel')
if mode == 'load':
    with tf.Session() as sess:
        saver1 = tf.train.import_meta_graph('./myModel.meta')
        saver1.restore(sess, tf.train.latest_checkpoint('./'))
        myVar = tf.get_collection('myVar')[0]  ### WHY NECESSARY?
        print sess.run(myVar)
</code></pre>
","I want to save a Tensorflow (0.12.0) model, including graph and variable values, then later load and execute it. I have the read the docs and other posts on this but cannot get the basics to work. I am using the technique from this page in the Tensorflow docs. Code: Save a simple model: Later, load and execute the model: Question 1: The saving code seems to work but the loading code produces this error: How to fix this?. Question 2: I included this line to follow the pattern in the TF docs... ... but why is that line necessary? Doesn't expert_meta_graphexport the entire graph by default? If not then does one need to add every variable in the graph to the collection before saving? Or do we just add to the collection those variables that will be accessed after the restore? ---------------------- Update January 12 2017 ----------------------------- Partial success based on Kashyap's suggestion below but a mystery still exists. The code below works but only if I include the lines containing tf.add_to_collection and tf.get_collection. Without those lines, 'load' mode throws an error in the last line: NameError: name 'myVar' is not defined. My understanding was that by default Saver.save saves and restores all variables in the graph, so why is it necessary to specify the name of variables that will be used in the collection? I assume this has to do with mapping Tensorflow's variable names to Python names, but what are the rules of the game here? For which variables does this need to be done?",https://stackoverflow.com/questions/41604616,3444294,Documentation Replicability,Documentation Replicability,I have the read the docs and other posts on this but cannot get the basics to work. I am using the technique from this page in the Tensorflow docs.
56413873,How BatchToSpaceND actually works?,"<p>I'm trying to figure out how <a href=""https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd"" rel=""nofollow noreferrer"">BatchToSpaceND</a> permutes the input matrix. One of the examples is the following:</p>

<blockquote>
  <p>(3) For the following input of shape [4, 2, 2, 1] and block_size of 2:</p>

<pre><code>x = [[[[1], [3]], [[9], [11]]],
     [[[2], [4]], [[10], [12]]],
     [[[5], [7]], [[13], [15]]],
     [[[6], [8]], [[14], [16]]]]
</code></pre>
  
  <p>The output tensor has shape [1, 4, 4, 1] and value:</p>

<pre><code>x = [[[1],   [2],  [3],  [4]],
     [[5],   [6],  [7],  [8]],
     [[9],  [10], [11],  [12]],
     [[13], [14], [15],  [16]]]
</code></pre>
</blockquote>

<p>Anyone know how the output tensor is derived? How come the first row is <code>[[1], [2], [3], [4]]</code> and not <code>[[1], [3], [9], [11]]</code> instead? I've also tried some code:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
sess = tf.InteractiveSession()

a = [[[[1], [3]], [[9], [11]]],
     [[[2], [4]], [[10], [12]]],
     [[[5], [7]], [[13], [15]]],
     [[[6], [8]], [[14], [16]]]]
b = [2, 2, 1, 2, 2, 1]
a = tf.reshape(a, b)

b = [1, 2, 2, 2, 2, 1]
a = tf.reshape(a, b)

b = [1, 4, 4, 1]
a = tf.reshape(a, b)

print(a.eval())

[[[[ 1]
   [ 3]
   [ 9]
   [11]]

  [[ 2]
   [ 4]
   [10]
   [12]]

  [[ 5]
   [ 7]
   [13]
   [15]]

  [[ 6]
   [ 8]
   [14]
   [16]]]]
</code></pre>

<p>which isn't quite the result in the doc.</p>
","I'm trying to figure out how BatchToSpaceND permutes the input matrix. One of the examples is the following: Anyone know how the output tensor is derived? How come the first row is [[1], [2], [3], [4]] and not [[1], [3], [9], [11]] instead? I've also tried some code: which isn't quite the result in the doc.",https://stackoverflow.com/questions/56413873,233798,Documentation Ambiguity,Documentation Replicability,I've also tried some code: which isn't quite the result in the doc.
56490000,Read values of tensor in tensorflow,"<p>I'm working with Python 3.6 in PyCharm. </p>

<p>In the file <code>site-packages/tensorflow/python/ops/nn_ops.py</code>, </p>

<p>I find after line 838</p>

<pre class=""lang-py prettyprint-override""><code>    with ops.name_scope(name, ""convolution"", [input, filter]) as name:
        input = ops.convert_to_tensor(input, name=""input"")  
        input_shape = input.get_shape()
        filter = ops.convert_to_tensor(filter, name=""filter"")  
        filter_shape = filter.get_shape()
        op = Convolution(
            input_shape,
            filter_shape,
            padding,
            strides=strides,
            dilation_rate=dilation_rate,
            name=name,
            data_format=data_format)
        return op(input,filter)
</code></pre>

<p>I want to know the values of input, filter and the returned tensor. </p>

<p>I tried, according to <a href=""https://www.tensorflow.org/api_docs/python/tf/InteractiveSession"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/InteractiveSession</a> to do</p>

<pre class=""lang-py prettyprint-override""><code>    with ops.name_scope(name, ""convolution"", [input, filter]) as name:
        input = ops.convert_to_tensor(input, name=""input"") 
        input_shape = input.get_shape()
        filter = ops.convert_to_tensor(filter, name=""filter"")  
        filter_shape = filter.get_shape()
        op = Convolution(
            input_shape,
            filter_shape,
            padding,
            strides=strides,
            dilation_rate=dilation_rate,
            name=name,
            data_format=data_format)
        temp = op(input,filter)
        import tensorflow as tf
        sess = tf.Session()
        with sess.as_default():
            assert tf.get_default_session() is sess
            test = filter.eval()
        return temp
</code></pre>

<p>Then, I got the error:</p>

<pre><code>    tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value conv2d_1/kernel
     [[{{node conv2d_1/kernel/read}}]]
</code></pre>

<p>What am I doing wrong?</p>
","I'm working with Python 3.6 in PyCharm. In the file site-packages/tensorflow/python/ops/nn_ops.py, I find after line 838 I want to know the values of input, filter and the returned tensor. I tried, according to https://www.tensorflow.org/api_docs/python/tf/InteractiveSession to do Then, I got the error: What am I doing wrong?",https://stackoverflow.com/questions/56490000,8516342,Documentation Replication on Other Examples,Documentation Replicability," I tried, according to https://www.tensorflow.org/api_docs/python/tf/InteractiveSession to do Then, I got the error: What am I doing wrong?"
46920414,type mismatch using sparse_precision_at_k from tensorflow.metrics,"<p>I am working with a toy example to check how <code>tensorflow.metrics.sparse_precision_at_k</code> works</p>

<p>From the documentation:</p>

<blockquote>
  <p>labels: <code>int64</code> <code>Tensor</code> or <code>SparseTensor</code> with shape
      [D1, ... DN, num_labels] or [D1, ... DN], where the latter implies
      num_labels=1. N >= 1 and num_labels is the number of target classes for
      the associated prediction. Commonly, N=1 and <code>labels</code> has shape
      [batch_size, num_labels]. [D1, ... DN] must match <code>predictions</code>. Values
      should be in range [0, num_classes), where num_classes is the last
      dimension of <code>predictions</code>. Values outside this range are ignored.</p>
  
  <p>predictions: Float <code>Tensor</code> with shape [D1, ... DN, num_classes] where
      N >= 1. Commonly, N=1 and predictions has shape [batch size, num_classes].
      The final dimension contains the logit values for each class. [D1, ... DN]
      must match <code>labels</code>.</p>
  
  <p>k: Integer, k for @k metric.</p>
</blockquote>

<p>So I have written a following example accordingly: </p>

<pre><code>import tensorflow as tf
import numpy as np

pred = np.asarray([[.8,.1,.1,.1],[.2,.9,.9,.9]]).T
print(pred.shape)

segm = [0,1,1,1]
segm = np.asarray(segm, np.float32)
print(segm.shape)

segm_tf = tf.Variable(segm, np.int64)
pred_tf = tf.Variable(pred, np.float32)

print(""segm_tf"", segm_tf.shape)
print(""pred_tf"", pred_tf.shape)

prec,_ = tf.metrics.sparse_precision_at_k(segm_tf, pred_tf, 1, class_id=1)
sess = tf.InteractiveSession()
tf.variables_initializer([prec, segm_tf, pred_tf])
</code></pre>

<p>However, I am getting an error:</p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-7-c6243802dedc&gt; in &lt;module&gt;()
     25 print(""pred_tf"", pred_tf.shape)
     26 
---&gt; 27 prec,_ = tf.metrics.sparse_precision_at_k(segm_tf, pred_tf, 1, class_id=1)
     28 sess = tf.InteractiveSession()
     29 tf.variables_initializer([prec, segm_tf, pred_tf])

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in sparse_precision_at_k(labels, predictions, k, class_id, weights, metrics_collections, updates_collections, name)
   2828         metrics_collections=metrics_collections,
   2829         updates_collections=updates_collections,
-&gt; 2830         name=scope)
   2831 
   2832 

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in _sparse_precision_at_top_k(labels, predictions_idx, k, class_id, weights, metrics_collections, updates_collections, name)
   2726     tp, tp_update = _streaming_sparse_true_positive_at_k(
   2727         predictions_idx=top_k_idx, labels=labels, k=k, class_id=class_id,
-&gt; 2728         weights=weights)
   2729     fp, fp_update = _streaming_sparse_false_positive_at_k(
   2730         predictions_idx=top_k_idx, labels=labels, k=k, class_id=class_id,

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in _streaming_sparse_true_positive_at_k(labels, predictions_idx, k, class_id, weights, name)
   1743     tp = _sparse_true_positive_at_k(
   1744         predictions_idx=predictions_idx, labels=labels, class_id=class_id,
-&gt; 1745         weights=weights)
   1746     batch_total_tp = math_ops.to_double(math_ops.reduce_sum(tp))
   1747 

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in _sparse_true_positive_at_k(labels, predictions_idx, class_id, weights, name)
   1689       name, 'true_positives', (predictions_idx, labels, weights)):
   1690     labels, predictions_idx = _maybe_select_class_id(
-&gt; 1691         labels, predictions_idx, class_id)
   1692     tp = sets.set_size(sets.set_intersection(predictions_idx, labels))
   1693     tp = math_ops.to_double(tp)

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in _maybe_select_class_id(labels, predictions_idx, selected_id)
   1651   if selected_id is None:
   1652     return labels, predictions_idx
-&gt; 1653   return (_select_class_id(labels, selected_id),
   1654           _select_class_id(predictions_idx, selected_id))
   1655 

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in _select_class_id(ids, selected_id)
   1627   filled_selected_id = array_ops.fill(
   1628       filled_selected_id_shape, math_ops.to_int64(selected_id))
-&gt; 1629   result = sets.set_intersection(filled_selected_id, ids)
   1630   return sparse_tensor.SparseTensor(
   1631       indices=result.indices, values=result.values, dense_shape=ids_shape)

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/sets_impl.py in set_intersection(a, b, validate_indices)
    191     intersections.
    192   """"""
--&gt; 193   a, b, _ = _convert_to_tensors_or_sparse_tensors(a, b)
    194   return _set_operation(a, b, ""intersection"", validate_indices)
    195 

/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/sets_impl.py in _convert_to_tensors_or_sparse_tensors(a, b)
     82   b = sparse_tensor.convert_to_tensor_or_sparse_tensor(b, name=""b"")
     83   if b.dtype.base_dtype != a.dtype.base_dtype:
---&gt; 84     raise TypeError(""Types don't match, %s vs %s."" % (a.dtype, b.dtype))
     85   if (isinstance(a, sparse_tensor.SparseTensor) and
     86       not isinstance(b, sparse_tensor.SparseTensor)):

TypeError: Types don't match, &lt;dtype: 'int64'&gt; vs &lt;dtype: 'float32'&gt;.
</code></pre>
","I am working with a toy example to check how tensorflow.metrics.sparse_precision_at_k works From the documentation: So I have written a following example accordingly: However, I am getting an error:",https://stackoverflow.com/questions/46920414,1716733,Requesting (Additional) Resources,Documentation Replicability,"I am working with a toy example to check how tensorflow.metrics.sparse_precision_at_k works from the documentation. So I have written a following example accordingly. However, I am getting an error."
63063260,Extracting features from EfficientNet Tensorflow,"<p>I have a CNN model trained using EfficientNetB6.
My task is to extract the features of this trained model by removing the last dense layer and then using those weights to train a boosting model.
i did this using Pytorch earlier and was able to extract the weights from the layers i was interested and predicted on my validation set and then boosted.</p>
<p>I am doing this now in tensorflow but currently stuck.
Below is my model structure and I have tried using the code on the website but did not had any luck.
<a href=""https://i.stack.imgur.com/eGdv4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eGdv4.png"" alt=""enter image description here"" /></a></p>
<p>I want to remove the last dense layer and predict on the validation set using the remaining layers.</p>
<p>I tried using :</p>
<p>layer_name = 'efficientnet-b6'
intermediate_layer_model = tf.keras.Model(inputs = model.input, outputs = model.get_layer(layer_name).output)</p>
<p>but i get an error &quot;
ValueError: Graph disconnected: cannot obtain value for tensor Tensor(&quot;input_1:0&quot;, shape=(None, 760, 760, 3), dtype=float32) at layer &quot;input_1&quot;. The following previous layers were accessed without issue: []&quot;</p>
<p>Any way to resolve this?</p>
","I have a CNN model trained using EfficientNetB6. My task is to extract the features of this trained model by removing the last dense layer and then using those weights to train a boosting model. i did this using Pytorch earlier and was able to extract the weights from the layers i was interested and predicted on my validation set and then boosted. I am doing this now in tensorflow but currently stuck. Below is my model structure and I have tried using the code on the website but did not had any luck. I want to remove the last dense layer and predict on the validation set using the remaining layers. I tried using : layer_name = 'efficientnet-b6' intermediate_layer_model = tf.keras.Model(inputs = model.input, outputs = model.get_layer(layer_name).output) but i get an error "" ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""input_1:0"", shape=(None, 760, 760, 3), dtype=float32) at layer ""input_1"". The following previous layers were accessed without issue: []"" Any way to resolve this?",https://stackoverflow.com/questions/63063260,5197636,Requesting (Additional) Resources,Documentation Replicability,Below is my model structure and I have tried using the code on the website but did not had any luck.
70894266,minimize method not taking argument,"<p>From the tensorflow doc i have read <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdamOptimizer"" rel=""nofollow noreferrer"">here</a>, I have tried to minimise the adam optimizer.</p>
<pre><code>optimizer = tf.compat.v1.train.AdamOptimizer
print(&quot;Using AdamOptimizer...&quot;)

train_step = optimizer.minimize(loss, global_step = global_step,var_list = [process_image])
</code></pre>
<p>But I receive this error below from the code. Even though I have passed through the 'loss' argument. I think it may be due to using Tensorflow 2?</p>
<p><a href=""https://i.stack.imgur.com/4GpQV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4GpQV.png"" alt=""enter image description here"" /></a></p>
","From the tensorflow doc i have read here, I have tried to minimise the adam optimizer. But I receive this error below from the code. Even though I have passed through the 'loss' argument. I think it may be due to using Tensorflow 2?",https://stackoverflow.com/questions/70894266,12164928,Documentation Replicability,Documentation Replicability,"From the tensorflow doc i have read here, I have tried to minimise the adam optimizer. But I receive this error below from the code. "
42323640,Tensorflow: AttributeError: module 'tensorflow' has no attribute 'Supervisor',"<p>I'm trying to use the Supervisor class to create checkpoints that can be used to save/load partial trainings, as mentioned in the TensorFlow documentation - <a href=""https://www.tensorflow.org/programmers_guide/supervisor"" rel=""nofollow noreferrer"">https://www.tensorflow.org/programmers_guide/supervisor</a> . </p>

<p>But when I try to use it as mentioned in the docs - </p>

<pre><code>sv = tf.Supervisor(logdir=""/checkpoints"")` 
with sv.managed_session() as sess:
</code></pre>

<p>It throws the below error -</p>

<blockquote>
  <p>Tensorflow: AttributeError: module 'tensorflow' has no attribute 'Supervisor'</p>
</blockquote>

<p>Whats am I missing?</p>
","I'm trying to use the Supervisor class to create checkpoints that can be used to save/load partial trainings, as mentioned in the TensorFlow documentation - https://www.tensorflow.org/programmers_guide/supervisor . But when I try to use it as mentioned in the docs - It throws the below error - Whats am I missing?",https://stackoverflow.com/questions/42323640,4993842,Documentation Replicability,Documentation Replicability,But when I try to use it as mentioned in the docs - It throws the below error - Whats am I missing?
48814591,Too many values to unpack in TensorFlow KMean Class,"<p>I'm currently using the <code>KMeans</code> Class from <code>tensorflow.contrib.factorization</code> module. My input is (assuming all variables are defined):</p>

<pre><code>kmeans = KMeans(inputs=X, num_clusters=k, distance_metric='cosine', use_mini_batch=True)
</code></pre>

<p>I'm following the documentation at <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeans"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeans</a> to unpack the values like:</p>

<pre><code>(all_scores, cluster_idx, scores, cluster_centers_initialized, init_op, train_op) = kmeans.training_graph()
</code></pre>

<p>I get the error:</p>

<pre><code>----&gt; (all_scores, cluster_idx, scores, cluster_centers_initialized, init_op, train_op) = kmeans.training_graph()    
ValueError: too many values to unpack
</code></pre>

<p>I'm strongly guessing that the <strong>documentation in the link stated above isn't updated</strong> because the output of <code>kmeans.training_graph()</code> is :</p>

<pre><code>((&lt;tf.Tensor 'sub_14:0' shape=(?, ?) dtype=float32&gt;,),
 (&lt;tf.Tensor 'Squeeze_7:0' shape=&lt;unknown&gt; dtype=int64&gt;,),
 (&lt;tf.Tensor 'Squeeze_6:0' shape=&lt;unknown&gt; dtype=float32&gt;,),
 &lt;tf.Variable 'initialized_3:0' shape=() dtype=bool_ref&gt;,
 &lt;tf.Variable 'clusters_3:0' shape=&lt;unknown&gt; dtype=float32_ref&gt;,
 tf.Tensor 'cond_3/Merge:0' shape=() dtype=bool&gt;,
 &lt;tf.Operation 'group_deps_3' type=NoOp&gt;)
</code></pre>

<p>Please let me know what is the extra returned valued that I'm not aware of by reading the documentation.</p>
",I'm currently using the KMeans Class from tensorflow.contrib.factorization module. My input is (assuming all variables are defined): I'm following the documentation at https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeans to unpack the values like: I get the error: I'm strongly guessing that the documentation in the link stated above isn't updated because the output of kmeans.training_graph() is : Please let me know what is the extra returned valued that I'm not aware of by reading the documentation.,https://stackoverflow.com/questions/48814591,3749292,Documentation Replicability,Documentation Replicability,I'm following the documentation at https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeans to unpack the values like: I get the error
45446236,Tensorflow slower when using multiple threads during preprocessing on CPU,"<p>I have a dataset that is generated on the fly on the CPU. Samples are computed in python by a function <code>make_sample</code> that is pretty complex and <em>cannot</em> be translated into tensorflow ops. Because sample generation is time consuming, I want to call the function from multiple threads to fill an input queue.</p>

<p>I started from the <a href=""https://www.tensorflow.org/programmers_guide/reading_data#batching"" rel=""nofollow noreferrer"">example given in the documentation</a> and arrived at the following toy example:</p>

<pre><code>import numpy as np
import tensorflow as tf
import time

def make_sample():
  # something that takes time and needs to be on CPU w/o tf ops
  p = 1
  for n in range(1000000):
    p = (p + np.random.random()) * np.random.random()
  return np.float32(p)

read_threads = 1

with tf.device('/cpu:0'):
  example_list = [tf.py_func(make_sample, [], [tf.float32]) for _ in range(read_threads)]
  for ex in example_list:
    ex[0].set_shape(())
  batch_size = 3
  capacity = 30
  batch = tf.train.batch_join(example_list, batch_size=batch_size, capacity=capacity)

with tf.Session().as_default() as sess:
  tf.global_variables_initializer().run()
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(sess=sess, coord=coord)
  try:
    # dry run, left out of timing
    sess.run(batch)
    start_time = time.time()
    for it in range(5):
      print(sess.run(batch))
  finally:
    duration = time.time() - start_time
    print('duration: {0:4.2f}s'.format(duration))
    coord.request_stop()
  coord.join(threads)
</code></pre>

<p>What surprises me is that, when increasing <code>read_threads</code>, the CPU usage never goes above 50%. What's worse, the computation time plummets: on my computer,</p>

<ul>
<li><code>read_threads=1</code> → <code>duration: 12s</code></li>
<li><code>read_threads=2</code> → <code>duration: 46s</code></li>
<li><code>read_threads=4</code> → <code>duration: 68s</code></li>
<li><code>read_threads=8</code> → <code>duration: 112s</code></li>
</ul>

<p>Is there an explanation, and above all, a solution to get efficient multithreaded data generation with custom python function on tensorflow?</p>
","I have a dataset that is generated on the fly on the CPU. Samples are computed in python by a function make_sample that is pretty complex and cannot be translated into tensorflow ops. Because sample generation is time consuming, I want to call the function from multiple threads to fill an input queue. I started from the example given in the documentation and arrived at the following toy example: What surprises me is that, when increasing read_threads, the CPU usage never goes above 50%. What's worse, the computation time plummets: on my computer, Is there an explanation, and above all, a solution to get efficient multithreaded data generation with custom python function on tensorflow?",https://stackoverflow.com/questions/45446236,1735003,Documentation Replicability,Documentation Replicability,I started from the example given in the documentation and arrived at the following toy example:
46870058,Calling TensorFlow's Dataset.from_generator method,"<p>The TensorFlow 1.4 documentation provides code that demonstrates the usage of <a href=""https://www.tensorflow.org/versions/r1.4/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">Dataset.from_generator</a>. When I run the code, I get an InvalidArgumentError:<code>0-th value returned by pyfunc_0 is int32, but expects int64</code>.</p>

<p>I'm using Python 3.6.1. Here's the code:</p>

<pre><code>def gen():
    for i in itertools.count(1):
    yield (i, [1] * i)

ds = tf.data.Dataset.from_generator(gen, (tf.int64, tf.int64), 
    (tf.TensorShape([]), tf.TensorShape([None])))
value = ds.make_one_shot_iterator().get_next()

with tf.Session() as sess:
    sess.run(value)  # (1, array([1]))
    sess.run(value)  # (2, array([1, 1]))
</code></pre>

<p>Any ideas?</p>
","The TensorFlow 1.4 documentation provides code that demonstrates the usage of Dataset.from_generator. When I run the code, I get an InvalidArgumentError:0-th value returned by pyfunc_0 is int32, but expects int64. I'm using Python 3.6.1. Here's the code: Any ideas?",https://stackoverflow.com/questions/46870058,934904,Documentation Replication on Other Examples,Documentation Replicability,"The TensorFlow 1.4 documentation provides code that demonstrates the usage of Dataset.from_generator. When I run the code, I get an InvalidArgumentError:"
67676763,How to read an array (list of dictionaries) into Python Tensorflow?,"<p>As a result of dealing with a gigantic dataset that takes up too much memory, I need to tap into Tensorflow's generator functions (e.g. map, apply)</p>
<p>I have the following array that I'd like to load into Tensorflow:</p>
<pre><code>array = [{'field_one':'1','field_two':'2'},{'field_one':'3','field_two':'4'},{'field_one':'5','field_two':'6'}]
</code></pre>
<p>From reading the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=fr"" rel=""nofollow noreferrer"">documentation</a>, I've tried the following:</p>
<pre><code>import tensorflow as tf

array = [{'field_one':'1','field_two':'2'},{'field_one':'3','field_two':'4'},{'field_one':'5','field_two':'6'}]

dataset = tf.data.Dataset.from_tensor_slices(array)
</code></pre>
<p>However it returns the following error:</p>
<pre><code>ValueError: Attempt to convert a value with an unsupported type to a Tensor. 
</code></pre>
<p>I've also tried the following based on <a href=""https://www.kite.com/python/answers/how-to-convert-a-numpy-array-to-a-tensorflow-tensor-in-python"" rel=""nofollow noreferrer"">this documentation</a> that generates the same error:</p>
<pre><code>data_tensor = tf.convert_to_tensor(array)
</code></pre>
<p>I've also tried this as well, which generates a different error:</p>
<pre><code>tf.data.Dataset(array)
</code></pre>
<p>Error:</p>
<pre><code>TypeError: Can't instantiate abstract class DatasetV2 with abstract methods _inputs, element_spec
</code></pre>
","As a result of dealing with a gigantic dataset that takes up too much memory, I need to tap into Tensorflow's generator functions (e.g. map, apply) I have the following array that I'd like to load into Tensorflow: From reading the documentation, I've tried the following: However it returns the following error: I've also tried the following based on this documentation that generates the same error: I've also tried this as well, which generates a different error: Error:",https://stackoverflow.com/questions/67676763,2850808,Documentation Replicability,Documentation Replicability,I've also tried the following based on this documentation that generates the same error.
75298969,OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed when using a dataset with tuples,"<p>I am trying to create my own transformer with tensorflow and of course I want to train it. For the purpuse I use dataset to handle my data. The data is created by a code snippet from the tensorflow dataset.from_tensor_slices() method documentation article. Nevertheless, tensorflow is giving me the following error when I call the fit() method:</p>
<blockquote>
<p>&quot;<strong>OperatorNotAllowedInGraphError: Iterating over a symbolic <code>tf.Tensor</code> is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.</strong>&quot;</p>
</blockquote>
<p>Here is the code that I am using:</p>
<pre><code>import numpy as np
import tensorflow as tf

batched_features = tf.constant([[[1, 3], [2, 3]],
                                [[2, 1], [1, 2]],
                                [[3, 3], [3, 2]]], shape=(3, 2, 2))
batched_labels = tf.constant([['A', 'A'],
                              ['B', 'B'],
                              ['A', 'B']], shape=(3, 2, 1))
dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))
dataset = dataset.batch(1)
for element in dataset.as_numpy_iterator():
  print(element)

class MyTransformer(tf.keras.Model):
    def __init__(self):
        super().__init__()
        
    def call(self, inputs, training):
        print(type(inputs))
        feature, lable = inputs
        return feature

model = MyTransformer()
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
              loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=[tf.keras.metrics.BinaryAccuracy(),
                       tf.keras.metrics.FalseNegatives()])

model.fit(train_data, batch_size = 1, epochs = 1)
</code></pre>
<p>The code is reduced significantly just for the purpuse of reproducing the issue.</p>
<p>I've tried passing the data as dictionary instead of tuple and couple more things but nothing worked. It seems that I am missing something.</p>
","I am trying to create my own transformer with tensorflow and of course I want to train it. For the purpuse I use dataset to handle my data. The data is created by a code snippet from the tensorflow dataset.from_tensor_slices() method documentation article. Nevertheless, tensorflow is giving me the following error when I call the fit() method: Here is the code that I am using: The code is reduced significantly just for the purpuse of reproducing the issue. I've tried passing the data as dictionary instead of tuple and couple more things but nothing worked. It seems that I am missing something.",https://stackoverflow.com/questions/75298969,5757458,Documentation Replicability,Documentation Replicability,"The data is created by a code snippet from the tensorflow dataset.from_tensor_slices() method documentation article. Nevertheless, tensorflow is giving me the following error when I call the fit() method."
52864435,Measuring GPU memory usage with TensorFlow profiler,"<p>Is there a way to properly measure GPU usage of tf.Estimator model using TensorFlow profiler? I've followed the documentation:</p>

<pre><code>g = tf.Graph()
sess = tf.Session(graph=g)
run_meta = tf.RunMetadata()

time_and_memory_args = tf.profiler.ProfileOptionBuilder.time_and_memory()

with g.as_default():
    data_shape = [BATCH_SIZE] + [3, 224, 224]
    in_plh = tf.placeholder(tf.float32, data_shape)

    model = some_model(in_plh, args=model_args, training=True)
    images = np.random.rand(BATCH_SIZE, 3, 224, 224)

    sess.run(tf.global_variables_initializer())
    sess.run(model, feed_dict={in_plh: images})

    time_and_memory = tf.profiler.profile(g, run_meta=run_meta, cmd='op',
                                          options=time_and_memory_args) 

    if time_and_memory is not None:
        print('Total requested bytes:', time_and_memory.total_requested_bytes)
</code></pre>

<p>But the printed result is always 0.</p>
",Is there a way to properly measure GPU usage of tf.Estimator model using TensorFlow profiler? I've followed the documentation: But the printed result is always 0.,https://stackoverflow.com/questions/52864435,5991102,Documentation Replicability,Documentation Replicability,Is there a way to properly measure GPU usage of tf.Estimator model using TensorFlow profiler? I've followed the documentation: But the printed result is always 0.
56453002,Tensorflow handling arrays as feature_columns,"<p>I'm trying to build a classifier which takes an array of floats as an input.</p>

<p>Despite following steps <a href=""https://www.tensorflow.org/alpha/tutorials/estimators/linear"" rel=""nofollow noreferrer"">here</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column"" rel=""nofollow noreferrer"">here</a> to include an array as the input feature I keep getting an TypeError whereby the estimator doesn't recognise the shape of the input.</p>

<p>How do you include an array as a feature for an estimator? Can you simply pass in the numeric_column with an appropriate shape as expected in the docs?</p>

<p>Sample code here:</p>

<pre><code>import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import feature_column

z = [[1, 2], [3,4]]
df = pd.DataFrame(z)
df = df.apply(lambda x: np.array(x), axis=1)

feature_columns = []

for col in ['feature']:
    feature_columns.append(feature_column.numeric_column(col, shape=(2, )))

df = pd.DataFrame(df)
df.columns = ['feature']
df['target'] = 1
y_train = df.pop('target')

def make_input_fn(X, y, n_epochs=None, shuffle=True):
    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
        if shuffle:
            dataset = dataset.shuffle(20)
        # For training, cycle thru dataset as many times as need (n_epochs=None).    
        dataset = dataset.repeat(n_epochs)  
        # In memory training doesn't use batching.
        dataset = dataset.batch(5)
        return dataset
    return input_fn

train_input_fn = make_input_fn(df, y_train)

linear_est = tf.estimator.LinearRegressor(feature_columns)

linear_est.train(train_input_fn, max_steps=100)
</code></pre>

<p>which gives a stack trace of </p>

<pre><code>Traceback (most recent call last):
  File ""/Applications/PyCharm.app/Contents/helpers/pydev/_pydevd_bundle/pydevd_exec2.py"", line 3, in Exec
    exec(exp, global_vars, local_vars)
  File ""&lt;string&gt;"", line 39, in &lt;module&gt;
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 359, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1139, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1166, in _train_model_default
    input_fn, ModeKeys.TRAIN))
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1003, in _get_features_and_labels_from_input_fn
    self._call_input_fn(input_fn, mode))
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1094, in _call_input_fn
    return input_fn(**kwargs)
  File ""&lt;string&gt;"", line 23, in input_fn
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 279, in from_tensor_slices
    return TensorSliceDataset(tensors)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 2091, in __init__
    for i, t in enumerate(nest.flatten(tensors))
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 2091, in &lt;listcomp&gt;
    for i, t in enumerate(nest.flatten(tensors))
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1050, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1108, in convert_to_tensor_v2
    as_ref=False)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1186, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py"", line 304, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py"", line 245, in constant
    allow_broadcast=True)
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py"", line 283, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 574, in make_tensor_proto
    append_fn(tensor_proto, proto_values)
  File ""tensorflow/python/framework/fast_tensor_util.pyx"", line 127, in tensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto
  File ""/Users/nicholashilton/.virtualenvs/fantifi/lib/python3.7/site-packages/tensorflow/python/util/compat.py"", line 61, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got array([1, 2])
</code></pre>
",I'm trying to build a classifier which takes an array of floats as an input. Despite following steps here and here to include an array as the input feature I keep getting an TypeError whereby the estimator doesn't recognise the shape of the input. How do you include an array as a feature for an estimator? Can you simply pass in the numeric_column with an appropriate shape as expected in the docs? Sample code here: which gives a stack trace of,https://stackoverflow.com/questions/56453002,6801991,Documentation Replicability,Documentation Replicability,Despite following steps here and here to include an array as the input feature I keep getting an TypeError whereby the estimator doesn't recognise the shape of the input.
44311820,Tensorflow tanh with quantized values,"<p>I am experimenting with the quantization of a neural network in Tensorflow 1.1.</p>

<p>According to the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/tanh"" rel=""nofollow noreferrer"">documentation</a>, the <code>tanh</code> operation supports floating point inputs as well as fixed point inputs of type <code>qint32</code>. However, I can't get this to work:</p>

<pre><code>import tensorflow as tf

sess = tf.InteractiveSession()

x = tf.constant([1.,2.,3.], dtype=tf.float32)

from tensorflow.python.ops.gen_array_ops import quantize_v2
x_quant = quantize_v2(x, min_range=0., max_range=4., T=tf.qint32)

y_quant = tf.nn.tanh(x_quant[0])
</code></pre>

<p>The code yields an error message:</p>

<blockquote>
<pre><code>TypeError: Value passed to parameter 'x' has DataType qint32 not in list of 
allowed values: float16, float32, float64, complex64, complex128
</code></pre>
</blockquote>

<p>Is there a way out or is it just a bug in the docs?</p>
","I am experimenting with the quantization of a neural network in Tensorflow 1.1. According to the documentation, the tanh operation supports floating point inputs as well as fixed point inputs of type qint32. However, I can't get this to work: The code yields an error message: Is there a way out or is it just a bug in the docs?",https://stackoverflow.com/questions/44311820,1095888,Documentation Replicability,Documentation Replicability,"According to the documentation, the tanh operation supports floating point inputs as well as fixed point inputs of type qint32. However, I can't get this to work: The code yields an error message: Is there a way out or is it just a bug in the docs?"
42419837,Tensorflow tf.matmul example is incorrect?,"<p>I read the official document for <a href=""https://www.tensorflow.org/api_docs/python/tf/matmul"" rel=""nofollow noreferrer"">tf.matmul</a> 
and I understand the first example.
It is a simple [2,3] x [3,2] operation:</p>

<pre><code>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])

b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])

c = tf.matmul(a, b) =&gt; [[58 64]
                    [139 154]]
</code></pre>

<p>However, the second example seems very strange :</p>

<pre><code>a = tf.constant(np.arange(1, 13, dtype=np.int32),
            shape=[2, 2, 3])

b = tf.constant(np.arange(13, 25, dtype=np.int32),
            shape=[2, 3, 2])

c = tf.matmul(a, b) =&gt; [[[ 94 100]
                     [229 244]],
                    [[508 532]
                     [697 730]]]
</code></pre>

<p>Why the matrix with shape [2,2,3] is allowed to multiply with [2,3,2] ?</p>
","I read the official document for tf.matmul and I understand the first example. It is a simple [2,3] x [3,2] operation: However, the second example seems very strange : Why the matrix with shape [2,2,3] is allowed to multiply with [2,3,2] ?",https://stackoverflow.com/questions/42419837,7611906,Documentation Replicability,Documentation Replicability,"I read the official document for tf.matmul and I understand the first example. It is a simple [2,3] x [3,2] operation: However, the second example seems very strange : Why the matrix with shape [2,2,3] is allowed to multiply with [2,3,2] ?"
42956766,3D tensors with tensorflow tf.matmul,"<p>I want to do a multiplication with two 3-D tensors, as defined:  </p>

<pre><code>a = tf.random_uniform(shape = [5,3,3])   

b = tf.ones(shape = [5,3,1])   

c = tf.matmul(a,b) 
</code></pre>

<p>but I can't get the right answer as described in the tf.matmul function   </p>

<p><a href=""https://www.tensorflow.org/api_docs/python/tf/matmul"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/matmul</a>  </p>
","I want to do a multiplication with two 3-D tensors, as defined: but I can't get the right answer as described in the tf.matmul function https://www.tensorflow.org/api_docs/python/tf/matmul",https://stackoverflow.com/questions/42956766,7752274,Documentation Replicability,Documentation Replicability,"I want to do a multiplication with two 3-D tensors, as defined: but I can't get the right answer as described in the tf.matmul function https://www.tensorflow.org/api_docs/python/tf/matmul"
51248442,Behavior of the parameter 'throttle_secs' in tf.estimator.EvalSpec for use in tf.estimator.train_and_evaluate,"<p>I am using tensorflow's train_and_eval function as in the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">example</a>. Therefore i create an instance of tf.estimator.EvalSpec, according to </p>

<pre><code>eval_spec = tf.estimator.EvalSpec(input_fn=...,throttle_secs=60).
</code></pre>

<p>According to its <a href=""http://eval_spec%20=%20tf.estimator.EvalSpec(input_fn=lambda:%20tf_data_utils.monuseg_input_func(mdl_info,train=False,normalize=True),throttle_secs=60*5)"" rel=""nofollow noreferrer"">documentation</a> the explanation of the parameter throttle_secs states that </p>

<p>""Of course, evaluation does not occur if no new checkpoints are available, hence, this is the minimum.""</p>

<p>However, i observe a different behavior. If there is no new checkpoint and evaluation should be triggered according to the passed parameter a new checkpoint is created and evaluation is performed. </p>

<p>Is this a bug or am i missing something here?</p>
","I am using tensorflow's train_and_eval function as in the example. Therefore i create an instance of tf.estimator.EvalSpec, according to According to its documentation the explanation of the parameter throttle_secs states that ""Of course, evaluation does not occur if no new checkpoints are available, hence, this is the minimum."" However, i observe a different behavior. If there is no new checkpoint and evaluation should be triggered according to the passed parameter a new checkpoint is created and evaluation is performed. Is this a bug or am i missing something here?",https://stackoverflow.com/questions/51248442,6456025,Documentation Replicability,Documentation Replicability,"According to its documentation the explanation of the parameter throttle_secs states that ""Of course, evaluation does not occur if no new checkpoints are available, hence, this is the minimum."" However, i observe a different behavior. "
52046902,cudnnLSTM won't restore into a cudnnCompatibleLSTM,"<p>I'm trying to train an elementary network on a GPU machine (AWS p3x2, Volta) with TF 1.9 / 1.10. Not Keras -- TF only.</p>

<p>Based on the [rather limited] documentation my aim is to train with cudnnLSTM cell, save a checkpoint, and then restore for inference on a CPU. Per that aim, I thought that cudnnCompatibleLSTM is the way to go as it is supposed to suck in the weights from the GPU-specific LSTM implementation.</p>

<p>I get the following error, no matter what I try:</p>

<pre><code>NotFoundError (see above for traceback): Key caseTesting/testbed/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias not found in checkpoint   [[Node: caseTesting/testbed/save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT],
_device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_ caseTesting/testbed/save/Const_0_0, caseTesting/testbed/save/RestoreV2/tensor_names, caseTesting/testbed/save/RestoreV2/shape_and_slices)]]
</code></pre>

<p>Another related issue is that cudnnCompatibleLSTM and cudnnLSTM are not the same mathematically. I get different results for initialized cells. [initialized by some tf.constant() as initializer, no save/restore]. Seems that cudnnLSTM does depend on the random seed [dropout is zero], which means that there are some unique tensor/tensor initialization going on, separating it from cudnnCompatibleLSTM.</p>

<p>Does anybody have a clue?</p>
","I'm trying to train an elementary network on a GPU machine (AWS p3x2, Volta) with TF 1.9 / 1.10. Not Keras -- TF only. Based on the [rather limited] documentation my aim is to train with cudnnLSTM cell, save a checkpoint, and then restore for inference on a CPU. Per that aim, I thought that cudnnCompatibleLSTM is the way to go as it is supposed to suck in the weights from the GPU-specific LSTM implementation. I get the following error, no matter what I try: Another related issue is that cudnnCompatibleLSTM and cudnnLSTM are not the same mathematically. I get different results for initialized cells. [initialized by some tf.constant() as initializer, no save/restore]. Seems that cudnnLSTM does depend on the random seed [dropout is zero], which means that there are some unique tensor/tensor initialization going on, separating it from cudnnCompatibleLSTM. Does anybody have a clue?",https://stackoverflow.com/questions/52046902,6281444,Documentation Replicability,Documentation Replicability,"Based on the [rather limited] documentation my aim is to train with cudnnLSTM cell, save a checkpoint, and then restore for inference on a CPU. Per that aim, I thought that cudnnCompatibleLSTM is the way to go as it is supposed to suck in the weights from the GPU-specific LSTM implementation. I get the following error, no matter what I try."
48174988,Tensorflow: how to create a local variable?,"<p>I'm trying to understand how local and global variables are different in tensorflow and what's the right way to initialize the variables.</p>

<p>According to the doc, <code>tf.local_variables_initializer</code>:</p>

<blockquote>
  <p>Returns an Op that initializes all local variables.</p>
  
  <p>This is just a shortcut for variables_initializer(local_variables())</p>
</blockquote>

<p>So the essential part is <code>tf.local_variables</code>. <a href=""https://www.tensorflow.org/api_docs/python/tf/local_variables"" rel=""nofollow noreferrer"">The doc</a>:</p>

<blockquote>
  <p>Local variables - per process variables, usually not saved/restored to checkpoint and used for temporary or intermediate values. For example, they can be used as counters for metrics computation or number of epochs this machine has read data.</p>
</blockquote>

<p>It sounds logical, however, no matter how I tried, I couldn't make any variable local. </p>

<pre><code>features = 2
hidden = 3

with tf.variable_scope('start'):
  x = tf.placeholder(tf.float32, shape=[None, features], name='x')
  y = tf.placeholder(tf.float32, shape=[None], name='y')

with tf.variable_scope('linear'):
  W = tf.get_variable(name='W', shape=[features, hidden])
  b = tf.get_variable(name='b', shape=[hidden], initializer=tf.zeros_initializer)
  z = tf.matmul(x, W) + b

with tf.variable_scope('optimizer'):
  predict = tf.reduce_sum(z, axis=1)
  loss = tf.reduce_mean(tf.square(y - predict))
  optimizer = tf.train.AdamOptimizer(0.1).minimize(loss)

print(tf.local_variables())
</code></pre>

<p>The output is always an empty list. <strong>How</strong> and <strong>should</strong> I create local variables?</p>
","I'm trying to understand how local and global variables are different in tensorflow and what's the right way to initialize the variables. According to the doc, tf.local_variables_initializer: So the essential part is tf.local_variables. The doc: It sounds logical, however, no matter how I tried, I couldn't make any variable local. The output is always an empty list. How and should I create local variables?",https://stackoverflow.com/questions/48174988,9127536,Requesting (Additional) Resources,Documentation Replicability,"The doc: It sounds logical, however, no matter how I tried, I couldn't make any variable local. The output is always an empty list."
37668485,Create an int list feature to save as tfrecord in tensorflow?,"<p>How can I create a tensorflow record from a list?</p>

<p>From the <a href=""https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/core/example/feature.proto#L9-10"" rel=""noreferrer"">documentation</a> here it seems possible. There's also this <a href=""https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/examples/how_tos/reading_data/convert_to_records.py#L64-69"" rel=""noreferrer"">example</a> where they convert a numpy array into a byte array using the <code>.tostring()</code> from numpy. However when I try to pass in:</p>

<pre><code>labels = np.asarray([[1,2,3],[4,5,6]])
...
example = tf.train.Example(features=tf.train.Features(feature={
    'height': _int64_feature(rows),
    'width': _int64_feature(cols),
    'depth': _int64_feature(depth),
    'label': _int64_feature(labels[index]),
    'image_raw': _bytes_feature(image_raw)}))
writer.write(example.SerializeToString())
</code></pre>

<p>I get the error:</p>

<pre><code>TypeError: array([1, 2, 3]) has type type 'numpy.ndarray', but expected one of: (type 'int', type 'long')
</code></pre>

<p>Which doesn't help me to figure out how to store a list of integers into the tfrecord. I've tried looking through the docs.  </p>
",How can I create a tensorflow record from a list? From the documentation here it seems possible. There's also this example where they convert a numpy array into a byte array using the .tostring() from numpy. However when I try to pass in: I get the error: Which doesn't help me to figure out how to store a list of integers into the tfrecord. I've tried looking through the docs.,https://stackoverflow.com/questions/37668485,6416660,Documentation Replicability,Documentation Replicability,How can I create a tensorflow record from a list? From the documentation here it seems possible. There's also this example where they convert a numpy array into a byte array using the .tostring() from numpy. However when I try to pass in: I get the error: Which doesn't help me to figure out how to store a list of integers into the tfrecord. I've tried looking through the docs.
67754649,Mean of Tensorflow Keras's Glorot Normal Initializer is not zero,"<p>As per the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal"" rel=""nofollow noreferrer"">Glorot Normal</a>, <strong><code>mean</code></strong> of the <strong><code>Normal Distribution</code></strong> of the <strong><code>Initial Weights</code></strong> should be <strong><code>zero</code></strong>.</p>
<blockquote>
<p>Draws samples from a truncated normal distribution centered on 0</p>
</blockquote>
<p>But it doesn't seem to be <strong><code>zero</code></strong>, am I missing something?</p>
<p>Please find the code below:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import numpy as np

print(tf.__version__)

initializer = tf.keras.initializers.GlorotNormal(seed = 1234)


model = Sequential([Dense(units = 3, input_shape = [1], kernel_initializer = initializer,
                         bias_initializer = initializer),
                   Dense(units = 1, kernel_initializer = initializer,
                         bias_initializer = initializer)])

batch_size = 1

x = np.array([-1.0, 0, 1, 2, 3, 4.0], dtype = 'float32')
y = np.array([-3, -1.0, 1, 3.0, 5.0, 7.0], dtype = 'float32')

x = np.reshape(x, (-1, 1))

# Prepare the training dataset.
train_dataset = tf.data.Dataset.from_tensor_slices((x, y))
train_dataset = train_dataset.shuffle(buffer_size=64).batch(batch_size)

epochs = 1
learning_rate=1e-3

# Instantiate an optimizer.
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)

for epoch in range(epochs):

    # Iterate over the batches of the dataset.
    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
        
        with tf.GradientTape() as tape:
            logits = model(x_batch_train, training=True)  # Logits for this minibatch

            # Compute the loss value for this minibatch.
            loss_value = tf.keras.losses.MSE(y_batch_train, logits)               
        
       
        Initial_Weights_1st_Hidden_Layer = model.trainable_weights[0]
       
        Mean_Weights_Hidden_Layer = tf.reduce_mean(Initial_Weights_1st_Hidden_Layer)
                          
        Initial_Weights_Output_Layer = model.trainable_weights[2]
        
        Mean_Weights_Output_Layer = tf.reduce_mean(Initial_Weights_Output_Layer)  
               
        Initial_Bias_1st_Hidden_Layer = model.trainable_weights[1]
        
        Mean_Bias_Hidden_Layer = tf.reduce_mean(Initial_Bias_1st_Hidden_Layer)      
        
        Initial_Bias_Output_Layer = model.trainable_weights[3]
        
        Mean_Bias_Output_Layer = tf.reduce_mean(Initial_Bias_Output_Layer)
        
        if epoch ==0 and step==0:
            
            print('\n Initial Weights of First-Hidden Layer = ', Initial_Weights_1st_Hidden_Layer)
            print('\n Mean of Weights of Hidden Layer = %s' %Mean_Weights_Hidden_Layer.numpy())
            
            print('\n Initial Weights of Second-Hidden/Output Layer = ', Initial_Weights_Output_Layer)
            print('\n Mean of Weights of Output Layer = %s' %Mean_Weights_Output_Layer.numpy())
                
            print('\n Initial Bias of First-Hidden Layer = ', Initial_Bias_1st_Hidden_Layer)
            print('\n Mean of Bias of Hidden Layer = %s' %Mean_Bias_Hidden_Layer.numpy())

            print('\n Initial Bias of Second-Hidden/Output Layer = ', Initial_Bias_Output_Layer)
            print('\n Mean of Bias of Output Layer = %s' %Mean_Bias_Output_Layer.numpy())
</code></pre>
","As per the documentation of Glorot Normal, mean of the Normal Distribution of the Initial Weights should be zero. But it doesn't seem to be zero, am I missing something? Please find the code below:",https://stackoverflow.com/questions/67754649,10016590,Documentation Replicability,Documentation Replicability,"As per the documentation of Glorot Normal, mean of the Normal Distribution of the Initial Weights should be zero. But it doesn't seem to be zero, am I missing something?"
50312519,"Dimensions must be equal, but are 1 and 2 for 'Conv2D' (op: 'Conv2D') with input shapes: [2,2,2,1], [1,1,2,1]","<p>I am trying to learn Conv2d by this code.</p>

<p>Based on conv2d doc:</p>

<p>shape of input = [batch, in_height, in_width, in_channels]</p>

<p>shape of filter = [filter_height, filter_width, in_channels, out_channels]</p>

<p>When I try to run it , it sends me the wrong message.</p>

<pre><code>#-*-coding:utf-8-*-

import tensorflow as tf

input_batch = tf.constant([
    [
        [[0.0], [1.0]],
        [[2.0], [3.0]]
    ],
    [
        [[2.0], [4.0]],
        [[6.0], [8.0]]
    ]
])

kernel = tf.constant([
    [
        [[1.0], [2.0]],
    ]
])

conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 1, 1, 1],padding='SAME')

with tf.Session() as sess:
    sess.run(conv2d)
</code></pre>

<p>The wrong message:</p>

<pre><code>ValueError: Dimensions must be equal, but are 1 and 2 for 'Conv2D' (op: 'Conv2D') with input shapes: [2,2,2,1], [1,1,2,1].
</code></pre>
","I am trying to learn Conv2d by this code. Based on conv2d doc: shape of input = [batch, in_height, in_width, in_channels] shape of filter = [filter_height, filter_width, in_channels, out_channels] When I try to run it , it sends me the wrong message. The wrong message:",https://stackoverflow.com/questions/50312519,8874295,Documentation Replicability,Documentation Replicability,"I am trying to learn Conv2d by this code. Based on conv2d doc: shape of input = [batch, in_height, in_width, in_channels] shape of filter = [filter_height, filter_width, in_channels, out_channels] When I try to run it , it sends me the wrong message."
62270283,Tensorflow - Custom loss function with sample_weight,"<p>I'm trying to run a custom function that accepts sample_weights. I'm following this documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss</a>. </p>

<p>However, when I try to use the following cost function:</p>

<pre><code>class deltaE(Loss):
  def __call__(self, y_true, y_pred, sample_weight):
    errors = tf_get_deltaE2000(y_true * tf_Xtrain_labels_max, y_pred * tf_Xtrain_labels_max)
    errors *= sample_weight
    return tf.math.reduce_mean(errors, axis=-1)

loss_deltaE = deltaE()
</code></pre>

<p>I get this error on the <code>Model.fit</code> method.</p>

<pre><code>TypeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:543 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:411 update_state
        metric_obj.update_state(y_t, y_p)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated
        update_op = update_state_fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:603 update_state
        matches = self._fn(y_true, y_pred, **self._fn_kwargs)

    TypeError: __call__() missing 1 required positional argument: 'sample_weight'
</code></pre>

<p>I'm using a generator that yields a tuple of length 3 just as required. I've checked that. That's working properly.</p>

<p>The cost function works fine too. When I use the code below, the model trains without problems.</p>

<pre><code>def loss_deltaE(y_true, y_pred):
  errors = tf_get_deltaE2000(y_true * tf_Xtrain_labels_max, y_pred * tf_Xtrain_labels_max)
  return tf.math.reduce_mean(errors, axis=-1)
</code></pre>

<p>If someone has any clue. I'd appreciate it. Thanks in advance!</p>
","I'm trying to run a custom function that accepts sample_weights. I'm following this documentation https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss. However, when I try to use the following cost function: I get this error on the Model.fit method. I'm using a generator that yields a tuple of length 3 just as required. I've checked that. That's working properly. The cost function works fine too. When I use the code below, the model trains without problems. If someone has any clue. I'd appreciate it. Thanks in advance!",https://stackoverflow.com/questions/62270283,6509883,Documentation Replicability,Documentation Replicability,"I'm trying to run a custom function that accepts sample_weights. I'm following this documentation https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss. However, when I try to use the following cost function: I get this error on the Model.fit method. I'm using a generator that yields a tuple of length 3 just as required."
66420994,How to use tfa.metrics.F1Score with image_dataset_from_directory correctly?,"<p>Colab code is <a href=""https://colab.research.google.com/drive/1XhVpnjhpvtDq3kjZJ4_vjeAhoYQh9XsR?usp=sharing"" rel=""nofollow noreferrer"">here</a>:</p>
<p>I am following the docs <a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/F1Score"" rel=""nofollow noreferrer"">here</a> to get the result for multiclass prediction</p>
<p>When I train using</p>
<pre><code>#last layer
tf.keras.layers.Dense(2, activation='softmax')

model.compile(optimizer=&quot;adam&quot;,
              loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=[tf.keras.metrics.CategoricalAccuracy(),
                       tfa.metrics.F1Score(num_classes=2, average='macro')])
</code></pre>
<p>I get</p>
<pre><code>144/144 [==] - 8s 54ms/step - loss: 0.0613 - categorical_accuracy: 0.9789 - f1_score: 0.9788 - val_loss: 0.0826 - val_categorical_accuracy: 0.9725 - val_f1_score: 0.9722
</code></pre>
<p>When I do:</p>
<pre><code>model.evaluate(val_ds)
</code></pre>
<p>I get</p>
<pre><code>16/16 [==] - 0s 15ms/step - loss: 0.0826 - categorical_accuracy: 0.9725 - f1_score: 0.9722
[0.08255868405103683, 0.9725490212440491, 0.9722140431404114]
</code></pre>
<p>I would like to use the <code>metric.result</code> as in the official website. When I load the below code, I get <code>0.4875028</code> which is wrong. How can I get the correct <code>predicted_categories</code> and <code>true_categories</code>?</p>
<pre><code>metric = tfa.metrics.F1Score(num_classes=2, average='macro')

predicted_categories = model.predict(val_ds)
true_categories = tf.concat([y for x, y in val_ds], axis=0).numpy() 

metric.update_state(true_categories, predicted_categories)
result = metric.result()
print(result.numpy())

#0.4875028
</code></pre>
<p>Here is how I loaded my data</p>
<pre><code>train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    main_folder,
    validation_split=0.1,
    subset=&quot;training&quot;,
    label_mode='categorical',
    seed=123,
    image_size=(dim, dim))

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    main_folder,
    validation_split=0.1,
    subset=&quot;validation&quot;,
    label_mode='categorical',
    seed=123,
    image_size=(dim, dim))
</code></pre>
","Colab code is here: I am following the docs here to get the result for multiclass prediction When I train using I get When I do: I get I would like to use the metric.result as in the official website. When I load the below code, I get 0.4875028 which is wrong. How can I get the correct predicted_categories and true_categories? Here is how I loaded my data",https://stackoverflow.com/questions/66420994,10868301,Documentation Replicability,Documentation Replicability," I would like to use the metric.result as in the official website. When I load the below code, I get 0.4875028 which is wrong. How can I get the correct predicted_categories and true_categories? "
45734487,tensorflow: Error multiplying a sparse matrix with a dense matrix using tf.matmul,"<p>In the following code, I want dense matrix <code>B</code> to left multiply a sparse matrix <code>A</code>, but I got errors.</p>

<pre><code>import tensorflow as tf
import numpy as np

A = tf.sparse_placeholder(tf.float32)
B = tf.placeholder(tf.float32, shape=(5,5))
C = tf.matmul(B,A,a_is_sparse=False,b_is_sparse=True)
sess = tf.InteractiveSession()
indices = np.array([[3, 2], [1, 2]], dtype=np.int64)
values = np.array([1.0, 2.0], dtype=np.float32)
shape = np.array([5,5], dtype=np.int64)
Sparse_A = tf.SparseTensorValue(indices, values, shape)
RandB = np.ones((5, 5))
print sess.run(C, feed_dict={A: Sparse_A, B: RandB})
</code></pre>

<p>The error message is as follows:</p>

<pre><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt; 
to Tensor. Contents: SparseTensor(indices=Tensor(""Placeholder_4:0"", shape=(?, ?), dtype=int64), values=Tensor(""Placeholder_3:0"", shape=(?,), dtype=float32), dense_shape=Tensor(""Placeholder_2:0"", shape=(?,), dtype=int64)). 
Consider casting elements to a supported type.
</code></pre>

<p>What's wrong with my code?</p>

<p>I'm doing this following the <a href=""https://www.tensorflow.org/api_docs/python/tf/matmul"" rel=""nofollow noreferrer"">documentation</a> and it says we should use <code>a_is_sparse</code> to denote whether the first matrix is sparse, and similarly with <code>b_is_sparse</code>. Why is my code wrong?</p>

<p>As is suggested by vijay, I should use <code>C = tf.matmul(B,tf.sparse_tensor_to_dense(A),a_is_sparse=False,b_is_sparse=True)</code></p>

<p>I tried this but I met with another error saying:</p>

<pre><code>Caused by op u'SparseToDense', defined at:
  File ""a.py"", line 19, in &lt;module&gt;
    C = tf.matmul(B,tf.sparse_tensor_to_dense(A),a_is_sparse=False,b_is_sparse=True)
  File ""/home/fengchao.pfc/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/sparse_ops.py"", line 845, in sparse_tensor_to_dense
    name=name)
  File ""/home/mypath/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/sparse_ops.py"", line 710, in sparse_to_dense
    name=name)
  File ""/home/mypath/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_sparse_ops.py"", line 1094, in _sparse_to_dense
    validate_indices=validate_indices, name=name)
  File ""/home/mypath/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/mypath/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/mypath/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): indices[1] = [1,2] is out of order
[[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_Placeholder_4_0_2, _arg_Placeholder_2_0_0, _arg_Placeholder_3_0_1, SparseToDense/default_value)]]
</code></pre>

<p>Thank you all for helping me!</p>
","In the following code, I want dense matrix B to left multiply a sparse matrix A, but I got errors. The error message is as follows: What's wrong with my code? I'm doing this following the documentation and it says we should use a_is_sparse to denote whether the first matrix is sparse, and similarly with b_is_sparse. Why is my code wrong? As is suggested by vijay, I should use C = tf.matmul(B,tf.sparse_tensor_to_dense(A),a_is_sparse=False,b_is_sparse=True) I tried this but I met with another error saying: Thank you all for helping me!",https://stackoverflow.com/questions/45734487,5005808,Documentation Replicability,Documentation Replicability," I'm doing this following the documentation and it says we should use a_is_sparse to denote whether the first matrix is sparse, and similarly with b_is_sparse. Why is my code wrong?"
57206247,How to fix ‘RuntimeError: The Session graph is empty. Add operations to the graph before calling run().”,"<p>I just simply typed the code given in <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/Tensor"" rel=""noreferrer"">tf.Tensor Tensorflow 2.0</a>, and here is my code:</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
print(tf.__version__)
# Build a dataflow graph.
c = tf.constant([[1.0, 2.0], [3.0, 4.0]])
d = tf.constant([[1.0, 1.0], [0.0, 1.0]])
e = tf.matmul(c, d)

# Construct a `Session` to execute the graph.
sess = tf.compat.v1.Session()

# Execute the graph and store the value that `e` represents in `result`.
result = sess.run(e)
</code></pre>

<p>But it raised an error:</p>

<pre><code>2.0.0-beta1
2019-07-25 17:06:35.972372: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File ""/Users/yupng/Documents/Dissertation/kmnist/kminst_v1.0.py"", line 14, in &lt;module&gt;
    result = sess.run(e)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1098, in _run
    raise RuntimeError('The Session graph is empty.  Add operations to the '
RuntimeError: The Session graph is empty.  Add operations to the graph before calling run().

Process finished with exit code 1
</code></pre>

<p>What could I do to fix this error?</p>
","I just simply typed the code given in tf.Tensor Tensorflow 2.0, and here is my code: But it raised an error: What could I do to fix this error?",https://stackoverflow.com/questions/57206247,11837392,Documentation Replicability,Documentation Replicability,"I just simply typed the code given in tf.Tensor Tensorflow 2.0, and here is my code: But it raised an error: What could I do to fix this error?"
67652872,InvalidArgumentError: Inner dimensions of output shape must match inner dimensions of updates shape,"<p>I'm trying to implement an SPL loss in keras. All I need to do is pretty simple, I'll write it in numpy to explain what I need:</p>
<pre class=""lang-py prettyprint-override""><code>def spl_loss(y_true, y_pred, lmda):
    # compute any arbitrary loss function
    L = categorical_cross_entropy(y_true, y_pred)
    # set to zero those values with an error greater than lambda
    L[L&gt;lmda] = 0
    return L
</code></pre>
<p>I'm trying to implement it <a href=""https://medium.com/@Bloomore/how-to-write-a-custom-loss-function-with-additional-arguments-in-keras-5f193929f7a0"" rel=""nofollow noreferrer"">following this tutorial</a> but I'm having troubles with the step needed to set values to zero.</p>
<p>Currently I have the following code:</p>
<pre class=""lang-py prettyprint-override""><code>def spl_loss(lmda, loss_fn):
    def loss(y_true, y_pred):
         # compute an arbitrary loss function, L
        loss_value = loss_fn(y_true, y_pred) # tensor of shape (64,)
        # get the mask of L greater than lmda
        mask = tf.greater( loss_value, tf.constant( float(lmda) ) )    # tensor of shape (64,)
        # compute indexes for the mask
        indexes = tf.reshape(tf.where(mask), [-1])  # tensor of shape (n,); where n&lt;=64
        # set to zero values on indexes
        spl_loss_value = tf.tensor_scatter_nd_update(loss_value, indexes, tf.zeros_like(loss_value, dtype=loss_value.dtype) )  # this line gives the error
        
        return spl_loss_value
    return loss
</code></pre>
<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update"" rel=""nofollow noreferrer"">docs</a>, <code>tensor_scatter_nd_update</code> operation should perform the assignment operation, but it fails with the following error:</p>
<pre><code>    spl_loss_value = tf.tensor_scatter_nd_update(loss_value, indexes, tf.zeros_like(loss_value, dtype=loss_value.dtype) )
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper  **
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5512 tensor_scatter_nd_update
        tensor=tensor, indices=indices, updates=updates, name=name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py:11236 tensor_scatter_update
        _ops.raise_from_not_ok_status(e, name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:6862 raise_from_not_ok_status
        six.raise_from(core._status_to_exception(e.code, message), None)
    &lt;string&gt;:3 raise_from
        

    InvalidArgumentError: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [64] updates: [64] [Op:TensorScatterUpdate]
</code></pre>
<p>I'm running it in colab, <a href=""https://colab.research.google.com/drive/1JT2ub3p1kAQpLp5ESqOhsvna4b8M-MNp?usp=sharing"" rel=""nofollow noreferrer"">here</a> you can try it.</p>
<p>I tried several re-shapes, because I understand it is a matter of shapes expected vs obtained, but I don't find the way. What's going on here?</p>
<p>Thanks in advance</p>
","I'm trying to implement an SPL loss in keras. All I need to do is pretty simple, I'll write it in numpy to explain what I need: I'm trying to implement it following this tutorial but I'm having troubles with the step needed to set values to zero. Currently I have the following code: According to the docs, tensor_scatter_nd_update operation should perform the assignment operation, but it fails with the following error: I'm running it in colab, here you can try it. I tried several re-shapes, because I understand it is a matter of shapes expected vs obtained, but I don't find the way. What's going on here? Thanks in advance",https://stackoverflow.com/questions/67652872,4913143,Documentation Replicability,Documentation Replicability,"According to the docs, tensor_scatter_nd_update operation should perform the assignment operation, but it fails with the following error."
39133312,Why does setting an initialization value prevent placing a variable on a GPU in TensorFlow?,"<p>I get an exception when I try to run the following very simple TensorFlow code, although I virtually copied it from the documentation:</p>

<pre><code>import tensorflow as tf

with tf.device(""/gpu:0""):
  x = tf.Variable(0, name=""x"")

sess = tf.Session()
sess.run(x.initializer) # Bombs!
</code></pre>

<p>The exception is:</p>

<pre><code>tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to
node 'x': Could not satisfy explicit device specification '/device:GPU:0' because
no supported kernel for GPU devices is available.
</code></pre>

<p>If I change the variable's initial value to <code>tf.zeros([1])</code> instead, everything works fine:</p>

<pre><code>import tensorflow as tf

with tf.device(""/gpu:0""):
  x = tf.Variable(tf.zeros([1]), name=""x"")

sess = tf.Session()     
sess.run(x.initializer)  # Works fine
</code></pre>

<p>Any idea what's going on?</p>
","I get an exception when I try to run the following very simple TensorFlow code, although I virtually copied it from the documentation: The exception is: If I change the variable's initial value to tf.zeros([1]) instead, everything works fine: Any idea what's going on?",https://stackoverflow.com/questions/39133312,38626,Documentation Replicability,Documentation Replicability,"I get an exception when I try to run the following very simple TensorFlow code, although I virtually copied it from the documentation: The exception is: If I change the variable's initial value to tf.zeros([1]) instead, everything works fine: Any idea what's going on?"
48072635,Why and when does the tensor's shape information unspecific?,"<p>I found piece of code like this:</p>

<pre><code>y = tf.strided_slice(data, [0, i * num_steps + 1],
                     [batch_size, (i + 1) * num_steps + 1])
y.set_shape([batch_size, num_steps])
</code></pre>

<p>as <a href=""https://stackoverflow.com/questions/35451948/clarification-on-tf-tensor-set-shape"">Clarification on tf.Tensor.set_shape()</a> said, set_shape can make the shape information more specific. But why data's shape information here is not specific? When does the tensor's information unspecific?</p>
","I found piece of code like this: as Clarification on tf.Tensor.set_shape() said, set_shape can make the shape information more specific. But why data's shape information here is not specific? When does the tensor's information unspecific?",https://stackoverflow.com/questions/48072635,3134227,Documentation Replicability,Documentation Replicability,"I found piece of code like this: as Clarification on tf.Tensor.set_shape() said, set_shape can make the shape information more specific. But why data's shape information here is not specific?"
53915078,"What are b, y, x and c which get flattened and returned along with the max-pooled features in tf.nn.max_pool_with_argmax?","<p>I went through the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/max_pool_with_argmax"" rel=""nofollow noreferrer"">tf.nn.max_pool_with_argmax</a> where it is written</p>

<blockquote>
  <p>Performs max pooling on the input and outputs both max values and indices.</p>
  
  <p>The indices in argmax are flattened, so that a maximum value at
  position [b, y, x, c] becomes flattened index ((b * height + y) *
  width + x) * channels + c.</p>
  
  <p>The indices returned are always in [0, height) x [0, width) before
  flattening, even if padding is involved and the mathematically correct
  answer is outside (either negative or too large). This is a bug, but
  fixing it is difficult to do in a safe backwards compatible way,
  especially due to flattening.</p>
</blockquote>

<p>The variables b, y, x and c haven't been explicitly defined hence I was having issues implementing this method. Can someone please provide the same.</p>
","I went through the documentation of tf.nn.max_pool_with_argmax where it is written The variables b, y, x and c haven't been explicitly defined hence I was having issues implementing this method. Can someone please provide the same.",https://stackoverflow.com/questions/53915078,7184172,Documentation Replicability,Documentation Replicability,"I went through the documentation of tf.nn.max_pool_with_argmax where it is written. The variables b, y, x and c haven't been explicitly defined hence I was having issues implementing this method."
54183967,Using tf.map_fn with multiple GPUs,"<p>I'm trying to extend my single-GPU TensorFlow code to multi-GPU. I have to work on 3 degrees of freedom and unfortunately I need to use tf.map_fn to parallelize over the 3rd one. I tried to use device placement as shown in the official documentation, but it looks like it is impossible to do it with <code>tf.map_fn</code>. Is there a way to run <code>tf.map_fn</code> on multiple GPUs?</p>

<p>Here the error output:</p>

<pre><code>InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'map_1/TensorArray_1': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/device:GPU:1'
Colocation Debug Info:
Colocation group had the following types and devices: 
TensorArrayGatherV3: GPU CPU 
Range: GPU CPU 
TensorArrayWriteV3: GPU CPU 
TensorArraySizeV3: GPU CPU 
MatMul: GPU CPU 
Enter: GPU CPU 
TensorArrayV3: GPU CPU 
Const: GPU CPU 

Colocation members and user-requested devices:
  map_1/TensorArrayStack/range/delta (Const) 
  map_1/TensorArrayStack/range/start (Const) 
  map_1/TensorArray_1 (TensorArrayV3) 
  map_1/while/TensorArrayWrite/TensorArrayWriteV3/Enter (Enter) /device:GPU:1
  map_1/TensorArrayStack/TensorArraySizeV3 (TensorArraySizeV3) 
  map_1/TensorArrayStack/range (Range) 
  map_1/TensorArrayStack/TensorArrayGatherV3 (TensorArrayGatherV3) 
  map_1/while/MatMul (MatMul) /device:GPU:1
  map_1/while/TensorArrayWrite/TensorArrayWriteV3 (TensorArrayWriteV3) /device:GPU:1

         [[Node: map_1/TensorArray_1 = TensorArrayV3[clear_after_read=true, dtype=DT_FLOAT, dynamic_size=false, element_shape=&lt;unknown&gt;, identical_element_shapes=true, tensor_array_name=""""](map_1/TensorArray_1/size)]]
</code></pre>

<p>Here a simple code example to reproduce it:</p>

<pre><code>import tensorflow as tf
import numpy

rc = 1000

sess = tf.Session()

for deviceName in ['/cpu:0', '/device:GPU:0', '/device:GPU:1']:
        with tf.device(deviceName):
                matrices = tf.random_uniform([rc,rc,4],minval = 0, maxval = 1, dtype = tf.float32)

                def mult(i):
                        product = tf.matmul(matrices[:,:,i],matrices[:,:,i+1])
                        return product

                mul = tf.zeros([rc,rc,3], dtype = tf.float32)
                mul = tf.map_fn(mult, numpy.array([0,1,2]), dtype = tf.float32, parallel_iterations = 10)

m = sess.run(mul)


</code></pre>
","I'm trying to extend my single-GPU TensorFlow code to multi-GPU. I have to work on 3 degrees of freedom and unfortunately I need to use tf.map_fn to parallelize over the 3rd one. I tried to use device placement as shown in the official documentation, but it looks like it is impossible to do it with tf.map_fn. Is there a way to run tf.map_fn on multiple GPUs? Here the error output: Here a simple code example to reproduce it:",https://stackoverflow.com/questions/54183967,6044435,Documentation Replicability,Documentation Replicability,"I tried to use device placement as shown in the official documentation, but it looks like it is impossible to do it with tf.map_fn."
36521908,How to Iteratively Create Tensorflow Graphs On The Fly Without Accumulating Memory?,"<p>What is the idiomatic way to construct a new neural network during each iteration of the training loop? It is an unusual thing to do, but I am working on an unusual project.</p>

<p>The tensorflow API documentation says ""A session may own resources, such as variables, queues, and readers. It is important to release these resources when they are no longer required. To do this, either invoke the close() method on the session, or use the session as a context manager."", so my first attempt involved declaring all my tensorflow variables within a session context manager, so that they can be freed at the next iteration of the training loop:</p>

<pre><code>with tf.device('/gpu:1'):
     while step * train_batchsize &lt; training_iters:
         with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=False)) as sess:
             X_placeholder = tf.placeholder(tf.float32, [None, 227 * 227 * 3])

             y_placeholder = tf.placeholder(tf.float32, [None, nclasses])
             # mkoptimize is my function which constructs the neural network.
             weights,biases,optimizer,accuracy,cost,conv1,conv2,dense1 = mkoptimize(X_placeholder,y_placeholder,table,npyweights,npybiases,nclasses)
             feed = {X_placeholder : X.reshape((train_batchsize,227 * 227 * 3)), y_placeholder : gt, keep_prob: dropout}
             sess.run(tf.initialize_all_variables())
             sess.run(optimizer, feed_dict=feed)
             npyweights = {k : sess.run(v).flatten() for k,v in weights.items()}
             npybiases = {k : sess.run(v).flatten() for k,v in biases.items()}
             # manually modify npyweights and npybiases according to some ensemble methods, and do some other things of interest.
             feed_acc = {X_placeholder: xs.reshape((test_batchsize,227 * 227 * 3)), y_placeholder: gt, keep_prob: 1.}
             sess.run(tf.initialize_all_variables())
             acc = sess.run(accuracy,feed_dict=feed_acc)
</code></pre>

<p>The first iteration of the training loop executes correctly, but on the second iteration the call to <code>tf.initialize_all_variables()</code> leads to a memory error ""ValueError: GraphDef cannot be larger than 2GB."" Does exiting the session context not in fact free memory in the graph? Each iteration of the loop involves the same amount of data and the same number of parameters in the neural network, so I don't think it's my construction that leads to the memory error.</p>

<p>The documentation is not very detailed on what exactly <code>tf.reset_default_graph</code> does, but I've tried freeing memory by calling  at the end of the session, leading to the error:</p>

<pre><code>File ""/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 706, in __exit__
   context_manager.__exit__(exec_type, exec_value, exec_tb)
   File ""/usr/local/anaconda3/lib/python3.5/contextlib.py"", line 77, in __exit__
    self.gen.throw(type, value, traceback)
   File ""/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2978, in get_controller
    assert self.stack[-1] is default
IndexError: list index out of range
</code></pre>

<p>How can I iteratively create tensorflow graphs without accumulating memory?</p>
","What is the idiomatic way to construct a new neural network during each iteration of the training loop? It is an unusual thing to do, but I am working on an unusual project. The tensorflow API documentation says ""A session may own resources, such as variables, queues, and readers. It is important to release these resources when they are no longer required. To do this, either invoke the close() method on the session, or use the session as a context manager."", so my first attempt involved declaring all my tensorflow variables within a session context manager, so that they can be freed at the next iteration of the training loop: The first iteration of the training loop executes correctly, but on the second iteration the call to tf.initialize_all_variables() leads to a memory error ""ValueError: GraphDef cannot be larger than 2GB."" Does exiting the session context not in fact free memory in the graph? Each iteration of the loop involves the same amount of data and the same number of parameters in the neural network, so I don't think it's my construction that leads to the memory error. The documentation is not very detailed on what exactly tf.reset_default_graph does, but I've tried freeing memory by calling at the end of the session, leading to the error: How can I iteratively create tensorflow graphs without accumulating memory?",https://stackoverflow.com/questions/36521908,1483516,Documentation Completeness,Documentation Completeness,"The documentation is not very detailed on what exactly tf.reset_default_graph does, but I've tried freeing memory by calling at the end of the session, leading to the error."
48514123,"Tensorflow: SavedModelBuilder, How to save model with best validation accuracy","<p>I have gone through tensorflow documentation but couldn't find the way of saving model with best validation accuracy, using SavedModelBuilder class. 
I am using tflearn for model building and below is the work around i have tried but it is taking lot of time, where i am running fit method for each epoch separately and saving model</p>

<pre><code>for i in range(epoch):
    model.fit(trainX, trainY, n_epoch=1, validation_set=(testX, testY), show_metric=True, batch_size=8)
    builder = tf.saved_model.builder.SavedModelBuilder('/tmp/serving/model/' + str(i))
    builder.add_meta_graph_and_variables(model.session,
                                     ['TRAINING'],
                                     signature_def_map={
                                         'predict': prediction_sig
                                     })
    builder.save()
</code></pre>

<p>Please suggest if there is a better approach.</p>
","I have gone through tensorflow documentation but couldn't find the way of saving model with best validation accuracy, using SavedModelBuilder class. I am using tflearn for model building and below is the work around i have tried but it is taking lot of time, where i am running fit method for each epoch separately and saving model Please suggest if there is a better approach.",https://stackoverflow.com/questions/48514123,2398191,Documentation Completeness,Documentation Completeness,"I have gone through tensorflow documentation but couldn't find the way of saving model with best validation accuracy, using SavedModelBuilder class."
50220191,How to import(restore) Neural network model built by tflearn from files,"<p>I am referring to <a href=""https://sourcedexter.com/tensorflow-text-classification-python/"" rel=""nofollow noreferrer"">this tutorial</a> on text classification and built a custom training set for a text classification.</p>

<p>I am saving the model with below code.</p>

<pre><code># Define model and setup tensorboard
model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')
# Start training (apply gradient descent algorithm)
model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)
model.save('model.tflearn')
</code></pre>

<p>This generates below files.</p>

<pre><code>model.tflearn.data-00000-of-00001
model.tflearn.index
model.tflearn.meta
tflearn_logs folder
</code></pre>

<p>I want to use the model built in different iteration for testing purpose.</p>

<p>I tried ,</p>

<pre><code>with tf.Session() as sess:
    saver = tf.train.import_meta_graph('model.tflearn.meta')
    saver.restore(sess, tf.train.latest_checkpoint('./'))
</code></pre>

<p><em>but I get;</em></p>

<blockquote>
  <p><strong>KeyError: ""The name 'adam' refers to an Operation not in the graph.""</strong> error</p>
</blockquote>

<p>I know <a href=""http://tflearn.org/getting_started/#weights-persistence"" rel=""nofollow noreferrer"">from documentation</a> that <code>tflearn.DNN(network).load('file_name')</code> loads a model , but we need to create and pass the network instance, to build a network we again go through same code from scratch which takes time since it will do training which I want to avoid.</p>

<p>Code for building network</p>

<pre><code>net = tflearn.input_data(shape=[None, len(train_x[0])])
net = tflearn.fully_connected(net, 8)
net = tflearn.fully_connected(net, 8)
net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')
net = tflearn.regression(net)
</code></pre>

<p><code>tflearn.input_data</code> has shape input as mandatory , so we would again need training data to be fed again.So it causes rebuilding model.
I checked the documentation , could not find what I need (2-3 lines of code which would import build neural network model to save retraining time.</p>

<p>Please let me know if you guys know solution for this.</p>

<p><a href=""https://stackoverflow.com/questions/45595646/in-tensorflow-how-to-freeze-saved-model/46637498?noredirect=1#comment87414509_46637498"">Similar question</a> but its not duplicate </p>

<ul>
<li>OP was facing issue while building neural net during building tree , while I am facing issue importing build model.  </li>
<li>Tutorial mentioned in the answer does not have tflearn NN model import </li>
</ul>
","I am referring to this tutorial on text classification and built a custom training set for a text classification. I am saving the model with below code. This generates below files. I want to use the model built in different iteration for testing purpose. I tried , but I get; I know from documentation that tflearn.DNN(network).load('file_name') loads a model , but we need to create and pass the network instance, to build a network we again go through same code from scratch which takes time since it will do training which I want to avoid. Code for building network tflearn.input_data has shape input as mandatory , so we would again need training data to be fed again.So it causes rebuilding model. I checked the documentation , could not find what I need (2-3 lines of code which would import build neural network model to save retraining time. Please let me know if you guys know solution for this. Similar question but its not duplicate",https://stackoverflow.com/questions/50220191,7907591,Documentation Completeness,Documentation Completeness,"I checked the documentation , could not find what I need (2-3 lines of code which would import build neural network model to save retraining time)."
33720645,Why is this TensorFlow implementation vastly less successful than Matlab's NN?,"<p>As a toy example I'm trying to fit a function <code>f(x) = 1/x</code> from 100 no-noise data points. The matlab default implementation is phenomenally successful with mean square difference ~10^-10, and interpolates perfectly.</p>

<p>I implement a neural network with one hidden layer of 10 sigmoid neurons. I'm a beginner at neural networks so be on your guard against dumb code.</p>

<pre><code>import tensorflow as tf
import numpy as np

def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)

#Can't make tensorflow consume ordinary lists unless they're parsed to ndarray
def toNd(lst):
    lgt = len(lst)
    x = np.zeros((1, lgt), dtype='float32')
    for i in range(0, lgt):
        x[0,i] = lst[i]
    return x

xBasic = np.linspace(0.2, 0.8, 101)
xTrain = toNd(xBasic)
yTrain = toNd(map(lambda x: 1/x, xBasic))

x = tf.placeholder(""float"", [1,None])
hiddenDim = 10

b = bias_variable([hiddenDim,1])
W = weight_variable([hiddenDim, 1])

b2 = bias_variable([1])
W2 = weight_variable([1, hiddenDim])

hidden = tf.nn.sigmoid(tf.matmul(W, x) + b)
y = tf.matmul(W2, hidden) + b2

# Minimize the squared errors.
loss = tf.reduce_mean(tf.square(y - yTrain))
optimizer = tf.train.GradientDescentOptimizer(0.5)
train = optimizer.minimize(loss)

# For initializing the variables.
init = tf.initialize_all_variables()

# Launch the graph
sess = tf.Session()
sess.run(init)

for step in xrange(0, 4001):
    train.run({x: xTrain}, sess)
    if step % 500 == 0:
        print loss.eval({x: xTrain}, sess)
</code></pre>

<p>Mean square difference ends at ~2*10^-3, so about 7 orders of magnitude worse than matlab. Visualising with</p>

<pre><code>xTest = np.linspace(0.2, 0.8, 1001)
yTest = y.eval({x:toNd(xTest)}, sess)  
import matplotlib.pyplot as plt
plt.plot(xTest,yTest.transpose().tolist())
plt.plot(xTest,map(lambda x: 1/x, xTest))
plt.show()
</code></pre>

<p>we can see the fit is systematically imperfect:
<a href=""https://i.stack.imgur.com/Blxq9.png""><img src=""https://i.stack.imgur.com/Blxq9.png"" alt=""enter image description here""></a>
while the matlab one looks perfect to the naked eye with the differences uniformly &lt; 10^-5:
<a href=""https://i.stack.imgur.com/kC8aJ.jpg""><img src=""https://i.stack.imgur.com/kC8aJ.jpg"" alt=""enter image description here""></a>
I have tried to replicate with TensorFlow the diagram of the Matlab network:</p>

<p><a href=""https://i.stack.imgur.com/ORLXL.png""><img src=""https://i.stack.imgur.com/ORLXL.png"" alt=""enter image description here""></a></p>

<p>Incidentally, the diagram seems to imply a tanh rather than sigmoid activation function. I cannot find it anywhere in documentation to be sure. However, when I try to use a tanh neuron in TensorFlow the fitting quickly fails with <code>nan</code> for variables. I do not know why.</p>

<p>Matlab uses Levenberg–Marquardt training algorithm. Bayesian regularization is even more successful with mean squares at 10^-12 (we are probably in the area of vapours of float arithmetic).</p>

<p>Why is TensorFlow implementation so much worse, and what can I do to make it better?</p>
","As a toy example I'm trying to fit a function f(x) = 1/x from 100 no-noise data points. The matlab default implementation is phenomenally successful with mean square difference ~10^-10, and interpolates perfectly. I implement a neural network with one hidden layer of 10 sigmoid neurons. I'm a beginner at neural networks so be on your guard against dumb code. Mean square difference ends at ~2*10^-3, so about 7 orders of magnitude worse than matlab. Visualising with we can see the fit is systematically imperfect: while the matlab one looks perfect to the naked eye with the differences uniformly &lt; 10^-5: I have tried to replicate with TensorFlow the diagram of the Matlab network: Incidentally, the diagram seems to imply a tanh rather than sigmoid activation function. I cannot find it anywhere in documentation to be sure. However, when I try to use a tanh neuron in TensorFlow the fitting quickly fails with nan for variables. I do not know why. Matlab uses Levenberg–Marquardt training algorithm. Bayesian regularization is even more successful with mean squares at 10^-12 (we are probably in the area of vapours of float arithmetic). Why is TensorFlow implementation so much worse, and what can I do to make it better?",https://stackoverflow.com/questions/33720645,1715157,Lack of Alternative Solutions/Documentation,Documentation Completeness,I cannot find it anywhere in documentation to be sure.
41361766,tensorflow cifar10 tutorial fails,"<p>I have downloaded the CIFAR10 code from the link in the tutorial <a href=""https://www.tensorflow.org/tutorials/deep_cnn/"" rel=""nofollow noreferrer"">here</a> and am trying to run the tutorial. I run it with the command</p>

<pre><code>python cifar10_train.py
</code></pre>

<p>It starts ok and downloads the data file as expected. When it tries to open the input file it fails with the following trace:</p>

<pre><code>Traceback (most recent call last):
  File ""cifar10_train.py"", line 120, in &lt;module&gt;
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""cifar10_train.py"", line 116, in main
    train()
  File ""cifar10_train.py"", line 63, in train
    images, labels = cifar10.distorted_inputs()
  File ""/notebooks/Python Scripts/tensorflowModels/tutorials/image/cifar10/cifar10.py"", line 157, in distorted_inputs
    batch_size=FLAGS.batch_size)
  File ""/notebooks/Python Scripts/tensorflowModels/tutorials/image/cifar10/cifar10_input.py"", line 161, in distorted_inputs
    read_input = read_cifar10(filename_queue)
  File ""/notebooks/Python Scripts/tensorflowModels/tutorials/image/cifar10/cifar10_input.py"", line 87, in read_cifar10
    tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)
TypeError: strided_slice() takes at least 4 arguments (3 given)
</code></pre>

<p>Sure enough, when I investigate the code there is a call in cifar10_input.py to strided_slice() with only 3 arguments:</p>

<pre><code>tf.strided_slice(record_bytes, [0], [label_bytes])
</code></pre>

<p>Whereas the tensorflow documentation does indeed state that there must be at least 4 arguments.</p>

<p>What is going wrong? I have downloaded the latest tensorflow (0.12) and I'm running the master branch of the cifar code.</p>
","I have downloaded the CIFAR10 code from the link in the tutorial here and am trying to run the tutorial. I run it with the command It starts ok and downloads the data file as expected. When it tries to open the input file it fails with the following trace: Sure enough, when I investigate the code there is a call in cifar10_input.py to strided_slice() with only 3 arguments: Whereas the tensorflow documentation does indeed state that there must be at least 4 arguments. What is going wrong? I have downloaded the latest tensorflow (0.12) and I'm running the master branch of the cifar code.",https://stackoverflow.com/questions/41361766,2467383,Documentation Replicability,Documentation Completeness,Whereas the tensorflow documentation does indeed state that there must be at least 4 arguments.
41515716,Tensorflow tf.contrib.learn.DNNClassifer estimation accuracy does not align to DNNClassifier prediction accuracy,"<p>In general, what alignment should we expect between the accuracy achieved during estimation, and the accuracy achieved during prediction? Simply put, if we achieved an 85% accuracy during estimation, should we expect a similar result during prediction? There are a few other posts discussion prediction accuracy issues, but none appear to ask this question directly.</p>

<p>To be more specific, I am using a DNNClassifier to learn against 1000 rows of feature data, each with 53 characteristics (i.e. columns). This is then tested against 100 samples. The model is configured to classify against two labels: 0 and 1, and achieves the prediction accuracy below.</p>

<p>INFO:tensorflow:Saving evaluation summary for step 45300:
accuracy: 0.846154
accuracy/baseline_label_mean: 0.197802
accuracy/threshold_0.500000_mean: 0.846154
auc: 0.743912
global_step: 45300
labels/actual_label_mean: 0.197802
labels/prediction_mean: 0.283492
loss: 0.398202
precision/positive_threshold_0.500000_mean: 1.0
recall/positive_threshold_0.500000_mean: 0.222222</p>

<p>However, when 15 examples are then used during the prediction step, and where 50% should be classified with a label of 1, they are generally all returned as 0s. Occasionally, a single example will be correctly classified as a 1.</p>

<p>For example:
Predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</p>

<p>My DNNClassifier is configured as follows:</p>

<pre><code>m = tf.contrib.learn.DNNClassifier(model_dir=model_dir,
                                       feature_columns=deep_columns,
                                       hidden_units=[32, 16],
                                       activation_fn=tf.nn.relu,
                                       n_classes=2,
                                       optimizer=tf.train.AdagradOptimizer(
                                       learning_rate=0.1))
</code></pre>

<p>and the predict function is called as below:</p>

<pre><code>y = m.predict(input_fn = lambda: input_fn(df_predict))
    predictions = list(itertools.islice(y, 15))
    print(""Predictions: {}"".format(str(predictions)))
    for i in predictions:
        print(i)
</code></pre>

<p>I have two questions.
(1) Am I correct to assume that there should be a direct correlation between estimation and prediction accuracy, and therefore that an 85% estimation accuracy should result in a similar prediction accuracy?</p>

<p>(2) Do the other results provided when training completes (i.e. ""labels/prediction_mean: 0.283492"") provide information that is relevant to the low level of prediction accuracy being achieved? I have not been able to find a definition of these result labels in the TensorFlow documentation, and my apologies if I have missed something.</p>

<p>Many thanks for any thoughts on this.</p>
","In general, what alignment should we expect between the accuracy achieved during estimation, and the accuracy achieved during prediction? Simply put, if we achieved an 85% accuracy during estimation, should we expect a similar result during prediction? There are a few other posts discussion prediction accuracy issues, but none appear to ask this question directly. To be more specific, I am using a DNNClassifier to learn against 1000 rows of feature data, each with 53 characteristics (i.e. columns). This is then tested against 100 samples. The model is configured to classify against two labels: 0 and 1, and achieves the prediction accuracy below. INFO:tensorflow:Saving evaluation summary for step 45300: accuracy: 0.846154 accuracy/baseline_label_mean: 0.197802 accuracy/threshold_0.500000_mean: 0.846154 auc: 0.743912 global_step: 45300 labels/actual_label_mean: 0.197802 labels/prediction_mean: 0.283492 loss: 0.398202 precision/positive_threshold_0.500000_mean: 1.0 recall/positive_threshold_0.500000_mean: 0.222222 However, when 15 examples are then used during the prediction step, and where 50% should be classified with a label of 1, they are generally all returned as 0s. Occasionally, a single example will be correctly classified as a 1. For example: Predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] My DNNClassifier is configured as follows: and the predict function is called as below: I have two questions. (1) Am I correct to assume that there should be a direct correlation between estimation and prediction accuracy, and therefore that an 85% estimation accuracy should result in a similar prediction accuracy? (2) Do the other results provided when training completes (i.e. ""labels/prediction_mean: 0.283492"") provide information that is relevant to the low level of prediction accuracy being achieved? I have not been able to find a definition of these result labels in the TensorFlow documentation, and my apologies if I have missed something. Many thanks for any thoughts on this.",https://stackoverflow.com/questions/41515716,7382474,Documentation Completeness,Documentation Completeness,"I have not been able to find a definition of these result labels in the TensorFlow documentation, and my apologies if I have missed something."
41796965,Tensorflow: How to use a trained model in a application?,"<p>I have trained a Tensorflow Model, and now I want to export the ""function"" to use it in my python program. Is that possible, and if yes, how? Any help would be nice, could not find much in the documentation. (I dont want to save a session!)</p>

<p>I have now stored the session as you suggested. I am loading it now like this:</p>

<pre><code>f = open('batches/batch_9.pkl', 'rb')
input = pickle.load(f)
f.close()
sess = tf.Session()

saver = tf.train.Saver()
saver.restore(sess, 'trained_network.ckpt')
y_pred = []

sess.run(y_pred, feed_dict={x: input})

print(y_pred)
</code></pre>

<p>However, I get the error ""no Variables to save"" when I try to initialize the saver. </p>

<p>What I want to do is this: I am writing a bot for a board game, and the input is the situation on the board formatted into a tensor. Now I want to return a tensor which gives me the best position to play next, i.e. a tensor with 0 everywhere and a 1 at one position.</p>
","I have trained a Tensorflow Model, and now I want to export the ""function"" to use it in my python program. Is that possible, and if yes, how? Any help would be nice, could not find much in the documentation. (I dont want to save a session!) I have now stored the session as you suggested. I am loading it now like this: However, I get the error ""no Variables to save"" when I try to initialize the saver. What I want to do is this: I am writing a bot for a board game, and the input is the situation on the board formatted into a tensor. Now I want to return a tensor which gives me the best position to play next, i.e. a tensor with 0 everywhere and a 1 at one position.",https://stackoverflow.com/questions/41796965,6480160,Lack of Alternative Solutions/Documentation,Documentation Completeness,"Any help would be nice, could not find much in the documentation."
42164772,Tensorflow Estimator API: Summaries,"<p>I can't achieve to make summaries work with the Estimator API of Tensorflow.</p>

<p>The Estimator class is very useful for many reasons: I have already implemented my own classes which are really similar but I am trying to switch to this one.</p>

<p>Here is the code sample:</p>

<pre><code>import tensorflow as tf
import tensorflow.contrib.layers as layers
import tensorflow.contrib.learn as learn
import numpy as np

 # To reproduce the error: docker run --rm -w /algo -v $(pwd):/algo tensorflow/tensorflow bash -c ""python sample.py""

def model_fn(x, y, mode):
    logits = layers.fully_connected(x, 12, scope=""dense-1"")
    logits = layers.fully_connected(logits, 56, scope=""dense-2"")
    logits = layers.fully_connected(logits, 4, scope=""dense-3"")

    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y), name=""xentropy"")

    return {""predictions"":logits}, loss, tf.train.AdamOptimizer(0.001).minimize(loss)


def input_fun():
    """""" To be completed for a 4 classes classification problem """"""

    feature = tf.constant(np.random.rand(100,10))
    labels = tf.constant(np.random.random_integers(0,3, size=(100,)))

    return feature, labels

estimator = learn.Estimator(model_fn=model_fn, )

trainingConfig = tf.contrib.learn.RunConfig(save_checkpoints_secs=60)

estimator = learn.Estimator(model_fn=model_fn, model_dir=""./tmp"", config=trainingConfig)

# Works
estimator.fit(input_fn=input_fun, steps=2)

# The following code does not work

# Can't initialize saver

# saver = tf.train.Saver(max_to_keep=10) # Error: No variables to save

# The following fails because I am missing a saver... :(

hooks=[
        tf.train.LoggingTensorHook([""xentropy""], every_n_iter=100),
        tf.train.CheckpointSaverHook(""./tmp"", save_steps=1000, checkpoint_basename='model.ckpt'),
        tf.train.StepCounterHook(every_n_steps=100, output_dir=""./tmp""),
        tf.train.SummarySaverHook(save_steps=100, output_dir=""./tmp""),
]

estimator.fit(input_fn=input_fun, steps=2, monitors=hooks)
</code></pre>

<p>As you can see, I can create an Estimator and use it but I can achieve to add hooks to the fitting process.</p>

<p>The logging hooks works just fine but the others require both <strong>tensors</strong> and a <strong>saver</strong> which I can't provide.</p>

<p>The tensors are defined in the model function, thus I can't pass them to the <strong>SummaryHook</strong> and the <strong>Saver</strong> can't be initialized because there is no tensor to save...</p>

<p>Is there a solution to my problem? (I am guessing yes but there is a lack of documentation of this part in the tensorflow documentation)</p>

<ul>
<li>How can I initialized my <strong>saver</strong>? Or should I use other objects such as <em>Scaffold</em>?</li>
<li>How can I pass <strong>summaries</strong> to the <strong>SummaryHook</strong> since they are defined in my model function?</li>
</ul>

<p>Thanks in advance.</p>

<p><em>PS: I have seen the DNNClassifier API but I want to use the estimator API for Convolutional Nets and others. I need to create summaries for any estimator.</em></p>
","I can't achieve to make summaries work with the Estimator API of Tensorflow. The Estimator class is very useful for many reasons: I have already implemented my own classes which are really similar but I am trying to switch to this one. Here is the code sample: As you can see, I can create an Estimator and use it but I can achieve to add hooks to the fitting process. The logging hooks works just fine but the others require both tensors and a saver which I can't provide. The tensors are defined in the model function, thus I can't pass them to the SummaryHook and the Saver can't be initialized because there is no tensor to save... Is there a solution to my problem? (I am guessing yes but there is a lack of documentation of this part in the tensorflow documentation) Thanks in advance. PS: I have seen the DNNClassifier API but I want to use the estimator API for Convolutional Nets and others. I need to create summaries for any estimator.",https://stackoverflow.com/questions/42164772,5184894,Lack of Alternative Solutions/Documentation,Documentation Completeness,Is there a solution to my problem? (I am guessing yes but there is a lack of documentation of this part in the tensorflow documentation) 
43634968,Parallelizing a tensorflow operation across multiple GPU's,"<p>In below code of a single hidden layer neural network I'm attempting to parallelize the gradient descent operation across two GPU's. I'm just attempting to thinking about this conceptually at the moment. There does not appear to be very much literature on how to perform this. Reading <a href=""https://stackoverflow.com/questions/41029037/training-multi-gpu-on-tensorflow-a-simpler-way"">Training Multi-GPU on Tensorflow: a simpler way?</a> does not provide a concrete answer. In below code I've added two functions <code>runOnGPU1()</code> &amp; <code>runOnGPU1()</code> which is a conceptual idea of how to split the training of the network across two GPU's. Can these two loops be split in order to share the computation across multiple GPU's ?</p>

<pre><code>import numpy as np
import tensorflow as tf

sess = tf.InteractiveSession()

# a batch of inputs of 2 value each
inputs = tf.placeholder(tf.float32, shape=[None, 2])

# a batch of output of 1 value each
desired_outputs = tf.placeholder(tf.float32, shape=[None, 1])

# [!] define the number of hidden units in the first layer
HIDDEN_UNITS = 4 

# connect 2 inputs to 3 hidden units
# [!] Initialize weights with random numbers, to make the network learn
weights_1 = tf.Variable(tf.truncated_normal([2, HIDDEN_UNITS]))

# [!] The biases are single values per hidden unit
biases_1 = tf.Variable(tf.zeros([HIDDEN_UNITS]))

# connect 2 inputs to every hidden unit. Add bias
layer_1_outputs = tf.nn.sigmoid(tf.matmul(inputs, weights_1) + biases_1)

# [!] The XOR problem is that the function is not linearly separable
# [!] A MLP (Multi layer perceptron) can learn to separe non linearly separable points ( you can
# think that it will learn hypercurves, not only hyperplanes)
# [!] Lets' add a new layer and change the layer 2 to output more than 1 value

# connect first hidden units to 2 hidden units in the second hidden layer
weights_2 = tf.Variable(tf.truncated_normal([HIDDEN_UNITS, 2]))
# [!] The same of above
biases_2 = tf.Variable(tf.zeros([2]))

# connect the hidden units to the second hidden layer
layer_2_outputs = tf.nn.sigmoid(
    tf.matmul(layer_1_outputs, weights_2) + biases_2)

# [!] create the new layer
weights_3 = tf.Variable(tf.truncated_normal([2, 1]))
biases_3 = tf.Variable(tf.zeros([1]))

logits = tf.nn.sigmoid(tf.matmul(layer_2_outputs, weights_3) + biases_3)

# [!] The error function chosen is good for a multiclass classification taks, not for a XOR.
error_function = 0.5 * tf.reduce_sum(tf.subtract(logits, desired_outputs) * tf.subtract(logits, desired_outputs))

train_step = tf.train.GradientDescentOptimizer(0.05).minimize(error_function)

sess.run(tf.global_variables_initializer())

training_inputs = [[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]]

training_outputs = [[0.0], [1.0], [1.0], [0.0]]

def runOnGPU1() : 
    for i in range(5):
        _, loss = sess.run([train_step, error_function],
                           feed_dict={inputs: np.array(training_inputs),
                                      desired_outputs: np.array(training_outputs)})
        print(loss)

def runOnGPU2() : 
    for i in range(5):
        _, loss = sess.run([train_step, error_function],
                           feed_dict={inputs: np.array(training_inputs),
                                      desired_outputs: np.array(training_outputs)})
        print(loss)

runOnGPU1()
runOnGPU2()
</code></pre>
",In below code of a single hidden layer neural network I'm attempting to parallelize the gradient descent operation across two GPU's. I'm just attempting to thinking about this conceptually at the moment. There does not appear to be very much literature on how to perform this. Reading Training Multi-GPU on Tensorflow: a simpler way? does not provide a concrete answer. In below code I've added two functions runOnGPU1() &amp; runOnGPU1() which is a conceptual idea of how to split the training of the network across two GPU's. Can these two loops be split in order to share the computation across multiple GPU's ?,https://stackoverflow.com/questions/43634968,470184,Documentation Completeness,Documentation Completeness,There does not appear to be very much literature on how to perform this. Reading Training Multi-GPU on Tensorflow: a simpler way? does not provide a concrete answer.
43649591,Serving Keras Models With Tensorflow Serving,"<p>Right now we are successfully able to serve models using Tensorflow Serving. We have used following method to export the model and host it with Tensorflow Serving. </p>

<pre><code>     ------------
      For exporting 
     ------------------
     from tensorflow.contrib.session_bundle import exporter

     K.set_learning_phase(0)
     export_path = ... # where to save the exported graph
     export_version = ... # version number (integer)

     saver = tf.train.Saver(sharded=True)
     model_exporter = exporter.Exporter(saver)
     signature = exporter.classification_signature(input_tensor=model.input,
                                          scores_tensor=model.output)
     model_exporter.init(sess.graph.as_graph_def(),
                default_graph_signature=signature)
     model_exporter.export(export_path, tf.constant(export_version), sess)

      --------------------------------------

      For hosting
      -----------------------------------------------

      bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=default --model_base_path=/serving/models
</code></pre>

<p>However our issue is - we want keras to be integrated with Tensorflow serving. We would like to serve the model through Tensorflow serving using Keras.
The reason we would like to have that is because - in our architecture we follow couple of different ways to train our model like deeplearning4j + Keras , 
Tensorflow + Keras, but for serving we would like to use only one servable engine that's Tensorflow Serving. We don't see any straight forward way to achieve that. Any comments ?</p>

<p>Thank you. </p>
","Right now we are successfully able to serve models using Tensorflow Serving. We have used following method to export the model and host it with Tensorflow Serving. However our issue is - we want keras to be integrated with Tensorflow serving. We would like to serve the model through Tensorflow serving using Keras. The reason we would like to have that is because - in our architecture we follow couple of different ways to train our model like deeplearning4j + Keras , Tensorflow + Keras, but for serving we would like to use only one servable engine that's Tensorflow Serving. We don't see any straight forward way to achieve that. Any comments ? Thank you.",https://stackoverflow.com/questions/43649591,7780215,Requesting (Additional) Resources,Documentation Completeness,We don't see any straight forward way to achieve that.
43662094,im2txt: Load input images from memory (instead of read from disk),"<p>I'm interested in modifying <a href=""https://github.com/tensorflow/models/tree/master/im2txt"" rel=""nofollow noreferrer"">the tensorflow implementation of Show and Tell</a>, in particular <a href=""https://github.com/tensorflow/models/tree/f653bd2340b15ce2a22669ba136b77b2751e462e/im2txt"" rel=""nofollow noreferrer"">this v0.12 snapshot</a>, in order to accept an image in numpy form instead of read it from disk.</p>

<p>Loading a filename using the upstream code results in a python string after </p>

<pre><code>with tf.gfile.GFile(filename, ""r"") as f:
    image = f.read()
</code></pre>

<p>in <code>run_inference.py</code> which is then turned into an ndarray of no shape. However, I can't replicate that.</p>

<p>I've tried the following:</p>

<h1>Loading the numpy array directly</h1>

<p>I wrote this function to load a pillow image from a filename, convert the image to a numpy array and feed it to the <code>beam_search</code> function in <code>run_inference.py</code></p>

<pre><code>def load_image(filename):
    from keras.preprocessing.image import img_to_array
    arr = img_to_array(PILImage.open(filename))
    return arr
...
captions = generator.beam_search(sess, image)
</code></pre>

<p>In this case, there is a size mismatch later, resulting in the following stack trace:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/run_inference.py"", line 107, in &lt;module&gt;
    tf.app.run()
  File ""/home/pmelissi/miniconda2/envs/im2txt/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/run_inference.py"", line 97, in main
    captions = generator.beam_search(sess, image)
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/inference_utils/caption_generator.py"", line 142, in beam_search
    initial_state = self.model.feed_image(sess, encoded_image)
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/inference_wrapper.py"", line 41, in feed_image
    feed_dict={""image_feed:0"": encoded_image})
  File ""/home/pmelissi/miniconda2/envs/im2txt/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/home/pmelissi/miniconda2/envs/im2txt/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 943, in _run
    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (960, 640, 3) for Tensor u'image_feed:0', which has shape '()'

Process finished with exit code 1
</code></pre>

<p>Can I somehow trick numpy into thinking the array has no shape?</p>

<h1>Converting to tf.string</h1>

<p>Here I used the following function</p>

<pre><code>def encode_image(filename):
    g2 = tf.Graph()
    from keras.preprocessing.image import img_to_array
    with g2.as_default() as g:
        with g.name_scope(""g2"") as g2_scope:
            arr = img_to_array(PILImage.open(filename))
            image = tf.image.encode_jpeg(arr)
            return image
...
captions = generator.beam_search(sess, image)
</code></pre>

<p>This didn't work either:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/run_inference.py"", line 107, in &lt;module&gt;
    tf.app.run()
  File ""/home/pmelissi/miniconda2/envs/im2txt/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/run_inference.py"", line 97, in main
    captions = generator.beam_search(sess, image)
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/inference_utils/caption_generator.py"", line 142, in beam_search
    initial_state = self.model.feed_image(sess, encoded_image)
  File ""/home/pmelissi/repos/tensorflow-models/im2txt/bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/inference_wrapper.py"", line 41, in feed_image
    feed_dict={""image_feed:0"": encoded_image})
  File ""/home/pmelissi/miniconda2/envs/im2txt/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/home/pmelissi/miniconda2/envs/im2txt/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 924, in _run
    raise TypeError('The value of a feed cannot be a tf.Tensor object. '
TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.
</code></pre>

<p>The last line in this stacktrace seems helpful, however there is no documentation as to what kind of structure is expected</p>

<pre><code>TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.
</code></pre>

<p>So, what should a valid input look like? The internals of preprocessing are not particularly clear to me.</p>

<p>Thanks for your time!</p>

<p>EDIT: <a href=""https://gist.github.com/PavlosMelissinos/9daa295d11af87848c3ea0778696eddd"" rel=""nofollow noreferrer"">Attached gist of the modified inference script for the big picture</a></p>

<p>EDIT 2: 
The path to sess.run goes like this:</p>

<p>1: run_inference.py</p>

<pre><code>captions = generator.beam_search(sess, image)
</code></pre>

<p>2: caption_generator.py</p>

<pre><code>def beam_search(self, sess, encoded_image):
    initial_state = self.model.feed_image(sess, encoded_image)
</code></pre>

<p>3: inference_wrapper.py</p>

<pre><code>def feed_image(self, sess, encoded_image):
    initial_state = sess.run(fetches=""lstm/initial_state:0"",
                         feed_dict={""image_feed:0"": encoded_image})
    return initial_state
</code></pre>

<p>EDIT 3: I forgot to mention that I'm restricted to TensorFlow v0.12 and therefore I'm using <a href=""https://github.com/tensorflow/models/tree/f653bd2340b15ce2a22669ba136b77b2751e462e/im2txt"" rel=""nofollow noreferrer"">this snapshot of the im2txt repo</a>.</p>
","I'm interested in modifying the tensorflow implementation of Show and Tell, in particular this v0.12 snapshot, in order to accept an image in numpy form instead of read it from disk. Loading a filename using the upstream code results in a python string after in run_inference.py which is then turned into an ndarray of no shape. However, I can't replicate that. I've tried the following: I wrote this function to load a pillow image from a filename, convert the image to a numpy array and feed it to the beam_search function in run_inference.py In this case, there is a size mismatch later, resulting in the following stack trace: Can I somehow trick numpy into thinking the array has no shape? Here I used the following function This didn't work either: The last line in this stacktrace seems helpful, however there is no documentation as to what kind of structure is expected So, what should a valid input look like? The internals of preprocessing are not particularly clear to me. Thanks for your time! EDIT: Attached gist of the modified inference script for the big picture EDIT 2: The path to sess.run goes like this: 1: run_inference.py 2: caption_generator.py 3: inference_wrapper.py EDIT 3: I forgot to mention that I'm restricted to TensorFlow v0.12 and therefore I'm using this snapshot of the im2txt repo.",https://stackoverflow.com/questions/43662094,7932035,Documentation Completeness,Documentation Completeness,"The last line in this stacktrace seems helpful, however there is no documentation as to what kind of structure is expected So, what should a valid input look like? The internals of preprocessing are not particularly clear to me. "
44177817,Calling reshape on an LSTMStateTuple turns it into a tensor,"<p>I was using dynamic_rnn with an LSTMCell, which put out an LSTMStateTuple containing the inner state. Calling reshape on this object (by my mistake) results in a tensor without causing any error at graph creation. I didn't get any error at runtime when feeding input through the graph, either.</p>

<p>Code:</p>

<pre><code>cell = tf.contrib.rnn.LSTMCell(size, state_is_tuple=True, ...)
outputs, states = tf.nn.dynamic_rnn(cell, inputs, ...)
print(states) # state is an LSTMStateTuple
states = tf.reshape(states, [-1, size])
print(states) # state is a tensor of shape [?, size]
</code></pre>

<p>Is this a bug (I ask because it's not documented anywhere)? What is the reshaped tensor holding?</p>
","I was using dynamic_rnn with an LSTMCell, which put out an LSTMStateTuple containing the inner state. Calling reshape on this object (by my mistake) results in a tensor without causing any error at graph creation. I didn't get any error at runtime when feeding input through the graph, either. Code: Is this a bug (I ask because it's not documented anywhere)? What is the reshaped tensor holding?",https://stackoverflow.com/questions/44177817,4204963,Lack of Alternative Solutions/Documentation,Documentation Completeness,Is this a bug (I ask because it's not documented anywhere)? 
44482637,How to use Tensorflow queues in real example,"<p>I have a Tensorflow  DNN model in with I use <code>feed_dict</code> to feed the Input 
<code>Training and Test</code> data and the labels that belongs to them. To keep things simple  this the important part of the code: </p>

<pre><code>def feed_dict(train):
""""""Make a TensorFlow feed_dict: maps data onto Tensor placeholders.""""""
if train == True :
    xs,ys = next_Training_Batch()
    drop_out_value = 0.9
else:
    #Run a test
    xs,ys=  Testing_Data,Testing_Labels
    drop_out_value = 1
return {x:xs,y_:ys,keep_prob:drop_out_value}
for i in range(max_steps):
    if i%5 ==0: # Record summarie and Test-set accruracy
        summary, acc = sess.run([merged,accuracy], feed_dict=feed_dict(False))
        test_writer.add_summary(summary,i)
        #print('Accuracy at steps%s: %s '%(i,acc))
    else:# Record train set summaries and train
        if i%10==0:
            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
            run_metadata = tf.RunMetadata()
            summary, _ = sess.run([merged, train_steps],
                          feed_dict=feed_dict(True),
                          options=run_options,
                          run_metadata=run_metadata)
            train_writer.add_run_metadata(run_metadata, 'step%03d' % i)
            train_writer.add_summary(summary, i)
        else:
            summary,_ = sess.run([merged, train_steps], feed_dict=feed_dict(True))
            train_writer.add_summary(summary,i)
</code></pre>

<p>I've been reading about the TF queue are a way more efficient, I've have huge difficulties get them running, here is what I've done so far: </p>

<pre><code>    import tensorflow as tf

'''
# Both Training.csv and Test.csv  include the features values and the and labels as follows :
Feature0  Feature1  Feature2  Feature3  Feature4  Feature5   .......  ClassID(Labels)  onehot
0.200985  1.000000  0.064534  0.415348  0.005391  1.000000             1000             1
0.151232  1.000000  0.048849  0.312474  0.007160  1.000000             2001             2
0.061576  1.000000  0.026125  0.127097  0.017450  1.000000             1000             3
...............................................................................
Each file has &gt; 2500 rows
'''

fileNames = [""Training.csv"",""Test.csv""]
BATCH_SIZE = 20
number_OF_features  = 450

def batch_generator(fileNames):
    fileNames_queue = tf.train.string_input_producer(fileNames)
    reader = tf.TextLineReader(skip_header_lines=1)
    key , values = reader.read(fileNames_queue)
    record_defaults = [[1.0] for _ in range(number_OF_features)]
    content = tf.decode_csv(values,record_defaults = record_defaults)
    features = tf.stack(content[:-2])
    labels = content[-1]
    min_after_dequeue =10 * BATCH_SIZE
    capacity = 20*BATCH_SIZE
    # suffle the data
    data_batch, label_batch = tf.train.shuffle_batch([features, labels], batch_size=BATCH_SIZE,
    capacity =capacity , min_after_dequeue = min_after_dequeue)
    return data_batch , label_batch

with tf.Session() as sess:
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    for _ in range(100 ): # generating 100 batch
        sess.run(batch_generator(fileNames))
        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        # I just  don'T get how to proceed from this point
        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        coord.request_stop()
        coord.join(threads)
</code></pre>

<p>My question is how can I ""feed""  data  in train and testing.  I've been reading TF docs but it didn't help.</p>

<p>Ref: The code I wrote is based on this <a href=""https://github.com/chiphuyen/tf-stanford-tutorials/tree/master/examples"" rel=""nofollow noreferrer"">great tutorials</a></p>
","I have a Tensorflow DNN model in with I use feed_dict to feed the Input Training and Test data and the labels that belongs to them. To keep things simple this the important part of the code: I've been reading about the TF queue are a way more efficient, I've have huge difficulties get them running, here is what I've done so far: My question is how can I ""feed"" data in train and testing. I've been reading TF docs but it didn't help. Ref: The code I wrote is based on this great tutorials",https://stackoverflow.com/questions/44482637,1563123,Documentation Completeness,Documentation Completeness,I've been reading TF docs but it didn't help.
45097828,Tensorflow: load multiple images to process (Python),"<p>I am working on a Tensorflow project (<a href=""https://github.com/niektemme/tensorflow-mnist-predict"" rel=""nofollow noreferrer"">https://github.com/niektemme/tensorflow-mnist-predict</a>) and I am in front of a problem.
In the file named <code>predict_2.py</code> there is a block of code which load an image..</p>

<pre><code>def imageprepare(argv):
    """"""
    This function returns the pixel values.
    The input is a png file location.
    """"""

    im = Image.open(argv).convert('L')
    width = float(im.size[0])
    height = float(im.size[1])
    newImage = Image.new('L', (28, 28), (255)) #creates white canvas of 28x28 pixels

    if width &gt; height: #check which dimension is bigger
        #Width is bigger. Width becomes 20 pixels.
        nheight = int(round((20.0/width*height),0)) #resize height according to ratio width
        if (nheight == 0): #rare case but minimum is 1 pixel
            nheigth = 1  
        # resize and sharpen
        img = im.resize((20,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)
        wtop = int(round(((28 - nheight)/2),0)) #caculate horizontal pozition
        newImage.paste(img, (4, wtop)) #paste resized image on white canvas
    else:
        #Height is bigger. Heigth becomes 20 pixels. 
        nwidth = int(round((20.0/height*width),0)) #resize width according to ratio height
        if (nwidth == 0): #rare case but minimum is 1 pixel
            nwidth = 1
         # resize and sharpen
        img = im.resize((nwidth,20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)
        wleft = int(round(((28 - nwidth)/2),0)) #caculate vertical pozition
        newImage.paste(img, (wleft, 4)) #paste resized image on white canvas

    #newImage.save(""sample.png"")

    tv = list(newImage.getdata()) #get pixel values

    #normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.
    tva = [ (255-x)*1.0/255.0 for x in tv] 
    return tva
</code></pre>

<p>Normally, I execute all the code (not just this one) in CMD so the program works.
What I would like to do now is to load multiple images (maybe from a different folder) and not just to pass the argv in the console which load only one image at the time.</p>

<p>What I previously thought was to create an array/list of images and then to put it instead of <code>im</code> variable. It doesn't work...</p>

<p>Can someone help ? Documentation on Tensorflow (and even the project itself) are very poor (atleast for me).</p>

<p>Thank you.</p>

<p>EDIT:</p>

<p>Here is full code</p>

<pre><code>""""""Predict a handwritten integer (MNIST expert).

Script requires
1) saved model (model2.ckpt file) in the same location as the script is run from.
(requried a model created in the MNIST expert tutorial)
2) one argument (png file location of a handwritten integer)

Documentation at:
http://niektemme.com/ @@to do
""""""

#import modules
import sys
import tensorflow as tf
from PIL import Image, ImageFilter
from PIL import Image as PImage
import os
from os import listdir
from datetime import datetime
from os import listdir

def predictint(imvalue):
    """"""
    This function returns the predicted integer.
    The input is the pixel values from the imageprepare() function.
    """"""

    # Define the model (same as when creating the model file)
    x = tf.placeholder(tf.float32, [None, 784])
    W = tf.Variable(tf.zeros([784, 10]))
    b = tf.Variable(tf.zeros([10]))

    def weight_variable(shape):
      initial = tf.truncated_normal(shape, stddev=0.1)
      return tf.Variable(initial)

    def bias_variable(shape):
      initial = tf.constant(0.1, shape=shape)
      return tf.Variable(initial)

    def conv2d(x, W):
      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

    def max_pool_2x2(x):
      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')   

    W_conv1 = weight_variable([5, 5, 1, 32])
    b_conv1 = bias_variable([32])

    x_image = tf.reshape(x, [-1,28,28,1])
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
    h_pool1 = max_pool_2x2(h_conv1)

    W_conv2 = weight_variable([5, 5, 32, 64])
    b_conv2 = bias_variable([64])

    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
    h_pool2 = max_pool_2x2(h_conv2)

    W_fc1 = weight_variable([7 * 7 * 64, 1024])
    b_fc1 = bias_variable([1024])

    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

    keep_prob = tf.placeholder(tf.float32)
    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)

    W_fc2 = weight_variable([1024, 10])
    b_fc2 = bias_variable([10])

    y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)

    init_op = tf.initialize_all_variables()
    saver = tf.train.Saver()

    """"""
    Load the model2.ckpt file
    file is stored in the same directory as this python script is started
    Use the model to predict the integer. Integer is returend as list.

    Based on the documentatoin at
    https://www.tensorflow.org/versions/master/how_tos/variables/index.html
    """"""
    with tf.Session() as sess:
        sess.run(init_op)
        saver.restore(sess, ""model2.ckpt"")
        #print (""Model restored."")

        prediction=tf.argmax(y_conv,1)

        return prediction.eval(feed_dict={x: [imvalue],keep_prob: 1.0}, session=sess)


def imageprepare(argv):
    """"""
    This function returns the pixel values.
    The input is a png file location.
    """"""

    im = Image.open(argv).convert('L')
    width = float(im.size[0])
    height = float(im.size[1])
    newImage = Image.new('L', (28, 28), (255)) #creates white canvas of 28x28 pixels

    if width &gt; height: #check which dimension is bigger
        #Width is bigger. Width becomes 20 pixels.
        nheight = int(round((20.0/width*height),0)) #resize height according to ratio width
        if (nheight == 0): #rare case but minimum is 1 pixel
            nheigth = 1  
        # resize and sharpen
        img = im.resize((20,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)
        wtop = int(round(((28 - nheight)/2),0)) #caculate horizontal pozition
        newImage.paste(img, (4, wtop)) #paste resized image on white canvas
    else:
        #Height is bigger. Heigth becomes 20 pixels. 
        nwidth = int(round((20.0/height*width),0)) #resize width according to ratio height
        if (nwidth == 0): #rare case but minimum is 1 pixel
            nwidth = 1
         # resize and sharpen
        img = im.resize((nwidth,20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)
        wleft = int(round(((28 - nwidth)/2),0)) #caculate vertical pozition
        newImage.paste(img, (wleft, 4)) #paste resized image on white canvas

    #newImage.save(""sample.png"")

    tv = list(newImage.getdata()) #get pixel values

    #normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.
    tva = [ (255-x)*1.0/255.0 for x in tv] 
    return tva
    #print(tva)  


def main(argv):
    """"""
    Main function.
    """"""
    imvalue = imageprepare(argv)
    predint = predictint(imvalue)
    print (predint[0]) #first value in list

    timestr = datetime.now().strftime(""%Y%m%d-%H%M%S-%f"")
    file = open('B' + timestr + '.txt', 'w')
    file.write('Causale: ' + str(predint))
    file.close()

if __name__ == ""__main__"":
    main('C:\\Users\\Wkgrp\\Desktop\\numeri\\4.jpg')
</code></pre>
","I am working on a Tensorflow project (https://github.com/niektemme/tensorflow-mnist-predict) and I am in front of a problem. In the file named predict_2.py there is a block of code which load an image.. Normally, I execute all the code (not just this one) in CMD so the program works. What I would like to do now is to load multiple images (maybe from a different folder) and not just to pass the argv in the console which load only one image at the time. What I previously thought was to create an array/list of images and then to put it instead of im variable. It doesn't work... Can someone help ? Documentation on Tensorflow (and even the project itself) are very poor (atleast for me). Thank you. EDIT: Here is full code",https://stackoverflow.com/questions/45097828,8193135,Inadequate Examples,Documentation Completeness,Documentation on Tensorflow (and even the project itself) are very poor (atleast for me).
46111888,Initializing variables with imported tensors from another graph,"<p>I am using tensorflow (version : v1.1.0-13-g8ddd727 1.1.0) in python3 (Python 3.4.3 (default, Nov 17 2016, 01:08:31) [GCC 4.8.4] on linux), it is installed from source and GPU-based.</p>

<p>I would like to know if it is possible to initialize variables with imported tensors from another session, as tensorflow documentations does not mention it and I have found it on stackoverflow.</p>

<pre><code>train_dir = './gan/train_logs'
    ckpt = tf.train.latest_checkpoint(train_dir)
    filename = ""."".join([ckpt, 'meta'])
    print(filename)
    saver = tf.train.import_meta_graph(filename)
    saver.restore(sess, ckpt)
    test = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')
</code></pre>

<p>Here the tensors are successfully imported and I want to use them to initialize same generator.</p>

<p>Thanks for your help!</p>
","I am using tensorflow (version : v1.1.0-13-g8ddd727 1.1.0) in python3 (Python 3.4.3 (default, Nov 17 2016, 01:08:31) [GCC 4.8.4] on linux), it is installed from source and GPU-based. I would like to know if it is possible to initialize variables with imported tensors from another session, as tensorflow documentations does not mention it and I have found it on stackoverflow. Here the tensors are successfully imported and I want to use them to initialize same generator. Thanks for your help!",https://stackoverflow.com/questions/46111888,8572742,Documentation Completeness,Documentation Completeness,"I would like to know if it is possible to initialize variables with imported tensors from another session, as tensorflow documentations does not mention it and I have found it on stackoverflow."
46646736,Applying custom learning rates to variables in Tensorflow,"<p>In Tensorflow, after I obtain my loss term, I give it to an optimizer and it adds the necessary differentiation and update terms to the computation graph:</p>

<pre><code>global_counter = tf.Variable(0, dtype=DATA_TYPE, trainable=False)
learning_rate = tf.train.exponential_decay(
    INITIAL_LR,  # Base learning rate.
    global_counter,  # Current index into the dataset.
    DECAY_STEP,  # Decay step.
    DECAY_RATE,  # Decay rate.
    staircase=True)
optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(network.finalLoss, global_step=global_counter)
feed_dict = {TRAIN_DATA_TENSOR: samples, TRAIN_LABEL_TENSOR: labels}
results = sess.run([optimizer], feed_dict=feed_dict)
</code></pre>

<p>I want a small modification to this process. I want to scale the <code>learning_rate</code> differently for my every distinct parameter in the network. For example, let <code>A</code> and <code>B</code> two different trainable parameters in the network and let <code>dL/dA</code> and <code>dL/dB</code> the partial derivatives of the parameters with respect to the loss. The momentum optimizer updates the variables as:</p>

<pre><code>   Ma &lt;- 0.9*Ma + learning_rate*dL/dA
   A &lt;- A - Ma

   Mb &lt;- 0.9*Mb + learning_rate*dL/dB
   B &lt;- B - Mb
</code></pre>

<p>I want to modify this as:</p>

<pre><code>   Ma &lt;- 0.9*Ma + ca*learning_rate*dL/dA
   A &lt;- A - Ma

   Mb &lt;- 0.9*Mb + cb*learning_rate*dL/dB
   B &lt;- B - Mb
</code></pre>

<p>Where <code>ca</code> and <code>cb</code> are special learning rate scales for different parameters. As far as I understand, Tensorflow has <code>compute_gradients</code> and <code>apply_gradients</code> methods we can call for such cases, but the documentation is not very clear about how to use them. Any help would be much appreciated. </p>
","In Tensorflow, after I obtain my loss term, I give it to an optimizer and it adds the necessary differentiation and update terms to the computation graph: I want a small modification to this process. I want to scale the learning_rate differently for my every distinct parameter in the network. For example, let A and B two different trainable parameters in the network and let dL/dA and dL/dB the partial derivatives of the parameters with respect to the loss. The momentum optimizer updates the variables as: I want to modify this as: Where ca and cb are special learning rate scales for different parameters. As far as I understand, Tensorflow has compute_gradients and apply_gradients methods we can call for such cases, but the documentation is not very clear about how to use them. Any help would be much appreciated.",https://stackoverflow.com/questions/46646736,1538049,Documentation Completeness,Documentation Completeness,"As far as I understand, Tensorflow has compute_gradients and apply_gradients methods we can call for such cases, but the documentation is not very clear about how to use them."
46648536,Tensorflow initialize certain scope only,"<p>He there,</p>

<p>I have a question regarding control over which variable scope is initialized, or at least, which variable scope is used during the run.</p>

<p>Take for example this easy piece of code</p>

<pre><code>import numpy as np
import tensorflow as tf

with tf.variable_scope('0') as scope:
    place_holder_batch_x = tf.Variable(np.random.rand(11,6), dtype=tf.float64)
    place_holder_batch_y = tf.Variable(np.random.rand(8,5), dtype=tf.float64)
    rnn_cell = tf.nn.rnn_cell.BasicRNNCell(3)
    z = place_holder_batch_x*2

with tf.variable_scope('1') as scope:
    place_holder_batch_x = tf.Variable(np.random.rand(10,5), dtype=tf.float64)
    place_holder_batch_y = tf.Variable(np.random.rand(9,6), dtype=tf.float64)
    rnn_cell = tf.nn.rnn_cell.BasicRNNCell(4)
    z = place_holder_batch_x*2

init = tf.global_variables_initializer()

sess = tf.Session()
sess.run(init)
print(sess.run(z).shape)
</code></pre>

<p>If I would run this as is, I would get the shape of variable z as is defined in variable scope '1'.
But how can I specify which variable scope to use during the session? I couldn't find any answer on stackoverflow or in the documentation...</p>

<p>Of course I could just rename both z's to z1 and z2... but I want to stay on the situation where both scopes look a lot like each other and use the same names...</p>
","He there, I have a question regarding control over which variable scope is initialized, or at least, which variable scope is used during the run. Take for example this easy piece of code If I would run this as is, I would get the shape of variable z as is defined in variable scope '1'. But how can I specify which variable scope to use during the session? I couldn't find any answer on stackoverflow or in the documentation... Of course I could just rename both z's to z1 and z2... but I want to stay on the situation where both scopes look a lot like each other and use the same names...",https://stackoverflow.com/questions/46648536,6329284,Documentation Completeness,Documentation Completeness,I couldn't find any answer on stackoverflow or in the documentation
47798492,Using Datasets to consume Numpy arrays,"<p>I'm trying to use Numpy arrays within a graph, feeding in the data using a Dataset.</p>

<p>I've read through <a href=""https://www.tensorflow.org/programmers_guide/dataset"" rel=""nofollow noreferrer"">this</a>, but can't quite make sense of how I should feed placeholder arrays within a Dataset.</p>

<p>If we take a simple example, I start with:</p>

<pre><code>A = np.arange(4)
B = np.arange(10, 14)

a = tf.placeholder(tf.float32, [None])
b = tf.placeholder(tf.float32, [None])
c = tf.add(a, b)

with tf.Session() as sess:
    for i in range(10):
        x = sess.run(c, feed_dict={a: A, b:B})
        print(i, x)
</code></pre>

<p>Then I attempt to modify it to use a Dataset as follows:</p>

<pre><code>A = np.arange(4)
B = np.arange(10, 14)

a = tf.placeholder(tf.int32, A.shape)
b = tf.placeholder(tf.int32, B.shape)
c = tf.add(a, b)

dataset = tf.data.Dataset.from_tensors((a, b))

iterator = dataset.make_initializable_iterator()

with tf.Session() as sess3:
    sess3.run(tf.global_variables_initializer())
    sess3.run(iterator.initializer, feed_dict={a: A, b: B})

    for i in range(10):
        x = sess3.run(c)
        print(i, x)
</code></pre>

<p>If I run this I get 'InvalidArgumentError: You must feed a value for placeholder tensor ...'</p>

<p>The code until the for loop mimics the example <a href=""https://www.tensorflow.org/programmers_guide/datasets#consuming_numpy_arrays"" rel=""nofollow noreferrer"">here</a>, but I don't get how I can then employ the placeholders a &amp; b without supplying a feed_dict to every call to sess3.run(c) [which would be expensive]. I suspect I have to somehow use the iterator, but I don't understand how.</p>

<p><strong>Update</strong></p>

<p>It appears I oversimplified too much when picking the example. What I am really trying to do is use Datasets when training a neural network, or similar.</p>

<p>For a more sensible question, how would I go about using Datasets to feed placeholders in the below (though imagine X and Y_true are much longer...). The documentation takes me to the point where the loop starts and then I'm not sure.</p>

<pre><code>X = np.arange(8.).reshape(4, 2)
Y_true = np.array([0, 0, 1, 1])

x = tf.placeholder(tf.float32, [None, 2], name='x')
y_true = tf.placeholder(tf.float32, [None], name='y_true')

w = tf.Variable(np.random.randn(2, 1), name='w', dtype=tf.float32)

y = tf.squeeze(tf.matmul(x, w), name='y')

loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
                                labels=y_true, logits=y),
                                name='x_entropy')

# set optimiser
optimiser = tf.train.AdamOptimizer().minimize(loss)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    for i in range(100):
        _, loss_out = sess.run([optimiser, loss], feed_dict={x: X, y_true:Y_true})
        print(i, loss_out)
</code></pre>

<p>Trying the following only gets me a InvalidArgumentError</p>

<pre><code>X = np.arange(8.).reshape(4, 2)
Y_true = np.array([0, 0, 1, 1])

x = tf.placeholder(tf.float32, [None, 2], name='x')
y_true = tf.placeholder(tf.float32, [None], name='y_true')

dataset = tf.data.Dataset.from_tensor_slices((x, y_true))
iterator = dataset.make_initializable_iterator()

w = tf.Variable(np.random.randn(2, 1), name='w', dtype=tf.float32)

y = tf.squeeze(tf.matmul(x, w), name='y')

loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
                                labels=y_true, logits=y),
                                name='x_entropy')

# set optimiser
optimiser = tf.train.AdamOptimizer().minimize(loss)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    sess.run(iterator.initializer, feed_dict={x: X,
                                              y_true: Y_true})

    for i in range(100):
        _, loss_out = sess.run([optimiser, loss])
        print(i, loss_out)
</code></pre>
","I'm trying to use Numpy arrays within a graph, feeding in the data using a Dataset. I've read through this, but can't quite make sense of how I should feed placeholder arrays within a Dataset. If we take a simple example, I start with: Then I attempt to modify it to use a Dataset as follows: If I run this I get 'InvalidArgumentError: You must feed a value for placeholder tensor ...' The code until the for loop mimics the example here, but I don't get how I can then employ the placeholders a &amp; b without supplying a feed_dict to every call to sess3.run(c) [which would be expensive]. I suspect I have to somehow use the iterator, but I don't understand how. Update It appears I oversimplified too much when picking the example. What I am really trying to do is use Datasets when training a neural network, or similar. For a more sensible question, how would I go about using Datasets to feed placeholders in the below (though imagine X and Y_true are much longer...). The documentation takes me to the point where the loop starts and then I'm not sure. Trying the following only gets me a InvalidArgumentError",https://stackoverflow.com/questions/47798492,9094969,Documentation Completeness,Documentation Completeness,The documentation takes me to the point where the loop starts and then I'm not sure.
48225315,Reading data into tensorflow and creating Dataset with TF-slim,"<p>I need to read in many 'images' from .txt files and want to generate a tensorflow dataset with them. Currently, I read in every single matrix with numpy.loadtxt and create an array of shape [N_matrices, height, width, N_channels], and a similar array with the label for every matrix. </p>

<p>I create a tensorflow dataset from these two arrays by using </p>

<pre><code>inputs = tf.convert_to_tensor(x_train, dtype=tf.float32)
labels = tf.convert_to_tensor(y_train, dtype=tf.float32)
dataset = tf.data.Dataset.from_tensor_slices( {""image"": inputs,""label"": labels})
</code></pre>

<p>I now want to make use of the following function to create batches from this dataset (as done <a href=""https://github.com/mnuke/tf-slim-mnist/blob/master/model.py"" rel=""nofollow noreferrer"">here</a>):</p>

<pre><code>def load_batch(dataset, batch_size=BATCH_SIZE, height=LENGTH_INPUT, width=LENGTH_INPUT):

    data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset)

    image, label = data_provider.get(['image', 'label'])

    images, labels = tf.train.batch(
    [image, label],
    batch_size=batch_size,
    allow_smaller_final_batch=True)

    return images, labels 
</code></pre>

<p>However, this gives me the following error:</p>

<blockquote>
<pre><code>data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset)
</code></pre>
  
  <p>File ""/home/.local/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/data/dataset_data_provider.py"", line 85, in <strong>init</strong>
      dataset.data_sources,</p>
  
  <p>AttributeError: 'TensorSliceDataset' object has no attribute 'data_sources'</p>
</blockquote>

<p>Why am I getting this error, and how can I fix it? I also suppose there are much better ways for handling input from txt files to tensorflow (or tensorflow-slim) but I've found very little information on this. How could I generate my Datasets in a better way?</p>
","I need to read in many 'images' from .txt files and want to generate a tensorflow dataset with them. Currently, I read in every single matrix with numpy.loadtxt and create an array of shape [N_matrices, height, width, N_channels], and a similar array with the label for every matrix. I create a tensorflow dataset from these two arrays by using I now want to make use of the following function to create batches from this dataset (as done here): However, this gives me the following error: Why am I getting this error, and how can I fix it? I also suppose there are much better ways for handling input from txt files to tensorflow (or tensorflow-slim) but I've found very little information on this. How could I generate my Datasets in a better way?",https://stackoverflow.com/questions/48225315,9208637,Requesting (Additional) Resources,Documentation Completeness,I also suppose there are much better ways for handling input from txt files to tensorflow (or tensorflow-slim) but I've found very little information on this.
48266862,Trouble Displaying an Image with Bounding Boxes,"<p>I have some code which is meant to simply draw a bounding box on an image, and save it out as a new image. However, when I run it I get a <code>TypeError: Cannot handle this data type</code> from pillow.</p>

<p>The code is</p>

<pre><code># Tests that the processed data file can be read correctly and has correct bounding boxes

import tensorflow as tf
import numpy as np
from PIL import Image

def read_processed_data(filename, num_show):
    """""" Reads in the processed data file and displays the
        given number of images, along with the bounding boxes.
    """"""
    with open(filename, 'r') as f:
        i = 0

        while i &lt; num_show:
            for line in f:
                filename = line.rstrip()
                next_line = f.readline()
                num_faces = int(next_line.rstrip())
                face_num = 0

                #while face_num &lt; num_faces:
                bb_line = f.readline().rstrip()
                y1, x1, y2, x2 = bb_line.split(',')

                box = [y1, x1, y2, x2]
                box = tf.cast(box, tf.float32)

                return box, filename

with tf.Session() as sess:
    bb, fn = read_processed_data(""processed.txt"", 1)
    image = tf.image.decode_image(tf.read_file(fn))
    img = image.eval()
    print(img.shape)

    img_show = np.asarray(img)
    Image.fromarray(img_show).save(""test_no_bb.jpg"") # Works

    bb_image = tf.image.draw_bounding_boxes(img, bb)
    print(bb_image.shape)
    bb_image = tf.cast(bb_image, tf.uint8)
    bb_img_jpeg = tf.image.encode_jpeg(bb_image)
    bb_image_np = np.asarray(bb_img_jpeg)
    Image.fromarray(bb_image_np).save(""test.jpg"") # Does not work
</code></pre>

<p><code>test_no_bb.jpg</code> gets created fine, but when I reach <code>Image.fromarray(bb_image_np).save(""test.jpg"")</code>, I get the aforementioned type error.</p>

<p>I have searched the web all over to no avail, and TensorFlow's documentation on this is lacking. The shape of the <code>bb_image</code> is correct, and the output of <code>bb</code> (the coordinates of the bounding box) is also correct so I am at a loss.</p>

<p>Any help is greatly appreciated.</p>
","I have some code which is meant to simply draw a bounding box on an image, and save it out as a new image. However, when I run it I get a TypeError: Cannot handle this data type from pillow. The code is test_no_bb.jpg gets created fine, but when I reach Image.fromarray(bb_image_np).save(""test.jpg""), I get the aforementioned type error. I have searched the web all over to no avail, and TensorFlow's documentation on this is lacking. The shape of the bb_image is correct, and the output of bb (the coordinates of the bounding box) is also correct so I am at a loss. Any help is greatly appreciated.",https://stackoverflow.com/questions/48266862,5280140,Documentation Completeness,Documentation Completeness,"I have searched the web all over to no avail, and TensorFlow's documentation on this is lacking."
49775557,"How can I invoke a SageMaker model, trained with TensorFlow, using a csv file in the body of the call?","<p>I have deployed a TensorFlow model on AWS SageMaker, and I want to be able to invoke it using a csv file as the body of the call. The documentation says about creating a <code>serving_input_function</code> like the one below: </p>

<pre><code>def serving_input_fn(hyperparameters):
  # Logic to the following:
  # 1. Defines placeholders that TensorFlow serving will feed with inference requests
  # 2. Preprocess input data
  # 3. Returns a tf.estimator.export.ServingInputReceiver or tf.estimator.export.TensorServingInputReceiver,
  # which packages the placeholders and the resulting feature Tensors together.
</code></pre>

<p>In step 2, where it says preprocess input data, how do I get a handle on input data to process them?</p>
","I have deployed a TensorFlow model on AWS SageMaker, and I want to be able to invoke it using a csv file as the body of the call. The documentation says about creating a serving_input_function like the one below: In step 2, where it says preprocess input data, how do I get a handle on input data to process them?",https://stackoverflow.com/questions/49775557,4537553,Documentation Ambiguity,Documentation Completeness,"The documentation says about creating a serving_input_function like the one below: In step 2, where it says preprocess input data, how do I get a handle on input data to process them?"
49785605,How does tensorflow connect the dimensions of linked convolutional layers?,"<p>The is a very basic tensorflow question, but I haven't yet seen a clear explanation in the docs.  Following the <a href=""https://www.tensorflow.org/tutorials/layers"" rel=""nofollow noreferrer"">examples on the tensorflow site</a>, we basically have these two layers connected:</p>

<pre><code>conv1 = tf.layers.conv2d(
    inputs=input_layer,
    filters=32,
    kernel_size=[5, 5],
    padding=""same"",
    activation=tf.nn.relu)
</code></pre>

<p>The shape at this point will be <code>(28, 28, 32)</code>. </p>

<pre><code>conv2 = tf.layers.conv2d(
    inputs=conv1,
    filters=64,
    kernel_size=[5, 5],
    padding=""same"",
    activation=tf.nn.relu)
</code></pre>

<p>The shape at this point will be <code>(28, 28, 64)</code>.  How does tensorflow take the <code>(28, 28, 32)</code> and turn it into <code>(28, 28, 64)</code> using a 2d kernel.  Could you please explain or point me to the documentation?  How about when the output dimension of the second layer is smaller, say </p>

<pre><code>conv2 = tf.layers.conv2d(
    inputs=conv1,
    filters=8,
    kernel_size=[5, 5],
    padding=""same"",
    activation=tf.nn.relu)
</code></pre>

<p>How would tensorflow combine the 32 dimensions into 8?  </p>
","The is a very basic tensorflow question, but I haven't yet seen a clear explanation in the docs. Following the examples on the tensorflow site, we basically have these two layers connected: The shape at this point will be (28, 28, 32). The shape at this point will be (28, 28, 64). How does tensorflow take the (28, 28, 32) and turn it into (28, 28, 64) using a 2d kernel. Could you please explain or point me to the documentation? How about when the output dimension of the second layer is smaller, say How would tensorflow combine the 32 dimensions into 8?",https://stackoverflow.com/questions/49785605,1759909,Documentation Completeness,Documentation Completeness,"The is a very basic tensorflow question, but I haven't yet seen a clear explanation in the docs."
51016991,How to customize a RNN cell,"<p>I would like to implement a custom LSTM or GRU cell in TensorFlow (Python 3). For example, I want to scale the cell state signal from the cell at time step T before entering the cell at time step T+1. I've tried searching in TensorFlow documentation without a success.
Could you give me a hint?
Thank you.</p>

<p><strong>EDIT</strong><br>Having checked the answer given by <a href=""https://stackoverflow.com/questions/50262174/effect-of-setting-sequence-length-on-the-returned-state-in-dynamic-rnn/50289099#50289099"">@vijay m</a>, I create my model as follows:</p>

<pre><code>def dynamic_scale_RNN(x, timescale, seqlen, weights, biases, keep_prop):
    batch_size = tf.shape(x)[0]

    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)
    x = tf.unstack(x, max_seq_len, 1)
    timescale_unstack = tf.unstack(timescale, max_seq_len, 1)

    gru_cell = tf.contrib.rnn.GRUCell(n_hidden)

    #init_state has to be set to zero
    init_state = gru_cell.zero_state(batch_size, dtype=tf.float32)

    outputs = []
    # Create a loop of N LSTM cells, N = time_steps.
    for i in range(len(x)):
        output, state= tf.nn.static_rnn(gru_cell, [x[i]], dtype=tf.float32, initial_state= init_state)
        # copy the init_state with the new state
        mask = tf.tile(tf.expand_dims(timescale_unstack[i],axis=1),[1,state[0].get_shape()[-1]])
        init_state = tf.multiply(state,mask)
        # init_state = state
        outputs.append(output)

    # Transform the output to [batch_size, time_steps, vector_size]        
    outputs = tf.transpose(tf.squeeze(tf.stack(outputs)), [1, 0, 2])
</code></pre>

<p>In the code above, timescale is a tensor of shape <code>[batch_size, sequence_length, 1]</code> and I want to scale the cell state using this tensor. Even though the code can run, it returns <code>nan</code> for cost function.
If I uncomment the line <code>init_state = state</code>, it works, but it won't scale the cell state.</p>

<p>My question, for now, is that: Why I get <code>nan</code> values for cost function?</p>
","I would like to implement a custom LSTM or GRU cell in TensorFlow (Python 3). For example, I want to scale the cell state signal from the cell at time step T before entering the cell at time step T+1. I've tried searching in TensorFlow documentation without a success. Could you give me a hint? Thank you. EDITHaving checked the answer given by @vijay m, I create my model as follows: In the code above, timescale is a tensor of shape [batch_size, sequence_length, 1] and I want to scale the cell state using this tensor. Even though the code can run, it returns nan for cost function. If I uncomment the line init_state = state, it works, but it won't scale the cell state. My question, for now, is that: Why I get nan values for cost function?",https://stackoverflow.com/questions/51016991,2241766,Lack of Alternative Solutions/Documentation,Documentation Completeness,I've tried searching in TensorFlow documentation without a success.
51144993,Tensorflow: Is the learning rate you set in Adam and Adagrad just the initial learning rate?,"<p>I'm reading this blog</p>

<p><a href=""https://smist08.wordpress.com/2016/10/04/the-road-to-tensorflow-part-10-more-on-optimization/"" rel=""nofollow noreferrer"">https://smist08.wordpress.com/2016/10/04/the-road-to-tensorflow-part-10-more-on-optimization/</a></p>

<p>where it mentions all the tensorflow's learning rates</p>

<pre><code>optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)

optimizer = tf.train.AdadeltaOptimizer(starter_learning_rate).minimize(loss)

optimizer = tf.train.AdagradOptimizer(starter_learning_rate).minimize(loss)     # promising

optimizer = tf.train.AdamOptimizer(starter_learning_rate).minimize(loss)      # promising

optimizer = tf.train.MomentumOptimizer(starter_learning_rate, 0.001).minimize(loss) # diverges

optimizer = tf.train.FtrlOptimizer(starter_learning_rate).minimize(loss)    # promising

optimizer = tf.train.RMSPropOptimizer(starter_learning_rate).minimize(loss)   # promising
</code></pre>

<p>It says that the learning rate you input is only the starter learning rate. Does that mean that if you change the learning rate in the middle of training, that change will have no effect because it's not using the starter learning rate anymore?  </p>

<p>I tried looking at the API docs and it doesn't specify this. </p>
","I'm reading this blog https://smist08.wordpress.com/2016/10/04/the-road-to-tensorflow-part-10-more-on-optimization/ where it mentions all the tensorflow's learning rates It says that the learning rate you input is only the starter learning rate. Does that mean that if you change the learning rate in the middle of training, that change will have no effect because it's not using the starter learning rate anymore? I tried looking at the API docs and it doesn't specify this.",https://stackoverflow.com/questions/51144993,3259896,Documentation Completeness,Documentation Completeness,I tried looking at the API docs and it doesn't specify this.
52323297,TypeError when using tf.keras.layers.Reshape,"<p>when building a model in Keras, I run into this error:</p>

<pre><code>TypeError: Expected int32, got 8.0 of type 'float' instead.
</code></pre>

<p>The error occurs when initially building the model (as opposed to during execution), more specifically on the last line of this snippet:</p>

<pre><code>    d_dense1 = Dense(
        ((IMAGE_SIZE/4)**2)*(n if vanilla_architecture else 3*n),
        input_shape = (h,),
        activation = ""relu"",
        name = name_prefix + ""dense1""
    )(d_in)
    d_reshape1 = tf.keras.layers.Reshape(
        (IMAGE_SIZE/4, IMAGE_SIZE/4, (n if vanilla_architecture else 3*n)),
        name = name_prefix + ""reshape1""
    )(d_dense1)
</code></pre>

<blockquote>
  <p>Side note: I am using tf.keras.layers.Dense, IMAGE_SIZE is an integer, vanilla_architecture is a boolean, and n is an integer</p>
</blockquote>

<p>Obviously the dense layer will pass along a tensor of floats because, well, it's a machine learning operation. The issue seems to be that Reshape requires a tensor of integers. I read the documentation but there is no information there. </p>

<p>Here are some things I've tried:</p>

<ul>
<li>using tf.reshape

<ul>
<li>Same issue</li>
</ul></li>
<li>using numpy reshape

<ul>
<li>Just plain doesn't work </li>
</ul></li>
<li>reading example code like like 54 of <a href=""https://github.com/keras-team/keras/blob/master/examples/mnist_acgan.py"" rel=""nofollow noreferrer"">this</a> 

<ul>
<li>they seem to be doing the same thing as me but theirs works</li>
</ul></li>
</ul>

<p>The weird part is that it works just fine when using eager execution. I don't want to have eager execution enabled though because I want to use tensorboard. </p>
","when building a model in Keras, I run into this error: The error occurs when initially building the model (as opposed to during execution), more specifically on the last line of this snippet: Obviously the dense layer will pass along a tensor of floats because, well, it's a machine learning operation. The issue seems to be that Reshape requires a tensor of integers. I read the documentation but there is no information there. Here are some things I've tried: The weird part is that it works just fine when using eager execution. I don't want to have eager execution enabled though because I want to use tensorboard.",https://stackoverflow.com/questions/52323297,4293998,Lack of Alternative Solutions/Documentation,Documentation Completeness,I read the documentation but there is no information there.
53816414,TensorFlow Operation and cannot be found in official API,"<p>recently I try to repeat and learn the code posted on GitHub by Nvidia--progressive_growing_of_gans. However, I find that there are several operations that I can not find reference based on official API as the following.</p>

<pre><code>feed_dict = {}
setter = tf.assign(var, tf.placeholder(var.dtype, var.shape, 'new_value'),name='setter')
feed_dict[setter.op.inputs[1]] = value
</code></pre>

<p>What does the setter.op.inputs mean?</p>

<pre><code>v = tf.cast(value_expr, tf.float32)
v.shape.ndims
</code></pre>

<p>What does the v.shape.ndims mean? </p>

<p>By the way, how can I get the reference for such class method? It seems that they are not included in official API.</p>

<p>Thank you, everybody!</p>
","recently I try to repeat and learn the code posted on GitHub by Nvidia--progressive_growing_of_gans. However, I find that there are several operations that I can not find reference based on official API as the following. What does the setter.op.inputs mean? What does the v.shape.ndims mean? By the way, how can I get the reference for such class method? It seems that they are not included in official API. Thank you, everybody!",https://stackoverflow.com/questions/53816414,9881203,Documentation Completeness,Documentation Completeness,"However, I find that there are several operations that I can not find reference based on official API as the following."
54521572,How to transform keras model to tpu model,"<p>I am trying to transform my Keras model in the Google cloud console into a TPU model. Unfortunatelly I am getting an error as shown below. My minimal example is the following:</p>

<pre><code>import keras
from keras.models import Sequential
from keras.layers import Dense, Activation
import tensorflow as tf
import os
model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Dense(32))
model.add(Activation('relu'))
model.compile(optimizer='rmsprop', loss='mse')
tpu_model = tf.contrib.tpu.keras_to_tpu_model(
    model,
    strategy=tf.contrib.tpu.TPUDistributionStrategy(
         tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))
</code></pre>

<p>My output is:</p>

<pre><code>Using TensorFlow backend.
Traceback (most recent call last):
     File ""cloud_python4.py"", line 11, in &lt;module&gt;
     tpu_model = tf.contrib.tpu.keras_to_tpu_model(AttributeError: module 'tensorflow.contrib.tpu' has no attribute 'keras_to_tpu_model'
</code></pre>

<p>The keras_to_tpu_model method seems experimental as indicated on the tensorflow website. Has it recently been removed? If so, how can I proceed to make use of TPUs to estimate my Keras model? If the keras_to_tpu_model method would be still available, why can I not invoke it?</p>
","I am trying to transform my Keras model in the Google cloud console into a TPU model. Unfortunatelly I am getting an error as shown below. My minimal example is the following: My output is: The keras_to_tpu_model method seems experimental as indicated on the tensorflow website. Has it recently been removed? If so, how can I proceed to make use of TPUs to estimate my Keras model? If the keras_to_tpu_model method would be still available, why can I not invoke it?",https://stackoverflow.com/questions/54521572,6493472,Documentation Completeness,Documentation Completeness, The keras_to_tpu_model method seems experimental as indicated on the tensorflow website. Has it recently been removed?
55868173,Accepting base64-images as input for TensorFlow model,"<p>I am trying to export my TensorFlow image-classifying model such that it accepts base64 strings as input. </p>

<p>I have tried to implement the solution that is provided on <a href=""https://stackoverflow.com/a/47944205/11415897"">this question</a>, however I am getting the following error:</p>

<blockquote>
  <p>""InvalidArgumentError: Shape must be rank 0 but is rank 1 for
  'DecodeJpeg_1' (op: 'DecodeJpeg') with input shapes: [?].""</p>
</blockquote>

<p>The error appears as a result of the code on line 4. </p>

<pre><code>export_dir = '~/models/1'
builder = saved_model_builder.SavedModelBuilder(export_dir)
image = tf.placeholder(dtype=tf.string, shape=[None], name='source')
decoded = tf.image.decode_jpeg(image)
scores = build_model(decoded)
signature = predict_signature_def(inputs={'image_bytes': image},
                                 outputs={'output': scores})

with K.get_session() as sess:
    builder.add_meta_graph_and_variables(sess=sess,
                                         tags=[tag_constants.SERVING],
                                         signature_def_map={'predict': signature})
    builder.save()
sess.close()
</code></pre>

<p>Also,</p>

<p>I see that on line 5, ""scores"" provides the output of the model based on the <code>build_model</code> function. However, I can't find in the original question's answers or in the TensorFlow documentation where this function comes from.</p>
","I am trying to export my TensorFlow image-classifying model such that it accepts base64 strings as input. I have tried to implement the solution that is provided on this question, however I am getting the following error: The error appears as a result of the code on line 4. Also, I see that on line 5, ""scores"" provides the output of the model based on the build_model function. However, I can't find in the original question's answers or in the TensorFlow documentation where this function comes from.",https://stackoverflow.com/questions/55868173,11415897,Documentation Completeness,Documentation Completeness,"However, I can't find in the original question's answers or in the TensorFlow documentation where this function comes from."
56672695,How to specify variables in tensorflow simple save,"<p>I am trying unsuccessfully to save my tensorflow model using the simple save method.</p>

<p>I have built a model using keras and trained it successfully, with an accuracy of 88%.  I am now trying to save this model so we can serve it, but the function I need, simple save, isn't clear about how to specify the variables that get passed in.</p>

<p>The the session and the export directory is clear enough, but the inputs and outputs are mysterious.  I believe that because I've used Keras, these variables are hidden by the abstraction of keras and the documentation from Tensorflow on simple save offers no explanation.</p>

<p>As a hailmary, I set Z equal to y just to put something in there, but obviously that is wrong.  Do I need to set up an output variable Z, and if so, what type is it?</p>

<p>Not sure if this is enough code to get to the bottom of this.  Even getting pointed at the right docs would be a big boost.</p>

<pre><code>import tensorflow as tf
session =  tf.keras.backend.get_session()
export_dir = ""/Users/somedir/""
z = np.array([])
tf.saved_model.simple_save(session,
            export_dir,
            inputs={""x"": X, ""y"": y},
            outputs={""z"": z})
</code></pre>

<p>X is my dataset -- an array of all independent variables.  Y is the outcome (dependent variable). I don't have another candidate for z, so I set it to an empty array.  </p>

<p>I get AttributeError: 'numpy.ndarray' object has no attribute 'get_shape'</p>
","I am trying unsuccessfully to save my tensorflow model using the simple save method. I have built a model using keras and trained it successfully, with an accuracy of 88%. I am now trying to save this model so we can serve it, but the function I need, simple save, isn't clear about how to specify the variables that get passed in. The the session and the export directory is clear enough, but the inputs and outputs are mysterious. I believe that because I've used Keras, these variables are hidden by the abstraction of keras and the documentation from Tensorflow on simple save offers no explanation. As a hailmary, I set Z equal to y just to put something in there, but obviously that is wrong. Do I need to set up an output variable Z, and if so, what type is it? Not sure if this is enough code to get to the bottom of this. Even getting pointed at the right docs would be a big boost. X is my dataset -- an array of all independent variables. Y is the outcome (dependent variable). I don't have another candidate for z, so I set it to an empty array. I get AttributeError: 'numpy.ndarray' object has no attribute 'get_shape'",https://stackoverflow.com/questions/56672695,914863,Documentation Completeness,Documentation Completeness,"I believe that because I've used Keras, these variables are hidden by the abstraction of keras and the documentation from Tensorflow on simple save offers no explanation."
57133866,"How to fix:""Expected shapes TensorShape([Dimension(None), Dimension(785)]) got dataset with shapes TensorShape([Dimension(785)])""","<p>So I am trying to build Fashion-MNIST CNN classifier using tensorflow. and I am getting this dimensionality error.I am a newbie to tensorflow.</p>

<p>I read tensorflow documentation but i didnt get solution to my problem.
I am sharing the code which i find related to the error.
Following is the entire traceback </p>

<pre><code>    Traceback (most recent call last):

    File ""&lt;ipython-input-2-8a4292875dbe&gt;"", line 208, in &lt;module&gt;
        model.build()

    File ""&lt;ipython-input-2-8a4292875dbe&gt;"", line 133, in build
        self.getdata()

    File ""&lt;ipython-input-2-8a4292875dbe&gt;"", line 65, in getdata
        self.test_data_init = iterator.make_initializer(test_data)    
    # initializer for test_data

    File ""/home/aditya/anaconda3/envs/train/lib/python3.7/site- 
    packages/tensorflow/python/data/ops/iterator_ops.py"", line 369, 
    in make_initializer
       (self.output_shapes, dataset_output_shapes))

    TypeError: Expected output shapes compatible with 
    TensorShape([Dimension(None), Dimension(785)]) but got dataset 
    with output shapes TensorShape([Dimension(785)]).
</code></pre>

<p>my model.build()</p>

<pre><code>    def build(self):
    '''
    Build the computation graph
    '''
    self.getdata()
    self.inference()
    self.loss()
    self.optimize()
    self.eval()
    self.summary()
</code></pre>

<p>my getdata()</p>

<pre><code>    def getdata(self):
    with tf.name_scope('data'):
        train_data=tf.data.Dataset.from_tensor_slices(train)
        train_data = train_data.shuffle(10000) # if you want to shuffle your data
        train_data = train_data.batch(self.batch_size)

        test_data=tf.data.Dataset.from_tensor_slices(test)           
iterator=tf.data.Iterator.from_structure(train_data.output_types,train_data.output_shapes)
        self.train_data_init = iterator.make_initializer(train_data)  # initializer for train_data
        self.test_data_init = iterator.make_initializer(test_data)    # initializer for test_data
        img, self.label = iterator.get_next()
        self.img = tf.reshape(img, shape=[-1, 28, 28, 1])
        # reshape the image to make it work with tf.nn.conv2d
</code></pre>

<p>I was expecting to find a way to reshape but I couldnt do it.Any help will be appreciated</p>
",So I am trying to build Fashion-MNIST CNN classifier using tensorflow. and I am getting this dimensionality error.I am a newbie to tensorflow. I read tensorflow documentation but i didnt get solution to my problem. I am sharing the code which i find related to the error. Following is the entire traceback my model.build() my getdata() I was expecting to find a way to reshape but I couldnt do it.Any help will be appreciated,https://stackoverflow.com/questions/57133866,6873425,Inadequate Examples,Documentation Completeness,I read tensorflow documentation but i didnt get solution to my problem.
58100071,What is the correct way to implement a 'useless loss' with Keras?,"<p>I have a Keras model that has two outputs:</p>

<ul>
<li><p><code>output</code> is the true output of the network on which the loss is going to be computed</p></li>
<li><p><code>additional</code> is used to make an external task during inference (no loss should be computed with this output)</p></li>
</ul>

<p>When I build the model, I write something like that:</p>

<pre><code>model = Model(inputs=inp, outputs=[output, additional])
</code></pre>

<p>Since my <code>Model</code> has two outputs, I need to provide two losses when compiling the model so I created a useless loss like this:</p>

<pre><code>class NoopLoss(object):

    def __call__(self, y_true, y_pred, **kwargs):
        return self.compute_loss(y_true, y_pred)

    def compute_loss(self, y_true, y_pred):
        return tf.math.square(0.0)

</code></pre>

<p>Which I integrate in the compile step like this:</p>

<pre><code>loss = UsefulLoss()  # the real loss I'm using
noop_loss = NoopLoss()

model.compile(loss=[loss, noop_loss], optimizer=optimizer, metrics=['binary_accuracy'])
</code></pre>

<p>It works, but I feel it is a bit hackish, is there a correct way to implement this behavior? I didn't find any official useless loss in the Keras documentation.</p>
","I have a Keras model that has two outputs: When I build the model, I write something like that: Since my Model has two outputs, I need to provide two losses when compiling the model so I created a useless loss like this: Which I integrate in the compile step like this: It works, but I feel it is a bit hackish, is there a correct way to implement this behavior? I didn't find any official useless loss in the Keras documentation.",https://stackoverflow.com/questions/58100071,2206908,Requesting (Additional) Resources,Documentation Completeness,"It works, but I feel it is a bit hackish, is there a correct way to implement this behavior? I didn't find any official useless loss in the Keras documentation."
59549667,How to use Tensorflows GradientTape() to compute biases,"<p>I'm looking to implement GradientTape() on a custom NN architecture but I don't see an explanation anywhere on how to use this to compute biases. A similar question was answered <a href=""https://stackoverflow.com/questions/57814376/gradient-calculation-for-bias-term-using-gradienttape"">here</a>, but it was not answered fully.</p>

<p>As a simple example, I have the training step for my NN like so:</p>

<pre><code>self.W = ## Initialized earlier on
self.b = ## Initialized earlier on

@tf.function
    def train(self):
        with tf.GradientTape() as tape:
            pred = self.feedforward()
            loss = self.loss_evaluation()
        grad = tape.gradient(loss, self.W)
        grad = tape.gradient(loss, self.b) ## How do I do this?

        optimizer.apply_gradients(zip(grad, self.W))
        optimizer.apply_gradients(zip(grad, self.b)) ## How do I do this?
</code></pre>

<p>Put simply, I cannot evaluate the gradients with respect to the biases as nowhere in any documentation or tutorial do I see the bias term included. So, how do I go about implementing the bias term as a trainable variable in my code? I'm not looking to implement this with keras, so do not suggest I use <code>trainable_variables</code> as I want to do it from scratch.</p>
","I'm looking to implement GradientTape() on a custom NN architecture but I don't see an explanation anywhere on how to use this to compute biases. A similar question was answered here, but it was not answered fully. As a simple example, I have the training step for my NN like so: Put simply, I cannot evaluate the gradients with respect to the biases as nowhere in any documentation or tutorial do I see the bias term included. So, how do I go about implementing the bias term as a trainable variable in my code? I'm not looking to implement this with keras, so do not suggest I use trainable_variables as I want to do it from scratch.",https://stackoverflow.com/questions/59549667,11065415,Documentation Completeness,Documentation Completeness,"Put simply, I cannot evaluate the gradients with respect to the biases as nowhere in any documentation or tutorial do I see the bias term included."
59697286,Creating SequenceExample(s) using TensorFlow Transform,"<p>With TensorFlow Transform, we can pre-process data using Apache Beam. One of the requirements when setting up such a pipeline is to define a <strong>DatasetMetadata</strong> object, which contains the schema that has the information needed to parse the data from its on-disk or in-memory format, into tensors.</p>

<p>In the official documentation, we are given an example of the form:</p>

<pre><code>raw_data_metadata = dataset_metadata.DatasetMetadata(
dataset_schema.from_feature_spec({
    's': tf.FixedLenFeature([], tf.string),
    'y': tf.FixedLenFeature([], tf.float32),
    'x': tf.FixedLenFeature([], tf.float32),
}))
</code></pre>

<p>This is all fine if your raw data is a dictionary of the form:</p>

<pre><code>{
    's': 'example string',
    'y': 32.0,
    'x': 35.0
}
</code></pre>

<p>However, I am somewhat lost when it comes to defining a schema for a <strong>SequenceExample</strong>.
More specifically, consider that my data has the following format:</p>

<pre><code>{
    # context features
    'length': 5,
    # sequence features
    'tokens': [
        {
            'raw': 'The',
            'ner-tag': 'O'
        },
        {
            'raw': 'European',
            'ner-tag': 'B-org'
        },
        {
            'raw': 'Union',
            'ner-tag': 'I-org'
        },
        {
            'raw': 'is',
            'ner-tag': 'O'
        },
        {
            'raw': 'nice',
            'ner-tag': 'O'
        }
        ...
    ]
}
</code></pre>

<p>Above I have a sentence with 2 sequences:</p>

<ul>
<li><strong>ner-tag</strong> sequence which is going to be used as a label for the model</li>
<li><strong>raw</strong> sequence which is going to be used as a feature for the model</li>
</ul>

<p>How can I create a TFT data schema for such examples? </p>

<p>The documentation is a bit absent for this one.
Any help much appreciated!</p>
","With TensorFlow Transform, we can pre-process data using Apache Beam. One of the requirements when setting up such a pipeline is to define a DatasetMetadata object, which contains the schema that has the information needed to parse the data from its on-disk or in-memory format, into tensors. In the official documentation, we are given an example of the form: This is all fine if your raw data is a dictionary of the form: However, I am somewhat lost when it comes to defining a schema for a SequenceExample. More specifically, consider that my data has the following format: Above I have a sentence with 2 sequences: How can I create a TFT data schema for such examples? The documentation is a bit absent for this one. Any help much appreciated!",https://stackoverflow.com/questions/59697286,5923976,Lack of Alternative Solutions/Documentation,Documentation Completeness,How can I create a TFT data schema for such examples? The documentation is a bit absent for this one.
59968630,Tensorflow one custom metric for multioutput models,"<p>I can't find the info in the documentation so I am asking here.</p>

<p>I have a multioutput model with 3 different outputs:</p>

<pre class=""lang-py prettyprint-override""><code>model = tf.keras.Model(inputs=[input], outputs=[output1, output2, output3])
</code></pre>

<p>The predicted labels for validation are constructed from these 3 outputs to form only one, it's a post-processing step. The dataset used for training is a dataset of those 3 intermediary outputs, for validation I evaluate on a dataset of labels instead of the 3 kind of intermediary data.</p>

<p>I would like to evaluate my model using a custom metric that handle the post processing and comparaison with the ground truth.</p>

<p><strong>My question is</strong>, in the code of the custom metric, will <code>y_pred</code> be a list of the 3 outputs of the model?</p>

<pre class=""lang-py prettyprint-override""><code>class MyCustomMetric(tf.keras.metrics.Metric):

  def __init__(self, name='my_custom_metric', **kwargs):
    super(MyCustomMetric, self).__init__(name=name, **kwargs)

  def update_state(self, y_true, y_pred, sample_weight=None):
    # ? is y_pred a list [batch_output_1, batch_output_2, batch_output_3] ? 

  def result(self):
    pass 

# one single metric handling the 3 outputs?
model.compile(optimizer=tf.compat.v1.train.RMSPropOptimizer(0.01),
              loss=tf.keras.losses.categorical_crossentropy,
              metrics=[MyCustomMetric()])

</code></pre>
","I can't find the info in the documentation so I am asking here. I have a multioutput model with 3 different outputs: The predicted labels for validation are constructed from these 3 outputs to form only one, it's a post-processing step. The dataset used for training is a dataset of those 3 intermediary outputs, for validation I evaluate on a dataset of labels instead of the 3 kind of intermediary data. I would like to evaluate my model using a custom metric that handle the post processing and comparaison with the ground truth. My question is, in the code of the custom metric, will y_pred be a list of the 3 outputs of the model?",https://stackoverflow.com/questions/59968630,7483509,Lack of Alternative Solutions/Documentation,Documentation Completeness,I can't find the info in the documentation so I am asking here.
61302405,"TensorFlow2 beginner, recalculating after assigning new value","<p>I'm new to TensorFlow (using TensorFlow2). <br/>
Trying to understand how to re-calculate a simple calculation, after re-assigning a value to variable. It sounds simple, but I'm having a hard time finding it in the new TF2 documentation. <br/> <br/>
Simple example: define a tensor which is a sum two variables (3+4). Then, if I re-assign one of the variables, I'd like to re-use this ""sum tensor"" - making it re-calculate (without having to create a new ""sum tensor""). Is there a way to achieve this please? thank!</p>

<pre><code>v1 = tf.Variable(3)
v2 = tf.Variable(4)
sum1=tf.add(v1,v2)
print(""Original sum 3+4:"",sum1)   # This hows 7 as expected
v1.assign(9)
print(""Sum after re-assign"",sum1) # Fails, shows the old 7
</code></pre>
","I'm new to TensorFlow (using TensorFlow2). Trying to understand how to re-calculate a simple calculation, after re-assigning a value to variable. It sounds simple, but I'm having a hard time finding it in the new TF2 documentation. Simple example: define a tensor which is a sum two variables (3+4). Then, if I re-assign one of the variables, I'd like to re-use this ""sum tensor"" - making it re-calculate (without having to create a new ""sum tensor""). Is there a way to achieve this please? thank!",https://stackoverflow.com/questions/61302405,13353258,Lack of Alternative Solutions/Documentation,Documentation Completeness,"It sounds simple, but I'm having a hard time finding it in the new TF2 documentation."
61882452,Tensorflow tf.layer.batch_normalization: how to use global moving stats to do normalization during training?,"<p>From the documentation, the arg training</p>

<blockquote>
  <p>Either a Python boolean, or a TensorFlow boolean scalar tensor (e.g. a placeholder). Whether to return the output in training mode (normalized with statistics of the current batch) or in inference mode (normalized with moving statistics). NOTE: make sure to set this parameter correctly, or else your training/inference will not work properly.</p>
</blockquote>

<p>It never mentioned that this arg also controls whether to update global moving stats. Even if the update ops is added through </p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'train_model') 
with tf.control_dependencies(update_ops):
    train_ops = ...
</code></pre>

<p>they will not be updated is <code>training=False</code>. I am curious if there is a way to have these moving stats keep updating during training, at the same time use them to perform normalization?</p>
","From the documentation, the arg training It never mentioned that this arg also controls whether to update global moving stats. Even if the update ops is added through they will not be updated is training=False. I am curious if there is a way to have these moving stats keep updating during training, at the same time use them to perform normalization?",https://stackoverflow.com/questions/61882452,11111055,Documentation Completeness,Documentation Completeness,"From the documentation, the arg training It never mentioned that this arg also controls whether to update global moving stats."
63645132,Normalizing difference between x_train /= 255.0 and x_train = x_train/255.0,"<p>I have some simple code, which loads the mnist data and normalizes the images.</p>
<pre><code>    mnist = tf.keras.datasets.mnist

    (x_train, y_train),(x_test, y_test) = mnist.load_data()
    x_train = x_train/255.0
    x_test = x_test/255.0

</code></pre>
<p>The code above works, however, if I try to use the shorthand for division, I get an error:</p>
<pre><code>    mnist = tf.keras.datasets.mnist

    (x_train, y_train),(x_test, y_test) = mnist.load_data()
    x_train /= 255.0
    x_test /= 255.0
</code></pre>
<p>The error is as follows:
<code>TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind''</code></p>
<p>By playing around, I found a fix to it, in that typecasting <code>x_train</code> to <code>float32</code>, would get rid of the error, but I only stumbled upon the fix by accident. I don't understand why the code below fixes the issue</p>
<pre><code>    mnist = tf.keras.datasets.mnist

    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)
    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')
    x_train /= 255.0
    x_test /= 255.0
</code></pre>
<p>Could someone explain what's happening here? Why do the two versions behave differently? Why's an explicit case required in the second instance but not the first?
<br> I didn't have much luck finding this behaviour documented anywhere.</p>
<p>Edit: I'm not sure what additional 'debugging details' I'm required to provide, since I've basically provided the entire code, the results as well as the details which I did not understand. I've also received no comments explaining why the question was closed, and/or what additional information is expected here. I would like some constructive criticism so as to atleast be able to ask the question in a better manner, if the present form isn't satisfactory by itself.</p>
","I have some simple code, which loads the mnist data and normalizes the images. The code above works, however, if I try to use the shorthand for division, I get an error: The error is as follows: TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind'' By playing around, I found a fix to it, in that typecasting x_train to float32, would get rid of the error, but I only stumbled upon the fix by accident. I don't understand why the code below fixes the issue Could someone explain what's happening here? Why do the two versions behave differently? Why's an explicit case required in the second instance but not the first? I didn't have much luck finding this behaviour documented anywhere. Edit: I'm not sure what additional 'debugging details' I'm required to provide, since I've basically provided the entire code, the results as well as the details which I did not understand. I've also received no comments explaining why the question was closed, and/or what additional information is expected here. I would like some constructive criticism so as to atleast be able to ask the question in a better manner, if the present form isn't satisfactory by itself.",https://stackoverflow.com/questions/63645132,12279039,Lack of Alternative Solutions/Documentation,Documentation Completeness,I didn't have much luck finding this behaviour documented anywhere.
64451250,How to load a Tensorflow model saved with make_image_classifier tool,"<p>I've made a custom image classifier model using a Tensorflow tool called make_image_classifier
<a href=""https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier"" rel=""nofollow noreferrer"">https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier</a></p>
<p>Now the model is exported into a .pb file and also 2 folders, assets and variables.</p>
<p>The question is how can I use this custom model to make predictions?
I've gone through all TF documentation and have tried many different things over these days but found no solution.</p>
<p>Someone wrote about it when he found no clear information, so he created a guide but it also doesn't work for me. In &quot;step 3&quot; its all the code required to load the module and classify an image using the custom model. The problem with this is I need to know the name of the input and output node, and I don't have them. I've tried to find them using Netron but it didn't work.
<a href=""https://heartbeat.fritz.ai/automl-vision-edge-exporting-and-loading-tensorflow-saved-models-with-python-f4e8ce1b943a"" rel=""nofollow noreferrer"">https://heartbeat.fritz.ai/automl-vision-edge-exporting-and-loading-tensorflow-saved-models-with-python-f4e8ce1b943a</a></p>
<pre><code>import tensorflow as tf
export_path = '/Users/aayusharora/Aftershoot/backend/loadmodel/models/'
with tf.Session(graph=tf.Graph()) as sess:
  tf.saved_model.loader.load(sess, ['serve'], export_path)
path = '/Users/aayusharora/Aftershoot/backend/sampleImage.jpg'
with open(path, &quot;rb&quot;) as img_file:
  y_pred = sess.run('tile:0', feed_dict={'normalised_input_image_tensor': [img_file.read()] })
print(y_pred)
</code></pre>
<p>Can someone please give me a clue about how to load a saved model and use it to make predictions?</p>
","I've made a custom image classifier model using a Tensorflow tool called make_image_classifier https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier Now the model is exported into a .pb file and also 2 folders, assets and variables. The question is how can I use this custom model to make predictions? I've gone through all TF documentation and have tried many different things over these days but found no solution. Someone wrote about it when he found no clear information, so he created a guide but it also doesn't work for me. In ""step 3"" its all the code required to load the module and classify an image using the custom model. The problem with this is I need to know the name of the input and output node, and I don't have them. I've tried to find them using Netron but it didn't work. https://heartbeat.fritz.ai/automl-vision-edge-exporting-and-loading-tensorflow-saved-models-with-python-f4e8ce1b943a Can someone please give me a clue about how to load a saved model and use it to make predictions?",https://stackoverflow.com/questions/64451250,14351825,Documentation Completeness,Documentation Completeness,I've gone through all TF documentation and have tried many different things over these days but found no solution.
65441499,Tensorflow: Too many dimensions,"<p>I'm trying to create a TensorFlow (2.0) variable like this:</p>
<pre><code>c_init = tf.zeros_initializer()
c = tf.Variable(initial_value=c_init(shape=shape, dtype=&quot;float32&quot;), trainable=True)
</code></pre>
<p>the shape variable is this:</p>
<pre><code>shape=(49, 52, 26, 49, 6, 3, 31, 11, 24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
</code></pre>
<p>I'm getting this error message:</p>
<blockquote>
<p>InvalidArgumentError: Too many dimensions [Op:Fill] name: zeros/</p>
</blockquote>
<p>I did not know there is a limit in the number of dimensions. I did not see anything in TensorFlow documentation about it. Is there any way to get around this limitation?</p>
",I'm trying to create a TensorFlow (2.0) variable like this: the shape variable is this: I'm getting this error message: I did not know there is a limit in the number of dimensions. I did not see anything in TensorFlow documentation about it. Is there any way to get around this limitation?,https://stackoverflow.com/questions/65441499,67120,Documentation Completeness,Documentation Completeness,I did not see anything in TensorFlow documentation about it.
66667080,Convert a KerasTensor object to a numpy array to visualize predictions in Callback,"<p>I am writing a custom on_train_end callback function for model.fit() method of tensorflow keras sequential model. The callback function is about plotting the predictions that the model makes, so it involves converting the inputs of the model to a numpy array and feeds it into model.predict(). I use self.model.inputs to access the inputs, which is a list of KerasTensor objects and the one at 0th index is what I want. I tried the following approach</p>
<pre><code>class my_visualizer(tf.keras.callbacks.Callback):

    def on_train_end(self, logs=None):

        x = tf.keras.backend.eval(self.model.inputs[0])
        y_predictions = self.model.predict(x)
        
</code></pre>
<p>but got the error</p>
<pre><code>AttributeError: 'KerasTensor' object has no attribute 'numpy'
</code></pre>
<p>So this method is for another type of tensor rather than KerasTensor. Other solutions I found work for tensorflow's Tensor object but not keras' KerasTensor object, and I did not find any mentioning of the ways to achieve the desired feature in keras documentation. Thanks for your help!</p>
","I am writing a custom on_train_end callback function for model.fit() method of tensorflow keras sequential model. The callback function is about plotting the predictions that the model makes, so it involves converting the inputs of the model to a numpy array and feeds it into model.predict(). I use self.model.inputs to access the inputs, which is a list of KerasTensor objects and the one at 0th index is what I want. I tried the following approach but got the error So this method is for another type of tensor rather than KerasTensor. Other solutions I found work for tensorflow's Tensor object but not keras' KerasTensor object, and I did not find any mentioning of the ways to achieve the desired feature in keras documentation. Thanks for your help!",https://stackoverflow.com/questions/66667080,12345152,Documentation Completeness,Documentation Completeness,I did not find any mentioning of the ways to achieve the desired feature in keras documentation.
71245237,tensorflow : @ symbol,"<p>I saw a code snippet in the tensorflow documentation and couldn't find any info about it
So, what is the role/purpose of the <code>@</code> symbol at the code below :</p>
<pre><code>x @ tf.transpose(x)
</code></pre>
","I saw a code snippet in the tensorflow documentation and couldn't find any info about it So, what is the role/purpose of the @ symbol at the code below :",https://stackoverflow.com/questions/71245237,14118985,Documentation Ambiguity,Documentation Completeness,I saw a code snippet in the tensorflow documentation and couldn't find any info about it
71543827,understanding tensorflow Recommending movies: retrieval / usage of : in python class /usage of : in python function,"<p>I was reading and trying to work with below documentation from tensorflow
<a href=""https://www.tensorflow.org/recommenders/examples/basic_retrieval?hl=sl"" rel=""nofollow noreferrer"">https://www.tensorflow.org/recommenders/examples/basic_retrieval?hl=sl</a></p>
<p>In this we have implementation of <code>MovielenseModel</code> class. Let me provide snippet of same code below</p>
<pre><code>class MovielensModel(tfrs.Model):

  def __init__(self, user_model, movie_model):
    super().__init__()
    self.movie_model: tf.keras.Model = movie_model
    self.user_model: tf.keras.Model = user_model
    self.task: tf.keras.layers.Layer = task

  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -&gt; tf.Tensor:
    # We pick out the user features and pass them into the user model.
    user_embeddings = self.user_model(features[&quot;user_id&quot;])
    # And pick out the movie features and pass them into the movie model,
    # getting embeddings back.
    positive_movie_embeddings = self.movie_model(features[&quot;movie_title&quot;])

    # The task computes the loss and the metrics.
    return self.task(user_embeddings, positive_movie_embeddings)
</code></pre>
<p>In this one usages are not clear and could not find much help in any online documentations</p>
<ol>
<li>Usage of <code>self.movie_model: tf.keras.Model = movie_model</code> . Looks like its first class object implementation of function but how does this work? When I simply tried <code>d:c=3</code>, just to replicate it worked fine <code>d</code> gets value 3 and <code>c</code> its saying as undefined.</li>
</ol>
",I was reading and trying to work with below documentation from tensorflow https://www.tensorflow.org/recommenders/examples/basic_retrieval?hl=sl In this we have implementation of MovielenseModel class. Let me provide snippet of same code below In this one usages are not clear and could not find much help in any online documentations,https://stackoverflow.com/questions/71543827,12271381,Documentation Ambiguity,Documentation Completeness,In this one usages are not clear and could not find much help in any online documentations
73359572,normalize trained data with tensorflow,"<p>this is the code from the TensorFlow website, but doesn't explain well,</p>
<pre><code>normalization_layer = tf.keras.layers.Rescaling(1./255)
train_data = train_data.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.
</code></pre>
<p>i know what is the goal of this code which is to normalize data and make it between 0 and 1 instead of 0 to 255, but I need to understand what does lambda means here.</p>
","this is the code from the TensorFlow website, but doesn't explain well, i know what is the goal of this code which is to normalize data and make it between 0 and 1 instead of 0 to 255, but I need to understand what does lambda means here.",https://stackoverflow.com/questions/73359572,4399890,Documentation Ambiguity,Documentation Completeness,"This is the code from the TensorFlow website, but doesn't explain well."
73629508,Keras Model.fit() TypeError: __init__() missing 1 required positional argument: 'normalizer',"<p>I am attempting to build a sequential model in Keras and use it to do image classification. I am getting the following error in the Anaconda3 (Python 3.9) terminal and haven't been able to track down the cause:</p>
<pre><code>(tf) &gt;python image_classification.py 10

Building Sequential Model ...

Compiling ...

Fitting Sequential Model with (X_train, Y_train) ...

Epoch 1/10
Traceback (most recent call last):
  File &quot;C:\%\image_classification.py&quot;, line 121, in &lt;module&gt;
    high_level_neural_net(X_train, Y_train, X_test, Y_test,  M, Nnodes1, Nnodes2, inject_layer, af, MAKE_PLOTS)
  File &quot;C:\%\image_classification.py&quot;, line 67, in high_level_neural_net
    model.fit(x=X_train, y=Y_train, epochs=M)
  File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\utils\traceback_utils.py&quot;, line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File &quot;C:\%\AppData\Local\Temp\__autograph_generated_filev98m50s2.py&quot;, line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
TypeError: in user code:

    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\training.py&quot;, line 1051, in train_function  *
        return step_function(self, iterator)
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\training.py&quot;, line 1040, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\training.py&quot;, line 1030, in run_step  **
        outputs = model.train_step(data)
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\training.py&quot;, line 894, in train_step
        return self.compute_metrics(x, y, y_pred, sample_weight)
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\training.py&quot;, line 987, in compute_metrics
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\compile_utils.py&quot;, line 480, in update_state
        self.build(y_pred, y_true)
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\compile_utils.py&quot;, line 393, in build
        self._metrics = tf.__internal__.nest.map_structure_up_to(
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\compile_utils.py&quot;, line 526, in _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\compile_utils.py&quot;, line 526, in &lt;listcomp&gt;
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\engine\compile_utils.py&quot;, line 545, in _get_metric_object
        metric_obj = metrics_mod.get(metric)
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\metrics\__init__.py&quot;, line 182, in get
        return deserialize(str(identifier))
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\metrics\__init__.py&quot;, line 138, in deserialize
        return deserialize_keras_object(
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\utils\generic_utils.py&quot;, line 718, in deserialize_keras_object
        return obj()
    File &quot;C:\%\Anaconda3\envs\tf\lib\site-packages\keras\dtensor\utils.py&quot;, line 141, in _wrap_function
        init_method(instance, *args, **kwargs)

    TypeError: __init__() missing 1 required positional argument: 'normalizer'

</code></pre>
<p>So far, I haven't seen the 'normalizer' argument mentioned in the Tensorflow/Keras documentation or on the stackoverflow forums. Here is my source code:</p>
<pre><code>import os
import sys
import math
import scipy as sp
import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

def get_dataset():
    
    SHOW_IMAGE = False

    mnist = tf.keras.datasets.mnist     # 28x28 images of hand-written digits 0-9
    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
    
    X_train = tf.keras.utils.normalize(X_train,axis=1)  # Normalize input datasets between 0 and 1, Helps the NN converge.
    X_test = tf.keras.utils.normalize(X_test,axis=1)

    if (SHOW_IMAGE):
        plt.imshow(X_train[0])
        plt.show()
        input()
        plt.imshow(Y_train[0])
        plt.show()
        input()

    return X_train, Y_train, X_test, Y_test

def high_level_neural_net(X_train, Y_train, X_test, Y_test, M, Nnodes1, Nnodes2, inject_layer, af, MAKE_PLOTS):
    
    class InjectInputCallback(tf.keras.callbacks.Callback):

        # Inject input data to layer between residual blocks; I'm unsure if this works yet.

        def __init__(self,train_dataset,layer,logs=None):
            self.first_trainds = train_dataset
            self.inject_layer = layer

        def on_layer_end(self,layer,logs=None):
            model.layers[self.inject_layer].output = model.layers[self.inject_layer].output + self.first_trainds
           
    print('\n')
    
    print('Building Sequential Model ...\n')
   
    model = Sequential()
    model.add(Flatten())
    model.add(Dense(Nnodes2, activation=tf.nn.relu))                                   # Residual block 1 (hidden layers) 
    model.add(Dense(Nnodes2, activation=tf.nn.relu))                                   # ...
    model.add(Dense(10, activation=tf.nn.relu))                                         # Output layer of residual block 1/Input layer of residual block 2
    model.add(Dense(Nnodes2, activation=tf.nn.relu))                                   # Residual block 2 (hidden layers)
    model.add(Dense(Nnodes2, activation=tf.nn.relu))                                   # ...
    model.add(Dense(10, activation=tf.nn.relu))                                 # Output layer of residual block 2/Output of neural net 

    print('Compiling ...\n')
    model.compile(optimizer=Adam(learning_rate=0.001),  # Uses Adam algorithm as loss function optimizer
                 loss='MeanSquaredError',                                  # sets the model to use MSE as loss function during training
                 metrics=['MeanRelativeError'])                            
    
    print('Fitting Sequential Model with (X_train, Y_train) ...\n') 
    
    #tf.print('X_train = ', X_train, 'with shape', tf.shape(X_train), '\n')
    #tf.print('Y_train = ', Y_train, 'with shape', tf.shape(Y_train), '\n')

    model.fit(x=X_train, y=Y_train, epochs=M)
    #callbacks=[InjectInputCallback(X_train,inject_layer)]

    if (MAKE_PLOTS):
        plt.plot(history.history['MeanSquareError'])
        plt.title('Model Training')
        plt.ylabel('Mean Squared Error')
        plt.xlabel('Epoch')
        plt.legend(['X_Train','Y_Train'], loc='upper right')
        plt.show()

    #print('Evaluating Sequential Model with Analytic Solution...')
    #model.evaluate()
    
    #print('Predicting')
    #model.predict()

    model.build(tf.shape(X_train)) 
    tf.print(model.summary())

if (__name__ == &quot;__main__&quot;):
 
    print(&quot;\n&quot;)

    MAKE_PLOTS = True               # Turns on plots during training and evaluation of neural net

    M = int(sys.argv[1])            # Number of training iterations
   
    Ninputs = 3             # Number of node inputs
    Nnodes1 = 10            # Number of nodes in layers
    Nnodes2 = 30            # Number of nodes in 2nd and 4th layers
    inject_layer = 3        # layer of neural net where we inject input data to output of layer

    X_train, Y_train, X_test, Y_test = get_dataset()
    high_level_neural_net(X_train, Y_train, X_test, Y_test,  M, Nnodes1, Nnodes2, inject_layer, af, MAKE_PLOTS)
</code></pre>
","I am attempting to build a sequential model in Keras and use it to do image classification. I am getting the following error in the Anaconda3 (Python 3.9) terminal and haven't been able to track down the cause: So far, I haven't seen the 'normalizer' argument mentioned in the Tensorflow/Keras documentation or on the stackoverflow forums. Here is my source code:",https://stackoverflow.com/questions/73629508,19936707,Documentation Completeness,Documentation Completeness,I haven't seen the 'normalizer' argument mentioned in the Tensorflow/Keras documentation or on the stackoverflow forums.
74481219,How to get number of values in each row of a sparse tensor?,"<p>I have a Sparse Tensor as follows:</p>
<pre><code>st = tf.sparse.from_dense([[1, 0, 2, 5], [3, 0, 0, 4], [0, 0, 0, 0], [1, 1, 3, 0], [1, 2, 2, 2]])
print(st)
</code></pre>
<pre><code>SparseTensor(indices=tf.Tensor(
[[0 0]
 [0 2]
 [0 3]
 [1 0]
 [1 3]
 [3 0]
 [3 1]
 [3 2]
 [4 0]
 [4 1]
 [4 2]
 [4 3]], shape=(12, 2), dtype=int64), values=tf.Tensor([1 2 5 3 4 1 1 3 1 2 2 2], shape=(12,), dtype=int32), dense_shape=tf.Tensor([5 4], shape=(2,), dtype=int64))
</code></pre>
<p>I want to convert this sparse tensor to another 1D tensor of shape <code>(5, 1)</code> where the only column represents the number (or size) of values in each of the rows.</p>
<p>For example, for the above sparse tensor, desired 1D tensor would be <code>[3, 2, 0, 3, 4]</code>.</p>
<p>How can I do it?</p>
<p>I tried going through the TensorFlow API docs but couldn't find anything to try.</p>
","I have a Sparse Tensor as follows: I want to convert this sparse tensor to another 1D tensor of shape (5, 1) where the only column represents the number (or size) of values in each of the rows. For example, for the above sparse tensor, desired 1D tensor would be [3, 2, 0, 3, 4]. How can I do it? I tried going through the TensorFlow API docs but couldn't find anything to try.",https://stackoverflow.com/questions/74481219,3243499,Documentation Completeness,Documentation Completeness,I tried going through the TensorFlow API docs but couldn't find anything to try.
75963463,reshaping logits to dim 1,"<p>I am currently working on a T5 model which I am trying to fine-tune. On the training step, I get my outputs, get my loss, and try to update the state of my metric. However, in order to update the state of the metric I am required to use a 1-D array.</p>
<p>From the documentation: &quot;Both
prediction and labels must be 1-D arrays of the same shape in order for this
function to work.&quot;</p>
<p>My question is, is there a recommended way to reshape my outputs.logits variable? it currently has a shape of (8, 2, 32128) and would like to bring it 8. I have tried the argmax function, and softmax but had no luck. Any ideas would be appreciated.</p>
<p>Code:</p>
<pre><code>model_name = 't5-base'
t5_model = TFT5ForConditionalGeneration.from_pretrained(model_name)
t5_tokenizer = T5Tokenizer.from_pretrained(model_name)

def train_step(self, inputs):
  input_ids = inputs['input_ids']
  attention_mask = inputs['attention_mask']
  labels = inputs['labels']
  labels_mask = inputs['labels_mask']
  with tf.GradientTape() as tape:
    outputs = self(input_ids=input_ids,
                       attention_mask=attention_mask,
                       labels=labels,
                       decoder_attention_mask=labels_mask,
                       training=True
                  )
    loss = self.compiled_loss(labels, outputs.logits, regularization_losses=self.losses)
    
  self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
  self.compiled_metrics.update_state(labels, outputs.logits) ## issue happens here
  return_metrics = {}
  for metric in self.metrics:
    result = metric.result()
    if isinstance(result, dict):
        return_metrics.update(result)
    else:
        return_metrics[metric.name] = result
  if &quot;loss&quot; in return_metrics and &quot;loss_loss&quot; in return_metrics:
    del return_metrics[&quot;loss_loss&quot;]
  return return_metrics
</code></pre>
","I am currently working on a T5 model which I am trying to fine-tune. On the training step, I get my outputs, get my loss, and try to update the state of my metric. However, in order to update the state of the metric I am required to use a 1-D array. From the documentation: ""Both prediction and labels must be 1-D arrays of the same shape in order for this function to work."" My question is, is there a recommended way to reshape my outputs.logits variable? it currently has a shape of (8, 2, 32128) and would like to bring it 8. I have tried the argmax function, and softmax but had no luck. Any ideas would be appreciated. Code:",https://stackoverflow.com/questions/75963463,1261440,Requesting (Additional) Resources,Documentation Completeness,"From the documentation: ""Both prediction and labels must be 1-D arrays of the same shape in order for this function to work."" My question is, is there a recommended way to reshape my outputs.logits variable?"
38510339,the usage or API of tf.app.flags,"<p>When reading the <a href=""https://github.com/tensorflow/tensorflow/blob/e008ecf12607f691952a9bfe8971f406b30bc56e/tensorflow/models/image/cifar10/cifar10_train.py#L129"" rel=""nofollow"">cifar10 example</a>, I can see the following code segment, which is said to follow the google  commandline standard. But in specific, what does this code segment do? I did not find the API document to cover something like <code>tf.app.flags.DEFINE_string</code></p>

<pre><code>FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',
                       """"""Directory where to write event logs """"""
                       """"""and checkpoint."""""")
tf.app.flags.DEFINE_integer('max_steps', 1000000,
                        """"""Number of batches to run."""""")
tf.app.flags.DEFINE_boolean('log_device_placement', False,
                        """"""Whether to log device placement."""""")
</code></pre>
","When reading the cifar10 example, I can see the following code segment, which is said to follow the google commandline standard. But in specific, what does this code segment do? I did not find the API document to cover something like tf.app.flags.DEFINE_string",https://stackoverflow.com/questions/38510339,288609,Documentation Completeness,Documentation Completeness,I did not find the API document to cover something like tf.app.flags.DEFINE_string
39657063,Is the collection in tensorflow.get_collection() cleared?,"<p>I'm learning about neural nets using Tensorflow through the Stanford course. I found this while implementing a RNN and did not quite understand why the losses are accumulated:</p>

<pre class=""lang-python prettyprint-override""><code># This adds a loss operation to the Graph for batch training
def add_loss_op(self, output):
    all_ones = [tf.ones([self.config.batch_size * self.config.num_steps])]
    cross_entropy = sequence_loss(
        [output], [tf.reshape(self.labels_placeholder, [-1])], all_ones, len(self.vocab))
    tf.add_to_collection('total_loss', cross_entropy)
    # Doesn't this increase in size every batch of training?
    loss = tf.add_n(tf.get_collection('total_loss')) 
    return loss
</code></pre>

<p>The documentation for <code>get_collection()</code>  <a href=""https://www.tensorflow.org/versions/r0.10/api_docs/python/framework.html#Graph.get_collection"" rel=""nofollow"">here</a> doesn't mention anything about clearing the variables. Since this is run for every training step, are the losses incremented every epoch / minibatch of training and carried over? </p>

<p>I am still new to NNs so do correct any misunderstanding I have on this!</p>
","I'm learning about neural nets using Tensorflow through the Stanford course. I found this while implementing a RNN and did not quite understand why the losses are accumulated: The documentation for get_collection() here doesn't mention anything about clearing the variables. Since this is run for every training step, are the losses incremented every epoch / minibatch of training and carried over? I am still new to NNs so do correct any misunderstanding I have on this!",https://stackoverflow.com/questions/39657063,4207476,Documentation Completeness,Documentation Completeness,The documentation for get_collection() here doesn't mention anything about clearing the variables.
36227354,Saving tensorflow model after training is finished,"<p>I have finished running a big model in tensorflow python. But I have not saved it inside the session. Now that the training is over, I want to save the variables. I am doing the following: </p>

<pre><code>saver=tf.train.Saver()
with tf.Session(graph=graph) as sess:  
    save_path = saver.save(sess, ""86_model.ckpt"")
    print(""Model saved in file: %s"" % save_path)
</code></pre>

<p>This returns : ValueError: No variables to save. According to their website what is missing is initialize_all_variables(). The documentation says little about what exactly that does. The word ""initialize"" scares me, I do not want to reset all my trained values. Any way to save my model without re-running it? </p>
","I have finished running a big model in tensorflow python. But I have not saved it inside the session. Now that the training is over, I want to save the variables. I am doing the following: This returns : ValueError: No variables to save. According to their website what is missing is initialize_all_variables(). The documentation says little about what exactly that does. The word ""initialize"" scares me, I do not want to reset all my trained values. Any way to save my model without re-running it?",https://stackoverflow.com/questions/36227354,3761534,Documentation Ambiguity,Documentation Completeness,According to their website what is missing is initialize_all_variables(). The documentation says little about what exactly that does.
51330841,How to save and restore a tf.estimator.Estimator model with export_savedmodel?,"<p>I started using Tensorflow recently and I try to get use to tf.estimator.Estimator objects. I would like to do something a priori quite natural: after having trained my classifier, i.e. an instance of tf.estimator.Estimator (with the <code>train</code> method), I would like to save it in a file (whatever the extension) and then reload it later to predict the labels for some new data. Since the official documentation recommends to use Estimator APIs, I guess something as important as that should be implemented and documented.</p>

<p>I saw on some other page that the method to do that is <code>export_savedmodel</code> (see <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Estimator#export_savedmodel"" rel=""nofollow noreferrer"">the official documentation</a>) but I simply don't understand the documentation. There is no explanation of how to use this method. What is the argument <code>serving_input_fn</code>? I never encountered it in the <a href=""https://www.tensorflow.org/guide/custom_estimators"" rel=""nofollow noreferrer"">Creating Custom Estimators</a> tutorial or in any of the tutorials that I read. By doing some googling, I discovered that around a year ago the estimators where defined using an other class (<code>tf.contrib.learn.Estimator</code>) and it looks like the tf.estimator.Estimator is reusing some of the previous APIs. But I don't find clear explanations in the documentation about it.</p>

<p>Could someone please give me a toy example? Or explain me how to define/find this <code>serving_input_fn</code>?</p>

<p>And then how would be load the trained classifier again?</p>

<p>Thank you for your help!</p>

<p><strong>Edit:</strong> I discovered that one doesn't necessarily need to use export_savemodel to save the model. It is actually done automatically. Then if we define later a new estimator having the same model_dir argument, it will also automatically restore the previous estimator, as explained <a href=""https://www.tensorflow.org/guide/checkpoints"" rel=""nofollow noreferrer"">here</a>.</p>
","I started using Tensorflow recently and I try to get use to tf.estimator.Estimator objects. I would like to do something a priori quite natural: after having trained my classifier, i.e. an instance of tf.estimator.Estimator (with the train method), I would like to save it in a file (whatever the extension) and then reload it later to predict the labels for some new data. Since the official documentation recommends to use Estimator APIs, I guess something as important as that should be implemented and documented. I saw on some other page that the method to do that is export_savedmodel (see the official documentation) but I simply don't understand the documentation. There is no explanation of how to use this method. What is the argument serving_input_fn? I never encountered it in the Creating Custom Estimators tutorial or in any of the tutorials that I read. By doing some googling, I discovered that around a year ago the estimators where defined using an other class (tf.contrib.learn.Estimator) and it looks like the tf.estimator.Estimator is reusing some of the previous APIs. But I don't find clear explanations in the documentation about it. Could someone please give me a toy example? Or explain me how to define/find this serving_input_fn? And then how would be load the trained classifier again? Thank you for your help! Edit: I discovered that one doesn't necessarily need to use export_savemodel to save the model. It is actually done automatically. Then if we define later a new estimator having the same model_dir argument, it will also automatically restore the previous estimator, as explained here.",https://stackoverflow.com/questions/51330841,8733572,Requesting (Additional) Resources,Documentation Completeness, There is no explanation of how to use this method.
52157213,Tensorflow tf.placeholder with shape = [],"<p>I am looking at a Tensorflow code that has learning rate input to the graph using placeholder with shape = [], as below:</p>

<pre><code>self.lr_placeholder = tf.placeholder(dtype=tf.float32, shape=[])
</code></pre>

<p>I looked at the official documentation page of Tensorflow (<a href=""https://www.tensorflow.org/api_docs/python/tf/placeholder"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/placeholder</a>) to understand what would shape=[] mean, but could not get an explanation for the shape set to empty list. If someone can explain what does this mean.</p>
","I am looking at a Tensorflow code that has learning rate input to the graph using placeholder with shape = [], as below: I looked at the official documentation page of Tensorflow (https://www.tensorflow.org/api_docs/python/tf/placeholder) to understand what would shape=[] mean, but could not get an explanation for the shape set to empty list. If someone can explain what does this mean.",https://stackoverflow.com/questions/52157213,7561372,Documentation Completeness,Documentation Completeness,"I looked at the official documentation page of Tensorflow (https://www.tensorflow.org/api_docs/python/tf/placeholder) to understand what would shape=[] mean, but could not get an explanation for the shape set to empty list."
45521499,legacy_init_op in TensorFlow Serving,"<p>I've noticed every example on TensorFlow Serving uses <code>legacy_init_op</code> parameter in <code>SavedModelBuilder</code> but I have not found any clear explanations on what this is and why it is called <strong>legacy</strong>. Anyone knows the purpose of this argument? </p>

<p>Example:</p>

<pre><code>legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')

builder.add_meta_graph_and_variables(
      sess, [tf.saved_model.tag_constants.SERVING],
      signature_def_map={
          'predict_images':
              prediction_signature,
          tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
              classification_signature,
      },
      legacy_init_op=legacy_init_op)
</code></pre>
",I've noticed every example on TensorFlow Serving uses legacy_init_op parameter in SavedModelBuilder but I have not found any clear explanations on what this is and why it is called legacy. Anyone knows the purpose of this argument? Example:,https://stackoverflow.com/questions/45521499,539617,Documentation Completeness,Documentation Completeness,I've noticed every example on TensorFlow Serving uses legacy_init_op parameter in SavedModelBuilder but I have not found any clear explanations on what this is and why it is called legacy.
53122412,AOT compilation of an Estimator,"<p>I find it very challenging to find in the documentation any help on this important issue.. Indeed, after creating an estimator (canned or custom), one wants to <code>tf.compile</code> the resulting predictor, produce the <code>.so</code> and link it to one's project..</p>

<p>So I have my calib class in which I define a simple linear estimator</p>

<pre><code>self.model = tf.estimator.LinearRegressor(
        feature_columns=self.feature_columns,
        model_dir = self.model_dir)
</code></pre>

<p>After training, I want to 
1- get the trained model with optimal parameters (load it in my variable self.model)</p>

<p>2- extract the graph and freeze it</p>

<p>3- tf.compile that graph</p>

<p>I could not find any way to do parts 1- and 2-. Once I have them, part 3 is solved by using tf.compile</p>

<p>Can you please point me to a good way to it?</p>
","I find it very challenging to find in the documentation any help on this important issue.. Indeed, after creating an estimator (canned or custom), one wants to tf.compile the resulting predictor, produce the .so and link it to one's project.. So I have my calib class in which I define a simple linear estimator After training, I want to 1- get the trained model with optimal parameters (load it in my variable self.model) 2- extract the graph and freeze it 3- tf.compile that graph I could not find any way to do parts 1- and 2-. Once I have them, part 3 is solved by using tf.compile Can you please point me to a good way to it?",https://stackoverflow.com/questions/53122412,886724,Documentation Completeness,Documentation Completeness,I find it very challenging to find in the documentation any help on this important issue.
44313202,What are the 'from' and 'to' dimensions of transition_params in tf.contrib.crf.crf_log_likelihood?,"<p>On TensorFlow, I want to pass a transition_params matrix as argument to <code>tf.contrib.crf.crf_log_likelihood</code> (<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/crf/crf_log_likelihood"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/crf/crf_log_likelihood</a>), in order to initialize the transitions matrix of the CRF. Although, in the documentation, it is not clear which dimension of this matrix corresponds to the first tag of the transition and which dimension corresponds to the second.</p>

<p>So, let <code>T</code> be the transitions matrix, does <code>T[i,j]</code> represent the score of the transition from tag <code>i</code> to tag <code>j</code>, or is it the other way around?</p>
","On TensorFlow, I want to pass a transition_params matrix as argument to tf.contrib.crf.crf_log_likelihood (https://www.tensorflow.org/api_docs/python/tf/contrib/crf/crf_log_likelihood), in order to initialize the transitions matrix of the CRF. Although, in the documentation, it is not clear which dimension of this matrix corresponds to the first tag of the transition and which dimension corresponds to the second. So, let T be the transitions matrix, does T[i,j] represent the score of the transition from tag i to tag j, or is it the other way around?",https://stackoverflow.com/questions/44313202,1868775,Documentation Completeness,Documentation Completeness,"Although, in the documentation, it is not clear which dimension of this matrix corresponds to the first tag of the transition and which dimension corresponds to the second."
45155864,Tensorflow LinearRegressor not converging,"<p>I'm attempting to do a toy linear regression in Python with TensorFlow, using the pre-built estimator tf.contrib.learn.LinearRegressor instead of building my own estimator. 
The inputs I'm using are real-valued numbers between 0 and 1, and the outputs are just 3*inputs. TensorFlow seems to fit the data (no errors raised), but the outputs have no correlation to what they should be.</p>

<p>I'm not sure I'm getting the predictions done correctly- the documentation for the predict() function is pretty sparse.</p>

<p>Any ideas for how to improve the fitting?</p>

<pre><code>import numpy as np
import pandas as pd
import tensorflow as tf
import itertools
import matplotlib.pyplot as plt

#Defining data set
x = np.random.rand(200)
y = 3.0*x
data = pd.DataFrame({'X':x, 'Y':y})
training_data = data[50:]
test_data= data[:50]

COLUMNS = ['Y','X']
FEATURES = ['X']
LABELS = 'Y'

#Wrapper function for the inputs of LinearRegressor
def get_input_fn(data_set, num_epochs=None, shuffle=True):
  return tf.estimator.inputs.pandas_input_fn(
      x=pd.DataFrame(data_set[FEATURES]),
      y=pd.Series(data_set[LABELS]),
      num_epochs=num_epochs,
      shuffle=shuffle)


feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]
regressor = tf.contrib.learn.LinearRegressor(feature_columns=feature_cols)
regressor.fit(input_fn=get_input_fn(test_data), steps=100)

results = regressor.predict(input_fn=get_input_fn(test_data, 
num_epochs=1))
predictions = list(itertools.islice(results, 50))

#Visualizing the results
fig = plt.figure(figsize=[8,8])
ax = fig.add_subplot(111)
ax.scatter(test_data[LABELS], predictions)

ax.set_xlabel('Actual')
ax.set_ylabel('Predicted')
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/IGI8o.png"" rel=""nofollow noreferrer"">Scatter plot of results</a></p>
","I'm attempting to do a toy linear regression in Python with TensorFlow, using the pre-built estimator tf.contrib.learn.LinearRegressor instead of building my own estimator. The inputs I'm using are real-valued numbers between 0 and 1, and the outputs are just 3*inputs. TensorFlow seems to fit the data (no errors raised), but the outputs have no correlation to what they should be. I'm not sure I'm getting the predictions done correctly- the documentation for the predict() function is pretty sparse. Any ideas for how to improve the fitting? Scatter plot of results",https://stackoverflow.com/questions/45155864,1552018,Requesting (Additional) Resources,Documentation Completeness,The documentation for the predict() function is pretty sparse.
46821855,Got error when setting read_batch_size in tf.contrib.learn.read_batch_examples. default is ok,"<p>I modified code of the wide &amp; deep tutorial for reading large input from file using tf.contrib.learn.read_batch_examples. For speeding up the training process, I set the read_batch_size and got an error <strong>ValueError: All shapes must be fully defined: [TensorShape([]), TensorShape([Dimension(None)])]</strong>
My piece of code：</p>

<pre><code>def input_fn_pre(batch_size, filename):
  examples_op = tf.contrib.learn.read_batch_examples(
    filename,
    batch_size=5000,
    reader=tf.TextLineReader,
    num_epochs=5,
    num_threads=5,
    read_batch_size=2500,
    parse_fn=lambda x: tf.decode_csv(x, [tf.constant(['0'], dtype=tf.string)] * len(COLUMNS) * 2500, use_quote_delim=False))                                  
  examples_dict = {}

  for i, col in enumerate(COLUMNS):
    examples_dict[col] = examples_op[:, i]
  feature_cols = {k: tf.string_to_number(examples_dict[k], out_type=tf.float32) for k in CONTINUOUS_COLUMNS}
  feature_cols.update({k: dense_to_sparse(examples_dict[k]) for k in CATEGORICAL_COLUMNS})
  label = tf.string_to_number(examples_dict[LABEL_COLUMN], out_type=tf.int32)
  return feature_cols, label
</code></pre>

<p>while using the default parameter setting is ok:</p>

<pre><code>def input_fn_pre(batch_size, filename):
  examples_op = tf.contrib.learn.read_batch_examples(
    filename,
    batch_size=5000,
    reader=tf.TextLineReader,
    num_epochs=5,
    num_threads=5,
    parse_fn=lambda x: tf.decode_csv(x, [tf.constant(['0'], dtype=tf.string)] * len(COLUMNS), use_quote_delim=False))                                  
  examples_dict = {}

  for i, col in enumerate(COLUMNS):
    examples_dict[col] = examples_op[:, i]
  feature_cols = {k: tf.string_to_number(examples_dict[k], out_type=tf.float32) for k in CONTINUOUS_COLUMNS}
  feature_cols.update({k: dense_to_sparse(examples_dict[k]) for k in CATEGORICAL_COLUMNS})
  label = tf.string_to_number(examples_dict[LABEL_COLUMN], out_type=tf.int32)
  return feature_cols, label
</code></pre>

<p>There is not enough explanation in the tensorflow doc.</p>
","I modified code of the wide &amp; deep tutorial for reading large input from file using tf.contrib.learn.read_batch_examples. For speeding up the training process, I set the read_batch_size and got an error ValueError: All shapes must be fully defined: [TensorShape([]), TensorShape([Dimension(None)])] My piece of code： while using the default parameter setting is ok: There is not enough explanation in the tensorflow doc.",https://stackoverflow.com/questions/46821855,3004058,Documentation Completeness,Documentation Completeness,There is not enough explanation in the tensorflow doc.
41714318,Input parameters of tf.contrib.learn.read_batch_features,"<p>I am working through these tensorflow <a href=""https://github.com/dennybritz/chatbot-retrieval/tree/master/models%20&#39;codes&#39;"" rel=""nofollow noreferrer"">codes</a> which implement a LSTM in tensorflow. While going through the codes, I came across this function (in <a href=""https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_inputs.py"" rel=""nofollow noreferrer"">input_fn code</a> - line 38) <code>tf.contrib.learn.read_batch_features</code>. I looked up the documentation of <code>tf.contrib.learn.read_batch_features</code> <a href=""https://www.tensorflow.org/api_docs/python/contrib.learn/input_processing#read_batch_features"" rel=""nofollow noreferrer"">here</a>. This is what I got - </p>

<pre>
file_pattern: List of files or pattern of file paths containing Example records. 
batch_size: An int or scalar Tensor specifying the batch size to use.
features: A dict mapping feature keys to FixedLenFeature or VarLenFeature values.
randomize_input: Whether the input should be randomized.
num_epochs: Integer specifying the number of times to read through the dataset. If None, cycles through the dataset forever. NOTE - If specified, creates a variable that must be initialized, so call tf.local_variables_initializer() as shown in the tests.
queue_capacity: Capacity for input queue.
reader_num_threads: The number of threads to read examples.
name: Name of resulting op.
</pre>

<p>There are few input parameters that I am not able to understand and was hoping someone could help me with it.</p>

<ol>
<li><p>The <code>randomize_input</code> parameter. Does it mean it will shuffle the entire dataset?</p></li>
<li><p>For <code>num_epochs</code>, if I specify <code>None</code> does it mean that my <code>input_fn</code> will keep feeding to the <code>model_fn</code>. In that case the training wouldn't stop. This doesn't make sense to me. I guess I'm going wrong somewhere here.</p></li>
<li><p><code>queue_capacity</code> I am not sure what this means</p></li>
</ol>

<p>Would appreciate any help around these questions. Thanks in advance!</p>
","I am working through these tensorflow codes which implement a LSTM in tensorflow. While going through the codes, I came across this function (in input_fn code - line 38) tf.contrib.learn.read_batch_features. I looked up the documentation of tf.contrib.learn.read_batch_features here. This is what I got - There are few input parameters that I am not able to understand and was hoping someone could help me with it. Would appreciate any help around these questions. Thanks in advance!",https://stackoverflow.com/questions/41714318,2324298,Documentation Completeness,Documentation Completeness,I looked up the documentation of tf.contrib.learn.read_batch_features here. This is what I got - There are few input parameters that I am not able to understand and was hoping someone could help me with it.
48309631,TensorFlow - tf.data.Dataset reading large HDF5 files,"<p>I am setting up a TensorFlow pipeline for reading large HDF5 files as input for my deep learning models. Each HDF5 file contains 100 videos of variable size length stored as a collection of compressed JPG images (to make size on disk manageable). Using <code>tf.data.Dataset</code> and a map to <code>tf.py_func</code>, reading examples from the HDF5 file using custom Python logic is quite easy. For example:</p>

<pre><code>def read_examples_hdf5(filename, label):
    with h5py.File(filename, 'r') as hf:
        # read frames from HDF5 and decode them from JPG
    return frames, label

filenames = glob.glob(os.path.join(hdf5_data_path, ""*.h5""))
labels = [0]*len(filenames) # ... can we do this more elegantly?

dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.map(
    lambda filename, label: tuple(tf.py_func(
        read_examples_hdf5, [filename, label], [tf.uint8, tf.int64]))
)

dataset = dataset.shuffle(1000 + 3 * BATCH_SIZE)
dataset = dataset.batch(BATCH_SIZE)
iterator = dataset.make_one_shot_iterator()
next_batch = iterator.get_next()
</code></pre>

<p>This example works, however the problem is that it seems like <code>tf.py_func</code> can only handle one example at a time. As my HDF5 container stores 100 examples, this limitation causes significant overhead as the files constantly need to be opened, read, closed and reopened. It would be much more efficient to read all the 100 video examples into the dataset object and then move on with the next HDF5 file (preferably in multiple threads, each thread dealing with it's own collection of HDF5 files).</p>

<p>So, what I would like is a number of threads running in the background, reading video frames from the HDF5 files, decode them from JPG and then feed them into the dataset object. Prior to the introduction of the <code>tf.data.Dataset</code> pipeline, this was quite easy using the <code>RandomShuffleQueue</code> and <code>enqueue_many</code> ops, but it seems like there is currently no elegant way of doing this (or the documentation is lacking). </p>

<p>Does anyone know what would be the best way of achieving my goal? I have also looked into (and implemented) the pipeline using <code>tfrecord</code> files, but taking a random sample of video frames stored in a <code>tfrecord</code> file seems quite impossible (see <a href=""https://stackoverflow.com/questions/48101576/tensorflow-read-video-frames-from-tfrecords-file"">here</a>). Additionally, I have looked at the <code>from_generator()</code> inputs for <code>tf.data.Dataset</code> but that is definitely not going to run in multiple threads it seems. Any suggestions are more than welcome.</p>
","I am setting up a TensorFlow pipeline for reading large HDF5 files as input for my deep learning models. Each HDF5 file contains 100 videos of variable size length stored as a collection of compressed JPG images (to make size on disk manageable). Using tf.data.Dataset and a map to tf.py_func, reading examples from the HDF5 file using custom Python logic is quite easy. For example: This example works, however the problem is that it seems like tf.py_func can only handle one example at a time. As my HDF5 container stores 100 examples, this limitation causes significant overhead as the files constantly need to be opened, read, closed and reopened. It would be much more efficient to read all the 100 video examples into the dataset object and then move on with the next HDF5 file (preferably in multiple threads, each thread dealing with it's own collection of HDF5 files). So, what I would like is a number of threads running in the background, reading video frames from the HDF5 files, decode them from JPG and then feed them into the dataset object. Prior to the introduction of the tf.data.Dataset pipeline, this was quite easy using the RandomShuffleQueue and enqueue_many ops, but it seems like there is currently no elegant way of doing this (or the documentation is lacking). Does anyone know what would be the best way of achieving my goal? I have also looked into (and implemented) the pipeline using tfrecord files, but taking a random sample of video frames stored in a tfrecord file seems quite impossible (see here). Additionally, I have looked at the from_generator() inputs for tf.data.Dataset but that is definitely not going to run in multiple threads it seems. Any suggestions are more than welcome.",https://stackoverflow.com/questions/48309631,3419427,Documentation Replication on Other Examples,Documentation Completeness,"Prior to the introduction of the tf.data.Dataset pipeline, this was quite easy using the RandomShuffleQueue and enqueue_many ops, but it seems like there is currently no elegant way of doing this (or the documentation is lacking). "
52731624,"""A nested structure of tf.Tensor objects"" for Iterator.get_next() result type","<p>When I write Tensorflow code, I try to keep in mind the type of different things, e.g. tuple of two Tensors, or list of Tensors. This is important because when the types/shapes don't match, Tensorflow emits an error.</p>

<p>The text of the title of this question shows up a lot in the documentation especially when describing the result of some function, e.g. for <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Iterator#get_next"" rel=""nofollow noreferrer""><code>Iterator.get_next()</code></a>, but I find it too vague. It doesn't tell me exactly what to expect, a list of tuples? a tuple of tuples? What exactly is this 'nested structure'? Right now, the only way I can track this is to print the result after Session.run(). Is there a cleaner and more definitive way?</p>

<p>Also, it seems that the value of <code>Iterator.get_next()</code> is always a list of one element; I haven't been able to make it return a non-list, an empty list or a list with multiple elements. When does <code>Iterator.get_next()</code> return something that's not a list of one element? If never, then the wrapping of the content in a list seems superfluous -- why was <code>Iterator.get_next()</code> designed this way?</p>

<p>This is example code showing I mean:</p>

<pre><code>import numpy as np
import tensorflow as tf

ds = tf.data.Dataset.from_tensor_slices(np.array(range(0, 8)).reshape(4,2))
it = ds.make_one_shot_iterator()

with tf.Session() as sess:
    for i in range(0, 4):
        x = sess.run([it.get_next()])
        print(x)
</code></pre>

<p>Output:</p>

<pre><code>[array([0, 1])]
[array([2, 3])]
[array([4, 5])]
[array([6, 7])]
</code></pre>

<p>Why not just the following?</p>

<pre><code>array([0, 1])
array([2, 3])
array([4, 5])
array([6, 7])
</code></pre>
","When I write Tensorflow code, I try to keep in mind the type of different things, e.g. tuple of two Tensors, or list of Tensors. This is important because when the types/shapes don't match, Tensorflow emits an error. The text of the title of this question shows up a lot in the documentation especially when describing the result of some function, e.g. for Iterator.get_next(), but I find it too vague. It doesn't tell me exactly what to expect, a list of tuples? a tuple of tuples? What exactly is this 'nested structure'? Right now, the only way I can track this is to print the result after Session.run(). Is there a cleaner and more definitive way? Also, it seems that the value of Iterator.get_next() is always a list of one element; I haven't been able to make it return a non-list, an empty list or a list with multiple elements. When does Iterator.get_next() return something that's not a list of one element? If never, then the wrapping of the content in a list seems superfluous -- why was Iterator.get_next() designed this way? This is example code showing I mean: Output: Why not just the following?",https://stackoverflow.com/questions/52731624,679688,Documentation Completeness,Documentation Completeness,"The text of the title of this question shows up a lot in the documentation especially when describing the result of some function, e.g. for Iterator.get_next(), but I find it too vague. It doesn't tell me exactly what to expect, a list of tuples? a tuple of tuples?"
58276774,How do you write a fixed len feature to tfrecord,"<p>I'm struggling with the basics of writing a tensorflow tfrecord file. I'm writing a simple example with an ndarray in python, but for some reason when I read it it's required to be variable-length and reads it as a SparseTensor.</p>

<p>Here's the example</p>

<pre><code>def serialize_tf_record(features, targets):
    record = {
        'shape': tf.train.Int64List(value=features.shape),
        'features': tf.train.FloatList(value=features.flatten()),
        'targets': tf.train.Int64List(value=targets),
    }

    return build_tf_example(record)

def deserialize_tf_record(record):
    tfrecord_format = {
        'shape': tf.io.VarLenFeature(tf.int64),
        'features': tf.io.VarLenFeature(tf.float32),
        'targets': tf.io.VarLenFeature(tf.int64),
    }

    features_tensor = tf.io.parse_single_example(record, tfrecord_format)
    return features_tensor
</code></pre>

<p>Can anybody explain to me why this writes a variable-length record? It is fixed in code, but I can't seem to write it in a way tensorflow knows its fixed. The tensorflow documentation is pretty horrific here. Can anybody clarify the API for me?</p>
","I'm struggling with the basics of writing a tensorflow tfrecord file. I'm writing a simple example with an ndarray in python, but for some reason when I read it it's required to be variable-length and reads it as a SparseTensor. Here's the example Can anybody explain to me why this writes a variable-length record? It is fixed in code, but I can't seem to write it in a way tensorflow knows its fixed. The tensorflow documentation is pretty horrific here. Can anybody clarify the API for me?",https://stackoverflow.com/questions/58276774,1196033,Documentation Completeness,Documentation Completeness,The tensorflow documentation is pretty horrific here.
48768206,How to use dataset.shard in tensorflow?,"<p>Recently I am looking into the dataset API in Tensorflow, and there is a method <code>dataset.shard()</code> which is for distributed computations.</p>

<p>This is what's stated in Tensorflow's documentation:</p>

<pre><code>Creates a Dataset that includes only 1/num_shards of this dataset.

d = tf.data.TFRecordDataset(FLAGS.input_file)
d = d.shard(FLAGS.num_workers, FLAGS.worker_index)
d = d.repeat(FLAGS.num_epochs)
d = d.shuffle(FLAGS.shuffle_buffer_size)
d = d.map(parser_fn, num_parallel_calls=FLAGS.num_map_threads)
</code></pre>

<p>This method is said to return a portion of the original dataset. If I have two workers, am I supposed to do:</p>

<pre><code>d_0 = d.shard(FLAGS.num_workers, worker_0)
d_1 = d.shard(FLAGS.num_workers, worker_1)
......
iterator_0 = d_0.make_initializable_iterator()
iterator_1 = d_1.make_initializable_iterator()

for worker_id in workers:
    with tf.device(worker_id):
        if worker_id == 0:
            data = iterator_0.get_next()
        else:
            data = iterator_1.get_next()
        ......
</code></pre>

<p>Because the documentation did not specify how to make subsequent calls, I am a bit confused here.</p>

<p>Thanks!</p>
","Recently I am looking into the dataset API in Tensorflow, and there is a method dataset.shard() which is for distributed computations. This is what's stated in Tensorflow's documentation: This method is said to return a portion of the original dataset. If I have two workers, am I supposed to do: Because the documentation did not specify how to make subsequent calls, I am a bit confused here. Thanks!",https://stackoverflow.com/questions/48768206,8736709,Documentation Completeness,Documentation Completeness,"Because the documentation did not specify how to make subsequent calls, I am a bit confused here."
75135220,"How to define positional arguments: 'op', 'value_index', and 'dtype' in a tensor?","<p>when I run the below piece of code</p>
<pre><code>from tensorflow.python.ops.numpy_ops import np_config
np_config.enable_numpy_behavior()
import pandas as pd

df = pd.DataFrame(
    {'x':[1.,2.,3.,4.],
     'y':[1.59,4.24,2.38,0.53]}
)

data = tf.data.Dataset.from_tensor_slices(df.to_numpy())
data = data.flat_map(lambda x: x.reshape((2,1)))
</code></pre>
<p>I receive:
<em><strong>TypeError: <strong>init</strong>() missing 3 required positional arguments: 'op', 'value_index', and 'dtype'</strong></em> . I understand why this is happening as I didn't define values for 'op', 'value_index', and 'dtype' amd that tensorflow cant produce tensors.
Basically I want to use <strong>flat_map</strong> function to create tensors with <strong>shape = (1,)</strong> and <strong>dtype = tf.float64</strong> such that when I run the below code the printed tensors look like:</p>
<pre><code>for item in data:
    print(item)

tf.Tensor([1.], shape=(1,), dtype=float64)
tf.Tensor([2.], shape=(1,), dtype=float64)
tf.Tensor([3.], shape=(1,), dtype=float64)
tf.Tensor([4.], shape=(1,), dtype=float64)
tf.Tensor([1.59], shape=(1,), dtype=float64)
tf.Tensor([4.24], shape=(1,), dtype=float64)
tf.Tensor([2.38], shape=(1,), dtype=float64)
tf.Tensor([0.53], shape=(1,), dtype=float64)
</code></pre>
<p>How can I specify those values inside <strong>flat_map</strong> function or any other function which I can pass into <strong>flat_map</strong> function?</p>
<p>I checked here <a href=""https://www.tensorflow.org/api_docs/python/tf/Tensor"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/Tensor</a> but unfortunately I couldn't come up with a solution.</p>
<p>Thanks!</p>
","when I run the below piece of code I receive: TypeError: init() missing 3 required positional arguments: 'op', 'value_index', and 'dtype' . I understand why this is happening as I didn't define values for 'op', 'value_index', and 'dtype' amd that tensorflow cant produce tensors. Basically I want to use flat_map function to create tensors with shape = (1,) and dtype = tf.float64 such that when I run the below code the printed tensors look like: How can I specify those values inside flat_map function or any other function which I can pass into flat_map function? I checked here https://www.tensorflow.org/api_docs/python/tf/Tensor but unfortunately I couldn't come up with a solution. Thanks!",https://stackoverflow.com/questions/75135220,13841479,Requesting (Additional) Resources,Documentation Completeness,I checked here https://www.tensorflow.org/api_docs/python/tf/Tensor but unfortunately I couldn't come up with a solution.
49505986,How do i get the VALUES of trainable variables from a restored graph & checkpoint in tensorflow,"<p>I want to get the values of the variables from a trained model.  I have a check point file and I can restore graphs and checkpoints and do inference with them just fine.</p>

<p>However, I'm finding it extremely difficult to figure out how to get the trainable variable values (like the weight and bias values, not names...i want the VALUES) after I restore the checkpoint and graph.  I've read through Tensorflow documentation and there's lots of suggestions regarding ""with variable_scope"", ""reuse = True"", and ""tf.get_variable(""myvar"") within the scope...etc, but I get errors stating either the variable already exists or it hasn't been initialized.  tf.graphkeys only returns names...not values.</p>
","I want to get the values of the variables from a trained model. I have a check point file and I can restore graphs and checkpoints and do inference with them just fine. However, I'm finding it extremely difficult to figure out how to get the trainable variable values (like the weight and bias values, not names...i want the VALUES) after I restore the checkpoint and graph. I've read through Tensorflow documentation and there's lots of suggestions regarding ""with variable_scope"", ""reuse = True"", and ""tf.get_variable(""myvar"") within the scope...etc, but I get errors stating either the variable already exists or it hasn't been initialized. tf.graphkeys only returns names...not values.",https://stackoverflow.com/questions/49505986,3496060,Documentation Ambiguity,Documentation Ambiguity,"However, I'm finding it extremely difficult to figure out how to get the trainable variable values (like the weight and bias values, not names...i want the VALUES) after I restore the checkpoint and graph. "
54282753,How to input 2d numpy array into Tensorflow? (also on how to get matrix input and output working with TF),"<p>I'm new to Tensorflow and I'm trying to understand how it processes data. Currently, this is what I want to have as my input. My full code is up on <a href=""https://github.com/stockfish8/PolySolver"" rel=""nofollow noreferrer"">github</a> should you want to download it.</p>

<pre><code>print (y_train[0])
&gt;&gt;&gt; [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 
1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 
1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 
1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 
1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 
0.0, 1.0, 0.0, 1.0, 0.0, 0.0]
# list of 80 elements

print (np.array(y_train))
&gt;&gt;&gt; [[0. 0. 1. ... 1. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [1. 0. 1. ... 0. 0. 0.]
 ...
 [0. 0. 1. ... 1. 1. 0.]
 [1. 0. 0. ... 0. 0. 1.]
 [0. 0. 0. ... 1. 0. 1.]]

print (np.array(y_train).shape)
&gt;&gt;&gt; (11645, 80)

print (x_train[0])
&gt;&gt;&gt; [1.0, 4.0, 5.0, 2.0, 5.0, 3.0, 5.0, 3.0, 4.0, 5.0, 3.0, 5.0, 4.0, 3.0, 
3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 5.0]

print (np.array(x_train)/5)
&gt;&gt;&gt; [[0.2 0.8 1.  ... 0.8 0.8 1. ]
[0.6 0.8 1.  ... 1.  1.  0.8]
[0.8 0.4 1.  ... 1.  0.6 1. ]
...
[1.  0.6 0.8 ... 0.4 0.8 0.6]
[1.  0.8 0.8 ... 0.4 0.6 1. ]
[0.6 0.8 0.8 ... 1.  0.8 0.6]]

print (np.array(x_train).shape)
&gt;&gt;&gt; (11645, 26)
</code></pre>

<p>So basically I have 11645 pieces of data in my dataset. For the input, I wish to have 26 inputs normalized from 0 to 1. For the output, I wish to have 80 binary outputs. I don't think TF can give binary outputs, so I probably will use a sigmoid activation function. </p>

<p>How do I get Tensorflow to understand that I have 11645 pieces of data I want to process and that the input shape should be 26x1 and the output 80x1? There are some pieces of Tensorflow and Keras that I don't understand how they fit together. For instance, if I want Tensorflow to understand that my input should be 1x26 and not some other input shape, should I use <code>x_train = tf.reshape(x_train, [-1,1*26])</code> and <code>y_train = tf.reshape(y_train, [-1,1*80])</code>? From the documentations it seems like it will shape x_train into a tensor of only 1 row and 26 columns, and I will have 11645 of those. But does that specify to Tensorflow that the input should only be 1x26 and it won't go off grabbing some other number (eg. 26x2). Or do I have to do something more explicit like this where I specify the input shape into the model? <code>model.add(tf.keras.layers.Dense(26, activation=keras.activations.relu, input_shape=(26,)))</code>? </p>

<p>Again, for my output, I want to have a 1x80 tensor that I can reshape and stuff. Do I have to specify to tensorflow explicitly? Or will something like <code>model.add(tf.keras.layers.Dense(80, activation=keras.activations.sigmoid))</code> be enough to tell Tensorflow that I want a 1x80 matrix, and (for eg, using the sigmoid function) that it should compare every piece of data in that predicted 1x80 with the 1x80 matrix I have in y_train to calculate the loss function?</p>

<p>Basically, I am confused as to how Tensorflow 'knows' what data to accept as an individual input and output. Is there a way to specify it or is it a step one can omit?</p>

<p>EDIT: Based on the answers, I have used the code:</p>

<pre><code>model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(26, input_dim=26,activation='relu'))
model.add(tf.keras.layers.Dense(80, activation='sigmoid'))
model.compile(optimizer='rmsprop',
      loss='binary_crossentropy',
      metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10, batch_size=32)
</code></pre>

<p>I'm getting the following matrix:</p>

<pre><code>[0.38176608 0.34900635 0.36545524 0.36806932 0.36692804 0.37398493
  0.36821148 0.35577637 0.38441166 0.3676901  0.41162464 0.40428266
  0.41464344 0.4040607  0.39316037 0.428753   0.3547327  0.35693064
  0.3422352  0.36919317 0.36431065 0.3515264  0.3889933  0.33974153
  0.37329385 0.35898593 0.3891792  0.42334762 0.40694237 0.41910493
  0.39983115 0.47813386 0.37625512 0.35567597 0.36811477 0.38242644
  0.36549032 0.35696995 0.37058106 0.3556903  0.37096408 0.34965912
  0.4247738  0.41512045 0.41622216 0.38645518 0.40850884 0.43454456
  0.3655926  0.34644917 0.36782715 0.34224963 0.35035127 0.3502
  0.3607877  0.38218996 0.37265536 0.3653391  0.41620222 0.41124558
  0.3916335  0.41291553 0.39959764 0.4649614  0.34603494 0.36731967
  0.34146535 0.34573284 0.33941117 0.35885242 0.3493014  0.35866526
  0.37188208 0.34971312 0.38165745 0.3962399  0.38913697 0.4078925
  0.38799426 0.4709055 ]
</code></pre>

<p>This is a far cry from the 0 and 1 matrix I want. What should I do to get closer to that? I've tried Googling my problem, but to no avail. Should I simply apply a threshold to this (eg. 0.4?) and convert it to a binary matrix that way? </p>
","I'm new to Tensorflow and I'm trying to understand how it processes data. Currently, this is what I want to have as my input. My full code is up on github should you want to download it. So basically I have 11645 pieces of data in my dataset. For the input, I wish to have 26 inputs normalized from 0 to 1. For the output, I wish to have 80 binary outputs. I don't think TF can give binary outputs, so I probably will use a sigmoid activation function. How do I get Tensorflow to understand that I have 11645 pieces of data I want to process and that the input shape should be 26x1 and the output 80x1? There are some pieces of Tensorflow and Keras that I don't understand how they fit together. For instance, if I want Tensorflow to understand that my input should be 1x26 and not some other input shape, should I use x_train = tf.reshape(x_train, [-1,1*26]) and y_train = tf.reshape(y_train, [-1,1*80])? From the documentations it seems like it will shape x_train into a tensor of only 1 row and 26 columns, and I will have 11645 of those. But does that specify to Tensorflow that the input should only be 1x26 and it won't go off grabbing some other number (eg. 26x2). Or do I have to do something more explicit like this where I specify the input shape into the model? model.add(tf.keras.layers.Dense(26, activation=keras.activations.relu, input_shape=(26,)))? Again, for my output, I want to have a 1x80 tensor that I can reshape and stuff. Do I have to specify to tensorflow explicitly? Or will something like model.add(tf.keras.layers.Dense(80, activation=keras.activations.sigmoid)) be enough to tell Tensorflow that I want a 1x80 matrix, and (for eg, using the sigmoid function) that it should compare every piece of data in that predicted 1x80 with the 1x80 matrix I have in y_train to calculate the loss function? Basically, I am confused as to how Tensorflow 'knows' what data to accept as an individual input and output. Is there a way to specify it or is it a step one can omit? EDIT: Based on the answers, I have used the code: I'm getting the following matrix: This is a far cry from the 0 and 1 matrix I want. What should I do to get closer to that? I've tried Googling my problem, but to no avail. Should I simply apply a threshold to this (eg. 0.4?) and convert it to a binary matrix that way?",https://stackoverflow.com/questions/54282753,9721336,Requesting (Additional) Resources,Documentation Ambiguity,"Basically, I am confused as to how Tensorflow 'knows' what data to accept as an individual input and output. "
38902433,TensorFlow strings: what they are and how to work with them,"<p>When I read file with <code>tf.read_file</code> I get something with type <code>tf.string</code>. Documentation says only that it is ""Variable length byte arrays. Each element of a Tensor is a byte array."" (<a href=""https://www.tensorflow.org/versions/r0.10/resources/dims_types.html"" rel=""noreferrer"">https://www.tensorflow.org/versions/r0.10/resources/dims_types.html</a>). I have no idea how to interpret this.</p>

<p>I can do nothing with this type. In usual python you can get elements by index like <code>my_string[:4]</code>, but when I run following code I get an error.</p>

<pre><code>import tensorflow as tf
import numpy as np

x = tf.constant(""This is string"")
y = x[:4]


init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)
result = sess.run(y)
print result
</code></pre>

<p>It says </p>

<pre>  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 621, in assert_has_rank
    raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape () must have rank 1
</pre>

<p>Also I cannot convert my string to <code>tf.float32</code> tensor. It is <code>.flo</code> file and it has magic header ""PIEH"". This numpy code successfuly convert such header into number (see example here <a href=""https://stackoverflow.com/a/28016469/4744283"">https://stackoverflow.com/a/28016469/4744283</a>) but I can't do that with tensorflow. I tried <code>tf.string_to_number(string, out_type=tf.float32)</code> but it says </p>

<pre>tensorflow.python.framework.errors.InvalidArgumentError: StringToNumberOp could not correctly convert string: PIEH
</pre>

<p>So, what string is? What it's shape is? How can I at least get part of the string? I suppose that if I can get part of it I can just skip ""PIEH"" part.</p>

<p><strong>UPD</strong>: I forgot to say that <code>tf.slice(string, [0], [4])</code> also doesn't work with same error.</p>
","When I read file with tf.read_file I get something with type tf.string. Documentation says only that it is ""Variable length byte arrays. Each element of a Tensor is a byte array."" (https://www.tensorflow.org/versions/r0.10/resources/dims_types.html). I have no idea how to interpret this. I can do nothing with this type. In usual python you can get elements by index like my_string[:4], but when I run following code I get an error. It says Also I cannot convert my string to tf.float32 tensor. It is .flo file and it has magic header ""PIEH"". This numpy code successfuly convert such header into number (see example here https://stackoverflow.com/a/28016469/4744283) but I can't do that with tensorflow. I tried tf.string_to_number(string, out_type=tf.float32) but it says So, what string is? What it's shape is? How can I at least get part of the string? I suppose that if I can get part of it I can just skip ""PIEH"" part. UPD: I forgot to say that tf.slice(string, [0], [4]) also doesn't work with same error.",https://stackoverflow.com/questions/38902433,4744283,Documentation Ambiguity,Documentation Ambiguity,"Documentation says only that it is ""Variable length byte arrays. Each element of a Tensor is a byte array. I have no idea how to interpret this."
43972949,TFlearn to categorical,"<p>I`m using DNN of tflearn, and I want to change my features and lables to be categorical and not numeric. </p>

<p>here is my net:</p>

<pre><code>x = tf.placeholder(dtype= tf.float32, shape=[None, 6], name='x')
# Build neural network
input_layer = tflearn.input_data(shape=[None, 6])
net = input_layer
net = tflearn.fully_connected(net, 128, activation='relu')
net = tflearn.fully_connected(net, 64, activation='relu')
net = tflearn.fully_connected(net, 16, activation='relu')
net = tflearn.fully_connected(net, 2, activation='sigmoid')
net = tflearn.regression(net, optimizer='adam', loss='mean_square', metric='R2')

w = tf.Variable(tf.truncated_normal([2, 2], stddev=0.1))
b = tf.Variable(tf.constant(1.0, shape=[2]))
y = tf.nn.softmax(tf.matmul(net, w) + b, name='y')

model = tflearn.DNN(net, tensorboard_verbose=3)
return model
</code></pre>

<p>I know about tflearn.data_utils.to_categorical but I dont know how to inject this method.
thanks</p>

<p><strong>EDIT:</strong>
I tried few things, like:</p>

<pre><code>train_goal = tflearn.data_utils.to_categorical(train_goal, nb_classes=2)
            test_goal = tflearn.data_utils.to_categorical(test_goal, nb_classes=2)
</code></pre>

<p>and also change the loss:</p>

<pre><code>net = tflearn.regression(net, optimizer='adadelta',  loss='categorical_crossentropy', metric= self.accuracy)
</code></pre>

<p>but I got loss more than 1:</p>

<pre><code>Training Step: 35  | total loss: 1.64734 | time: 1.322s
| AdaDelta | epoch: 001 | loss: 1.64734 - acc: 1.0000 | val_loss: 1.64313 - val_acc: 1.0000 -- iter: 2204/2204
--
Training Step: 70  | total loss: 1.61961 | time: 0.216s
| AdaDelta | epoch: 002 | loss: 1.61961 - acc: 1.0000 | val_loss: 0.00000 - val_acc: 0.0000 -- iter: 2204/2204
--
Training Step: 105  | total loss: 1.58511 | time: 1.188s
| AdaDelta | epoch: 003 | loss: 1.58511 - acc: 1.0000 | val_loss: 1.57300 - val_acc: 1.0000 -- iter: 2204/2204
</code></pre>

<p>where is the problem?</p>
","I`m using DNN of tflearn, and I want to change my features and lables to be categorical and not numeric. here is my net: I know about tflearn.data_utils.to_categorical but I dont know how to inject this method. thanks EDIT: I tried few things, like: and also change the loss: but I got loss more than 1: where is the problem?",https://stackoverflow.com/questions/43972949,6925731,Documentation Ambiguity,Documentation Ambiguity,I know about tflearn.data_utils.to_categorical but I dont know how to inject this method.
59796343,Transformer model not able to be saved,"<p>I'm trying to follow this tutrial <a href=""https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb</a>, However, when I tried to save the model in order to load it again without training I got an error mentioned here <a href=""https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf"">NotImplementedError: Layers with arguments in `__init__` must override `get_config`</a>
I understood from the answer that I need to make the encoder and decoder as classes and customise it(instead of leaving it as functions like the colab tutrial) so I went back to tensor flow documentation of this model here: <a href=""https://www.tensorflow.org/tutorials/text/transformer#encoder_layer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/text/transformer#encoder_layer</a> and tried to edit in it. I made the encoder layer as:</p>

<pre><code>class EncoderLayer(tf.keras.layers.Layer):
  def __init__(self, d_model, num_heads,  rate=0.1,**kwargs,):
    #super(EncoderLayer, self).__init__()
    super().__init__(**kwargs)
    self.mha = MultiHeadAttention(d_model, num_heads)
    self.ffn = point_wise_feed_forward_network(d_model, dff)

    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)

    self.dropout1 = tf.keras.layers.Dropout(rate)
    self.dropout2 = tf.keras.layers.Dropout(rate)
  def get_config(self):

        config = super().get_config().copy()
        config.update({
            #'vocab_size': self.vocab_size,
            #'num_layers': self.num_layers,
            #'units': self.units,
            'd_model': self.d_model,
            'num_heads': self.num_heads,
            'dropout': self.dropout,
        })
        return config

  def call(self, x, training, mask):

    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)
    attn_output = self.dropout1(attn_output, training=training)
    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)

    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)
    ffn_output = self.dropout2(ffn_output, training=training)
    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)

    return out2
</code></pre>

<p>and same for the decoder layer class. Then the same encoder in the documentation of tf</p>

<pre><code>class Encoder(tf.keras.layers.Layer):
  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,
               maximum_position_encoding, rate=0.1):
    super(Encoder, self).__init__()

    self.d_model = d_model
    self.num_layers = num_layers

    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)
    self.pos_encoding = positional_encoding(maximum_position_encoding, 
                                            self.d_model)


    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) 
                       for _ in range(num_layers)]

    self.dropout = tf.keras.layers.Dropout(rate)

  def call(self, x, training, mask):

    seq_len = tf.shape(x)[1]

    # adding embedding and position encoding.
    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)
    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
    x += self.pos_encoding[:, :seq_len, :]

    x = self.dropout(x, training=training)

    for i in range(self.num_layers):
      x = self.enc_layers[i](x, training, mask)

    return x  # (batch_size, input_seq_len, d_model)
</code></pre>

<p>the function of the model as:</p>

<pre><code>def transformer(vocab_size,
                num_layers,
                units,
                d_model,
                num_heads,
                dropout,
                name=""transformer""):
  inputs = tf.keras.Input(shape=(None,), name=""inputs"")
  dec_inputs = tf.keras.Input(shape=(None,), name=""dec_inputs"")

  enc_padding_mask = tf.keras.layers.Lambda(
      create_padding_mask, output_shape=(1, 1, None),
      name='enc_padding_mask')(inputs)
  # mask the future tokens for decoder inputs at the 1st attention block
  look_ahead_mask = tf.keras.layers.Lambda(
      create_look_ahead_mask,
      output_shape=(1, None, None),
      name='look_ahead_mask')(dec_inputs)
  # mask the encoder outputs for the 2nd attention block
  dec_padding_mask = tf.keras.layers.Lambda(
      create_padding_mask, output_shape=(1, 1, None),
      name='dec_padding_mask')(inputs)

  enc_outputs = Encoder(
      num_layers=num_layers, d_model=d_model, num_heads=num_heads, 
                         input_vocab_size=vocab_size,


  )(inputs=[inputs, enc_padding_mask])

  dec_outputs = Decoder(
      num_layers=num_layers, d_model=d_model, num_heads=num_heads, 
                          target_vocab_size=vocab_size,


  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])

  outputs = tf.keras.layers.Dense(units=vocab_size, name=""outputs"")(dec_outputs)

  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)
</code></pre>

<p>and calling the model:</p>

<pre><code>#the model itself with its paramters:
# Hyper-parameters
NUM_LAYERS = 3
D_MODEL = 256
#D_MODEL=tf.cast(D_MODEL, tf.float32)

NUM_HEADS = 8
UNITS = 512
DROPOUT = 0.1
model = transformer(
    vocab_size=VOCAB_SIZE,
    num_layers=NUM_LAYERS,
    units=UNITS,
    d_model=D_MODEL,
    num_heads=NUM_HEADS,
    dropout=DROPOUT)
</code></pre>

<p>However, I got that error:
<code>TypeError: __init__() missing 2 required positional arguments: 'dff' and 'maximum_position_encoding'</code>
I am really confused and I don't understand what dff and maximum position encoding mean in the documentation and when I removed them from the encoder and decoder classes, I got anther error as positional_encoding function takes maximum position as input and also dff is passed as input inside the class. I am not so sure what I should do as I am not sure whether I am following the right steps or not</p>
","I'm trying to follow this tutrial https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb, However, when I tried to save the model in order to load it again without training I got an error mentioned here NotImplementedError: Layers with arguments in `__init__` must override `get_config` I understood from the answer that I need to make the encoder and decoder as classes and customise it(instead of leaving it as functions like the colab tutrial) so I went back to tensor flow documentation of this model here: https://www.tensorflow.org/tutorials/text/transformer#encoder_layer and tried to edit in it. I made the encoder layer as: and same for the decoder layer class. Then the same encoder in the documentation of tf the function of the model as: and calling the model: However, I got that error: TypeError: __init__() missing 2 required positional arguments: 'dff' and 'maximum_position_encoding' I am really confused and I don't understand what dff and maximum position encoding mean in the documentation and when I removed them from the encoder and decoder classes, I got anther error as positional_encoding function takes maximum position as input and also dff is passed as input inside the class. I am not so sure what I should do as I am not sure whether I am following the right steps or not",https://stackoverflow.com/questions/59796343,10291435,Documentation Ambiguity,Documentation Ambiguity,"I am really confused and I don't understand what dff and maximum position encoding mean in the documentation and when I removed them from the encoder and decoder classes, I got anther error as positional_encoding function takes maximum position as input and also dff is passed as input inside the class. "
61665285,Problem with input to tf.keras.layers.GRU,"<p>I am trying to make a seq2seq model using <code>tfa.seq2seq.BaseDecoder</code> in TensorFlow 2.1. I have</p>

<pre><code>tf.keras.layers.GRU(64)(inputs, [states])
</code></pre>

<p>where inputs has shape <code>(batch_size, 1, embedding_dimension)</code> and comes from </p>

<pre><code>inputs = tf.keras.layers.Embedding(1000, 64, mask_zero=True)(tf.fill([batch_size, 1], value=1))
</code></pre>

<p>and <code>states</code> are the encoder hidden states for the batch.</p>

<p>I am implementing <code>tfa.seq2seq.BaseDecoder</code>'s <code>initialize</code>, <code>step</code> and some properties and the error is happening in <code>step</code> which contains the line that I have copied out here.</p>

<p>However, it gives me the following error message (some function names are changed to make explaining the question easier and are slightly different in the code).</p>

<pre><code>    Traceback (most recent call last):
  File ""/home/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2659, in _set_inputs
    outputs = self(inputs, **kwargs)
  File ""/home/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/home/.local/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in converted code:

    /home/lemmatizer_noattn.py:155 call  *
        output_layer, _, output_lens, _ = self.DecoderTraining((source_states, target_charseqs), True)
    /home/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:785 __call__
        str(e) + '\n""""""')

    TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.
    Encountered error:
    """"""
    in converted code:

        /home/.local/lib/python3.7/site-packages/tensorflow_addons/seq2seq/decoder.py:162 call  *
            return dynamic_decode(
        /home/.local/lib/python3.7/site-packages/tensorflow_addons/seq2seq/decoder.py:405 body  *
            (next_outputs, decoder_state, next_inputs, decoder_finished) = decoder.step(
        /home/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py:2478 while_loop_v2
            return_same_structure=True)
        /home/lemmatizer_noattn.py:79 step  *
            outputs, [states] = self.lemmatizer.target_rnn_cell(inputs, [states])
        /home/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:539 __iter__
            self._disallow_iteration()
        /home/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:535 _disallow_iteration
            self._disallow_in_graph_mode(""iterating over `tf.Tensor`"")
        /home/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:515 _disallow_in_graph_mode
            "" this function with @tf.function."".format(task))

        OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.

    """"""
</code></pre>

<p>I didn't manage to figure out from the documentation where the error might be comming from nor did I find any advice on the internet. Any ideas on where the problem might be?</p>
","I am trying to make a seq2seq model using tfa.seq2seq.BaseDecoder in TensorFlow 2.1. I have where inputs has shape (batch_size, 1, embedding_dimension) and comes from and states are the encoder hidden states for the batch. I am implementing tfa.seq2seq.BaseDecoder's initialize, step and some properties and the error is happening in step which contains the line that I have copied out here. However, it gives me the following error message (some function names are changed to make explaining the question easier and are slightly different in the code). I didn't manage to figure out from the documentation where the error might be comming from nor did I find any advice on the internet. Any ideas on where the problem might be?",https://stackoverflow.com/questions/61665285,13045395,Requesting (Additional) Resources,Documentation Ambiguity,I didn't manage to figure out from the documentation where the error might be comming from nor did I find any advice on the internet.
70294847,Low accuracy using functional API + CNN and CIFAR10; incorrect initialization?,"<p>I'm new to using CNNs but I'm trying to make one using the functional API with the CIFAR10 dataset. The only thing is I'm getting very very low accuracy. I've looked over my textbook examples and documentation but can't figure out why it's so low when it should be starting way higher. This is my setup using DenseNet201 and tf version 2.7:</p>
<pre><code>#load in data 
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
X_train, X_test = X_train / 255.0, X_test / 255.0

# one hot encode target values/labels
y_train = tf.keras.utils.to_categorical(y_train)
y_test = tf.keras.utils.to_categorical(y_test)

# have to preprocess before using functional API
X_testP = tf.keras.applications.densenet.preprocess_input(X_test)
X_trainP = tf.keras.applications.densenet.preprocess_input(X_train)

# data size we start with
inputs = tf.keras.Input(shape=(32,32,3))
# densenet expects 224x224 so use lambda layer
resized_images = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, (224, 224)))(inputs)

# initialize model
transfer = keras.applications.DenseNet201(include_top=False, weights='imagenet', pooling='max', input_tensor = resized_images,input_shape=(224,224,3), classes=1000)

# add your layers
x = transfer.output
x = tf.keras.layers.Flatten()(x)
x = tf.keras.layers.Dense(256, activation='relu')(x)
x = tf.keras.layers.BatchNormalization() (x)
x = tf.keras.layers.Dense(200, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(64, activation='relu')(x)
output = tf.keras.layers.Dense(10, activation='softmax')(x)

transfer_model = keras.Model(inputs=transfer.input, outputs=output)
transfer_model.trainable = False;

# here I try SGD but I also tried Adam to no better results
optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)

transfer_model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])

history_transfer = transfer_model.fit(X_trainP, y_train,epochs=20)
</code></pre>
<p>I feel like all the examples I've seen start way higher and that's even without additional layers. Am I misunderstanding something in the initialization?</p>
",I'm new to using CNNs but I'm trying to make one using the functional API with the CIFAR10 dataset. The only thing is I'm getting very very low accuracy. I've looked over my textbook examples and documentation but can't figure out why it's so low when it should be starting way higher. This is my setup using DenseNet201 and tf version 2.7: I feel like all the examples I've seen start way higher and that's even without additional layers. Am I misunderstanding something in the initialization?,https://stackoverflow.com/questions/70294847,12379067,Documentation Ambiguity,Documentation Ambiguity,I've looked over my textbook examples and documentation but can't figure out why it's so low when it should be starting way higher.
37980518,meaning of `grad` parameter in tensorflow gradient functions (python),"<p>What does the <code>grad</code> parameter in tensorflow gradient functions in python (like the example below from the docs) represent?</p>

<pre><code>@tf.RegisterGradient(""Sub"")
def _sub_grad(unused_op, grad):
  return grad, tf.neg(grad)
</code></pre>

<p>The docs say it represents ""the gradients with respect to each output of the op."" Which gradients? The gradients of Each output of the op, with respect to each output of the op?</p>

<p>The op here is x - y. Does that mean the <code>grad</code> parameter in this function refers to </p>

<p><a href=""https://i.stack.imgur.com/zl9ck.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zl9ck.png"" alt=""grad""></a></p>

<p>?</p>

<p>This would be consistent with the output of the function, which is</p>

<p><a href=""https://i.stack.imgur.com/gVwLR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gVwLR.png"" alt=""enter image description here""></a>,</p>

<p>but I wanted to make sure.</p>

<p>Thanks in advance for your clarification!</p>
","What does the grad parameter in tensorflow gradient functions in python (like the example below from the docs) represent? The docs say it represents ""the gradients with respect to each output of the op."" Which gradients? The gradients of Each output of the op, with respect to each output of the op? The op here is x - y. Does that mean the grad parameter in this function refers to ? This would be consistent with the output of the function, which is , but I wanted to make sure. Thanks in advance for your clarification!",https://stackoverflow.com/questions/37980518,1387992,Documentation Completeness,Documentation Ambiguity,"What does the grad parameter in tensorflow gradient functions in python (like the example below from the docs) represent? The docs say it represents ""the gradients with respect to each output of the op."""
38190365,How does one initialize a variable with tf.get_variable and a numpy value in TensorFlow?,"<p>I wanted to initialize some of the variable on my network with numpy values. For the sake of the example consider:</p>

<pre><code>init=np.random.rand(1,2)
tf.get_variable('var_name',initializer=init)
</code></pre>

<p>when I do that I get an error:</p>

<pre><code>ValueError: Shape of a new variable (var_name) must be fully defined, but instead was &lt;unknown&gt;.
</code></pre>

<p>why is it that I am getting that error? </p>

<p>To try to fix it I tried doing:</p>

<pre><code>tf.get_variable('var_name',initializer=init, shape=[1,2])
</code></pre>

<p>which yielded a even weirder error:</p>

<pre><code>TypeError: 'numpy.ndarray' object is not callable
</code></pre>

<p>I tried reading <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/state_ops.html#variable_scope"" rel=""noreferrer"">the docs and examples</a> but it didn't really help.</p>

<p>Is it not possible to initialize variables with numpy arrays with the get_variable method in TensorFlow?</p>
",I wanted to initialize some of the variable on my network with numpy values. For the sake of the example consider: when I do that I get an error: why is it that I am getting that error? To try to fix it I tried doing: which yielded a even weirder error: I tried reading the docs and examples but it didn't really help. Is it not possible to initialize variables with numpy arrays with the get_variable method in TensorFlow?,https://stackoverflow.com/questions/38190365,1601580,Requesting (Additional) Resources,Documentation Ambiguity,I tried reading the docs and examples but it didn't really help.
38678820,How do I create a single script file for when I do and don't want to collect TensorBoard statistics?,"<p>I want to have a single script, that either collects tensorboard data or not, depending on how I run it. I am aware that I can pass flags to tell my script how I want it to be run. I could even hard code it in the script and just manually change the script. </p>

<p>Either solution has a bigger problem. I find myself having to write an if statement everywhere on my script when I want the summary writer operations to be ran or not. For example I find that I would have to do something like:</p>

<pre><code>if tb_sys_arg = 'tensorboard':
    merged = tf.merge_all_summaries()
</code></pre>

<p>and then depending on the value of <code>tb_sys_arg</code> run the summaries or not, as in:</p>

<pre><code>if tb_sys_arg = 'tensorboard':
    merged = tf.merge_all_summaries()
else:
    train_writer = tf.train.SummaryWriter(tensorboard_data_dump_train, sess.graph)
</code></pre>

<p>this seems really silly to me. I'd rather not have to do that. Is this the right way to do this? I just don't want to collect statistics each time I run my main script but I also don't want to have two separate scripts either.</p>

<hr>

<p>As an anecdotical story, few months ago I started using TensorBoard and it seems I have been running my main file as follow:</p>

<pre><code>python main.py —logdir=/tmp/mdl_logs
</code></pre>

<p>so that it collects tensorboard data. But realized that I don't think I need that last flag to collect tensorboard data. Its been so long that now I forget if I actually need that. I've been reading the documentation and tutorials but it seems I don't need that last flag (its only needed to run the web app as in <code>tensorboard --logdir=path/to/log-directory</code>, right?) Have I been doing this wrong all this time?</p>
","I want to have a single script, that either collects tensorboard data or not, depending on how I run it. I am aware that I can pass flags to tell my script how I want it to be run. I could even hard code it in the script and just manually change the script. Either solution has a bigger problem. I find myself having to write an if statement everywhere on my script when I want the summary writer operations to be ran or not. For example I find that I would have to do something like: and then depending on the value of tb_sys_arg run the summaries or not, as in: this seems really silly to me. I'd rather not have to do that. Is this the right way to do this? I just don't want to collect statistics each time I run my main script but I also don't want to have two separate scripts either. As an anecdotical story, few months ago I started using TensorBoard and it seems I have been running my main file as follow: so that it collects tensorboard data. But realized that I don't think I need that last flag to collect tensorboard data. Its been so long that now I forget if I actually need that. I've been reading the documentation and tutorials but it seems I don't need that last flag (its only needed to run the web app as in tensorboard --logdir=path/to/log-directory, right?) Have I been doing this wrong all this time?",https://stackoverflow.com/questions/38678820,1601580,Documentation Ambiguity,Documentation Ambiguity,"I've been reading the documentation and tutorials but it seems I don't need that last flag (its only needed to run the web app as in tensorboard --logdir=path/to/log-directory, right?)"
40258943,"Using height, width information stored in a TFRecords file to set shape of a Tensor","<p>I have converted a directory of images and their labels into a TFRecords file, the feature maps include <code>image_raw</code>, <code>label</code>, <code>height</code>, <code>width</code> and <code>depth</code>. The function is as follows:</p>

<pre><code>def convert_to_tfrecords(data_samples, filename):
    def _int64_feature(value):
        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))
    def _bytes_feature(value):
        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
    writer = tf.python_io.TFRecordWriter(filename)
    for fname, lb in data_samples:
        im = cv2.imread(fname, cv2.IMREAD_UNCHANGED)
        image_raw = im.tostring()
        feats = tf.train.Features(
            feature =
            {
                'image_raw': _bytes_feature(image_raw),
                'label': _int64_feature(int(lb)),
                'height': _int64_feature(im.shape[0]),
                'width': _int64_feature(im.shape[1]),
                'depth': _int64_feature(im.shape[2])
            }
        )
        example = tf.train.Example(features=feats)
        writer.write(example.SerializeToString())
    writer.close()
</code></pre>

<p>Now, I would like to read this TFRecords file to feed a input pipeline. However, since <code>image_raw</code> has been flattened, we need to reshape it into the original <code>[height, width, depth]</code> size. So how can I get the values of <code>height</code>, <code>width</code> and <code>depth</code> from the TFRecords file? It seems the following code cannot work because <code>height</code> is a Tensor without values.</p>

<pre><code>def read_and_decode(filename_queue):
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    feats = {
        'image_raw': tf.FixedLenFeature([], tf.string),
        'label': tf.FixedLenFeature([], tf.int64),
        'height': tf.FixedLenFeature([], tf.int64),
        'width': tf.FixedLenFeature([], tf.int64),
        'depth': tf.FixedLenFeature([], tf.int64)
    }
    features = tf.parse_single_example(serialized_example, features=feats)
    image = tf.decode_raw(features['image_raw'], tf.uint8)
    label = tf.cast(features['label'], tf.int32)
    height = tf.cast(features['height'], tf.int32)
    width = tf.cast(features['width'], tf.int32)
    depth = tf.cast(features['depth'], tf.int32)
    image = tf.reshape(image, [height, width, depth]) # &lt;== not work
    image = tf.cast(image, tf.float32) * (1. / 255) - 0.5
    return image, label
</code></pre>

<p>When I read the Tensorflow's official documents, I found they usually pass into a known size, saying <code>[224,224,3]</code>. However, I don't like it, because this information has been stored into the TFRecords file, and manually passing into fixed size cannot ensure the size is consistent with the data stored in the file.</p>

<p>So any ideas?</p>
","I have converted a directory of images and their labels into a TFRecords file, the feature maps include image_raw, label, height, width and depth. The function is as follows: Now, I would like to read this TFRecords file to feed a input pipeline. However, since image_raw has been flattened, we need to reshape it into the original [height, width, depth] size. So how can I get the values of height, width and depth from the TFRecords file? It seems the following code cannot work because height is a Tensor without values. When I read the Tensorflow's official documents, I found they usually pass into a known size, saying [224,224,3]. However, I don't like it, because this information has been stored into the TFRecords file, and manually passing into fixed size cannot ensure the size is consistent with the data stored in the file. So any ideas?",https://stackoverflow.com/questions/40258943,1659534,Requesting (Additional) Resources,Documentation Ambiguity,"When I read the Tensorflow's official documents, I found they usually pass into a known size, saying [224,224,3]. However, I don't like it, because this information has been stored into the TFRecords file, and manually passing into fixed size cannot ensure the size is consistent with the data stored in the file."
40435329,TensorFlow:What should be the first parameter for prediction using sess.run() in TensorFlow after loading a saved model.ckpt file?,"<p>I am new to TensorFlow and machine learning. I am trying to classify two objects a cup and a pendrive (jpeg images). I have trained and exported a model.ckpt successfully. Now I am trying to restore the saved model.ckpt for prediction of an image. Here is the script:</p>

<pre><code>with tf.Session() as sess:
   saver.restore(sess, ""./model.ckpt"")
   print ""...Model Loaded...""   
   x_ = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE , IMAGE_SIZE , IMAGE_CHANNELS])
   y_ = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES])
   keep_prob = tf.placeholder(tf.float32)

   init = tf.initialize_all_variables()

   sess.run(init)
   my_classification = sess.run(___________ , feed_dict={x_:image})
   print 'Neural Network predicted', my_classification[0], ""for your image""
</code></pre>

<p>In the above script what should I use as the first parameter in sess.run() ? I have read many stackoverflow and github posts but havent found a solution that works for my case. The TensorFlow Documentation is also not very clear.</p>

<p>Thank you in advance</p>
",I am new to TensorFlow and machine learning. I am trying to classify two objects a cup and a pendrive (jpeg images). I have trained and exported a model.ckpt successfully. Now I am trying to restore the saved model.ckpt for prediction of an image. Here is the script: In the above script what should I use as the first parameter in sess.run() ? I have read many stackoverflow and github posts but havent found a solution that works for my case. The TensorFlow Documentation is also not very clear. Thank you in advance,https://stackoverflow.com/questions/40435329,6438307,Documentation Ambiguity,Documentation Ambiguity,The TensorFlow Documentation is also not very clear.
40819321,Understanding the conceptual basics of Distributed TensorFlow,"<p>Let me describe the cluster setup first :</p>

<ul>
<li>I have two nodes (each with 2 GPUs). I refer to them as Node A and Node B</li>
<li>Each node has its own SSD storage.</li>
<li><a href=""http://oar.imag.fr/docs/latest/user/commands/oarsub.html"" rel=""nofollow noreferrer"">OAR</a> is the cluster manager that is used.</li>
</ul>

<p>I have gone through the Distributed TensorFlow documentation but there are some functional basics I could not understand properly and hence this question.</p>

<p>Consider the following situation :</p>

<ul>
<li>I have copied around 600 GB of data on Node A.</li>
<li>I can use OAR to specifically ask for allocation of 4 GPUs across the two nodes.</li>
</ul>

<p>If I want to use Distributed TensorFlow to train a model :</p>

<ol>
<li>How do I specify network addresses to tf.train.ClusterSpec ? What are those network addresses ? In the documentation are names such as localhost:2222 the same names reserved for a particular node with the cluster manager ?</li>
<li>My data is copied to node A. During training will TensorFlow itself be responsible for sending this data as input to the GPU that is on node B ?</li>
<li>Will I need to manually create the TensorFlow Graph for each GPU on each node using tf.device() ?</li>
<li>If I also want to use some additional CPU nodes will I have to have their names beforehand and put them in the code ?</li>
</ol>
",Let me describe the cluster setup first : I have gone through the Distributed TensorFlow documentation but there are some functional basics I could not understand properly and hence this question. Consider the following situation : If I want to use Distributed TensorFlow to train a model :,https://stackoverflow.com/questions/40819321,6842947,Documentation Ambiguity,Documentation Ambiguity,I have gone through the Distributed TensorFlow documentation but there are some functional basics I could not understand properly and hence this question.
40859416,Confusion about rank and shape in TensorFlow,"<p>I am confused about rank and shape concept of TensorFlow. I have read the details from <a href=""https://www.tensorflow.org/versions/r0.12/resources/dims_types.html"" rel=""nofollow noreferrer"">here</a> and did run some code to clear my concept about them. But I am still confused and need help to understand.</p>

<pre><code>x = tf.placeholder(tf.float32, shape=[2, 12])
print(x.get_shape()) # ==&gt; (2, 12)
print(x[0, :].get_shape())  # ==&gt; (12,)
print(x[1, :].get_shape())  # ==&gt; (12,)
print(x[2, :].get_shape())  # ==&gt; (12,)
print(x[120, :].get_shape())  # ==&gt; (12,)
</code></pre>

<p>I thought <code>x</code> is like a 2d matrix where <code>2</code> is <code>number of rows</code> and <code>12</code> is <code>number of columns</code>. Then why I am getting shape for <code>x[120, :]</code> as <code>(12, )</code>? How even <code>x[120, :]</code> is possible with the given shape?</p>

<p>Besides, since I thought x is a 2D tensor, its rank is also 2 because dimension and rank is the same thing for tensors (according to my understanding). But when I run:</p>

<pre><code>print(x[0].get_shape())
</code></pre>

<p>I am getting this error:</p>

<pre><code>Shape (2, 12) must have rank 1
</code></pre>

<p>It means my understanding is wrong about rank and dimension. What I am missing about rank and dimensions? Is rank and dimension two different things? How the rank of <code>tensor x</code> in the above example is 1? How can I set the rank of a tensor? Can anyone explain in details with some comprehensive examples?</p>
","I am confused about rank and shape concept of TensorFlow. I have read the details from here and did run some code to clear my concept about them. But I am still confused and need help to understand. I thought x is like a 2d matrix where 2 is number of rows and 12 is number of columns. Then why I am getting shape for x[120, :] as (12, )? How even x[120, :] is possible with the given shape? Besides, since I thought x is a 2D tensor, its rank is also 2 because dimension and rank is the same thing for tensors (according to my understanding). But when I run: I am getting this error: It means my understanding is wrong about rank and dimension. What I am missing about rank and dimensions? Is rank and dimension two different things? How the rank of tensor x in the above example is 1? How can I set the rank of a tensor? Can anyone explain in details with some comprehensive examples?",https://stackoverflow.com/questions/40859416,5352399,Documentation Ambiguity,Documentation Ambiguity,I am confused about rank and shape concept of TensorFlow. I have read the details from here and did run some code to clear my concept about them. But I am still confused and need help to understand. 
41651034,input pipeline in tensorflow,"<p>While practicing on the official tensorflow mnist dataset tutorial for beginners, I'm trying to change the mnist data to my own images collected from search engines. </p>

<pre><code>strFilePaths,iLabels ,strSubFolderNames,iNumTotalDatasets = ScanForImage('Datasets')

tsFileNameQueue = tf.train.string_input_producer(strFilePaths)
tsReader = tf.WholeFileReader()
_,tsImage = tsReader.read(tsFileNameQueue)

tsImage = tf.image.decode_jpeg(tsImage, channels=3)
tsImage = tf.cast(tsImage,tf.float32)
tsLabels = tf.convert_to_tensor(iLabels, dtype=tf.float32)
tsImage = tf.reshape(tsImage, shape=[1,168*300*3])

matWeights = tf.Variable(tf.random_normal([168*300*3, 2]))
vBiases = tf.Variable(tf.zeros([2]))
vPredictions = tf.nn.softmax(tf.matmul(tsImage, matWeights) + vBiases)
fCrossEntropy = tf.reduce_mean(-tf.reduce_sum(tsLabels * tf.log(vPredictions), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.1).minimize(fCrossEntropy)
init = tf.global_variables_initializer()

with tf.Session() as sess : 
    sess.run(init)
    for i in range (1000) : 
    tsTrainingSets = tf.train.batch([tsImage,tsLabels], batch_size=100)
    sess.run(train_step)
        if i % 20 == 0 : 
            correct_prediction = tf.equal(tf.argmax(vPredictions,1),tf.argmax(tsTrainingSets[1],1))
            accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
            print(sess.run(accuracy))
</code></pre>

<p>That strFilePaths is a standard python list containing all my image paths , iLabels is a list of lists representing labels. And I have only 2 classes in this case.</p>

<p>This program runs without error output but tensorflow just keeps on running and not giving me any output. I've read the ""reading files"" session in tensorflow website for like a thousand times but I still don't have a clue on whether I did things right or not.</p>

<p>Q1: What's wrong with this code?
Q2: Is there any complete example on how to read jpeg files into tensorflow and perform some training tasks on them?</p>
","While practicing on the official tensorflow mnist dataset tutorial for beginners, I'm trying to change the mnist data to my own images collected from search engines. That strFilePaths is a standard python list containing all my image paths , iLabels is a list of lists representing labels. And I have only 2 classes in this case. This program runs without error output but tensorflow just keeps on running and not giving me any output. I've read the ""reading files"" session in tensorflow website for like a thousand times but I still don't have a clue on whether I did things right or not. Q1: What's wrong with this code? Q2: Is there any complete example on how to read jpeg files into tensorflow and perform some training tasks on them?",https://stackoverflow.com/questions/41651034,3205742,Requesting (Additional) Resources,Documentation Ambiguity,"I've read the ""reading files"" session in tensorflow website for like a thousand times but I still don't have a clue on whether I did things right or not."
44975585,Reading data in tensorflow,"<p>I am learning how to use tensorflow from the documentation. But, I cannot understand the below two functions. I've tried searching the documentation but, I could not get a clear answer.</p>

<pre><code>input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x_train}, y_train,
                                          batch_size=4,
                                          num_epochs=1000)
eval_input_fn = tf.contrib.learn.io.numpy_input_fn(
    {""x"":x_eval}, y_eval, batch_size=4, num_epochs=1000)
</code></pre>

<p>Also, it would be great if you could explain what the parameters in the functions are. Thanks in advance!</p>
","I am learning how to use tensorflow from the documentation. But, I cannot understand the below two functions. I've tried searching the documentation but, I could not get a clear answer. Also, it would be great if you could explain what the parameters in the functions are. Thanks in advance!",https://stackoverflow.com/questions/44975585,5459235,Documentation Ambiguity,Documentation Ambiguity,"I am learning how to use tensorflow from the documentation. But, I cannot understand the below two functions. I've tried searching the documentation but, I could not get a clear answer."
45204898,what TensorFlow hash_bucket_size matters,"<p>I am creating a DNNclassifier with sparse columns. The training data looks like this,</p>

<pre><code>samples        col1                         col2          price label
  eg1    [[0,1,0,0,0,2,0,1,0,3,...]    [[0,0,4,5,0,...]    5.2    0
  eg2    [0,0,...]                     [0,0,...]            0     1
  eg3    [0,0,...]]                    [0,0,...]            0     1
</code></pre>

<p>The following snippet can run successfully,</p>

<pre><code>import tensorflow as tf

sparse_feature_a = tf.contrib.layers.sparse_column_with_hash_bucket('col1', 3, dtype=tf.int32)
sparse_feature_b = tf.contrib.layers.sparse_column_with_hash_bucket('col2', 1000, dtype=tf.int32)

sparse_feature_a_emb = tf.contrib.layers.embedding_column(sparse_id_column=sparse_feature_a, dimension=2)
sparse_feature_b_emb = tf.contrib.layers.embedding_column(sparse_id_column=sparse_feature_b, dimension=2)
feature_c = tf.contrib.layers.real_valued_column('price')

estimator = tf.contrib.learn.DNNClassifier(
    feature_columns=[sparse_feature_a_emb, sparse_feature_b_emb, feature_c],
    hidden_units=[5, 3],
    n_classes=2,
    model_dir='./tfTmp/tfTmp0')

# Input builders
def input_fn_train(): # returns x, y (where y represents label's class index).
    features = {'col1': tf.SparseTensor(indices=[[0, 1], [0, 5], [0, 7], [0, 9]],
                                  values=[1, 2, 1, 3],
                                  dense_shape=[3, int(250e6)]),
                'col2': tf.SparseTensor(indices=[[0, 2], [0, 3]],
                                    values=[4, 5],
                                    dense_shape=[3, int(100e6)]),
                        'price': tf.constant([5.2, 0, 0])}
    labels = tf.constant([0, 1, 1])
    return features, labels

estimator.fit(input_fn=input_fn_train, steps=100)
</code></pre>

<p>However, I have a question from this sentence,</p>

<pre><code>sparse_feature_a = tf.contrib.layers.sparse_column_with_hash_bucket('col1', 3, dtype=tf.int32)
</code></pre>

<p>where 3 means <strong>hash_bucket_size=3</strong>, but this sparse tensor includes 4 non-zero values,</p>

<pre><code>'col1': tf.SparseTensor(indices=[[0, 1], [0, 5], [0, 7], [0, 9]],
                              values=[1, 2, 1, 3],
                              dense_shape=[3, int(250e6)])
</code></pre>

<p>It seems <em>has_bucket_size</em> does nothing here. No matter how many non-zero values you have in your sparse tensor, you just need to set it with an integer > 1 and it works correctly.</p>

<p>I know my understanding may not be right. Could anyone explain how <strong>has_bucket_size</strong> works? Thanks a lot!</p>
","I am creating a DNNclassifier with sparse columns. The training data looks like this, The following snippet can run successfully, However, I have a question from this sentence, where 3 means hash_bucket_size=3, but this sparse tensor includes 4 non-zero values, It seems has_bucket_size does nothing here. No matter how many non-zero values you have in your sparse tensor, you just need to set it with an integer &gt; 1 and it works correctly. I know my understanding may not be right. Could anyone explain how has_bucket_size works? Thanks a lot!",https://stackoverflow.com/questions/45204898,5878281,Documentation Ambiguity,Documentation Ambiguity,I know my understanding may not be right. Could anyone explain how has_bucket_size works? 
45679562,Output from fully connected network in tensorflow,"<pre><code>weights = {

# 5x5 conv, 1 input, 32 outputs

'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),
`# 5x5 conv, 32 inputs, 64 outputs`

'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])), 

# fully connected, 7*7*64 inputs, 1024 outputs
'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])), 
 # 1024 inputs, 10 outputs (class prediction)



'out': tf.Variable(tf.random_normal([1024, n_classes])) 


}
</code></pre>

<p>In this code,the output from fully connected layer is given as 1024 but I cannot understand from which calculation this '1024' is generated and I cannot find any satisfactory answer from tensorflow documentation.And How this ouput size affects the prediction result.
Thanks in advance.</p>
","In this code,the output from fully connected layer is given as 1024 but I cannot understand from which calculation this '1024' is generated and I cannot find any satisfactory answer from tensorflow documentation.And How this ouput size affects the prediction result. Thanks in advance.",https://stackoverflow.com/questions/45679562,7580858,Documentation Ambiguity,Documentation Ambiguity,I cannot understand from which calculation this '1024' is generated and I cannot find any satisfactory answer from tensorflow documentation.
46820500,How to handle large amouts of data in tensorflow?,"<p>For my project I have large amounts of data, about 60GB spread into npy files, each holding about 1GB, each containing about 750k records and labels.</p>

<p>Each record is a 345 float32  and the labels are 5 float32.</p>

<p>I read the tensorflow dataset documentation and the queues / threads documentation as well but I can't figure out how to best handle the input for training and then how save the model and weights for future predicting.</p>

<p>My model is pretty straight forward, it looks like this:</p>

<pre><code>x = tf.placeholder(tf.float32, [None, 345], name='x')
y = tf.placeholder(tf.float32, [None, 5], name='y')
wi, bi = weight_and_bias(345, 2048)
hidden_fc = tf.nn.sigmoid(tf.matmul(x, wi) + bi)
wo, bo = weight_and_bias(2048, 5)
out_fc = tf.nn.sigmoid(tf.matmul(hidden_fc, wo) + bo)
loss = tf.reduce_mean(tf.squared_difference(y, out_fc))
train_op = tf.train.AdamOptimizer().minimize(loss)
</code></pre>

<p>The way I was training my neural net was reading the files one at a time in a random order then using a shuffled numpy array to index each file and manually creating each batch to feed the <code>train_op</code> using <code>feed_dict</code>. From everything I read this is very inefficient and I should somehow replace it with datasets or queue and threads but as I said the documentation was of no help.</p>

<p>So, what is the best way to handle large amounts of data in tensorflow?</p>

<p>Also, for reference, my data was saved to a numpy file in a 2 operation step:</p>

<pre><code>with open('datafile1.npy', 'wb') as fp:
    np.save(data, fp)
    np.save(labels, fp)
</code></pre>
","For my project I have large amounts of data, about 60GB spread into npy files, each holding about 1GB, each containing about 750k records and labels. Each record is a 345 float32 and the labels are 5 float32. I read the tensorflow dataset documentation and the queues / threads documentation as well but I can't figure out how to best handle the input for training and then how save the model and weights for future predicting. My model is pretty straight forward, it looks like this: The way I was training my neural net was reading the files one at a time in a random order then using a shuffled numpy array to index each file and manually creating each batch to feed the train_op using feed_dict. From everything I read this is very inefficient and I should somehow replace it with datasets or queue and threads but as I said the documentation was of no help. So, what is the best way to handle large amounts of data in tensorflow? Also, for reference, my data was saved to a numpy file in a 2 operation step:",https://stackoverflow.com/questions/46820500,686572,Inadequate Examples,Documentation Ambiguity,I read the tensorflow dataset documentation and the queues / threads documentation as well but I can't figure out how to best handle the input for training and then how save the model and weights for future predicting.
47058158,restoring two Tensorflow models,"<p>I have trained two separate Tensorflow models and would like to use them both in one Jupyter notebook. I am following the following <a href=""https://stackoverflow.com/questions/41607144/loading-two-models-from-saver-in-the-same-tensorflow-session"">SO post</a>. However, I would like to avoid using <code>with</code> statement as it obscures my understanding of what is happening. Here is my code and error messages:</p>

<pre><code>meta_path_1 = r'.\NN state save\case_guessing-3.meta'
checkpoint_path_1 = r'.\NN state save'

meta_path_2 = r'.\NN state save\class_guessing-3.meta'
checkpoint_path_2 = r'.\NN state save'

new_all_saver_1 = tf.train.import_meta_graph(meta_path_1)
new_all_saver_2 = tf.train.import_meta_graph(meta_path_2)

graph_1 = tf.Graph()
graph_2 = tf.Graph()

sess_1 = tf.Session(graph = graph_1)
sess_2 = tf.Session(graph = graph_2)

new_all_saver_1.restore(sess_1, tf.train.latest_checkpoint(checkpoint_path_1))
new_all_saver_2.restore(sess_2, tf.train.latest_checkpoint(checkpoint_path_2))

predict_tensor_1= graph_1.get_tensor_by_name('predictions:0')
predict_tensor_2= graph_2.get_tensor_by_name('predictions:0')

x_1=graph_1.get_tensor_by_name('input_placeholder:0')
x_2=graph_2.get_tensor_by_name('input_placeholder:0')

print(sess_1.run(tf.shape(x_1)))
print(sess_2.run(tf.shape(x_2)))
</code></pre>

<p>Here is error message:</p>

<pre><code>INFO:tensorflow:Restoring parameters from .\TNC-Kaggle\Output\NN_1\NN state save\case_guessing-3
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-18-9f8dfdc2cc26&gt; in &lt;module&gt;()
     14 sess_2 = tf.Session(graph = graph_2)
     15 
---&gt; 16 new_all_saver_1.restore(sess_1, tf.train.latest_checkpoint(checkpoint_path_1))
     17 new_all_saver_2.restore(sess_2, tf.train.latest_checkpoint(checkpoint_path_2))
     18 

~\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\training\saver.py in restore(self, sess, save_path)
   1558     logging.info(""Restoring parameters from %s"", save_path)
   1559     sess.run(self.saver_def.restore_op_name,
-&gt; 1560              {self.saver_def.filename_tensor_name: save_path})
   1561 
   1562   @staticmethod

~\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    893     try:
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 895                          run_metadata_ptr)
    896       if run_metadata:
    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

~\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1051       raise RuntimeError('Attempted to use a closed Session.')
   1052     if self.graph.version == 0:
-&gt; 1053       raise RuntimeError('The Session graph is empty.  Add operations to the '
   1054                          'graph before calling run().')
   1055 

RuntimeError: The Session graph is empty.  Add operations to the graph before calling run().
</code></pre>

<p>How can I fix it? I already re-read multiple times google docs on interaction between graph and session, but I am still unclear what is missing. Inserging <code>as_default()</code> as some places produced different errors (too many to reproduce here)</p>
","I have trained two separate Tensorflow models and would like to use them both in one Jupyter notebook. I am following the following SO post. However, I would like to avoid using with statement as it obscures my understanding of what is happening. Here is my code and error messages: Here is error message: How can I fix it? I already re-read multiple times google docs on interaction between graph and session, but I am still unclear what is missing. Inserging as_default() as some places produced different errors (too many to reproduce here)",https://stackoverflow.com/questions/47058158,1700890,Documentation Ambiguity,Documentation Ambiguity,"I already re-read multiple times google docs on interaction between graph and session, but I am still unclear what is missing."
47117498,Does `tf.data.Dataset.repeat()` buffer the entire dataset in memory?,"<p>
Looking at this code example from the TF documentation:</p>

<pre class=""lang-py prettyprint-override""><code>filenames = [""/var/data/file1.tfrecord"", ""/var/data/file2.tfrecord""]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(32)
dataset = dataset.repeat(num_epochs)
iterator = dataset.make_one_shot_iterator()
</code></pre>

<p>Does the <code>dataset.repeat(num_epochs)</code> require that the entire dataset be loaded into memory? Or is it re-initializing the dataset(s) that came before it when it receives an end-of-dataset exception?</p>

<p>The documentation is ambiguous about this point.</p>
",Looking at this code example from the TF documentation: Does the dataset.repeat(num_epochs) require that the entire dataset be loaded into memory? Or is it re-initializing the dataset(s) that came before it when it receives an end-of-dataset exception? The documentation is ambiguous about this point.,https://stackoverflow.com/questions/47117498,4790871,Documentation Ambiguity,Documentation Ambiguity,The documentation is ambiguous about this point.
48038889,why embedding_lookup only used as encoder but no decoder in ptb_word_ln.py,"<p>I have a question about embedding_lookup while I looking the tensorflow's official sample code ptb_word_ln.py.
<a href=""https://i.stack.imgur.com/jIc00.png"" rel=""nofollow noreferrer"">the embedding_lookup node</a></p>

<p>I found it is only used as an input. the output doesn't use this. so the loss evaluation cannot be benefit from this embedding. so what is the benefit using embedding_lookup here? If I want to use this word-embedding in the optimizer, shouldn't I connect it with loss function explicitly?</p>

<p>the source code as following:</p>

<pre><code>self._input = input_

batch_size = input_.batch_size
num_steps = input_.num_steps
size = config.hidden_size
vocab_size = config.vocab_size

def lstm_cell():
  # With the latest TensorFlow source code (as of Mar 27, 2017),
  # the BasicLSTMCell will need a reuse parameter which is unfortunately not
  # defined in TensorFlow 1.0. To maintain backwards compatibility, we add
  # an argument check here:
  if 'reuse' in inspect.getargspec(
      tf.contrib.rnn.BasicLSTMCell.__init__).args:
    return tf.contrib.rnn.BasicLSTMCell(
        size, forget_bias=0.0, state_is_tuple=True,
        reuse=tf.get_variable_scope().reuse)
  else:
    return tf.contrib.rnn.BasicLSTMCell(
        size, forget_bias=0.0, state_is_tuple=True)
attn_cell = lstm_cell
if is_training and config.keep_prob &lt; 1:
  def attn_cell():
    return tf.contrib.rnn.DropoutWrapper(
        lstm_cell(), output_keep_prob=config.keep_prob)
cell = tf.contrib.rnn.MultiRNNCell(
    [attn_cell() for _ in range(config.num_layers)], state_is_tuple=True)

self._initial_state = cell.zero_state(batch_size, data_type())

with tf.device(""/cpu:0""):
  embedding = tf.get_variable(
      ""embedding"", [vocab_size, size], dtype=data_type())
  inputs = tf.nn.embedding_lookup(embedding, input_.input_data)#only use embeddings here

if is_training and config.keep_prob &lt; 1:
  inputs = tf.nn.dropout(inputs, config.keep_prob)

outputs = []
state = self._initial_state
with tf.variable_scope(""RNN""):
  for time_step in range(num_steps):
    if time_step &gt; 0: tf.get_variable_scope().reuse_variables()
    (cell_output, state) = cell(inputs[:, time_step, :], state)
    outputs.append(cell_output)

output = tf.reshape(tf.stack(axis=1, values=outputs), [-1, size])
softmax_w = tf.get_variable(
    ""softmax_w"", [size, vocab_size], dtype=data_type())
softmax_b = tf.get_variable(""softmax_b"", [vocab_size], dtype=data_type())
logits = tf.matmul(output, softmax_w) + softmax_b
loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(
    [logits],
    [tf.reshape(input_.targets, [-1])],
    [tf.ones([batch_size * num_steps], dtype=data_type())])
self._cost = cost = tf.reduce_sum(loss) / batch_size
self._final_state = state

if not is_training:
  return

self._lr = tf.Variable(0.0, trainable=False)
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),
                                  config.max_grad_norm)
optimizer = tf.train.GradientDescentOptimizer(self._lr)
self._train_op = optimizer.apply_gradients(
    zip(grads, tvars),
    global_step=tf.contrib.framework.get_or_create_global_step())

self._new_lr = tf.placeholder(
    tf.float32, shape=[], name=""new_learning_rate"")
self._lr_update = tf.assign(self._lr, self._new_lr)
</code></pre>
","I have a question about embedding_lookup while I looking the tensorflow's official sample code ptb_word_ln.py. the embedding_lookup node I found it is only used as an input. the output doesn't use this. so the loss evaluation cannot be benefit from this embedding. so what is the benefit using embedding_lookup here? If I want to use this word-embedding in the optimizer, shouldn't I connect it with loss function explicitly? the source code as following:",https://stackoverflow.com/questions/48038889,3134227,Documentation Ambiguity,Documentation Ambiguity,I have a question about embedding_lookup while I looking the tensorflow's official sample code ptb_word_ln.py. the embedding_lookup node I found it is only used as an input.
48067854,Trouble understanding tensorflow shuffle_batch enqueue_many=False,"<p>I am reading the Tensorflow documentation and the code for the Cifar10 example.  This bit is currently racking my brain:</p>

<pre><code># Creates batches of 32 images and 32 labels.
image_batch, label_batch = tf.train.shuffle_batch(
  [single_image, single_label],
  batch_size=32,
  num_threads=4,
  capacity=50000,
  min_after_dequeue=10000)
</code></pre>

<p>We are passing in a single image, and somehow a batch of images results?? What is going on here?</p>
","I am reading the Tensorflow documentation and the code for the Cifar10 example. This bit is currently racking my brain: We are passing in a single image, and somehow a batch of images results?? What is going on here?",https://stackoverflow.com/questions/48067854,2886575,Documentation Ambiguity,Documentation Ambiguity,I am reading the Tensorflow documentation and the code for the Cifar10 example. This bit is currently racking my brain
48091693,tensorflow Dataset API diff between make_initializable_iterator and make_one_shot_iterator,"<p>I want to know the difference between <code>make_initializable_iterator</code> and <code>make_one_shot_iterator</code>.<br>
1. Tensorflow documentations said that <code>A ""one-shot"" iterator does not currently support re-initialization.</code> What exactly does that mean?<br>
2.  Are the following 2 snippets equivalent?<br>
Use <code>make_initializable_iterator</code>  </p>

<pre><code>iterator = data_ds.make_initializable_iterator()
data_iter = iterator.get_next()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
for e in range(1, epoch+1):
    sess.run(iterator.initializer)
    while True:
        try:
            x_train, y_train = sess.run([data_iter])
            _, cost = sess.run([train_op, loss_op], feed_dict={X: x_train,
                                                               Y: y_train})
        except tf.errors.OutOfRangeError:   
            break
sess.close()
</code></pre>

<p>Use <code>make_one_shot_iterator</code>  </p>

<pre><code>iterator = data_ds.make_one_shot_iterator()
data_iter = iterator.get_next()
sess = tf.Session()
sess.run(tf.global_variables_initializer())
for e in range(1, epoch+1):
    while True:
        try:
            x_train, y_train = sess.run([data_iter])
            _, cost = sess.run([train_op, loss_op], feed_dict={X: x_train,
                                                               Y: y_train})
        except tf.errors.OutOfRangeError:   
            break
sess.close()
</code></pre>
","I want to know the difference between make_initializable_iterator and make_one_shot_iterator. 1. Tensorflow documentations said that A ""one-shot"" iterator does not currently support re-initialization. What exactly does that mean? 2. Are the following 2 snippets equivalent? Use make_initializable_iterator Use make_one_shot_iterator",https://stackoverflow.com/questions/48091693,2641038,Documentation Ambiguity,Documentation Ambiguity,"Tensorflow documentations said that A ""one-shot"" iterator does not currently support re-initialization. What exactly does that mean? "
48458509,Strange behavior of tensorflow when dividing by 0 in tf.metrics.mean_absolute_error,"<p>So I do not know if is a bug or the problem is in my code, but I am trying to understand what is happening. 
when I run the model and got to estimate the accuracy using Mean Relative Error. I know in my validation data I have 0s so I was expecting to get some error or some inf. However this is not the case.
This is my code:</p>

<pre><code>X_test_norm = preprocessing.scale(X_test)
predictions = sess.run(pred, feed_dict={x: X_test_norm})
prediction = tf.convert_to_tensor(predictions)
expectation = tf.cast(Y_test, tf.float32)

MANUAL_MRE = tf.reduce_mean(tf.abs((Y_test - tf.transpose(predictions)) / Y_test))
MAE_op, MAE = tf.metrics.mean_absolute_error(expectation, prediction)
MRE_op, MRE = tf.metrics.mean_relative_error(expectation, prediction, expectation)
tf.local_variables_initializer().run()

print(""MANUAL_MRE: %4f"" % sess.run(MANUAL_MRE))
print(""MRE: %4f"" % sess.run(MRE))
print(""MAE: %4f"" % sess.run(MAE))
</code></pre>

<p>This is the output:</p>

<pre><code>MANUAL_MRE:  inf

MRE: 1.603528

MAE: 76.489990
</code></pre>

<p>When I run it on a data that has values bigger than 0, my <code>MANUAL_MRE</code> and MRE values are the same like it should be. I checked the documentation of TF and the first case does not make sense. </p>

<p>Can someone tell me where I am wrong or I just found a bug/ new feature. </p>
","So I do not know if is a bug or the problem is in my code, but I am trying to understand what is happening. when I run the model and got to estimate the accuracy using Mean Relative Error. I know in my validation data I have 0s so I was expecting to get some error or some inf. However this is not the case. This is my code: This is the output: When I run it on a data that has values bigger than 0, my MANUAL_MRE and MRE values are the same like it should be. I checked the documentation of TF and the first case does not make sense. Can someone tell me where I am wrong or I just found a bug/ new feature.",https://stackoverflow.com/questions/48458509,4898951,Documentation Completeness,Documentation Ambiguity,I checked the documentation of TF and the first case does not make sense.
48947083,Re-train pre-trained ResNet-50 model with tf slim for classification purposes,"<p>I would like to re-train a pre-trained ResNet-50 model with TensorFlow slim, and use it later for classifying purposes. </p>

<p>The ResNet-50 is designed to 1000 classes, but I would like just 10 classes (land cover types) as output.</p>

<p>First, I try to code it for only one image, what I can generalize later.
So this is my code:</p>

<pre><code>from tensorflow.contrib.slim.nets import resnet_v1
import tensorflow as tf
import tensorflow.contrib.slim as slim
import numpy as np

batch_size = 1
height, width, channels = 224, 224, 3
# Create graph
inputs = tf.placeholder(tf.float32, shape=[batch_size, height, width, channels])
with slim.arg_scope(resnet_v1.resnet_arg_scope()):
    logits, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False)

saver = tf.train.Saver()    

with tf.Session() as sess:
    saver.restore(sess, 'd:/bitbucket/cnn-lcm/data/ckpt/resnet_v1_50.ckpt')
    representation_tensor = sess.graph.get_tensor_by_name('resnet_v1_50/pool5:0')
    #  list of files to read
    filename_queue = tf.train.string_input_producer(['d:/bitbucket/cnn-lcm/data/train/AnnualCrop/AnnualCrop_735.jpg']) 
    reader = tf.WholeFileReader()
    key, value = reader.read(filename_queue)
    img = tf.image.decode_jpeg(value, channels=3)    

    im = np.array(img)
    im = im.reshape(1,224,224,3)
    predict_values, logit_values = sess.run([end_points, logits], feed_dict= {inputs: im})
    print (np.max(predict_values), np.max(logit_values))
    print (np.argmax(predict_values), np.argmax(logit_values))

    #img = ...  #load image here with size [1, 224,224, 3]
    #features = sess.run(representation_tensor, {'Placeholder:0': img})
</code></pre>

<p>I am a bit confused about what comes next (I should open a graph, or I should load the structure of the network and load the weights, or load batches. There is a problem with the image shape as well. There are a lot of versatile documentations, which aren't easy to interpret :/</p>

<p>Any advice how to correct the code in order to fit my purposes?</p>

<p>The test image: AnnualCrop735</p>

<p><a href=""https://i.stack.imgur.com/RRd4u.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RRd4u.jpg"" alt=""AnnualCrop735""></a></p>
","I would like to re-train a pre-trained ResNet-50 model with TensorFlow slim, and use it later for classifying purposes. The ResNet-50 is designed to 1000 classes, but I would like just 10 classes (land cover types) as output. First, I try to code it for only one image, what I can generalize later. So this is my code: I am a bit confused about what comes next (I should open a graph, or I should load the structure of the network and load the weights, or load batches. There is a problem with the image shape as well. There are a lot of versatile documentations, which aren't easy to interpret :/ Any advice how to correct the code in order to fit my purposes? The test image: AnnualCrop735",https://stackoverflow.com/questions/48947083,4569591,Requesting (Additional) Resources,Documentation Ambiguity,"There are a lot of versatile documentations, which aren't easy to interpret"
49150587,"Distributed TensorFlow [Async, Between-Graph Replication]: which are the exactly interaction between workers and servers regarding Variables update","<p>I've read <a href=""https://www.tensorflow.org/deploy/distributed"" rel=""nofollow noreferrer"">Distributed TensorFlow Doc</a> and <a href=""https://stackoverflow.com/q/43147435/9099269"">this question on StackOverflow</a> but I still have some doubt about the dynamics behind the distributed training that can be done with TensorFlow and its Parameter Server Architecture.
This is a snipped of code from the Distributed TensorFlow Doc:</p>
<pre><code>if FLAGS.job_name == &quot;ps&quot;:
    server.join()
  elif FLAGS.job_name == &quot;worker&quot;:

    # Assigns ops to the local worker by default.
    with tf.device(tf.train.replica_device_setter(
        worker_device=&quot;/job:worker/task:%d&quot; % FLAGS.task_index,
        cluster=cluster)):

      # Build model...
      loss = ...
      global_step = tf.contrib.framework.get_or_create_global_step()

      train_op = tf.train.AdagradOptimizer(0.01).minimize(
          loss, global_step=global_step)
</code></pre>
<p>And here part of the answer of the StackOverflow question that I read:</p>
<blockquote>
<p>The worker reads all of the shared model parameters in parallel from
the PS task(s), and copies them to the worker task. These reads are
uncoordinated with any concurrent writes, and no locks are acquired:
in particular the worker may see partial updates from one or more
other workers (e.g. a subset of the updates from another worker may
have been applied, or a subset of the elements in a variable may have
been updated).</p>
<p>The worker computes gradients locally, based on a batch
of input data and the parameter values that it read in step 1.</p>
<p>The
worker sends the gradients for each variable to the appropriate PS
task, and applies the gradients to their respective variable, using an
update rule that is determined by the optimization algorithm (e.g.
SGD, SGD with Momentum, Adagrad, Adam, etc.). The update rules
typically use (approximately) commutative operations, so they may be
applied independently on the updates from each worker, and the state
of each variable will be a running aggregate of the sequence of
updates received.</p>
</blockquote>
<p>I have to reproduce this kind of parameter server architecture in another environment and I need to deeply understand how workers and PS tasks interact with each other inside the TensorFlow framework.
My question is, does the PS task do some kind of merging or updating operation after receiving the value from the workers or it just store the newest value ? Can be something reasonable just storing the newest value ? Looking at the code from the TensorFlow documentation I see that the PS task just do a join() and I wonder behind this method call which are the complete behaviour of the PS task.</p>
<p>One more question, what is the difference between compute a gradient and apply a gradient ?</p>
","I've read Distributed TensorFlow Doc and this question on StackOverflow but I still have some doubt about the dynamics behind the distributed training that can be done with TensorFlow and its Parameter Server Architecture. This is a snipped of code from the Distributed TensorFlow Doc: And here part of the answer of the StackOverflow question that I read: I have to reproduce this kind of parameter server architecture in another environment and I need to deeply understand how workers and PS tasks interact with each other inside the TensorFlow framework. My question is, does the PS task do some kind of merging or updating operation after receiving the value from the workers or it just store the newest value ? Can be something reasonable just storing the newest value ? Looking at the code from the TensorFlow documentation I see that the PS task just do a join() and I wonder behind this method call which are the complete behaviour of the PS task. One more question, what is the difference between compute a gradient and apply a gradient ?",https://stackoverflow.com/questions/49150587,9099269,Requesting (Additional) Resources,Documentation Ambiguity,I've read Distributed TensorFlow Doc and this question on StackOverflow but I still have some doubt about the dynamics behind the distributed training that can be done with TensorFlow and its Parameter Server Architecture.
49482390,"Tensorflow, replacing feed_dict with Dataset.from_generator","<p>I have an existing model which reads through a text file in a loop, the resulting input and output looks like this:</p>

<pre><code>    self.X = tf.placeholder('float32', shape=[None, None, max_word_length, ALPHABET_SIZE], name='X')
    self.Y = tf.placeholder('float32', shape=[None, 2], name='Y')
    ...
    _, c, a = sess.run([optimizer, cost, acc], feed_dict={self.X: batch_x, self.Y: batch_y})
</code></pre>

<p>But now i want to convert to using the Dataset.from_generator method, to get started i created a wrapper class around my text reader that implemted the generator function, this all works well, and returns the input data as expected:</p>

<pre><code>    dsr = DatasetReader(TRAIN_SET, BATCH_SIZE, max_word_length)
    ds = tf.data.Dataset.from_generator(dsr.generator, (tf.float32, tf.float32))
    ds = ds.prefetch(2)
    dsi = ds.make_one_shot_iterator()
    self.X, self.Y = dsi.get_next()
    _, c, a = sess.run([optimizer, cost, acc])
</code></pre>

<p>However i am getting an error</p>

<pre><code>InvalidArgumentError: You must feed a value for placeholder tensor 'X' with dtype float and shape [?,?,16,70]
</code></pre>

<p>And i assume this is because i have declared X/Y inputs as placeholders, the documentation states the values must be fed via feed_dict.</p>

<p>So i got a couple of questions:</p>

<ol>
<li><p>How do i convert from feed_dict and placeholders to using the from_generator correctly? I want to keep the naming of the tensors X and Y so i am able to feed them in by that name during inference</p></li>
<li><p>More generally, I dont see how the dataset and its iterator is linked to the session, is it linked purely by virtue of the iterator outputs being used as inputs to other operations in the graph?</p></li>
</ol>
","I have an existing model which reads through a text file in a loop, the resulting input and output looks like this: But now i want to convert to using the Dataset.from_generator method, to get started i created a wrapper class around my text reader that implemted the generator function, this all works well, and returns the input data as expected: However i am getting an error And i assume this is because i have declared X/Y inputs as placeholders, the documentation states the values must be fed via feed_dict. So i got a couple of questions:",https://stackoverflow.com/questions/49482390,1371314,Requesting (Additional) Resources,Documentation Ambiguity,The documentation states the values must be fed via feed_dict. So i got a couple of questions
49560420,Deep Learning implementation in Tensorflow or Keras give drastic different results,"<p><em><strong>Context:</strong> I'm using a fully convolutional network to perform image segmentation. Typically, the input is an RGB image <code>shape = [512, 256]</code> and the target is a 2 channels binary mask defining the annotated regions (2nd channel is the opposite of the fist channel).</em></p>
<p><strong>Question:</strong> I have the same CNN implementation using Tensorflow and Keras. But the Tensorflow model doesn't start learning. Actually, the <code>loss</code> even grows with the number of epochs! What is wrong in this Tensorflow implementation that prevents it from learning?</p>
<p><strong>Setup:</strong> The dataset is split into 3 subsets: training (78%), testing (8%) and validation (14%) sets which are fed to the network by batches of 8 images. The graphs show the evolution of the <code>loss</code> for each subsets. The images show the <code>prediction</code> after 10 epoch for two different images.</p>
<hr />
<p><strong>Tensorflow</strong> implementation and results</p>
<pre><code>import tensorflow as tf

tf.reset_default_graph()
x = inputs = tf.placeholder(tf.float32, shape=[None, shape[1], shape[0], 3])
targets = tf.placeholder(tf.float32, shape=[None, shape[1], shape[0], 2])

for d in range(4):
    x = tf.layers.conv2d(x, filters=np.exp2(d+4), kernel_size=[3,3], strides=[1,1], padding=&quot;SAME&quot;, activation=tf.nn.relu)
    x = tf.layers.max_pooling2d(x, strides=[2,2], pool_size=[2,2], padding=&quot;SAME&quot;)
    
x = tf.layers.conv2d(x, filters=2, kernel_size=[1,1])
logits = tf.image.resize_images(x, [shape[1], shape[0]], align_corners=True)
prediction = tf.nn.softmax(logits)

loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=logits))
optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(loss)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

def run(mode, x_batch, y_batch):
    if mode == 'TRAIN':
        return sess.run([loss, optimizer], feed_dict={inputs: x_batch, targets: y_batch})
    else:
        return sess.run([loss, prediction], feed_dict={inputs: x_batch, targets: y_batch})
</code></pre>
<p><a href=""https://i.stack.imgur.com/cTbWl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cTbWl.png"" alt=""Tensorflow loss evolution"" /></a>
<a href=""https://i.stack.imgur.com/6Gbgm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6Gbgm.png"" alt=""Tensorflow prediction after 10 epochs"" /></a></p>
<hr />
<p><strong>Keras</strong> implementation and reslults</p>
<pre><code>import keras as ke

ke.backend.clear_session()
x = inputs = ke.layers.Input(shape=[shape[1], shape[0], 3])

for d in range(4):
    x = ke.layers.Conv2D(int(np.exp2(d+4)), [3,3], padding=&quot;SAME&quot;, activation=&quot;relu&quot;)(x)
    x = ke.layers.MaxPool2D(padding=&quot;SAME&quot;)(x)

x = ke.layers.Conv2D(2, [1,1], padding=&quot;SAME&quot;)(x)
logits = ke.layers.Lambda(lambda x: ke.backend.tf.image.resize_images(x, [shape[1], shape[0]], align_corners=True))(x)
prediction = ke.layers.Activation('softmax')(logits)

model = ke.models.Model(inputs=inputs, outputs=prediction)
model.compile(optimizer=&quot;rmsprop&quot;, loss=&quot;categorical_crossentropy&quot;)

def run(mode, x_batch, y_batch):
    if mode == 'TRAIN':
        loss = model.train_on_batch(x=x_batch, y=y_batch)
        return loss, None
    else:
        loss = model.evaluate(x=x_batch, y=y_batch, batch_size=None, verbose=0)
        prediction = model.predict(x=x_batch, batch_size=None)
        return loss, prediction
</code></pre>
<p><a href=""https://i.stack.imgur.com/OXMFd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OXMFd.png"" alt=""Keras loss evolution"" /></a>
<a href=""https://i.stack.imgur.com/O0f8E.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/O0f8E.png"" alt=""Keras prediction after 10 epochs"" /></a></p>
<hr />
<p>There must be a difference between the two but my understanding of the documentation lead me nowhere. I would be really interested to know where the difference lies. Thanks in advance!</p>
","Context: I'm using a fully convolutional network to perform image segmentation. Typically, the input is an RGB image shape = [512, 256] and the target is a 2 channels binary mask defining the annotated regions (2nd channel is the opposite of the fist channel). Question: I have the same CNN implementation using Tensorflow and Keras. But the Tensorflow model doesn't start learning. Actually, the loss even grows with the number of epochs! What is wrong in this Tensorflow implementation that prevents it from learning? Setup: The dataset is split into 3 subsets: training (78%), testing (8%) and validation (14%) sets which are fed to the network by batches of 8 images. The graphs show the evolution of the loss for each subsets. The images show the prediction after 10 epoch for two different images. Tensorflow implementation and results Keras implementation and reslults There must be a difference between the two but my understanding of the documentation lead me nowhere. I would be really interested to know where the difference lies. Thanks in advance!",https://stackoverflow.com/questions/49560420,1782553,Documentation Ambiguity,Documentation Ambiguity,There must be a difference between the two but my understanding of the documentation lead me nowhere.
49607071,use of updated weights in tensorflow,"<p>I have tried a sample example in tensorflow. My question is when I run y_pred with the same initial features x, does it use weights updated in the preceding for loop or it just uses the initialized weights. </p>

<pre><code>#linear regression for y = -(x-1)
x = tf.placeholder(dtype=tf.float32,shape=(None,1))
y_true = tf.placeholder(dtype=tf.float32,shape=(None,1))

linear_model = tf.layers.Dense(units=1)
y_pred = linear_model(x)

sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)

loss = tf.losses.mean_squared_error(labels = y_true,predictions=y_pred)
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
train = optimizer.minimize(loss)
for i in range(1000):
    _,loss_ = sess.run((train,loss),{x:[[0],[1],[2],[3]],y_true:[[1],[0],[-1],[-2]]})

print(sess.run(y_pred,{x:[[0],[1],[2],[3]]}))
</code></pre>

<p>My confusion arises from the documentation when it says that, to calculate the output of an operation it backtracks. So, to calculate y_pred, it backtracks and initialize the weights and calculate y_pred using x? or does it use already updated weights of the Dense layer?</p>

<p>The output of the above code is:</p>

<pre><code>[[ 0.9960759 ]
 [-0.00208616]
 [-1.0002482 ]
 [-1.9984105 ]]
</code></pre>
","I have tried a sample example in tensorflow. My question is when I run y_pred with the same initial features x, does it use weights updated in the preceding for loop or it just uses the initialized weights. My confusion arises from the documentation when it says that, to calculate the output of an operation it backtracks. So, to calculate y_pred, it backtracks and initialize the weights and calculate y_pred using x? or does it use already updated weights of the Dense layer? The output of the above code is:",https://stackoverflow.com/questions/49607071,4985049,Documentation Ambiguity,Documentation Ambiguity,"My confusion arises from the documentation when it says that, to calculate the output of an operation it backtracks."
49944223,Tensorflow Hub Image Modules: Clarity on Preprocessing and Output values,"<p>Many thanks for support!
I currently use TF Slim - and TF Hub seems like a very useful addition for transfer learning. However the following things are not clear from the documentation:<BR><BR>
<strong>1. Is preprocessing done implicitly?</strong> Is this based on ""trainable=True/False"" parameter in constructor of module?</p>

<pre><code>module = hub.Module(""https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1"", trainable=True)
</code></pre>

<p>When I use Tf-slim I use the preprocess method:<BR></p>

<pre><code>inception_preprocessing.preprocess_image(image, img_height, img_width, is_training)
</code></pre>

<p><strong>2.How to get access to AuxLogits for an inception model?</strong> Seems to be missing:</p>

<pre><code>import tensorflow_hub as hub
import tensorflow as tf

img = tf.random_uniform([10,299,299,3])
module = hub.Module(""https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1"", trainable=True)
outputs = module(dict(images=img), signature=""image_feature_vector"", as_dict=True)
</code></pre>

<p>The output is</p>

<pre><code>dict_keys(['InceptionV3/Mixed_6b', 'InceptionV3/MaxPool_5a_3x3', 'InceptionV3/Mixed_6c', 'InceptionV3/Mixed_6d', 'InceptionV3/Mixed_6e', 'InceptionV3/Mixed_7a', 'InceptionV3/Mixed_7b', 'InceptionV3/Conv2d_2a_3x3', 'InceptionV3/Mixed_7c', 'InceptionV3/Conv2d_4a_3x3', 'InceptionV3/Conv2d_1a_3x3', 'InceptionV3/global_pool', 'InceptionV3/MaxPool_3a_3x3', 'InceptionV3/Conv2d_2b_3x3', 'InceptionV3/Conv2d_3b_1x1', 'default', 'InceptionV3/Mixed_5b', 'InceptionV3/Mixed_5c', 'InceptionV3/Mixed_5d', 'InceptionV3/Mixed_6a'])
</code></pre>
","Many thanks for support! I currently use TF Slim - and TF Hub seems like a very useful addition for transfer learning. However the following things are not clear from the documentation: 1. Is preprocessing done implicitly? Is this based on ""trainable=True/False"" parameter in constructor of module? When I use Tf-slim I use the preprocess method: 2.How to get access to AuxLogits for an inception model? Seems to be missing: The output is",https://stackoverflow.com/questions/49944223,6147954,Documentation Completeness,Documentation Ambiguity,However the following things are not clear from the documentation
51765061,Display realtime Training of model using tensorboard Python Tensorflow,"<p>I am unable to the documentation of the Tensorboard as there are many confusing stuffs for me.   </p>

<p>I want to know how I can display the complete training and validation movements of my model in tensorboard. I want to display values and how they are playing as input and what output is getting generated and the MSE error loss for the training and validation.    </p>

<p>Here is what tried till now. It only gives me the training loss result per iteration in an epoch.   </p>

<pre><code>seq_len = 9
## Basic Cell RNN in tensorflow
index_in_epoch = 0;
perm_array  = np.arange(x_train.shape[0])
np.random.shuffle(perm_array)
# function to get the next batch
def get_next_batch(batch_size):
    global index_in_epoch, x_train, perm_array   
    start = index_in_epoch
    index_in_epoch += batch_size

    if index_in_epoch &gt; x_train.shape[0]:
        np.random.shuffle(perm_array) # shuffle permutation array
        start = 0 # start next epoch
        index_in_epoch = batch_size

    end = index_in_epoch
    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]
# parameters
n_steps = seq_len-1 
n_inputs = x_train.shape[2]#4 

n_neurons = 400 
n_outputs = y_train.shape[1]#4
n_layers = 2
learning_rate = 0.000001

batch_size = 50
n_epochs = 100#200 
train_set_size = x_train.shape[0]
test_set_size = x_test.shape[0]

tf.reset_default_graph()

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_outputs])

# use Basic RNN Cell
layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)
          for layer in range(n_layers)]                                                                 
multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)
rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)
stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) 
stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)
outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])
outputs = outputs[:,n_steps-1,:] # keep only last output of sequence                                     
loss = tf.reduce_mean(tf.square(outputs - y)) # loss function = mean squared error 
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) 
training_op = optimizer.minimize(loss)
tf.summary.scalar('MyLoss', loss)
summ = tf.summary.merge_all()
</code></pre>

<p>Training starts like this:  </p>

<pre><code>saver = tf.train.Saver()
try:
    with tf.Session() as sess: 
        sess.run(tf.global_variables_initializer())        
        for iteration in range(int(n_epochs*train_set_size/batch_size)):
            x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch
            writer = tf.summary.FileWriter(""logs"", sess.graph)
            [_,s] = sess.run([training_op,summ], feed_dict={X: x_batch, y: y_batch}) 
            writer.add_summary(s, iteration)    
            if iteration % int(5*train_set_size/batch_size) == 0:
                mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) 
                mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) 
                print('%.2f epochs: MSE train/valid = %.10f/%.10f'%(
                    iteration*batch_size/train_set_size, mse_train, mse_valid))
                save_path = saver.save(sess, ""modelsOHLC\\model""+str(iteration)+"".ckpt"")                
            writer.close()
except KeyboardInterrupt:
    print(""Keyboard stopped"")
</code></pre>

<p>Please anyone please guide me what I can do to see my training and validation lively. I just cannot understand whether my data is making any sense to the model or not. Hence, visualization can become a better option for me. Please help me.</p>
","I am unable to the documentation of the Tensorboard as there are many confusing stuffs for me. I want to know how I can display the complete training and validation movements of my model in tensorboard. I want to display values and how they are playing as input and what output is getting generated and the MSE error loss for the training and validation. Here is what tried till now. It only gives me the training loss result per iteration in an epoch. Training starts like this: Please anyone please guide me what I can do to see my training and validation lively. I just cannot understand whether my data is making any sense to the model or not. Hence, visualization can become a better option for me. Please help me.",https://stackoverflow.com/questions/51765061,4948889,Documentation Ambiguity,Documentation Ambiguity,I am unable to the documentation of the Tensorboard as there are many confusing stuffs for me.
52177257,Noob stuck Tensor flow adjusting the array shape,"<p>first thank you for any help that you can give. I am absolutely lost on the shape in tensensorflow. I have searched google, StackOverflow, discord, and youtube. I want to run a RNN on a CSV file. </p>

<pre><code>import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras as keras

data = pd.read_csv(""Big Data Chart Final no symbol.csv"")
data.shape 
(2941, 120)
</code></pre>

<h1>I believe this is a 2d dimension array? My batch size is 120?</h1>

<pre><code>inputs=tf.placeholder('float',[None,2],name=""input"")
targets = tf.placeholder('float',name='Target')
</code></pre>

<p>#So I have 120 input neurons? Since I have 120 columns?</p>

<h1>then my input data is 120? and I have 2941 sets of inputs,correct? so my batch shape should be 2941,120?</h1>

<p>I am getting lost even trying to explain it. AM I on the right track? I know there is a lot of info out there and I did read the documentation. Any help would be greatly appreciated.</p>
","first thank you for any help that you can give. I am absolutely lost on the shape in tensensorflow. I have searched google, StackOverflow, discord, and youtube. I want to run a RNN on a CSV file. #So I have 120 input neurons? Since I have 120 columns? I am getting lost even trying to explain it. AM I on the right track? I know there is a lot of info out there and I did read the documentation. Any help would be greatly appreciated.",https://stackoverflow.com/questions/52177257,10193731,Documentation Ambiguity,Documentation Ambiguity,I am absolutely lost on the shape in tensensorflow.
52311186,How model.fit works in Keras?,"<p><strong>My previous post or error is this <a href=""https://stackoverflow.com/questions/52261090/do-the-operations-defined-in-array-ops-in-tensorflow-have-gradient-defined"">one</a></strong>.
So, I found a different way of writing the function so it will be Tensorflow compatible. I tested it and it was working fine.
However when I want to integrate it into the keras ,I couldn't.
This is the solution for my previous post:</p>

<pre><code>graph = tf.Graph()
with graph.as_default():
i = tf.Variable(0)
error = tf.Variable(initial_value=0,dtype=tf.float64)
sol = tf.random_uniform(shape=[10, 36], dtype=tf.float64, 
maxval=1)
error_1 = tf.Variable(initial_value=0,dtype=tf.float64)
final_loss = tf.Variable(0)

def cond(i, sol, error):
    return tf.less(i, 9)
def body(i, sol,error):
    i = tf.add(i, 1)
    print('i',i)
    #sol = tf.add(sol, 1)
    original_reshaped_elem = original_dim* sol[i]
    original_reshaped_elem = tf.reshape(original_reshaped_elem, 
    [DIM,DIM])
    a = tf.reshape(original_reshaped_elem[:,DIM-1], [DIM,1])
    b = tf.reshape(original_reshaped_elem[:,1], [DIM,1])

    original_reshaped_elem = tf.concat 
    ([b,original_reshaped_elem], axis= 1)
    original_reshaped_elem = tf.concat 
    ([original_reshaped_elem,a], axis= 1)

    c= tf.reshape(original_reshaped_elem[DIM-1,:], [1,DIM+2])
    d= tf.reshape(original_reshaped_elem[1,:], [1,DIM+2])
    original_reshaped_elem = tf.concat 
    ([d,original_reshaped_elem],axis=0)
    reshaped_elem_extended = tf.concat 
    ([original_reshaped_elem,c],axis=0)
    print('reshaped shape', reshaped_elem_extended)


    error = 
tf.add(error,tf.norm(tf.norm(reshaped_elem_extended,ord=2,axis=0),ord=2,axis=0))
    error_1 = tf.divide(error, 36)
    return [i, sol, error_1]


with tf.Session(graph=graph) as session:
     tf.global_variables_initializer().run()

result = tf.while_loop(cond, body, [i, sol, error])
final_loss = tf.divide(result[2], 10)
print(final_loss.eval())
print(result[1].eval())
</code></pre>

<p>This is how I call it in my model:</p>

<pre><code>result = tf.while_loop(cond, body, [i, inputs, error])
final_loss = tf.divide(result[2], 10)
vae.add_loss(final_loss)
</code></pre>

<p>then I get again this error</p>

<pre><code>ValueError: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.
</code></pre>

<p>So, I want to know how model.fit works in keras ? Does it instantiate the graph ? I didn't find any clear documentation about how it works, so I can integrate my loss function accordingly.</p>
","My previous post or error is this one. So, I found a different way of writing the function so it will be Tensorflow compatible. I tested it and it was working fine. However when I want to integrate it into the keras ,I couldn't. This is the solution for my previous post: This is how I call it in my model: then I get again this error So, I want to know how model.fit works in keras ? Does it instantiate the graph ? I didn't find any clear documentation about how it works, so I can integrate my loss function accordingly.",https://stackoverflow.com/questions/52311186,5159740,Documentation Ambiguity,Documentation Ambiguity,"I didn't find any clear documentation about how it works, so I can integrate my loss function accordingly."
52879126,How are tensors immutable in TensorFlow?,"<p>I read the following sentence in the TensorFlow documentation:</p>

<blockquote>
  <p>With the exception of tf.Variable, the value of a tensor is immutable,
  which means that in the context of a single execution tensors only
  have a single value. However, evaluating the same tensor twice can
  return different values; for example that tensor can be the result of
  reading data from disk, or generating a random number.</p>
</blockquote>

<p>Can someone elaborate a little bit on the ""immutable"" aspect of a Tensor?</p>

<ol>
<li>What is the ""scope of the immutability"" since evaluating a tensor twice could return different results? </li>
<li>What does it mean ""the context of a single execution""?</li>
</ol>
","I read the following sentence in the TensorFlow documentation: Can someone elaborate a little bit on the ""immutable"" aspect of a Tensor?",https://stackoverflow.com/questions/52879126,3926152,Documentation Ambiguity,Documentation Ambiguity,"I read the following sentence in the TensorFlow documentation: Can someone elaborate a little bit on the ""immutable"" aspect of a Tensor?"
53233633,2 Layer Neural Network Does not Converge,"<h1>Background</h1>

<p>I am a newbie to TensorFlow and I am trying to understand the basics of deep learning. I started from writing a two-layer neural network from scratch and it achieved 89% accuracy on MNIST dataset and now I am trying to implement the same network in TensorFlow and compare their performance. </p>

<h1>Problem</h1>

<p>I am not sure if I miss something basic in the code, but the following implementation seems to be unable to update weights and therefore could not output anything meaningful.</p>

<pre><code>num_hidden = 100
# x -&gt; (batch_size, 784)
x = tf.placeholder(tf.float32, [None, 784])

W1 = tf.Variable(tf.zeros((784, num_hidden)))
b1 = tf.Variable(tf.zeros((1, num_hidden)))
W2 = tf.Variable(tf.zeros((num_hidden, 10)))
b2 = tf.Variable(tf.zeros((1, 10)))
# z -&gt; (batch_size, num_hidden)
z = tf.nn.relu(tf.matmul(x, W1) + b1)
# y -&gt; (batch_size, 10)
y = tf.nn.softmax(tf.matmul(z, W2) + b2)

# y_ -&gt; (batch_size, 10)
y_ =  tf.placeholder(tf.float32, [None, 10])
# y_ * tf.log(y) -&gt; (batch_size, 10)
cross_entropy =  -tf.reduce_sum(y_ * tf.log(y+1e-10))
train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)
sess = tf.InteractiveSession()
tf.global_variables_initializer().run()
# tf.argmax(y, axis=1) returns the maximum index in each row
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
for epoch in range(1000):
    # batch_xs -&gt; (100, 784)
    # batch_ys -&gt; (100, 10), one-hot encoded
    batch_xs, batch_ys = mnist.train.next_batch(100)
    train_data = {x: batch_xs, y_: batch_ys}
    sess.run(train_step, feed_dict=train_data)
print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
W1_e, b1_e, W2_e, b2_e = W1.eval(), b1.eval(), W2.eval(), b2.eval()
sess.close()
</code></pre>

<h1>What I Have Done</h1>

<p>I checked many the official docs and many other implementations, but I feel totally confused since they may use different versions and API varies greatly.</p>

<p>So could someone help me, thank you in advance.</p>
","I am a newbie to TensorFlow and I am trying to understand the basics of deep learning. I started from writing a two-layer neural network from scratch and it achieved 89% accuracy on MNIST dataset and now I am trying to implement the same network in TensorFlow and compare their performance. I am not sure if I miss something basic in the code, but the following implementation seems to be unable to update weights and therefore could not output anything meaningful. I checked many the official docs and many other implementations, but I feel totally confused since they may use different versions and API varies greatly. So could someone help me, thank you in advance.",https://stackoverflow.com/questions/53233633,7784797,Documentation Ambiguity,Documentation Ambiguity,"I checked many the official docs and many other implementations, but I feel totally confused since they may use different versions and API varies greatly."
53470714,image classify and tensorflow serving,"<p>First of all sorry I am not prcise for this question but I am studying the tensorflow-serving and how to put in production my cnn. sincerely the documentation is quite confuse to me. I hope you can help to understand better the save model architecture. So please reply to me as teacher, i would like to know more about the whole flow.</p>

<p>I am developping a simple cnn to classify an image to 4 output.
I need tensorflow-serving to put it in production.
The image in input can be watherver size, the CNN should resize it first and predict.
Here the code</p>

<pre><code>import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from matplotlib import pyplot as plt
from scipy.misc import toimage
from keras.models import Sequential
from keras.layers import *
from keras.optimizers import *
from tensorflow.python.saved_model import builder as saved_model_builder
from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl
import cv2



#train_path='Garage/train'
#train_datagen = ImageDataGenerator(rescale=1./255)
#train_batch = train_datagen.flow_from_directory(train_path, target_size=(64,64), class_mode='categorical', batch_size=10, color_mode='grayscale')


#validation_datagen = ImageDataGenerator(rescale=1./255)
#validation_batch = validation_datagen.flow_from_directory(
#        './Garage/validation',
#        target_size=(64, 64),
#        batch_size=3,
#        class_mode='categorical', color_mode='grayscale')

model = Sequential()
model.add(InputLayer(input_shape=[64,64,1]))
model.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu'))
model.add(MaxPool2D(pool_size=5,padding='same'))

model.add(Conv2D(filters=50,kernel_size=5,strides=1,padding='same',activation='relu'))
model.add(MaxPool2D(pool_size=5,padding='same'))

model.add(Conv2D(filters=80,kernel_size=5,strides=1,padding='same',activation='relu'))
model.add(MaxPool2D(pool_size=5,padding='same'))

model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(Dropout(rate=0.5))
model.add(Dense(4,activation='softmax'))
optimizer=Adam(lr=1e-3)

model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
#model.fit_generator(
#        train_batch,
#        epochs=50,
#        steps_per_epoch=6,
#        validation_data=validation_batch,
#        validation_steps=5)

model.load_weights('model.h5')

#score = model.evaluate_generator(validation_batch,steps=3)
#print('Test loss:', score[0])
#print('Test accuracy:', score[1])

#model.save('model.h5')


from PIL import Image
import requests
from io import BytesIO

response = requests.get('http://192.168.3.21:7451/shot.jpg')
image_pil = Image.open(BytesIO(response.content))
image = np.asarray(image_pil)

img2 = cv2.resize(image,(64,64))
img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
img = np.reshape(img2,[1,64,64,1])

classes = model.predict_classes(img)

print(classes)

model_version=""1""

sess = tf.Session()

#setting values for the sake of saving the model in the proper format
x = model.input
y = model.output

prediction_signature = tf.saved_model.signature_def_utils.predict_signature_def({""inputs"":x}, {""prediction"":y})

valid_prediction_signature = tf.saved_model.signature_def_utils.is_valid_signature(prediction_signature)
if(valid_prediction_signature == False):
    raise ValueError(""Error: Prediction signature not valid!"")

builder = saved_model_builder.SavedModelBuilder('./'+model_version)
legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')

# Add the meta_graph and the variables to the builder
builder.add_meta_graph_and_variables(
      sess, [tag_constants.SERVING],
      signature_def_map={
           signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature, },
      legacy_init_op=legacy_init_op)

# save the graph
builder.save()
</code></pre>

<p>the code will take the picture from a cam <a href=""http://192.168.3.21:7451/shot.jpg"" rel=""nofollow noreferrer"">http://192.168.3.21:7451/shot.jpg</a>
and then it will predict it</p>

<p>When I compile the code it return a lot of errors when it try to save the model. can you please check it and tell me if the save model instructions are right?</p>

<p>I use x = model.input as input from the serving but I would like it take the picture as input from the server. 
I am quite confuse actually, sorry.
The scope is when I request by gRPC to predict the image the model can give me the prediction result 
Thanks</p>
","First of all sorry I am not prcise for this question but I am studying the tensorflow-serving and how to put in production my cnn. sincerely the documentation is quite confuse to me. I hope you can help to understand better the save model architecture. So please reply to me as teacher, i would like to know more about the whole flow. I am developping a simple cnn to classify an image to 4 output. I need tensorflow-serving to put it in production. The image in input can be watherver size, the CNN should resize it first and predict. Here the code the code will take the picture from a cam http://192.168.3.21:7451/shot.jpg and then it will predict it When I compile the code it return a lot of errors when it try to save the model. can you please check it and tell me if the save model instructions are right? I use x = model.input as input from the serving but I would like it take the picture as input from the server. I am quite confuse actually, sorry. The scope is when I request by gRPC to predict the image the model can give me the prediction result Thanks",https://stackoverflow.com/questions/53470714,10675469,Documentation Ambiguity,Documentation Ambiguity,Sincerely the documentation is quite confuse to me.
57346191,Tensorflow pad sequence feature column,"<p>How to pad sequences in the feature column and also what is a <code>dimension</code> in the <code>feature_column</code>.</p>

<p>I am using <code>Tensorflow 2.0</code> and implementing an example of text summarization. Pretty new to machine learning, deep learning, and TensorFlow.</p>

<p>I came across <code>feature_column</code> and found them useful as I think they can be embedded in the processing pipeline of the model.</p>

<p>In a classic scenario where not using <code>feature_column</code>, I can pre-process the text, tokenize it, convert it into a sequence of numbers and then pad them to a <code>maxlen</code> of say 100 words. I am not able to get this done when using the <code>feature_column</code>.</p>

<p>Below is what I have written sofar. </p>

<pre class=""lang-py prettyprint-override""><code>
train_dataset = tf.data.experimental.make_csv_dataset(
    'assets/train_dataset.csv', label_name=LABEL, num_epochs=1, shuffle=True, shuffle_buffer_size=10000, batch_size=1, ignore_errors=True)

vocabulary = ds.get_vocabulary()

def text_demo(feature_column):
    feature_layer = tf.keras.experimental.SequenceFeatures(feature_column)
    article, _ = next(iter(train_dataset.take(1)))

    tokenizer = tf_text.WhitespaceTokenizer()

    tokenized = tokenizer.tokenize(article['Text'])

    sequence_input, sequence_length = feature_layer({'Text':tokenized.to_tensor()})

    print(sequence_input)

def categorical_column(feature_column):
    dense_column = tf.keras.layers.DenseFeatures(feature_column)

    article, _ = next(iter(train_dataset.take(1)))

    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(
      filters='')
    lang_tokenizer.fit_on_texts(article)

    tensor = lang_tokenizer.texts_to_sequences(article)

    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,
                                                         padding='post', maxlen=50)

    print(dense_column(tensor).numpy())


text_seq_vocab_list = tf.feature_column.sequence_categorical_column_with_vocabulary_list(key='Text', vocabulary_list=list(vocabulary))
text_embedding = tf.feature_column.embedding_column(text_seq_vocab_list, dimension=8)
text_demo(text_embedding)

numerical_voacb_list = tf.feature_column.categorical_column_with_vocabulary_list(key='Text', vocabulary_list=list(vocabulary))
embedding = tf.feature_column.embedding_column(numerical_voacb_list, dimension=8)
categorical_column(embedding)

</code></pre>

<p>I am also confused as to what to use here, <code>sequence_categorical_column_with_vocabulary_list</code> or <code>categorical_column_with_vocabulary_list</code>. In the documentation, <code>SequenceFeatures</code> is also not explained, all though I know it is an experimental feature.</p>

<p>I am also not able to understand what does <code>dimension</code> param do?</p>
","How to pad sequences in the feature column and also what is a dimension in the feature_column. I am using Tensorflow 2.0 and implementing an example of text summarization. Pretty new to machine learning, deep learning, and TensorFlow. I came across feature_column and found them useful as I think they can be embedded in the processing pipeline of the model. In a classic scenario where not using feature_column, I can pre-process the text, tokenize it, convert it into a sequence of numbers and then pad them to a maxlen of say 100 words. I am not able to get this done when using the feature_column. Below is what I have written sofar. I am also confused as to what to use here, sequence_categorical_column_with_vocabulary_list or categorical_column_with_vocabulary_list. In the documentation, SequenceFeatures is also not explained, all though I know it is an experimental feature. I am also not able to understand what does dimension param do?",https://stackoverflow.com/questions/57346191,1561188,Lack of Alternative Solutions/Documentation,Documentation Ambiguity,"In the documentation, SequenceFeatures is also not explained, all though I know it is an experimental feature. I am also not able to understand what does dimension param do?"
59811773,How to use keras attention layer on top of LSTM/GRU?,"<p>I'd like to implement an encoder-decoder architecture based on a LSTM or GRU with an attention layer. I saw that Keras has a layer for that <code>tensorflow.keras.layers.Attention</code> and I'd like to use it (all other questions and resources seem to implement it themselves or use third party libraries). Also I'm not using the network for sequence to sequence translation but for binary classification, therefore the example provided in the documentation is a bit confusing to me.</p>

<p>I'm imagining a model like this.</p>

<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf

x = tf.keras.Input((100, 50))

# encoder
hidden_states = tf.keras.layers.GRU(32, return_sequences=True)(x)

# decoder + attention
? = tf.keras.layers.Attention()([?, ?])
z = tf.keras.layers.GRU(32)(?)

# classification
z = tf.keras.layers.Dense(1, activation='sigmoid')(z)

model = tf.keras.Model(inputs=x, outputs=z)
</code></pre>

<p>The decoder and attention part are of this network are unclear to me. I know that I need to create a context vector from the hidden states of the encoder and the decoders current hidden state.</p>

<p>How would I implement the decoder and attention part of this network?</p>
","I'd like to implement an encoder-decoder architecture based on a LSTM or GRU with an attention layer. I saw that Keras has a layer for that tensorflow.keras.layers.Attention and I'd like to use it (all other questions and resources seem to implement it themselves or use third party libraries). Also I'm not using the network for sequence to sequence translation but for binary classification, therefore the example provided in the documentation is a bit confusing to me. I'm imagining a model like this. The decoder and attention part are of this network are unclear to me. I know that I need to create a context vector from the hidden states of the encoder and the decoders current hidden state. How would I implement the decoder and attention part of this network?",https://stackoverflow.com/questions/59811773,3666302,Documentation Ambiguity,Documentation Ambiguity,"Also I'm not using the network for sequence to sequence translation but for binary classification, therefore the example provided in the documentation is a bit confusing to me."
60996450,Keras ignores the input_shape provided to the first layer,"<p>I build a simple model like this, specifying an input shape of <code>(32, 32, 1)</code> to the first (and only) layer:</p>

<pre><code>import numpy as np
import tensorflow as tf

class Model(tf.keras.Model):
  def __init__(self):
    super().__init__()
    self.conv = tf.keras.layers.Conv2D(64, 3, input_shape=(32, 32, 1))
  def call(self, x):
    x = self.conv(x)
    return x

model = Model()
</code></pre>

<p>Now when I call</p>

<pre><code>print(model.summary())
</code></pre>

<p>I get the following error</p>

<pre class=""lang-none prettyprint-override""><code>This model has not yet been built. Build the model first by calling `build()` or calling `fit()`
with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.
</code></pre>

<p>despite the fact that <code>input_shape</code> is indeed specified.</p>

<p>The model also happily takes input with non-conforming shapes:</p>

<pre><code>x = np.zeros((1, 24, 24, 1), dtype=np.float32)
model(x)  # OK!
</code></pre>

<p>Does this mean that despite what the documentation says, <code>input_shape</code> specification to the first layer is simply ignored? How to enforce this value?</p>

<p><em>(My TF version is 2.1.0).</em></p>
","I build a simple model like this, specifying an input shape of (32, 32, 1) to the first (and only) layer: Now when I call I get the following error despite the fact that input_shape is indeed specified. The model also happily takes input with non-conforming shapes: Does this mean that despite what the documentation says, input_shape specification to the first layer is simply ignored? How to enforce this value? (My TF version is 2.1.0).",https://stackoverflow.com/questions/60996450,9973879,Documentation Completeness,Documentation Ambiguity,"Does this mean that despite what the documentation says, input_shape specification to the first layer is simply ignored? "
61994141,Loss and learning rate scaling strategies for Tensorflow distributed training when using TF Estimator,"<p>For those who don't want to read the whole story:</p>

<p><strong>TL; DR</strong>: When using <code>TF Estimator</code>, do we have to scale learning rate by the factor by which we increase batch size (I know this is the right way, I am not sure if TF handles this internally)? Similarly, do we have to scale per example loss by global batch size (batch_size_per_replica * number of replicas)?</p>

<p>Documentation on Tensorflow distributed learning is confusing. I need clarification on below points.</p>

<ol>
<li><p>It is now understood that if you increase the batch size by a factor of <code>k</code> then you need to increase the learning rate by <code>k</code> (see <a href=""https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h5.pdf"" rel=""nofollow noreferrer"">this</a> and <a href=""https://arxiv.org/pdf/1711.00489.pdf"" rel=""nofollow noreferrer"">this</a> paper). However, Tensoflow official page on distributed learning makes no clarifying comment about this. They do mention <a href=""https://www.tensorflow.org/tutorials/distribute/multi_worker_with_estimator#multiworkermirroredstrategy"" rel=""nofollow noreferrer"">here</a> that learning rate needs to be adjusted. Do they handle the learning rate scaling by themselves? To make matters more complicated, the behavior is different in Keras and tf.Estimator (see next point). Any suggestions on should I increase the LR by a factor of K or not <em>when I am using <code>tf.Estimator</code></em>?</p></li>
<li><p>It is widely accepted that the per example loss should be scaled by <code>global_batch_size = batch_size_per_replica * number of replicas</code>. Tensorflow mentions it <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training#define_the_loss_function"" rel=""nofollow noreferrer"">here</a> but then when illustrating how to achieve this with a tf.Estimator, they either forget or the scaling by <code>global_batch_size</code> is not required. See <a href=""https://www.tensorflow.org/tutorials/distribute/multi_worker_with_estimator#define_the_model"" rel=""nofollow noreferrer"">here</a>, in the code snippet, loss is defined as follows.</p></li>
</ol>

<pre><code>loss = tf.reduce_sum(loss) * (1. / BATCH_SIZE)
</code></pre>

<p>and <code>BATCH_SIZE</code> to the best of my understanding is defined above as per replica batch size.</p>

<p>To complicate things further, the scaling is handled automatically if you are using Keras (for reasons I will never understand, it would have been better to keep everything consistent).</p>
","For those who don't want to read the whole story: TL; DR: When using TF Estimator, do we have to scale learning rate by the factor by which we increase batch size (I know this is the right way, I am not sure if TF handles this internally)? Similarly, do we have to scale per example loss by global batch size (batch_size_per_replica * number of replicas)? Documentation on Tensorflow distributed learning is confusing. I need clarification on below points. and BATCH_SIZE to the best of my understanding is defined above as per replica batch size. To complicate things further, the scaling is handled automatically if you are using Keras (for reasons I will never understand, it would have been better to keep everything consistent).",https://stackoverflow.com/questions/61994141,1586200,Documentation Ambiguity,Documentation Ambiguity,Documentation on Tensorflow distributed learning is confusing.
63175471,How to control if input features contribute exclusively to one neuron in subsequent layer of a Tensorflow neural network?,"<p>I'm trying to make the most basic of basic neural networks to get familiar with functional API in Tensorflow 2.x.</p>
<p>Basically what I'm trying to do is the following with my simplified iris dataset (i.e. setosa or not)</p>
<ol>
<li>Use the 4 features as input</li>
<li>Dense layer of 3</li>
<li>Sigmoid activation function</li>
<li>Dense layer of 2 (one for each class)</li>
<li>Softmax activation</li>
<li>Binary cross entropy / log-loss as my loss function</li>
</ol>
<p>However, I can't figure out how to control one key aspect of the model.  That is, <strong>how can I ensure that each feature from my input layer contributes to only one neuron in my subsequent dense layer?</strong>  Also, how can I allow a feature to contribute to more than one neuron?</p>
<p>This isn't clear to me from the documentation.</p>
<pre><code># Load data
from sklearn.datasets import load_iris
import pandas as pd

iris = load_iris()
X, y = load_iris(return_X_y=True, as_frame=True)
X = X.astype(&quot;float32&quot;)
X.index = X.index.map(lambda i: &quot;iris_{}&quot;.format(i))
X.columns = X.columns.map(lambda j: j.split(&quot; (&quot;)[0].replace(&quot; &quot;,&quot;_&quot;))
y.index = X.index
y = y.map(lambda i:iris.target_names[i])
y_simplified = y.map(lambda i: {True:1, False:0}[i == &quot;setosa&quot;])
y_simplified = pd.get_dummies(y_simplified, columns=[&quot;setosa&quot;, &quot;not_setosa&quot;])

# Traing test split
from sklearn.model_selection import train_test_split
seed=0
X_train,X_test, y_train,y_test= train_test_split(X,y_simplified, test_size=0.3, random_state=seed)

# Simple neural network
import tensorflow as tf
tf.random.set_seed(seed)


# Input[4 features] -&gt; Dense layer of 3 neurons -&gt; Activation function -&gt; Dense layer of 2 (one per class) -&gt; Softmax
inputs = tf.keras.Input(shape=(4))
x = tf.keras.layers.Dense(3)(inputs)
x = tf.keras.layers.Activation(tf.nn.sigmoid)(x)
x = tf.keras.layers.Dense(2)(x)
outputs = tf.keras.layers.Activation(tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs, name=&quot;simple_binary_iris&quot;)
model.compile(loss=&quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;] )
model.summary()

history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2)

test_scores = model.evaluate(X_test, y_test)
print(&quot;Test loss:&quot;, test_scores[0])
print(&quot;Test accuracy:&quot;, test_scores[1])
</code></pre>
<p>Results:</p>
<pre><code>Model: &quot;simple_binary_iris&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_44 (InputLayer)        [(None, 4)]               0         
_________________________________________________________________
dense_96 (Dense)             (None, 3)                 15        
_________________________________________________________________
activation_70 (Activation)   (None, 3)                 0         
_________________________________________________________________
dense_97 (Dense)             (None, 2)                 8         
_________________________________________________________________
activation_71 (Activation)   (None, 2)                 0         
=================================================================
Total params: 23
Trainable params: 23
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
2/2 [==============================] - 0s 40ms/step - loss: 0.6344 - accuracy: 0.6667 - val_loss: 0.6107 - val_accuracy: 0.7143
Epoch 2/10
2/2 [==============================] - 0s 6ms/step - loss: 0.6302 - accuracy: 0.6667 - val_loss: 0.6083 - val_accuracy: 0.7143
Epoch 3/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6278 - accuracy: 0.6667 - val_loss: 0.6056 - val_accuracy: 0.7143
Epoch 4/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.6667 - val_loss: 0.6038 - val_accuracy: 0.7143
Epoch 5/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6239 - accuracy: 0.6667 - val_loss: 0.6014 - val_accuracy: 0.7143
Epoch 6/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6223 - accuracy: 0.6667 - val_loss: 0.6002 - val_accuracy: 0.7143
Epoch 7/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6209 - accuracy: 0.6667 - val_loss: 0.5989 - val_accuracy: 0.7143
Epoch 8/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6195 - accuracy: 0.6667 - val_loss: 0.5967 - val_accuracy: 0.7143
Epoch 9/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6179 - accuracy: 0.6667 - val_loss: 0.5953 - val_accuracy: 0.7143
Epoch 10/10
2/2 [==============================] - 0s 7ms/step - loss: 0.6166 - accuracy: 0.6667 - val_loss: 0.5935 - val_accuracy: 0.7143
2/2 [==============================] - 0s 607us/step - loss: 0.6261 - accuracy: 0.6444
Test loss: 0.6261375546455383
Test accuracy: 0.644444465637207
</code></pre>
","I'm trying to make the most basic of basic neural networks to get familiar with functional API in Tensorflow 2.x. Basically what I'm trying to do is the following with my simplified iris dataset (i.e. setosa or not) However, I can't figure out how to control one key aspect of the model. That is, how can I ensure that each feature from my input layer contributes to only one neuron in my subsequent dense layer? Also, how can I allow a feature to contribute to more than one neuron? This isn't clear to me from the documentation. Results:",https://stackoverflow.com/questions/63175471,678572,Documentation Ambiguity,Documentation Ambiguity,This isn't clear to me from the documentation. 
64908920,Can't use color_mode = 'grayscale' with grayscale JPEGs,"<p>I'm using tensorflow v 2.3.1</p>
<p>This is my code:</p>
<pre><code>train_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input).flow_from_directory(
    directory = train_path, target_size=(224,224), classes = ['1', '2', '3'], color_mode = 'grayscale', batch_size = 20)
</code></pre>
<p>Errors out with :</p>
<pre><code>...    
    231   else:
    232     x[..., 0] -= mean[0]
--&gt; 233     x[..., 1] -= mean[1]
    234     x[..., 2] -= mean[2]
    235     if std is not None:
IndexError: index 1 is out of bounds for axis 2 with size 1
</code></pre>
<p>I thought, documentation says, grayscale is how jpeg will be preprocessed.</p>
<p>Any ideas about the cause?</p>
","I'm using tensorflow v 2.3.1 This is my code: Errors out with : I thought, documentation says, grayscale is how jpeg will be preprocessed. Any ideas about the cause?",https://stackoverflow.com/questions/64908920,14665728,Documentation Replicability,Documentation Ambiguity,"I thought, documentation says, grayscale is how jpeg will be preprocessed."
65006011,Size of output of a Conv1D layer in Keras,"<p>I am trying to understand the output of a 1D convolution layer applied on a number of batches (3 in this case) of 2D input shapes (6x6).</p>
<p>The output of the code below is <code>(4, 10, 32)</code>. This answer is quite straight-forward for the first 2 indices.</p>
<ul>
<li>(4) We plug in N examples, we get out N examples.</li>
<li>(8) When doing the convolution between a (10, 128) * (3, 1) and because the default padding is set to &quot;valid&quot;, two of the values in our input space won't be mapped to our final result, that's why we get 8.</li>
<li>I don't understand why the layer outputs 32 as the final index. What is the actual role of the <code>filters</code> argument in the Conv1D layer? It's not really intuitive for me how does the layer operates the final output as stated by the phrase down below.</li>
</ul>
<p><strong>By the documentation this should be the output shape</strong></p>
<blockquote>
<p>Output shape: 3+D tensor with shape: batch_shape + (new_steps, filters) steps value might have changed due to padding or strides.</p>
</blockquote>
<pre><code>input_shape = (4, 10, 128)
x = tf.random.normal(input_shape)
y = tf.keras.layers.Conv1D(
    32, 3, input_shape=input_shape[1:])(x)
print(y.shape) # (4, 10, 32)
</code></pre>
","I am trying to understand the output of a 1D convolution layer applied on a number of batches (3 in this case) of 2D input shapes (6x6). The output of the code below is (4, 10, 32). This answer is quite straight-forward for the first 2 indices. By the documentation this should be the output shape",https://stackoverflow.com/questions/65006011,7450491,Documentation Ambiguity,Documentation Ambiguity,By the documentation this should be the output shape
65475110,Are Keras custom layer parameters non-trainable by default?,"<p>I built a simple custom layer in Keras and was surprised to find that the parameters were not set to trainable by default. I can get it to work by explicitly setting the trainable attribute. I can't explain why this is by looking at documentation or code. Is this how it is supposed to be or I am doing something wrong which is making the parameters non-trainable by default?
Code:</p>
<pre><code>import tensorflow as tf


class MyDense(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(MyDense, self).__init__(kwargs)
        self.dense = tf.keras.layers.Dense(2, tf.keras.activations.relu)

    def call(self, inputs, training=None):
        return self.dense(inputs)


inputs = tf.keras.Input(shape=10)
outputs = MyDense()(inputs)
model = tf.keras.Model(inputs=inputs, outputs=outputs, name='test')
model.compile(loss=tf.keras.losses.MeanSquaredError())
model.summary()
</code></pre>
<p>Output:</p>
<pre><code>Model: &quot;test&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 10)]              0         
_________________________________________________________________
my_dense (MyDense)           (None, 2)                 22        
=================================================================
Total params: 22
Trainable params: 0
Non-trainable params: 22
_________________________________________________________________
</code></pre>
<p>If I change the custom layer creation like this:</p>
<pre><code>outputs = MyDense(trainable=True)(inputs)
</code></pre>
<p>the output is what I expect (all parameters are trainable):</p>
<pre><code>=================================================================
Total params: 22
Trainable params: 22
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>then it works as expected and makes all the parameters trainable. I don't understand why that is needed though.</p>
",I built a simple custom layer in Keras and was surprised to find that the parameters were not set to trainable by default. I can get it to work by explicitly setting the trainable attribute. I can't explain why this is by looking at documentation or code. Is this how it is supposed to be or I am doing something wrong which is making the parameters non-trainable by default? Code: Output: If I change the custom layer creation like this: the output is what I expect (all parameters are trainable): then it works as expected and makes all the parameters trainable. I don't understand why that is needed though.,https://stackoverflow.com/questions/65475110,14890777,Documentation Ambiguity,Documentation Ambiguity,I can't explain why this is by looking at documentation or code.
66778153,How exactly does tf.data.Dataset.interleave() differ from map() and flat_map()?,"<p>My current understanding is:</p>
<p><strong>Different map_func</strong>: Both  <code>interleave</code> and <code>flat_map</code> expect &quot;A function mapping a dataset element to a <strong>dataset</strong>&quot;. In contrast, <code>map</code> expects    &quot;A function mapping a dataset element to another <strong>dataset element</strong>&quot;.</p>
<p><strong>Arguments</strong>: Both <code>interleave</code> and <code>map</code> offer the argument num_parallel_calls, whereas <code>flat_map</code> does not. Moreover, interleave offers these magical arguments block_length and cycle_length. For cycle_length=1, the documentation states that  the outputs of interleave and flat_map are equal.</p>
<p>Last, I have seen <a href=""https://cs230.stanford.edu/blog/datapipeline/#building-an-image-data-pipeline"" rel=""noreferrer"">data loading pipelines without interleave</a> as well as <a href=""https://www.tensorflow.org/guide/data_performance"" rel=""noreferrer"">ones with interleave</a>. Any advice when to use <code>interleave</code> vs. <code>map</code> or <code>flat_map</code> would be greatly appreciated</p>
<hr />
<p>//EDIT: I do see the value of interleave, if we start out with different datasets, such as in <a href=""https://docs.w3cub.com/tensorflow%7Eguide/performance/datasets_performance"" rel=""noreferrer"">the code below</a></p>
<pre><code>  files = tf.data.Dataset.list_files(&quot;/path/to/dataset/train-*.tfrecord&quot;)
  dataset = files.interleave(tf.data.TFRecordDataset)
</code></pre>
<p>However, is there any benefit of using <code>interleave</code> over <code>map</code> in a scenario such as the one below?</p>
<pre><code>files = tf.data.Dataset.list_files(&quot;/path/to/dataset/train-*.png&quot;)
dataset = files.map(load_img, num_parallel_calls=tf.data.AUTOTUNE)
</code></pre>
","My current understanding is: Different map_func: Both interleave and flat_map expect ""A function mapping a dataset element to a dataset"". In contrast, map expects ""A function mapping a dataset element to another dataset element"". Arguments: Both interleave and map offer the argument num_parallel_calls, whereas flat_map does not. Moreover, interleave offers these magical arguments block_length and cycle_length. For cycle_length=1, the documentation states that the outputs of interleave and flat_map are equal. Last, I have seen data loading pipelines without interleave as well as ones with interleave. Any advice when to use interleave vs. map or flat_map would be greatly appreciated //EDIT: I do see the value of interleave, if we start out with different datasets, such as in the code below However, is there any benefit of using interleave over map in a scenario such as the one below?",https://stackoverflow.com/questions/66778153,2135504,Documentation Ambiguity,Documentation Ambiguity,"For cycle_length=1, the documentation states that the outputs of interleave and flat_map are equal. However, is there any benefit of using interleave over map in a scenario such as the one below?"
67801758,tf.Variable gets converted to normal tensor in loop,"<p>I have a custom layer in Keras in which I define some variables to which I assign some values in the call section.</p>
<pre><code>class Mine_layer(KL.Layer):
  def __init__(self,shape):
    self.block=tf.Variable(tf.constant(1,shape=shape))
  def call (self,indeces):
    self.block=self.block[indeces[0][0],indeces[0][1]].assign(1)
</code></pre>
<p>this works but if i try to utilize a for loop over all the indeces:</p>
<pre><code>for i in tf.range(0,limit=tf.shape(indeces)[0]):
   self.block=self.block[indeces[i][0],indeces[i][1]].assign(1)
</code></pre>
<p>this gives me an error saying that &quot;'Tensor' object has no attribute 'assign'&quot;.</p>
<p>Why does this happen? How can I solve it?</p>
<p>I tried looking at the documentation but I still don't get it.</p>
<p>Thanks in advance to anyone who may answer.</p>
","I have a custom layer in Keras in which I define some variables to which I assign some values in the call section. this works but if i try to utilize a for loop over all the indeces: this gives me an error saying that ""'Tensor' object has no attribute 'assign'"". Why does this happen? How can I solve it? I tried looking at the documentation but I still don't get it. Thanks in advance to anyone who may answer.",https://stackoverflow.com/questions/67801758,10067045,Documentation Ambiguity,Documentation Ambiguity,I tried looking at the documentation but I still don't get it.
69932821,Keras preprocessing layer,"<p>I am trying to feed a neural network 50 features (All Yes/No values) to predict the probability of one Yes/No label. I am trying to do this with keras <code>CategoryEncoding</code>, but running into some issues.</p>
<p>The start of my code is below:</p>
<pre class=""lang-py prettyprint-override""><code>model = Sequential([
    tf.keras.Input(shape = (50,)),
    tf.keras.layers.CategoryEncoding(num_tokens=100, output_mode='one_hot'),
    tf.keras.layers.LayerNormalization(),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='softmax')
])
</code></pre>
<p>However, I get this error below:</p>
<pre class=""lang-py prettyprint-override""><code>ValueError: Exception encountered when calling layer &quot;category_encoding_12&quot; (type CategoryEncoding).

When output_mode is not `'int'`, maximum supported output rank is 2. Received output_mode one_hot and input shape (None, 50), which would result in output rank 3.

Call arguments received:
  • inputs=tf.Tensor(shape=(None, 50), dtype=float32)
  • count_weights=None
</code></pre>
<p>I am looking through the documentation, and I don't think I fully understand what a token is in its context here. Also, how would I preprocess my label here? I could use <code>pd.get_dummies</code>, but I don't know if tensorflow has anything that could do that automatically?</p>
","I am trying to feed a neural network 50 features (All Yes/No values) to predict the probability of one Yes/No label. I am trying to do this with keras CategoryEncoding, but running into some issues. The start of my code is below: However, I get this error below: I am looking through the documentation, and I don't think I fully understand what a token is in its context here. Also, how would I preprocess my label here? I could use pd.get_dummies, but I don't know if tensorflow has anything that could do that automatically?",https://stackoverflow.com/questions/69932821,16354723,Documentation Ambiguity,Documentation Ambiguity,"I am looking through the documentation, and I don't think I fully understand what a token is in its context here."
71889649,(Conv1D) Tensorflow and Jax Resulting Different Outputs for The Same Input,"<p>I am trying to use conv1d functions to make a transposed convlotion repectively at jax and tensorflow. I read the documentation of both of jax and tensorflow for the con1d_transposed operation but they are resulting with different outputs for the same input.</p>
<p>I can not find out what the problem is. And I don't know which one produces the correct results. Help me please.</p>
<p>My Jax Implementation (Jax Code)</p>
<pre class=""lang-py prettyprint-override""><code>x = np.asarray([[[1, 2, 3, 4, -5], [1, 2, 3, 4, 5]]], dtype=np.float32).transpose((0, 2, 1))
filters = np.array([[[1, 0, -1], [-1,  0,  1]], 
                    [[1, 1,  1], [-1, -1, -1]]], 
                    dtype=np.float32).transpose((2, 1, 0))

kernel_rot = np.rot90(np.rot90(filters))

print(f&quot;x strides:  {x.strides}\nfilters strides: {kernel_rot.strides}\nx shape: {x.shape}\nfilters shape: {filters.shape}\nx: \n{x}\nfilters: \n{filters}\n&quot;)

dn1 = lax.conv_dimension_numbers(x.shape, filters.shape,('NWC', 'WIO', 'NWC'))
print(dn1)

res = lax.conv_general_dilated(x,kernel_rot,(1,),'SAME',(1,),(1,),dn1)     

res = np.asarray(res)
print(f&quot;result strides: {res.strides}\nresult shape: {res.shape}\nresult: \n{res}\n&quot;)
</code></pre>
<p>My TensorFlow Implementation (TensorFlow Code)</p>
<pre class=""lang-py prettyprint-override""><code>x = np.asarray([[[1, 2, 3, 4, -5], [1, 2, 3, 4, 5]]], dtype=np.float32).transpose((0, 2, 1))
filters = np.array([[[1, 0, -1], [-1,  0,  1]], 
                    [[1, 1,  1], [-1, -1, -1]]], 
                    dtype=np.float32).transpose((2, 1, 0))

print(f&quot;x strides:  {x.strides}\nfilters strides: {filters.strides}\nx shape: {x.shape}\nfilters shape: {filters.shape}\nx: \n{x}\nfilters: \n{filters}\n&quot;)
    
res = tf.nn.conv1d_transpose(x, filters, output_shape = x.shape, strides = (1, 1, 1), padding = 'SAME', data_format='NWC', dilations=1)

res = np.asarray(res)
print(f&quot;result strides: {res.strides}\nresult shape: {res.shape}\nresult: \n{res}\n&quot;)
</code></pre>
<p>Output from the Jax</p>
<pre><code>result strides: (40, 8, 4)
result shape: (1, 5, 2)
result: 
[[[ 0.  0.]
  [ 0.  0.]
  [ 0.  0.]
  [10. 10.]
  [ 0. 10.]]]
</code></pre>
<p>Output from the TensorFlow</p>
<pre><code>result strides: (40, 8, 4)
result shape: (1, 5, 2)
result: 
[[[  5.  -5.]
  [  8.  -8.]
  [ 11. -11.]
  [  4.  -4.]
  [  5.  -5.]]]
</code></pre>
",I am trying to use conv1d functions to make a transposed convlotion repectively at jax and tensorflow. I read the documentation of both of jax and tensorflow for the con1d_transposed operation but they are resulting with different outputs for the same input. I can not find out what the problem is. And I don't know which one produces the correct results. Help me please. My Jax Implementation (Jax Code) My TensorFlow Implementation (TensorFlow Code) Output from the Jax Output from the TensorFlow,https://stackoverflow.com/questions/71889649,17030468,Documentation Ambiguity,Documentation Ambiguity,I read the documentation of both of jax and tensorflow for the con1d_transposed operation but they are resulting with different outputs for the same input. I can not find out what the problem is.
72311927,How to train mnist data with tensorflow ParameterServerStrategy distributed training?,"<p>I'm trying to train the mnist dataset using the ParameterServerStrategy. As a beginner, I find the documentations to be confusing specially when it comes to the section &quot;Clusters in the real world&quot;. This is the docs that I'm following:<a href=""https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#scrollTo=zyby6M2Jqg6J&amp;uniqifier=1"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#scrollTo=zyby6M2Jqg6J&amp;uniqifier=1</a> So far I have this:</p>
<pre class=""lang-py prettyprint-override""><code>
#this is mnist_setup.py

import os
import tensorflow as tf
import numpy as np

def mnist_dataset(batch_size):
  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
  # The `x` arrays are in uint8 and have values in the [0, 255] range.
  # You need to convert them to float32 with values in the [0, 1] range.
  x_train = x_train / np.float32(255)
  y_train = y_train.astype(np.int64)
  train_dataset = tf.data.Dataset.from_tensor_slices(
      (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)
  return train_dataset

def build_and_compile_model():
  model = tf.keras.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
  ])
  model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      optimizer=tf.keras.optimizers.SGD(),
      metrics=['accuracy'])
  return model
</code></pre>
<pre class=""lang-py prettyprint-override""><code>#this is main.py

import os
import json

import tensorflow as tf
import mnist_setup

per_worker_batch_size = 64

os.environ[&quot;TF_CONFIG&quot;] = json.dumps({
    &quot;cluster&quot;: {
        &quot;worker&quot;: ['ip_of_deeplearning_VM:port'], #worker1
        &quot;ps&quot;: ['ip_of_deeplearning_VM:port'], #worker2
        &quot;chief&quot;: ['ip_of_deeplearning_VM:port'] #masterz
    },
    &quot;task&quot;: {&quot;type&quot;: &quot;chief&quot;, &quot;index&quot;: 0}
})

cluster_spec = tf.train.ClusterSpec({
    'ps':['ip_of_deeplearning_VM:port'], #worker2
    'worker': ['ip_of_deeplearning_VM:port'] #worker1
})

cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(cluster_spec, task_type=&quot;ps&quot;,task_id=0)

tf_config = json.loads(os.environ['TF_CONFIG'])
num_workers = len(tf_config['cluster']['worker'])

strategy = tf.distribute.experimental.ParameterServerStrategy(cluster_resolver)

global_batch_size = per_worker_batch_size * num_workers
multi_worker_dataset = mnist_setup.mnist_dataset(global_batch_size)

with strategy.scope():
  # Model building/compiling need to be within `strategy.scope()`.
    multi_worker_model = mnist_setup.build_and_compile_model()
    
print(&quot;chief gets called!&quot;)
result = multi_worker_model.fit(multi_worker_dataset, epochs=3)
</code></pre>
<p>I copy these files to the worker and ps VM, change the index and run &quot;main.py&quot; on all of them at the same time. I get the message saying that the server was started at ip_address but that's about it. Would anyone please show me what I need to do in order to get this working?</p>
","I'm trying to train the mnist dataset using the ParameterServerStrategy. As a beginner, I find the documentations to be confusing specially when it comes to the section ""Clusters in the real world"". This is the docs that I'm following:https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#scrollTo=zyby6M2Jqg6J&amp;uniqifier=1 So far I have this: I copy these files to the worker and ps VM, change the index and run ""main.py"" on all of them at the same time. I get the message saying that the server was started at ip_address but that's about it. Would anyone please show me what I need to do in order to get this working?",https://stackoverflow.com/questions/72311927,11909464,Documentation Ambiguity,Documentation Ambiguity,"I find the documentations to be confusing specially when it comes to the section ""Clusters in the real world"". "
73569804,Dataset.batch doesn't work as expected with a zipped dataset,"<p>I have a dataset like this:</p>
<pre><code>a = tf.data.Dataset.range(1, 16)
b = tf.data.Dataset.range(16, 32)
zipped = tf.data.Dataset.zip((a, b))
list(zipped.as_numpy_iterator())

# output: 
[(0, 16),
 (1, 17),
 (2, 18),
 (3, 19),
 (4, 20),
 (5, 21),
 (6, 22),
 (7, 23),
 (8, 24),
 (9, 25),
 (10, 26),
 (11, 27),
 (12, 28),
 (13, 29),
 (14, 30),
 (15, 31)]
</code></pre>
<p>When I apply <code>batch(4)</code> to it, the expected result is an array of batches, where each batch contains four tuples:</p>
<pre><code>[[(0, 16), (1, 17), (2, 18), (3, 19)],
 [(4, 20), (5, 21), (6, 22), (7, 23)],
 [(9, 24), (10, 25), (10, 26), (11, 27)],
 [(12, 28), (13, 29), (14, 30), (15, 31)]]
</code></pre>
<p>But this is what I receive instead:</p>
<pre><code>batched = zipped.batch(4)
list(batched.as_numpy_iterator())

# Output:
[(array([0, 1, 2, 3]), array([16, 17, 18, 19])), 
 (array([4, 5, 6, 7]), array([20, 21, 22, 23])), 
 (array([ 8,  9, 10, 11]), array([24, 25, 26, 27])), 
 (array([12, 13, 14, 15]), array([28, 29, 30, 31]))]
</code></pre>
<p>I'm following this <a href=""https://www.youtube.com/watch?v=N_W4EYtsa10&amp;t=5591s"" rel=""nofollow noreferrer"">tutorial</a>, he does the same steps but gets the correct output somehow.</p>
<hr />
<p>Update: according to the documentation this is the intended behavior:</p>
<blockquote>
<p>The components of the resulting element will have an additional <strong>outer</strong> dimension, which will be batch_size</p>
</blockquote>
<p>But it doesn't make any sense. To my understanding, dataset is a list of pieces of data. It doesn't matter the shape of those pieces of data, when we are batching it we are combining the elements [whatever their shape is] into batches, therefore it should always insert the new dimention to the second position (<code>(length, a, b, c)</code> -&gt; <code>(length', batch_size, a, b, c)</code>).</p>
<p>So my questions are: I wonder what is the purpose of <code>batch()</code> being implemented this way? And what is the alternative that does what I described?</p>
","I have a dataset like this: When I apply batch(4) to it, the expected result is an array of batches, where each batch contains four tuples: But this is what I receive instead: I'm following this tutorial, he does the same steps but gets the correct output somehow. Update: according to the documentation this is the intended behavior: But it doesn't make any sense. To my understanding, dataset is a list of pieces of data. It doesn't matter the shape of those pieces of data, when we are batching it we are combining the elements [whatever their shape is] into batches, therefore it should always insert the new dimention to the second position ((length, a, b, c) -&gt; (length', batch_size, a, b, c)). So my questions are: I wonder what is the purpose of batch() being implemented this way? And what is the alternative that does what I described?",https://stackoverflow.com/questions/73569804,12694438,Requesting (Additional) Resources,Documentation Ambiguity, According to the documentation this is the intended behavior: But it doesn't make any sense.
73840190,Why is StringLookup from producing an extra label?,"<p>From TF documentation:
&quot;one_hot&quot;: Encodes each individual element in the input into an array <strong>the same size</strong> as the vocabulary.</p>
<pre><code>alphabet = set(&quot;abcdefghijklmnopqrstuvwxyz&quot;)
one_hot_encoder = tf.keras.layers.StringLookup(vocabulary=list(alphabet), output_mode='one_hot')
print(len(alphabet)) #26
print(one_hot_encoder(&quot;a&quot;).shape) #(27,)
</code></pre>
<p>As far as I understand it it should encode to a 26 shaped tensor. Why does it encode to a 27 shaped one? Should there be an extra label to represent &quot;no class&quot;?</p>
","From TF documentation: ""one_hot"": Encodes each individual element in the input into an array the same size as the vocabulary. As far as I understand it it should encode to a 26 shaped tensor. Why does it encode to a 27 shaped one? Should there be an extra label to represent ""no class""?",https://stackoverflow.com/questions/73840190,14742134,Documentation Completeness,Documentation Ambiguity,"From TF documentation: ""one_hot"": Encodes each individual element in the input into an array the same size as the vocabulary. As far as I understand it it should encode to a 26 shaped tensor. Why does it encode to a 27 shaped one?"
76402835,ValueError: tf.function only supports singleton tf.Variables created on the first call,"<p>I have the following code:</p>
<pre><code>class Encoder(tf.keras.Model):
    def __init__(self, params):
        super(Encoder, self).__init__()
        self.params = params
        
        self.hidden_layer_one = tf.keras.layers.Conv2D(filters=self.params['e_filters'],
                                                       kernel_size=self.params['e_size'],
                                                       activation=self.params['activation'], strides=1, padding='same',
                                                       kernel_initializer=params['initializer'], use_bias=False)
        self.hidden_layer_two = tf.keras.layers.Conv2D(filters=self.params['num_endmembers'], kernel_size=1,
                                                       activation=self.params['activation'], strides=1, padding='same',
                                                       kernel_initializer=self.params['initializer'], use_bias=False)
        self.asc_layer = ASC(params=self.params, name='abundances')

    def call(self, input_patch):
        code = self.hidden_layer_one(input_patch)
        code = tf.keras.layers.BatchNormalization()(code)
        code = tf.keras.layers.SpatialDropout2D(0.2)(code)
        code = self.hidden_layer_two(code)
        code = tf.keras.layers.BatchNormalization()(code)
        code = tf.keras.layers.SpatialDropout2D(0.2)(code)
        code = self.asc_layer(code)
        return code

class Autoencoder(tf.keras.Model):
    def __init__(self, params):
        super(Autoencoder, self).__init__()
        self.encoder = Encoder(params)
        self.decoder = Decoder(params)
        self.params = params

    def call(self, patch):
        abunds = self.encoder(patch)
        abunds = tf.keras.layers.SpatialDropout2D(0.08)(abunds)
        output = self.decoder(abunds)
        return output

    
    def train(self, patches, callback):
        self.plotWhileTraining = callback
        self.fit(patches, patches, epochs=self.params['epochs'], batch_size=self.params['batch_size'],
                 callbacks=[self.plotWhileTraining], verbose=0)

</code></pre>
<p>I get the error in the title,</p>
<pre><code>ValueError: tf.function only supports singleton tf.Variables created on the first call. 
Make sure the tf.Variable is only created once or created outside tf.function. 
See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.
        
        
        Call arguments received by layer 'encoder_3' (type Encoder):
          • input_patch=tf.Tensor(shape=(15, 80, 80, 156), dtype=float32)
    
    
    Call arguments received by layer 'autoencoder_3' (type Autoencoder):
      • patch=tf.Tensor(shape=(15, 80, 80, 156), dtype=float32)
</code></pre>
<p>I read the documentation but I still don't know how to solve it.</p>
<p>I tried <code>model.build()</code> but I'm not sure where to call it.</p>
","I have the following code: I get the error in the title, I read the documentation but I still don't know how to solve it. I tried model.build() but I'm not sure where to call it.",https://stackoverflow.com/questions/76402835,14114819,Documentation Ambiguity,Documentation Ambiguity, I read the documentation but I still don't know how to solve it
44335033,Does 'tf.assign' return its argument?,"<p>The Tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/assign"" rel=""nofollow noreferrer"">documentation</a> says that <code>tf.assign(ref, ...)</code> returns <code>ref</code>, but it appears instead (not surprisingly) to return a <code>Tensor</code> (attached to the <code>assign</code> op):</p>

<pre><code>import tensorflow as tf
sess = tf.InteractiveSession()

Q = tf.Variable(tf.constant(range(1, 12)))
sess.run(tf.global_variables_initializer())
qop = tf.assign(Q, tf.zeros(Q.shape, tf.int32))#.eval()

print(Q.eval())
print(qop.eval())
print(Q.eval())
</code></pre>

<p>produces</p>

<pre><code>[ 1  2  3  4  5  6  7  8  9 10 11]
[0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0]
</code></pre>

<p>demonstrating that the argument <code>Q</code> and what's returned <code>qop</code> behave differently (and that <code>Q</code> is unchanged until <code>qop</code> is executed).</p>

<p>Is the return value of <code>tf.assign</code> described correctly in the documentation?</p>
","The Tensorflow documentation says that tf.assign(ref, ...) returns ref, but it appears instead (not surprisingly) to return a Tensor (attached to the assign op): produces demonstrating that the argument Q and what's returned qop behave differently (and that Q is unchanged until qop is executed). Is the return value of tf.assign described correctly in the documentation?",https://stackoverflow.com/questions/44335033,656912,Documentation Ambiguity,Documentation Ambiguity,Is the return value of tf.assign described correctly in the documentation?
45134654,Easily switching between feed_dict and queues for input to TensorFlow model,"<p>Right now I have a model configured to take its inputs with <code>feed_dict</code>. The code looks something like this:</p>

<pre><code># model.py
class MyModel(object):
  def __init__(self, hyperparams):
    self.build_model(hyperparams)

  def build_model(self, hps):
    self.input_data = tf.placeholder(dtype=tf.float32, shape=[hps.batch_size, hps.nfeats])
    self.labels = tf.placeholder(dtype=tf.float32, shape=[hps.batch_size])
    # Define hidden layers, loss, training step, etc.

# train.py
model = MyModel(hps)
for _ in range(100):
  x, y = some_python_function() # Read a batch from disk, preprocess
  sess.run(model.train_step, feed_dict={model.input_data: x, model.labels: y})
</code></pre>

<p>For performance reasons, I'd like to switch to using queues for training. But I'd like to maintain the ability to use <code>feed_dict</code>, e.g. for inference or testing.</p>

<p>Is there an elegant way to do this? What I'd like to do is, when using queues, 'swap out' the placeholder variables for the tensors returned by my queue's dequeue op. I thought that <code>tf.assign</code> would be the way to do this, i.e.:</p>

<pre><code>single_x, single_y = tf.parse_single_example(...)
x, y = tf.train.batch([single_x, single_y], batch_size)
model = MyModel(hps)
sess.run([tf.assign(model.input_data, x), tf.assign(model.labels, y)])
for _ in range(100):
  sess.run(model.train_step)
</code></pre>

<p>But this raises <code>AttributeError: 'Tensor' object has no attribute 'assign'</code>. The API docs for <a href=""https://www.tensorflow.org/api_docs/python/tf/assign"" rel=""nofollow noreferrer""><code>tf.assign</code></a> describe the first argument as: ""A mutable <code>Tensor</code>. Should be from a <code>Variable</code> node. May be uninitialized."" Does this mean my placeholders aren't mutable? Can I make them so? Or am I approaching this the wrong way?</p>

<p>Minimal runnable example <a href=""https://gist.github.com/colinmorris/8ca883c04831c755ee3bc745cab52761"" rel=""nofollow noreferrer"">here</a>.</p>
","Right now I have a model configured to take its inputs with feed_dict. The code looks something like this: For performance reasons, I'd like to switch to using queues for training. But I'd like to maintain the ability to use feed_dict, e.g. for inference or testing. Is there an elegant way to do this? What I'd like to do is, when using queues, 'swap out' the placeholder variables for the tensors returned by my queue's dequeue op. I thought that tf.assign would be the way to do this, i.e.: But this raises AttributeError: 'Tensor' object has no attribute 'assign'. The API docs for tf.assign describe the first argument as: ""A mutable Tensor. Should be from a Variable node. May be uninitialized."" Does this mean my placeholders aren't mutable? Can I make them so? Or am I approaching this the wrong way? Minimal runnable example here.",https://stackoverflow.com/questions/45134654,262271,Lack of Alternative Solutions/Documentation,Documentation Ambiguity,"The API docs for tf.assign describe the first argument as: ""A mutable Tensor. Should be from a Variable node. May be uninitialized."" Does this mean my placeholders aren't mutable?"
44563648,How to effectively use tf.bucket_by_sequence_length in Tensorflow?,"<p>So I'm trying to use tf.bucket_by_sequence_length() from Tensorflow, but can not quite figure out how to make it work.</p>

<p>Basically, it should take sequences (of different lengths) as input and have buckets of sequences as output, but it does not seem to work this way.</p>

<p>From this discussion: 
<a href=""https://github.com/tensorflow/tensorflow/issues/5609"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/5609</a>
I have the impression that it needs a queue in order to feed this function, sequence by sequence. It's not clear though.</p>

<p>Function's documentation can be found here: <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.training/bucketing#bucket_by_sequence_length"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.training/bucketing#bucket_by_sequence_length</a></p>
","So I'm trying to use tf.bucket_by_sequence_length() from Tensorflow, but can not quite figure out how to make it work. Basically, it should take sequences (of different lengths) as input and have buckets of sequences as output, but it does not seem to work this way. From this discussion: https://github.com/tensorflow/tensorflow/issues/5609 I have the impression that it needs a queue in order to feed this function, sequence by sequence. It's not clear though. Function's documentation can be found here: https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.training/bucketing#bucket_by_sequence_length",https://stackoverflow.com/questions/44563648,8165188,Inadequate Examples,Documentation Ambiguity,It's not clear though. Function's documentation can be found here:
48495699,How to understand the effect of local_step in tf.ConditionalAccumulator(),"<p>I want to implement the function which conducts <code>backward()</code> after multiple <code>forward()</code> operations in order to increase the actual <code>batch_size</code> with limited GPU memory. So I came to <code>tf.ConditionalAccumulator</code>.</p>

<p>In the arguments of <a href=""https://www.tensorflow.org/api_docs/python/tf/ConditionalAccumulator#apply_grad"" rel=""nofollow noreferrer""><code>tf.ConditionalAccumulator().apply_grad()</code></a>, there is an argument <code>local_step</code> which I do not understand how to appoint. The document explains as follow:</p>

<blockquote>
  <p>Attempts to apply a gradient to the accumulator.</p>
  
  <p>The attempt is silently dropped if the gradient is stale, i.e., local_step is less than the accumulator's global time step.</p>
  
  <p>Args:</p>
  
  <p><code>grad</code>: The gradient tensor to be applied.</p>
  
  <p><code>local_step</code>: Time step at which the gradient was computed.</p>
  
  <p><code>name</code>: Optional name for the operation.</p>
</blockquote>

<p>I tried to search the implementation of <code>tf.CondionalAccumentor().apply_grad()</code>, but didn't find the member variable refers to <code>global_time_step</code>. In my understanding, there should be ten gradient slots, if we want to accumulate 10 times before one gradient update. The <code>global_time_step</code> is applied as an indicator to point out which slot should be used. if the <code>local_step</code> is less than the <code>global_time_step</code>, which means the corresponding slot has been used, so the gradient is stale and should be discarded.</p>

<p>In my implementation, I assign it with <code>global_step</code> variable, which is used to record the number of gradient update in training procedure, and it increases one in every <code>batch_size</code> iterations, thus it increases one after <code>batch_size</code> examples forward. I am not sure about the correctness of my implementation.</p>

<p>I hope someone can help to explain the mechanism of <code>tf.ConditionalAccumulator</code>. </p>
","I want to implement the function which conducts backward() after multiple forward() operations in order to increase the actual batch_size with limited GPU memory. So I came to tf.ConditionalAccumulator. In the arguments of tf.ConditionalAccumulator().apply_grad(), there is an argument local_step which I do not understand how to appoint. The document explains as follow: I tried to search the implementation of tf.CondionalAccumentor().apply_grad(), but didn't find the member variable refers to global_time_step. In my understanding, there should be ten gradient slots, if we want to accumulate 10 times before one gradient update. The global_time_step is applied as an indicator to point out which slot should be used. if the local_step is less than the global_time_step, which means the corresponding slot has been used, so the gradient is stale and should be discarded. In my implementation, I assign it with global_step variable, which is used to record the number of gradient update in training procedure, and it increases one in every batch_size iterations, thus it increases one after batch_size examples forward. I am not sure about the correctness of my implementation. I hope someone can help to explain the mechanism of tf.ConditionalAccumulator.",https://stackoverflow.com/questions/48495699,4202137,Documentation Ambiguity,Documentation Ambiguity,"In the arguments of tf.ConditionalAccumulator().apply_grad(), there is an argument local_step which I do not understand how to appoint. The document explains as follow:"
53124755,How to prevent Tensorflow from allocating the totality of a GPU memory when using eager execution?,"<p>I have pretty much the same question that has already been answered <a href=""https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory"">here</a>, with a slight difference though:</p>

<p>I'm working on a server with a few GPUs that I share with my colleagues for training our deep learning models. The server should also run a small web application that samples from our models. The sampling script uses the relatively new <a href=""https://www.tensorflow.org/guide/eager"" rel=""nofollow noreferrer"">eager execution</a>. In theory it allows me to stop Tensorflow from allocating all the GPU memory by providing a configuration like this:</p>

<pre><code>config = tf.ConfigProto()
config.gpu_options.allow_growth = True
tf.enable_eager_execution(config=config)
</code></pre>

<p>In practice this does not work though. The documentation of the eager execution also states that not all the configuration options that work for sessions will work in eager execution (<a href=""https://www.tensorflow.org/api_docs/python/tf/enable_eager_execution#args"" rel=""nofollow noreferrer"">here</a>). But how can I limit the used memory then?</p>

<p>I know that I can limit the visible devices like this:</p>

<pre><code>os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""
</code></pre>

<p>But I don't want to constantly block an entire GPU for a task that gets called very occasionally and actually needs way less memory.</p>
","I have pretty much the same question that has already been answered here, with a slight difference though: I'm working on a server with a few GPUs that I share with my colleagues for training our deep learning models. The server should also run a small web application that samples from our models. The sampling script uses the relatively new eager execution. In theory it allows me to stop Tensorflow from allocating all the GPU memory by providing a configuration like this: In practice this does not work though. The documentation of the eager execution also states that not all the configuration options that work for sessions will work in eager execution (here). But how can I limit the used memory then? I know that I can limit the visible devices like this: But I don't want to constantly block an entire GPU for a task that gets called very occasionally and actually needs way less memory.",https://stackoverflow.com/questions/53124755,4528518,Requesting (Additional) Resources,Documentation Ambiguity, The documentation of the eager execution also states that not all the configuration options that work for sessions will work in eager execution (here). But how can I limit the used memory then? 
47585864,What's the difference between get_collection and get_collection_ref?,"<p>I have checked the documentations of both methods but they look the same, except that get_collection can take an additional scope parameter. </p>



<pre class=""lang-python prettyprint-override""><code>In [11]: aaa = tf.get_collection_ref(tf.GraphKeys.UPDATE_OPS)
In [12]: aaaa = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
In [13]: aaa == aaaa
Out[13]: True
In [14]: aaa is aaaa
Out[14]: False
</code></pre>

<p>What's the difference between the two and when to use which one?</p>
","I have checked the documentations of both methods but they look the same, except that get_collection can take an additional scope parameter. What's the difference between the two and when to use which one?",https://stackoverflow.com/questions/47585864,3552975,Documentation Ambiguity,Documentation Ambiguity,"I have checked the documentations of both methods but they look the same, except that get_collection can take an additional scope parameter. What's the difference between the two and when to use which one?"
44464055,How the cell state size and cell output size is determined in BasicRNNCell?,"<p>Consider the following code:</p>

<pre><code>import tensorflow as tf
cell=tf.contrib.rnn.BasicRNNCell(num_units = rnn_size)
output, state = tf.nn.dynamic_rnn(cell, input, dtype=tf.float32) 
</code></pre>

<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">documentation of dynamic_rnn</a>, the <code>output</code> and <code>state</code> have shapes <code>[batch_size, max_time, cell.output_size]</code> and <code>[batch_size, cell.state_size]</code>, respectively. </p>

<p>The question: how the <code>cell.state_size</code> and <code>cell.output_size</code> is determined in <code>BasicRNNCell</code>? What is the relationship between <code>num_units = rnn_size</code> in the initilizer of BasicRNNCell and its <code>state_size</code> and <code>output_size</code>?</p>
","Consider the following code: According to the documentation of dynamic_rnn, the output and state have shapes [batch_size, max_time, cell.output_size] and [batch_size, cell.state_size], respectively. The question: how the cell.state_size and cell.output_size is determined in BasicRNNCell? What is the relationship between num_units = rnn_size in the initilizer of BasicRNNCell and its state_size and output_size?",https://stackoverflow.com/questions/44464055,5617507,Documentation Ambiguity,Documentation Ambiguity,"According to the documentation of dynamic_rnn, the output and state have shapes [batch_size, max_time, cell.output_size] and [batch_size, cell.state_size], respectively. The question: how the cell.state_size and cell.output_size is determined in BasicRNNCell? "
45523380,why the tf.nn.dynamic_rnn returns different result regarding sequence_length,"<p>while i studied RNN in the book called Hands-On Machine Learning with Scikit-Learn and TensorFlow, i encountered different result which must be the same.</p>
<hr />
<h1>first code</h1>
<pre><code>n_steps = 2
n_inputs = 3
n_neurons = 5

reset_graph()

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
basic_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)

seq_length = tf.placeholder(tf.int32, [None])
outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)


init = tf.global_variables_initializer()

X_batch = np.array([
        # step 0     step 1
        [[0, 1, 2], [9, 8, 7]], # instance 1
        [[3, 4, 5], [0, 0, 0]], # instance 2 (padded with zero vectors)
        [[6, 7, 8], [6, 5, 4]], # instance 3
        [[9, 0, 1], [3, 2, 1]], # instance 4
    ])

with tf.Session() as sess:
    init.run()
    outputs_val, states_val = sess.run(
        [outputs, states], feed_dict={X: X_batch})
</code></pre>
<h1>result</h1>
<pre><code>[[[ 0.10273618  0.03536123  0.14367972  0.1572928   0.23754682]
  [ 0.41665766  0.49650002  0.1549654   0.07568012  0.82703578]]

 [[ 0.35701871  0.20796996  0.13533755  0.21938165  0.64902753]
  [ 0.15402019  0.14915846  0.31022152  0.13305351  0.36220491]]

 [[ 0.48224443  0.24930702  0.07341093  0.18052572  0.72496963]
  [ 0.3561081   0.55856758  0.31825539  0.13380432  0.90042865]]

 [[ 0.02311822 -0.16510175  0.49798414 -0.06049323  0.23668778]
  [ 0.28713134  0.16252561  0.4774358   0.07630309  0.50222367]]]
</code></pre>
<hr />
<h1>second code</h1>
<pre><code>    n_steps = 2
    n_inputs = 3
    n_neurons = 5

    reset_graph()
    
    X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
    basic_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)
    
    seq_length = tf.placeholder(tf.int32, [None])
    outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,
    sequence_length=seq_length)
    
    init = tf.global_variables_initializer()
    
    X_batch = np.array([
            # step 0     step 1
            [[0, 1, 2], [9, 8, 7]], # instance 1
            [[3, 4, 5], [0, 0, 0]], # instance 2 (padded with zero vectors)
            [[6, 7, 8], [6, 5, 4]], # instance 3
            [[9, 0, 1], [3, 2, 1]], # instance 4
        ])
    seq_length_batch = np.array([2, 1, 2, 2])


    with tf.Session() as sess:
        init.run()
        outputs_val, states_val = sess.run(
            [outputs, states], feed_dict={X: X_batch,seq_length:seq_length_batch})
</code></pre>
<h1>result</h1>
<pre><code>    [[[-0.05313011 -0.03707792 -0.00771733  0.25379574  0.06289639]
      [ 0.34355608 -0.00646485 -0.00426668  0.35139424  0.02420545]]
    
     [[ 0.07838845 -0.04377012 -0.00758527  0.44615552  0.01038414]
      [ 0.          0.          0.          0.          0.        ]]
    
     [[ 0.16005152 -0.01226684 -0.0048396   0.48419252  0.00086438]
      [ 0.4990865  -0.03458051  0.01733598  0.35500884  0.02000519]]
    
     [[ 0.73743606 -0.00149451 -0.102979   -0.39292669  0.50247419]
      [ 0.6204772  -0.04163819 -0.4165332  -0.14101879  0.34553975]]]
</code></pre>
<hr />
<p>Tensorflow document says 'If sequence_length not provided, all batch entries are assumed to be full sequences; and time reversal is applied from time 0 to max_time for each sequence. '</p>
<p>So must the result be the same?</p>
","while i studied RNN in the book called Hands-On Machine Learning with Scikit-Learn and TensorFlow, i encountered different result which must be the same. Tensorflow document says 'If sequence_length not provided, all batch entries are assumed to be full sequences; and time reversal is applied from time 0 to max_time for each sequence. ' So must the result be the same?",https://stackoverflow.com/questions/45523380,4571281,Requesting (Additional) Resources,Documentation Ambiguity,"Tensorflow document says 'If sequence_length not provided, all batch entries are assumed to be full sequences; and time reversal is applied from time 0 to max_time for each sequence. ' So must the result be the same?"
49889153,How to retrieve intermediary state in TensorFlow RNN,"<p>I am running an RNN on a signal in fixed-size segments. The following code allows me to preserve the final state of the previous batch to initialize the initial state of the next batch. </p>

<pre><code>rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=init_state)
</code></pre>

<p>This works when the batches are non-overlapping. For example, my first batch processes samples 0:124 and <code>final_state</code> is the state after this processing. Then, the next batch processes samples 124:256, setting <code>init_state</code> to <code>final_state</code>. </p>

<p>My question is how to retrieve an intermediary state when the batches are overlapping. First, I process samples 0:124, then 10:134, 20:144, so the hop size is 10. I would like to retrieve not the <code>final_state</code> but the state after processing 10 samples. </p>

<p>Is it possible in TF to keep the intermediary state? The <a href=""https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/rnn/static_rnn"" rel=""nofollow noreferrer"">documentation</a> shows that the return value consists only of the final state. </p>

<p>The image shows the issue I am facing due to state discontinuity. In my program, the RNN segment length is 215 and the hop length is 20.</p>

<p><a href=""https://i.stack.imgur.com/G9owu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/G9owu.png"" alt=""Sample results""></a></p>

<p>Update: the easiest turned out to be what <a href=""https://stackoverflow.com/a/49890068/4008884"">David Parks</a> described:</p>

<pre><code>rnn_outputs_one, mid_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs_one, initial_state=rnn_tuple_state)
rnn_outputs_two, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs_two, initial_state=mid_state)
rnn_outputs = rnn_outputs_one + rnn_outputs_two
</code></pre>

<p>and </p>

<pre><code>prev_state = sess.run(mid_state)
</code></pre>

<p>Now, after just a few iterations, the results look much better. <a href=""https://i.stack.imgur.com/4EU6N.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4EU6N.png"" alt=""enter image description here""></a></p>
","I am running an RNN on a signal in fixed-size segments. The following code allows me to preserve the final state of the previous batch to initialize the initial state of the next batch. This works when the batches are non-overlapping. For example, my first batch processes samples 0:124 and final_state is the state after this processing. Then, the next batch processes samples 124:256, setting init_state to final_state. My question is how to retrieve an intermediary state when the batches are overlapping. First, I process samples 0:124, then 10:134, 20:144, so the hop size is 10. I would like to retrieve not the final_state but the state after processing 10 samples. Is it possible in TF to keep the intermediary state? The documentation shows that the return value consists only of the final state. The image shows the issue I am facing due to state discontinuity. In my program, the RNN segment length is 215 and the hop length is 20. Update: the easiest turned out to be what David Parks described: and Now, after just a few iterations, the results look much better.",https://stackoverflow.com/questions/49889153,4008884,Requesting (Additional) Resources,Documentation Completeness,"Is it possible in TF to keep the intermediary state? The <a href=""https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/rnn/static_rnn"" rel=""nofollow noreferrer"">documentation</a> shows that the return value consists only of the final state."
47193290,Servers and sessions,"<p>I'm learning about distributed TensorFlow applications, and I understand jobs, tasks, and servers. A server's target identifies its gRPC location, as in grpc://localhost:1234.</p>

<p>I don't understand what happens when you create a session with a server's target, as in the following code:</p>

<pre><code>with tf.Session(server.target) as sess:
    ...
</code></pre>

<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/Session"" rel=""nofollow noreferrer"">documentation</a> states that <code>server.target</code> identifies the session's execution engine. Another <a href=""https://www.tensorflow.org/deploy/distributed"" rel=""nofollow noreferrer"">page</a> says that the constructor creates a session on the server. This isn't clear to me. How exactly does a server's target affect the session's execution?</p>
","I'm learning about distributed TensorFlow applications, and I understand jobs, tasks, and servers. A server's target identifies its gRPC location, as in grpc://localhost:1234. I don't understand what happens when you create a session with a server's target, as in the following code: The documentation states that server.target identifies the session's execution engine. Another page says that the constructor creates a session on the server. This isn't clear to me. How exactly does a server's target affect the session's execution?",https://stackoverflow.com/questions/47193290,934904,Documentation Ambiguity,Documentation Ambiguity,The documentation states that server.target identifies the session's execution engine. Another page says that the constructor creates a session on the server. This isn't clear to me. 
37921781,What does opt.apply_gradients() do in TensorFlow?,"<p>The documentation is not quite clear about this. I suppose the gradients one can obtain by <code>opt.compute_gradients(E, [v])</code> contain the <code>∂E/∂x = g(x)</code> for each element <code>x</code> of the tensor that <code>v</code> stores. Does <code>opt.apply_gradients(grads_and_vars)</code> essentially execute <code>x ← -η·g(x)</code>, where <code>η</code> is the learning rate? That would imply that if I want to add a positive additive change <code>p</code> to the variable, I would need to need to change <code>g(x) ← g(x) - (1/η)p</code>, e.g. like this:</p>

<pre class=""lang-py prettyprint-override""><code>opt = tf.train.GradientDescentOptimizer(learning_rate=l)
grads_and_vars = opt.compute_gradients(loss, var_list)

for l, gv in enumerate(grads_and_vars):
    grads_and_vars[l] = (gv[0] - (1/l) * p, gv[1])

train_op = opt.apply_gradients(grads_and_vars)
</code></pre>

<p>Is there a better way to do this?</p>
","The documentation is not quite clear about this. I suppose the gradients one can obtain by opt.compute_gradients(E, [v]) contain the ∂E/∂x = g(x) for each element x of the tensor that v stores. Does opt.apply_gradients(grads_and_vars) essentially execute x ← -η·g(x), where η is the learning rate? That would imply that if I want to add a positive additive change p to the variable, I would need to need to change g(x) ← g(x) - (1/η)p, e.g. like this: Is there a better way to do this?",https://stackoverflow.com/questions/37921781,852592,Documentation Completeness,Documentation Ambiguity,The documentation is not quite clear about this.
49114306,Avoiding duplicating graph in tensorflow (LSTM model),"<p>I have the following simplified code (actually, unrolled LSTM model):</p>

<pre><code>def func(a, b):
    with tf.variable_scope('name'):
        res = tf.add(a, b)
    print(res.name)
    return res

func(tf.constant(10), tf.constant(20))
</code></pre>

<p>Whenever I run the last line, it seems that it changes the graph. But I don't want the graph changes. Actually my code is different and is a neural network model but it is too huge, so I've added the above code. I want to call the <code>func</code> without changing the graph of model but it changes. I read about variable scope in <code>TensorFlow</code> but it seems that I've not understand it at all.</p>
","I have the following simplified code (actually, unrolled LSTM model): Whenever I run the last line, it seems that it changes the graph. But I don't want the graph changes. Actually my code is different and is a neural network model but it is too huge, so I've added the above code. I want to call the func without changing the graph of model but it changes. I read about variable scope in TensorFlow but it seems that I've not understand it at all.",https://stackoverflow.com/questions/49114306,9422652,Documentation Ambiguity,Documentation Ambiguity, I read about variable scope in TensorFlow but it seems that I've not understand it at all.
44908968,Tensorflow multiple export strategies,"<p>I am training a model with the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment"" rel=""nofollow noreferrer"">Experiment class</a> and although the documentation seems to suggest you can have more than one export strategy: </p>

<blockquote>
  <p>export_strategies: Iterable of ExportStrategys, or a single one, or None.</p>
</blockquote>

<p>When I include two I get an error while training with ml engine: </p>

<pre><code> AssertionError: Export directory already exists. Please specify a different export directory
</code></pre>

<p>When using the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/learn/make_export_strategy"" rel=""nofollow noreferrer"">make_export_strategy function</a> there is no option to specify the export directory. </p>

<p>Am I approaching this in the wrong way? Ultimately I want people to be able to make prediction requests to the same model with CSV and JSON inputs.</p>

<pre><code> tf.contrib.learn.Experiment(
    estimator=estimator,
    train_input_fn=train_input,
    eval_input_fn=eval_input,
    eval_metrics=eval_metrics,
    train_steps=train_steps,
    eval_steps=eval_steps,
    eval_delay_secs=eval_delay_secs,
    min_eval_frequency=min_eval_frequency,        
    export_strategies=[
      saved_model_export_utils.make_export_strategy(
        serving_input_fn=csv_serving_input_fn,
        exports_to_keep=1),
      saved_model_export_utils.make_export_strategy(
        serving_input_fn=json_serving_input_fn,
        exports_to_keep=1)
    ]
 )
</code></pre>
",I am training a model with the Experiment class and although the documentation seems to suggest you can have more than one export strategy: When I include two I get an error while training with ml engine: When using the make_export_strategy function there is no option to specify the export directory. Am I approaching this in the wrong way? Ultimately I want people to be able to make prediction requests to the same model with CSV and JSON inputs.,https://stackoverflow.com/questions/44908968,6520820,Documentation Completeness,Documentation Replication on Other Examples,I am training a model with the Experiment class and although the documentation seems to suggest you can have more than one export strategy: When I include two I get an error while training with ml engine
46444018,"Meaning of buffer_size in Dataset.map , Dataset.prefetch and Dataset.shuffle","<p>As per TensorFlow <a href=""https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset#prefetch"" rel=""noreferrer"">documentation</a> , the <code>prefetch</code> and <code>map</code> methods of <code>tf.contrib.data.Dataset</code> class, both have a parameter called <code>buffer_size</code>.</p>
<p>For <code>prefetch</code> method, the parameter is known as <code>buffer_size</code> and according to documentation :</p>
<blockquote>
<p>buffer_size: A tf.int64 scalar tf.Tensor, representing the maximum
number elements that will be buffered when prefetching.</p>
</blockquote>
<p>For the <code>map</code> method, the parameter is known as <code>output_buffer_size</code> and according to documentation :</p>
<blockquote>
<p>output_buffer_size: (Optional.) A tf.int64 scalar tf.Tensor,
representing the maximum number of processed elements that will be
buffered.</p>
</blockquote>
<p>Similarly for the <code>shuffle</code> method, the same quantity appears and according to documentation :</p>
<blockquote>
<p>buffer_size: A tf.int64 scalar tf.Tensor, representing the number of
elements from this dataset from which the new dataset will sample.</p>
</blockquote>
<p>What is the relation between these parameters ?</p>
<p>Suppose I create a<code>Dataset</code> object as follows :</p>
<pre><code> tr_data = TFRecordDataset(trainfilenames)
    tr_data = tr_data.map(providefortraining, output_buffer_size=10 * trainbatchsize, num_parallel_calls\
=5)
    tr_data = tr_data.shuffle(buffer_size= 100 * trainbatchsize)
    tr_data = tr_data.prefetch(buffer_size = 10 * trainbatchsize)
    tr_data = tr_data.batch(trainbatchsize)
</code></pre>
<p>What role is being played by the <code>buffer</code> parameters in the above snippet ?</p>
","As per TensorFlow documentation , the prefetch and map methods of tf.contrib.data.Dataset class, both have a parameter called buffer_size. For prefetch method, the parameter is known as buffer_size and according to documentation : For the map method, the parameter is known as output_buffer_size and according to documentation : Similarly for the shuffle method, the same quantity appears and according to documentation : What is the relation between these parameters ? Suppose I create aDataset object as follows : What role is being played by the buffer parameters in the above snippet ?",https://stackoverflow.com/questions/46444018,8530591,Documentation Ambiguity,Documentation Ambiguity,"Similarly for the shuffle method, the same quantity appears and according to documentation : What is the relation between these parameters ? "
49393659,tf.Data: what are stragglers in parallel interleaving?,"<p><a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset#interleave"" rel=""noreferrer""><code>interleave</code></a> is a <code>tf.Data.Dataset</code> method that can be used to interleave together elements from multiple datasets. <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/data/parallel_interleave"" rel=""noreferrer""><code>tf.contrib.data.parallel_interleave</code></a> provides a parallel version of the same functionality with the help of <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply"" rel=""noreferrer""><code>apply</code></a>.</p>

<p>I can see that reading from many datasets in parallel and having buffers for them as allowed by the parallel version will improve throughput. But the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/data/parallel_interleave"" rel=""noreferrer"">documentation</a> also has this to say about how <code>parallel_interleave</code> can increase data throughput:</p>

<blockquote>
  <p>Unlike tf.data.Dataset.interleave, it gets elements from cycle_length
  nested datasets in parallel, which increases the throughput,
  especially in the presence of stragglers.</p>
</blockquote>

<p>What exactly are stragglers, and why does <code>parallel_interleave</code> work especially well in terms of throughput in their presence?</p>
","interleave is a tf.Data.Dataset method that can be used to interleave together elements from multiple datasets. tf.contrib.data.parallel_interleave provides a parallel version of the same functionality with the help of apply. I can see that reading from many datasets in parallel and having buffers for them as allowed by the parallel version will improve throughput. But the documentation also has this to say about how parallel_interleave can increase data throughput: What exactly are stragglers, and why does parallel_interleave work especially well in terms of throughput in their presence?",https://stackoverflow.com/questions/49393659,5471520,Documentation Completeness,Documentation Ambiguity,"But the documentation also has this to say about how parallel_interleave can increase data throughput: What exactly are stragglers, and why does parallel_interleave work especially well in terms of throughput in their presence?"
57009265,How transition from keras fit_generator() to the models input layer works exactly,"<p>I am working with image data and some scalar meta-data (like hair-color, eye-color, ...).
I am using a self-written generator to use the Keras <code>.fit_generator()</code> function.</p>

<p>The process looks like the following:</p>

<p>After applying some data augmentation I have the shape <code>((10,200,200,3),(10,),(10,),(10,),(10,))</code> of my dataset (For imagination: I extract images of shape <code>(200,200,3</code>) and stack together 10 of them -> <code>(10,200,200,3)</code>. Accordingly, I duplicate the metadata 10 times -> shapes <code>(10,)</code> for each )</p>

<p>Afterwards I use the tensorflow function <code>dataset = dataset.apply(tf.contrib.data.unbatch())</code> so that the shape of my dataset is <code>((200,200,3),(),(),(),())</code>. From here I now share the code with you: </p>

<p><strong>Edit (more Code):</strong></p>

<p>Following code are the last line of my generator-function which will be called from the <code>.fit_generator()</code> function in the <code>main()</code></p>

<pre><code>shape_dataset = tf.shape(dataset) # shape ((10,200,200,3),(10,),(10,),(10,),(10,)) like I mentioned above
dataset = dataset.apply(tf.contrib.data.unbatch()) # shape ((200,200,3),(),(),(),()) like I mentioned a bove 
dataset = dataset.shuffle(buffer_size = buffer_size)
dataset = dataset.batch(batch_size=batch_size) 
dataset = dataset.repeat()
iterator_all = dataset.make_one_shot_iterator()
next_all = iterator_all.get_next()

with tf.Session() as sess:
    while True:
        try:
            image, eye_color, hair_ color, labels = sess.run(next_all)
            yield [image, eye_color, hair_ color], labels

        except tf.errors.OutOfRangeError:
            print('Finished')
            break
</code></pre>

<p>This tensor will now be fed into my network via the keras <code>.fit_generator()</code> function.
The input layer looks like the following:</p>

<pre><code>input_image = Input(shape=(200, 200, 3))
input_eye_color = Input(shape=(1,), name='input_ec')
input_hair_color = Input(shape=(1,), name='input_hc')
</code></pre>

<p>Now I have some question:</p>

<ol>
<li><p>Where does the 10 from <code>((10,200,200,3),(10,),(10,),(10,),(10,))</code> go through the <code>tf.contrib.data.unbatch())</code> function? For me it feels like I am losing these 10 values and just get 1?</p></li>
<li><p>The <code>fit_generator()</code> function works batch-wise, but how? Stupid as i sounds I have the feeling my network gets data of shape <code>((200,200,3),(),(),(),())</code> for one iteration step. Obviously it gets data like  <code>((8,10,200,200,3),(8,10,),(8,10,),(8, 10,),(8, 10,))</code> as batch size is 8.</p></li>
</ol>

<p>Can someone explain this issue with the shapes to me?
And really I read a lot but I still do not get it. </p>

<p>Thanks for your help :-) </p>
","I am working with image data and some scalar meta-data (like hair-color, eye-color, ...). I am using a self-written generator to use the Keras .fit_generator() function. The process looks like the following: After applying some data augmentation I have the shape ((10,200,200,3),(10,),(10,),(10,),(10,)) of my dataset (For imagination: I extract images of shape (200,200,3) and stack together 10 of them -&gt; (10,200,200,3). Accordingly, I duplicate the metadata 10 times -&gt; shapes (10,) for each ) Afterwards I use the tensorflow function dataset = dataset.apply(tf.contrib.data.unbatch()) so that the shape of my dataset is ((200,200,3),(),(),(),()). From here I now share the code with you: Edit (more Code): Following code are the last line of my generator-function which will be called from the .fit_generator() function in the main() This tensor will now be fed into my network via the keras .fit_generator() function. The input layer looks like the following: Now I have some question: Can someone explain this issue with the shapes to me? And really I read a lot but I still do not get it. Thanks for your help :-)",https://stackoverflow.com/questions/57009265,11765047,Lack of Alternative Solutions/Documentation,Lack of Alternative Solutions/Documentation,Can someone explain this issue with the shapes to me? And really I read a lot but I still do not get it.
49416931,What does the tensorflow.python.eager.tape do in the implementation of tf.contrib.eager.custom_gradient?,"<p>I am going through TensorFlow Eager Execution from <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md"" rel=""nofollow noreferrer"">here</a> and find it difficult to understand the customizing gradients part. </p>

<pre><code>@tfe.custom_gradient
def logexp(x):
    e = tf.exp(x)
    def grad(dy):
        return dy * (1 - 1/(1 + e))
    return tf.log(1 + e), grad
</code></pre>

<p>First, it is difficult to make sense what does dy do in the gradient function.</p>

<p>When I read the implementation of tf.contrib.eager.custom_gradient.
I can't really make sense the working mechanism behind tape. Following is the code I borrow from the implementation of tf.contrib.eager.custom_gradient. Can anybody explain what does tape do here?</p>

<pre><code>from tensorflow.python.eager import tape
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import gen_array_ops
from tensorflow.python.util import nest
from tensorflow.python.framework import ops as tf_ops

def my_custom_gradient(f):
    def decorated(*args, **kwargs):
        for x in args:
            print('args {0}'.format(x))
        input_tensors = [tf_ops.convert_to_tensor(x) for x in args]

        with tape.stop_recording():
            result, grad_fn = f(*args, **kwargs)
            flat_result = nest.flatten(result)
            flat_result = [gen_array_ops.identity(x) for x in flat_result]

        def actual_grad_fn(*outputs):
            print(*outputs)
            return nest.flatten(grad_fn(*outputs))

       tape.record_operation(
            f.__name__, # the name of f, in this case logexp
            flat_result,
            input_tensors,
            actual_grad_fn) # backward_function
       flat_result = list(flat_result)
       return nest.pack_sequence_as(result, flat_result)
return decorated 
</code></pre>

<p>Even though I found the implementation of tape from <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/tape.py"" rel=""nofollow noreferrer"">here</a>. But I can't really get much out of it due the poor documentation.</p>
","I am going through TensorFlow Eager Execution from here and find it difficult to understand the customizing gradients part. First, it is difficult to make sense what does dy do in the gradient function. When I read the implementation of tf.contrib.eager.custom_gradient. I can't really make sense the working mechanism behind tape. Following is the code I borrow from the implementation of tf.contrib.eager.custom_gradient. Can anybody explain what does tape do here? Even though I found the implementation of tape from here. But I can't really get much out of it due the poor documentation.",https://stackoverflow.com/questions/49416931,3744927,Documentation Ambiguity,Documentation Completeness,Even though I found the implementation of tape from here. But I can't really get much out of it due the poor documentation.
53149059,Why do these two fc api act differently?,"<p>I was implementing the resnet and training on cifar-10 dataset. After ""global average pooling"" layer, I add 10-way fully connected layer. I used two tensorflow API to implement fc layer. However, the method 2 works to me, but the method 1 doesn't work. The method 1 is according to tensorflow official api: <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected"" rel=""nofollow noreferrer"">tf.contrib.layers.fully_connected</a>. The second method is according to <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/dense"" rel=""nofollow noreferrer"">tf.layers.dense</a>. I'm so confused why the first method doesn't work here. FYI, the output of global average pooling layer is [batch_size, 1, 1, 64]. Looking for some help! Thanks in advance!</p>

<p>Edit: Doesn't work means if I use the first method, all output logit of fc become zero, which doesn't make any sense to me. </p>

<pre><code># Method 1: 
def fc(x, n_outputs, scope):
  with tf.variable_scope(scope):
    # x = tf.layers.flatten(x)
    x = tf.contrib.layers.fully_connected(x, num_outputs=n_outputs, weights_initializer=weight_init, weights_regularizer=weight_reg, scope=scope)
    return x

# Method 2:
def fc(x, n_outputs, scope):
  with tf.variable_scope(scope):
     x = tf.layers.flatten(x)
     x = tf.layers.dense(x, units=n_outputs, kernel_initializer=weight_init, kernel_regularizer=weight_reg)
     return x
</code></pre>
","I was implementing the resnet and training on cifar-10 dataset. After ""global average pooling"" layer, I add 10-way fully connected layer. I used two tensorflow API to implement fc layer. However, the method 2 works to me, but the method 1 doesn't work. The method 1 is according to tensorflow official api: tf.contrib.layers.fully_connected. The second method is according to tf.layers.dense. I'm so confused why the first method doesn't work here. FYI, the output of global average pooling layer is [batch_size, 1, 1, 64]. Looking for some help! Thanks in advance! Edit: Doesn't work means if I use the first method, all output logit of fc become zero, which doesn't make any sense to me.",https://stackoverflow.com/questions/53149059,7212365,Documentation Ambiguity,Documentation Replication on Other Examples,The second method is according to tf.layers.dense. I'm so confused why the first method doesn't work here.
43752099,Predictions for tf.contrib.metrics.streaming_auc distributed uniformly?,"<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_auc"" rel=""nofollow noreferrer"">TensorFlow documentation for tf.contrib.metrics.streaming_auc</a> mentions the following:</p>

<blockquote>
  <p>For best results, predictions should be distributed approximately
  uniformly in the range [0, 1] and not peaked around 0 or 1. The
  quality of the AUC approximation may be poor if this is not the case.</p>
</blockquote>

<p>I am a bit confused because I feel like a common paradigm is to have <code>predictions</code> be compared against a target 1-hot encoding:</p>

<pre><code>logits = tf.contrib.layers.fully_connected(
    last_fully_connected_layer,
    num_outputs=2,
    activation_fn=None)
loss = tf.losses.softmax_cross_entropy(target, logits)

# I believe this yields a 3-vector with all 0s but a 1 at 1 single position.
predictions = tf.argmax(logits, 1)
</code></pre>

<p>In those cases, the <code>predictions</code> tensor contains all 0s or 1s.</p>

<p>Should we avoid using <code>tf.contrib.metrics.streaming_auc</code> in those cases? I am not sure in what cases we would use <code>tf.contrib.metrics.streaming_auc</code> then.</p>
","The TensorFlow documentation for tf.contrib.metrics.streaming_auc mentions the following: I am a bit confused because I feel like a common paradigm is to have predictions be compared against a target 1-hot encoding: In those cases, the predictions tensor contains all 0s or 1s. Should we avoid using tf.contrib.metrics.streaming_auc in those cases? I am not sure in what cases we would use tf.contrib.metrics.streaming_auc then.",https://stackoverflow.com/questions/43752099,1276460,Documentation Ambiguity,Documentation Ambiguity,"The TensorFlow documentation for tf.contrib.metrics.streaming_auc mentions the following: I am a bit confused because I feel like a common paradigm is to have predictions be compared against a target 1-hot encoding: In those cases, the predictions tensor contains all 0s or 1s."
43929037,What is the difference between LSTMBlockCell and BasicLSTMCell in Tensorflow contrib.rnn,"<p>I know that LSTMBlockCell is efficient to initialize at the begining of training. The official API guides of Tensorflow said that LSTMBlockCell add a forgot_bias. Can I just replace the BasicLSTMCell with LSTMBlockCell in my RNN models? And there are too many stuffs in tf.contrib.rnn, I feel that those APIs are really inconsistent.</p>
","I know that LSTMBlockCell is efficient to initialize at the begining of training. The official API guides of Tensorflow said that LSTMBlockCell add a forgot_bias. Can I just replace the BasicLSTMCell with LSTMBlockCell in my RNN models? And there are too many stuffs in tf.contrib.rnn, I feel that those APIs are really inconsistent.",https://stackoverflow.com/questions/43929037,8000679,Documentation Ambiguity,Documentation Completeness,I feel that those APIs are really inconsistent.
42470319,Output of Tensorflow LSTM-Cell,"<p>I've got a question on Tensorflow LSTM-Implementation. There are currently several implementations in TF, but I use:</p>
<pre class=""lang-py prettyprint-override""><code>cell = tf.contrib.rnn.BasicLSTMCell(n_units)
</code></pre>
<ul>
<li>where n_units is the amount of 'parallel' LSTM-Cells.</li>
</ul>
<p>Then to get my output I call:</p>
<pre class=""lang-py prettyprint-override""><code> rnn_outputs, rnn_states = tf.nn.dynamic_rnn(cell, x,
                        initial_state=initial_state, time_major=False)
</code></pre>
<ul>
<li>where (as <code>time_major=False</code>) <code>x</code> is of shape <code>(batch_size, time_steps, input_length)</code></li>
<li>where <code>batch_size</code> is my batch_size</li>
<li>where <code>time_steps</code> is the amount of timesteps my RNN will go through</li>
<li>where <code>input_length</code> is the length of one of my input vectors (vector fed into the network on one specific timestep on one specific batch)</li>
</ul>
<p>I expect rnn_outputs to be of shape <code>(batch_size, time_steps, n_units, input_length)</code> as I have not specified another output size.
Documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer""><code>nn.dynamic_rnn</code></a> tells me that output is of shape <code>(batch_size, input_length, cell.output_size)</code>.
The documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell"" rel=""nofollow noreferrer""><code>tf.contrib.rnn.BasicLSTMCell</code></a> does have a property <code>output_size</code>, which is defaulted to n_units (the amount of LSTM-cells I use).</p>
<p>So does each LSTM-Cell only output a scalar for every given timestep? I would expect it to output a vector of the length of the input vector. This seems not to be the case from how I understand it right now, so I am confused. Can you tell me whether that's the case or how I could change it to output a vector of size of the input vector per single lstm-cell maybe?</p>
","I've got a question on Tensorflow LSTM-Implementation. There are currently several implementations in TF, but I use: Then to get my output I call: I expect rnn_outputs to be of shape (batch_size, time_steps, n_units, input_length) as I have not specified another output size. Documentation of nn.dynamic_rnn tells me that output is of shape (batch_size, input_length, cell.output_size). The documentation of tf.contrib.rnn.BasicLSTMCell does have a property output_size, which is defaulted to n_units (the amount of LSTM-cells I use). So does each LSTM-Cell only output a scalar for every given timestep? I would expect it to output a vector of the length of the input vector. This seems not to be the case from how I understand it right now, so I am confused. Can you tell me whether that's the case or how I could change it to output a vector of size of the input vector per single lstm-cell maybe?",https://stackoverflow.com/questions/42470319,6917400,Documentation Ambiguity,Documentation Ambiguity,"The documentation of tf.contrib.rnn.BasicLSTMCell does have a property output_size, which is defaulted to n_units (the amount of LSTM-cells I use). This seems not to be the case from how I understand it right now, so I am confused."
46455648,Tensorflow seq2seq Decoder problems?,"<p>I try to write a seq2seq decoder with the tensorflow tf.contrib.seq2seq package. 
I am wondering if my code is correct and if there is better way to rewrite it. The documentation is not easy to read. </p>

<p>Or my question can be: how can I easily debug this kind of code? How can I inspect some intermediate results in tensorflow?</p>

<pre><code>class Decoder:
    def __init__(self, embedding, hidden_size, num_layers=1, max_length=15):
        self.embedding = embedding
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.cell = tf.nn.rnn_cell.GRUCell(hidden_size)  
        self.linear = tf.Variable(tf.random_normal(shape=(self.hidden_size, cn_total_words))*0.1)


    def __call__(self, inputs, state, encoder_outputs, encoder_state, decoder_length, mode=""train""):


        with tf.variable_scope(""decoder"") as scope:

            inputs = tf.nn.embedding_lookup(self.embedding, inputs)
            encoder_state = tf.tile(tf.expand_dims(encoder_state, 1), (1, tf.shape(inputs)[1], 1))

            attention_mechanism = tf.contrib.seq2seq.LuongAttention(self.hidden_size, encoder_outputs)
            attn_cell = tf.contrib.seq2seq.AttentionWrapper(self.cell, attention_mechanism, self.hidden_size)
            if mode == ""train"":
                helper = tf.contrib.seq2seq.TrainingHelper(inputs=inputs, sequence_length=decoder_length)
            elif mode == ""infer"":
                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding=self.embedding, 
                                                start_tokens=tf.tile([en_dict[""BOS""]], [tf.shape(inputs)[0]]), end_token=en_dict[""EOS""])

            decoder = tf.contrib.seq2seq.BasicDecoder(cell=attn_cell, helper=helper, 
                                                      initial_state=attn_cell.zero_state(tf.shape(inputs)[0], tf.float32))

            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder)
            outputs = tf.concat([tf.expand_dims(out, 1) for out in outputs], 1)

            outputs = tf.tensordot(outputs, self.linear, axes=[[2], [0]])
            return outputs, state
</code></pre>

<p>I got the following error when running the code</p>

<blockquote>
  <p>--------------------------------------------------------------------------- ValueError                                Traceback (most recent call
  last)
  ~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py
  in apply_op(self, op_type_name, name, **keywords)
      434                 preferred_dtype=default_dtype,
  --> 435                 as_ref=input_arg.is_ref)
      436             if input_arg.number_attr and len(</p>
  
  <p>~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py
  in internal_convert_n_to_tensor(values, dtype, name, as_ref,
  preferred_dtype)
      736             as_ref=as_ref,
  --> 737             preferred_dtype=preferred_dtype))
      738   return ret</p>
  
  <p>~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py
  in internal_convert_to_tensor(value, dtype, name, as_ref,
  preferred_dtype)
      675         if ret is None:
  --> 676           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      677 </p>
  
  <p>~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py
  in _TensorTensorConversionFunction(t, dtype, name, as_ref)
      548         ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r""
  --> 549         % (dtype.name, t.dtype.name, str(t)))
      550   return t</p>
  
  <p>ValueError: Tensor conversion requested dtype float32 for Tensor with
  dtype int32: 'Tensor(""seq2seq-train/decoder/ExpandDims_2:0"", shape=(?,
  1, ?), dtype=int32)'</p>
  
  <p>During handling of the above exception, another exception occurred:</p>
  
  <p>TypeError                                 Traceback (most recent call
  last)  in ()
        4 emb_en = np.random.uniform(low=-0.1, high=0.1, size=(en_total_words, hidden_size))
        5 emb_cn = np.random.uniform(low=-0.1, high=0.1, size=(cn_total_words, hidden_size))
  ----> 6 model = Seq2Seq(hidden_size, num_layers, emb_en, emb_cn)
        7 sess = tf.Session()
        8 init = tf.global_variables_initializer()</p>
  
  <p> in <strong>init</strong>(self, hidden_size,
  num_layers, embed_words_en, embed_words_cn)
       81             encoder_outputs, encoder_state = self.encoder(self.encoder_inputs, self.encoder_length)
       82             decoder_length = tf.cast(tf.reduce_sum(self.decoder_mask, 1), tf.int32)
  ---> 83             decoder_outputs, decoder_state = self.decoder(self.decoder_inputs, encoder_state, encoder_outputs,
  encoder_state, decoder_length)
       84 
       85             # decoder_outputs.append(decoder_out)</p>
  
  <p> in <strong>call</strong>(self, inputs, state,
  encoder_outputs, encoder_state, decoder_length, mode)
       50 
       51             outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=decoder)
  ---> 52             outputs = tf.concat([tf.expand_dims(out, 1) for out in outputs], 1)
       53 
       54             outputs = tf.tensordot(outputs, self.linear, axes=[[2], [0]])</p>
  
  <p>~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py
  in concat(values, axis, name)    1064   return
  gen_array_ops._concat_v2(values=values,    1065<br>
  axis=axis,
  -> 1066                                   name=name)    1067     1068 </p>
  
  <p>~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py
  in _concat_v2(values, axis, name)
      491   """"""
      492   result = _op_def_lib.apply_op(""ConcatV2"", values=values, axis=axis,
  --> 493                                 name=name)
      494   return result
      495 </p>
  
  <p>~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py
  in apply_op(self, op_type_name, name, **keywords)
      461                                 (prefix, dtype.name))
      462               else:
  --> 463                 raise TypeError(""%s that don't all match."" % prefix)
      464             else:
      465               raise TypeError(""%s that are invalid."" % prefix)</p>
  
  <p>TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have
  types [float32, int32] that don't all match.</p>
</blockquote>
",I try to write a seq2seq decoder with the tensorflow tf.contrib.seq2seq package. I am wondering if my code is correct and if there is better way to rewrite it. The documentation is not easy to read. Or my question can be: how can I easily debug this kind of code? How can I inspect some intermediate results in tensorflow? I got the following error when running the code,https://stackoverflow.com/questions/46455648,5942350,Documentation Ambiguity,Documentation Ambiguity,The documentation is not easy to read.
42608245,How to use tf.contrib.seq2seq.simple_decoder_fn_inference API,"<p>I did not understand the parameters that needed to be passed into the API call to   <code>tf.contrib.seq2seq.simple_decoder_fn_inference</code> in Tensorflow 1.0
for building the inference block for a Seq2Seq Attention mechanism RNN.</p>

<p>Can someone explain, in detail, what each parameter of this function call means and is supposed to do?</p>

<p>The link to the documentation is here :
<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/attention_decoder_fn_inference"" rel=""nofollow noreferrer"">tf.contrib.seq2seq.attention_decoder_fn_inference()</a></p>
","I did not understand the parameters that needed to be passed into the API call to tf.contrib.seq2seq.simple_decoder_fn_inference in Tensorflow 1.0 for building the inference block for a Seq2Seq Attention mechanism RNN. Can someone explain, in detail, what each parameter of this function call means and is supposed to do? The link to the documentation is here : tf.contrib.seq2seq.attention_decoder_fn_inference()",https://stackoverflow.com/questions/42608245,7661539,Documentation Ambiguity,Documentation Ambiguity,"Can someone explain, in detail, what each parameter of this function call means and is supposed to do? The link to the documentation is here"
46359843,Parameters in tf.contrib.seq2seq.sequence_loss,"<p>I'm trying to use the tf.contrib.seq2seq.sequence_loss function in a RNN model to calculate the loss. 
According to the API document, this function requires at least three parameters: logits, targets and weights</p>

<pre><code>sequence_loss(
    logits,
    targets,
    weights,
    average_across_timesteps=True,
    average_across_batch=True,
    softmax_loss_function=None,
    name=None
)

logits: A Tensor of shape [batch_size, sequence_length, num_decoder_symbols] and dtype float. The logits correspond to the prediction across all classes at each timestep.
targets: A Tensor of shape [batch_size, sequence_length] and dtype int. The target represents the true class at each timestep. 
weights: A Tensor of shape [batch_size, sequence_length] and dtype float. weights constitutes the weighting of each prediction in the sequence. When using weights as masking, set all valid timesteps to 1 and all padded timesteps to 0, e.g. a mask returned by tf.sequence_mask.
average_across_timesteps: If set, sum the cost across the sequence dimension and divide the cost by the total label weight across timesteps.
average_across_batch: If set, sum the cost across the batch dimension and divide the returned cost by the batch size.
softmax_loss_function: Function (labels, logits) -&gt; loss-batch to be used instead of the standard softmax (the default if this is None). Note that to avoid confusion, it is required for the function to accept named arguments.
name: Optional name for this operation, defaults to ""sequence_loss"".
</code></pre>

<p>My understand is logits is my prediction after using Xw+b, so the shape of it should be [batch_size, sequence_length, output size]. Then target should be my label, but the shape required in is [batch_size, sequence_length]. I suppose my label should have the same shape as the logits. </p>

<p>So how to convert the 3d labels to 2d? Thanks  in  advance </p>
","I'm trying to use the tf.contrib.seq2seq.sequence_loss function in a RNN model to calculate the loss. According to the API document, this function requires at least three parameters: logits, targets and weights My understand is logits is my prediction after using Xw+b, so the shape of it should be [batch_size, sequence_length, output size]. Then target should be my label, but the shape required in is [batch_size, sequence_length]. I suppose my label should have the same shape as the logits. So how to convert the 3d labels to 2d? Thanks in advance",https://stackoverflow.com/questions/46359843,1779012,Requesting (Additional) Resources,Requesting (Additional) Resources,"According to the API document, this function requires at least three parameters: logits, targets and weights.I suppose my label should have the same shape as the logits. So how to convert the 3d labels to 2d? "
47035862,How does tensorflow's tf.contrib.training.batch_sequences_with_states API work?,"<p>I am dealing with long sequential data which has to be passed to an RNN. To do truncated BPTT and batching, seems like there are two options: </p>

<ol>
<li>Create a batch by combining <em>respective</em> segments from different sequences. Preserve final state of each sequence in a batch and pass it on to next batch.</li>
<li>Consider each sequence as a mini-batch with segments from the sequence becoming members of the batch. Preserve the state of the last time step in one segment and pass it on to the first time step of the next segment.</li>
</ol>

<p>I came across <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/training/batch_sequences_with_states"" rel=""nofollow noreferrer""><code>tf.contrib.training.batch_sequences_with_states</code></a> which seems to be doing one of the two. The documentation is confusing to me and hence I want to be certain which way does it generate the batches. </p>

<p>My guess is it does it the first way.  That’s because, if the batching is being done the second way, then we cannot leverage the benefits of vectorization, since, to preserve the state between the last time step of one segement  to the first time step of the next segment, RNN should process one token at a time sequentially. </p>

<p>Question:</p>

<p>Which of these two batching strategies are implemented in <code>tf.contrib.training.batch_sequences_with_states</code>?</p>
","I am dealing with long sequential data which has to be passed to an RNN. To do truncated BPTT and batching, seems like there are two options: I came across tf.contrib.training.batch_sequences_with_states which seems to be doing one of the two. The documentation is confusing to me and hence I want to be certain which way does it generate the batches. My guess is it does it the first way. That’s because, if the batching is being done the second way, then we cannot leverage the benefits of vectorization, since, to preserve the state between the last time step of one segement to the first time step of the next segment, RNN should process one token at a time sequentially. Question: Which of these two batching strategies are implemented in tf.contrib.training.batch_sequences_with_states?",https://stackoverflow.com/questions/47035862,3001665,Documentation Ambiguity,Documentation Ambiguity,The documentation is confusing to me and hence I want to be certain which way does it generate the batches.
44742878,Reading CSV files in Tensorflow 1.2.0,"<p>I am trying to read <a href=""https://github.com/chiphuyen/tf-stanford-tutorials/blob/master/data/heart.csv"" rel=""nofollow noreferrer"">heart.csv</a> file data in batches. Following the documentation from <a href=""https://www.tensorflow.org/versions/r0.12/how_tos/reading_data/#reading_from_files"" rel=""nofollow noreferrer"">tensorflow</a> website, I have the following code working to read row by row</p>

<pre><code>import tensorflow as tf
filename_queue = tf.train.string_input_producer([""heart.csv""])
reader = tf.TextLineReader(skip_header_lines=1)
_, csv_row = reader.read(filename_queue)

record_defaults = [[0], [0.0], [0.0], [0.0], [""""], [0], [0.0], [0.0], [0], [0]]
sbp, tobacco, ldl, adiposity, famhist, typea, obesity, alcohol, age, chd = tf.decode_csv(csv_row, record_defaults=record_defaults)
features = [sbp, tobacco, ldl, adiposity, famhist, typea, obesity, alcohol, age]

nof_examples = 10
with tf.Session() as sess:
    tf.global_variables_initializer().run()
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    while nof_examples &gt; 0:
        nof_examples -= 1
        try:
            data_features, data_chd = sess.run([features, chd])
#             data_features[4] = 1 if data_features[4] == 'Present' else 0
            print(data_features, data_chd)
        except tf.errors.OutOfRangeError:
            coord.request_stop()
            coord.join(threads)
            break
    coord.request_stop()
    coord.join(threads)
</code></pre>

<p>Output:</p>

<pre><code>([160, 12.0, 5.73, 23.110001, 'Present', 49, 25.299999, 97.199997, 52], 1)
([144, 0.0099999998, 4.4099998, 28.610001, 'Absent', 55, 28.870001, 2.0599999, 63], 1)
([118, 0.079999998, 3.48, 32.279999, 'Present', 52, 29.139999, 3.8099999, 46], 0)
([170, 7.5, 6.4099998, 38.029999, 'Present', 51, 31.99, 24.26, 58], 1)
([134, 13.6, 3.5, 27.780001, 'Present', 60, 25.99, 57.34, 49], 1)
([132, 6.1999998, 6.4699998, 36.209999, 'Present', 62, 30.77, 14.14, 45], 0)
([142, 4.0500002, 3.3800001, 16.200001, 'Absent', 59, 20.809999, 2.6199999, 38], 0)
([114, 4.0799999, 4.5900002, 14.6, 'Present', 62, 23.110001, 6.7199998, 58], 1)
([114, 0.0, 3.8299999, 19.4, 'Present', 49, 24.860001, 2.49, 29], 0)
([132, 0.0, 5.8000002, 30.959999, 'Present', 69, 30.110001, 0.0, 53], 1)
</code></pre>

<p>But when i try to read in batches as showed in the tensorflow documentation, i get</p>

<pre><code>TypeError: Cannot convert a list containing a tensor of dtype &lt;dtype:
float32'&gt; to &lt;dtype: 'int32'&gt; (Tensor is: &lt;tf.Tensor 'DecodeCSV_6:1'
shape=() dtype=float32&gt;)
</code></pre>

<p>Batch processing code</p>

<pre><code>import tensorflow as tf
batch_size = 1
def read_my_file_format(filename_queue):
    reader = tf.TextLineReader(skip_header_lines=1)
    _, csv_row = reader.read(filename_queue)
    record_defaults = [[0], [0.0], [0.0], [0.0], [""""], [0], [0.0], [0.0], [0], [0]]
    sbp, tobacco, ldl, adiposity, famhist, typea, obesity, alcohol, age, chd = tf.decode_csv(csv_row, record_defaults=record_defaults)
    feature = [sbp, tobacco, ldl, adiposity, famhist, typea, obesity, alcohol, age]
    label = [chd]
    return feature, label

def input_pipeline(filenames, batch_size, num_epochs=None):
    filename_queue = tf.train.string_input_producer(filenames, 
                                                    num_epochs=num_epochs, 
                                                    shuffle=True)
    feature, label = read_my_file_format(filename_queue)
    min_after_dequeue = 10000
    capacity = min_after_dequeue + 3 * batch_size
    feature_batch, label_batch = tf.train.shuffle_batch([feature, label], 
                                                        batch_size=batch_size, 
                                                        capacity=capacity,
                                                        min_after_dequeue=min_after_dequeue)
    return feature_batch, label_batch

features, labels = input_pipeline(['heart.csv'], batch_size)

with tf.Session() as sess:
    tf.global_variables_initializer().run()

    # start populating filename queue
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    try:
        while not coord.should_stop():
            feature_batch, label_batch = sess.run([features, labels])
            print(feature_batch)
    except tf.errors.OutOfRangeError:
        print('Done training, epoch reached')
    finally:
        coord.request_stop()
    coord.join(threads) 
</code></pre>

<p>Reading CSV files using tensorflow seems bit cumbersome but I am sure it has its importance in the library being a distributed system. I found it confusing and took more than 60 mins to read and get a grasp on how the reading feed pipeline worked for csv files. May be documentation should be better and more visuals are needed.</p>
","I am trying to read heart.csv file data in batches. Following the documentation from tensorflow website, I have the following code working to read row by row Output: But when i try to read in batches as showed in the tensorflow documentation, i get Batch processing code Reading CSV files using tensorflow seems bit cumbersome but I am sure it has its importance in the library being a distributed system. I found it confusing and took more than 60 mins to read and get a grasp on how the reading feed pipeline worked for csv files. May be documentation should be better and more visuals are needed.",https://stackoverflow.com/questions/44742878,471384,Documentation Ambiguity,Documentation Ambiguity,I found it confusing and took more than 60 mins to read and get a grasp on how the reading feed pipeline worked for csv files. May be documentation should be better and more visuals are needed.
73374580,optimize data input pipeline with keras datagenerator by using tf dataset,"<p>i want to train my autoencoder with ~100k hdf5 files. I wrote a datagenerator using keras.utils.Sequence. Everything works fine, but now im getting a data bottleneck. I watched some documentation on the tf datasets and how they perform much faster.</p>
<pre><code>class DataGenerator(keras.utils.Sequence):

def __init__(self,path,batch_size):
    self.path = path
    self.batch_size = batch_size
    self.ids = os.listdir(self.path)

def __len__(self):
    return int(np.floor(len(self.ids) / self.batch_size))

def __getitem__(self,index):
    epsilons,fields = list(), list()

    for id in self.ids[index*self.batch_size:(index+1)*self.batch_size]:

        hf = h5py.File(os.path.join(self.path, id), 'r')
        epsilons.append(np.array(hf.get('epsilon')))
        fields.append(np.array(hf.get('field')))
        hf.close()

    return np.asarray(epsilons), np.asarray(fields)
</code></pre>
<p>Normally I would use my generator like this:</p>
<pre><code>train = DataGenerator(args.p_train, args.bs)
m.fit(train, epochs=args.ep,callbacks = [tboard_callback])
</code></pre>
<p>Now I'm using the Dataset.from generator method:</p>
<pre><code>dataset = tf.data.Dataset.from_generator(lambda: train,(tf.float64,tf.float64))
dataset = dataset.prefetch(autotune)

m.fit(dataset, epochs=args.ep,callbacks = [tboard_callback])
</code></pre>
<p>Unfortunately my basic approach need 20s per epoch, the from_generator approach takes 31s.
Does anyone of you had similar problems on how to get your datagenerator much faster?</p>
<p>Thanks,
Lukas</p>
","i want to train my autoencoder with ~100k hdf5 files. I wrote a datagenerator using keras.utils.Sequence. Everything works fine, but now im getting a data bottleneck. I watched some documentation on the tf datasets and how they perform much faster. Normally I would use my generator like this: Now I'm using the Dataset.from generator method: Unfortunately my basic approach need 20s per epoch, the from_generator approach takes 31s. Does anyone of you had similar problems on how to get your datagenerator much faster? Thanks, Lukas",https://stackoverflow.com/questions/73374580,19264587,Requesting (Additional) Resources,Requesting (Additional) Resources,Does anyone of you had similar problems on how to get your datagenerator much faster? 
46938530,Produce balanced mini batch with Dataset API,"<p>I've a question about the new dataset API (tensorflow 1.4rc1).
I've a unbalanced dataset wrt to labels <code>0</code> and <code>1</code>. My goal is to create balanced mini batches during the preprocessing.</p>

<p>Assume I've two filtered datasets:</p>

<pre><code>ds_pos = dataset.filter(lambda l, x, y, z: tf.reshape(tf.equal(l, 1), []))
ds_neg = dataset.filter(lambda l, x, y, z: tf.reshape(tf.equal(l, 0), [])).repeat()
</code></pre>

<p>Is there a way to combine these two datasets such that the resulting dataset looks like <code>ds = [0, 1, 0, 1, 0, 1]</code>:</p>

<p>Something like this:</p>

<pre><code>dataset = tf.data.Dataset.zip((ds_pos, ds_neg))
dataset = dataset.apply(...)
# dataset looks like [0, 1, 0, 1, 0, 1, ...]
dataset = dataset.batch(20)
</code></pre>

<p>My current approach is:</p>

<pre><code>def _concat(x, y):
   return tf.cond(tf.random_uniform(()) &gt; 0.5, lambda: x, lambda: y)
dataset = tf.data.Dataset.zip((ds_pos, ds_neg))
dataset = dataset.map(_concat)
</code></pre>

<p>But I've the feeling there is a more elegant way.</p>

<p>Thanks in advance!</p>
","I've a question about the new dataset API (tensorflow 1.4rc1). I've a unbalanced dataset wrt to labels 0 and 1. My goal is to create balanced mini batches during the preprocessing. Assume I've two filtered datasets: Is there a way to combine these two datasets such that the resulting dataset looks like ds = [0, 1, 0, 1, 0, 1]: Something like this: My current approach is: But I've the feeling there is a more elegant way. Thanks in advance!",https://stackoverflow.com/questions/46938530,863543,Requesting (Additional) Resources,Requesting (Additional) Resources,But I've the feeling there is a more elegant way.
52636943,"What is a ""stateful object"" in tensorflow?","<p>In several parts of the documentation (e.g. <code>Dataset Iterators</code> <a href=""https://www.tensorflow.org/guide/datasets#consuming_values_from_an_iterator"" rel=""noreferrer"">here</a>) there are references to <code>Stateful Objects</code>. What exactly are they and what role do they play in the graph?</p>

<p>To clarify, in the Dataset documentation there's an example with the <code>one_shot_iterator</code> that works because it's stateless:  </p>

<pre><code>dataset = tf.data.Dataset.range(100)
iterator = dataset.make_one_shot_iterator()
</code></pre>

<p>what makes the iterator stateless?</p>
","In several parts of the documentation (e.g. Dataset Iterators here) there are references to Stateful Objects. What exactly are they and what role do they play in the graph? To clarify, in the Dataset documentation there's an example with the one_shot_iterator that works because it's stateless: what makes the iterator stateless?",https://stackoverflow.com/questions/52636943,1047543,Documentation Ambiguity,Documentation Ambiguity,In several parts of the documentation (e.g. Dataset Iterators here) there are references to Stateful Objects. What exactly are they and what role do they play in the graph?
58628787,What is the intuition behind the Iterator.get_next method?,"<p>The name of the method <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/data/Iterator#get_next"" rel=""nofollow noreferrer""><code>get_next()</code></a> is a little bit misleading. The documentation says</p>
<blockquote>
<p>Returns a nested structure of <code>tf.Tensor</code>s representing the next element.</p>
<p>In graph mode, you should typically call this method <strong>once</strong> and use its result as the input to another computation. A typical loop will then call <code>tf.Session.run</code> on the result of that computation. The loop will terminate when the <code>Iterator.get_next()</code> operation raises <code>tf.errors.OutOfRangeError</code>. The following skeleton shows how to use this method when building a training loop:</p>
</blockquote>
<pre><code>dataset = ...  # A `tf.data.Dataset` object.
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Build a TensorFlow graph that does something with each element.
loss = model_function(next_element)
optimizer = ...  # A `tf.compat.v1.train.Optimizer` object.
train_op = optimizer.minimize(loss)

with tf.compat.v1.Session() as sess:
  try:
    while True:
      sess.run(train_op)
  except tf.errors.OutOfRangeError:
    pass
</code></pre>
<p>Python also has a function called <a href=""https://docs.python.org/3/library/functions.html#next"" rel=""nofollow noreferrer""><code>next</code></a>, which needs to be called every time we need the next element of the iterator. However, according to the documentation of <code>get_next()</code> quoted above, <code>get_next()</code> should be called only once and its result should be evaluated by calling the method <code>run</code> of the session, so this is a little bit unintuitive, because I was used to the Python's built-in function <code>next</code>. In <a href=""https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/bayesian_neural_network.py"" rel=""nofollow noreferrer"">this script</a>, <code>get_next()</code> is also called only and the result of the call is evaluated at every step of the computation.</p>
<p>What is the intuition behind <code>get_next()</code> and how is it different from <code>next()</code>? I think that the next element of the dataset (or feedable iterator), in the second example I linked above, is retrieved every time the result of the first call to <code>get_next()</code> is evaluated by calling the method <code>run</code>, but this is a little unintuitive. I don't get why we do not need to call <code>get_next</code> at every step of the computation (to get the next element of the feedable iterator), even after reading the note in the documentation</p>
<blockquote>
<p>NOTE: It is legitimate to call <code>Iterator.get_next()</code> multiple times, e.g. when you are distributing different elements to multiple devices in a single step. However, a common pitfall arises when users call <code>Iterator.get_next()</code> in each iteration of their training loop. <code>Iterator.get_next()</code> adds ops to the graph, and executing each op allocates resources (including threads); as a consequence, invoking it in every iteration of a training loop causes slowdown and eventual resource exhaustion. To guard against this outcome, we log a warning when the number of uses crosses a fixed threshold of suspiciousness.</p>
</blockquote>
<p>In general, it is not clear how the Iterator works.</p>
","The name of the method get_next() is a little bit misleading. The documentation says Python also has a function called next, which needs to be called every time we need the next element of the iterator. However, according to the documentation of get_next() quoted above, get_next() should be called only once and its result should be evaluated by calling the method run of the session, so this is a little bit unintuitive, because I was used to the Python's built-in function next. In this script, get_next() is also called only and the result of the call is evaluated at every step of the computation. What is the intuition behind get_next() and how is it different from next()? I think that the next element of the dataset (or feedable iterator), in the second example I linked above, is retrieved every time the result of the first call to get_next() is evaluated by calling the method run, but this is a little unintuitive. I don't get why we do not need to call get_next at every step of the computation (to get the next element of the feedable iterator), even after reading the note in the documentation In general, it is not clear how the Iterator works.",https://stackoverflow.com/questions/58628787,3924118,Documentation Ambiguity,Documentation Ambiguity,"I don't get why we do not need to call get_next at every step of the computation (to get the next element of the feedable iterator), even after reading the note in the documentation In general, it is not clear how the Iterator works."
63665112,Can anyone explain how the function of shuffle in tf.dataset work?,"<p>I can't find out how the function of shuffle in tf.dataset work.
I try to see output to guess what happen inside.</p>
<pre><code>dataset = tf.data.Dataset.range(6);
dataset = dataset.shuffle(buffer_size =1).batch(6)
for item in dataset:
  print(item)
</code></pre>
<p>Output:</p>
<pre><code>tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int64)
</code></pre>
<p>===&gt; As you see, the shuffle doesn't work when buffer_size =1
But when I change buffer_size = 2 the list change the order but the first item only in 0 or 1 although I run 100 time again.</p>
<p>Anyone in group can explain the role of buffer_size. I read the document of tensorflow at
<a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle</a></p>
<p>In my thought, when set buffer_size = 1, as document said, maybe i can replace element in buffer_size. But the output I get make me confused.</p>
<p>can anyone run into the same problem ?</p>
","I can't find out how the function of shuffle in tf.dataset work. I try to see output to guess what happen inside. Output: ===&gt; As you see, the shuffle doesn't work when buffer_size =1 But when I change buffer_size = 2 the list change the order but the first item only in 0 or 1 although I run 100 time again. Anyone in group can explain the role of buffer_size. I read the document of tensorflow at https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle In my thought, when set buffer_size = 1, as document said, maybe i can replace element in buffer_size. But the output I get make me confused. can anyone run into the same problem ?",https://stackoverflow.com/questions/63665112,1755017,Documentation Ambiguity,Documentation Ambiguity,Anyone in group can explain the role of buffer_size. I read the document of tensorflow
55319623,Large dataset processing for Tensorflow Federated,"<p>What is the efficient way to prepare ImageNet (or other big datasets) for Tensorflow federated simulations? Particularly with applying custom map function on tf.Dataset object? I looked into the tutorials and docs but did not find anything helpful for this usecase. This tutorial (<a href=""https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2</a>) shows MNIST processing but this dataset is relatively small.</p>
",What is the efficient way to prepare ImageNet (or other big datasets) for Tensorflow federated simulations? Particularly with applying custom map function on tf.Dataset object? I looked into the tutorials and docs but did not find anything helpful for this usecase. This tutorial (https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2) shows MNIST processing but this dataset is relatively small.,https://stackoverflow.com/questions/55319623,10966395,Documentation Completeness,Documentation Completeness, I looked into the tutorials and docs but did not find anything helpful for this usecase.
58672774,Training using tf.Dataset in TensorFlow 2.0,"<p>I'm having difficulty training my TensorFlow model using a <code>tf.Dataset</code> rather than, say, a <code>pd.DataFrame</code> (which works fine). </p>

<p>I have created a dummy example below that I would expect to work given what I have read online/on the <a href=""https://www.tensorflow.org/guide/data"" rel=""nofollow noreferrer"">TensorFlow website</a>.</p>

<pre class=""lang-py prettyprint-override""><code>!pip install tensorflow==2.0.0 &gt; /dev/null

import numpy as np
import tensorflow as tf

features, target = np.random.rand(100, 30), np.random.randint(0, 2, 100)
dataset = tf.data.Dataset.from_tensor_slices((features, target))

model = tf.keras.Sequential([
    tf.keras.layers.Dense(30, activation='relu', input_shape=(30,)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(30, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.fit(
    dataset, 
    epochs=10,
)
</code></pre>

<p>which returns the following error message</p>

<pre><code>...

ValueError: Error when checking input: expected dense_input to have shape (30,) but got array with shape (1,)
</code></pre>

<p>Is there anything obviously wrong in the above? Why is TensorFlow grabbing an input with shape <code>(1,)</code>?</p>
","I'm having difficulty training my TensorFlow model using a tf.Dataset rather than, say, a pd.DataFrame (which works fine). I have created a dummy example below that I would expect to work given what I have read online/on the TensorFlow website. which returns the following error message Is there anything obviously wrong in the above? Why is TensorFlow grabbing an input with shape (1,)?",https://stackoverflow.com/questions/58672774,11978086,Documentation Replication on Other Examples,Documentation Replication on Other Examples, I have created a dummy example below that I would expect to work given what I have read online/on the TensorFlow website.
48552103,"Why does the TensorFlow tf.data.Dataset.shuffle function's reshuffle_each_iteration boolean argument default to None, as opposed to True?","<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"" rel=""nofollow noreferrer"">documentation for the tf.Dataset.data.shuffle function</a> states the following:</p>

<blockquote>
  <ul>
  <li><strong>reshuffle_each_iteration</strong>: (Optional.) A boolean, which if true indicates that the dataset should be pseudorandomly reshuffled each time it is iterated over. (Defaults to True.)</li>
  </ul>
</blockquote>

<p>However, the default value in the function is None, as mentioned on the same page and in <a href=""https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/python/data/ops/dataset_ops.py#L590"" rel=""nofollow noreferrer"">the actual code</a>:</p>

<pre><code>def shuffle(self, buffer_size, seed=None, reshuffle_each_iteration=None):
</code></pre>

<p>The function calls the ShuffleDataset class, whose <code>__init__</code> function also <a href=""https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/python/data/ops/dataset_ops.py#L1245"" rel=""nofollow noreferrer"">sets the same argument to None by default</a>, and <a href=""https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/python/data/ops/dataset_ops.py#L1292"" rel=""nofollow noreferrer"">uses the following logic</a> to set the default value of the argument to True:</p>

<pre><code>if reshuffle_each_iteration is None:
  self._reshuffle_each_iteration = True
else:
  self._reshuffle_each_iteration = reshuffle_each_iteration
</code></pre>

<p>Why isn't the argument just set to True by default in both the function and the class? This would make the above code block redundant and allow replacing it with only <code>self._reshuffle_each_iteration = reshuffle_each_iteration</code>.</p>
","The documentation for the tf.Dataset.data.shuffle function states the following: However, the default value in the function is None, as mentioned on the same page and in the actual code: The function calls the ShuffleDataset class, whose __init__ function also sets the same argument to None by default, and uses the following logic to set the default value of the argument to True: Why isn't the argument just set to True by default in both the function and the class? This would make the above code block redundant and allow replacing it with only self._reshuffle_each_iteration = reshuffle_each_iteration.",https://stackoverflow.com/questions/48552103,6457747,Documentation Ambiguity,Documentation Ambiguity,"The documentation for the tf.Dataset.data.shuffle function states the following: However, the default value in the function is None, as mentioned on the same page and in the actual code"
50245039,record_defaults of tf.decode_csv in tensorflow,"<p>I used tf.decode_csv in tensorflow as decoder to parse training examples in a tab-delimited file into cnn models. For every training example, the features are 2 dimensions (100 columns, 2000 rows). After reading the document in tensorflow official site, I still have two questions. </p>

<ol>
<li>how to create record_defaults? The following is my code to do that, but I
am not sure if it is right.</li>
</ol>

<p>code</p>

<pre><code>filename_queue = tf.train.string_input_producer([file], num_epochs)

key, value = tf.TextLineReader().read(filename_queue)

record_defaults = [[1.0 for col in range(0, 100)] for row in range(0, 2000)]

content = tf.decode_csv(value, record_defaults = record_defaults, field_delim = '\t')

features = tf.pack(content[0:1999])
</code></pre>

<ol start=""2"">
<li>I am doing binary (0, 1) classification. Where do I put the labels for training examples? in the 2001th row? (For every training example, the first 2000 rows for features, and the 2001th row for label)</li>
</ol>

<p>Thanks for your time!</p>
","I used tf.decode_csv in tensorflow as decoder to parse training examples in a tab-delimited file into cnn models. For every training example, the features are 2 dimensions (100 columns, 2000 rows). After reading the document in tensorflow official site, I still have two questions. code Thanks for your time!",https://stackoverflow.com/questions/50245039,9378677,Documentation Completeness,Documentation Ambiguity," After reading the document in tensorflow official site, I still have two questions."
59906819,What is the correct explanation for tf.dense?,"<p>I am using a tutorial to learn RNN. 
As shown in the image below, it has used tf.dense and given an explanation which I cannot understand. </p>

<p>(As a newbie to stackoverflow, I cannot insert images, hence the link)</p>

<p>The documentation at tensorflow.org also does not help much and it is so bad for a beginner like me that I've given a 1-star rating. It says the following (which does not make sense to me)</p>

<p><a href=""https://i.stack.imgur.com/cjFv5.png"" rel=""nofollow noreferrer"">The explanation at tensorflow.org</a></p>

<p>Can someone kindly explain it to me. Thank you</p>

<p><a href=""https://i.stack.imgur.com/tGIYM.png"" rel=""nofollow noreferrer"">Excerpt from the tutorial I am using to learn.</a></p>
","I am using a tutorial to learn RNN. As shown in the image below, it has used tf.dense and given an explanation which I cannot understand. (As a newbie to stackoverflow, I cannot insert images, hence the link) The documentation at tensorflow.org also does not help much and it is so bad for a beginner like me that I've given a 1-star rating. It says the following (which does not make sense to me) The explanation at tensorflow.org Can someone kindly explain it to me. Thank you Excerpt from the tutorial I am using to learn.",https://stackoverflow.com/questions/59906819,12483947,Documentation Completeness,Documentation Completeness, The documentation at tensorflow.org also does not help much and it is so bad for a beginner like me that I've given a 1-star rating. 
71830863,MirroredStrategy causes IndexError: pop from empty list when using Keras Sequences as model input,"<p>While the <a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy"" rel=""nofollow noreferrer"">MirroredStrategy</a>'s <code>IndexError: pop from empty list</code> is now infamous and there are numerous possible causes for it, such as reported in the following questions:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/68309367/keras-multigpu-training-fails-with-error-message-indexerror-pop-from-empty-li"">MirroredStrategy <code>IndexError</code> caused by <code>K.clear_session()</code></a></li>
<li><a href=""https://github.com/keras-team/autokeras/issues/1101"" rel=""nofollow noreferrer"">MirroredStrategy <code>IndexError</code> within AutoKeras</a></li>
<li><a href=""https://github.com/tensorflow/tensorflow/issues/19744"" rel=""nofollow noreferrer"">MirroredStrategy <code>IndexError</code> when training from checkpoint</a></li>
</ul>
<p>And so forth, but none apply to my use case.</p>
<p>In my use case, I'm using <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"" rel=""nofollow noreferrer""><code>Keras Sequence</code></a> objects to generate the training inputs, as I'm working on large datasets (would not fit in RAM) with a single known positive class and unknown negatives.</p>
<p>Following tutorials such as the one available on the <a href=""https://keras.io/getting_started/faq/#how-can-i-train-a-keras-model-on-multiple-gpus-on-a-single-machine"" rel=""nofollow noreferrer"">Keras Documentation</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy"" rel=""nofollow noreferrer"">TensorFlow documentation</a> my code looks like the following:</p>
<pre class=""lang-py prettyprint-override""><code>
my_training_sequence = MySequenceObject()

if tf.config.list_physical_devices('GPU'):
    strategy = tf.distribute.MirroredStrategy(devices)
else:
    # Use the Default Strategy
    strategy = tf.distribute.get_strategy()

with strategy.scope():
    model = CreateMyKerasModel()
    # While in the TensorFlow documentation the compilation step
    # is shown OUTSIDE the scope, in the Keras one it happens
    # within the scope.
    # I  have found out that is NECESSARY to place it inside the scope
    # as the Keras Metrics need to be in the same strategy scope of the model
    # to work properly.
    model.compile(...)

# Then, OUSIDE from the score, run the fit
# which causes the IndexError
model.fit(my_training_sequence)
</code></pre>
<p>Any ideas on how to deal with this?</p>
","While the MirroredStrategy's IndexError: pop from empty list is now infamous and there are numerous possible causes for it, such as reported in the following questions: And so forth, but none apply to my use case. In my use case, I'm using Keras Sequence objects to generate the training inputs, as I'm working on large datasets (would not fit in RAM) with a single known positive class and unknown negatives. Following tutorials such as the one available on the Keras Documentation and TensorFlow documentation my code looks like the following: Any ideas on how to deal with this?",https://stackoverflow.com/questions/71830863,2550541,Documentation Replicability,Documentation Replicability,Following tutorials such as the one available on the Keras Documentation and TensorFlow documentation my code looks like the following: Any ideas on how to deal with this?
50164090,Tensorflow ServingInputReceiver input shape error in client,"<p>I'm currently working with tensorflow Estimator API and have problems with the confusing serving options that are available. My confusion comes from the very undetailed tensorflow documentation.</p>

<p>This is my goal:
Use tensorflow-serving prediction_service_pb2 by sending a serialized proto message as string to the ServingInputReceiver function of my exported Estimator model. I expect the ServingInputReceiver function to receive the serialized proto string on the ""input"" tensor which then will deserialize it to the features ""ink"" (=varlength float array) and ""shape"" (=fixedlength int64).</p>

<p><strong>This is my (implementation of google quickdraw model) estimator Input function:</strong></p>

<pre><code>def _parse_tfexample_fn(example_proto, mode):
    """"""Parse a single record which is expected to be a tensorflow.Example.""""""
    feature_to_type = {
        ""ink"": tf.VarLenFeature(dtype=tf.float32),
        ""shape"": tf.FixedLenFeature([2], dtype=tf.int64)
    }
    if mode != tf.estimator.ModeKeys.PREDICT:
        # The labels won't be available at inference time, so don't add them
        # to the list of feature_columns to be read.
        feature_to_type[""class_index""] = tf.FixedLenFeature([1], dtype=tf.int64)

    parsed_features = tf.parse_single_example(example_proto, feature_to_type)
    parsed_features[""ink""] = tf.sparse_tensor_to_dense(parsed_features[""ink""])

    if mode != tf.estimator.ModeKeys.PREDICT:
        labels = parsed_features[""class_index""]
        return parsed_features, labels
    else:
        return parsed_features  # In prediction, we have no labels
</code></pre>

<p><strong>This is my Serving Input Function:</strong></p>

<pre><code>def serving_input_receiver_fn():
""""""An input receiver that expects a serialized tf.Example.""""""
feature_to_type = {""ink"": tf.VarLenFeature(dtype=tf.float32), ""shape"": tf.FixedLenFeature([2], dtype=tf.int64)}

serialized_tf_example = tf.placeholder(dtype=tf.string, shape=[None], name='input')

parsed_features = tf.parse_example(serialized_tf_example, feature_to_type)
parsed_features[""ink""] = tf.sparse_tensor_to_dense(parsed_features[""ink""])

return tf.estimator.export.ServingInputReceiver(parsed_features, serialized_tf_example)
</code></pre>

<p><strong>This is my client.py request:</strong></p>

<pre><code>features = {}
features[""ink""] = tf.train.Feature(float_list=tf.train.FloatList(value=np_ink.flatten()))
features[""shape""] = tf.train.Feature(int64_list=tf.train.Int64List(value=np_ink.shape))
f = tf.train.Features(feature=features)
data = tf.train.Example(features=f)
serialized=data.SerializeToString() # tensor to byte string
request.inputs['input'].ParseFromString(tf.contrib.util.make_tensor_proto(serialized, shape=[1], verify_shape=True))
</code></pre>

<p><strong>And this is the error I get after calling the Predict function in client.py</strong></p>

<pre><code>grpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.INVALID_ARGUMENT, details=""input tensor alias not found in signature: ink. Inputs expected to be in the set {input}."")
</code></pre>

<p><strong>I tried the following Servingfunctions:</strong>
<strong>ServingInputReceiver</strong> and <strong>build_raw_serving_input_receiver_fn</strong> give me the same grpc error. When I use <strong>build_parsing_serving_input_receiver_fn</strong> it wont even export my model. I tried to wrap my head around the documentation but it is very undetailed and I don't understand when to use which serving input function.</p>
","I'm currently working with tensorflow Estimator API and have problems with the confusing serving options that are available. My confusion comes from the very undetailed tensorflow documentation. This is my goal: Use tensorflow-serving prediction_service_pb2 by sending a serialized proto message as string to the ServingInputReceiver function of my exported Estimator model. I expect the ServingInputReceiver function to receive the serialized proto string on the ""input"" tensor which then will deserialize it to the features ""ink"" (=varlength float array) and ""shape"" (=fixedlength int64). This is my (implementation of google quickdraw model) estimator Input function: This is my Serving Input Function: This is my client.py request: And this is the error I get after calling the Predict function in client.py I tried the following Servingfunctions: ServingInputReceiver and build_raw_serving_input_receiver_fn give me the same grpc error. When I use build_parsing_serving_input_receiver_fn it wont even export my model. I tried to wrap my head around the documentation but it is very undetailed and I don't understand when to use which serving input function.",https://stackoverflow.com/questions/50164090,8804834,Documentation Completeness,Documentation Completeness,My confusion comes from the very undetailed tensorflow documentation. 
54060667,Continue training of a custom tf.Estimator with AdamOptimizer,"<p>I created a custom tf.Estimator whose weights I'm training using the tf.train.AdamOptimizer. When I continue training of an existing model, I observe a steep change in the metrics at the start of the continued training in Tensorboard. After a few steps, the metrics stabilise. The behaviour looks similar to the initial transients when training a model. The behaviour is the same if I continue training on the same Estimator instance, or if I recreate the estimator from a checkpoint. I suspect that the moving averages and/or the bias correction factor are reset when restarting the training. The model weights themselves seem to be properly restored, as the metrics do continue from where they settled before, only the effective learning rate seems to be too high.</p>

<p>Previous Stack-Overflow answers seem to suggest that these auxiliary learning parameters should be stored with the checkpoints together with the model weights. So what am I doing wrong here? How can I control restoring of these auxiliary variables? I would like to be able to continue training as if it had never been stopped. However, other people sometimes seem look for the opposite control, to completely reset the optimizer without resetting the model weights. An answer that shows how both effects can be achieved would probably most helpful.</p>

<p>Here is a sketch of my <code>model_fn</code>:</p>

<pre><code>def model_fn(features, labels, mode, params):
    inputs = features['inputs']
    logits = create_model(inputs, training=mode == tf.estimator.ModeKeys.TRAIN)

    if mode == tf.estimator.ModeKeys.PREDICT:
        ...

    if mode == tf.estimator.ModeKeys.TRAIN:
        outputs = labels['outputs']

        loss = tf.losses.softmax_cross_entropy(
            tf.one_hot(outputs,tf.shape(inputs)[-1]),
            logits,
#            reduction=tf.losses.Reduction.MEAN,
        )
        optimizer = tf.train.AdamOptimizer(learning_rate=params.learning_rate)

        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)

        with tf.control_dependencies(update_ops):
            train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())

        accuracy = tf.metrics.accuracy(
            labels = outputs,
            predictions = tf.argmax(logits, axis=-1),
        )

        tf.summary.histogram('logits',logits)
        tf.summary.scalar('accuracy', accuracy[1])
        tf.summary.scalar('loss', loss)

        return tf.estimator.EstimatorSpec(
            mode=tf.estimator.ModeKeys.TRAIN,
            loss=loss,
            train_op=train_op)

    if mode == tf.estimator.ModeKeys.EVAL:
        ...

    raise ValueError(mode)
</code></pre>

<p>The training step is called as follows:</p>

<pre><code>cfg = tf.estimator.RunConfig(
    save_checkpoints_secs = 5*60,  # Save checkpoints every 1 minutes.
    keep_checkpoint_max = 10,       # Retain the 10 most recent checkpoints.
    save_summary_steps = 10,
    log_step_count_steps = 100,
)
estimator = tf.estimator.Estimator(
    model_fn = model_fn,
    params = dict(
        learning_rate = 1e-3,
    ),
    model_dir = model_dir,
    config=cfg,
)
# train for the first time
estimator.train(
    input_fn=train_input_fn,
)
# ... at some later time, train again
estimator.train(
    input_fn=train_input_fn,
)
</code></pre>

<p>EDIT:</p>

<p>The documentation of the <code>warm_start_from</code> argument of <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator"" rel=""nofollow noreferrer""><code>tf.estimator.Estimator</code></a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/WarmStartSettings"" rel=""nofollow noreferrer""><code>tf.estimator.WarmStartSettings</code></a> are not entirely clear what exactly will happen in the default case, as I am using in the example above. However, the documentation of [<code>tf.train.warm_start</code>] (<a href=""https://www.tensorflow.org/api_docs/python/tf/train/warm_start"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/warm_start</a>) seems to suggest that in the default case, all <code>TRAINABLE_VARIABLES</code> will be warm-started, which</p>

<blockquote>
  <p>excludes variables such as accumulators and moving statistics from batch norm</p>
</blockquote>

<p>Indeed, I find Adam's accumulator variables in <code>VARIABLES</code>, but not in <code>TRAINABLE_VARIABLES</code>. These documentation pages also state how to change the list of warm-started variables, to either a list of <code>tf.Variable</code> instances, or a list of their names. However, one question remains: How do I create one of those lists in advance, given that with <code>tf.Estimator</code>, I have no graph to collect those variables/their names from?</p>

<p>EDIT2:</p>

<p>The source-code of <code>warm_start</code> highlights an undocumented feature: The list of variable names is in fact a list of regexes, to be matched against GLOBAL_VARIABLES. Thus, one may use </p>

<pre><code>    warm_start_from=tf.estimator.WarmStartSettings(
        ckpt_to_initialize_from=str(model_dir),
    #    vars_to_warm_start="".*"", # everything in TRAINABLE_VARIABLES - excluding optimiser params 
        vars_to_warm_start=["".*""], # everything in GLOBAL_VARIABLES - including optimiser params 
    ),
</code></pre>

<p>to load all variables. However, even with that, the spikes in the summary stats remain. With that, I'm completely at a loss now what is going on.</p>
","I created a custom tf.Estimator whose weights I'm training using the tf.train.AdamOptimizer. When I continue training of an existing model, I observe a steep change in the metrics at the start of the continued training in Tensorboard. After a few steps, the metrics stabilise. The behaviour looks similar to the initial transients when training a model. The behaviour is the same if I continue training on the same Estimator instance, or if I recreate the estimator from a checkpoint. I suspect that the moving averages and/or the bias correction factor are reset when restarting the training. The model weights themselves seem to be properly restored, as the metrics do continue from where they settled before, only the effective learning rate seems to be too high. Previous Stack-Overflow answers seem to suggest that these auxiliary learning parameters should be stored with the checkpoints together with the model weights. So what am I doing wrong here? How can I control restoring of these auxiliary variables? I would like to be able to continue training as if it had never been stopped. However, other people sometimes seem look for the opposite control, to completely reset the optimizer without resetting the model weights. An answer that shows how both effects can be achieved would probably most helpful. Here is a sketch of my model_fn: The training step is called as follows: EDIT: The documentation of the warm_start_from argument of tf.estimator.Estimator and tf.estimator.WarmStartSettings are not entirely clear what exactly will happen in the default case, as I am using in the example above. However, the documentation of [tf.train.warm_start] (https://www.tensorflow.org/api_docs/python/tf/train/warm_start) seems to suggest that in the default case, all TRAINABLE_VARIABLES will be warm-started, which Indeed, I find Adam's accumulator variables in VARIABLES, but not in TRAINABLE_VARIABLES. These documentation pages also state how to change the list of warm-started variables, to either a list of tf.Variable instances, or a list of their names. However, one question remains: How do I create one of those lists in advance, given that with tf.Estimator, I have no graph to collect those variables/their names from? EDIT2: The source-code of warm_start highlights an undocumented feature: The list of variable names is in fact a list of regexes, to be matched against GLOBAL_VARIABLES. Thus, one may use to load all variables. However, even with that, the spikes in the summary stats remain. With that, I'm completely at a loss now what is going on.",https://stackoverflow.com/questions/54060667,4112821,Documentation Completeness,Documentation Completeness,The source-code of warm_start highlights an undocumented feature
45959112,Get coefficients of a linear regression in Tensorflow,"<p>I've done a simple linear regression in Tensorflow. How can I know what are the coefficients of the regression? 
I've read the docs but I cannot find it anywhere! (<a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor</a>)</p>

<p><strong>EDIT</strong> Code example</p>

<pre><code>import numpy as np
import tensorflow as tf

# Declare list of features, we only have one real-valued feature
def model_fn(features, labels, mode):
  # Build a linear model and predict values
  W = tf.get_variable(""W"", [1], dtype=tf.float64)
  b = tf.get_variable(""b"", [1], dtype=tf.float64)
  y = W * features['x'] + b
  # Loss sub-graph
  loss = tf.reduce_sum(tf.square(y - labels))
  # Training sub-graph
  global_step = tf.train.get_global_step()
  optimizer = tf.train.GradientDescentOptimizer(0.01)
  train = tf.group(optimizer.minimize(loss),
                   tf.assign_add(global_step, 1))
  # EstimatorSpec connects subgraphs we built to the
  # appropriate functionality.
  return tf.estimator.EstimatorSpec(
      mode=mode,
      predictions=y,
      loss=loss,
      train_op=train)

estimator = tf.estimator.Estimator(model_fn=model_fn)
# define our data sets
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.estimator.inputs.numpy_input_fn(
    {""x"": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    {""x"": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    {""x"": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)

# train
estimator.train(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did.
train_metrics = estimator.evaluate(input_fn=train_input_fn)
eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
print(""train metrics: %r""% train_metrics)
print(""eval metrics: %r""% eval_metrics)
</code></pre>
",I've done a simple linear regression in Tensorflow. How can I know what are the coefficients of the regression? I've read the docs but I cannot find it anywhere! (https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) EDIT Code example,https://stackoverflow.com/questions/45959112,3070571,Documentation Completeness,Documentation Completeness,I've read the docs but I cannot find it anywhere
43284897,How can I multiply a vector and a matrix in tensorflow without reshaping?,"<p>This:</p>

<pre><code>import numpy as np
a = np.array([1, 2, 1])
w = np.array([[.5, .6], [.7, .8], [.7, .8]])

print(np.dot(a, w))
# [ 2.6  3. ] # plain nice old matrix multiplication n x (n, m) -&gt; m

import tensorflow as tf

a = tf.constant(a, dtype=tf.float64)
w = tf.constant(w)

with tf.Session() as sess:
    print(tf.matmul(a, w).eval())
</code></pre>

<p>results in:</p>

<pre class=""lang-none prettyprint-override""><code>C:\_\Python35\python.exe C:/Users/MrD/.PyCharm2017.1/config/scratches/scratch_31.py
[ 2.6  3. ]
# bunch of errors in windows...
Traceback (most recent call last):
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""C:\_\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/MrD/.PyCharm2017.1/config/scratches/scratch_31.py"", line 14, in &lt;module&gt;
    print(tf.matmul(a, w).eval())
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1765, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 1454, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2329, in create_op
    set_shapes_for_outputs(ret)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1717, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1667, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].

Process finished with exit code 1
</code></pre>

<p>(not sure why the same exception is raised inside its handling)</p>

<p>The solution suggested in  <a href=""https://stackoverflow.com/a/34908326/281545"">Tensorflow exception with matmul</a> is reshaping the vector to a matrix but this leads to needlessly complicated code - is there still no other way to multiply a vector with a matrix?</p>

<p>Incidentally using <code>expand_dims</code> (as suggested in the link above) with default arguments raises a <code>ValueError</code> - that's not mentioned in the <a href=""https://www.tensorflow.org/api_docs/python/tf/expand_dims"" rel=""noreferrer"">docs</a> and defeats the purpose of having a default argument.</p>
",This: results in: (not sure why the same exception is raised inside its handling) The solution suggested in Tensorflow exception with matmul is reshaping the vector to a matrix but this leads to needlessly complicated code - is there still no other way to multiply a vector with a matrix? Incidentally using expand_dims (as suggested in the link above) with default arguments raises a ValueError - that's not mentioned in the docs and defeats the purpose of having a default argument.,https://stackoverflow.com/questions/43284897,281545,Documentation Completeness,Documentation Completeness, Incidentally using expand_dims (as suggested in the link above) with default arguments raises a ValueError - that's not mentioned in the docs
40731433,Understanding tf.extract_image_patches for extracting patches from an image,"<p>I found the following method <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#extract_image_patches"" rel=""noreferrer"">tf.extract_image_patches</a> in tensorflow API, but I am not clear about its functionality. </p>

<p>Say the <code>batch_size = 1</code>, and an image is of size <code>225x225x3</code>, and we want to extract patches of size <code>32x32</code>. </p>

<p>How exactly does this function behave? Specifically, the documentation mentions the dimension of the output tensor to be <code>[batch, out_rows, out_cols, ksize_rows * ksize_cols * depth]</code> , but what <code>out_rows</code> and <code>out_cols</code> are is not mentioned.</p>

<p>Ideally, given an input image tensor of size <code>1x225x225x3</code> (where 1 is the batch size), I want to be able to get <code>Kx32x32x3</code> as output, where <code>K</code> is the total number of patches and <code>32x32x3</code> is the dimension of each patch. Is there something in tensorflow that already achieves this?</p>
","I found the following method tf.extract_image_patches in tensorflow API, but I am not clear about its functionality. Say the batch_size = 1, and an image is of size 225x225x3, and we want to extract patches of size 32x32. How exactly does this function behave? Specifically, the documentation mentions the dimension of the output tensor to be [batch, out_rows, out_cols, ksize_rows * ksize_cols * depth] , but what out_rows and out_cols are is not mentioned. Ideally, given an input image tensor of size 1x225x225x3 (where 1 is the batch size), I want to be able to get Kx32x32x3 as output, where K is the total number of patches and 32x32x3 is the dimension of each patch. Is there something in tensorflow that already achieves this?",https://stackoverflow.com/questions/40731433,1252766,Documentation Ambiguity,Documentation Completeness,"Specifically, the documentation mentions the dimension of the output tensor to be [batch, out_rows, out_cols, ksize_rows * ksize_cols * depth] , but what out_rows and out_cols are is not mentioned."
76187146,Gather elements from tensor with an inner batch dimension in tensorflow,"<p>I'll present my actual problem, and then a simpler version that is more easily reproducible.</p>
<h2>My actual problem</h2>
<p>I have a tensor that represents a batch of images from my training data. Its shape is:</p>
<pre class=""lang-py prettyprint-override""><code>[domains, batch_size, image_size, image_size, channels] = [4 x 4 x 64 x 64 x 4]
</code></pre>
<p>The 64x64x4 images are pixel art character sprites, and the <code>domains</code> dimension represent images of them in: back, left, front, and right poses. The reason that the <code>batch_size</code> dim is not the outer-most is that the images are read from a <code>tf.data.Dataset</code> that produces a 4-tuple for each sample (character in the back, left, front, and right poses). And when I do <code>next(iter(dataset))</code>, what I get is a tensor with the mentioned shape (<code>[domains, batch_size, image_size, image_size, channels]</code>).</p>
<p>At each training step, I need to randomly pick a target pose for each image in the batch, so I can ask a generator to translate them from their source into a target pose. I am using <code>tf.gather</code> for this, but it does not correctly select images the way I need. My code:</p>
<pre class=""lang-py prettyprint-override""><code>batch_size = 4
domains = 4
batch = next(iter(dataset))  # shape 4 x 4 x 64 x 64 x 4
# back, left, front, right = batch

target_indices = tf.random.uniform(shape=[batch_size], dtype=&quot;int32&quot;, maxval=domains)
target_images = tf.gather(batch, target_indices, axis=0)

print(&quot;Shape of target_images&quot;, tf.shape(target_images))
# 4 x 4 x 64 x 64 x 4
</code></pre>
<p>I need the resulting <code>target_images</code> to have a shape of <code>[4, 64, 64, 4]</code>, which would be 1 image for each character sprite in the randomly picked target pose. But as per the documentation of <code>tf.gather</code>, <em>&quot;the output shape has the same shape as the input, with the indexed-axis replaced by the shape of the indices.&quot;</em></p>
<p>One option is to use the <code>batch_dims=1</code> argument of <code>tf.gather</code>, doing:</p>
<pre><code>batch_size = 4
domains = 4
batch = next(iter(dataset))  # shape 4 x 4 x 64 x 64 x 4
# back, left, front, right = batch

target_indices = tf.random.uniform(shape=[batch_size], dtype=&quot;int32&quot;, maxval=domains)
target_images = tf.gather(batch, target_indices, axis=1, batch_dims=1)

print(&quot;Shape of target_images&quot;, tf.shape(target_images))
# 4 x 64 x 64 x 4
</code></pre>
<p>...that does yield a tensor with the correct shape, but not with the correctly gathered subtensors: in the simplified example I show next it is easier to see what is going on. The reason is that although the <code>batch_dims</code> argument exists, it seems to require the batch dimension(s) to be the outer-most one(s). Let' move on to a simpler problem.</p>
<h2>Simplification (reproducible)</h2>
<p>Suppose we have a tensor with a shape of:</p>
<pre class=""lang-py prettyprint-override""><code>[domains, batch_size, content] = [2, 3, 1]
</code></pre>
<p>I want to be able to gather one element (<code>content</code>, <code>axis=2</code>) for each element in the batch (<code>axis=1</code>) according to some random domain (<code>axis=0</code>). Let's try some code:</p>
<pre class=""lang-py prettyprint-override""><code>batch_size = 3
domains = 2
batch = tf.constant([
  [ [1],  [2],  [3]],
  [[10], [20], [30]]
])
target_indices = tf.constant([0, 1, 1])  # randomly picked indices to gather

# the batch has 3 elements and I want to get the content of domain 0 for the first element,
# and domain 1 for the second and third: [[1], [20], [30]], with shape (3, 1)
#
# attempts:
tf.gather(batch, target_indices, axis=0)
# shape=(3, 3, 1) ❌
# [[[ 1], [ 2], [ 3]],
#  [[10], [20], [30]],
#  [[10], [20], [30]]] 

tf.gather(batch, target_indices, axis=1)
# shape=(2, 3, 1) ❌
# [[[ 1], [ 2], [ 2]],
#  [[10], [20], [20]]] 

tf.gather(batch, target_indices, axis=1, batch_dims=1)
# InvalidArgumentError: params.shape[0]: 2 should be equal to indices.shape[0]: 3 [Op:GatherV2] ❌


# last attempt: permute the batch tensor so the batch dim becomes the outer-most
permuted_batch = tf.transpose(batch, [1, 0, 2])
print(&quot;Shape of permuted_batch&quot;, tf.shape(permuted_batch)) # (3, 2, 1)
tf.gather(permuted_batch, target_indices, axis=1, batch_dims=1)
# shape=(3, 1)
# [[1], [20], [30]] ✅
</code></pre>
<p>As we can see, permuting the tensor to put the batch dimension as the outer-most allows me to use <code>batch_dims=1, axis=1</code> for <code>tf.gather</code> and yields the correct result. However, I'm a bit afraid of the performance of <code>tf.transpose</code>.</p>
<p><strong>My question</strong>: is there some way I can gather the desired elements of a tensor that has a batch dimension as an inner dimension?</p>
","I'll present my actual problem, and then a simpler version that is more easily reproducible. I have a tensor that represents a batch of images from my training data. Its shape is: The 64x64x4 images are pixel art character sprites, and the domains dimension represent images of them in: back, left, front, and right poses. The reason that the batch_size dim is not the outer-most is that the images are read from a tf.data.Dataset that produces a 4-tuple for each sample (character in the back, left, front, and right poses). And when I do next(iter(dataset)), what I get is a tensor with the mentioned shape ([domains, batch_size, image_size, image_size, channels]). At each training step, I need to randomly pick a target pose for each image in the batch, so I can ask a generator to translate them from their source into a target pose. I am using tf.gather for this, but it does not correctly select images the way I need. My code: I need the resulting target_images to have a shape of [4, 64, 64, 4], which would be 1 image for each character sprite in the randomly picked target pose. But as per the documentation of tf.gather, ""the output shape has the same shape as the input, with the indexed-axis replaced by the shape of the indices."" One option is to use the batch_dims=1 argument of tf.gather, doing: ...that does yield a tensor with the correct shape, but not with the correctly gathered subtensors: in the simplified example I show next it is easier to see what is going on. The reason is that although the batch_dims argument exists, it seems to require the batch dimension(s) to be the outer-most one(s). Let' move on to a simpler problem. Suppose we have a tensor with a shape of: I want to be able to gather one element (content, axis=2) for each element in the batch (axis=1) according to some random domain (axis=0). Let's try some code: As we can see, permuting the tensor to put the batch dimension as the outer-most allows me to use batch_dims=1, axis=1 for tf.gather and yields the correct result. However, I'm a bit afraid of the performance of tf.transpose. My question: is there some way I can gather the desired elements of a tensor that has a batch dimension as an inner dimension?",https://stackoverflow.com/questions/76187146,1783793,Requesting (Additional) Resources,Requesting (Additional) Resources,is there some way I can gather the desired elements of a tensor that has a batch dimension as an inner dimension?
45074049,Tensorflow: How does tf.get_variable work?,"<p>I have read about <code>tf.get_variable</code> from this <a href=""https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow"">question</a> and also a bit from the documentation available at the tensorflow website. However, I am still not clear and was unable to find an answer online.</p>
<p>How does <code>tf.get_variable</code> work? For example:</p>
<pre><code>var1 = tf.Variable(3.,dtype=float64)
var2 = tf.get_variable(&quot;var1&quot;,[],dtype=tf.float64)
</code></pre>
<p>Does it mean that <strong>var2</strong> is <strong>another</strong> variable with initialization similar to <strong>var1</strong>? Or is <strong>var2</strong> an alias for <strong>var1</strong> (I tried and it doesn't seem to)?</p>
<p>How are <strong>var1</strong> and <strong>var2</strong> related?</p>
<p>How is a variable constructed when the variable we are <em>getting</em> doesn't really exist?</p>
","I have read about tf.get_variable from this question and also a bit from the documentation available at the tensorflow website. However, I am still not clear and was unable to find an answer online. How does tf.get_variable work? For example: Does it mean that var2 is another variable with initialization similar to var1? Or is var2 an alias for var1 (I tried and it doesn't seem to)? How are var1 and var2 related? How is a variable constructed when the variable we are getting doesn't really exist?",https://stackoverflow.com/questions/45074049,6687875,Documentation Ambiguity,Documentation Ambiguity,"I have read about tf.get_variable from this question and also a bit from the documentation available at the tensorflow website. However, I am still not clear and was unable to find an answer online."
49223976,Default Initialization for Tensorflow LSTM states and weights?,"<p>I am using the LSTM cell in Tensorflow.</p>

<pre><code>lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)
</code></pre>

<p>I was wondering how the weights and states are initialized or rather what the default initializer is for LSTM cells (states and weights) in Tensorflow?</p>

<p>And is there an easy way to manually set an Initializer?</p>

<p>Note: For <code>tf.get_variable()</code> the glorot_uniform_initializer is used as far as I could find out from the <a href=""https://www.tensorflow.org/api_docs/python/tf/get_variable"" rel=""nofollow noreferrer"">documentation</a>.</p>
",I am using the LSTM cell in Tensorflow. I was wondering how the weights and states are initialized or rather what the default initializer is for LSTM cells (states and weights) in Tensorflow? And is there an easy way to manually set an Initializer? Note: For tf.get_variable() the glorot_uniform_initializer is used as far as I could find out from the documentation.,https://stackoverflow.com/questions/49223976,5763590,Documentation Completeness,Documentation Completeness,For tf.get_variable() the glorot_uniform_initializer is used as far as I could find out from the documentation.
57438371,tf.global_variable_initializer() with regard to session?,"<p>My understandings on Sessions in Tensorflow still seem to be flawed even after reading the <a href=""https://www.tensorflow.org/guide/graphs"" rel=""nofollow noreferrer"">official documentation</a> and <a href=""https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/"" rel=""nofollow noreferrer"">this</a> tutorial. </p>

<p>In particular, does <code>tf.global_variable_initializer()</code> initialize global variables with regard to a particular session, or for all the sessions in the program? Are there ways to ""uninitialize"" a variable in / during a session?</p>

<p>Can a <code>tf.variable</code> be used in multiple sessions? The answer seems to be yes (e.g. the following code), but then are there good cases where we want multiple sessions in a program, instead of a single one?</p>

<pre><code>#!/usr/bin/env python
import tensorflow as tf

def main():
    x = tf.constant(0.)
    with tf.Session() as sess:
        print(sess.run(x))
    with tf.Session() as sess:
        print(sess.run(x))

if __name__ == '__main__':
    main()
</code></pre>
","My understandings on Sessions in Tensorflow still seem to be flawed even after reading the official documentation and this tutorial. In particular, does tf.global_variable_initializer() initialize global variables with regard to a particular session, or for all the sessions in the program? Are there ways to ""uninitialize"" a variable in / during a session? Can a tf.variable be used in multiple sessions? The answer seems to be yes (e.g. the following code), but then are there good cases where we want multiple sessions in a program, instead of a single one?",https://stackoverflow.com/questions/57438371,3736306,Documentation Ambiguity,Documentation Ambiguity,My understandings on Sessions in Tensorflow still seem to be flawed even after reading the official documentation and this tutorial.
44433438,What is the purpose of tf.global_variables_initializer?,"<p>I would like to understand what <code>tf.global_variables_initializer</code> does in a bit more detail.
A <a href=""https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer"" rel=""noreferrer"">sparse description is given here</a>:</p>

<blockquote>
  <p>Returns an Op that initializes global variables.</p>
</blockquote>

<p>But that doesn't really help me. I know that the op is necessary to initialize the graph, but what does that actually mean? Is this the step where the graph is complied? </p>
","I would like to understand what tf.global_variables_initializer does in a bit more detail. A sparse description is given here: But that doesn't really help me. I know that the op is necessary to initialize the graph, but what does that actually mean? Is this the step where the graph is complied?",https://stackoverflow.com/questions/44433438,3747801,Documentation Ambiguity,Documentation Ambiguity,A sparse description is given here: But that doesn't really help me
51907487,How to use TensorFlow with Flask,"<p>I am building a multi threaded rest api with using flask, tensorflow and keras models. After getting <a href=""https://stackoverflow.com/questions/40785224/tensorflow-cannot-interpret-feed-dict-key-as-tensor"">this</a> error, I did some research and came up with the following solution:</p>

<pre><code>executor = ThreadPoolExecutor(10)

@app.route('/createLearningTask', methods=['POST'])
def createLearningTask():
    request_data = request.get_json(force=True)
    executor.submit(LearningTask().processData)
    return ('', 200) 
</code></pre>

<p>Basically, I submit each new post request to executor. And in each request, I build model with given parameters, producing model, predict and store result for another GET request.</p>

<pre><code>class LearningTask:

    resultDict = {} # access to this map is protected by locks, which I omitted in here

    def processData(self, **kwargs):
        graph = tf.Graph() # tf = tensorflow
        with graph.as_default():
            with tf.Session().as_default():
                model = Sequential() # keras model
                model.add(..)
                model.add(..)
                model.add(..)
                model.compile(..)
                model.fit(..)
                model.predict(..)
</code></pre>

<p>I omitted irrelevant parts of the code. It works good, after processing data and getting results, I save it to dictionary. I create new graph and new session for each post request.</p>

<p>After reading <a href=""https://github.com/keras-team/keras/issues/8538"" rel=""nofollow noreferrer"">this</a> and <a href=""https://github.com/keras-team/keras/issues/2397"" rel=""nofollow noreferrer"">this</a> github discussions, I produced my solution.</p>

<p><strong><em>My question is, is that solution safe and correct usage of tensorflow? In <a href=""https://www.tensorflow.org/api_docs/python/tf/Graph"" rel=""nofollow noreferrer"">documentation</a>, it says graph is not thread safe, but I did some load test and it can handle simultaneous requests with no problem.</em></strong></p>
","I am building a multi threaded rest api with using flask, tensorflow and keras models. After getting this error, I did some research and came up with the following solution: Basically, I submit each new post request to executor. And in each request, I build model with given parameters, producing model, predict and store result for another GET request. I omitted irrelevant parts of the code. It works good, after processing data and getting results, I save it to dictionary. I create new graph and new session for each post request. After reading this and this github discussions, I produced my solution. My question is, is that solution safe and correct usage of tensorflow? In documentation, it says graph is not thread safe, but I did some load test and it can handle simultaneous requests with no problem.",https://stackoverflow.com/questions/51907487,6002951,Requesting (Additional) Resources,Requesting (Additional) Resources,"My question is, is that solution safe and correct usage of tensorflow? In documentation, it says graph is not thread safe, but I did some load test and it can handle simultaneous requests with no problem."
56899105,How to use regularizer argument in tf.get_variable?,"<p>The syntax of the usage is clear:</p>

<pre><code>decay = tf.constant(0.001, dtype=tf.float32)
w = tf.get_variable(name='weight', shape=[512, 512],
                    regularizer=tf.contrib.layers.l2_regularizer(decay))
</code></pre>

<p>However, in the documentation only the following is stated:</p>

<blockquote>
  <p><code>regularizer</code>: A (Tensor -> Tensor or None) function; the result of applying it on a newly created variable will be added to the collection <code>tf.GraphKeys.REGULARIZATION_LOSSES</code> and can be used for regularization.</p>
</blockquote>

<p>The above does not imply that the regularization loss is automatically minimized. So do we need to manually get the variable from the collection  <code>tf.GraphKeys.REGULARIZATION_LOSSES</code> and add it to our main loss in order for it to be applied?</p>
","The syntax of the usage is clear: However, in the documentation only the following is stated: The above does not imply that the regularization loss is automatically minimized. So do we need to manually get the variable from the collection tf.GraphKeys.REGULARIZATION_LOSSES and add it to our main loss in order for it to be applied?",https://stackoverflow.com/questions/56899105,4958717,Documentation Completeness,Documentation Completeness,"However, in the documentation only the following is stated: The above does not imply that the regularization loss is automatically minimized."
54887445,Tensorflow tf.hessian returns only zeros,"<p>I have a trained keras model of which I need to compute both the gradients and hessian of the output respect to the input.
The input <code>X</code> is a 5000x3 numpy array and the output <code>y</code> is 5000x1.</p>

<p>The gradient computation works fine both using keras' gradients and tensorflow's gradients functions, and I get an array 5000x3 with the correct values in it, but the hessian using tf.hessian() returns only zeros.
This should not be the case as my model is approximating a highly nonlinear function, so that second derivatives are well expected to be nonzero.</p>

<p>The code is the following (I simplified some parameters for redeability):</p>

<pre><code>def get_derivatives_NN(X, y):

    # Define Keras model
    model = keras.Sequential()
    model.add(keras.layers.Dense(500, activation=tf.nn.relu, input_shape=(X.shape[1],)))
    model.add(keras.layers.Dense(300, activation=tf.nn.relu))
    model.add(keras.layers.Dense(100, activation=tf.nn.relu))
    model.add(keras.layers.Dense(y.shape[1]))

    # Compile and fit model
    optimz = keras.optimizers.Adam(optimizer_parameters)
    model.compile(optimizer=optimz, loss='mse', metrics=['mae'])
    model.fit(X, y, epochs = 200, validation_split=0)

    # Evaluate gradients in Keras
    grads = keras.backend.gradients(model.output, model.input)[0] # tensor
    get_gradients = keras.backend.function([model.input], [grads])
    evaluated_gradients = get_gradients([X]) # this is the evaluated gradient in Keras

    # Evaluate gradienst in tf
    session = keras.backend.get_session()
    session.run(tf.global_variables_initializer())
    evaluated_gradients_TF = session.run(tf.gradients(model.output, model.input), feed_dict={model.input: X})

    # Evaluate hessian in tf
    evaluated_hessian = session.run(tf.hessians(model.output, model.input), feed_dict={model.input: X})

    return evaluated_gradients, evaluated_gradients_TF, evaluated_hessian
</code></pre>

<p>The output is (truncating my copy-paste):</p>

<pre><code>GRADIENT KERAS:
[array([[-0.00286908,  0.06114262,  0.0178928 ],
       [-0.00717778,  0.05055936,  0.0415092 ],
       [-0.00725342,  0.0075229 ,  0.06268862],
       ..., dtype=float32)]


GRADIENT TF:
[array([[-0.00286908,  0.06114262,  0.0178928 ],
       [-0.00717778,  0.05055936,  0.0415092 ],
       [-0.00725342,  0.0075229 ,  0.06268862],
       ..., dtype=float32)]

HESSIAN TF:
[array([[[[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         ...,
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]], ....... etcetera
</code></pre>

<p>There are two problems with this:</p>

<p>1) The size of the hessian doesn't really make sense to me. I expected a (5000, 3, 3) array, or a (5000,9) at most, while I get a (5000, 3, 5000, 3);</p>

<p>2) The values are all zeros, I have checked with <code>np.count_nonzero(evaluated_hessian)</code> which returns <code>0</code>.</p>

<p>I would understand if both the gradient and the hessian calculation failed, then it would be clear I have made something silly... but gradients works fine while hessians fails, and the docs seem to indicate they both obey to the same syntax call, which is what I have done here.
Any help as to why this is happening?</p>

<p>EDIT:
If I use the calculated gradient as input for another <code>get_derivative_NN</code> call I get the correct value for the second derivative out, so this proves that there is something strange going on with the <code>tf.hessians()</code> function.</p>
","I have a trained keras model of which I need to compute both the gradients and hessian of the output respect to the input. The input X is a 5000x3 numpy array and the output y is 5000x1. The gradient computation works fine both using keras' gradients and tensorflow's gradients functions, and I get an array 5000x3 with the correct values in it, but the hessian using tf.hessian() returns only zeros. This should not be the case as my model is approximating a highly nonlinear function, so that second derivatives are well expected to be nonzero. The code is the following (I simplified some parameters for redeability): The output is (truncating my copy-paste): There are two problems with this: 1) The size of the hessian doesn't really make sense to me. I expected a (5000, 3, 3) array, or a (5000,9) at most, while I get a (5000, 3, 5000, 3); 2) The values are all zeros, I have checked with np.count_nonzero(evaluated_hessian) which returns 0. I would understand if both the gradient and the hessian calculation failed, then it would be clear I have made something silly... but gradients works fine while hessians fails, and the docs seem to indicate they both obey to the same syntax call, which is what I have done here. Any help as to why this is happening? EDIT: If I use the calculated gradient as input for another get_derivative_NN call I get the correct value for the second derivative out, so this proves that there is something strange going on with the tf.hessians() function.",https://stackoverflow.com/questions/54887445,2924735,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"but gradients works fine while hessians fails, and the docs seem to indicate they both obey to the same syntax call, which is what I have done here. "
37146272,How do I get TensorFlow's 'import_graph_def' to return Tensors,"<p>If I attempt to import a saved <a href=""https://www.tensorflow.org"" rel=""noreferrer"">TensorFlow</a> graph definition with</p>

<pre><code>import tensorflow as tf
from tensorflow.python.platform import gfile

with gfile.FastGFile(FLAGS.model_save_dir.format(log_id) + '/graph.pb', 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
x, y, y_ = tf.import_graph_def(graph_def, 
                               return_elements=['data/inputs',
                                                'output/network_activation',
                                                'data/correct_outputs'],
                               name='')
</code></pre>

<p>the returned values are not <code>Tensor</code>s as expected, but something else: instead, for example, of getting <code>x</code> as </p>

<pre><code>Tensor(""data/inputs:0"", shape=(?, 784), dtype=float32)
</code></pre>

<p>I get</p>

<pre><code>name: ""data/inputs_1""
op: ""Placeholder""
attr {
  key: ""dtype""
  value {
    type: DT_FLOAT
  }
}
attr {
  key: ""shape""
  value {
    shape {
    }
  }
}
</code></pre>

<p>That is, instead of getting the expected tensor <code>x</code> I get, <code>x.op</code>. This confuses me because the <a href=""https://www.tensorflow.org/versions/r0.8/api_docs/python/framework.html#import_graph_def"" rel=""noreferrer"">documentation</a> seems to say I should get a <code>Tensor</code> (though there are a bunch of <em>or</em>s there that make it hard to understand).</p>

<p>How do I get <code>tf.import_graph_def</code> to return specific <code>Tensor</code>s that I can then use (e.g. in feeding the loaded model, or running analyses)?</p>
","If I attempt to import a saved TensorFlow graph definition with the returned values are not Tensors as expected, but something else: instead, for example, of getting x as I get That is, instead of getting the expected tensor x I get, x.op. This confuses me because the documentation seems to say I should get a Tensor (though there are a bunch of ors there that make it hard to understand). How do I get tf.import_graph_def to return specific Tensors that I can then use (e.g. in feeding the loaded model, or running analyses)?",https://stackoverflow.com/questions/37146272,656912,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"If I attempt to import a saved TensorFlow graph definition with the returned values are not Tensors as expected, but something else: instead, for example, of getting x as I get That is, instead of getting the expected tensor x I get, x.op. This confuses me because the documentation seems to say I should get a Tensor (though there are a bunch of ors there that make it hard to understand)."
49692842,Tensorflow: Importing GraphDef with Placeholder,"<p>How do I replace a placeholder in a GraphDef loaded from a file to connect the imported graph to a dataset provider? </p>

<p>This script borrows heavily from the <a href=""https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py"" rel=""nofollow noreferrer""><code>eval_image_classifier.py</code></a> script as part of the <code>slim</code> API. </p>

<p>First I open a graph</p>

<pre><code>with tf.Graph().as_default():
</code></pre>

<p>Then I set up a dataset provider and preprocessing function using the <code>slim</code> API</p>

<pre><code>  # Select the dataset
  # Create a dataset provider that loads data from the dataset
  # Select the preprocessing function
  ...
  image = image_preprocessing_fn(image, eval_image_size, eval_image_size)

  images, labels = tf.train.batch(
      [image, label],
      batch_size=batch_size,
      num_threads=num_preprocessing_threads,
      capacity=5 * batch_size)
</code></pre>

<p>Then I import a graph from a GraphDef from a file and load it into the current graph using <code>import_graph_def</code></p>

<pre><code>  quantized_graph_def = graph_pb2.GraphDef()
  with tf.gfile.FastGFile(path.join(cwd(), quantized_graph_filename), 'rb') as f:
    quantized_graph_def.ParseFromString(f.read())
  tf.import_graph_def(quantized_graph_def, input_map={'batch': images}, name='')
</code></pre>

<p>Then I set up the metrics and call <code>slim.evaluation.evaluate_once</code> to process the batches</p>

<pre><code>  # Define the metrics:
  names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
      'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),
      'Recall_5': slim.metrics.streaming_recall_at_k(
          logits, labels, 5),
  })

  ...

  slim.evaluation.evaluate_once(
      master=master,
      checkpoint_path=checkpoint_path,
      logdir=log_dir,
      num_evals=num_batches,
      eval_op=list(names_to_updates.values()))
</code></pre>

<p>When I run this I get the following error:</p>

<pre><code>Caused by op 'batch_1', defined at:
  File ""vanilla_vgg.py"", line 319, in &lt;module&gt;
    import_quantized_graph_with_imagenet()
  File ""vanilla_vgg.py"", line 251, in import_quantized_graph_with_imagenet
    tf.import_graph_def(quantized_graph_def, input_map={'batch': images}, name='')
  File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 553, in import_graph_def
    op_def=op_def)
  File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/localtmp/mp3t/venv/doggett/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'batch_1' with dtype float and shape [100,224,224,3]
         [[Node: batch_1 = Placeholder[dtype=DT_FLOAT, shape=[100,224,224,3], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
</code></pre>

<p>The GraphDef that I am loading has a Placeholder op with the name <code>batch</code>, with the same shape and dtype as the tensor <code>images</code>. For reference, running <code>print(images)</code> returns:</p>

<pre><code>Tensor(""batch:0"", shape=(100, 224, 224, 3), dtype=float32)
</code></pre>

<p>Note that I have supplied the argument <code>input_map</code> to the <code>import_graph_def</code> function that should replace the <code>batch</code> placeholder with the tensor <code>images</code>. I have also tried using <code>batch:0</code> and <code>batch_1</code> as the key to the <code>input_map</code> but neither works.</p>

<p>According to the documentation for <code>tf.import_graph_def</code>:</p>

<blockquote>
  <p><code>input_map</code>: A dictionary mapping input names (as strings) in graph_def to Tensor objects. The values of the named input tensors in the imported graph will be re-mapped to the respective Tensor values.</p>
</blockquote>

<p>As I understand it, the <code>input_map</code> argument should connect the two graphs, but that doesn't seem to be working. See related article <a href=""https://blog.konpat.me/tf-connecting-two-graphs-together/"" rel=""nofollow noreferrer"">""Connecting Two Graphs Together using <code>import_graph_def</code>""</a>. I believe that I am doing the same thing as in the article.</p>

<p>Also, <code>evaluate_once</code> is a function that runs a batch of images in a single function call, so I cannot simply call <code>images.eval()</code> and pass the result to <code>evaluate_once</code> because it would only run the first batch. So the two graphs must be connected and able to be run with a single invocation.</p>
","How do I replace a placeholder in a GraphDef loaded from a file to connect the imported graph to a dataset provider? This script borrows heavily from the eval_image_classifier.py script as part of the slim API. First I open a graph Then I set up a dataset provider and preprocessing function using the slim API Then I import a graph from a GraphDef from a file and load it into the current graph using import_graph_def Then I set up the metrics and call slim.evaluation.evaluate_once to process the batches When I run this I get the following error: The GraphDef that I am loading has a Placeholder op with the name batch, with the same shape and dtype as the tensor images. For reference, running print(images) returns: Note that I have supplied the argument input_map to the import_graph_def function that should replace the batch placeholder with the tensor images. I have also tried using batch:0 and batch_1 as the key to the input_map but neither works. According to the documentation for tf.import_graph_def: As I understand it, the input_map argument should connect the two graphs, but that doesn't seem to be working. See related article ""Connecting Two Graphs Together using import_graph_def"". I believe that I am doing the same thing as in the article. Also, evaluate_once is a function that runs a batch of images in a single function call, so I cannot simply call images.eval() and pass the result to evaluate_once because it would only run the first batch. So the two graphs must be connected and able to be run with a single invocation.",https://stackoverflow.com/questions/49692842,129814,Requesting (Additional) Resources,Documentation Replicability,"According to the documentation for tf.import_graph_def: As I understand it, the input_map argument should connect the two graphs, but that doesn't seem to be working."
41439254,What are the differences between tf.initialize_all_variables() and tf.global_variables_initializer(),"<p>On Tensorflow official website, it gives explantions of the <code>tf.initialize_all_variables()</code> and <code>tf.global_variables_initializer()</code> functions as follow  </p>

<blockquote>
  <h3>tf.initialize_all_variables():</h3>
  
  <p>Returns an op that initializes all variables.</p>
  
  <h3>tf.global_variables_initializer():</h3>
  
  <p>Adds an op to initialize all variables in the model</p>
</blockquote>

<p>It seems like both can be used to initialize all variables in graphs. Can we use these two functions exchangbly? If not, what would be the differences? </p>
","On Tensorflow official website, it gives explantions of the tf.initialize_all_variables() and tf.global_variables_initializer() functions as follow It seems like both can be used to initialize all variables in graphs. Can we use these two functions exchangbly? If not, what would be the differences?",https://stackoverflow.com/questions/41439254,6733064,Documentation Ambiguity,Documentation Ambiguity,"On Tensorflow official website, it gives explantions of the tf.initialize_all_variables() and tf.global_variables_initializer() functions as follow It seems like both can be used to initialize all variables in graphs. Can we use these two functions exchangbly?"
48077625,Why match_filenames_once function returns a local variable,"<p>I was trying to understand the mechanism of tensorflow for reading images using queues. I was using the code found <a href=""https://gist.github.com/eerwitt/518b0c9564e500b4b50f"" rel=""nofollow noreferrer"">here</a>, whom basic parts are:</p>

<pre><code>filename_queue = tf.train.string_input_producer(tf.train.match_filenames_once('D:/Dataset/*.jpg'))
image_reader = tf.WholeFileReader()
image_name, image_file = image_reader.read(filename_queue)
image = tf.image.decode_jpeg(image_file)

with tf.Session() as sess:
    tf.global_variables_initializer().run()

    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    image_tensor = sess.run([image])
    print(image_tensor)
</code></pre>

<p>which in reality does nothing special. I was getting an error:</p>

<blockquote>
  <p>OutOfRangeError (see above for traceback): FIFOQueue
  '_0_input_producer' is closed and has insufficient elements (requested
  1, current size 0)</p>
</blockquote>

<p>which lead to search for missing images, wrong folder, wrong glob pattern etc until I discovered that tensorflow basically meant this:
""You need to initialize local variables also""!</p>

<p>Besides the fact that the code seemed to work in the original <a href=""https://gist.github.com/eerwitt/518b0c9564e500b4b50f"" rel=""nofollow noreferrer"">gist</a> with just this substitution:</p>

<pre><code>tf.initialize_all_variables().run()
</code></pre>

<p>instead of</p>

<pre><code>tf.global_variables_initializer().run()
</code></pre>

<p>in my code it does not work. It produces the same error. I guess it has changed the implementation of <code>initialize_all_variables()</code> with tensorflow development (I am using 1.3.0), since in <a href=""https://stackoverflow.com/questions/40220201/tensorflow-tf-initialize-all-variables-vs-tf-initialize-local-variables"">here</a> it mentions that it initialize local variables also.</p>

<p>So, the final conclusion I came with was that I should initialize local variables also. And my code worked. The error message is awfully misleading (which did not help at all) but anyway to the main part I am a bit confused why am I getting a local variable by <code>match_filenames_once</code>. In <a href=""https://www.tensorflow.org/api_docs/python/tf/train/match_filenames_once"" rel=""nofollow noreferrer"">documentation</a> there is no reference about this (I am not sure it should though). </p>

<p>Am I always going to get local from this <code>match_filenames_once</code>? Can I control it somehow?</p>
","I was trying to understand the mechanism of tensorflow for reading images using queues. I was using the code found here, whom basic parts are: which in reality does nothing special. I was getting an error: which lead to search for missing images, wrong folder, wrong glob pattern etc until I discovered that tensorflow basically meant this: ""You need to initialize local variables also""! Besides the fact that the code seemed to work in the original gist with just this substitution: instead of in my code it does not work. It produces the same error. I guess it has changed the implementation of initialize_all_variables() with tensorflow development (I am using 1.3.0), since in here it mentions that it initialize local variables also. So, the final conclusion I came with was that I should initialize local variables also. And my code worked. The error message is awfully misleading (which did not help at all) but anyway to the main part I am a bit confused why am I getting a local variable by match_filenames_once. In documentation there is no reference about this (I am not sure it should though). Am I always going to get local from this match_filenames_once? Can I control it somehow?",https://stackoverflow.com/questions/48077625,3584765,Documentation Completeness,Documentation Completeness,In documentation there is no reference about this (I am not sure it should though).
73496717,"In neural networks, activation is applied by a function or layer?","<p>I am using the Functional API of the TensorFlow/Keras for building a CNN model. In this model, I am trying to apply a custom activation (with constraints) on the output layer.</p>
<p>After going through various resources (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/activations"" rel=""nofollow noreferrer"">1</a>, <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/activations"" rel=""nofollow noreferrer"">2</a>), I am confused about whether the activation needs to be applied by a simple python function or layer.</p>
<p>I tried implementing it by subclassing the Layer class as follows,</p>
<pre><code>class MapToBounds(layers.Layer):

    def __init__(self, lower_bound, upper_bound, **kwargs):
        super().__init__(**kwargs)
        self.lower_bound = lower_bound
        self.upper_bound = upper_bound

    def call(self, inputs, *args, **kwargs):
        return tf.add(self.lower_bound, tf.multiply(tf.sigmoid(inputs), self.upper_bound))
    
</code></pre>
<p>and called it in the model as</p>
<pre><code>x = MapToBounds(lower_bound=-3.0, upper_bound=20.0)(x)
</code></pre>
<p>where <code>x</code> is the previous layer instance.</p>
<p>My questions are:</p>
<ol>
<li>Is it the right approach?</li>
<li>In this approach, do I have to set <code>training=False</code>?</li>
<li>Is there any simple way I can implement it with a python function instead of a layer?</li>
</ol>
","I am using the Functional API of the TensorFlow/Keras for building a CNN model. In this model, I am trying to apply a custom activation (with constraints) on the output layer. After going through various resources (1, 2), I am confused about whether the activation needs to be applied by a simple python function or layer. I tried implementing it by subclassing the Layer class as follows, and called it in the model as where x is the previous layer instance. My questions are:",https://stackoverflow.com/questions/73496717,11936209,Requesting (Additional) Resources,Requesting (Additional) Resources,Is there any simple way I can implement it with a python function instead of a layer?
74818306,Issues with using Tensorflows preprocessing function for InceptionV3,"<pre class=""lang-py prettyprint-override""><code>#Here my args, they are pretty much the same for all three functions:
training_preprocessing_args = dict(
    labels='inferred',
    label_mode='int',
    class_names=classes,
    color_mode='rgb',
    image_size=hyper_parameter[&quot;image_size&quot;],
    shuffle=True,
    seed=seed,
    validation_split=None,
    subset=None,
    interpolation='bilinear',
    follow_links=False,
    crop_to_aspect_ratio=False
)



    logging.info(&quot;Training Data:&quot;)
    train_dataset:tf.data.Dataset =  tf.keras.utils.image_dataset_from_directory(directory=PATH_DATA_TRAINING, **training_preprocessing_args)

    logging.info(&quot;Testing Data:&quot;)
    test_dataset:tf.data.Dataset =  tf.keras.utils.image_dataset_from_directory(directory=PATH_DATA_TESTING, **testing_preprocessing_args)

    logging.info(&quot;Validation Data:&quot;)
    validation_dataset:tf.data.Dataset =  tf.keras.utils.image_dataset_from_directory(directory=PATH_DATA_VALIDATION, **validation_preprocessing_args)

    logging.info(&quot;Preprocessing:&quot;)
    train_dataset = tf.keras.applications.inception_v3.preprocess_input(tf.cast(train_dataset, tf.float32))
    validation_dataset = tf.keras.applications.inception_v3.preprocess_input(tf.cast(validation_dataset, tf.float32))
    test_dataset = tf.keras.applications.inception_v3.preprocess_input(tf.cast(test_dataset, tf.float32))
</code></pre>
<p>So this is my setup. At first I had it without the cast, then I would get a different error - since the documentation mentions the cast, I will discuss it like that.</p>
<p>Documentation does it as follows (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input</a>):</p>
<pre class=""lang-py prettyprint-override""><code>i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)
x = tf.cast(i, tf.float32)
x = tf.keras.applications.mobilenet.preprocess_input(x)
core = tf.keras.applications.MobileNet()
x = core(x)
model = tf.keras.Model(inputs=[i], outputs=[x])

image = tf.image.decode_png(tf.io.read_file('file.png'))
result = model(image)
</code></pre>
<p>which is kinda hard to translate into my real application.</p>
<p>I get the following Error:</p>
<pre><code>15-12-2022 23:21:15 INFO     Training Data:
Found 6988 files belonging to 10 classes.
2022-12-15 23:21:16.075523: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:tensorflow:Converted call: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761FC0&gt;
    args: (&lt;tf.Tensor 'args_0:0' shape=() dtype=string&gt;,)
    kwargs: {}

15-12-2022 23:21:16 INFO     Converted call: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761FC0&gt;
    args: (&lt;tf.Tensor 'args_0:0' shape=() dtype=string&gt;,)
    kwargs: {}

INFO:tensorflow:Allowlisted: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761FC0&gt;: DoNotConvert rule for keras
15-12-2022 23:21:16 INFO     Allowlisted: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761FC0&gt;: DoNotConvert rule for keras
15-12-2022 23:21:16 INFO     Testing Data:
Found 1699 files belonging to 10 classes.
INFO:tensorflow:Converted call: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D763490&gt;
    args: (&lt;tf.Tensor 'args_0:0' shape=() dtype=string&gt;,)
    kwargs: {}

15-12-2022 23:21:16 INFO     Converted call: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D763490&gt;
    args: (&lt;tf.Tensor 'args_0:0' shape=() dtype=string&gt;,)
    kwargs: {}

INFO:tensorflow:Allowlisted: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D763490&gt;: DoNotConvert rule for keras
15-12-2022 23:21:16 INFO     Allowlisted: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D763490&gt;: DoNotConvert rule for keras
15-12-2022 23:21:16 INFO     Validation Data:
Found 1700 files belonging to 10 classes.
INFO:tensorflow:Converted call: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761BD0&gt;
    args: (&lt;tf.Tensor 'args_0:0' shape=() dtype=string&gt;,)
    kwargs: {}

15-12-2022 23:21:16 INFO     Converted call: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761BD0&gt;
    args: (&lt;tf.Tensor 'args_0:0' shape=() dtype=string&gt;,)
    kwargs: {}

INFO:tensorflow:Allowlisted: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761BD0&gt;: DoNotConvert rule for keras
15-12-2022 23:21:16 INFO     Allowlisted: &lt;function paths_and_labels_to_dataset.&lt;locals&gt;.&lt;lambda&gt; at 0x000002063D761BD0&gt;: DoNotConvert rule for keras
15-12-2022 23:21:16 INFO     Preprocessing:
Traceback (most recent call last):
  File &quot;_CORE\main.py&quot;, line 27, in &lt;module&gt;
    main()
  File &quot;_CORE\main.py&quot;, line 17, in main
    data:tuple = run_preprocessing()
  File &quot;_CORE\preprocessing\run.py&quot;, line 10, in run_preprocessing
    data = create_datasets()
  File &quot;_CORE\preprocessing\CreateDataset.py&quot;, line 23, in create_datasets
    train_dataset = tf.keras.applications.inception_v3.preprocess_input(train_dataset)#tf.cast(train_dataset, tf.float32))
  File &quot;_ENV\_ENV_1\lib\site-packages\keras\applications\inception_v3.py&quot;, line 448, in preprocess_input
    return imagenet_utils.preprocess_input(
  File &quot;_ENV\_ENV_1\lib\site-packages\keras\applications\imagenet_utils.py&quot;, line 123, in preprocess_input
    return _preprocess_symbolic_input(x, data_format=data_format, mode=mode)
  File &quot;_ENV\_ENV_1\lib\site-packages\keras\applications\imagenet_utils.py&quot;, line 271, in _preprocess_symbolic_input
    x /= 127.5
TypeError: unsupported operand type(s) for /=: 'BatchDataset' and 'float'

</code></pre>
<p>Now this is more or less useless, except for the last line. Anyone has a clue what I have done wrong? Do I need to resize anything or something like that? As far as I understood, the preprocessing function would do that for me.</p>
","So this is my setup. At first I had it without the cast, then I would get a different error - since the documentation mentions the cast, I will discuss it like that. Documentation does it as follows (https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input): which is kinda hard to translate into my real application. I get the following Error: Now this is more or less useless, except for the last line. Anyone has a clue what I have done wrong? Do I need to resize anything or something like that? As far as I understood, the preprocessing function would do that for me.",https://stackoverflow.com/questions/74818306,19409269,Documentation Replicability,Documentation Replication on Other Examples,Documentation does it as follows (https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input): which is kinda hard to translate into my real application
70368770,How to create checkpoint filenames with epoch or batch number when using ModelCheckpoint() with save_freq as interger?,"<p>I have tensorflow 2 v. 2.5.0 installed and am using jupyter notebooks with python 3.10.</p>
<p>I'm practicing using an argument, save_freq as an integer from an online course (they use tensorflow 2.0.0 where the following code runs fine but it does work in my more recent version).</p>
<p>here's the link to relevant documentation  without an example on using integer in save_freq.
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint</a></p>
<p>here is my code:</p>
<pre><code>    import tensorflow as tf
    from tensorflow.keras.callbacks import ModelCheckpoint
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
    
    # Use the CIFAR-10 dataset
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
    x_train = x_train / 255.0
    x_test = x_test / 255.0
    
    # using a smaller subset -- speeds things up
    x_train = x_train[:10000]
    y_train = y_train[:10000]
    x_test = x_test[:1000]
    y_test = y_test[:1000]
    
    # define a function that creates a new instance of a simple CNN.
    def create_model():
        model = Sequential([
            Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), 
                   activation='relu', name='conv_1'),
            Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_2'),
            MaxPooling2D(pool_size=(4, 4), name='pool_1'),
            Flatten(name='flatten'),
            Dense(units=32, activation='relu', name='dense_1'),
            Dense(units=10, activation='softmax', name='dense_2')
        ])
        model.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])
        return model
    
    
    # Create Tensorflow checkpoint object with epoch and batch details 
    
    checkpoint_5000_path = 'model_checkpoints_5000/cp_{epoch:02d}-{batch:04d}'
    checkpoint_5000 = ModelCheckpoint(filepath = checkpoint_5000_path,
                                     save_weights_only = True,
                                     save_freq = 5000,
                                     verbose = 1)
    
    
    # Create and fit model with checkpoint
    
    model = create_model()
    model.fit(x = x_train,
              y = y_train,
              epochs = 3,
              validation_data = (x_test, y_test),
              batch_size = 10,
              callbacks = [checkpoint_5000])
</code></pre>
<p>I want to create and save the checkpoint filenames including the epoch and batch number.
However, the files are not created and it writes 'File not found'. After I create manually the directory, model_checkpoints_5000, no files are added in.</p>
<p>(we can check the directory contents by running ' ! dir -a model_checkpoints_5000' (in windows), or  'ls -lh model_checkpoints_500' (in linux)).</p>
<p>I have also tried to change to 'model_checkpoints_5000/cp_{epoch:02d}', it still does not save the files with every epoch's number.</p>
<p>Then I have tried to follow the example from Checkpoint Callback options with save_freq, which saves files with me.
<a href=""https://www.tensorflow.org/tutorials/keras/save_and_load"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/keras/save_and_load</a></p>
<p>yet, it is still not saving any of my files.</p>
<pre><code>checkpoint_path = &quot;model_checkpoints_5000/cp-{epoch:02d}.ckpt&quot;
checkpoint_dir = os.path.dirname(checkpoint_path)

batch_size = 10

checkpoint_5000 = ModelCheckpoint(filepath = checkpoint_path,
                                 save_weights_only = True,
                                 save_freq = 500*batch_size,


model = create_model()

model.fit(x = x_train,
          y = y_train,
          epochs = 3,
          validation_data = (x_test, y_test),
          batch_size = batch_size,
          callbacks = [checkpoint_5000])                                verbose = 1)
</code></pre>
<p>any suggestions how to make it work? other than downgrading my tensorflow.</p>
","I have tensorflow 2 v. 2.5.0 installed and am using jupyter notebooks with python 3.10. I'm practicing using an argument, save_freq as an integer from an online course (they use tensorflow 2.0.0 where the following code runs fine but it does work in my more recent version). here's the link to relevant documentation without an example on using integer in save_freq. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint here is my code: I want to create and save the checkpoint filenames including the epoch and batch number. However, the files are not created and it writes 'File not found'. After I create manually the directory, model_checkpoints_5000, no files are added in. (we can check the directory contents by running ' ! dir -a model_checkpoints_5000' (in windows), or 'ls -lh model_checkpoints_500' (in linux)). I have also tried to change to 'model_checkpoints_5000/cp_{epoch:02d}', it still does not save the files with every epoch's number. Then I have tried to follow the example from Checkpoint Callback options with save_freq, which saves files with me. https://www.tensorflow.org/tutorials/keras/save_and_load yet, it is still not saving any of my files. any suggestions how to make it work? other than downgrading my tensorflow.",https://stackoverflow.com/questions/70368770,11028689,Inadequate Examples,Inadequate Examples,here's the link to relevant documentation without an example on using integer in save_freq.
64747663,How to apply Attention layer to LSTM model,"<p>I am doing a speech emotion recognition machine training.</p>
<p>I wish to apply an attention layer to the model. The instruction <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention"" rel=""nofollow noreferrer"">page</a> is hard to understand.</p>
<pre><code>def bi_duo_LSTM_model(X_train, y_train, X_test,y_test,num_classes,batch_size=68,units=128, learning_rate=0.005, epochs=20, dropout=0.2, recurrent_dropout=0.2):
    
    class myCallback(tf.keras.callbacks.Callback):

        def on_epoch_end(self, epoch, logs={}):
            if (logs.get('acc') &gt; 0.95):
                print(&quot;\nReached 99% accuracy so cancelling training!&quot;)
                self.model.stop_training = True

    callbacks = myCallback()

    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Masking(mask_value=0.0, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(tf.keras.layers.Bidirectional(LSTM(units, dropout=dropout, recurrent_dropout=recurrent_dropout,return_sequences=True)))
    model.add(tf.keras.layers.Bidirectional(LSTM(units, dropout=dropout, recurrent_dropout=recurrent_dropout)))
    #     model.add(tf.keras.layers.Bidirectional(LSTM(32)))
    model.add(Dense(num_classes, activation='softmax'))

    adamopt = tf.keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8)
    RMSopt = tf.keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=1e-6)
    SGDopt = tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9, decay=0.1, nesterov=False)

    model.compile(loss='binary_crossentropy',
                  optimizer=adamopt,
                  metrics=['accuracy'])

    history = model.fit(X_train, y_train,
                        batch_size=batch_size,
                        epochs=epochs,
                        validation_data=(X_test, y_test),
                        verbose=1,
                        callbacks=[callbacks])

    score, acc = model.evaluate(X_test, y_test,
                                batch_size=batch_size)

    yhat = model.predict(X_test)

    return history, yhat

</code></pre>
<p>How can I apply it to fit for my model?</p>
<p>And are <code>use_scale</code>, <code>causal</code> and <code>dropout</code> all the arguments?</p>
<p>If there is a <code>dropout</code> in <code>attention layer</code>, how do we deal with it since we have <code>dropout</code> in LSTM layer?</p>
","I am doing a speech emotion recognition machine training. I wish to apply an attention layer to the model. The instruction page is hard to understand. How can I apply it to fit for my model? And are use_scale, causal and dropout all the arguments? If there is a dropout in attention layer, how do we deal with it since we have dropout in LSTM layer?",https://stackoverflow.com/questions/64747663,14128879,Documentation Ambiguity,Documentation Ambiguity, The instruction page is hard to understand.
64203611,tf.keras.layers.BatchNormalization with trainable=False appears to not update its internal moving mean and variance,"<p>I am trying to find out, how exactly does BatchNormalization layer behave in TensorFlow. I came up with the following piece of code which to the best of my knowledge should be a perfectly valid keras model, however the mean and variance of BatchNormalization doesn't appear to be updated.</p>
<p>From docs <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization</a></p>
<blockquote>
<p>in the case of the BatchNormalization layer, setting trainable = False on the layer means that the layer will be subsequently run in inference mode (meaning that it will use the moving mean and the moving variance to normalize the current batch, rather than using the mean and variance of the current batch).</p>
</blockquote>
<p>I expect the model to return a different value with each subsequent predict call.
What I see, however, are the exact same values returned 10 times.
Can anyone explain to me why does the BatchNormalization layer not update its internal values?</p>
<pre><code>import tensorflow as tf
import numpy as np

if __name__ == '__main__':

    np.random.seed(1)
    x = np.random.randn(3, 5) * 5 + 0.3

    bn = tf.keras.layers.BatchNormalization(trainable=False, epsilon=1e-9)
    z = input = tf.keras.layers.Input([5])
    z = bn(z)

    model = tf.keras.Model(inputs=input, outputs=z)

    for i in range(10):
        print(x)
        print(model.predict(x))
        print()
</code></pre>
<p>I use <strong>TensorFlow 2.1.0</strong></p>
","I am trying to find out, how exactly does BatchNormalization layer behave in TensorFlow. I came up with the following piece of code which to the best of my knowledge should be a perfectly valid keras model, however the mean and variance of BatchNormalization doesn't appear to be updated. From docs https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization I expect the model to return a different value with each subsequent predict call. What I see, however, are the exact same values returned 10 times. Can anyone explain to me why does the BatchNormalization layer not update its internal values? I use TensorFlow 2.1.0",https://stackoverflow.com/questions/64203611,3399825,Documentation Ambiguity,Documentation Replicability,"From docs https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization I expect the model to return a different value with each subsequent predict call. What I see, however, are the exact same values returned 10 times."
50164572,BatchNormalization in Keras,"<p>How do I update moving mean and moving variance in keras BatchNormalization?</p>

<p>I found this in tensorflow documentation, but I don't know where to put <code>train_op</code> or how to work it with keras models:</p>

<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
        with tf.control_dependencies(update_ops):
            train_op = optimizer.minimize( loss )
</code></pre>

<p>No posts I found say what to do with train_op and whether you can use it in <code>model.compile</code>.</p>
","How do I update moving mean and moving variance in keras BatchNormalization? I found this in tensorflow documentation, but I don't know where to put train_op or how to work it with keras models: No posts I found say what to do with train_op and whether you can use it in model.compile.",https://stackoverflow.com/questions/50164572,8748308,Documentation Ambiguity,Documentation Ambiguity,"I found this in tensorflow documentation, but I don't know where to put train_op or how to work it with keras models"
62801832,Rewrite tf.contrib.layers.batch_norm in Tensorflow 2.0,"<p>Could somebody help me rewrite the following block of code in Tf2.0?<br />
I'm aware batch_norm is equivalent to keras.layers.BatchNormalization but the documentation doesn't give clear solution as to what 'decay' and 'epsilon' correspond to. Thanks!</p>
<pre><code>def batch_norm(opts, _input, is_train, reuse, scope, scale=True):
    &quot;&quot;&quot;Batch normalization based on tf.contrib.layers.

    &quot;&quot;&quot;
    return tf.contrib.layers.batch_norm(
        _input, center=True, scale=scale,
        epsilon=opts['batch_norm_eps'], decay=opts['batch_norm_decay'],
        is_training=is_train, reuse=True, updates_collections=None,
        scope=scope, fused=False)
</code></pre>
",Could somebody help me rewrite the following block of code in Tf2.0? I'm aware batch_norm is equivalent to keras.layers.BatchNormalization but the documentation doesn't give clear solution as to what 'decay' and 'epsilon' correspond to. Thanks!,https://stackoverflow.com/questions/62801832,13636839,Documentation Completeness,Documentation Completeness, I'm aware batch_norm is equivalent to keras.layers.BatchNormalization but the documentation doesn't give clear solution as to what 'decay' and 'epsilon' correspond to.
73796471,using tf.keras.layers.Embedding for categorical variables in regression problem,"<p>Using the iris dataset as a hypothetical hello world example:</p>
<pre><code>import pandas as pd
from sklearn import datasets

iris = datasets.load_iris()
df = pd.DataFrame(iris['data'], columns = iris['feature_names'])
df['iris_class'] = pd.Series(iris['target'], name = 'target_values')
df['iris_class_name'] = df['iris_class'].replace([0,1,2], ['iris-' + species for species in iris['target_names'].tolist()])
df.columns = df.columns.str.replace(&quot;[() ]&quot;, &quot;&quot;)

print(df.head())
</code></pre>
<p>Let us say I want to use tf.keras.layers.Embedding instead of one-hot/dummy encoding as part of ANN for regression. e.g.:</p>
<p><strong>iris_class_name + sepalwidthcm + petallengthcm -&gt; sepallengthcm</strong></p>
<p>where sepallengthcm is the dependent variable. I came across <a href=""https://discuss.tensorflow.org/t/how-to-embed-categorical-features-which-are-strings-in-tensorflow/9381"" rel=""nofollow noreferrer"">this</a>:</p>
<pre><code>city_lookup = tf.keras.layers.StringLookup(vocabulary = city_vocabulary, mask_token = None);
city_embedding= tf.keras.Sequential([
    city_lookup,
    tf.keras.layers.Embedding(len(city_vocabulary) + 1, embedding_dimension)
  ], &quot;city_embedding&quot;)
  
city = features[&quot;city&quot;]
city_embedding_output = city_embedding(city)
</code></pre>
<p>but am not sure how to exactly use it in my use case. Any pointers very much welcome. Thanks!</p>
",Using the iris dataset as a hypothetical hello world example: Let us say I want to use tf.keras.layers.Embedding instead of one-hot/dummy encoding as part of ANN for regression. e.g.: iris_class_name + sepalwidthcm + petallengthcm -&gt; sepallengthcm where sepallengthcm is the dependent variable. I came across this: but am not sure how to exactly use it in my use case. Any pointers very much welcome. Thanks!,https://stackoverflow.com/questions/73796471,283538,Requesting (Additional) Resources,Requesting (Additional) Resources,I came across this: but am not sure how to exactly use it in my use case. Any pointers very much welcome.
71919267,Trying to achieve same result with Pytorch and Tensorflow MultiheadAttention,"<p>I'm trying to recreate a transformer written in Pytorch and implement it in Tensorflow. The problem is that despite both the documentation for the <a href=""https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html"" rel=""nofollow noreferrer"">Pytorch</a> version and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention"" rel=""nofollow noreferrer"">Tensorflow</a> version, they still come out pretty differently.
I wrote a little code snippet to show the issue:</p>
<pre><code>import torch
import tensorflow as tf
import numpy as np

class TransformerLayer(tf.Module):
    def __init__(self, d_model, nhead, dropout=0):
        super(TransformerLayer, self).__init__()
        self.self_attn = torch.nn.MultiheadAttention(d_model, nhead, dropout=dropout)

batch_size = 2
seq_length = 5
d_model = 10

src = np.random.uniform(size=(batch_size, seq_length, d_model))
srcTF = tf.convert_to_tensor(src)
srcPT = torch.Tensor(src.reshape((seq_length, batch_size, d_model)))

self_attnTF = tf.keras.layers.MultiHeadAttention(key_dim=10, num_heads=5, dropout=0)
transformer_encoder = TransformerLayer(d_model=10, nhead=5, dropout=0.0)

output, scores = self_attnTF(srcTF, srcTF, srcTF, return_attention_scores=True)
print(&quot;Tensorflow Attendtion outputs:&quot;, output)
print(&quot;Tensorflow (averaged) weights:&quot;, tf.math.reduce_mean(scores, 1))
print(&quot;Torch Attendtion outputs:&quot;, transformer_encoder.self_attn(srcPT,srcPT,srcPT)[0])
print(&quot;Torch attention output weights:&quot;, transformer_encoder.self_attn(srcPT,srcPT,srcPT)[1])
</code></pre>
<p>and the result is:</p>
<pre><code>Tensorflow Attendtion outputs: tf.Tensor(
[[[ 0.02602757 -0.14134401  0.00855263  0.4735083  -0.01851891
   -0.20382246 -0.18152176 -0.21076852  0.08623976 -0.33548725]
  [ 0.02607442 -0.1403394   0.00814065  0.47415024 -0.01882939
   -0.20353754 -0.18291879 -0.21234266  0.08595885 -0.33613583]
  [ 0.02524654 -0.14096384  0.00870436  0.47411725 -0.01800703
   -0.20486829 -0.18163288 -0.21082559  0.08571021 -0.3362339 ]
  [ 0.02518575 -0.14039244  0.0090138   0.47431853 -0.01775141
   -0.20391947 -0.18138805 -0.2118245   0.08432849 -0.33521986]
  [ 0.02556361 -0.14039293  0.00876258  0.4746476  -0.01891363
   -0.20398234 -0.18229616 -0.21147579  0.08555281 -0.33639923]]

 [[ 0.07844199 -0.1614371   0.01649148  0.5287745   0.05126739
   -0.13851154 -0.09829871 -0.1621251   0.01922669 -0.2428589 ]
  [ 0.07844222 -0.16024739  0.01805423  0.52941847  0.04975721
   -0.13537636 -0.09829231 -0.16129729  0.01979005 -0.24491176]
  [ 0.07800542 -0.160701    0.01677295  0.52902794  0.05082911
   -0.13843337 -0.09805533 -0.16165744  0.01928401 -0.24327613]
  [ 0.07815789 -0.1600025   0.01757433  0.5291927   0.05032986
   -0.1368022  -0.09849522 -0.16172451  0.01929555 -0.24438493]
  [ 0.0781548  -0.16028519  0.01764914  0.52846324  0.04941286
   -0.13746066 -0.09787872 -0.16141161  0.01994199 -0.2440269 ]]], shape=(2, 5, 10), dtype=float32)
Tensorflow (averaged) weights: tf.Tensor(
[[[0.199085   0.20275716 0.20086522 0.19873264 0.19856   ]
  [0.2015336  0.19960018 0.20218948 0.19891861 0.19775811]
  [0.19906266 0.20318432 0.20190334 0.19812575 0.19772394]
  [0.20074987 0.20104568 0.20269363 0.19744729 0.19806348]
  [0.19953248 0.20176074 0.20314851 0.19782843 0.19772986]]

 [[0.2010009  0.20053487 0.20004745 0.20092985 0.19748697]
  [0.20034568 0.20035927 0.19955876 0.20062163 0.19911464]
  [0.19967113 0.2006859  0.20012529 0.20047483 0.19904283]
  [0.20132652 0.19996871 0.20019794 0.20008174 0.19842513]
  [0.2006393  0.20000939 0.19938737 0.20054278 0.19942114]]], shape=(2, 5, 5), dtype=float32)
Torch Attendtion outputs: tensor([[[ 0.1097, -0.4467, -0.0719, -0.1779, -0.0766, -0.1247,  0.1557,
           0.0051, -0.3932, -0.1323],
         [ 0.1264, -0.3822,  0.0759, -0.0335, -0.1084, -0.1539,  0.1475,
          -0.0272, -0.4235, -0.1744]],

        [[ 0.1122, -0.4502, -0.0747, -0.1796, -0.0756, -0.1271,  0.1581,
           0.0049, -0.3964, -0.1340],
         [ 0.1274, -0.3823,  0.0754, -0.0356, -0.1091, -0.1547,  0.1477,
          -0.0272, -0.4252, -0.1752]],

        [[ 0.1089, -0.4427, -0.0728, -0.1746, -0.0756, -0.1202,  0.1501,
           0.0031, -0.3894, -0.1242],
         [ 0.1263, -0.3820,  0.0718, -0.0374, -0.1063, -0.1562,  0.1485,
          -0.0271, -0.4233, -0.1761]],

        [[ 0.1061, -0.4369, -0.0685, -0.1696, -0.0772, -0.1173,  0.1454,
           0.0012, -0.3860, -0.1201],
         [ 0.1265, -0.3820,  0.0762, -0.0325, -0.1082, -0.1560,  0.1501,
          -0.0271, -0.4249, -0.1779]],

        [[ 0.1043, -0.4402, -0.0705, -0.1719, -0.0791, -0.1205,  0.1508,
           0.0018, -0.3895, -0.1262],
         [ 0.1260, -0.3805,  0.0775, -0.0298, -0.1083, -0.1547,  0.1494,
          -0.0276, -0.4242, -0.1768]]], grad_fn=&lt;AddBackward0&gt;)
Torch attention output weights: tensor([[[0.2082, 0.2054, 0.1877, 0.1956, 0.2031],
         [0.2100, 0.2079, 0.1841, 0.1943, 0.2037],
         [0.2007, 0.1995, 0.1929, 0.1999, 0.2070],
         [0.1995, 0.1950, 0.1976, 0.2002, 0.2077],
         [0.1989, 0.1969, 0.1970, 0.2024, 0.2048]],

        [[0.2095, 0.1902, 0.1987, 0.2027, 0.1989],
         [0.2090, 0.1956, 0.1997, 0.2004, 0.1952],
         [0.2047, 0.1869, 0.2006, 0.2121, 0.1957],
         [0.2073, 0.1953, 0.1982, 0.2014, 0.1978],
         [0.2089, 0.2003, 0.1953, 0.1957, 0.1998]]], grad_fn=&lt;DivBackward0&gt;)
</code></pre>
<p>The output weights look similar but the base attention outputs are way off. Is there any way to make the Tensorflow model come out more like the Pytorch one? Any help would be greatly appreciated!</p>
","I'm trying to recreate a transformer written in Pytorch and implement it in Tensorflow. The problem is that despite both the documentation for the Pytorch version and Tensorflow version, they still come out pretty differently. I wrote a little code snippet to show the issue: and the result is: The output weights look similar but the base attention outputs are way off. Is there any way to make the Tensorflow model come out more like the Pytorch one? Any help would be greatly appreciated!",https://stackoverflow.com/questions/71919267,9404761,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"The problem is that despite both the documentation for the Pytorch version and Tensorflow version, they still come out pretty differently."
66878893,Tensorflow TextVectorization layer: How to define a custom standardize function?,"<p>I try to create a custom standardize function for the <a href=""https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization"" rel=""nofollow noreferrer"">TextVectorization layer in Tensorflow 2.1</a> but I seem to get something fundamentally wrong.</p>
<p>I have the following text data:</p>
<pre><code>import numpy as np

my_array = np.array([
    &quot;I am a sentence.&quot;,
    &quot;I am another sentence!&quot;
])
</code></pre>
<h2>My Goal</h2>
<p>I basically want to lower the text, remove punctuation and remove some words.
The default standardize-Function of the TextVectorization layer (<code>LOWER_AND_STRIP_PUNCTUATION</code>) lowers and removes punctuation, but afaik there is not way to remove whole words.</p>
<p>(<strong>If you know a way to do so, an alternative approach to mine as described below is of course also very much appreciated</strong>)</p>
<hr />
<h2>An example that is working</h2>
<p>First, find an example of a <strong>working</strong> custom standardiazion function <a href=""https://www.tensorflow.org/tutorials/text/word_embeddings"" rel=""nofollow noreferrer"">from the tensorflow documentation</a></p>
<pre><code>def custom_standardization(input_data):
  lowercase = tf.strings.lower(input_data)
  stripped_html = tf.strings.regex_replace(lowercase, '&lt;br /&gt;', ' ')
  return tf.strings.regex_replace(stripped_html,
                                  '[%s]' % re.escape(string.punctuation), '')
</code></pre>
<p>when I pass it to the <code>TextVectorization</code> and adapt in on <code>my_array</code>, it works just fine</p>
<pre><code>vectorize_layer_1 = TextVectorization(
    output_mode='int',
    standardize=custom_standardization,
    )

vectorize_layer_1.adapt(my_array)  # no error
</code></pre>
<hr />
<h2>The custom function that is not working</h2>
<p>However, my custom standardization keeps raising an error. Here is my code:</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.preprocessing.text import text_to_word_sequence

my_array = np.array([
    &quot;I am a sentence&quot;,
    &quot;I am another sentence&quot;
])

# these words should be removed
bad_words = [&quot;i&quot;, &quot;am&quot;]

def remove_words(tokens):
    return [word for word in tokens if word not in bad_words]

# this is the normalization function I want to apply
def my_custom_normalize(my_array):
    tokenized = [text_to_word_sequence(str(sentence)) for sentence in my_array]
    clean_texts = [&quot; &quot;.join(remove_words(tokenized_string))
                     for tokenized_string
                     in tokenized]
    clean_tensor = tf.convert_to_tensor(clean_texts)
    return clean_tensor
    
my_vectorize_layer = TextVectorization(
    output_mode='int',
    standardize=my_custom_normalize,
    )
</code></pre>
<p>However, once I try adapting, I keep running in an error:</p>
<pre><code>my_vectorize_layer.adapt(my_array)  # raises error
</code></pre>
<pre><code>InvalidArgumentError: Tried to squeeze dim index 1 for tensor with 1 dimensions. [Op:Squeeze]
</code></pre>
<p>And I really do not understand why. In the <a href=""https://keras.io/api/layers/preprocessing_layers/core_preprocessing_layers/text_vectorization/"" rel=""nofollow noreferrer"">documentation</a> it says:</p>
<blockquote>
<p>When using a custom callable for standardize, the data received by the callable will be exactly as passed to this layer. The callable should return a tensor of the same shape as the input</p>
</blockquote>
<p>I thought maybe thats what is causing the error.
but when I look at the shapes, everything seems correct:</p>
<pre><code>my_result = my_custom_normalize(my_array)
my_result.shape  # returns TensorShape([2])
working_result = custom_standardization(my_array)
working_result.shape # returns TensorShape([2])
</code></pre>
<p>I am really lost here. What am I doing wrong? am I not supposed to use list comprehensions?</p>
","I try to create a custom standardize function for the TextVectorization layer in Tensorflow 2.1 but I seem to get something fundamentally wrong. I have the following text data: I basically want to lower the text, remove punctuation and remove some words. The default standardize-Function of the TextVectorization layer (LOWER_AND_STRIP_PUNCTUATION) lowers and removes punctuation, but afaik there is not way to remove whole words. (If you know a way to do so, an alternative approach to mine as described below is of course also very much appreciated) First, find an example of a working custom standardiazion function from the tensorflow documentation when I pass it to the TextVectorization and adapt in on my_array, it works just fine However, my custom standardization keeps raising an error. Here is my code: However, once I try adapting, I keep running in an error: And I really do not understand why. In the documentation it says: I thought maybe thats what is causing the error. but when I look at the shapes, everything seems correct: I am really lost here. What am I doing wrong? am I not supposed to use list comprehensions?",https://stackoverflow.com/questions/66878893,10465165,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"First, find an example of a working custom standardiazion function from the tensorflow documentation when I pass it to the TextVectorization and adapt in on my_array, it works just fine However, my custom standardization keeps raising an error."
67600983,How can I prevent TextVectorization in Tensorflow creating values for Unknown and blank strings?,"<p>I am looking to one hot encode string tensor as part of my dataset pipeline. It seems to me this can be achieved using <code>TextVectorization</code> to get an integer representation of the string tensor and then <code>one_hot</code> to convert to achieve the encoded 2d tensor.</p>
<p>When i use TextVectorization it seems to automatically try to map &quot;&quot; to 0 and strings out of vocabulary strings to 1. See below using Tensorflow 2.3:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras import layers

possible_values = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;]
text_vectorization = layers.experimental.preprocessing.TextVectorization(output_sequence_length=1)
text_vectorization.set_vocabulary(possible_values)

print(text_vectorization.get_vocabulary())

['', '[UNK]', 'a', 'b', 'c']
</code></pre>
<p>I can see why it would be useful as it would handle the last 2 values in the below tensor without throwing an error and creating a feature for them in the process.</p>
<pre><code>test_tensor = tf.constant([&quot;b&quot;,&quot;b&quot;,&quot;c&quot;,&quot;b&quot;,&quot;a&quot;,&quot;potato&quot;,&quot;&quot;])

print(text_vectorization.call(test_tensor))

tf.Tensor(
[[3]
 [3]
 [4]
 [3]
 [2]
 [1]
 [0]], shape=(7, 1), dtype=int64)
</code></pre>
<p>In my application though I want to switch this behaviour off as I don't need it. <a href=""https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization"" rel=""nofollow noreferrer"">The documentation</a> doesn't seem to provide an option to disable it and for now I am just going to -2 from the output but that doesn't feel right.</p>
<p>Are there any cleaner, tensorflow native, solutions for generating integer representations of string tensors?</p>
","I am looking to one hot encode string tensor as part of my dataset pipeline. It seems to me this can be achieved using TextVectorization to get an integer representation of the string tensor and then one_hot to convert to achieve the encoded 2d tensor. When i use TextVectorization it seems to automatically try to map """" to 0 and strings out of vocabulary strings to 1. See below using Tensorflow 2.3: I can see why it would be useful as it would handle the last 2 values in the below tensor without throwing an error and creating a feature for them in the process. In my application though I want to switch this behaviour off as I don't need it. The documentation doesn't seem to provide an option to disable it and for now I am just going to -2 from the output but that doesn't feel right. Are there any cleaner, tensorflow native, solutions for generating integer representations of string tensors?",https://stackoverflow.com/questions/67600983,5799799,Documentation Completeness,Documentation Completeness,The documentation doesn't seem to provide an option to disable it
68089330,TimeDistributed(Dense) vs Dense And TimeDistributed(Conv2D),"<p>I am trying to understand the how <code>TimeDitributed()</code> Layer works in keras!! I know that when we wrap <code>Conv2D</code> layer in <code>TimeDitributed()</code> it applies same Conv2D layer to all the time events of a video(or to different frames that are present in a video sequence). As mentioned here <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed</a>.</p>
<p>For the purpose of my project I am trying to build an LSTM model which is of the as follows:</p>
<pre><code>class Lstm_model_1(tf.keras.Model):

    def __init__(self, num_classes):
        super(Lstm_model_1, self).__init__()   
        self.Lstm1 = tf.keras.layers.LSTM(32,return_sequences=True)
        self.Lstm2 = tf.keras.layers.LSTM(32,return_sequences=True) 
        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')
        self.TimeDistributed=tf.keras.layers.TimeDistributed(self.classifier)

    def call(self, inputs):
        input_A=inputs
        x = self.Lstm1(input_A)
        x = self.Lstm2(x)
        output = self.TimeDistributed(x)
        
        return  output
lstm_1 = Lstm_model_1(3)
lstm_1.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy())
lstm_1.fit(X_train,Y_train, epochs=3,validation_data=(X_test,Y_test))
lstm_1.summary()
Model: &quot;lstm_model_1_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_9 (LSTM)                multiple                  55552     
_________________________________________________________________
lstm_10 (LSTM)               multiple                  8320      
_________________________________________________________________
dense_6 (Dense)              multiple                  99        
_________________________________________________________________
time_distributed (TimeDistri multiple                  99        
=================================================================
Total params: 63,971
Trainable params: 63,971
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>Here I am getting 99 parameters in the <code>TimeDistributed()</code> layer.</p>
<p>Now when I am not using <code>TimeDistributed()</code> Layer I am getting same number of parameters i.e 99.</p>
<p>I have read in the following posts that :-</p>
<blockquote>
<p>If return_sequences=True, then the Dense layer is used to apply at every timestep just like TimeDistributedDense.</p>
</blockquote>
<p>and</p>
<hr />
<blockquote>
<p>As a side note: this makes TimeDistributed(Dense(...)) and Dense(...) equivalent to each other.</p>
</blockquote>
<hr />
<blockquote>
<p>Another side note: be aware that this has the effect of shared weights.&quot;&quot;</p>
</blockquote>
<hr />
<ol>
<li><a href=""https://stackoverflow.com/questions/58560304/timedistributeddense-vs-dense-in-seq2seq"">TimeDistributed(Dense) vs Dense in seq2seq</a></li>
<li><a href=""https://stackoverflow.com/questions/52089601/keras-dense-layers-input-is-not-flattened/52092176#52092176"">Keras Dense layer&#39;s input is not flattened</a></li>
</ol>
<p>Now According to me it makes sense that the dense layer when applied on the LSTM <code>return_sequences=True</code> should have the same weights for the all the timestamps. But I have few questions that are mentioned below.</p>
<ol>
<li>Is the <code>TimeDitributed()</code> wrapped with <code>Dense()</code> is redundant and can we use <code>Dense()</code> directly?</li>
<li>If let's say I don't want to use shared weights corresponding to the sequence outputs then what should I do? I want my network to learn different set of weights corresponding to each of the output in case of <code>return_sequences=True</code></li>
<li>Why are we still wrapping our <code>Dense()</code> layer in the <code>TimeDitributed()</code> layer if both of them are sharing weights in the time squences? I have seen the usage of <code>TimeDitributed()</code> layer with <code>RepeatedVector()</code> layer here <a href=""https://datascience.stackexchange.com/questions/46491/what-is-the-job-of-repeatvector-and-timedistributed"">https://datascience.stackexchange.com/questions/46491/what-is-the-job-of-repeatvector-and-timedistributed</a></li>
<li>Is it only with the case of <code>Dense()</code> that <code>TimeDitribued()</code>  is redundant or is it also the same with <code>Conv2D</code> Layer?</li>
</ol>
",I am trying to understand the how TimeDitributed() Layer works in keras!! I know that when we wrap Conv2D layer in TimeDitributed() it applies same Conv2D layer to all the time events of a video(or to different frames that are present in a video sequence). As mentioned here https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed. For the purpose of my project I am trying to build an LSTM model which is of the as follows: Here I am getting 99 parameters in the TimeDistributed() layer. Now when I am not using TimeDistributed() Layer I am getting same number of parameters i.e 99. I have read in the following posts that :- and Now According to me it makes sense that the dense layer when applied on the LSTM return_sequences=True should have the same weights for the all the timestamps. But I have few questions that are mentioned below.,https://stackoverflow.com/questions/68089330,16156882,Documentation Replication on Other Examples,Documentation Replication on Other Examples, For the purpose of my project I am trying to build an LSTM model which is of the as follows: 
57244733,Where does the documentation point to a list of values for the loss property of the compile function?,"<p>I'm following the <a href=""https://www.tensorflow.org/tutorials/keras/basic_classification"" rel=""nofollow noreferrer"">Tensorflow documentation for creating a simple neural network</a>.  One of the steps is</p>

<pre><code>model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])  
</code></pre>

<p>When I look at the documentation for the <code>loss</code> parameter, it says </p>

<blockquote>
  <p><strong>loss</strong>: String (name of objective function), objective function or
  tf.losses.Loss  instance. See tf.losses. If the model has multiple
  outputs, you can use a  different loss on each output by passing a
  dictionary or a list of losses. The  loss value that will be minimized
  by the model will then be the sum of all  individual losses.</p>
</blockquote>

<p>Based on this documentation of the <code>compile</code> function, how would I find a list of the strings and/or objective functions that I can pass for the <code>loss</code> parameter?  I found the <code>tr.keras.losses</code> that has the objective functions by Googling, but it seems like there should be a link or mention of that in the documentation for <code>Sequential.compile</code>.  Am I missing something?</p>
","I'm following the Tensorflow documentation for creating a simple neural network. One of the steps is When I look at the documentation for the loss parameter, it says Based on this documentation of the compile function, how would I find a list of the strings and/or objective functions that I can pass for the loss parameter? I found the tr.keras.losses that has the objective functions by Googling, but it seems like there should be a link or mention of that in the documentation for Sequential.compile. Am I missing something?",https://stackoverflow.com/questions/57244733,4820436,Documentation Replicability,Documentation Replicability,"I'm following the Tensorflow documentation for creating a simple neural network. One of the steps is When I look at the documentation for the loss parameter, it says Based on this documentation of the compile function, how would I find a list of the strings and/or objective functions that I can pass for the loss parameter?"
71909901,Guiding tensorflow keras model training to achieve best Recall At Precision 0.95 for binary classification,"<p>I am hoping to get some help on the titular topic.
I have a database of medical data of patients with two similar pathologies, one severe and one much less so. I need flag most of the formers (≥95%) and leave out as many of the latter as possible.</p>
<p>Therefore, I want to create a binary classifier that reflects this. Looking around on the web (not an expert) I put together this piece of code, substituting the metric I found with RecallAtPrecision(0.95) in the middle part of the code. Below is an abridged version:</p>
<pre><code>import tensorflow as tf

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(10, input_dim=x_train.shape[1], activation='relu', kernel_initializer='he_normal'))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.RecallAtPrecision(0.95)])

history = model.fit(x_train, y_train, validation_split=0.33, batch_size=16, epochs=EPOCHS)
</code></pre>
<p>However, it simply doesn't work, as it throws the following error:</p>
<blockquote>
<p>AttributeError: module 'tensorflow_core.keras.metrics' has no attribute 'RecallAtPrecision'</p>
</blockquote>
<p>I am at a loss about why that happened, as I can clearly see it in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RecallAtPrecision"" rel=""nofollow noreferrer"">documentation</a>. The code works if I use Recall(), Precision() or most any other metrics. Looking around some more, I am beginning to think I am missing something fundamental.
Do any of you fine ladies and gentlemen have any pointers on how to solve this problem?</p>
","I am hoping to get some help on the titular topic. I have a database of medical data of patients with two similar pathologies, one severe and one much less so. I need flag most of the formers (≥95%) and leave out as many of the latter as possible. Therefore, I want to create a binary classifier that reflects this. Looking around on the web (not an expert) I put together this piece of code, substituting the metric I found with RecallAtPrecision(0.95) in the middle part of the code. Below is an abridged version: However, it simply doesn't work, as it throws the following error: I am at a loss about why that happened, as I can clearly see it in the documentation. The code works if I use Recall(), Precision() or most any other metrics. Looking around some more, I am beginning to think I am missing something fundamental. Do any of you fine ladies and gentlemen have any pointers on how to solve this problem?",https://stackoverflow.com/questions/71909901,18846088,Documentation Replication on Other Examples,Documentation Replication on Other Examples," I am at a loss about why that happened, as I can clearly see it in the documentation. The code works if I use Recall(), Precision() or most any other metrics. "
68123049,Tensorflow Autoencoder ValueError: No gradients provided for any variable,"<p>I'm trying to create a autoencoder using tensorflow that analyses a dataset of cars for a university project. However the code outputs a error when starting to train that I can't seem to find the solution for.</p>
<p>First I tried reading the tensorflow documentation for the <code>fit</code> function but there was no reference to this error.
Next I tried to search for similar errors on StackOverflow but I couldn't find anything that was related.</p>
<pre class=""lang-py prettyprint-override""><code>import os
import pathlib

import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.layers import (Activation, BatchNormalization, Conv2D,
                                     Conv2DTranspose, Dense, Flatten, Input,
                                     LeakyReLU, Reshape)
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Configuration
HEIGHT = 28
WIDTH = 32
NUM_CHANNELS = 3
BATCH_SIZE = 32
LATENT_SPACE_DIM = 20
EPOCHS = 25

AUTOTUNE = tf.data.experimental.AUTOTUNE

# Download dataset
dataset_url = &quot;http://ai.stanford.edu/~jkrause/car196/car_ims.tgz&quot;
data_dir = tf.keras.utils.get_file(origin=dataset_url,
                                   fname='car_ims',
                                   untar=True)
data_dir = pathlib.Path(data_dir)

normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)

# Load dataset
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    labels=None,
    image_size=(WIDTH, HEIGHT),
    seed=123,
    validation_split=0.3,
    subset=&quot;training&quot;,
    smart_resize=True,
    batch_size=BATCH_SIZE)

dataset = dataset.map(normalization_layer)
dataset = dataset.cache()
dataset = dataset.prefetch(buffer_size=AUTOTUNE)

# Load testset
testset = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    labels=None,
    image_size=(WIDTH, HEIGHT),
    seed=123,
    validation_split=0.3,
    subset=&quot;validation&quot;,
    smart_resize=True,
    batch_size=BATCH_SIZE)

testset = testset.map(normalization_layer)
testset = testset.cache()
testset = testset.prefetch(buffer_size=AUTOTUNE)

# Encoder
inputs = Input(shape =(WIDTH, HEIGHT, NUM_CHANNELS))

x = Conv2D(32, (3, 3), strides=2, padding=&quot;same&quot;)(inputs)
x = LeakyReLU(alpha=0.2)(x)
x = BatchNormalization()(x)

x = Conv2D(64, (3, 3), strides=2, padding=&quot;same&quot;)(x)
x = LeakyReLU(alpha=0.2)(x)
x = BatchNormalization()(x)

volumeSize = K.int_shape(x)
x = Flatten()(x)

# Latent space
latent = Dense(LATENT_SPACE_DIM, name=&quot;latent&quot;)(x)

#decoder
latentInputs = Input(shape=(LATENT_SPACE_DIM,))
y = Dense(np.prod(volumeSize[1:]))(latentInputs)
y = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(y)

y = Conv2DTranspose(64, (3, 3), strides=2, padding=&quot;same&quot;)(y)
y = LeakyReLU(alpha=0.2)(y)
y = BatchNormalization()(y)

y = Conv2DTranspose(32, (3, 3), strides=2, padding=&quot;same&quot;)(y)
y = LeakyReLU(alpha=0.2)(y)
y = BatchNormalization()(y)

y = Conv2DTranspose(NUM_CHANNELS, (3, 3), padding=&quot;same&quot;)(y)
outputs = Activation(&quot;sigmoid&quot;, name=&quot;decoded&quot;)(y)

encoder = Model(inputs, latent, name=&quot;encoder&quot;)
decoder = Model(latentInputs, outputs, name=&quot;decoder&quot;)
autoencoder = Model(inputs=inputs, outputs=decoder(encoder(inputs)))

encoder.summary()
decoder.summary()
autoencoder.summary()

# Prepare model
autoencoder.compile(loss=&quot;mse&quot;, optimizer=Adam(learning_rate=1e-3))

# train the convolutional autoencoder
history = autoencoder.fit(
    dataset,
    validation_data=testset,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE)
</code></pre>
<p>The portion of the output with the error:</p>
<pre><code>Epoch 1/25
Traceback (most recent call last):
  File &quot;/home/mightymime/repos/TA-2021/src/main.py&quot;, line 111, in &lt;module&gt;
    history = autoencoder.fit(
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py&quot;, line 1183, in fit
    tmp_logs = self.train_function(iterator)
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py&quot;, line 889, in __call__
    result = self._call(*args, **kwds)
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py&quot;, line 933, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py&quot;, line 763, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py&quot;, line 3050, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py&quot;, line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py&quot;, line 3279, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py&quot;, line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;/home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 986, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *
        return step_function(self, iterator)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica
        return fn(*args, **kwargs)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **
        outputs = model.train_step(data)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:799 train_step
        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:530 minimize
        return self.apply_gradients(grads_and_vars, name=name)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:630 apply_gradients
        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)
    /home/mightymime/.local/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/utils.py:75 filter_empty_gradients
        raise ValueError(&quot;No gradients provided for any variable: %s.&quot; %

    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'latent/kernel:0', 'latent/bias:0', 'dense/kernel:0', 'dense/bias:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0'].
</code></pre>
<p>Can anyone help me debug this? Thanks in advance</p>
",I'm trying to create a autoencoder using tensorflow that analyses a dataset of cars for a university project. However the code outputs a error when starting to train that I can't seem to find the solution for. First I tried reading the tensorflow documentation for the fit function but there was no reference to this error. Next I tried to search for similar errors on StackOverflow but I couldn't find anything that was related. The portion of the output with the error: Can anyone help me debug this? Thanks in advance,https://stackoverflow.com/questions/68123049,10754901,Requesting (Additional) Resources,Requesting (Additional) Resources,First I tried reading the tensorflow documentation for the fit function but there was no reference to this error. Next I tried to search for similar errors on StackOverflow but I couldn't find anything that was related.
75364751,'Generator' object has no attribute 'shape' when trying to training model on data from generator,"<p>I have been trying to train a simpletf.keras.Sequential() model with the help of a custom generator. According to <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">this</a> I can pass a generator to model.fit() like so:</p>
<pre><code>model.fit(x=generator, epochs=5)
</code></pre>
<p>However I keep getting the following error.</p>
<pre><code>AttributeError                            Traceback (most recent call last)
Cell In[35], line 1
----&gt; 1 model.fit(x=generator, epochs=5)

File ~\venv\lib\site-packages\keras\utils\traceback_utils.py:70, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---&gt; 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File ~venv\lib\site-packages\keras\engine\data_adapter.py:885, in GeneratorDataAdapter.__init__(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)
    878     except NotImplementedError:
    879         # The above call may fail if the model is a container-like class
    880         # that does not implement its own forward pass (e.g. a GAN or
    881         # VAE where the forward pass is handled by subcomponents).  Such
    882         # a model does not need to be built.
    883         pass
--&gt; 885 self._first_batch_size = int(tf.nest.flatten(peek)[0].shape[0])
    887 def _get_tensor_spec(t):
    888     # TODO(b/226395276): Remove _with_tensor_ranks_only usage.
    889     return type_spec.type_spec_from_value(t)._with_tensor_ranks_only()

AttributeError: 'SequenceGenerator' object has no attribute 'shape'
</code></pre>
<p>The model I was trying to train:</p>
<pre><code># Create model
model = tf.keras.Sequential()
model.add(tf.keras.layers.LSTM(32,
                               input_shape=(gen_config[&quot;num_steps&quot;], 40,),
                               return_sequences=False,
                               stateful=False,
                               ))

model.add(tf.keras.layers.Dense(3, activation='softmax'))

#compile model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'],
              )
</code></pre>
<p>The generator I use to yield the inputs:</p>
<pre><code>class SequenceGenerator():

    def __iter__(self): 

        # set seed everytime that generator is restarted
        if self.seed:
            np.random.seed(self.seed)

        # set chunk_index, batch_index
        self.chunk_index = 0
        self.batch_index = 0

        # set chunk_indexer
        self._chunk_indexer_setup()  # self._chunk_indexer_reset()
        self.no_total_chunks = len(self._chunk_indexer)
        self._no_features = self.pipeline_function.no_features

        # Start iteration
        if len(self._chunk_indexer) &gt; 0:

            # Infinite iteration
            while True:

                # Fill pool of chunks if
                # (1) x_ts is not yet initialized
                # (2) self.x_ts is not enough to feed two batches
                if self.x_ts is None or len(self.x_ts) &lt; self.batch_size * 2:
                    chunk_pool = self.get_chunk_pool()

                    if len(chunk_pool) &gt; 0:
                        x, y, flag = [np.vstack(array) for array in zip(*chunk_pool)]
                        x_ts, y_ts = self._get_timeseries(x, y, flag)

                        # 1st iteration of generator
                        if self.x_ts is None:
                            self.x_ts, self.y_ts = x_ts, y_ts
                        # Iterations after 1st, i.e. observations exists: just append
                        else:
                            self.x_ts = np.concatenate((self.x_ts, x_ts))
                            self.y_ts = np.concatenate((self.y_ts, y_ts))

                # if x_ts contains at least one batch, yield batch
                # if generator is exhausted, yield empty batch
                if len(self.x_ts) &gt;= self.batch_size or self.exhausted:
                    yield self.x_ts[:self.batch_size], self.y_ts[:self.batch_size]
</code></pre>
<p>The generator outputs a tuple of length 2 (as specified in &quot;Unpacking behavior for iterator-like inputs&quot; in the documentation), consisting of two numpy arrays.
The shape of x is (32, 100, 40) and that of y is (32, 1).
I am cofused about what shape attribute model.fit() expects the generator to provide.
Any help is greatly appreciated.</p>
","I have been trying to train a simpletf.keras.Sequential() model with the help of a custom generator. According to this I can pass a generator to model.fit() like so: However I keep getting the following error. The model I was trying to train: The generator I use to yield the inputs: The generator outputs a tuple of length 2 (as specified in ""Unpacking behavior for iterator-like inputs"" in the documentation), consisting of two numpy arrays. The shape of x is (32, 100, 40) and that of y is (32, 1). I am cofused about what shape attribute model.fit() expects the generator to provide. Any help is greatly appreciated.",https://stackoverflow.com/questions/75364751,18073394,Documentation Completeness,Documentation Replicability,According to this I can pass a generator to model.fit() like so: However I keep getting the following error. 
69595923,How to decrease the learning rate every 10 epochs by a factor of 0.9?,"<p>I want to set the learning rate at 10^-3 with a decay every 10 epochs by a factor of 0.9. I am using the Adam optimizer in Tensorflow Keras. I have found this code in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay"" rel=""nofollow noreferrer"">official documentation</a>:</p>
<pre class=""lang-py prettyprint-override""><code>initial_learning_rate = 0.1

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=100000,
    decay_rate=0.96,
    staircase=True
)
</code></pre>
<p>I do not know what is this <code>decay_steps=100000</code>. Actually I want to decrease my learning rate after 10 epochs. How can I do it?</p>
",I want to set the learning rate at 10^-3 with a decay every 10 epochs by a factor of 0.9. I am using the Adam optimizer in Tensorflow Keras. I have found this code in the official documentation: I do not know what is this decay_steps=100000. Actually I want to decrease my learning rate after 10 epochs. How can I do it?,https://stackoverflow.com/questions/69595923,14808637,Documentation Replicability,Documentation Replicability,I have found this code in the official documentation: I do not know what is this decay_steps=100000. 
60786257,How to view samples from ImageDataGenerator(),"<p>I am currently working through a tutorial which is using the cifar10 images. I have written some fully working code which has the line <code>model.fit(x_train, y_train)</code> where x_train as a numpy array of dimension 50000x32x32x3 and dtype ""uint8"". I.e. it contains 50000 32x32 pixel colour images. I can display a sample of these images with calls to imshow() - it all looks and works fine.</p>

<p>But now in the next part of the tutorial it suggests that the model will generalise better if we use ImageDataGenerator() to create multiple warped (rotated, zoomed, sheered etc) versions of our training images. I want to better understand ImageDataGenerator() by displaying some of the warped images that are produced in the process. Looking at <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"" rel=""nofollow noreferrer"">the documentation</a>, it gives the following example:</p>

<pre><code># here's a more ""manual"" example
for e in range(epochs):
    print('Epoch', e)
    batches = 0
    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):
        model.fit(x_batch, y_batch)
        batches += 1
        if batches &gt;= len(x_train) / 32:
            # we need to break the loop by hand because
            # the generator loops indefinitely
            break
</code></pre>

<p>My current code (without warping) trains the model with the line <code>model.fit(x_train, y_train)</code>, so looking at the line in the example <code>model.fit(x_batch, y_batch)</code> I assume that x_batch must be a collection of 32 different warped versions of the current x_train image. I tried to write some code so that I could actually display the 32 images like so:</p>

<pre><code>import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

def print_array_info(v):
    print(""{} is of type {} with shape {} and dtype {}"".format(v,
                                                           eval(""type({})"".format(v)),
                                                           eval(""{}.shape"".format(v)),
                                                           eval(""{}.dtype"".format(v))
                                                           ))

def show_samples(array_of_images):
    n = array_of_images.shape[0]
    total_rows = 1+int((n-1)/5)
    total_columns = 5
    fig = plt.figure()
    gridspec_array = fig.add_gridspec(total_rows, total_columns)

    for i, img in enumerate(array_of_images):
        row = int(i/5)
        col = i % 5
        ax = fig.add_subplot(gridspec_array[row, col])
        ax.imshow(img)

    plt.show()


cifar_data = tf.keras.datasets.cifar10
(x_train, y_train), (x_test, y_test) = cifar_data.load_data()

data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20)

print_array_info(""x_train"")

batches = 0
batch_size=32

for x_batch, y_batch in data_generator.flow(x_train, y_train, batch_size=batch_size):
    print_array_info(""x_batch"")
    batches += 1
    if batches &gt;= len(x_train) / 32:
        break
    show_samples(x_batch[:batch_size])
</code></pre>

<p>I thought that the first time through the loop I would be shown 32 different warped versions of the zeroth image in x_train. But when I run this it produces almost blank images - I say almost because one or to of them may contain a few garbage looking pixels. I expected x_batch to be of size 32x32x32x3, i.e. a collection of 32 colour images of size 32x32pixels and 3 colours which indeed appears true but the dtype was float32 which confuses me - I thought the warping process would not change the dtype.</p>

<p>Have I got a bug in my code or have I misunderstood the documentation?</p>
","I am currently working through a tutorial which is using the cifar10 images. I have written some fully working code which has the line model.fit(x_train, y_train) where x_train as a numpy array of dimension 50000x32x32x3 and dtype ""uint8"". I.e. it contains 50000 32x32 pixel colour images. I can display a sample of these images with calls to imshow() - it all looks and works fine. But now in the next part of the tutorial it suggests that the model will generalise better if we use ImageDataGenerator() to create multiple warped (rotated, zoomed, sheered etc) versions of our training images. I want to better understand ImageDataGenerator() by displaying some of the warped images that are produced in the process. Looking at the documentation, it gives the following example: My current code (without warping) trains the model with the line model.fit(x_train, y_train), so looking at the line in the example model.fit(x_batch, y_batch) I assume that x_batch must be a collection of 32 different warped versions of the current x_train image. I tried to write some code so that I could actually display the 32 images like so: I thought that the first time through the loop I would be shown 32 different warped versions of the zeroth image in x_train. But when I run this it produces almost blank images - I say almost because one or to of them may contain a few garbage looking pixels. I expected x_batch to be of size 32x32x32x3, i.e. a collection of 32 colour images of size 32x32pixels and 3 colours which indeed appears true but the dtype was float32 which confuses me - I thought the warping process would not change the dtype. Have I got a bug in my code or have I misunderstood the documentation?",https://stackoverflow.com/questions/60786257,169774,Documentation Ambiguity,Documentation Replication on Other Examples,"Looking at the documentation, it gives the following example: My current code (without warping) trains the model with the line model.fit(x_train, y_train), so looking at the line in the example model.fit(x_batch, y_batch) I assume that x_batch must be a collection of 32 different warped versions of the current x_train image. "
59657166,Convert frozen model(.pb) to savedmodel,"<p>Recently I tried to convert the model (tf1.x) to the saved_model, and followed the official <a href=""https://www.tensorflow.org/guide/migrate"" rel=""noreferrer"">migrate document</a>. However in my use case, most of model in my hand or tensorflow model zoo usually is pb file, and according to the <a href=""https://www.tensorflow.org/guide/migrate#a_graphpb_or_graphpbtxt"" rel=""noreferrer"">official document</a> says that </p>

<blockquote>
  <p>There is no straightforward way to upgrade a raw Graph.pb file to TensorFlow 2.0, but if you have a ""Frozen graph"" (a tf.Graph where the variables have been turned into constants), then it is possible to convert this to a concrete_function using v1.wrap_function:</p>
</blockquote>

<p>But I still do not understand how to converted to <a href=""https://www.tensorflow.org/guide/saved_model"" rel=""noreferrer"">saved_model format</a>.</p>
","Recently I tried to convert the model (tf1.x) to the saved_model, and followed the official migrate document. However in my use case, most of model in my hand or tensorflow model zoo usually is pb file, and according to the official document says that But I still do not understand how to converted to saved_model format.",https://stackoverflow.com/questions/59657166,2469488,Documentation Ambiguity,Documentation Ambiguity,according to the official document says that But I still do not understand how to converted to saved_model format.
75698781,Keras Migration issues ImageDataGenerator to image_dataset_from_directory,"<p>It appears that <code>ImageDataGenerator</code> has been deprecated <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"" rel=""nofollow noreferrer"">after TF 2.10</a>. Thus, I wanted to change my code to avoid using this class and use pre-processing layers to do the augmentation.</p>
<p>The recommendation on TF Documentation is to use <code>image_dataset_from_directory</code>. But I'm having problems with this class as now I get a lot of errors about the type of file.</p>
<p>I'm using the Kaggle Cats-vs-Dogs dataset to test this. Here is the code using the <code>ImageDataGenerator</code>:</p>
<pre><code>val_data_gen = ImageDataGenerator(rescale=1/255.0)
train_data_gen = ImageDataGenerator(rescale=1/255.0,
                                    rotation_range=15,
                                    width_shift_range=0.1,
                                    height_shift_range=0.1,
                                    shear_range=0.1,
                                    zoom_range=0.1,
                                    horizontal_flip=True,
                                    fill_mode='nearest')

train_generator = train_data_gen.flow_from_directory(
    directory=train_dir,
    batch_size=128,
    class_mode='binary',
    target_size=(150, 150))

val_generator = val_data_gen.flow_from_directory(
    directory=val_dir,
    batch_size=128,
    class_mode='binary',
    target_size=(150, 150))
</code></pre>
<p>For the approach using <code>image_dataset_from_directory</code>, I create the preprocessing layers like:</p>
<pre><code>augmentation = keras.Sequential(
[
    layers.Resizing(150, 150),
    layers.Rescaling(1./255),
    layers.RandomFlip(&quot;horizontal&quot;),
    layers.RandomRotation(0.05, fill_mode='nearest'),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.5),
])
</code></pre>
<p>I add them to my model using:</p>
<pre><code>model.add(layers.InputLayer(input_shape=(300, 300, 3)))
model.add(augmentation)
</code></pre>
<p>And then I create the datasets using:</p>
<pre><code>train_ds = tf.keras.utils.image_dataset_from_directory(
TRAIN_DIR,
image_size=(150, 150),
label_mode='binary',
shuffle=True,
seed=101,
batch_size=128
)
</code></pre>
<p>Same thing goes for the validation set. However with <code>image_dataset_from_directory</code> I get:</p>
<pre><code>Unknown image file format. One of JPEG, PNG, GIF, BMP required.
 [[{{node decode_image/DecodeImage}}]]
 [[IteratorGetNext]] [Op:__inference_train_function_6414]
</code></pre>
<p><code>ImageDataGenerator</code> works without any issue. Is this a bug?</p>
","It appears that ImageDataGenerator has been deprecated after TF 2.10. Thus, I wanted to change my code to avoid using this class and use pre-processing layers to do the augmentation. The recommendation on TF Documentation is to use image_dataset_from_directory. But I'm having problems with this class as now I get a lot of errors about the type of file. I'm using the Kaggle Cats-vs-Dogs dataset to test this. Here is the code using the ImageDataGenerator: For the approach using image_dataset_from_directory, I create the preprocessing layers like: I add them to my model using: And then I create the datasets using: Same thing goes for the validation set. However with image_dataset_from_directory I get: ImageDataGenerator works without any issue. Is this a bug?",https://stackoverflow.com/questions/75698781,7056614,Documentation Replication on Other Examples,Documentation Replication on Other Examples, The recommendation on TF Documentation is to use image_dataset_from_directory. But I'm having problems with this class as now I get a lot of errors about the type of file.
46221420,How to use TensorFlow Dataset API in combination with dense layers,"<p>I am trying out the Dataset API for my input pipeline shown in the <a href=""https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets#using_high-level_apis"" rel=""nofollow noreferrer"">TensorFlow documentation</a> and use almost the same code:</p>

<pre><code>tr_data = Dataset.from_tensor_slices((train_images, train_labels))
tr_data = tr_data.map(input_parser, NUM_CORES, output_buffer_size=2000)
tr_data = tr_data.batch(BATCH_SIZE)
tr_data = tr_data.repeat(EPOCHS)

iterator = dataset.make_one_shot_iterator()
next_example, next_label = iterator.get_next()

# Script throws error here
loss = model_function(next_example, next_label)

with tf.Session(...) as sess:
    sess.run(tf.global_variables_initializer())

     while True:
        try:
            train_loss = sess.run(loss)
        except tf.errors.OutOfRangeError:
            print(""End of training dataset."")
            break
</code></pre>

<p>This should be faster since it avoids using the slow feed_dicts. But I can't make it work with my model, which is a simplified LeNet architecture. The <strong>problem</strong> is the <code>tf.layers.dense</code> in my <code>model_function()</code> which expects an known input shape (I guess because it has to know the number of weights beforehand). But <code>next_example</code> and <code>next_label</code> only get their shape by running them in the session. Before evaluating them their shape is just undefined <code>?</code></p>

<p>Declaring the <code>model_function()</code> throws this error:</p>

<blockquote>
  <p>ValueError: The last dimension of the inputs to <code>Dense</code> should be
  defined. Found <code>None</code>.</p>
</blockquote>

<p>Right now, I don't know if I am using this Dataset API in the intended way or if there is a workaround.</p>

<p>Thanks in advance!</p>

<p><strong>Edit 1:</strong> 
Below is my model and it throws the error at the first dense layer</p>

<pre><code>def conv_relu(input, kernel_shape):
    # Create variable named ""weights"".
    weights = tf.get_variable(""weights"", kernel_shape,
        initializer=tf.random_normal_initializer())
    # Create variable named ""biases"".
    biases = tf.get_variable(""biases"", kernel_shape[3],
        initializer=tf.constant_initializer(0.0))
    conv = tf.nn.conv2d(input, weights,
        strides=[1, 1, 1, 1], padding='VALID')
    return tf.nn.relu(conv + biases)

def fully(input, output_dim):
    assert len(input.get_shape())==2, 'Wrong input shape, need flattened tensor as input'
    input_dim = input.get_shape()[1]

    weight = tf.get_variable(""weight"", [input_dim, output_dim],
        initializer=tf.random_normal_initializer())
    bias = tf.get_variable('bias', [output_dim],
        initializer=tf.random_normal_initializer())

    fully = tf.nn.bias_add(tf.matmul(input, weight), bias)
    return fully


def simple_model(x):

    with tf.variable_scope('conv1'):
        conv1 = conv_relu(x, [3,3,1,10])
        conv1 = tf.nn.max_pool(conv1,[1,2,2,1],[1,2,2,1],'SAME')

    with tf.variable_scope('conv2'):
        conv2 = conv_relu(conv1, [3,3,10,10])
        conv2 = tf.nn.max_pool(conv2,[1,2,2,1],[1,2,2,1],'SAME')

    with tf.variable_scope('conv3'):
        conv3 = conv_relu(conv2, [3,3,10,10])
        conv3 = tf.nn.max_pool(conv3,[1,2,2,1],[1,2,2,1],'SAME')

    flat = tf.contrib.layers.flatten(conv3)
    with tf.variable_scope('fully1'):
        fully1 = tf.layers.dense(flat, 1000)
        fully1 = tf.nn.relu(fully1)

    with tf.variable_scope('fully2'):
        fully2 = tf.layers.dense(fully1, 100)
        fully2 = tf.nn.relu(fully2)

    with tf.variable_scope('output'):
        output = tf.layers.dense(fully2, 4)
        fully1 = tf.nn.relu(output)


    return output
</code></pre>

<p><strong>Edit 2:</strong>  </p>

<p>Here you see the print of the tensors. Notice that next_example does not have a shape</p>

<blockquote>
  <p>next_example: Tensor(""IteratorGetNext:0"", dtype=float32)<br>
  next_label: Tensor(""IteratorGetNext:1"", shape=(?, 4), dtype=float32)</p>
</blockquote>
","I am trying out the Dataset API for my input pipeline shown in the TensorFlow documentation and use almost the same code: This should be faster since it avoids using the slow feed_dicts. But I can't make it work with my model, which is a simplified LeNet architecture. The problem is the tf.layers.dense in my model_function() which expects an known input shape (I guess because it has to know the number of weights beforehand). But next_example and next_label only get their shape by running them in the session. Before evaluating them their shape is just undefined ? Declaring the model_function() throws this error: Right now, I don't know if I am using this Dataset API in the intended way or if there is a workaround. Thanks in advance! Edit 1: Below is my model and it throws the error at the first dense layer Edit 2: Here you see the print of the tensors. Notice that next_example does not have a shape",https://stackoverflow.com/questions/46221420,6661139,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I am trying out the Dataset API for my input pipeline shown in the TensorFlow documentation and use almost the same code: This should be faster since it avoids using the slow feed_dicts. But I can't make it work with my model, which is a simplified LeNet architecture"
59231031,Tensorflow: creating a diagonal matrix with input on the sub/superdiagonals,"<p>I have the following code:</p>

<pre><code>import tensorflow as tf

N = 10
X = tf.ones([N,], dtype=tf.float64)
D = tf.linalg.diag(X, k=1, num_rows=N+1, num_cols=N+1)

print(D)
</code></pre>

<p>which, based on the <a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/diag"" rel=""nofollow noreferrer"">TF2 documentation</a>, I expect to return an 11x11 tensor with X inserted on the first superdiagonal (even without the optional <code>num_rows</code> and <code>num_cols</code> arguments). However, the result is</p>

<pre><code>tf.Tensor(
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]], shape=(10, 10), dtype=float64)
</code></pre>

<p>Is there something obvious that I am missing?</p>
","I have the following code: which, based on the TF2 documentation, I expect to return an 11x11 tensor with X inserted on the first superdiagonal (even without the optional num_rows and num_cols arguments). However, the result is Is there something obvious that I am missing?",https://stackoverflow.com/questions/59231031,1799323,Documentation Replication on Other Examples,Documentation Replication on Other Examples,"I have the following code: which, based on the TF2 documentation, I expect to return an 11x11 tensor with X inserted on the first superdiagonal (even without the optional num_rows and num_cols arguments). However, the result is Is there something obvious that I am missing?"
44231072,Possible tensorflow cholesky_solve inconsistency?,"<p>I am trying to solve a linear system of equations using <a href=""https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops/matrix_math_functions#cholesky_solve"" rel=""nofollow noreferrer"">tensorflow.cholesky_solve</a> and I'm getting some unexpected results.</p>

<p>I wrote a script to compare the output of a very simple linear system with simple matrix inversion a la <a href=""https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops/matrix_math_functions#matrix_inverse"" rel=""nofollow noreferrer"">tensorflow.matrix_inverse</a>, the non-cholesky based matrix equation solver <a href=""https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops/matrix_math_functions#matrix_solve"" rel=""nofollow noreferrer"">tensorflow.matrix_solve</a>, and <code>tensorflow.cholesky_solve</code>. </p>

<p>According to my understanding of the docs I've linked, these three cases should all yield a solution of the identity matrix divided by 2, but this is not the case for <code>tensorflow.cholesky_solve</code>. Perhaps I'm misunderstanding the docs? </p>

<pre><code>import tensorflow as tf

I = tf.eye(2, dtype=tf.float32)
X = 2 * tf.eye(2, dtype=tf.float32)
X_inv = tf.matrix_inverse(X)
X_solve = tf.matrix_solve(X, I)
X_chol_solve = tf.cholesky_solve(tf.cholesky(X), I)

with tf.Session() as sess:
    for x in [X_inv, X_solve, X_chol_solve]:
        print('{}:\n{}'.format(x.name, sess.run(x)))
        print
</code></pre>

<p>yielding output:</p>

<pre><code>MatrixInverse:0:
[[ 0.5  0. ]
 [ 0.   0.5]]

MatrixSolve:0:
[[ 0.5  0. ]
 [ 0.   0.5]]

cholesky_solve/MatrixTriangularSolve_1:0:
[[ 1.  0.]
 [ 0.  1.]]


Process finished with exit code 0
</code></pre>
","I am trying to solve a linear system of equations using tensorflow.cholesky_solve and I'm getting some unexpected results. I wrote a script to compare the output of a very simple linear system with simple matrix inversion a la tensorflow.matrix_inverse, the non-cholesky based matrix equation solver tensorflow.matrix_solve, and tensorflow.cholesky_solve. According to my understanding of the docs I've linked, these three cases should all yield a solution of the identity matrix divided by 2, but this is not the case for tensorflow.cholesky_solve. Perhaps I'm misunderstanding the docs? yielding output:",https://stackoverflow.com/questions/44231072,2467355,Documentation Ambiguity,Documentation Ambiguity," According to my understanding of the docs I've linked, these three cases should all yield a solution of the identity matrix divided by 2, but this is not the case for tensorflow.cholesky_solve. Perhaps I'm misunderstanding the docs?"
56639621,how to use tensorflow tf.losses.softmax_cross_entropy?,"<p>I am doing some semantic segmentation problem and need to define loss function.</p>

<p>Does any one know how to use tensorflow ""tf.losses.softmax_cross_entropy""?</p>

<p>It is said in the documentation that the first input of the function is 
onehot_labels, so do we need to first transfer the pixel-wise class label into one hot encode format and input one hot encode into this function?</p>

<p>Or we can directly input the pixel class label like tf.losses.sigmoid_cross_entropy in this post <a href=""https://stackoverflow.com/questions/52046971/sigmoid-cross-entropy-loss-function-from-tensorflow-for-image-segmentation"">sigmoid_cross_entropy loss function from tensorflow for image segmentation</a>?</p>

<p>Thank you so much!</p>
","I am doing some semantic segmentation problem and need to define loss function. Does any one know how to use tensorflow ""tf.losses.softmax_cross_entropy""? It is said in the documentation that the first input of the function is onehot_labels, so do we need to first transfer the pixel-wise class label into one hot encode format and input one hot encode into this function? Or we can directly input the pixel class label like tf.losses.sigmoid_cross_entropy in this post sigmoid_cross_entropy loss function from tensorflow for image segmentation? Thank you so much!",https://stackoverflow.com/questions/56639621,9357193,Documentation Ambiguity,Documentation Ambiguity,"It is said in the documentation that the first input of the function is onehot_labels, so do we need to first transfer the pixel-wise class label into one hot encode format and input one hot encode into this function?"
48976538,Tensorflow AttributeError: 'module' object has no attribute 'manip',"<p>I try to roll a tensor and in the Tensorflow documentation i found a function called tf.manip.roll() but when i use it i get the error message:</p>

<p>AttributeError: 'module' object has no attribute 'manip'</p>

<p>Has someone an idea where this function has moved?</p>
",I try to roll a tensor and in the Tensorflow documentation i found a function called tf.manip.roll() but when i use it i get the error message: AttributeError: 'module' object has no attribute 'manip' Has someone an idea where this function has moved?,https://stackoverflow.com/questions/48976538,7487368,Documentation Replication on Other Examples,Documentation Replication on Other Examples,I try to roll a tensor and in the Tensorflow documentation i found a function called tf.manip.roll() but when i use it i get the error message
50433094,What do the return values of tf.metrics mean?,"<p>I've been trying to add some hopefully useful intermediate calculations used to derive my loss function to the <code>eval_metric_ops</code> dictionary for my evaluation <code>EstimatorSpec</code>. I have wrapped these in a call to <a href=""https://www.tensorflow.org/api_docs/python/tf/metrics/mean"" rel=""nofollow noreferrer""><code>tf.metrics.mean</code></a> as it seemed to fit my needs.</p>

<p>The return type of this function is a <code>tuple</code> of <code>(mean, update_op)</code>, where <code>mean</code> is ostensibly the current mean and <code>update_op</code> is an operation that computes the new mean and returns it.</p>

<p>However, when I try to evaluate it I see that the <code>value</code> and <code>update_op</code> fields seem to be different. The documentation doesn't provide an explanation for this as far as I can see.</p>

<p>For example, take the following snippet of code:</p>

<pre><code>    test_tensor = tensorflow.constant([[1, 2, 3], [4, 5, 6]])
    test_mean = tensorflow.metrics.mean(test_tensor)

    sess = tensorflow.Session()
    sess.run(tensorflow.global_variables_initializer())
    sess.run(tensorflow.local_variables_initializer())

    print sess.run(test_mean)
    print sess.run(test_mean)
    print sess.run(test_mean)
    print sess.run(test_mean)

    print sess.run(test_mean[0])
    print sess.run(test_mean)[1]
</code></pre>

<p>This returns the following:</p>

<pre><code>(0.0, 3.5)
(1.75, 3.5)
(2.3333333, 3.5)
(2.625, 3.5)
3.5
3.5
</code></pre>

<p>The second value of the tuple is obviously an overall average of the input value, but the left hand side values seem to be asymptoting towards <code>3.5</code>, while the taking the zero-index of test_mean and evaluating it results in <code>3.5</code> directly, as opposed to the value that I get by evaluating the whole operation and then taking the index.</p>

<p>What is happening here?</p>
","I've been trying to add some hopefully useful intermediate calculations used to derive my loss function to the eval_metric_ops dictionary for my evaluation EstimatorSpec. I have wrapped these in a call to tf.metrics.mean as it seemed to fit my needs. The return type of this function is a tuple of (mean, update_op), where mean is ostensibly the current mean and update_op is an operation that computes the new mean and returns it. However, when I try to evaluate it I see that the value and update_op fields seem to be different. The documentation doesn't provide an explanation for this as far as I can see. For example, take the following snippet of code: This returns the following: The second value of the tuple is obviously an overall average of the input value, but the left hand side values seem to be asymptoting towards 3.5, while the taking the zero-index of test_mean and evaluating it results in 3.5 directly, as opposed to the value that I get by evaluating the whole operation and then taking the index. What is happening here?",https://stackoverflow.com/questions/50433094,1613983,Documentation Completeness,Documentation Completeness, The documentation doesn't provide an explanation for this as far as I can see